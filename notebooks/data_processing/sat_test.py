from wtpsplit import SaT

sat = SaT("sat-12l-sm")
# optionally run on GPU for better performance
# also supports TPUs via e.g. sat.to("xla:0"), in that case pass `pad_last_batch=True` to sat.split
sat.half().to("cuda")

text = '''
I feel the choice of models used by the authors are different on 1 important aspect. It seems like except XLSR-53 all other models were trained from scratch. In my opinion there are 2 important factors in place - (1) single speaker (2) limited data on an endangered language. This can then lead to a variety of questions -  1) Which models (HMM/DNN , CTC , Enc-Dec) is better? 
2) Using pre-trained or training from scratch which is better? 
3) If using pre-trained is it better to use pre-trained model on many languages or just 1 language but multiple speakers is enough.  The results presented by the authors seem to answer these questions but only to some extent. This limits the contribution of this work. It would be great if they can add an additional "from scratch" vs "from pretrained" results for each of the model choices. 
1) Could you provide the source of the g2p rules. It's important for readers to replicate your results as the results are provided in PER and PER is also directly dependent on the ground truth phonemes generated by the g2p rule. 
2) Have you considered using a phone based model like Li et. al. 2020 and using that to then convert to phoneme based rules for the endangered language? 
3) XLSR-53 is a pre-trained acoustic model which is trained in a self-supervised manner. However there are many large multilingual or english models available that can be fine-tuned. It would be interesting to see how they work compared to XLSR-53. For example using the KALDI ASPIRE model, or models built in Dalmia et. al 2018, or multilingual models in ESPNET toolkit, or the hidden representations of the Allosaurus model in Li et. al. 2020; as done in -  https://arxiv.org/pdf/2104.01624.pdf.

'''

splits = sat.split(text, do_paragraph_segmentation=True)


for split in splits:
    print(split,'\n\n' + '='*50 + '\n\n')
