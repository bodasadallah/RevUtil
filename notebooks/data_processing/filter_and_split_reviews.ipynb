{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "/fsx/homes/Abdelrahman.Sadallah@mbzuai.ac.ae/mbzuai/review_rewrite\n",
                        "sdfsdfsdfsdfds fsdfsdf\n",
                        "**Therefore, the aspect score is: **0**\n",
                        "sdjgljsdgljslkdjgsd sldkjglsdkj sdgfdsgsd s b 2wq\n",
                        "/fsx/homes/Abdelrahman.Sadallah@mbzuai.ac.ae/mbzuai/review_rewrite\n",
                        "sdfsdfsdfsdfds fsdfsdf\n",
                        "**Therefore, the aspect score is: **0**\n",
                        "sdjgljsdgljslkdjgsd sldkjglsdkj sdgfdsgsd s b 2wq\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "from tqdm import tqdm\n",
                "import re\n",
                "import importlib\n",
                "\n",
                "module_path = Path(os.path.abspath(\"\")).parent.parent\n",
                "print(module_path)\n",
                "sys.path.append(str(module_path))\n",
                "\n",
                "from notebooks.inference import utils, rule_based_review_split\n",
                "\n",
                "importlib.reload(utils)\n",
                "\n",
                "\n",
                "processed_folder_path = f'{module_path}/data/processed'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing file: iclr_reviews.csv\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_3394774/94378738.py:11: DtypeWarning: Columns (1,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                        "  df = pd.read_csv(file_path)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of reviews from this source: 43198\n",
                        "Processing file: reviewer2_ARR_2022_reviews.csv\n",
                        "Number of reviews from this source: 573\n",
                        "Processing file: acl2017_reviews.csv\n",
                        "Number of reviews from this source: 205\n",
                        "Processing file: nips_reviews.csv\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_3394774/94378738.py:11: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,12,13,14,15,16,17,18,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                        "  df = pd.read_csv(file_path)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of reviews from this source: 39684\n"
                    ]
                }
            ],
            "source": [
                "all_reviews = []\n",
                "\n",
                "# Step 1: Check if the processed folder exists\n",
                "files = os.listdir(processed_folder_path)\n",
                "\n",
                "# Step 2: Concat reviews from all sources\n",
                "for file in files:\n",
                "    file_path = os.path.join(processed_folder_path, file)\n",
                "    if os.path.isfile(file_path) and file.endswith('.csv'):\n",
                "        print(f'Processing file: {file}')\n",
                "        df = pd.read_csv(file_path)\n",
                "        print(f'Number of reviews from this source: {len(df)}')\n",
                "\n",
                "        for index, row in df.iterrows():\n",
                "            review = row['focused_review']\n",
                "\n",
                "            if 'acl' in file:\n",
                "                source = row['filename'].split('josn')[0]\n",
                "            elif 'ARR' in file:\n",
                "                source = row['paped_id']\n",
                "            elif 'nips'in file or 'iclr' in file:\n",
                "                source = row['review_id']\n",
                "            \n",
                "            all_reviews.append({'source': source, 'focused_review': review})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Initial number of reviews: 83660\n",
                        "Number of reviews after removing one-point zero-length review 83660\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 83660/83660 [00:54<00:00, 1541.21it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of reviews with one point: 76933\n",
                        "Number of all points: 25020\n",
                        "Number of points after filtering typos and considering only bullet points: 17897\n",
                        "filtering reviwes, and only considering the ones with length of one STD away form mean.\n",
                        "Number of reviews before filtering: 5852\n",
                        "Number of the review points before filtering: 17897\n",
                        "mean: 65.08398055540034 std: 77.75540811373091 min: -12.671427558330564 max: 142.83938866913127\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 5852/5852 [00:00<00:00, 17577.21it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of the reviews after filtering: 17897\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "\n",
                "    \n",
                "all_reviews_df = pd.DataFrame(all_reviews)\n",
                "all_reviews_df['focused_review'] = all_reviews_df['focused_review'].astype(str)\n",
                "\n",
                "for index, row in all_reviews_df.iterrows():\n",
                "    review = row['focused_review']\n",
                "    review = utils.clean_text(review)\n",
                "    all_reviews_df.at[index, 'focused_review'] = review\n",
                "\n",
                "\n",
                "all_reviews_filtered = rule_based_review_split.split_and_filter(all_reviews_df,\n",
                "                                                                review_key='focused_review',\n",
                "                                                                consider_only_bullet_points=True, \n",
                "                                                                do_filter_typos=True,\n",
                "                                                                filter_short_reviews=True,\n",
                "                                                                exclude_long=False,\n",
                "                                                                exclude_short=False)\n",
                "\n",
                "\n",
                "all_reviews_filtered.to_csv(f'{module_path}/data/all_reviews.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of reviews: 5852\n",
                        "Number of reviews with one point: 1301\n",
                        "Number of reviews with more than one point: 4551\n",
                        "Precentage of reviews with one point: 0.22231715652768283\n",
                        "total number of points: 17897\n",
                        "Average number of points: 3.058270676691729\n",
                        "Max number of points: 22\n",
                        "Min number of points: 1\n",
                        "Number of samples of each source with more that one point\n",
                        "ICLR: 1775 \n",
                        "ARR: 407 \n",
                        "ACL: 166 \n",
                        "NIPS: 3504 \n",
                        "Number of points for each source\n",
                        "ICLR: 3866\n",
                        "ARR: 1754\n",
                        "ACL: 534\n",
                        "NIPS: 10442\n"
                    ]
                }
            ],
            "source": [
                "import ast\n",
                "\n",
                "\n",
                "all  = pd.read_csv(f'{module_path}/data/all_reviews.csv')\n",
                "\n",
                "num_of_points = []\n",
                "no_points = 0\n",
                "\n",
                "sources_cnt = {}\n",
                "sources_points_stats = {}\n",
                "for i,r in all.iterrows():\n",
                "    points = ast.literal_eval(r['split_review'])\n",
                "    src = r['source'].split('_')[0]\n",
                "    if len(points) == 1:\n",
                "        no_points += 1\n",
                "    else:\n",
                "        sources_points_stats[src] = sources_points_stats[src] + len(points) if src in sources_points_stats else len(points)\n",
                "    sources_cnt[src] = sources_cnt[src] + 1 if src in sources_cnt else 1\n",
                "    num_of_points.append(len(points))\n",
                "\n",
                "\n",
                "print(f'Number of reviews: {len(all)}')\n",
                "print(f'Number of reviews with one point: {no_points}')\n",
                "print(f'Number of reviews with more than one point: {len(all) - no_points}')\n",
                "print(f'Precentage of reviews with one point: {no_points/len(all)}')\n",
                "print(f'total number of points: {sum(num_of_points)}')\n",
                "print(f'Average number of points: {sum(num_of_points)/len(num_of_points)}')\n",
                "print(f'Max number of points: {max(num_of_points)}')\n",
                "print(f'Min number of points: {min(num_of_points)}')\n",
                "\n",
                "    \n",
                "\n",
                "\n",
                "print(f'Number of samples of each source with more that one point')\n",
                "for source, count in sources_cnt.items():\n",
                "    print(f'{source}: {count} ')\n",
                "\n",
                "print(f'Number of points for each source')\n",
                "for source, count in sources_points_stats.items():\n",
                "    print(f'{source}: {count}')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open('/fsx/homes/Abdelrahman.Sadallah@mbzuai.ac.ae/mbzuai/review_rewrite/outputs/test_new_spliting.txt','w')as f:\n",
                "\n",
                "\n",
                "    for i,r in all.sample(500).iterrows():\n",
                "        focused_review = r['focused_review']\n",
                "        splitted_reviews = ast.literal_eval(r['split_review'])\n",
                "        f.write(f'Focused review:\\n\\n{r[\"focused_review\"]}\\n\\n')\n",
                "        for sr in splitted_reviews:\n",
                "            f.write(f'Review Point: {sr}\\n')\n",
                "        f.write('='*50 + '\\n\\n')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "5852"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "len(all)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "preparing the data frame for annotation\n"
                    ]
                }
            ],
            "source": [
                "utils.prepare_df_to_annotation(all,f'{module_path}/data/all_review_points.csv', total_points=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['the model is hard to', 'it is hard for the model to', ' hard to made', 'hard to make']\n",
                        "Q1: the model is hard to - Q2: it is hard for the model to\n",
                        "0.7037037037037037\n",
                        "Q1: the model is hard to - Q2:  hard to made\n",
                        "0.7\n",
                        "Q1: the model is hard to - Q2: hard to make\n",
                        "0.75\n",
                        "Q1: it is hard for the model to - Q2: the model is hard to\n",
                        "0.7037037037037037\n",
                        "Q1: it is hard for the model to - Q2:  hard to made\n",
                        "0.5925925925925926\n",
                        "Q1: it is hard for the model to - Q2: hard to make\n",
                        "0.6666666666666666\n",
                        "Q1:  hard to made - Q2: the model is hard to\n",
                        "0.7\n",
                        "Q1:  hard to made - Q2: it is hard for the model to\n",
                        "0.5925925925925926\n",
                        "Q1:  hard to made - Q2: hard to make\n",
                        "0.15384615384615385\n",
                        "Q1: hard to make - Q2: the model is hard to\n",
                        "0.75\n",
                        "Q1: hard to make - Q2: it is hard for the model to\n",
                        "0.6666666666666666\n",
                        "Q1: hard to make - Q2:  hard to made\n",
                        "0.15384615384615385\n",
                        "['the model is hard to', 'it is hard for the model to', ' hard to made', 'hard to make']\n",
                        "Q1: the model is hard to - Q2: it is hard for the model to\n",
                        "0.7037037037037037\n",
                        "Q1: the model is hard to - Q2:  hard to made\n",
                        "0.7\n",
                        "Q1: the model is hard to - Q2: hard to make\n",
                        "0.75\n",
                        "Q1: it is hard for the model to - Q2: the model is hard to\n",
                        "0.7037037037037037\n",
                        "Q1: it is hard for the model to - Q2:  hard to made\n",
                        "0.5925925925925926\n",
                        "Q1: it is hard for the model to - Q2: hard to make\n",
                        "0.6666666666666666\n",
                        "Q1:  hard to made - Q2: the model is hard to\n",
                        "0.7\n",
                        "Q1:  hard to made - Q2: it is hard for the model to\n",
                        "0.5925925925925926\n",
                        "Q1:  hard to made - Q2: hard to make\n",
                        "0.15384615384615385\n",
                        "Q1: hard to make - Q2: the model is hard to\n",
                        "0.75\n",
                        "Q1: hard to make - Q2: it is hard for the model to\n",
                        "0.6666666666666666\n",
                        "Q1: hard to make - Q2:  hard to made\n",
                        "0.15384615384615385\n"
                    ]
                }
            ],
            "source": [
                "point = '''-- Typo p8 L719-721 left column: \"the model is hard to\" --> \"it is hard for the model to\"? & \" hard to made\" --> \"hard to make\"? \n",
                "'''\n",
                "import re\n",
                "quoted = r'[\"\\'“”](.*?)[\"\\'“”]'\n",
                "\n",
                "\n",
                "from similarity.normalized_levenshtein import NormalizedLevenshtein\n",
                "normalized_levenshtein = NormalizedLevenshtein()\n",
                "for i,word in enumerate(point.split()):\n",
                "            if word in ['->', '=>','-->','==>', '→', '⟶']:\n",
                "                qouted_text = re.findall(quoted,point)\n",
                "                print(qouted_text)\n",
                "                for i, q in enumerate(qouted_text):\n",
                "                    for j, q2 in enumerate(qouted_text):\n",
                "                        if i != j:\n",
                "                            print(f'Q1: {q} - Q2: {q2}')\n",
                "                            print(normalized_levenshtein.distance(q, q2))\n",
                "                # if i > 0 and normalized_levenshtein.distance( point[i+1], point[i-1]) < 0.8:\n",
                "                #     print('Typo')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>review_id</th>\n",
                            "      <th>source</th>\n",
                            "      <th>focused_review</th>\n",
                            "      <th>review_point</th>\n",
                            "      <th>human_actionability</th>\n",
                            "      <th>human_specificity</th>\n",
                            "      <th>human_verifiability</th>\n",
                            "      <th>human_politeness</th>\n",
                            "      <th>llm_actionability</th>\n",
                            "      <th>llm_specificity</th>\n",
                            "      <th>llm_verifiability</th>\n",
                            "      <th>llm_politeness</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>905</td>\n",
                            "      <td>ICLR_2023_2312</td>\n",
                            "      <td>Weaknesses\\n1. Literature Review\\nThe paper re...</td>\n",
                            "      <td>2. Unsupported claims and definitions The pape...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>4732</td>\n",
                            "      <td>NIPS_2020_1809</td>\n",
                            "      <td>- Note sure whether the authors intend to rele...</td>\n",
                            "      <td>- I'm missing a discussion why values for p di...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>612</td>\n",
                            "      <td>ICLR_2021_971</td>\n",
                            "      <td>Weaknesses\\nThe proposed algorithm is not para...</td>\n",
                            "      <td>2. The presented experimental results are not ...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>3649</td>\n",
                            "      <td>NIPS_2020_791</td>\n",
                            "      <td>There are several issues here which I would li...</td>\n",
                            "      <td>* What is the relationship between the CDF and...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>4288</td>\n",
                            "      <td>NIPS_2020_251</td>\n",
                            "      <td>* The NF assumption was not discussed as compa...</td>\n",
                            "      <td>* NKF does not show markedly better performanc...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>145</th>\n",
                            "      <td>4008</td>\n",
                            "      <td>NIPS_2020_404</td>\n",
                            "      <td>- What strikes me as surprising is the direct ...</td>\n",
                            "      <td>- The CR loss assumes all sampled points on th...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>146</th>\n",
                            "      <td>4072</td>\n",
                            "      <td>NIPS_2020_1186</td>\n",
                            "      <td>Theoretical Grounding: - Since the regret boun...</td>\n",
                            "      <td>- No ablations of β (presumably a crucial desi...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>147</th>\n",
                            "      <td>1231</td>\n",
                            "      <td>ICLR_2023_3550</td>\n",
                            "      <td>Weaknesses\\nI am not entirely sure about the u...</td>\n",
                            "      <td>• A training algorithm is individually fair if...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>148</th>\n",
                            "      <td>2297</td>\n",
                            "      <td>ACL_2017_71_review.json</td>\n",
                            "      <td>Weaknesses:  -The explanation of methods in so...</td>\n",
                            "      <td>- Based on section 2.4 it seems that topical r...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>149</th>\n",
                            "      <td>811</td>\n",
                            "      <td>ICLR_2021_1181</td>\n",
                            "      <td>Weaknesses\\n1.For domain adaptation in the NLP...</td>\n",
                            "      <td>2.The whole procedure is slightly complex. The...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>150 rows × 12 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "     review_id                   source  \\\n",
                            "0          905           ICLR_2023_2312   \n",
                            "1         4732           NIPS_2020_1809   \n",
                            "2          612            ICLR_2021_971   \n",
                            "3         3649            NIPS_2020_791   \n",
                            "4         4288            NIPS_2020_251   \n",
                            "..         ...                      ...   \n",
                            "145       4008            NIPS_2020_404   \n",
                            "146       4072           NIPS_2020_1186   \n",
                            "147       1231           ICLR_2023_3550   \n",
                            "148       2297  ACL_2017_71_review.json   \n",
                            "149        811           ICLR_2021_1181   \n",
                            "\n",
                            "                                        focused_review  \\\n",
                            "0    Weaknesses\\n1. Literature Review\\nThe paper re...   \n",
                            "1    - Note sure whether the authors intend to rele...   \n",
                            "2    Weaknesses\\nThe proposed algorithm is not para...   \n",
                            "3    There are several issues here which I would li...   \n",
                            "4    * The NF assumption was not discussed as compa...   \n",
                            "..                                                 ...   \n",
                            "145  - What strikes me as surprising is the direct ...   \n",
                            "146  Theoretical Grounding: - Since the regret boun...   \n",
                            "147  Weaknesses\\nI am not entirely sure about the u...   \n",
                            "148  Weaknesses:  -The explanation of methods in so...   \n",
                            "149  Weaknesses\\n1.For domain adaptation in the NLP...   \n",
                            "\n",
                            "                                          review_point  human_actionability  \\\n",
                            "0    2. Unsupported claims and definitions The pape...                  NaN   \n",
                            "1    - I'm missing a discussion why values for p di...                  NaN   \n",
                            "2    2. The presented experimental results are not ...                  NaN   \n",
                            "3    * What is the relationship between the CDF and...                  NaN   \n",
                            "4    * NKF does not show markedly better performanc...                  NaN   \n",
                            "..                                                 ...                  ...   \n",
                            "145  - The CR loss assumes all sampled points on th...                  NaN   \n",
                            "146  - No ablations of β (presumably a crucial desi...                  NaN   \n",
                            "147  • A training algorithm is individually fair if...                  NaN   \n",
                            "148  - Based on section 2.4 it seems that topical r...                  NaN   \n",
                            "149  2.The whole procedure is slightly complex. The...                  NaN   \n",
                            "\n",
                            "     human_specificity  human_verifiability  human_politeness  \\\n",
                            "0                  NaN                  NaN               NaN   \n",
                            "1                  NaN                  NaN               NaN   \n",
                            "2                  NaN                  NaN               NaN   \n",
                            "3                  NaN                  NaN               NaN   \n",
                            "4                  NaN                  NaN               NaN   \n",
                            "..                 ...                  ...               ...   \n",
                            "145                NaN                  NaN               NaN   \n",
                            "146                NaN                  NaN               NaN   \n",
                            "147                NaN                  NaN               NaN   \n",
                            "148                NaN                  NaN               NaN   \n",
                            "149                NaN                  NaN               NaN   \n",
                            "\n",
                            "     llm_actionability  llm_specificity  llm_verifiability  llm_politeness  \n",
                            "0                  NaN              NaN                NaN             NaN  \n",
                            "1                  NaN              NaN                NaN             NaN  \n",
                            "2                  NaN              NaN                NaN             NaN  \n",
                            "3                  NaN              NaN                NaN             NaN  \n",
                            "4                  NaN              NaN                NaN             NaN  \n",
                            "..                 ...              ...                ...             ...  \n",
                            "145                NaN              NaN                NaN             NaN  \n",
                            "146                NaN              NaN                NaN             NaN  \n",
                            "147                NaN              NaN                NaN             NaN  \n",
                            "148                NaN              NaN                NaN             NaN  \n",
                            "149                NaN              NaN                NaN             NaN  \n",
                            "\n",
                            "[150 rows x 12 columns]"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "annotation  = pd.read_csv(f'{module_path}/data/annotated_review_points.csv')\n",
                "\n",
                "\n",
                "annotation"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
