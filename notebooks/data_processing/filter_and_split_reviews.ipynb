{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fsx/homes/Abdelrahman.Sadallah@mbzuai.ac.ae/mbzuai/peerq-generation\n",
      "/fsx/homes/Abdelrahman.Sadallah@mbzuai.ac.ae/mbzuai/peerq-generation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import importlib\n",
    "\n",
    "module_path = Path(os.path.abspath(\"\")).parent.parent\n",
    "print(module_path)\n",
    "sys.path.append(str(module_path))\n",
    "\n",
    "from notebooks.inference import utils, rule_based_review_split\n",
    "\n",
    "importlib.reload(utils)\n",
    "\n",
    "\n",
    "processed_folder_path = f'{module_path}/data/processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: iclr_reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1506884/2295442157.py:12: DtypeWarning: Columns (1,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews from this source: 43198\n",
      "Processing file: reviewer2_ARR_2022_reviews.csv\n",
      "Number of reviews from this source: 573\n",
      "Processing file: acl2017_reviews.csv\n",
      "Number of reviews from this source: 205\n",
      "Processing file: nips_reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1506884/2295442157.py:12: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,12,13,14,15,16,17,18,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews from this source: 39684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83660/83660 [00:35<00:00, 2384.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering reviwes, and only considering the ones with length of one STD away form mean.\n",
      "Number of reviews before filtering: 83660\n",
      "Number of reviews before removing one-point reviews: 46112\n",
      "Number of reviews with more than one point: 6580\n",
      "Number of the review points before filtering: 23866\n",
      "mean: 80.07755803234727 std: 105.95737958465777 min: -25.879821552310503 max: 186.03493761700503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6580/6580 [00:00<00:00, 12922.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of the reviews after filtering: 23866\n"
     ]
    }
   ],
   "source": [
    "all_reviews = []\n",
    "\n",
    "\n",
    "# Step 1: Check if the processed folder exists\n",
    "files = os.listdir(processed_folder_path)\n",
    "\n",
    "# Step 4: Iterate over the files and process them\n",
    "for file in files:\n",
    "    file_path = os.path.join(processed_folder_path, file)\n",
    "    if os.path.isfile(file_path) and file.endswith('.csv'):\n",
    "        print(f'Processing file: {file}')\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f'Number of reviews from this source: {len(df)}')\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            review = row['focused_review']\n",
    "\n",
    "            if 'acl' in file:\n",
    "                source = row['filename'].split('josn')[0]\n",
    "            elif 'ARR' in file:\n",
    "                source = row['paped_id']\n",
    "            elif 'nips'in file or 'iclr' in file:\n",
    "                source = row['review_id']\n",
    "            \n",
    "            all_reviews.append({'source': source, 'focused_review': review})\n",
    "\n",
    "    \n",
    "all_reviews_df = pd.DataFrame(all_reviews)\n",
    "all_reviews_df['focused_review'] = all_reviews_df['focused_review'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "split_review_column = []\n",
    "## Split the reviews into points\n",
    "for i,r in tqdm(all_reviews_df.iterrows(),total=len(all_reviews_df)):\n",
    "    focused_review = re.sub(r'\\s+', ' ', r['focused_review'])\n",
    "\n",
    "    ## remove the first occurence of weakness or Weakness\n",
    "    remove_list = ['weakness', 'Weakness','weaknesses', 'Weaknesses']\n",
    "    for word in remove_list:\n",
    "        if focused_review.startswith(word) or focused_review.startswith(word + ':'):\n",
    "            focused_review  = ' '.join(focused_review.split()[1:])\n",
    "            \n",
    "    # Split thre review, and merge short sentences\n",
    "    splitted_reviews = rule_based_review_split.split_into_points_new(focused_review)\n",
    "    splitted_reviews = utils.merge_short_sentences(splitted_reviews)\n",
    "\n",
    "    ### TODO: Come up with a better way to merge the reviews, Why can't we save them as list\n",
    "    # all_reviews_filtered.at[i, 'split_review'] = '$$$'.join(splitted_reviews)\n",
    "\n",
    "    ##########333 Filter short reviews  ###################\n",
    "    final_split_review = []\n",
    "    for review in splitted_reviews:\n",
    "        if len(review.split()) >= 10: \n",
    "            final_split_review.append(review)\n",
    "\n",
    "\n",
    "    # print(splitted_reviews)\n",
    "    # print(final_split_review)\n",
    "\n",
    "    split_review_column.append(final_split_review)\n",
    "    # all_reviews_df['split_review'].iloc[i] = final_split_review\n",
    "    # all_reviews_df.at[i, 'split_review'] = ['dsfds','fdfdfd']\n",
    "\n",
    "\n",
    "\n",
    "all_reviews_df['split_review'] = split_review_column\n",
    "### Filter short reviews\n",
    "all_reviews_filtered = utils.filter_reviews(all_reviews_df, 'split_review')\n",
    "# print(f'Number of reviews before and after filtering: {len(all_reviews_df)} and {len(all_reviews_filtered)}')\n",
    "\n",
    "all_reviews_filtered.to_csv(f'{module_path}/data/all_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 6580\n",
      "Number of reviews with one point: 0\n",
      "Number of reviews with more than one point: 6580\n",
      "Precentage of reviews with one point: 0.0\n",
      "total number of points: 23866\n",
      "Average number of points: 3.6270516717325227\n",
      "Max number of points: 23\n",
      "Min number of points: 2\n",
      "Number of samples of each source with more that one point\n",
      "ICLR: 2274 \n",
      "ARR: 406 \n",
      "ACL: 169 \n",
      "NIPS: 3731 \n",
      "Number of points for each source\n",
      "ICLR: 7820\n",
      "ARR: 2017\n",
      "ACL: 756\n",
      "NIPS: 13273\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "all  = pd.read_csv(f'{module_path}/data/all_reviews.csv')\n",
    "\n",
    "num_of_points = []\n",
    "no_points = 0\n",
    "\n",
    "sources_cnt = {}\n",
    "sources_points_stats = {}\n",
    "for i,r in all.iterrows():\n",
    "    points = ast.literal_eval(r['split_review'])\n",
    "    src = r['source'].split('_')[0]\n",
    "    if len(points) == 1:\n",
    "        no_points += 1\n",
    "    else:\n",
    "        sources_points_stats[src] = sources_points_stats[src] + len(points) if src in sources_points_stats else len(points)\n",
    "    sources_cnt[src] = sources_cnt[src] + 1 if src in sources_cnt else 1\n",
    "    num_of_points.append(len(points))\n",
    "\n",
    "\n",
    "print(f'Number of reviews: {len(all)}')\n",
    "print(f'Number of reviews with one point: {no_points}')\n",
    "print(f'Number of reviews with more than one point: {len(all) - no_points}')\n",
    "print(f'Precentage of reviews with one point: {no_points/len(all)}')\n",
    "print(f'total number of points: {sum(num_of_points)}')\n",
    "print(f'Average number of points: {sum(num_of_points)/len(num_of_points)}')\n",
    "print(f'Max number of points: {max(num_of_points)}')\n",
    "print(f'Min number of points: {min(num_of_points)}')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "print(f'Number of samples of each source with more that one point')\n",
    "for source, count in sources_cnt.items():\n",
    "    print(f'{source}: {count} ')\n",
    "\n",
    "print(f'Number of points for each source')\n",
    "for source, count in sources_points_stats.items():\n",
    "    print(f'{source}: {count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/fsx/homes/Abdelrahman.Sadallah@mbzuai.ac.ae/mbzuai/peerq-generation/outputs/test_new_spliting.txt','w')as f:\n",
    "\n",
    "\n",
    "    for i,r in all.sample(500).iterrows():\n",
    "        focused_review = r['focused_review']\n",
    "        splitted_reviews = ast.literal_eval(r['split_review'])\n",
    "        f.write(f'Focused review:\\n\\n{r[\"focused_review\"]}\\n\\n')\n",
    "        for sr in splitted_reviews:\n",
    "            f.write(f'Review Point: {sr}\\n')\n",
    "        f.write('='*50 + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
