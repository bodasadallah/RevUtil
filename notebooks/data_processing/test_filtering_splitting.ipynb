{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filter_reviews, semantic_segmentation\n",
    "from semantic_segmentation import merge_short_sentences\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "############ This has a limitation for the cases when the point enumeration becomes more than 9\n",
    "############ This also have an issue with examples like \"3.2.1\" as it will be considered as a point\n",
    "def split_into_points(text):\n",
    "    splits_positions = []\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    for i, char in enumerate(text):\n",
    "        # match points that starts with:  - , * , = followed by a space\n",
    "        if char in ['-','*', '='] and text[i+1] == ' ':\n",
    "            if i > 0:\n",
    "                # make sure this point is preceded by a sentence ending or new line\n",
    "                if  text[i-1] in ['.','!','?','\\n'] or text[i-2] in ['.','!','?','\\n']:\n",
    "                    splits_positions.append(i)\n",
    "            else:\n",
    "                splits_positions.append(i)\n",
    "        if char.isnumeric():\n",
    "\n",
    "            ## check for x.x and x.x.x: \n",
    "            if text[i+1] == '.' and text[i+2].isnumeric():\n",
    "                i = i+2\n",
    "                continue\n",
    "            \n",
    "                \n",
    "            if text[i+1] in [')','.',':'] and text[i+2] != '\\n':\n",
    "                if i > 1:\n",
    "                    # make sure this point is preceded by a sentence ending or new line\n",
    "                    if  text[i-1] in [' ','\\n'] or text[i-2] in ['.','!','?','\\n']:\n",
    "                        splits_positions.append(i)\n",
    "                else:\n",
    "                    splits_positions.append(i)\n",
    "            ## Match when we have a number at the begining of a new line \n",
    "            elif (i == 0 or text[i-1] == '\\n') and text[i+1] == ' ':\n",
    "                splits_positions.append(i)\n",
    "\n",
    "    splits_positions = [0] + splits_positions \n",
    "    points = [ text[splits_positions[i]:splits_positions[i+1]].strip() for i in range(len(splits_positions)-1)]\n",
    "    points.append(text[splits_positions[-1]:].strip())\n",
    "\n",
    "    points = [point for point in points if point]\n",
    "    return points\n",
    "# # Example usage:\n",
    "# # paragraph = \" Attention attribution and entropy terms in section 3.2.1 needs a little more context or definition or example. \"\n",
    "# paragraph = all_reviews_df.sample(1).summary_of_weaknesses.values[0]\n",
    "# print(f\"Paragraph: {paragraph}\\n\\n\")\n",
    "# points = split_into_points(paragraph)\n",
    "# for i, point in enumerate(points, 1):\n",
    "#     print(f\"Point {i}: {point}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering reviwes, and only considering the ones with length of one STD away form mean.\n",
      "Number of the reviews before filtering: 573\n",
      "mean: 211.1405109489051 std: 124.57447410982289 min: 86.56603683908222 max: 335.71498505872796\n",
      "Number of the reviews after filtering: 374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 374/374 [00:00<00:00, 2486.66it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../../data/reviewer2_ARR_2022_reviews_gemma2.csv')\n",
    "\n",
    "df = filter_reviews.filter_reviews(df,'focused_review')\n",
    "\n",
    "new_col = []\n",
    "for i,r in tqdm(df.iterrows(),total=len(df)):\n",
    "    focused_review = re.sub(r'\\s+', ' ', r['focused_review'])\n",
    "    splitted_reviews = split_into_points(focused_review)\n",
    "    splitted_reviews = merge_short_sentences(splitted_reviews)\n",
    "\n",
    "    \n",
    "    # splitted_reviews = semantic_segmentation.split_paragraph(r['focused_review'])\n",
    "    # print(r['focused_review'].strip())\n",
    "    # print(''.join(splitted_reviews).strip())\n",
    "    # if len(''.join(splitted_reviews).strip()) != len(r['focused_review'].strip()):\n",
    "    #     print(len(''.join(splitted_reviews).strip()), len(r['focused_review'].strip()))\n",
    "    #     print(r['focused_review'].strip())\n",
    "    #     print(''.join(splitted_reviews).strip())\n",
    "\n",
    "    if abs(len(''.join(splitted_reviews).strip().replace(' ','').replace('\\n','')) - len(focused_review.strip().replace(' ','').replace('\\n',''))) > 10:\n",
    "        \n",
    "        print(''.join(splitted_reviews).strip())\n",
    "        print('\\n\\n')\n",
    "        print(focused_review.strip())\n",
    "        break\n",
    "    # assert abs(len(''.join(splitted_reviews).strip()) - len(r['focused_review'].strip())) < 10\n",
    "    new_col.append('$$$'.join(splitted_reviews))\n",
    "\n",
    "df['split_review'] = new_col\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../data/reviewer2_ARR_2022_manual_split_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- The paper is not so clear as the introduction part does not show much background about the cognitive models. The authors may need to refine the writing.$$$- This paper shows lots of analyses about the attention weights of the Transformer models. Although it presents an in-depth analysis, how to utilize these conclusions is still unclear. If the authors can present a more powerful attention mechanism which correlates better with human attention and improves task performance compared with those baselines, I will be more convinced of the conclusions. Comments:$$$1. If a model correlates better with human attention compared to other models, does it show better task performance?$$$2. Does all the experiments keep the numbers of the parameters of the compared models the same? Typos: Line 255 / Line 259: p < .05 --> p < 0.05 Line 266: Correlations grouped by sentence length shows stable values around .6 (SST) and .4-.6 (Wikipedia) except for shorter sen- tences where correlations fluctuate. -- > 0.6 0.4 0.6'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['split_review'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('split_test_0.6.txt','w')as f:\n",
    "#     for i,r in df.sample(5).iterrows():\n",
    "#     # for i, r in df.iloc[:5].iterrows():\n",
    "#         f.write(f'Focused review:\\n\\n{r[\"focused_review\"]}\\n\\n')\n",
    "#         for sr in r['split_review'].split('$$$'):\n",
    "#             f.write(f'Review Point: {sr}\\n')\n",
    "#         f.write('='*50 + '\\n\\n')\n",
    "\n",
    "        # f.write('Original Review:')\n",
    "        # f.write('\\n')\n",
    "        # f.write(r['focused_review'])\n",
    "        # f.write('\\n')\n",
    "        # f.write('$' * 50)\n",
    "        # f.write('\\n')\n",
    "        # f.write('$' * 50)\n",
    "        # f.write('\\n')\n",
    "        # f.write('Splitted Review:')\n",
    "        # f.write('\\n')\n",
    "        # for l in r['split_review']:\n",
    "        #     f.write(l)\n",
    "        #     f.write('\\n')\n",
    "        #     f.write('-' * 50)\n",
    "        #     f.write('\\n')\n",
    "        # f.write('#' * 70)\n",
    "        # f.write('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_reviews = pd.read_csv(\"../../data/reviewer2_ARR_2022_split_reviews.csv\")\n",
    "# split_reviews = split_reviews.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "for i, row in split_reviews.iterrows():\n",
    "    cur_split_review = row['split_review']\n",
    "    cur_split_review = cur_split_review.split('$$$')    \n",
    "    num_of_points = len(cur_split_review)\n",
    "    print(num_of_points)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['- The paper is not so clear as the introduction part does not show much background about the cognitive models. ',\n",
       " 'The authors may need to refine the writing.  ',\n",
       " '- This paper shows lots of analyses about the attention weights of the Transformer models. ',\n",
       " 'Although it presents an in-depth analysis, how to utilize these conclusions is still unclear. ',\n",
       " 'If the authors can present a more powerful attention mechanism which correlates better with human attention and improves task performance compared with those baselines, I will be more convinced of the conclusions. \\n',\n",
       " 'Comments: \\xa01. \\xa0If a model correlates better with human attention compared to other models, does it show better task performance?\\n\\xa0',\n",
       " '2. \\xa0Does all the experiments keep the numbers of the parameters of the compared models the same?\\n',\n",
       " 'Typos: Line 255 / Line 259:  ',\n",
       " 'p < .05 -->  p < 0.05 Line 266:  Correlations grouped by sentence length shows stable values around .6  (SST) and .4-.6 (Wikipedia) except for shorter sen-    ',\n",
       " 'tences where correlations fluctuate. -- > 0.6  0.4 0.6 ']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_split_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
