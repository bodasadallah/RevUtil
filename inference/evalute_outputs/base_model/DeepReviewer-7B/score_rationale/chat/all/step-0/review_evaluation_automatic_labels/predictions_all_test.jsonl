{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a potential benefit of minmax optimization but lacks specific instructions on how to implement it or identify relevant scenarios, making it partially actionable.", "grounding_specificity_rationale": "The review point mentions general concepts like 'minmax optimization' and 'PDEs with advective terms' without specifying which part of the paper or methodology it refers to, making it 1.", "verifiability_rationale": "The review point contains a claim about the difficulty of minmax optimization for certain PDEs, which could be investigated, but the supporting evidence is vague and general, making it partially verifiable.", "helpfulness_rationale": "The review point identifies a relevant area for improvement and suggests a revision, making it 3, but it lacks specific, actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the practical implications of a theoretical analysis, rather than directly pointing out a flaw or weakness in the modified algorithm. While it implies a potential issue (the modified algorithm might be less practical), it doesn't explicitly state what is wrong with the modified algorithm or how it needs to be improved. The actionability is indirect, focusing on the *why* rather than the *what*.", "grounding_specificity_rationale": "The review point explicitly mentions 'the modified learning algorithm' and 'Algorithm 1', providing strong grounding. It clearly identifies the specific area of the paper being discussed. The grounding is explicit and accurate.", "verifiability_rationale": "The review point is a question, not a statement that requires verification. It doesn't present a claim that needs to be supported by evidence. Therefore, it doesn't fit into the verifiability categories.", "helpfulness_rationale": "The review point is a question posed to the author, asking for justification for a design choice. While this can be helpful for the author to consider the practical implications of their theoretical work, it doesn't directly provide actionable feedback on how to improve the modified algorithm. It's a question without a proposed solution or direction. The helpfulness is limited to prompting the author to consider the practical aspects of their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the suggestion to 'empirically validate this claim' but doesn't provide the explicit action of 'validate' or the concrete steps to do so. The suggestion is present, making it 3, but the lack of explicit steps makes it '4'.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper (e.g., 'Section 3.2', 'Table 1') or a unique element. It is a general critique about the claim made in the paper. Therefore, it is 1 in the paper's content.", "verifiability_rationale": "The review point makes a claim about the paper's lack of empirical validation for the diversity coefficient. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. Therefore, the claim is not verifiable based on the information provided in the review point.", "helpfulness_rationale": "The review point identifies a specific weakness in the paper (lack of empirical validation for a key metric) and connects it to the paper's core focus (Task2Vec and model diversity). This provides clear and actionable feedback that empowers the authors to address this gap. Therefore, it is 5 in guiding the authors towards improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review points out a preference (inefficiency) and suggests an alternative (canary examples). This doesn't directly tell the authors *what* to do. It's more of an observation and a suggestion for improvement in their *process*, not their draft itself.", "grounding_specificity_rationale": "The review is broad and doesn't ground the comment in a specific part of the paper. It comments on the *concept* of canary clients vs. canary examples, not a specific element within the paper.", "verifiability_rationale": "The review states a preference ('more inefficient'), which is a claim. The verifiability of this claim would require the authors to investigate and provide evidence. The review itself doesn't *prove* or *disprove* the inefficiency.", "helpfulness_rationale": "The review offers a suggestion for improvement (making the process more efficient), which is better than no suggestion. However, the suggestion is broad and lacks concrete steps, making it less helpful than a review that provides more specific feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that they do not understand the relevance of 'Carefl' to the paper. While they identify a specific mention in the method section (Equation 6), they do not provide a clear action or suggestion for the authors to take based on this lack of clarity. The reviewer's statement is a direct criticism of a concept's relevance, which could be considered an implicit action, but it lacks the explicitness and concreteness expected. The reviewer does not specify what is missing or how the authors should proceed.", "grounding_specificity_rationale": "The reviewer mentions 'Equation (6)' as the only place 'Carefl' is mentioned in the method description. While this indicates a potential reference point, the reviewer does not explicitly identify which part of the paper (e.g., a specific section, table, figure) is being addressed. The reviewer's statement is about the *location* of a mention, not a precise identification of a section or table. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer states 'Not clear why Carefl is relevant to this paper'. This statement expresses a lack of understanding or justification for the relevance of 'Carefl'. There is X being made, nor is there any suggestion that 'Carefl' needs to be verified or supported by evidence. The statement is a direct criticism of the lack of clarity, making it 1.", "helpfulness_rationale": "The reviewer's comment directly points out a lack of clarity regarding the relevance of 'Carefl'. This is a clear and actionable feedback for the authors, indicating that they need to better understand this concept. While the reviewer does not explicitly state what is missing, the criticism itself is a helpful piece of feedback. The authors can directly address the lack of clarity the reviewer has experienced."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the approach is 'computeintensive' and that it 'assumes that the resultant GAA model is performant enough to provide meaningful prompts to annotators'. While these statements imply a lack of actionability for the authors, they are not explicit actions themselves. The reviewer points to potential issues but doesn't detail the specific steps the authors need to take to address them. The assumption about the GAA model's performance is also not an actionable statement that the authors can directly implement. Therefore, while the issues are implied, the lack of specific actionable steps makes this point 2.", "grounding_specificity_rationale": "The reviewer mentions 'pretraining on the same dataset' and 'resultant GAA model'. This provides some level of grounding as the authors can infer the specific aspects being referred to. However, the reviewer does not explicitly state which dataset or model variant is being used, making it only a weak grounding. The reviewer also mentions 'computeintensive' and 'assumptions about the resultant GAA model', which are vague and do not specify what needs to be addressed in this context. Therefore, the grounding is weak and the specificity is underspecified, making it 'Weakly Grounded and UnderSpecific'.", "verifiability_rationale": "The reviewer makes claims such as 'This approach is computeintensive' and 'It assumes that the resultant GAA model is performant enough to provide meaningful prompts to annotators'. These are statements that can be considered claims as they express opinions or judgments about the approach. However, the reviewer does not provide any evidence or reasoning to support these claims. They are presented as assumptions without backing. Therefore, the claims are 1.", "helpfulness_rationale": "The reviewer points out potential issues with the proposed approach, such as its computational intensity and the assumption about the GAA model's performance. While these issues are relevant to the authors, the review lacks concrete suggestions or guidance on how to address them. The reviewer does not offer any actionable steps or alternative approaches. Therefore, the review is likely to be '2' as it identifies problems but doesn't provide significant solutions."}
{"actionability_label": "Explicit and Concrete", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The statement explicitly mentions 'high dependence on the server dataset' as a limitation of the proposed method. This directly points to a specific area where the authors should focus to improve their draft. The action is to identify and address the dependence on the server dataset.", "grounding_specificity_rationale": "The comment explicitly mentions 'server dataset' as the part of the paper being addressed. This indicates strong grounding as the authors can directly identify the section or concept being discussed. The grounding is specific to a particular component of the work.", "verifiability_rationale": "The comment states a limitation ('high dependence on the server dataset') and its consequence ('significantly limits its potential use cases'). While it doesn't provide a solution, the limitation itself can be verified by examining the method description or experimental setup. The reasoning is present, making it 3.", "helpfulness_rationale": "The review point clearly identifies a weakness in the proposed method ('high dependence on the server dataset') and suggests an area for improvement ('reduces the generality'). While it doesn't offer a specific solution, it provides a clear direction for the authors to investigate and potentially address the identified limitation. The feedback is directly related to the work and its potential impact."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly asks a question about the selection of downstream search methods, indicating an implicit action: the authors should consider including BO and LS. The suggestion to include these methods is direct and actionable.", "grounding_specificity_rationale": "The comment is general about the *downstream search methods* used in the *reviewed paper* without referencing a specific section or table. While it identifies a *general* area for improvement, it doesn't specify *which* part of the paper is being criticized in relation to these methods.", "verifiability_rationale": "The comment itself does not contain a claim that requires verification. It's a question about the existing methodology.", "helpfulness_rationale": "The comment identifies a potential improvement (including more downstream search methods) but lacks specific details about *why* only EA was used in the reviewed paper or *how* including BO and LS would specifically benefit that work. The suggestion is present but lacks concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a deficiency ('the paper does not sufficiently highlight this comparison') and implicitly suggests a concrete action ('a direct comparison with other sparse models is missing'). While it doesn't provide specific details on *how* to perform the comparison, the action is clear. The reviewer points to a missing element and implies the authors should address it.", "grounding_specificity_rationale": "The comment refers to 'FLOPs and FPS' generally and 'other sparse models' broadly, without specifying a particular section, table, or unique aspect of the paper. While the comment mentions Table 7 containing FLOPs for pDETR, this is a consequence of the missing comparison, not the grounding itself. The grounding is about *where* the information should be, and it's not specific.", "verifiability_rationale": "The comment contains a claim ('the paper does not sufficiently highlight this comparison') that can be verified by examining the paper for the missing FLOPs/FPS comparison. The reviewer implies that by looking at the paper, specifically Table 7 and other sections on sparse models, the authors can identify the gap. While the reviewer doesn't provide specific evidence *within the review point*, the claim itself is verifiable.", "helpfulness_rationale": "The comment directly addresses a significant omission in the paper (lack of FLOPs and FPS comparison) and provides a clear direction for improvement ('a direct comparison with other sparse models is missing'). This actionable feedback is directly beneficial for the authors to enhance their work, although the specific implementation details are not provided."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that the metrics are hard to understand and that the example provided (reversing DollyV27B) yields a misleading accuracy score. While the reviewer identifies a problem with the clarity of the metrics, they don't explicitly state how to improve the actionability of the review point. The reviewer's suggestion to provide more detail on the metrics could potentially lead to more actionable feedback for the authors.", "grounding_specificity_rationale": "The reviewer mentions \"Appendix A.1\" but does not specify which section or provide enough context to pinpoint the exact location of the metrics or the issue. The reviewer's statement is general and doesn't identify a specific part of the paper being addressed.", "verifiability_rationale": "The reviewer claims that the accuracy for binary boolean questions is measured by the number of correct answers divided by the total number of questions, and that reversing the prediction of DollyV27B would yield an accuracy of 97%. The reviewer does not provide any supporting evidence or reasoning to back up this claim within the review point itself. The claim is presented as a statement of fact without justification.", "helpfulness_rationale": "The reviewer criticizes the metrics as being hard to understand and potentially misleading. This directly impacts the helpfulness of the review point for the authors. The reviewer's point highlights a lack of clarity and potential confusion for the authors, which hinders their ability to learn from the review. While the reviewer identifies a problem, they do not offer specific suggestions on how to improve the metrics or make the review point more helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the Gaussian assumption and its potential limitations, indicating an action to be taken or a problem to be addressed. However, the specific action or solution is not clearly defined in the review point itself.", "grounding_specificity_rationale": "The reviewer directly mentions key concepts like 'Gaussian assumption,' 'r << N,' and 'finiteN expansion,' providing clear grounding for these specific aspects of the analysis. The questions are also directed at specific parts of the methodology.", "verifiability_rationale": "The reviewer poses questions about the Gaussian assumption and its practicality, which are claims that require justification. However, the review point itself does not provide any evidence or references to support these claims.", "helpfulness_rationale": "The reviewer's questions are generally helpful for clarifying the Gaussian assumption and its implications. However, the review point lacks explicit actions or verifiable claims, making the overall helpfulness somewhat limited."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point is a statement of opinion ('I feel that the similarity...') and does not explicitly state what action the author should take. While it implies a need for comparison, the specific steps or changes are not outlined. Therefore, it is implicit and vague, making it 2.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or the nature of the similarity being discussed. The author is left to infer the reference point, making the grounding weak. Therefore, it is 1.", "verifiability_rationale": "The review point is a statement of opinion ('I feel that the similarity...') and does not contain a claim that requires verification. There are no logical statements, references, or external evidence being proposed. Therefore, it contains X and is classified as such.", "helpfulness_rationale": "The review point is a subjective feeling and a suggestion for further discussion. It does not provide concrete, actionable feedback or identify specific weaknesses that the author can address. It is more of a suggestion than a constructive critique. Therefore, it is 2."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete change to be made. While it prompts the authors to reconsider their interpretation of convergence, it doesn't provide a specific 'howto' for implementing this change. The reviewer suggests a different perspective on convergence, but the action remains implicit.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific part of the paper where the concept of convergence is discussed. They offer a general interpretation of CE loss minimization. While the concept of convergence is generally understood in the context of machine learning, the reviewer doesn't pinpoint where the authors should focus their attention or how the current discussion relates to this specific interpretation. The grounding is implied rather than explicitly stated.", "verifiability_rationale": "The reviewer makes a clear claim: 'convergence should probably be considered as convergence given that CE loss can never be minimized because of the exponential.' This claim is supported by logical reasoning about the nature of CE loss minimization and its practical implications. The reviewer provides a justification for why a more practical interpretation of convergence might be beneficial. The claim is verifiable based on the understanding of CE loss and its limitations.", "helpfulness_rationale": "The review point is 5. The reviewer provides a clear and logical argument for reconsidering the definition of convergence in the context of CE loss minimization. This encourages the authors to think critically about a potentially limiting assumption and consider a more practical interpretation. This feedback directly addresses a potential area of confusion or a constraint in their work, guiding them towards a more nuanced understanding."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the authors' statement about flexibility but does not provide explicit or concrete actions or suggestions on how to address this. It suggests the authors 'did not try any change or alternative in the paper to proof the robustness of the proposed framework' but does not tell the authors what to do next. The comment is about critiquing a potential improvement rather than providing actionable feedback.", "grounding_specificity_rationale": "The review point criticizes the authors' statement about flexibility but does not specify which part of the paper or element the authors are referring to. It is a general critique of the authors' approach to flexibility, not a specific comment on a particular section, table, or figure. The reviewer is speculating about the authors' intentions regarding flexibility, not pinpointing a specific area of concern.", "verifiability_rationale": "The review point contains a claim that the authors 'did not try any change or alternative in the paper to proof the robustness of the proposed framework'. However, this claim is not supported by any evidence or reasoning within the review point itself. The reviewer is stating a potential issue but does not provide any logical justification, examples, or external references to back up this assertion.", "helpfulness_rationale": "The review point raises a valid concern about the lack of robustness testing, which could be a legitimate weakness in the authors' work. By pointing out this potential issue, the reviewer is encouraging the authors to consider and address this aspect of their framework. While the review doesn't provide a solution, it highlights a potential area for improvement, which can be helpful for the authors in their selfassessment and revision process."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggestion. It asks a question, 'For the Atari game experiments, how is the number of disentangled factors chosen to be 30? In general, this might be hard to specify for an arbitrary domain.' This indicates a lack of direct guidance or improvement suggestions.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. It asks a general question about the choice of 30 disentangled factors in the Atari experiments. While it implies a concern about the 'method' section, it doesn't pinpoint a specific element within that section being questioned. The grounding is implied but not explicitly stated.", "verifiability_rationale": "The review point does not contain a claim. It is a question seeking information rather than making a statement that requires verification. Therefore, it does not have verifiability in the sense of supporting a claim with evidence.", "helpfulness_rationale": "The review point is a question seeking clarification on a methodological choice. While it highlights a potential area for improvement in the original paper (lack of justification for the number of factors), it does not directly suggest a concrete improvement or actionable step for the authors. It is more of a request for more information than a direct critique or suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment is somewhat implicit because 'By the way' suggests it's a tangential point, and the connection to the training stage isn't strongly implied. It's vague because it doesn't specify *how* to make the writing more professional.", "grounding_specificity_rationale": "The comment is not well grounded because 'By the way' makes it unclear which specific part of the paper the reviewer is referring to. It's underspecific because the reviewer doesn't identify the *exact* section or element being affected.", "verifiability_rationale": "The comment is 1 because it states a claim ('Colloquial expressions are unprofessional') but provides no supporting evidence, examples, or references.", "helpfulness_rationale": "The comment is 2 because it identifies a valid issue (professional language) but offers no concrete suggestions or actionable steps for the authors to improve their writing."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer criticizes the lack of definition for 'LLH'. While the reviewer doesn't explicitly state what 'LLH' refers to, the criticism implies a specific area of concern. The action the reviewer suggests is to define 'LLH', which is a concrete action once the meaning of 'LLH' is understood. However, the reviewer doesn't specify *where* 'LLH' is located or what aspect of the paper it pertains to, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer criticizes the lack of definition for 'LLH'. The authors cannot confidently determine which part of the paper 'LLH' addresses as its meaning is unclear. However, the reviewer clearly specifies the issue: 'this abbreviation was never defined' and 'OOD' was explicitly defined. This specificity pertains to the lack of definition, not a specific part of the paper. The criticism is about the *lack* of definition, not a specific element within the definition itself.", "verifiability_rationale": "The reviewer makes a claim: 'this abbreviation was never defined' and 'OOD' was explicitly defined. The claim about 'OOD' is stated as a fact within the review point. However, the claim about 'LLH' being *never* defined is a claim without any supporting evidence or justification within the review point itself. The reviewer states it without providing any references or logical reasoning to support this claim.", "helpfulness_rationale": "The reviewer's comment is a criticism of the lack of definition for 'LLH'. This comment identifies a potential area for improvement by suggesting that 'LLH' should be defined. The feedback is actionable in suggesting a specific action (defining 'LLH'). However, the criticism is vague about what 'LLH' refers to, making the feedback less specific and potentially less helpful for the authors in pinpointing exactly where the definition is needed."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks 'How stable is the proposed method?' and 'And what happens when stacking more layers?'. These are direct and specific questions about the stability and scalability of the method, which are actionable items for the authors to address. The reviewer identifies a potential issue (increased probability of failure with stacked layers) and proposes a solution (justification of stability), making the comment actionable.", "grounding_specificity_rationale": "The reviewer raises a concern about the stability of the proposed method when stacking multiple layers of WLS units. While they mention 'stochastic/random projection' and 'probability of the failure case,' they do not explicitly identify the *specific* part of the method where this issue arises. They imply it's across the stacked layers but don't pinpoint the exact location or cause of the failure. Therefore, the grounding is implicit and not fully specific.", "verifiability_rationale": "The reviewer states, 'My concern is that when stacking multiple layers of WLS units, the probability of the failure case of stochastic/random projection also increases (since projection is performed at each layer).' This is a statement of concern and a question about the behavior of the method. While it implies a potential issue, it doesn't provide a claim that can be verified with evidence or reasoning. The reviewer is asking a question rather than making a verifiable statement about the method's behavior.", "helpfulness_rationale": "The reviewer's point is highly relevant to the authors. They are directly addressing a potential limitation of their method (stability with stacked layers) and asking for clarification, which is a constructive suggestion for improvement. The reviewer's question is specific and directly related to the identified issue, making it a helpful point for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a *specific area* (computation of Bottleneck Distance) and identifies a *problem* (lack of clarity). While the exact steps are not provided, the reviewer implicitly suggests that the authors should clarify this computation. This makes the review implicitly pointing to an actionable step.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Definition 4.1' and 'Bottleneck Distance'. This directly identifies the specific part of the paper being addressed, providing strong grounding. The reviewer also clearly states that some sections lack clarity, specifying the nature of the issue within that part.", "verifiability_rationale": "The reviewer states that 'some sections of the paper lack clarity' and suggests that this should be improved. While the reviewer doesn't provide specific examples of the lack of clarity, the act of pointing to 'Definition 4.1' and the general statement about clarity implicitly verifies the location and nature of the problem. The reviewer is making a claim about a deficiency and suggesting a solution, which is verifiable by the authors.", "helpfulness_rationale": "The reviewer directly points out a specific area of the paper (computation of Bottleneck Distance) that is unclear. This is a concrete issue that the authors are likely to encounter while implementing or understanding their work. By highlighting this specific problem, the reviewer provides a clear direction for the authors to improve their draft. The reviewer's suggestion to 'improve their draft' is a direct and actionable goal for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a specific weakness ('weaker visualization') and suggests a concrete improvement ('longer exemplar'). While the exact placement of the exemplar isn't specified, the core action of improving the visualization is clear. The suggestion to make color assignment consistent with Figure 4 also indicates a clear action to be taken. However, the reviewer doesn't explicitly state the action of 'improving the visualization' itself, making it less explicit than fully explicit.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 5' and 'Figure 4', indicating a strong grounding. They also describe the issue in Figure 5 ('weaker visualization') and suggests a specific way to improve it ('longer exemplar', 'consistent color assignment'). This shows a clear understanding of the specific part of the paper being addressed and how to improve it.", "verifiability_rationale": "The reviewer identifies a problem ('weaker visualization') and suggests a solution ('longer exemplar', 'consistent color assignment'). While they don't provide external references, the suggestions are logically sound and based on common practices in data visualization. The problem itself ('weaker visualization leading to doubt') is a generally accepted issue. The reviewer's claim is supported by logical reasoning and common knowledge, although it could be strengthened by providing a specific example of a confusing visualization.", "helpfulness_rationale": "The reviewer directly points out a weakness in the visualization ('weaker visualization') and offers specific suggestions to improve it ('longer exemplar', 'consistent color assignment'). This directly addresses a likely area of confusion for the authors regarding their results. The suggestions are actionable and specific to the issues identified. While the exact location of the exemplar isn't specified, the reviewer clearly indicates what needs to be done to improve the visualization."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggest a change to the authors' work. It raises a question about a design choice (using PEFT for a small model) rather than directly instructing the authors on what to do. While it implies a potential inefficiency, it doesn't pinpoint a specific action the authors should take.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or the authors' work. It's a general question about the relationship between model size and training method. The reviewer is asking for clarification, not identifying a specific section or element that needs addressing.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It's a question prompting the authors to consider an alternative approach (full finetuning) rather than stating a fact that needs justification.", "helpfulness_rationale": "The review point is 3 because it raises a valid question about the necessity of using a parameterefficient training method for a small model. It prompts the authors to consider an alternative approach (full finetuning) and potentially leads to a discussion about the tradeoffs between different training methods. While it doesn't provide a concrete solution, it highlights a potential point of confusion or a missed opportunity for the authors to optimize their workflow."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer's statement about the proposed method being 'specific and not scalable' lacks a clear action for the authors to take. While the authors *intend* to create a challenging set, the reviewer questions the *implementation* and its potential to be broadly applicable. The vagueness in the description makes it difficult for the authors to understand how to achieve this 'specific and not scalable' approach. The reviewer is pointing to a gap between the intended goal and the concrete steps outlined, suggesting a lack of actionable information.", "grounding_specificity_rationale": "The reviewer's comment is a general assessment of the authors' intention to create a challenging set. They do not specify a particular section, table, figure, or unique aspect of the paper that they are referring to. The comment is about the general idea of creating a challenging set, not about any specific element within the paper.", "verifiability_rationale": "The reviewer's claim that the authors' description is 'specific and not scalable' is a subjective assessment without clear supporting evidence or logical reasoning. The reviewer is making a general judgment about the lack of specificity and scalability, but they do not provide any concrete examples or references to back up this claim. The statement is presented as a general observation rather than a specific claim supported by evidence.", "helpfulness_rationale": "The reviewer's comment expresses a negative opinion about the potential of the proposed method due to its lack of clarity and scalability. This directly impacts the helpfulness for the authors. The reviewer is questioning whether the authors' intention to create a challenging set is a worthwhile or achievable goal given the unclear description. The comment lacks a clear, actionable suggestion or critique that would empower the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the dependency of the method on the 'optimal value function corresponding to reward function' without requiring any inference. This makes the criticism directly actionable by the authors in terms of understanding a key aspect of the method.", "grounding_specificity_rationale": "The comment does not specify which part of the paper or method it is referring to. It is a general critique of the method's reliance on a specific concept. Therefore, it is 1 in a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The comment presents a potential weakness (strong reliance) but does not provide any evidence, examples, or references to support this claim. It is a statement of opinion rather than a verifiable claim.", "helpfulness_rationale": "The comment identifies a potential limitation of the proposed method, which can be helpful for the authors to understand its limitations. However, it does not offer specific suggestions or actions to address this limitation, making it less helpful in terms of providing concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the approach is 'derivative' and describes it as 'taking two existing approaches and combining them'. This clearly identifies an action: identifying the approach as derivative. While the reviewer doesn't provide specific details on *how* to implement this derivative approach, they do explain the *what*, making it somewhat concrete in identifying the issue. Therefore, the actionability is somewhat concrete.", "grounding_specificity_rationale": "The reviewer states the approach is 'derivative' and that it 'takes two existing approaches and combines them'. While the reviewer doesn't explicitly name the specific sections, tables, figures, or unique elements of the paper being addressed, the description of the derivative approach strongly implies a specific combination of existing components. This leaning towards 'full grounding' is because the *type* of derivative is described, even if the *specific* elements aren't. The specificity is also high as the reviewer clearly specifies what the derivative approach entails: combining two existing approaches. Therefore, the grounding specificity is 5.", "verifiability_rationale": "The reviewer makes a claim: 'The approach is derivative.' They then provide a justification for this claim by stating: 'It's not bad. I'm fine with derivatives if they work.' While this justification offers some context, it doesn't provide concrete evidence or references to support the claim that derivatives are inherently not bad or that the authors are fine with them. The justification is more of a statement of personal opinion rather than a verifiable fact. Therefore, the verifiability is 3.", "helpfulness_rationale": "The reviewer's point identifies a potential weakness in the approach (it being derivative) and offers a perspective on its acceptability. While the reviewer doesn't provide specific, actionable improvements, they highlight a potential issue and offer a viewpoint. This point provides some insight into the authors' concerns and can guide further discussion or investigation. Therefore, the helpfulness is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests a 'photographic style transfer method' as a potential improvement and points out the lack of such baselines in the evaluation. This is an explicit suggestion of a concrete method. While the reviewer doesn't explicitly state how to implement this, the suggestion itself is a clear action. Therefore, the review points out a potential area for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'photographic style transfer method' as a potential improvement. This directly identifies the specific part of the paper (the evaluation section) where this improvement could be applied. The reviewer also points out the 'lack of comparisons against any other potential baseline approaches in the evaluation', which clearly specifies the area where the grounding is lacking. This is fully grounded as the technique and the area are clearly identified.", "verifiability_rationale": "The reviewer claims that a 'photographic style transfer method would achieve similar, if not better, effects'. While the reviewer doesn't provide specific examples or references to support this claim within this review point, the concept of style transfer is generally understood in the field. The claim is based on a plausible idea, even without specific evidence. Therefore, it is 3 based on general knowledge and the plausibility of the concept.", "helpfulness_rationale": "The reviewer provides a concrete suggestion for improvement by proposing 'a photographic style transfer method' as a baseline. This directly addresses a potential weakness in the paper, which is the lack of comparisons against baseline approaches. The suggestion is actionable and points to a specific area for the authors to focus on. Therefore, the review is 5 in guiding the authors towards a concrete improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a clear problem: the difficulty in mapping symbols between Figure 2 and the equations. They propose that clarifying this mapping would improve understanding. While the reviewer doesn't explicitly state a concrete action, the act of pointing out the issue and suggesting a solution demonstrates a clear intention to address it. The reviewer's statement, 'For example, the authors did not explain what C_i, Q_i, R_i and A_i in Figure 2 mean in the main context,' directly implies a desire to understand these elements. The reviewer's intention to improve understanding is a clear indication of a potential action, even if not explicitly stated.", "grounding_specificity_rationale": "The reviewer provides a highly specific grounding by directly pointing out the lack of explanation for specific elements in both Figure 2 and the main text. They name specific symbols (C_i, Q_i, R_i, A_i) and the potential discrepancy with S_i. The reviewer's statement, 'In addition, to my understanding, S_i in Figure 2 is different from the calligraphic S_j (line 431), but if so, how to compute S_i was not explained in this paper,' demonstrates a precise identification of a specific issue and a clear understanding of what is missing. The reviewer's ability to pinpoint the exact elements and their meaning demonstrates a high level of grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about their understanding: 'the difficulty in mapping the symbols (e.g., C_0, C_1, etc.) in Figure 2 to those in the equations makes it difficult to understand the details of the proposed method.' This claim is 3 because the reviewer explicitly states their difficulty in understanding. However, the reviewer does not provide any evidence or justification for their claim, such as pointing to specific parts of the paper that are unclear or providing examples. The lack of supporting evidence makes it difficult to fully verify the claim. The reviewer's statement, 'In addition, to my understanding, S_i in Figure 2 is different from the calligraphic S_j (line 431), but if so, how to compute S_i was not explained in this paper,' itself is a claim that needs justification, as the paper does not explain how to compute S_i.", "helpfulness_rationale": "The reviewer states their intention to improve understanding: 'For example, the authors did not explain what C_i, Q_i, R_i and A_i in Figure 2 mean in the main context, making it difficult to know how to compute each node in Figure 2.' This statement is a clear indication of a desire to understand and improve the paper. While the reviewer does not explicitly state a concrete action they will take to address this, the desire to understand is a strong indicator of helpfulness. The reviewer's intention to clarify the mapping and explain the symbols demonstrates a desire to improve the paper's clarity and accessibility. However, the lack of a concrete action makes the helpfulness somewhat limited."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The request is explicit: 'I wished the number of backtracking steps and the acceptance rate were also studied'. However, it does not provide concrete instructions on how to tune these parameters. The request is vague in terms of action, as it doesn't directly instruct the author on what to do with this information.", "grounding_specificity_rationale": "The review point is a request for information about the number of backtracking steps and the acceptance rate. It does not explicitly identify a specific part of the paper being addressed. The request is general and does not pinpoint where these parameters are used or how they affect the results.", "verifiability_rationale": "The review point does not contain a claim. It is a request for information, not a statement of what is the case. Therefore, it does not have verifiability in the sense of supporting a claim.", "helpfulness_rationale": "The review point identifies a potential area for improvement by suggesting the need for further analysis of the hyperparameters. While it doesn't directly suggest an improvement, it points towards a valuable piece of information that could be useful for the author. The request is about gaining more understanding, which can lead to better tuning."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer is directly asking for clarification on a key detail (the objective function) in the paper. This constitutes an explicit action that the authors should take to understand the experimental setup. While the action itself is not very concrete (they don't specify *how* the DNN is trained to optimize the accuracy), the request for clarification is a valuable piece of feedback that would help the authors understand the evaluation process. Therefore, while not entirely actionable in terms of implementation, the request points towards a necessary step for improvement.", "grounding_specificity_rationale": "The reviewer is pointing out a lack of specificity in the paper regarding the objective function. While the paper mentions 'DNN\u2019s accuracy,' it doesn't explicitly state whether this refers to validation or test set accuracy. This makes the grounding somewhat weak because the reviewer cannot confidently determine which part of the paper they are addressing. The specificity is also underspecified because the paper doesn't provide a clear justification for choosing either validation or test accuracy. Therefore, the grounding is not fully grounded, and the specificity is not fully specific.", "verifiability_rationale": "The reviewer is making a claim about the ambiguity of the objective function definition in the paper. They are stating that the paper lacks clarity on whether the DNN's accuracy is being optimized on the validation or test set. This is a verifiable claim because if the authors were to add this clarification, it would be verifiable by pointing to the relevant section of the paper where the objective function is described. The claim is supported by the lack of explicit detail in the paper.", "helpfulness_rationale": "The review point is helpful because it directly addresses a potential point of confusion for the authors regarding the experimental details. By clarifying whether the DNN's accuracy is optimized on the validation or test set, the authors can better understand the evaluation process and potentially reproduce or build upon the work. The request for clarification is a valuable piece of feedback that would improve the clarity and reproducibility of the paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'I think, section 3.1 fits better inside related work, so the 3.2 can become section 3'. This action is clearly defined and provides a specific direction for improvement. The reviewer proposes a concrete change to the paper's structure.", "grounding_specificity_rationale": "The review point explicitly refers to 'section 3.1' and 'section 3.2', identifying the specific parts of the paper being discussed. It also explains why section 3.1 might be misplaced ('fits better inside related work'). This demonstrates strong grounding specificity as the authors can directly identify the referenced part and understand the issue with it.", "verifiability_rationale": "The review point makes a claim: 'section 3.1 fits better inside related work'. While it doesn't provide external references or logical reasoning to support this claim, the suggestion itself can be considered a form of implicit justification. The reviewer is offering a proposed solution, which implies that the current placement of section 3.1 is problematic.", "helpfulness_rationale": "The review point is 5 because it directly addresses a potential structural issue by suggesting a specific reorganization of the paper's sections. The reviewer proposes a concrete action ('section 3.1 fits better inside related work, so the 3.2 can become section 3'), which provides a clear next step for the authors. While the suggestion lacks supporting evidence, it is a specific and actionable piece of feedback."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests 'I suggest the authors perform additional evaluation on the VOT dataset'. This is a direct and actionable recommendation for the authors to improve their work. The suggestion is clear and provides a specific direction for the authors to take.", "grounding_specificity_rationale": "The reviewer suggests 'perform additional evaluation on the VOT dataset' and further specifies 'comparing the methods in terms of different metrics like Accuracy, Robustness, and EAO'. This shows a clear understanding of the current evaluation and provides specific details on what the authors should do. While the reviewer doesn't explicitly name a 'framework' or 'competing methods', the suggestion is about evaluating the framework on a new dataset, which is grounded. The specificity comes from naming the dataset and the metrics.", "verifiability_rationale": "The reviewer states 'Such an evaluation is good' which is a statement of opinion and doesn't require verification. However, the reviewer also suggests 'So I suggest the authors perform additional evaluation on the VOT dataset...'. This is a claim that requires justification (why is this suggestion good?). The reviewer implies it improves evaluation rigor by adding a new metric (VOT) and comparing against different metrics (Accuracy, Robustness, EAO).", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors to improve their evaluation. The suggestion is to evaluate on the VOT dataset using Accuracy, Robustness, and EAO metrics. This directly addresses a potential weakness (limited evaluation metrics) and offers a concrete alternative. The reviewer's intent is to help the authors improve their work by providing a specific and actionable direction."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'the method is not compared to any state of the art unsupervised semantic segmentation technique.' This is a direct and clear identification of a missing comparison, making it 5. The action is to compare the proposed method to stateoftheart unsupervised semantic segmentation techniques.", "grounding_specificity_rationale": "The comment explicitly mentions 'the method' and 'unsupervised semantic segmentation technique,' clearly identifying the specific part of the paper and the missing element. This is a strong example of full grounding and specificity.", "verifiability_rationale": "The comment contains a claim ('the method is not compared to any state of the art unsupervised semantic segmentation technique') that lacks supporting evidence or justification. There is no logical reasoning, common knowledge, or external references provided to back up this statement. Therefore, it is not verifiable.", "helpfulness_rationale": "The comment identifies a valid concern about the lack of comparison to unsupervised semantic segmentation techniques. However, it does not provide any suggestions or guidance on how the authors could address this issue. It simply states the problem without offering actionable steps. Therefore, it is 3 in identifying a gap but lacks actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a problem: 'To be honest, I'm not sure the first curvefinding part explains well why the FGE work.' They then ask a question: 'The cyclical learning rate scheduling would perturb the weight around the initial converged weight, but it cannot guarantee that weight is changing along the curve described in the first part.' This indicates an implicit action: the reviewer is trying to understand the connection and identify a potential gap. While they don't state the exact action they would take, the question implies a desire for more clarity on how the scheduling relates to the initial explanation. The action is somewhat vague as the reviewer doesn't specify *how* the connection should be explained or what specific details are missing.", "grounding_specificity_rationale": "The reviewer states: 'To be honest, I'm not sure the first curvefinding part explains well why the FGE work.' This directly points to a lack of clarity in a specific part of the paper. However, the reviewer doesn't explicitly identify *which* part of the paper is unclear. They are making a general statement about the connection between two concepts. Therefore, the grounding is weak because the reviewer cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer states: 'To be honest, I'm not sure the first curvefinding part explains well why the FGE work.' This can be considered a claim that the explanation is lacking. The reviewer then asks a question, implying that the current explanation is insufficient. This lack of specific examples or references makes the claim somewhat underspecific. The verifiability is somewhat underspecific because the reviewer doesn't provide concrete evidence or examples to support their claim about the lack of clarity.", "helpfulness_rationale": "The reviewer provides a clear criticism: 'To be honest, I'm not sure the first curvefinding part explains well why the FGE work.' They also suggest a potential improvement: 'The cyclical learning rate scheduling would perturb the weight around the initial converged weight, but it cannot guarantee that weight is changing along the curve described in the first part.' This suggests the reviewer is aware of a potential issue and is offering a suggestion for improvement. The criticism is specific to the connection between the curvefinding part and the cyclical learning rate. The helpfulness is 3 because the reviewer is pointing out a potential weakness in the authors' explanation and suggesting a direction for improvement."}
{"actionability_label": "Low", "grounding_specificity_label": "Low", "verifiability_label": "Medium", "helpfulness_label": "Medium", "actionability_rationale": "The reviewer does not explicitly state an action the authors should take. Instead, they point out a gap in the analysis of the distillation strategy results. They suggest the authors should provide more reasoning and explore the reasons behind the performance discrepancies between different distillation methods. The reviewer is prompting the authors to take action, but not directly instructing them on what to do. The action is implied rather than stated.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific section, table, figure, or unique aspect of the paper that needs clarification. They are making a general suggestion about the analysis of the results. The reviewer's comment is at a high level and doesn't target a particular element of the paper.", "verifiability_rationale": "The reviewer makes a claim: 'can the authors provide more reasoning/hypotheses based on the performance?' This claim is supported by the observation of the performance discrepancy between LFADSHard and LFADSSoft in Table 3, and the subsequent question about the general performance of NDTCorrelation. The reasoning is present in the reviewer's question itself, and the evidence is the observed performance differences. The claim is verifiable based on the presented results and the reviewer's request for further explanation.", "helpfulness_rationale": "The reviewer provides suggestions for improving the paper, specifically by including a case study with synthetic datasets and providing more reasoning/hypotheses for the observed performance differences. These suggestions are actionable and directly address the identified gap in the analysis. The reviewer is not asking for a retraction or a completely different approach, but rather for more information and analysis to support the current approach. The suggestions are relevant and would likely enhance the paper's clarity and completeness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer's suggestion is an explicit action that is also concrete. They are proposing a specific type of evaluation (clozestyle or question answering) and a specific area to focus on (factual knowledge generation). This provides a clear direction for the authors to improve their evaluation methodology. The action is explicit because the reviewer directly names the type of evaluation, and it is concrete because they provide specific methods for creating these evaluations.", "grounding_specificity_rationale": "The reviewer's point is explicitly grounded in the paper by focusing on the 'factual knowledge generation' aspect. They are not just broadly criticizing the evaluation of LM loss but specifically pointing out a lack of focus on factual knowledge within that evaluation. The specificity comes from the reviewer naming the exact area of the paper that needs improvement and suggesting concrete ways to address it.", "verifiability_rationale": "The reviewer's suggestion is not a claim but rather a suggestion for improvement. However, the *verifiability* of the *suggestion* itself is relevant. The proposed methods (clozestyle, question answering) are wellestablished and verifiable. Their verifiability comes from their established use in NLP. The reviewer isn't introducing a novel *concept* but rather suggesting a *method*. The verifiability lies in the fact that these methods are known and can be implemented.", "helpfulness_rationale": "The reviewer's point is 5 because it directly addresses a potential weakness in the authors' evaluation strategy. They are pointing out that focusing solely on LM loss might not be sufficient for assessing factual knowledge generation. By suggesting specific evaluation methods (clozestyle, question answering) tailored to factual knowledge, the reviewer provides the authors with concrete and actionable steps to improve their evaluation. This directly addresses a potential gap in the authors' analysis."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point directly identifies areas for improvement in the paper, specifically asking for theoretical or topological explanations for the sensitivity of the RTD score and justifying its specific application to network representation. These are concrete and actionable suggestions that authors can use to enhance their work.", "grounding_specificity_rationale": "The reviewer does not explicitly state which part of the paper is being addressed by the RTD score or why it is specifically suitable for network representation. The reference is general, lacking a precise identification of a section, table, figure, or unique aspect. The reviewer mentions 'As the key contribution, author claimed that RTD score is sensitive to cluster and verify this in experiments' and 'However, any theoretical or topological sides should be explained for the sensitive RTD score? It seems that the proposed RTD could be applied to measure any vectors with same size. Why it is specifically works for network representation?', indicating a lack of specific grounding in the paper's content or methodology. The reviewer is asking about the general applicability and specific relevance, but not pinpointing a specific element being discussed.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are asking for explanations and justifications, which is a request, not a claim to be proven. While the underlying intent is related to verifiability, the reviewer's statement itself does not contain a claim that needs to be supported by evidence. The reviewer states, 'As the key contribution, author claimed that RTD score is sensitive to cluster and verify this in experiments' and 'However, any theoretical or topological sides should be explained for the sensitive RTD score? It seems that the proposed RTD could be applied to measure any vectors with same size. Why it is specifically works for network representation?', which are questions or requests for information, not assertions that need verification.", "helpfulness_rationale": "The review point is a direct question about the methodology and the rationale behind the RTD score's specific application to network representation. This is a clear and actionable question that is likely to be helpful for the authors in understanding and improving their work. The reviewer is asking for clarification on a key aspect of their contribution, which is directly relevant to the validity and applicability of their results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the paper tries to make the case that ROCK has similar complexity as the original model. This is a direct and clear criticism that can be acted upon by the authors. The reviewer also provides specific details about the added layers in ROCK, which further clarifies the intended action.", "grounding_specificity_rationale": "The reviewer makes a general claim about the complexity of ROCK compared to the original model. While the reviewer later provides specific details about the added layers (8 conv layers, 3 pooling layers, and 1 fusion layer), this information alone doesn't explicitly identify a *specific* part of the ROCK model being compared to the *original* model. The grounding is weak because the specific elements being compared are not clearly pinpointed.", "verifiability_rationale": "The reviewer claims that the paper tries to make the case that ROCK has similar complexity as the original model. However, the reviewer does not provide any evidence or justification for this claim within their review point. There is no mention of inference timings or any other supporting data to back up this assertion. Therefore, the claim is not supported by any logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer's criticism is relevant and points to a potential flaw in the Rock model's design. Highlighting this could be helpful for the authors. The reviewer also suggests a concrete experiment (ablation study) to investigate their claim. This constructive suggestion makes the criticism valuable and actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about a specific technical detail (calculating the joint probability) and suggests a concrete action (adding an equation). This directly addresses a potential area of confusion for the authors. The action is clear and the suggestion is specific.", "grounding_specificity_rationale": "The reviewer refers to 'lines 197198' and the 'part' in question, indicating a specific location and the exact area of confusion. The suggestion to 'add the equation' is also specific.", "verifiability_rationale": "The reviewer states a question and a suggestion. The suggestion itself is a general principle ('add the equation'). While the *action* (adding an equation) is verifiable, the *initial question* about the joint probability in a nonautoregressive context might require a deeper understanding of the underlying model architecture to fully grasp the reviewer's point. However, the suggestion itself is a clear, actionable step.", "helpfulness_rationale": "The reviewer directly asks a question about a specific technical detail (calculating the joint probability) and suggests a concrete improvement (adding an equation for clarity). This directly addresses a potential need for the authors to understand this specific aspect of their model. The suggestion is actionable and directly addresses the identified weakness."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a lack of discussion on dataset limitations but does not provide specific actions or suggestions on how to address these limitations. The reviewer points out *what is missing* (limited discussion, rare conditions, variations, noisy data, imbalanced data, incomplete/inaccurate labels) but does not recommend *what needs to be done*.", "grounding_specificity_rationale": "The reviewer mentions 'dataset' as the area lacking discussion. While they identify specific aspects of the dataset (rare conditions, variations, noisy data, etc.), they do not pinpoint a specific section, table, figure, or unique element of the paper they are referring to. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer states a lack of discussion on dataset limitations. This can be considered a claim that needs justification. The reviewer implicitly identifies the area (dataset) and states that it is not adequately discussed. However, they do not provide specific examples or references to support this claim.", "helpfulness_rationale": "The review point highlights a crucial area often overlooked by reviewers: the diversity and quality of the dataset. This is a valuable piece of feedback for the authors, as it directly impacts the model's performance and generalizability. However, the review point does not offer specific suggestions on how to improve the dataset or address the identified limitations."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review points out the *number* of components and stages in the model and raises a concern about the reproducibility of training due to the lack of promised code. While this is a valid concern, the review does not explicitly state what needs to be done to address this issue. The reviewer mentions 'training the model requires multiple separate stages' and 'the provided training details about data and hyperparameters do not gurantee the results are reproducible' but does not provide specific, actionable steps to improve the model or ensure reproducibility. Therefore, the review lacks explicit and direct actions that authors can take to improve their draft.", "grounding_specificity_rationale": "The review mentions 'multiple components' and 'multiple separate stages' of training. While these relate to the *model*, they do not pinpoint a specific section, table, figure, or unique aspect of the *paper* that is problematic. The reviewer is discussing the *process* of training rather than referencing a specific part of the paper and explaining what needs to be addressed in that part. Therefore, the review does not identify a specific area within the paper that requires improvement.", "verifiability_rationale": "The review makes a claim about the reproducibility of training due to the lack of promised code. This is a claim that can be evaluated. The reviewer states, 'the provided training details about data and hyperparameters do not gurantee the results are reproducible' and attributes this to the 'lack of code'. While the reviewer provides a potential reason for the lack of reproducibility, it is not a definitive proof that the specific training details mentioned are the cause. The absence of code is the evidence, not a direct link to the unguaranteed reproducibility of those specific details. Therefore, the claim is supported by evidence, but the link between the evidence and the claim is not definitively proven, making it partially verifiable.", "helpfulness_rationale": "The review identifies a potential issue with the training process (reproducibility) but does not offer specific, actionable steps to address it. While raising concerns about reproducibility is important, the lack of concrete suggestions makes the review less helpful in improving the draft. The reviewer mentions 'training the model requires multiple separate stages' and 'the provided training details about data and hyperparameters do not gurantee the results are reproducible' but does not provide any guidance on how to resolve this issue or what needs to be changed in the training process. Therefore, the review does not provide actionable feedback that empowers the authors to significantly improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing information and provides a concrete example of what is missing (total number of agents in Flow's default configuration). This makes the action clear and directly actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Flow\u2019s default configuration' as the location where the missing information should be. This is a clear and accurate identification of the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim ('Critical setup information is missing') and provides a specific example ('total number of agents in Flow\u2019s default configuration') to support it. This makes the claim verifiable.", "helpfulness_rationale": "The reviewer points out a very specific and actionable issue that would directly benefit the authors by providing necessary setup information. This is 5 for improving the draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that there are many works inferring structures unsupervisedly and questions the claim of being the 'first' for 'unsupervised scenegraph discovery'. This is a clear and actionable point for the authors to address.", "grounding_specificity_rationale": "The reviewer directly mentions 'unsupervised scenegraph discovery', which is a specific area within the paper. They also provide details about the specific concern regarding the narrow definition of 'scene graph'. This demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer provides evidence for their claim by stating 'there are a lot of works that infer structures in an unsupervised way' and explaining why the 'first' claim is problematic ('I don\u2019t think it\u2019s fair to give a very narrow definition of \u201cscene graph\u201d and claim \u201cthe first\u201d'). This provides logical reasoning and justification, making the claim 5.", "helpfulness_rationale": "The reviewer's comment is directly relevant to the authors, pointing out a potential overstatement and suggesting a more nuanced approach to defining 'scene graph'. This is a helpful and constructive feedback point."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests 'more experiments on diverse datasets' and 'more complex shape with various topologies'. These are explicit suggestions for improvement. However, the reviewer does not specify how these experiments should be conducted or what specific aspects of the model's behavior should be evaluated. The action is identified, but the implementation details are missing, making it vague.", "grounding_specificity_rationale": "The reviewer mentions 'more experiments on diverse datasets' and 'more complex shape with various topologies'. While the reviewer implicitly refers to the *general* nature of datasets and shapes, they do not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The grounding is weak because the reviewer cannot confidently determine which part the comment addresses. However, the reviewer clearly specifies the *types* of datasets and shapes they want to explore, making the specificity somewhat clear.", "verifiability_rationale": "The reviewer states that 'more experiments on diverse datasets could further demonstrate the generalization capabilities of the model' and 'more complex shape with various topologies should be evaluated to demonstrate the core idea of the proposed method.' This statement contains a claim (the potential benefits of these experiments). However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The claim is stated, but there is no justification provided.", "helpfulness_rationale": "The review point suggests two concrete directions for future experiments: 'more experiments on diverse datasets' and 'more complex shape with various topologies'. These suggestions are intended to provide direction for the authors. However, the review point lacks specificity regarding how these experiments should be conducted, what specific aspects of the model's behavior should be evaluated, and why these experiments would definitively demonstrate the generalization capabilities or evaluate the core idea. The suggestions are present, but the lack of detail and justification makes the review point not 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for comparison against methods requiring more training time. However, the specifics of this comparison, such as which methods or how this comparison should be conducted, are not provided, making the action somewhat vague and explicit.", "grounding_specificity_rationale": "The reviewer discusses the general implications of low computational requirements and the potential for training fewer models. While the intent is to highlight a relevant issue, the specific section, table, or unique aspect of the paper being addressed is not explicitly identified. The reference to 'methods that require more training time' is general.", "verifiability_rationale": "The reviewer makes a claim that 'Although low compute restrictions during test time are typically essential for inference on new examples, we need to train fewer models and thus it may render such restrictions (e.g., a hard limit of 10 minutes of training time on a single CPU core) unnecessary.' The reviewer provides logical reasoning by stating the implications of low compute and arguing that the restrictions might be unnecessary due to the ability to train fewer models. This provides sufficient justification for the claim.", "helpfulness_rationale": "The reviewer points out the potential for fewer models to render low compute restrictions unnecessary. While this is a relevant observation, the reviewer does not provide concrete suggestions or actionable steps for the authors to take based on this insight. The comment is more of an observation than a direct recommendation for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states an action: 'I suggest the authors provide more comparison between DetNas and other networks constructed by effitive block.' This action is clear and directly addresses the identified issue. However, the reviewer does not specify *how* they suggest the comparison should be made (e.g., by FLOPs, parameters, or performance metrics). Therefore, while the action is explicit, it lacks concrete details on how to implement it. This aligns with the definition of '3'.", "grounding_specificity_rationale": "The reviewer suggests comparing DetNAS with 'other networks constructed by effite block'. This is a specific type of network, although 'effite' appears to be a typo and should likely be 'efficient'. Assuming it means 'efficient block', the reviewer attempts to identify the specific part of the paper being addressed (DetNAS and networks with efficient blocks). However, the reviewer does not explicitly state *which* part of the paper this comparison should be made within (e.g., within the architecture description, the experimental setup, or the results). This makes the grounding somewhat weak. It falls into the category of '3' as the part being addressed is somewhat specific (efficient blocks), but the method of addressing it is not precisely defined.", "verifiability_rationale": "The reviewer makes a claim: 'I suggest the authors provide more comparison between DetNas and other networks constructed by effite block.' This claim is verifiable by suggesting a specific type of network for comparison. The reasoning is clear: to improve the evaluation by considering more efficient alternatives to ResNet. This aligns with the definition of '3' as the claim is verifiable but lacks specific examples or references.", "helpfulness_rationale": "The review point identifies a potential flaw in the experimental setup by pointing out the unfair comparison between DetNAS and ResNet due to the inherent efficiency of ShuffleNetv2 blocks. The reviewer offers a concrete suggestion to improve the comparison by including networks with efficient blocks. This is a valuable suggestion that could enhance the evaluation. However, the reviewer does not specify *how* this comparison should be made (e.g., by FLOPs, parameters, or performance metrics). While the suggestion is relevant and constructive, it lacks the specific details needed to be fully helpful. Therefore, I rate this review point as '3'."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "Low", "actionability_rationale": "The reviewer states their claim directly: \"This does not seem as general as e.g. the two papers I mention in point (3)\". This indicates an explicit statement of a perceived limitation. However, the suggestion to compare the methods is implicit, as the specific papers are not named at this point. Therefore, the action is explicitly stated but requires further clarification to be actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"group itself under the regular or trivial representation\" and \"homogeneous space of the group.\" This clearly identifies the specific aspects of the paper being addressed, making the grounding fully explicit and specific.", "verifiability_rationale": "The reviewer makes a claim about the generality of the method: \"This does not seem as general as e.g. the two papers I mention in point (3)\". However, this claim is presented without immediate supporting evidence or justification. While the reviewer implies the existence of these other papers, their relevance and how they demonstrate the broader generality is not explicitly stated at this point. Therefore, the claim is not yet 5.", "helpfulness_rationale": "The reviewer points out a potential limitation of the method described in the paper. While the criticism is valid, the review point itself does not offer a direct solution or suggestion for improvement. The suggestion is implicit, pointing towards a need for comparison with other methods. Therefore, the review point is not 5 in providing concrete guidance to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states the problem of complexity but doesn't explicitly recommend solutions or provide detailed steps. The action is implied but not directly stated as a solution.", "grounding_specificity_rationale": "The reviewer mentions \"realworld image editing tasks,\" \"multiple objects,\" \"flexible prompts,\" and \"practical usability.\" These are specific aspects of the application domain. The authors can easily identify the specific part of the paper being addressed, which is the application of the system to image editing and the challenges of realworld scenarios. The comment specifies what needs to be addressed in this part, which is the complexity for typical users.", "verifiability_rationale": "The comment contains a claim about the complexity of the system for typical users in realworld tasks. However, it does not provide any supporting evidence or justification for this claim. There are no logical arguments, references to external works, or examples provided to back up the statement.", "helpfulness_rationale": "The reviewer points out a limitation in the system's usability for typical users. While relevant, it's more of a criticism or observation about the current state rather than a constructive suggestion for improvement. It highlights a problem but doesn't offer a clear path forward for the authors to address it."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the significance of the contributions but does not explicitly state an action the authors should take. While it implies a problem, it lacks a direct, actionable step. The reviewer asks a question about the significance, which is a form of implicit criticism, but doesn't provide a concrete solution or direction.", "grounding_specificity_rationale": "The review point explicitly mentions 'traditional classification' and 'manifold learning' as areas for comparison. It also refers to a 'literature gap' in contrasting the technique. This clearly identifies specific parts of the paper (or areas of related work) and specifies the issue of lacking contrast. The reviewer points out a specific deficiency in the paper's discussion.", "verifiability_rationale": "The review point makes statements about the significance of the contributions and the lack of contrast with other techniques. These are opinions or judgments about the paper. While the lack of contrast could be considered a claim requiring justification, the overall point is a critique of the paper's framing and context, not a verifiable fact based on logical reasoning or external references within this specific review point.", "helpfulness_rationale": "The review point raises concerns about the significance of the contributions and the lack of contrast with other techniques. These are valid points that could help the authors improve their paper by prompting them to reevaluate their claims about significance and to include a more thorough discussion of related work. While it doesn't provide specific steps, it identifies meaningful weaknesses and suggests a direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point asks for a discussion and suggests exploring the tradeoff between dataset size and accuracy/computation time. It doesn't explicitly state *what* to do.", "grounding_specificity_rationale": "The review point explicitly mentions 'the impact of the fewshot dataset' and 'the sparsity ratio,' clearly identifying the areas being discussed.", "verifiability_rationale": "The review point makes a claim about the tradeoff between dataset size and accuracy/computation time and provides citations 1 and 2 to support the general idea of larger datasets being more accurate but more computationally expensive.", "helpfulness_rationale": "The review point suggests exploring a tradeoff and provides a direction for investigation, encouraging authors to consider the impact of dataset size on sparsity ratio. While it doesn't offer a definitive solution, it points towards a valuable area of experimentation and provides context through citations."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a gap in the explanation by stating 'the authors do not illustrate why it is better to keep representations in the same hidden space'. While it points out a missing element, it doesn't explicitly tell the authors what steps to take to address this gap or how to illustrate it. The action is implied but not explicitly stated and detailed.", "grounding_specificity_rationale": "The review point does not explicitly mention a specific section, table, figure, or unique element of the paper where the issue lies. It refers to 'representations in the same hidden space' generally, making the grounding weak. The authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point makes a claim by stating 'the authors do not illustrate why it is better to keep representations in the same hidden space, it also has not been experimentally verified that they are in the same hidden space'. It identifies a potential area for improvement and a missing experimental verification. However, it does not provide specific examples, references, or logical reasoning to support this claim. The claim is present, but it lacks sufficient justification and examples.", "helpfulness_rationale": "The review point points to potential areas for improvement in the authors' work by stating that the explanation for keeping representations in the same hidden space is missing and that the experimental verification of this is also lacking. While it highlights a gap, it does not provide concrete, actionable steps for the authors to take to address these gaps. The feedback is present but lacks specific guidance on how to improve."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states 'Lack of Sufficient Novelty in Methodologies' and 'This approach does not seem to offer a significant advancement beyond the existing methods'. These statements directly identify a lack of novelty, which is an explicit action. While the reviewer mentions 'Longitudinal Representation Learning', 'Karwande et al. (2022)', and 'Faster RCNN (Ren et al., 2015)', the core issue is the lack of novelty, which is a concrete action to identify. However, the reviewer doesn't suggest how to make it more novel, making it only implicitly stated.", "grounding_specificity_rationale": "The review point mentions 'Longitudinal Representation Learning', 'Karwande et al. (2022)', and 'Faster RCNN (Ren et al., 2015)'. While these are specific citations, the review itself does not explicitly identify a specific part of the paper being criticized. The criticism is about the general methodology. Therefore, the grounding is weak. The issues mentioned, like 'lack of sufficient novelty', are general to the methodology and not specific to a particular section or table. Thus, the grounding is partially grounded in identifying the method but not a specific part of the paper.", "verifiability_rationale": "The review point contains a claim: 'This approach does not seem to offer a significant advancement beyond the existing methods.' This is a statement that requires verification. However, the reviewer does not provide any evidence, reasoning, or external references to support this claim. There are no logical arguments or citations presented to back up the assertion that Faster RCNN doesn't offer a significant advancement. Therefore, the verifiability is 1.", "helpfulness_rationale": "The review point is a critique of the methodology, stating that it lacks sufficient novelty. It does not offer any suggestions for improvement, alternative approaches, or guidance on how to make the method more novel. The comment is more of a diagnostic statement than a prescriptive one. It informs the authors about a potential limitation but doesn't provide actionable steps for them to take. Therefore, the helpfulness is 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly mentions an action ('evaluating the gradient of conjugate function') and states it is expensive/infeasible. However, the explanation lacks specific details about *why* it is expensive/infeasible, making it somewhat vague on how to apply this knowledge.", "grounding_specificity_rationale": "The review point discusses the general concept of evaluating the gradient of a conjugate function and its computational cost. It does not specify which part of a paper or model this relates to.", "verifiability_rationale": "The review point makes a claim about the computational cost of evaluating the gradient of a conjugate function. While this is generally true, the reviewer does not provide specific examples or citations to support this claim.", "helpfulness_rationale": "The review point is about the computational cost of evaluating the gradient of the conjugate function and suggests more examples are better for a dualfree approach. While the general idea of more examples being beneficial is helpful, the connection between the cost of evaluating the gradient and the benefit of more examples is not clearly established, making it only 2."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of explicit justification for choosing a probability from the interval 0, Pcj(0). While the action of identifying this lack of explanation is implicit, the underlying action of understanding *why* this range is chosen is not clearly articulated in the original text. The reviewer is essentially inferring the need for this probability and the range within the algorithm's context, but the explicit reasoning is missing.", "grounding_specificity_rationale": "The reviewer's question about the reason for selecting from 0, Pcj(0) indicates a lack of explicit grounding in the original text. While the notation 0, Pcj(0) specifies the range, the *grounding* of this probability within the algorithm or the data approximation technique is not explicitly stated. The reviewer is asking for a clarification of *which part* of the algorithm or data this probability is associated with, suggesting a need for better grounding. The specificity of the request is for a *justification* of the range itself, which is missing.", "verifiability_rationale": "The reviewer's request for the reason behind selecting from 0, Pcj(0) constitutes a claim in the review point. However, the original text does not provide any logical reasoning, common knowledge, or external references to support this choice. The justification is missing, making the claim 1.", "helpfulness_rationale": "The reviewer's question about the reason for selecting from 0, Pcj(0) is a relevant and helpful suggestion for the authors. It directly addresses a potential point of confusion or lack of understanding in the algorithm. However, the lack of explicit explanation in the original text makes this helpful suggestion less impactful, as the authors are left to infer the reasoning rather than having it clearly stated."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a lack of definition for 'spectrum of distributions' and 'characteristic functions'. While the reviewer suggests adding a definition, the action of defining these terms is not explicitly stated in the review point itself. The reviewer identifies a potential area for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions the lines (128 and 168) where the terms 'spectrum of distributions' and 'characteristic functions' are used. This clearly indicates that the reviewer can identify the specific part of the paper being addressed, thus having 'Full Grounding'. However, the reviewer does not specify what is wrong with these definitions or how they should be defined. Therefore, the grounding is 'UnderSpecific'.", "verifiability_rationale": "The reviewer's comment is not a critique of a claim made in the paper. They are suggesting an improvement by providing a definition. Therefore, there is no 'claim' being verified or unverified in the context of the paper's content. The comment is about the quality of the writing and the potential for improvement.", "helpfulness_rationale": "The reviewer's comment directly suggests a concrete improvement for the authors by clarifying the definitions of 'spectrum of distributions' and 'characteristic functions'. This actionable suggestion is directly aimed at improving the authors' understanding and the clarity of their work. Therefore, the review point is 5 in guiding the authors."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer does not explicitly state any actions or suggestions related to the AIG task itself. They criticize the task's convincingness and suggest improvements, but these are actions taken by the authors, not the reviewer. Therefore, the review point lacks explicit actions or concrete suggestions on how to improve the AIG task.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'AIGgeneration task' and suggests improvements like 'more background' and 'benchmarking on some existing datasets, e.g. those used by LayerDAG (Li et al., 2024a)'. This clearly connects the reviewer's comment to a specific part of the paper and provides concrete suggestions for improvement. Therefore, the reviewer grounds the comment by referring to a specific aspect of the paper and suggests concrete improvements.", "verifiability_rationale": "The reviewer states a claim: 'The AIGgeneration task is not convincing' and suggests improvements: 'I believe more background should be provided for readers unfamiliar with the area of logic synthesis' and 'benchmarking the proposed method on some existing datasets, e.g. those used by LayerDAG (Li et al., 2024a), would be more convincing'. While the reviewer doesn't provide external references to support their claim about the task's convincingness, they do offer logical reasoning and suggestions for improvement based on their interpretation of the paper's content. The claim is not entirely unsupported, as it's based on their assessment of the paper's current state. Therefore, the claim is 3 based on the reviewer's interpretation and suggestions.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as 'more background should be provided' and 'benchmarking the proposed method on some existing datasets, e.g. those used by LayerDAG (Li et al., 2024a), would be more convincing'. These suggestions are directly aimed at helping the authors improve their draft. The reviewer's comments are actionable and provide concrete directions for the authors to follow. Therefore, the review point is 5 as it offers clear and actionable feedback to the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment states that some statements lack detail and some statements lack analysis. It does not specify which statements or provide any concrete actions for the authors to take. The authors are left with a general observation rather than a specific instruction.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper (e.g., a section, table, figure, or unique element) that lacks detail or analysis. It is a general statement about the writing style without pinpointing the exact location of the issue.", "verifiability_rationale": "The comment is a statement of observation: 'Some statements in this paper lack detail and analysis.' It does not make a claim that requires verification or support. There is no suggestion to prove or disprove anything, and no indication of how the authors should approach the identified issue.", "helpfulness_rationale": "The comment identifies a weakness in the paper (lack of detail and analysis in some statements). However, it does not provide any specific advice or suggestions on how the authors should address this weakness. It is a critique without a prescription for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the suggestion to compare with VAE and analyze diffusion models, their timesteps, and their impact on feature learning. This is a clear, explicit action. It also provides a concrete target for the authors (investigate diffusion models and their timesteps). The language is direct and leaves no ambiguity about the intended action.", "grounding_specificity_rationale": "The review point explicitly mentions 'VAE', 'diffusion models', 'diffusion timesteps', and 'feature learning'. These are specific elements of the paper that the reviewer is referring to. The comment is precise and points to a particular area within the paper, making it 5.", "verifiability_rationale": "The review point suggests a comparison with VAE and an analysis of diffusion models. While it doesn't provide direct evidence or logical reasoning within the review point itself, it proposes a valuable direction for investigation based on existing knowledge of generative models. The suggestion to compare and analyze is a call to action that could be supported by external references and logical reasoning. Therefore, it is 3 but lacks key elements like direct evidence within the review point.", "helpfulness_rationale": "The review point directly suggests a comparison with VAE and an analysis of diffusion models, their timesteps, and their impact on feature learning. This provides the authors with a specific direction for their work and highlights a potentially valuable area of investigation. While it doesn't offer a complete solution, it guides the authors towards a potentially insightful comparison. The suggestion is helpful in directing the authors' attention to a relevant aspect of generative models."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides explicit suggestions for improvement. They recommend removing the combination of selfsupervised tasks, ICT and DaPI, and increasing the number of negative instances. These are clear actions that authors can directly implement to potentially improve their model's performance. The reviewer also provides a numerical result (0.434 > 0.438) to support their claim about the ineffectiveness of DaPI, which further strengthens the actionable nature of the feedback.", "grounding_specificity_rationale": "The reviewer refers to specific components of their proposed solution. They mention 'the combination of selfsupervised tasks ICT and DaPI' and 'the ICoL task and the negative instances'. While the reviewer doesn't explicitly state the exact row or column in Table 4 that is problematic, they clearly identify the specific tasks and instance type being addressed. This demonstrates a degree of grounding as the reviewer pinpoints the specific areas for improvement.", "verifiability_rationale": "The reviewer makes claims that are supported by evidence. For the DaPI claim, they provide the numerical change in performance (0.434 > 0.438), which serves as direct verification. For the claim about the lack of experiments on the number of negatives, the reviewer points out a gap in the experimental methodology, which is a valid point of missing evidence. The claim about DaPI's ineffectiveness is wellsupported by the provided numerical data.", "helpfulness_rationale": "The reviewer's comments are highly specific and actionable. They directly address concerns about memory usage and the impact of negative instances. The suggestion to remove DaPI due to its ineffectiveness and the recommendation to increase negative instances are concrete and directly address potential limitations of the model. The reviewer also highlights the importance of the quality of negatives over quantity, which is a valuable insight for the authors. The inclusion of the TASB reference further contextualizes the importance of negative instance quality."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the problem: 'it is not clear what is the difference between 3 plots on the same row' and directly suggests a solution: 'I think caption should be added to emphasize that'. This clearly points to an actionable issue.", "grounding_specificity_rationale": "The comment directly refers to 'Figure 3', which is a specific part of the paper. It also specifies the issue as being related to the 'difference between 3 plots' within that figure. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The comment contains a claim that the figure is not clear and that a caption should be added. While the *consequence* of a caption improving clarity is generally known, the *reason* for the current lack of clarity is inferred. The suggestion to add a caption is verifiable, but the underlying issue isn't explicitly stated with supporting evidence or references.", "helpfulness_rationale": "The comment directly identifies a weakness in the figure and provides a clear and actionable suggestion to improve it. This directly addresses a potential area of confusion for the authors and empowers them to make the figure clearer."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the limitation of handcrafted PSEs regarding computational complexity. However, it lacks specific details on *where* this complexity arises within the GPSE implementation and does not provide concrete actions for the authors to take to address it. While the point identifies a problem, the lack of specific actions makes it somewhat vague in terms of providing actionable feedback.", "grounding_specificity_rationale": "The review point refers to 'most handcrafted PSEs' and 'often complex handcrafted PSEs' without specifying a particular section, table, figure, or unique aspect of a specific PSE. This makes the grounding of the point weak, as the authors cannot confidently determine which part the comment addresses. However, the point does specify the *area* of concern (computational complexity), adding a degree of specificity.", "verifiability_rationale": "The review point contains a claim: 'A major limitation of most handcrafted PSEs is their high complexity on large graphs.' However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. It identifies a problem but does not explain why it is a problem or suggest how to address it. Therefore, the claim is not wellverified.", "helpfulness_rationale": "The review point identifies a valid and relevant limitation of the proposed method (GPSE) \u2013 its high computational complexity on large graphs. This is a pertinent issue for authors considering the practical application of their work. However, the point does not offer any suggestions or guidance on how to mitigate this complexity. While the feedback is relevant, the lack of actionable recommendations makes it less helpful in improving the draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the issue: 'In table 1, the results on the VQA dataset are reported on the testdev split.' It also implies an action by pointing out the guideline from the VQA authors regarding reporting on the teststandard split. This makes the action quite direct.", "grounding_specificity_rationale": "The comment explicitly mentions 'table 1', 'VQA dataset', 'testdev split' and 'teststandard split'. This indicates a strong grounding as the specific part of the paper and the relevant terminology are used. The comment also implies a specific action by suggesting the authors check their Table 1 for the correct split.", "verifiability_rationale": "The comment provides a claim: 'as mentioned in the guidelines from the VQA dataset authors'. It also provides supporting evidence by stating the guideline and explaining the potential issue (overfitting) and the correct split to report on. This provides clear justification for the comment.", "helpfulness_rationale": "The comment directly points out a potential problem in the authors' reporting of results. This is likely to be helpful for the authors to identify and correct any issues in their evaluation process. While it's a negative suggestion, it's a specific and actionable feedback."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The sentence starts with 'Although it can be counted as a strength...', which is a negative statement about a potential application. The core of the point is 'the fact that its performance considerably trails that of MON raises questions about whether the methods presented here are ready to be extended to nonfully connected architectures.' This clearly states a problem and asks a question, suggesting an actionable next step for the authors. The action is stated explicitly: ' raise questions about whether the methods presented here are ready to be extended to nonfully connected architectures.' This is a direct instruction for the authors. However, while the what is stated, the how or why isn't deeply elaborated. The authors are told to consider the performance difference but aren't given specific steps to take.", "grounding_specificity_rationale": "The sentence starts with 'Although it can be counted as a strength...', implying a connection to a previous discussion or concept ('LBEN'). The core of the point is about the performance difference between LBEN and MON. The question is about extending methods to nonfully connected architectures. The paper *does* address the performance difference between LBEN and MON. The question directly relates to this performance difference. The authors can identify the specific issue: the performance trail. This is strong grounding. The point clearly specifies the *what* \u2013 the performance difference between LBEN and MON, and the *why* \u2013 the question about extending methods to nonfully connected architectures. This is highly specific to the comparison being made.", "verifiability_rationale": "The sentence contains a claim: 'the fact that its performance considerably trails that of MON raises questions about whether the methods presented here are ready to be extended to nonfully connected architectures.' This is a statement of observation and a question, which can be considered a suggestion for improvement. The claim is based on the observed performance difference. While the *observation* is based on the performance difference, the reviewer isn't providing *external* references or logical reasoning beyond that observation. The reasoning is present (the performance difference), but it's not deeply elaborated upon or linked to external knowledge. The claim is based on observable data (performance difference), but the reasoning is brief and lacks extensive external support.", "helpfulness_rationale": "The review points out a clear weakness (performance difference) and asks a relevant question about extending methods. This directly helps the authors understand a limitation of their current approach and guides them to consider future work. While it doesn't provide a solution, it highlights a crucial area for improvement. The reviewer identifies a specific performance gap and asks a pertinent question about the applicability of their methods. This directly informs the authors' next steps and helps them focus their efforts."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer mentions metrics but doesn't specify how to apply them.", "grounding_specificity_rationale": "The reviewer mentions 'unit tests' but doesn't specify which part of the refactoring process. The metrics are suggested but not explained in detail.", "verifiability_rationale": "The reviewer claims the pass rate is insufficient but doesn't explain why or provide evidence. The suggested metrics are offered but not justified.", "helpfulness_rationale": "The reviewer suggests alternative metrics but doesn't provide detailed guidance on how to use them or why they are better than the current approach."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement identifies a weakness (lack of sufficient novelty due to prior work on Wiener deconvolution) but lacks specific guidance on how to address it. The action is implied rather than explicitly stated and detailed.", "grounding_specificity_rationale": "The reviewer mentions 'Wiener deconvolution' generally without specifying which section, equation, or aspect of their work is being criticized.", "verifiability_rationale": "The reviewer claims 'The Wiener deconvolution has been proposed already' but does not provide any references or evidence to support this claim.", "helpfulness_rationale": "The review points out a valid concern (lack of novelty) but does not offer any concrete suggestions or alternative approaches to address it, making it unhelpful for improving the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a weakness in the connection between the spin glass analogy and the regularization term, stating that it doesn't explain how the regularization helps escape bad local minima, the effect on Parisi's order parameter, or the role of temperature/learning rate. While the reviewer doesn't explicitly state that the comment is a direct instruction, the lack of explanation implies a desire for clarification and action on the part of the authors. The reviewer points to specific areas needing further understanding, which can be acted upon by the authors to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'equation 8' as the point of connection between the spin glass analogy and the regularization term. They also list specific aspects of the spin glass theory (lowquality outputs, Parisi\u2019s order parameter, temperature/learning rate) that they believe are not adequately explained. This direct identification of the relevant part of the paper and the specific missing explanations indicate that the reviewer has pinpointed the area needing clarification, thus fully grounding the comment.", "verifiability_rationale": "The reviewer makes a claim that the connection to spin glasses is weak and lacks explanation for specific aspects. They do not provide external references to support this claim. The claim is based on the absence of certain explanations within the existing framework. While the reviewer doesn't offer new verifiable information, the identification of the missing explanations constitutes a verifiable claim about the current state of the paper. The lack of explanation is a verifiable gap.", "helpfulness_rationale": "The reviewer's comment is primarily a question for clarification regarding the theoretical underpinnings and the connection to spin glasses. While the questions are valid and could be helpful for the authors, they are quite specific and don't provide broad, actionable feedback. The reviewer is not suggesting a concrete change to the draft but rather prompting the authors to investigate specific aspects of the theory. The helpfulness is conditional on the authors performing the suggested investigations, making it 3 but not highly so."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point is 2 because it identifies the nature of the contribution as a 'direct application' but lacks specific details on what this application entails and how it should be implemented.", "grounding_specificity_rationale": "The review point is 1 because it does not specify which part of the paper it is referring to. The comment is a general assessment of the contribution's nature.", "verifiability_rationale": "The review point contains X, as it is an opinion about the contribution's nature rather than a statement requiring verification.", "helpfulness_rationale": "The review point is 1 because it criticizes the contribution as 'relatively limited' and describes it as a 'direct application,' offering no specific, actionable feedback to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests using specific tools (zoomed in regions and allinfocus images) to inspect the quality of the rendered focal stack images. This constitutes an explicit action, as the authors are directed to apply these tools. However, the action is not very concrete, as the authors are not told *exactly* where to zoom or how to use the allinfocus feature.", "grounding_specificity_rationale": "The review point refers to the 'rendered focal stack' in general but does not specify which image or region is lowresolution. It also does not point to a specific section, table, or figure in the paper. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point makes a claim that the results shown in the paper are lowresolution. It also suggests specific actions (zoomed in regions and allinfocus images) that could be used to verify this claim. While the claim itself is not directly supported by external references, the suggestion to use specific tools provides a basis for verification. The reasoning is present, even if not fully detailed.", "helpfulness_rationale": "The review point identifies a potential issue with the visual presentation of the rendered focal stack images and suggests a way to investigate it. This is helpful for the authors as it guides them to potentially improve the quality of their visualizations. While it doesn't critique the content itself, it provides actionable feedback on the presentation."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer infers that the method has high inference cost due to multiple forward passes and relies on validation data for posthoc calibration. While the reviewer correctly identifies these as limitations, they are not explicit actions or concrete details on how to apply these. The reviewer states 'multiple forward passes' and 'posthoc calibration', which are concrete actions, but the *implication* is that these are limitations, not explicit instructions for the authors to improve their draft. The reviewer does not specify how to reduce the number of forward passes or how to perform posthoc calibration without validation data.", "grounding_specificity_rationale": "The reviewer states that the comparative inference method increases the inference cost significantly due to multiple forward passes, which may be a concern for realworld applications where computational resources are limited. Moreover, the posthoc calibration requires validation data, which may not be readily available for openended generation tasks, limiting the method's applicability in these scenarios. The reviewer's comments are not focused on a specific part of the paper or method. They are broadly stating limitations of the method in general. The reviewer is making general statements about the method's limitations without pinpointing a specific section or aspect of the paper where these issues arise.", "verifiability_rationale": "The reviewer states that the comparative inference method increases the inference cost significantly due to multiple forward passes, which may be a concern for realworld applications where computational resources are limited. Moreover, the posthoc calibration requires validation data, which may not be readily available for openended generation tasks, limiting the method's applicability in these scenarios. The reviewer's comments contain claims (i.e., criticism of an experimental choice) and require verification. The reviewer states 'multiple forward passes' and 'posthoc calibration', which are claims that need to be supported. The reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The reviewer's statements are presented as facts without justification.", "helpfulness_rationale": "The reviewer states that the comparative inference method increases the inference cost significantly due to multiple forward passes, which may be a concern for realworld applications where computational resources are limited. Moreover, the posthoc calibration requires validation data, which may not be readily available for openended generation tasks, limiting the method's applicability in these scenarios. The reviewer's comments are not about the limitations of the method, but rather about the *implications* of these limitations for the authors. The reviewer is pointing out general issues with the method's applicability and cost, but they are not providing specific, actionable feedback on how to improve the method or the authors' draft based on these limitations. The reviewer's comments are more about the limitations of the method rather than providing concrete feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests a solution (gradient clipping) to a stated problem (exploding gradients). It identifies the action as 'perform gradient clipping' and implies the implementation detail of setting a 'high value for the gradient norm'. This makes the action quite concrete. However, the exact method of determining this high value is not specified, making it somewhat vague on how to apply it.", "grounding_specificity_rationale": "The review point directly addresses the issue of 'exploding gradients' and suggests 'gradient clipping' as a solution. It does not explicitly refer to a specific part of the paper being addressed. The comment is focused on a general problem and a general solution. Therefore, the grounding is weak as it doesn't pinpoint the exact location of the problem in the paper.", "verifiability_rationale": "The review point identifies a problem ('exploding gradients') and suggests a solution ('gradient clipping'). It also critiques an alternative solution ('reinitializing the model') by labeling it 'quite hacky'. While the general idea of gradient clipping being a valid solution is generally verifiable, the specific implementation detail of 'high value for the gradient norm' is not explicitly justified or supported by external references. The critique of reinitialization, while subjective, points to a potential weakness in the alternative, which could be considered verifiable in the sense that reinitialization is often seen as a temporary fix.", "helpfulness_rationale": "The review point directly addresses a potential issue (exploding gradients) and offers a concrete solution (gradient clipping). It also critiques an alternative solution ('reinitializing the model') by labeling it 'quite hacky'. This provides valuable feedback to the authors on a specific problem and offers a constructive alternative. While the exact implementation detail of the gradient clipping is missing, the general suggestion is actionable and constructive. The critique of reinitialization also highlights a potential weakness in the alternative, which can guide the authors in making a more informed decision."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly asks for a definition of 'common pattern' by stating 'What is the exact meaning of 'common pattern'?'. This is an explicit action that the authors should take. However, the action itself is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The comment refers to 'common pattern' without specifying *where* in the paper this concept is being used or discussed. The reviewer doesn't have a specific section, table, or figure in mind. Therefore, the grounding is weak. The comment also doesn't specify what is meant by 'common pattern', making it not specific.", "verifiability_rationale": "The comment itself does not contain a claim that needs verification. It is a request for clarification and more information. Therefore, it falls under 'X'.", "helpfulness_rationale": "The comment directly addresses a clear need of the authors, which is to understand the concept of 'common pattern'. The request for a 'more detailed explanation' is a positive indication of how the review point can potentially help. While the comment doesn't propose a solution, it identifies a genuine area for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitation of the pretrained model to Reddit datasets and suggests testing on other sources (Twitter, Facebook). This is a clear and actionable suggestion for improving the draft by addressing a specific weakness. The reviewer identifies a concrete area for improvement and proposes a specific method to test it.", "grounding_specificity_rationale": "The reviewer correctly identifies the *type* of data (Redditspecific) as a potential limitation for generalization. They can identify the specific area being addressed (downstream tasks, model evaluation). However, they do not specify *which* parts of the Reddit data are problematic or what specific aspects of the model need adjustment. The suggestion to test on other sources is a general suggestion rather than a specific fix for the identified data.", "verifiability_rationale": "The reviewer makes a claim that the pretrained model might not generalize to datasets from other sources. However, they do not provide any evidence, reasoning, or external references to support this claim. The statement is presented as a question, indicating a lack of justification for the concern.", "helpfulness_rationale": "The reviewer provides information about the current dataset (Redditspecific) and suggests a way to test generalization (testing on other sources). While relevant, the suggestion is general and lacks specific actionable steps or a compelling reason why generalization is important. The reviewer does not offer concrete improvements or address the identified limitation in a detailed manner."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks 'How do the authors quality check the generated dataset?' This directly identifies the area of concern and the need for a process. However, it doesn't specify the methods or steps involved, making it somewhat vague and less actionable beyond identifying the need for a process.", "grounding_specificity_rationale": "The review point is about 'quality check' in general, without specifying which part of the paper or what specific issues are being addressed. It doesn't point to a particular section, table, figure, or unique element of the paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point is a question asking about a process, not a declarative statement containing a claim. It doesn't make a judgment, assertion, or request for justification. Therefore, it doesn't have verifiability.", "helpfulness_rationale": "The review point raises a valid and relevant concern for authors using LLMs, specifically the issue of hallucinations and the need for a quality control mechanism. It directly prompts for information that could help the authors improve their workflow. While it doesn't provide specific solutions, it identifies a practical problem and asks for a solution, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a difference in the training procedure of the models and contrasts it with the comparison being made. This directly points to a potential flaw in the experimental design, making it actionable.", "grounding_specificity_rationale": "The reviewer refers to 'the 4 models' and 'the other 3 models' without specifying which models are being discussed. This lack of specificity makes it difficult to pinpoint the exact issue the reviewer is addressing.", "verifiability_rationale": "The reviewer makes a claim about the meaningfulness of the comparison but doesn't provide any specific evidence, examples, or references to support this claim. This makes the claim 1.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the experimental setup and links it to the interpretation of the comparison. This suggests a valuable piece of feedback for the authors to consider the limitations of their study."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The comment explicitly states the need for more examples and suggests a specific location (Figure 2). It doesn't provide details on *how* to create these examples or where exactly they should be placed within Figure 2.", "grounding_specificity_rationale": "The comment refers to 'more examples' generally and then specifically mentions 'Figure 2.' While it points to a specific figure, the initial reference to 'examples' is broad.", "verifiability_rationale": "The comment makes a claim ('More examples such as Figure 2 would help') and provides some justification by stating the paper felt 'dense' and suggesting 'Figure 2' as an example. However, it lacks specific references to external literature or detailed explanations of *why* the paper felt dense.", "helpfulness_rationale": "The comment identifies a valid weakness ('the paper felt quite dense') and offers a concrete suggestion ('More examples such as Figure 2 would help'). While it lacks specific details on *how* to create these examples, it points in a helpful direction."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point states, '4.2 starts by providing highlevel intuition while 4.1 does not.' This is an observation about the content of the paper, not a directive for the author to make changes. It describes a difference in style but doesn't tell the author what to do or how to do it.", "grounding_specificity_rationale": "The review point mentions 'sections 4.1 and 4.2' and 'highlevel intuition.' While it identifies the sections, it doesn't pinpoint a specific element within those sections that needs improvement. The reviewer is pointing out a general difference in style rather than a specific flaw in a particular part of the paper.", "verifiability_rationale": "The review point is an observation about the structure and flow of the paper. It doesn't make a claim that requires verification. It's a suggestion for improvement based on a perceived pattern, not a statement that needs to be proven true or false.", "helpfulness_rationale": "The review point offers a suggestion for improvement by highlighting a potential redundancy if section 4.1 follows a highlevel intuition introduced in section 4.2. This provides the author with a constructive idea for restructuring the paper. While it doesn't explicitly tell the author what to do, it points out a potential area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests replacing the current permutation matrices with the ones labeled (e)(j)(o) in Figure 3. This is an explicit action, as the reviewer clearly states what should be replaced. However, the reviewer does not provide specific instructions on how to create or verify these new permutation matrices. The action is stated, but the implementation details are missing, making it somewhat incomplete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 3', 'permutation matrices', and specifically the labels '(e)(j)(o)'. This clearly identifies the specific part of the paper being addressed. The reviewer is also very specific about the elements within Figure 3. This indicates strong grounding specificity.", "verifiability_rationale": "The reviewer suggests 'more discussions' can be introduced. This is a suggestion for improvement, not a claim that needs to be verified. While the reviewer indicates a need for further analysis, they do not provide any specific examples or references to support this claim. Therefore, there is no verifiable claim in this review point.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by proposing the replacement of permutation matrices with specific labels from Figure 3 and recommending the addition of 'more discussions'. This directly addresses potential issues with the representation and encourages further analysis. The suggestion is actionable and directly targets specific elements of the paper, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for information about crowd workers, recruitment, and training. While it identifies a group and asks for actions, it doesn't explicitly or implicitly suggest how this information can be used to improve the paper.", "grounding_specificity_rationale": "The review point is a general question about the recruitment and training of crowd workers, without specifying which part of the paper or review process it relates to. It doesn't identify a specific section, table, figure, or unique element of the paper.", "verifiability_rationale": "The review point is a question, not a claim that needs verification or support. It doesn't make any statements that require logical reasoning, common knowledge, or external references to be considered valid.", "helpfulness_rationale": "The review point is informative but doesn't directly provide actionable feedback or insights that would empower the authors to improve their paper. It's about understanding the methodology of the review process rather than offering direct improvement suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the issue: 'It is mentioned that the correlation between automatic metrics and human evaluations is mainly weak.' It also suggests a direction for improvement: 'Let us not forget that human evaluations of the quality of the results are more important.' While the point identifies a problem and suggests focusing on human evaluations, the specific *how* of achieving this isn't detailed, making it somewhat implicit. The suggestion is broad, lacking concrete steps.", "grounding_specificity_rationale": "The review point mentions 'automatic metrics' and 'human evaluations' in relation to 'simplifications.' While it identifies these as related concepts, it doesn't pinpoint a specific part of the paper or analysis where this weak correlation is observed. The mention is general, lacking precise references to a particular section, table, figure, or unique element. The reviewer doesn't specify *which* automatic metrics are weakly correlated with *which* human evaluations for *simplifications*.", "verifiability_rationale": "The review point contains a claim: 'It is mentioned that the correlation between automatic metrics and human evaluations is mainly weak.' This is a statement of observation based on the text. However, the review doesn't provide any evidence or references to support this claim. It's an observation about a potentially important finding, but without backing, it's not a claim that requires verification.", "helpfulness_rationale": "The review point raises a valid concern about the limitations of automatic metrics in evaluating simplifications and emphasizes the importance of human evaluations. This directly addresses a practical issue in the field and offers a clear direction for future research or evaluation efforts. The suggestion to prioritize human evaluations is actionable and directly relevant to improving the quality of simplifications."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment asks the author to be more specific about the 'Chain of Reasoning' section, especially line 276. While it doesn't explicitly state what needs to be done, it implies the author should provide more details or clarification in that section. This makes it 3 as the author knows the area to focus on, though the exact action is not defined.", "grounding_specificity_rationale": "The comment explicitly mentions 'the 'Chain of Reasoning' section, especially line 276.' This clearly identifies the specific part of the paper being addressed, making it fully grounded. It also specifies what needs to be made more specific, making it specific as well.", "verifiability_rationale": "The comment is a request for more detail and does not contain a claim or assertion that needs verification. It is a suggestion, not a statement of opinion or judgment.", "helpfulness_rationale": "The comment points to a potential area for improvement (lack of clarity in the Chain of Reasoning) and asks the author to provide more detail. While it doesn't directly tell the author how to do this, it highlights a specific aspect of the paper that could benefit from further explanation, making it 3 in guiding the author towards improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "6", "helpfulness_label": "5", "actionability_rationale": "The positive comment about improved forecasting performance is implicit, suggesting a benefit without specifying how to achieve it. The negative comment about the missing sample quality metric is explicit. The actionability scale would be 3. 3 because the comment explicitly states an action (improving forecasting performance) but is vague on how to execute it.", "grounding_specificity_rationale": "The positive comment about improved forecasting performance is 1 as it doesn't specify which aspect of forecasting performance is improved. The negative comment about the missing sample quality metric is grounded as it explicitly mentions the CARLA data and common sample quality metrics like minADE and minMSD. Therefore, the grounding specificity scale would be 4. Mostly Grounded and UnderSpecific.", "verifiability_rationale": "The positive comment does not contain a claim. The negative comment contains a claim ('There should be some sample quality metric on the CARLA data.') and is verifiable because it refers to common metrics like minADE and minMSD. Therefore, the verifiability scale would be 6. 5.", "helpfulness_rationale": "The positive comment is not particularly helpful as it doesn't provide concrete steps for the authors. The negative comment is 5 as it points to a specific issue (missing sample quality metric) and suggests a solution (including common metrics). Therefore, the helpfulness scale would be 5. 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly asks a question about assumptions and discriminators, which can be interpreted as an implicit action to clarify these aspects. However, it doesn't specify *how* to address this or provide concrete steps. The action is present but lacks detail.", "grounding_specificity_rationale": "The comment is a general question about assumptions and discriminators and does not refer to any specific part of the paper, table, figure, or unique element. It lacks grounding as it doesn't identify a specific area of the paper being discussed.", "verifiability_rationale": "The comment, while raising a concern about assumptions and discriminators, doesn't present a claim that requires verification. It's a question posed to the authors, not a statement that needs to be proven. Therefore, it doesn't have verifiability in the sense of supporting evidence or justification.", "helpfulness_rationale": "The comment raises a valid point about the clarity of assumptions and discriminators, which could be helpful for the authors. However, it doesn't offer any specific advice or guidance on how to improve the paper based on this concern. It's a question rather than a suggestion, making it only marginally helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the relevance of Wasserstein distance in GANs and suggests considering WGAN. This is an explicit action, as the authors can directly understand the implication of this suggestion. The connection between optimal transport and Wasserstein distance is also concrete, making the action clear.", "grounding_specificity_rationale": "The comment explicitly mentions 'Wasserstein GAN (WGAN)' and 'Arjovsky et al. ICML 2017'. This is a very specific reference, allowing the authors to directly identify the relevant work. The grounding is strong as the paper and method are clearly named.", "verifiability_rationale": "The claim is that 'Wasserstein GAN (WGAN) is the first to leverage the Wasserstein Distance in GANs, specifically in the Wasserstein GAN paper (Arjovsky et al. ICML 2017). This claim is supported by the statement itself and the explicit mention of the paper. The reasoning is clear and directly points to the source of the information. External references are also provided, making the claim 5.", "helpfulness_rationale": "While the comment provides relevant information and points to a specific method (WGAN), it does not directly instruct the authors on how to implement or apply this method. The suggestion is more of a recommendation than a direct action. The authors would need to do further research and experimentation to incorporate this suggestion into their work. Therefore, the helpfulness is moderate as it provides context but requires further steps for implementation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'Important related work on MCMC in discrete spaces is absent' and 'Several methods have applied Langevin MCMC to sample discrete sequences1,2, which should be discussed'. The reviewer then names specific papers (Zhang et al., 2022 and Sun et al., 2023). This is a 5 comment as the authors can directly identify the missing related work and the specific methods that should be discussed. The action is very concrete, specifying the area of related work and the methods to be included.", "grounding_specificity_rationale": "The reviewer explicitly states 'Important related work on MCMC in discrete spaces is absent'. This directly identifies the specific part of the paper (related work section, or more specifically, the area within related work concerning MCMC in discrete spaces) that is missing. The reviewer also pinpoints the *type* of related work that is missing ('methods that apply Langevin MCMC to sample discrete sequences'). This is 5.", "verifiability_rationale": "The reviewer makes a claim by stating 'Several methods have applied Langevin MCMC to sample discrete sequences1,2'. This claim is verifiable because the reviewer provides specific references (Zhang et al., 2022 and Sun et al., 2023) to support their statement. These references directly relate to the methods they mention, making the claim verifiable.", "helpfulness_rationale": "The reviewer's comment is 5 because they identify a specific gap in the paper's background (absence of related work on MCMC in discrete spaces) and provide concrete suggestions by naming specific relevant papers (Zhang et al., 2022 and Sun et al., 2023). This directly guides the authors on what literature to include and why it's relevant. While it could be even more helpful by suggesting *how* to discuss these papers, the information provided is already very valuable for improving the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X: Not Verifiable", "helpfulness_label": "4", "actionability_rationale": "The review point directly asks for a reason or explanation for a specific methodological choice made in the paper. The reviewer is asking to understand *why* DSFedDRO and FedDRO use different methods for estimating g. This is a clear and direct request for information that would allow the reviewer to better understand the methods and potentially reproduce or build upon the work. The reviewer is explicitly seeking to take action by understanding this design choice.", "grounding_specificity_rationale": "The review point explicitly targets a specific aspect of the paper: the estimation of 'g' and the different methods used by DSFedDRO and FedDRO for this estimation. The reviewer is asking about the specific methods used in each method and why they differ. This is a highly specific request, as it focuses on a particular parameter and compares two specific methods. The reviewer is trying to understand the grounding of these methods in the paper.", "verifiability_rationale": "The review point is a question about a design choice in the paper. To answer it, one would need to look at the original paper and understand the methods described for each approach to estimating 'g'. If the paper provides sufficient detail on the methods used by DSFedDRO and FedDRO, then the verifiability of this point would depend on the clarity and completeness of that explanation within the paper. Without access to the original paper, it's impossible to definitively assess the verifiability of this point. However, the question itself is welldefined and points to a specific area of the paper.", "helpfulness_rationale": "The review point raises a valid question about a methodological choice in the paper. Understanding why different methods are used for estimating 'g' in DSFedDRO and FedDRO is important for gaining a deeper understanding of the approaches and potentially for replicating or extending the research. The reviewer is seeking to take action by understanding this design choice, which is a key aspect of evaluating the work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the reviewer wants a 'discussion' about a specific aspect of a paper ('difference between (6) in Nicekl Kiela and l>'). This is an explicit request for action. While it's not specifying exactly what to discuss, it clearly indicates a desired change. The reviewer is suggesting adding a section or paragraph explaining the difference.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Nicekl Kiela' and 'section (6)'. This provides a clear and specific reference point for the authors. The request is also quite specific \u2013 a *discussion* about the *difference*. This demonstrates strong grounding as the authors can easily identify the relevant section and understand the core of the request.", "verifiability_rationale": "The review point is not making a claim or assertion about the paper. It's a suggestion for the authors to include a discussion. Therefore, it doesn't contain a claim that needs verification. It's a constructive suggestion, not a critique requiring evidence.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors to improve their draft. They want to include a discussion about a specific aspect of a related work. This is a helpful suggestion as it directly addresses a potential area for improvement and provides a direction for the authors to follow."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the communication cost of their algorithm (O(SAH^2) or O(MSAH^2)) and compares it to the communication cost of other federated Qlearning algorithms (O(H)). While the reviewer identifies a difference in the communication cost, they do not specify *how* this difference makes the current algorithm's cost not low or noteworthy. The action is stated, but the method of implementation is vague.", "grounding_specificity_rationale": "The reviewer mentions 'other federated Qlearning algorithms 2,3' and their communication cost O(H). This provides a clear grounding point by referencing specific existing algorithms and their performance. However, the reviewer does not specify *which* part of their algorithm or their approach is causing the higher communication cost compared to these established methods. The grounding is present, but the specific area of concern is not identified.", "verifiability_rationale": "The reviewer makes a claim that the communication cost of their algorithm is 'not particularly low or noteworthy' by contrasting it with the O(H) communication cost of other federated Qlearning algorithms. The reviewer provides a logical comparison, suggesting that the higher cost is a valid observation. However, the reviewer does not provide specific examples, citations, or further analysis to substantiate this claim. The claim is presented with some justification (the comparison), but the lack of concrete evidence makes it somewhat subjective.", "helpfulness_rationale": "The reviewer points out that the communication cost of their algorithm is higher than that of other federated Qlearning algorithms. While this identifies a potential inefficiency, the reviewer does not offer any specific suggestions or guidance on how to improve the communication cost or make it more 'low or noteworthy'. The comment identifies a weakness but lacks actionable improvement suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states the main idea is 'trivial' and lacks 'specific adaptation' but does not explicitly identify what action or change is needed. The criticism is general and doesn't point to a specific problem or suggest a concrete fix. Therefore, it lacks the explicit and concrete nature of actionable feedback.", "grounding_specificity_rationale": "The reviewer criticizes the 'main idea' and the 'lack of specific adaptation' but does not explicitly identify which part of the paper or method is being referred to. The criticism is broad and does not specify what needs adaptation or what specific aspect of the idea is trivial. Therefore, the grounding is weak or nonexistent.", "verifiability_rationale": "The reviewer makes claims about the 'triviality' of the main idea and the 'lack of specific adaptation' but does not provide any logical reasoning, common knowledge, or external references to support these claims. These are subjective opinions without evidence. Therefore, the claims are not wellsupported.", "helpfulness_rationale": "The reviewer criticizes the main idea as 'trivial' and points out the lack of 'specific adaptation' to homomorphic encryption. While the criticism might be valid in a general sense, the feedback lacks specific, actionable suggestions. The reviewer does not offer concrete improvements or specific areas for the author to focus on. Therefore, the feedback is not particularly helpful in guiding the author's revision process."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that the new model improves upon the stateoftheart (MH) but does not explain *why* or *how*. While the *what* is implied (the new model's performance), the *why* and *how* are missing, making the action implicit. The lack of specific details on the mechanism of improvement makes it vague on how to apply it.", "grounding_specificity_rationale": "The reviewer makes a general statement about the lack of clarity regarding *why* and *how* the new model works better. They do not specify which part of the paper or model is unclear, making the grounding weak. Furthermore, the statement itself is vague and does not detail what is unclear.", "verifiability_rationale": "The reviewer makes a claim that the paper lacks clarity on *why* and *how* the new model works better. However, they do not provide any evidence, reasoning, or external references to support this claim. The statement is presented as a deduction or inferred observation without justification.", "helpfulness_rationale": "The reviewer identifies a significant weakness in the paper (lack of explanation for improved performance) but does not offer any suggestions or insights on how to address this weakness. They are simply pointing out a gap in the explanation, which is not helpful for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete change to the model. The reviewer is critiquing the *methodology* of the paper, not suggesting a direct action to be taken based on the identified issue. While the reviewer understands the mathematical operation, they are pointing out a potential flaw in the *implementation* of Adjective Projection, not proposing a specific action to address it.", "grounding_specificity_rationale": "The review point does not mention any specific part of the paper or the model architecture. The reviewer is criticizing the *mathematical formulation* of Adjective Projection, not pointing to a specific section or component that needs improvement. Therefore, the grounding is weak because the comment doesn't identify a specific area within the paper or model being discussed.", "verifiability_rationale": "The review point is not a claim that can be verified or falsified. It's a critique of a specific methodological choice. The reviewer is stating their opinion on the *effectiveness* of the proposed Adjective Projection method, but this is a subjective assessment, not a factual statement that can be verified through evidence or experiments. Therefore, there is no verifiable claim in this review point.", "helpfulness_rationale": "The review point is not helpful for the authors because it doesn't provide a clear understanding of the issue or suggest a concrete solution. The reviewer is pointing out a potential flaw in the *implementation* of a specific technique, but they are not providing the authors with any actionable feedback or guidance on how to address it. The comment is more of a critique than a helpful suggestion."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions the area of comparison as 'anyresolution generation' and suggests reading specific papers. This constitutes an explicit action, as the authors are directed to a particular area of research. However, the action is somewhat vague as it doesn't specify *how* to apply this comparison or what specific aspects of the cited papers are relevant.", "grounding_specificity_rationale": "The review point mentions the concept of 'anyresolution generation' and suggests comparing to 'recent works'. While it identifies a specific area of research, it doesn't pinpoint a particular section, table, figure, or unique element within the paper being reviewed. The suggestion to compare is general and doesn't specify what aspect of the cited papers is relevant to the authors' work. Therefore, the grounding is weak.", "verifiability_rationale": "The review point makes a claim by suggesting a comparison to 'more recent works' and provides a specific example of such works. It also implies a logical reasoning by suggesting this comparison would be beneficial. However, it doesn't provide specific examples of what aspects of these works are relevant or how the comparison should be conducted. The evidence provided is somewhat underspecific.", "helpfulness_rationale": "The review point is helpful in that it points towards relevant literature and suggests a direction for further research. It provides a highlevel recommendation that is generally useful for the authors. However, the suggestion is quite broad and doesn't offer specific actionable steps or insights into the cited works, making it 3 but not maximally so."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two potential areas for improvement. The first part, about the single subject in the test set, is an implicit action suggesting a potential overfitting issue. The second part, comparing ODER and RED, is an explicit action to investigate training time differences. However, the action for the first part is vague, and the second part lacks specific guidance on how to compare training times.", "grounding_specificity_rationale": "The review point mentions 'Section 6' in the context of limitations, but it doesn't explicitly identify which part of Section 6 is being referred to. While the content of the issues (single subject in the test set and the ODER vs. RED comparison) is specific, the lack of a clear reference to a specific subsection or table makes the grounding somewhat weak.", "verifiability_rationale": "The review point makes claims about potential overfitting and training time differences. However, it doesn't provide any evidence or reasoning to support these claims within the review point itself. For the training time comparison, it suggests a verification method (measuring training time) but doesn't offer specific examples or references to justify the claim.", "helpfulness_rationale": "The review point raises a valid concern about overfitting, which is a relevant issue for the authors. However, the suggestion to discuss limitations is vague and doesn't provide concrete steps for the authors to take. The request to compare training times is more helpful as it points to a concrete action the authors can undertake to improve their method. The lack of specific guidance on how to compare training times reduces the overall helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point is a statement of fact, pointing out a discrepancy between the stated bound and the actual bound. While it identifies a potential issue, it doesn't explicitly suggest a concrete action to address it.", "grounding_specificity_rationale": "The review point explicitly mentions the location 'between line 216 and 217', providing clear grounding. It also specifies the issue related to the 2Wasserstein bound, adding specificity.", "verifiability_rationale": "The review point makes a claim about a discrepancy in the stated bound, which can be directly verified by checking the text between line 216 and 217. The location and the specific bounds are mentioned, providing evidence for the claim.", "helpfulness_rationale": "The review point identifies a factual error or inconsistency in the paper by pointing out the discrepancy in the 2Wasserstein bound. However, it does not offer any suggestions or actions for the authors to take based on this finding."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the similarities and differences between the proposed method and IEConv/CDConv regarding the use of pooling layers for node reduction and the approach to multiscale representations. It also mentions ProNet's hierarchical representations. While the comparison is not deeply analyzed, the reviewer does ask a clarifying question, which can be interpreted as an implicit request for more specific details. Therefore, it can be considered partially actionable but lacks explicit guidance on how to apply the differences.", "grounding_specificity_rationale": "The review point explicitly mentions the names of specific methods (IEConv/CDConv, ProNet) and describes their characteristics (pooling layers, hierarchical representations). This clearly indicates strong grounding as the reviewer can easily identify the referenced parts. The comparison is also specific to the mentioned methods, further supporting high grounding specificity.", "verifiability_rationale": "The review point makes claims about the differences between the proposed method and the mentioned methods. However, it does not provide any logical reasoning, common knowledge, or external references to support these claims. The reviewer asks for clarification, implying a lack of sufficient justification. Therefore, the claims are not wellsupported, making the review point 3.", "helpfulness_rationale": "The review point identifies relevant differences between the proposed method and existing approaches. It highlights the use of pooling layers and hierarchical representations, which are important aspects of the field. However, it lacks specific details on how these differences translate to practical improvements for the authors. While it points out areas for improvement, it doesn't provide a comprehensive guide or concrete examples to make it 5. Therefore, it is 3 but could be more so with more detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a general issue with the paper's readability but lacks specific actions or suggestions. It points to a problem without providing a clear path for improvement, making it 2.", "grounding_specificity_rationale": "The review point is a general statement about the paper's readability and does not specify which part of the paper or what specific issue is being addressed. It is 1 and not specific.", "verifiability_rationale": "The review point is a descriptive statement about the paper's readability and does not contain a claim that requires verification. It is classified as 'X' because it contains X.", "helpfulness_rationale": "The review point identifies a valid weakness but lacks specific, actionable suggestions or guidance for improvement, making it 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2: 3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their desire for an analysis of the Beta distribution with and without bias, as well as questions about the tradeoff parameter (Theta) and the soft attention mechanism. These are direct requests for information and actions. The reviewer also suggests a baseline comparison, which is a concrete action to be taken. While the reviewer doesn't specify *how* they want the Beta distribution analyzed or what Theta was set to, they clearly indicate their interest in these aspects.", "grounding_specificity_rationale": "The reviewer refers to 'synthetic task,' 'addressing coefficients (Betas),' 'bias towards sequential addressing,' 'tradeoff parameter (Theta),' and 'soft attention mechanism.' While they don't explicitly point to a specific section or table, these are welldefined concepts within the context of the paper. The reviewer is clearly referring to a specific area of the work and its components. The questions are about specific parameters and mechanisms.", "verifiability_rationale": "The reviewer makes a claim that the work needs an analysis of the Beta distribution with and without bias, as well as information about the tradeoff parameter (Theta) and the soft attention mechanism. This claim is somewhat supported by the reviewer's explicit statements. However, the reviewer doesn't provide any logical reasoning, common knowledge, or external references to back up these claims. The suggestions for analysis and the baseline comparison are requests for further investigation rather than verifiable statements.", "helpfulness_rationale": "The reviewer's comments are highly relevant to understanding and potentially improving the work. They highlight areas where the authors might be lacking information or could benefit from further analysis and comparison. The suggestions for a Beta distribution analysis and a baseline comparison are concrete and directly address potential weaknesses or areas for improvement. The reviewer is essentially pointing out specific aspects of the work that require further clarification or investigation."}
{"actionability_label": "1", "grounding_specificity_label": "3: 4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the necessity of Proposition 1 but does not provide explicit instructions or suggestions on how to improve the paper based on this question. The reviewer is seeking clarification rather than taking action to address a perceived weakness.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'proposition 1' in their review point, which is a specific part of the paper being reviewed. However, they do not provide any information on what is wrong with proposition 1 or how it should be addressed. The grounding is present, but the specificity is lacking.", "verifiability_rationale": "The reviewer makes a claim by stating, 'I am not sure why proposition 1 is needed.' This is a claim that requires verification. However, the reviewer does not provide any external references or detailed reasoning to support their assertion about the necessity of proposition 1. The claim is present, but the supporting evidence is lacking.", "helpfulness_rationale": "The reviewer's point raises a valid concern about the potential unnecessary complexity introduced by Proposition 1. This critique could be helpful for the authors to consider alternative approaches or simplify their work. However, the reviewer does not provide specific suggestions or actions for the authors to take based on this concern. The review is primarily analytical rather than prescriptive."}
{"actionability_label": "4", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'Limited evaluation of defense techniques' and then names specific papers (Doan et al. Lira and Doan et al. Backdoor attack with imperceptible input and latent modification) as examples of relevant work. This indicates a clear intention for the authors to evaluate these specific defense techniques. While the reviewer doesn't provide explicit steps on how to perform the evaluation, the identification of the gap is a clear actionable suggestion.", "grounding_specificity_rationale": "The reviewer mentions 'defense techniques' and then specifically names two relevant papers (Doan et al. Lira and Doan et al. Backdoor attack with imperceptible input and latent modification). This demonstrates a clear grounding of the comment within the specific area of the paper and points to concrete examples.", "verifiability_rationale": "The reviewer states 'Limited evaluation of defense techniques' and then names specific papers. While the reviewer identifies a gap, they do not explicitly explain *why* this evaluation is important or *how* it should be conducted. The reasoning is implicit but not explicitly stated.", "helpfulness_rationale": "The reviewer clearly identifies a need for more evaluation of defense techniques and provides specific examples of relevant papers. This is a direct and useful suggestion for the authors, indicating that the comment is relevant and actionable."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a desire for a 'more focused related work section' and a 'description of similar datasets'. These are direct requests for action on the authors' part. The reviewer also mentions 'context and evidence based methods', which further specifies the desired content. The reviewer is not just stating a problem but also suggesting concrete solutions.", "grounding_specificity_rationale": "The reviewer mentions specific areas within the paper, namely 'related work section', 'similar dataset', and 'context and evidence based methods'. This indicates a clear understanding of where the information should be located. The reviewer also specifies the *type* of information needed for the related work section ('description of similar datasets') and the methods ('context and evidence based methods'). This level of detail suggests a strong grounding of the request.", "verifiability_rationale": "The reviewer makes a claim about what the related work and context and evidence based methods sections *should* contain. While the authors will need to verify the *actual* content of these sections, the reviewer's expectation is generally supported by common academic practices. The claim is specific about the *type* of information needed and the *where* it should be located, making it 3 based on standard academic norms.", "helpfulness_rationale": "The review point clearly identifies areas for improvement and suggests specific ways to improve the paper. The suggestions are explicit and actionable, guiding the authors on what to include in the related work section and how to describe similar datasets. The reviewer's expectations are generally aligned with standard academic practices, making the feedback constructive and likely to be helpful for the authors' revision efforts."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that 'experiment (Table 2) does show BN before ReLU hurt performance' and suggests a solution by 'BN can be folded into next Conv op, because all activation in the same conv feature map shares the same mean / var / scale / offset in BN implementation?'. The action is clearly stated, and the method for implementation is also provided, making it concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'same paragraph: experiment (Table 2)' and then refers to 'BN after ReLU'. The reference to 'Table 2' within the same paragraph and the specific mention of 'BN after ReLU' clearly identify the specific part of the paper being addressed. The explanation about shared statistics is also specific to this part.", "verifiability_rationale": "The reviewer makes a claim that 'experiment (Table 2) does show BN before ReLU hurt performance'. The reviewer also provides a potential explanation for this observation by suggesting 'BN can be folded into next Conv op, because all activation in the same conv feature map shares the same mean / var / scale / offset in BN implementation?'. While the explanation is a hypothesis about the underlying reason, the claim itself is based on the observation from Table 2. The grounding is specific to 'Table 2' and 'BN after ReLU'.", "helpfulness_rationale": "The review point identifies a specific experimental result ('BN before ReLU hurt performance') and offers a concrete suggestion for improvement ('BN can be folded into next Conv op'). The reviewer also provides a potential reason for this observation ('all activation in the same conv feature map shares the same mean / var / scale / offset in BN implementation?'). This provides the authors with a clear direction to explore and potentially improve their model."}
{"actionability_label": "5", "grounding_specificity_label": "Somewhat Grounded and Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the lack of largescale experiments and provides a concrete suggestion to vary the size of the network to investigate the scalability of the results. This action is both explicit and concrete, providing a clear direction for the authors to take.", "grounding_specificity_rationale": "The comment identifies the 'experiments section' as the area being addressed, which is a specific part of the paper. However, it does not pinpoint a specific subsection, table, or figure, nor does it specify a unique element within that section. Therefore, while the grounding is present, it is not fully specific.", "verifiability_rationale": "The comment states a fact about the model size but does not present a claim that requires verification or justification. There is no suggestion or recommendation provided. Therefore, it does not contain a claim that can be evaluated for verifiability.", "helpfulness_rationale": "The comment identifies a potential limitation in the experimental setup (lack of largescale experiments) and suggests a concrete improvement (varying the size of the network). This points out a weakness and offers a constructive suggestion for future work, making it 3 for guiding the authors towards better experimental design."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the condition 'W is the identity matrix' and asks a direct question about its implications. The reviewer also infers a connection to the 'spherical case' and requests a comparison with 'prior work'. These are all explicit statements and actions that the authors can readily identify and act upon.", "grounding_specificity_rationale": "The reviewer mentions 'spherical case' and 'prior work' but does not explicitly point to a specific section, table, figure, or unique element of the paper where this connection should be made. While the concepts are mentioned, the exact location and details are not provided, making the grounding weak.", "verifiability_rationale": "The reviewer is asking a question, not making a claim that needs verification. However, the *answer* to this question, which would involve explaining the connection to the spherical case and comparing with prior work, would be verifiable through reading the paper and potentially external references. The reviewer is seeking information, not a claim to be proven.", "helpfulness_rationale": "The reviewer is asking a question directly related to a specific technical detail ('W is identity matrix') and its implications. This is a relevant question for the authors and has the potential to be very helpful if the answer is clear and wellexplained in the paper. The reviewer is seeking to understand a specific aspect of their work and how it relates to existing literature in a simplified scenario."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states that the work 'mainly focuses' on CO problems on graphs and contrasts this with 'general' MILP or QUBO problems. This clearly indicates an action the authors should take, which is to consider a broader scope. While the action is not fully detailed, the explicit nature of the statement makes it actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'CO problems on graphs' and 'general MILP or QUBO problems'. This clearly identifies the specific parts of the paper being addressed, making it fully grounded. It also specifies what is limiting the application scope, making it specific.", "verifiability_rationale": "The comment identifies a limitation ('This work mainly focuses... which limits the application scope'). While it doesn't provide specific examples or citations, the limitation itself is a generally understood concept in the field. The reasoning behind the limitation (focusing on a specific class limiting generality) is logical and common knowledge. Therefore, it is 3 as it is supported by general knowledge and logical reasoning.", "helpfulness_rationale": "The comment identifies a valid weakness in the work \u2013 the limited scope to CO problems on graphs. It suggests a potential improvement by considering general MILP or QUBO problems. This is a relevant and constructive feedback that guides the authors towards a broader perspective. While it doesn't provide specific implementation details, it offers a clear direction for improvement, making it 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the section and the methods being compared ('For Sec. 5, the compression bandwidth of PC+IDF compared with IDF is recommended.') and implicitly suggests a need for comparison. However, it doesn't explicitly state the *reason* for the recommendation or the *specifics* of the comparison. The action is implied ('the authors should compare these methods').", "grounding_specificity_rationale": "The comment explicitly mentions 'Sec. 5', which is a specific section of the paper. It also compares 'PC+IDF' with 'IDF', which are specific methods. This clearly identifies the part of the paper being addressed and the elements being compared.", "verifiability_rationale": "The comment itself does not contain a claim that requires verification. It's a suggestion for further analysis. While the suggestion to compare these methods implies a potential issue (perhaps IDF is losing information), it doesn't provide any specific examples or references to back up this claim within the review point itself.", "helpfulness_rationale": "The review point identifies a specific section and suggests a comparison between two methods. However, it lacks a clear *action* for the authors. While it points to a potential area for improvement, it doesn't explicitly tell the authors what to do with this information. The suggestion is vague and doesn't provide concrete guidance on how to proceed with the comparison or what the expected outcome should be. Therefore, it's not 5 as it doesn't directly address a specific weakness or propose a concrete improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the current model names are 'misleading' and suggests 'alternative, more descriptive names'. This indicates a clear intention to provide a concrete action for the authors to take. While the suggestion is broad and doesn't specify *what* kind of alternative names, the action itself is direct and actionable. The reviewer is prompting the authors to consider new names.", "grounding_specificity_rationale": "The comment identifies the specific model names (T5ind, T5seq) as the source of the misleadingness. This demonstrates a degree of grounding as the reviewer pinpoints the exact elements being criticized. However, the comment does not specify *why* these names are misleading or what characteristics the 'more descriptive names' should have. The specificity is limited to the *what* (the model names) but not the *why* or the *how* of the improvement.", "verifiability_rationale": "The comment does not contain a claim that needs to be verified. It's a suggestion for improvement rather than a statement of fact or opinion. Therefore, the verifiability aspect is not applicable to this review point.", "helpfulness_rationale": "The comment provides a clear and actionable suggestion: to use more descriptive model names instead of the current T5ind and T5seq. This is a concrete improvement that directly addresses a potential point of confusion or lack of clarity for the authors. The suggestion is likely to be helpful in improving the authors' understanding and working with their models."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer's question is a direct inquiry about the meaning of the acronym 'AR' in the context of 'artificial intelligence'. While the question itself doesn't explicitly state an action to be taken, it implicitly encourages the authors to clarify their choice of acronym. The reviewer is prompting for a justification or explanation of why 'AR' was chosen over other potential acronyms. This could be considered a form of implicit action, asking for a clarification of a specific detail.", "grounding_specificity_rationale": "The reviewer points out a potential issue with the consistency of acronym usage. While the authors might be able to identify the specific section where the acronym is used, the reviewer's comment is not a direct instruction or explicit mention of a specific part of the paper. The grounding is implied rather than explicitly stated. The reviewer is highlighting a potential lack of clarity in how the acronym is being used.", "verifiability_rationale": "The reviewer's comment does not contain a claim in the sense of a statement that requires verification or justification. They are pointing out a potential issue in the writing style \u2013 the reuse of an acronym. While this could be considered a form of implicit critique, it doesn't fit the defined categories for a claim. There is no logical reasoning, common knowledge, or external references being presented in this comment.", "helpfulness_rationale": "The reviewer's question, while not directly providing feedback on a weakness, does prompt the authors to clarify their choice of acronym. This could be considered a form of helpful feedback, as it encourages the authors to provide more specific information. The question is clear and directly related to the content, making it 3 in the sense that it encourages a specific piece of information to be included."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests clarifying the motivation of the gating mechanism. While the reviewer explicitly states an action ('clarify'), the specifics of what needs clarification are not detailed. The action is present, but it's not fully concrete.", "grounding_specificity_rationale": "The reviewer mentions 'the core idea of this paper' and 'the gating design for MTL'. These are specific aspects of the paper. The reviewer explicitly names these aspects, indicating full grounding. While the paper title and the concept of gating are mentioned, there's no specific section or table number cited, making the grounding less than literal. However, the concepts themselves are unique elements, making it 5.", "verifiability_rationale": "The reviewer states that the motivation of the gating design for MTL is 'not clear' and that the gating mechanism is 'not a new story in MTL'. These are declarative statements about the lack of clarity and novelty. The reviewer does not provide any evidence or reasoning to support these claims, making them 1.", "helpfulness_rationale": "The reviewer criticizes the clarity of the motivation for the gating mechanism and the lack of novelty in the gating design. While the feedback is critical, the reviewer does not offer specific, actionable suggestions for improvement. The feedback is critical but lacks concrete steps on how to address the identified issues."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the limitations of learning to defer due to the need for 'ground truth' and 'DM's decisions' and provides concrete examples of these assumptions (biases, uncertainties, behaviors). This directly identifies a problem and provides a clear action for the authors to consider.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'ground truth' and 'DM's decisions' as crucial elements for training the model, and further specifies the nature of these assumptions (biases, uncertainties, behaviors). This clearly identifies the specific parts of the training process and the issues within them.", "verifiability_rationale": "The reviewer points out limitations based on assumptions about 'ground truth' and 'DM's decisions' without providing specific examples, references, or logical reasoning to support these claims about the inherent limitations of learning to defer. The review itself is a critique of the assumptions, not a claim that can be directly verified.", "helpfulness_rationale": "The reviewer identifies a potential problem with the practical applicability of learning to defer due to strong assumptions. While this highlights an important limitation, it does not directly suggest a solution or provide actionable steps for the authors to address this issue. It is a critique, not a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer states that the LR and SVM based baselines are 'too weak'. This is an explicit statement of a weakness. However, the reviewer does not specify *how* these baselines are weak or what makes them less convincing compared to deep learning approaches. The action of identifying the weakness is explicit, but the subsequent action of explaining *why* they are weak is not concrete.", "grounding_specificity_rationale": "The reviewer refers to 'LR and SVM based baselines' and 'deep learning approaches' generally. They do not specify a particular section, table, figure, or unique element of the paper being addressed. The grounding is at a high level, referring to categories of models rather than specific parts of the paper.", "verifiability_rationale": "The reviewer makes a judgment about the relative strength of different types of baselines. This is a claim. While this claim might be generally accepted knowledge in the field, the review itself does not provide specific examples or references to support this claim. The verifiability relies on general knowledge rather than specific evidence from the paper or external sources.", "helpfulness_rationale": "The review identifies a valid concern regarding the choice of baselines. However, the reviewer does not provide specific suggestions or actions for the authors to take to address this weakness. The feedback is a statement of a problem without offering concrete solutions or directions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the paper claims to be 'Communicationefficient' and that the motivation is to 'save communication'. They also claim that neither the theorem nor the experiment discuss the communication cost. This provides a clear and actionable criticism of a stated goal and identifies a specific area lacking information. The reviewer points to a potential deficiency in the experimental design or theoretical analysis related to communication cost, which the authors can directly address by including a theorem and an experiment focused on this aspect.", "grounding_specificity_rationale": "The reviewer states that neither the theorem nor the experiment discuss the communication cost. While they don't explicitly name a section, table, figure, or unique aspect of the paper where this information might be found, they do identify the specific parts of the paper (theorem and experiment) where the information should be present. This provides some level of grounding by specifying the type of content that is missing. However, the exact location within the theorem or experiment is not specified, making it 'weakly grounded'. The specificity is also good as they clearly identify what is missing (discussion of communication cost).", "verifiability_rationale": "The reviewer makes a clear claim: 'neither the theorem nor the experiment discuss the communication cost.' This is a specific statement about the content of the paper. While the claim itself is verifiable by examining the paper, the reviewer does not provide any specific examples or references to support this claim. Therefore, the claim is stated, but lacks supporting evidence or justification.", "helpfulness_rationale": "The reviewer's comment is 5 because it directly points out a stated goal of the paper (communication efficiency) and identifies a specific area where the paper is lacking (absence of discussion of communication cost in a theorem or experiment). This provides a clear direction for the authors to improve their work by adding a theorem and an experiment focused on communication cost. The criticism is specific and actionable, encouraging concrete changes."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action the authors should take: 'The contributions of the paper should be explicitly stated.' This is a direct and clear instruction.", "grounding_specificity_rationale": "The reviewer does not specify which part of the paper the contributions are located in. The authors would need to infer this from the context of the paper, making the grounding weak. The reviewer also does not specify what the contributions are, only that they should be stated. This makes the specificity low as the authors have to deduce the content of the contributions.", "verifiability_rationale": "The review point contains a claim: 'The contributions of the paper should be explicitly stated.' This is a clear and logical suggestion that does not require external references or complex reasoning to understand and implement. The authors can easily understand that they need to clearly articulate the paper's contributions.", "helpfulness_rationale": "The review point directly suggests a practical and often necessary improvement for authors: explicitly stating the paper's contributions. This is a helpful suggestion as it directly addresses a potential area where clarity can be improved and makes the paper easier to follow."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer asks for justification for the claim about semantic conflicts, but does not explicitly state the action to be taken or how to achieve it. The action is implicit.", "grounding_specificity_rationale": "The reviewer mentions 'semantic conflicts' generally, without specifying which part of the paper or section this refers to. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer makes a claim that 'different densities directly will cause semantic conflicts' and asks for justification. However, the justification is not provided in the review point itself. The claim is stated, but the supporting evidence or reasoning is missing.", "helpfulness_rationale": "The reviewer points out a potential weakness in the motivation and asks for justification. This is a valid point that could help the authors improve their work. However, the request for justification is broad and lacks specific guidance on how to achieve it, making it less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The question directly asks about the training method of the three transformer modules, which is a specific and actionable piece of information for the authors. The reviewer is asking for a direct identification of a missing detail.", "grounding_specificity_rationale": "The comment explicitly mentions 'the three transformer modules' and asks about their 'training method'. This directly identifies the specific part of the paper being addressed, achieving 'Full Grounding'. The reviewer is not making an inference about which part needs improvement, but rather asking about a specific component.", "verifiability_rationale": "The comment states that 'Figure 5 shows the visualization of another three cases which is similar to figure 1 and has the same flaws.' This is a claim that requires further investigation and verification. While the reviewer states the similarity, they do not provide explicit examples or references to support this claim within the review point itself. Therefore, it is 'Partially Verifiable'. The claim is present, but the supporting evidence is not fully detailed within the point.", "helpfulness_rationale": "The question directly asks about a crucial implementation detail of the proposed approach (the training method of the transformer modules). This is a significant piece of information for the authors to understand and potentially reproduce the work. It directly addresses a core aspect of the proposed method."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's statement is quite direct and identifies the potential misunderstanding of a fundamental property of ERM. They are pointing out a specific area of the text where a clarification is needed. The action is clear: the authors need to understand the relationship between the gradient of the sum and the sum of the gradients. While the action is clear, the reviewer doesn't explicitly state the *specific* action the authors should take to resolve this misunderstanding, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'lines 6074 (beginning of Sect. 2)' and the specific paragraph 'lines 7074'. This clearly indicates a strong attempt to pinpoint the relevant part of the paper. The grounding is good because the reviewer is referencing a specific section and a specific paragraph. The specificity is also good because the reviewer is not just saying 'the paper is unclear', but rather pointing to a specific section and a specific detail within that section.", "verifiability_rationale": "The reviewer makes a claim about the paper's explanation of ERM. They state that the paper might be implying that the gradient of the sum is not the sum of the gradients, while the reviewer knows this is generally true for ERM. However, the reviewer does not provide any external references or examples to support this claim. The reasoning is based on the reviewer's understanding of ERM, but the lack of supporting evidence within the review point makes it 1.", "helpfulness_rationale": "The reviewer's point is potentially helpful for the authors. They are highlighting a potential point of confusion regarding a fundamental concept in ERM. This could help the authors clarify their understanding. However, the reviewer's point is more about critiquing the paper's explanation rather than directly pointing out an error or a specific improvement needed in the authors' work. Therefore, while potentially helpful, it's not as directly actionable as a comment that points out a specific error or missing detail in the authors' equations or text."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out a potential issue with the use of L2 distance in equation (4) and suggests an alternative, 'earth mover's distance' (or OT distance). They are asking for the benefit of using L2 distance, which is a direct and concrete action the reviewer is proposing. The reviewer is not inferring the need for change, but rather suggesting a specific alternative and asking for justification.", "grounding_specificity_rationale": "The reviewer specifically mentions 'equation (4)' and 'L2 distance' in their review point. They are asking for the benefit of using L2 distance, which directly relates to the specific element they are pointing out. The reviewer is not making a general statement about the paper but is focusing on a particular aspect, making the grounding specific. They are also asking for a justification (the benefit), which fits the definition of grounding specificity having a clear specification of what needs to be addressed.", "verifiability_rationale": "The reviewer makes a factual observation about the potential ambiguity of the term 'earth mover's distance' and the more common 'OT distance'. They are asking for the benefit of using L2 distance, which is a claim that needs to be supported by logical reasoning, common knowledge, or external references. The reviewer is stating a fact and asking for a justification, which fits the criteria for verifiability.", "helpfulness_rationale": "The reviewer is directly addressing a potential ambiguity in the paper regarding the choice of distance metric. They are suggesting a change (using OT distance) and asking for a justification (benefit). This is a constructive and helpful suggestion aimed at improving the clarity and rigor of the paper. The reviewer is actively engaging with the content and proposing a concrete improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, not a statement with a clear action. It asks \"how this algorithm compares to other offline RL algorithms,\" which isn't a direct instruction for improvement. The question is broad and doesn't specify what needs to be compared or why this comparison is relevant to the authors' work. There is no explicit or implicit action or suggestion for the authors to take.", "grounding_specificity_rationale": "The reviewer points to \"other offline RL algorithms\" generally, without specifying a particular section, table, figure, or unique aspect of the paper. The comment is 1 at all. It does not identify a specific part of the paper being addressed. The mention of 'other offline RL algorithms' is vague and doesn't pinpoint a specific element within the paper to address.", "verifiability_rationale": "The review point itself is not a declarative statement with a claim. It is a question asking for information. Therefore, there is X to verify.", "helpfulness_rationale": "The review point is a request for more information (a broader comparison of offline RL algorithms) rather than a critique or a direct suggestion for improvement. While relevant to the authors' work, it doesn't directly guide them on how to improve their draft. It's a request for context, not a constructive critique."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about a specific scenario ('all increments are available at the same time') and its impact on the 'final solution'. While it doesn't explicitly state what needs to be done, it identifies a gap in the understanding of how this scenario affects the solution. The action is implicit in identifying the need for clarification, but the specific steps or actions are not directly provided.", "grounding_specificity_rationale": "The review point refers to 'all increments' and 'final solution'. While it doesn't point to a specific section or table, the terms used are highly specific within the context of discussing the system or model. The authors can reasonably infer the parts of the system and the solution being discussed.", "verifiability_rationale": "The review point is a question prompting clarification rather than a statement containing a claim that needs verification. It asks 'How does the final solution change...', which is a request for an explanation or comparison, not a claim about what is or is not the case.", "helpfulness_rationale": "The review point is helpful because it directly addresses a potential ambiguity in the design or implementation. By asking how the final solution changes when all increments are available at the same time, it seeks clarification on a specific scenario that could be unclear to the authors. This clarifies the intended behavior of the system or model."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential issue (the combination of feature spaces is convoluted and potentially circular) and suggests an action (perhaps simplifying the approach or just using one feature space). This is an implicit action, but the reviewer clearly states what is problematic.", "grounding_specificity_rationale": "The reviewer accurately describes the *what* (the combination of feature spaces) but fails to specify *where* in the paper this issue is most relevant. They don't identify a specific section, table, or figure where the convolutedness is most apparent. The reviewer doesn't mention any unique elements of the paper being referred to in relation to this issue.", "verifiability_rationale": "The reviewer expresses a concern about the approach without providing any evidence or references to support it. They state a potential issue ('convoluted' and 'potentially circular') but don't explain why it's a problem or provide any logical reasoning or external references to back it up. The reviewer's statement is a subjective opinion without any supporting data.", "helpfulness_rationale": "The reviewer clearly states that they found the technique to be convoluted and potentially circular. This directly points out a weakness in the methodology. While they don't offer specific solutions, they identify a problem that needs addressing, making the comment helpful in highlighting an area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states an action: 'compare with works using MobileNetV3 search space (e.g., AtomNAS)'. This fulfills the first criterion of explicit action. However, it does not provide specific guidance on *how* to perform this comparison, such as which metrics to use or what kind of analysis to conduct. Therefore, while an action is present, it lacks the detail needed for immediate implementation, making it somewhat vague.", "grounding_specificity_rationale": "The review point explicitly mentions 'MobileNetV3 search space' and provides a specific example 'AtomNAS'. This allows the authors to accurately identify the relevant area for comparison. The grounding is explicit and specific. The reviewer also asks a direct question about FLOPs and parameters, which is a specific request for information within the mentioned area. Therefore, the grounding is strong.", "verifiability_rationale": "The review point identifies a weakness or area for improvement (the lack of comparison with MobileNetV3 search space) and provides a suggestion (comparing with works in this space). However, it does not offer any external references or logical reasoning to support this suggestion. It simply states what should be done. Therefore, while a suggestion is made, it lacks the verifiability aspect of explaining *why* this comparison is valuable or how it would improve the work.", "helpfulness_rationale": "The review point offers a suggestion to compare with MobileNetV3 search space, which is relevant and potentially helpful for the authors. However, the suggestion lacks specific details on *how* to perform this comparison. The reviewer also asks for FLOPs and parameters, which, while potentially helpful, is not actionable as it requires the authors to calculate these values themselves. Furthermore, the reviewer asks a question about the OFA with progressive shrink results, which is valuable but not an actionable suggestion. The lack of concrete action items and the request for specific metrics make the review point less helpful overall."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what needs to be done or how. It is a suggestion for further discussion, which is not an actionable step for the authors.", "grounding_specificity_rationale": "The review point does not refer to a specific part of the paper or identify a particular issue within it. It is a general suggestion.", "verifiability_rationale": "The review point is a suggestion, not a claim that needs verification. While it implies a belief in the desirability of fixing hallucinations, it doesn't present a verifiable statement.", "helpfulness_rationale": "The review point is relevant and provides context for the authors' work, suggesting a general improvement. However, it lacks specific details and actionable steps, making it less immediately helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue with the clarity of the null hypothesis. While they don't explicitly state 'You should state the null hypothesis earlier', the mention of specific statistical terms before the null hypothesis could be interpreted as an implicit suggestion that the authors should consider this. However, the reviewer doesn't provide a clear action or guidance on how to address this.", "grounding_specificity_rationale": "The reviewer mentions 'Type1 error, Type2 error, and false positive rate' specifically. This indicates a clear reference to the statistical terms mentioned in the paper. However, the grounding is weak because the reviewer doesn't explicitly state where the null hypothesis should be addressed or how these terms relate to it.", "verifiability_rationale": "The reviewer's statement is a factual observation about the order of information in the paper. They are pointing out a potential organizational issue. While they identify a fact, they don't provide any justification or suggest improvements based on this observation. The comment is a description, not a claim requiring verification or support.", "helpfulness_rationale": "The reviewer points out a potential organizational issue that could affect the clarity of the paper. While they identify a problem (null hypothesis placement), they don't offer a specific solution or suggest how this issue could be addressed. The comment is descriptive rather than prescriptive."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue with estimating a continuous importance weight function in a probabilistic model, which is a direct problem related to the author's work. While the reviewer doesn't explicitly state how to solve this, they identify a clear weakness in the methodology. The action is implicit: the reviewer is indicating a problem that needs addressing. The solution is left to the author.", "grounding_specificity_rationale": "The reviewer mentions 'estimating a continuous importance weight function' and 'probabilistic process' as the issue. While these are specific technical terms, the reviewer doesn't explicitly link them to a specific part of the author's draft or work. The problem is presented in general terms, making it difficult to pinpoint the exact location or nature of the uncertainty. The grounding is implicit, relying on the reader's understanding of probabilistic modeling. The specificity is limited as the exact area of concern is not clearly defined within the author's work.", "verifiability_rationale": "The reviewer states a problem: 'Estimating a continuous importance weight function is a probabilistic process, together with the regularization process, this may inherent uncertainty in the estimates, affecting the model's reliability in certain cases.' This is a claim that needs to be addressed. The reviewer identifies the source of the problem as the probabilistic nature of the process and the regularization. This provides some level of support, but the explanation is brief and lacks specific examples or references. The claim is present, and a potential cause is identified, but the reasoning is not fully developed, making it 3.", "helpfulness_rationale": "The reviewer raises a valid concern about a potential limitation of a probabilistic model, which is directly relevant to authors working in this area. The reviewer identifies a weakness in their or someone else's methodology. While the reviewer doesn't offer a solution, they clearly point out a problem that could impact the reliability of the model. This information is helpful in identifying potential issues, even if it doesn't provide a complete solution. The feedback is relevant and points to a specific area of concern."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem: 'Despite correlating well with human on styles that are more semanticsrelevant... their SFAM scorers which serve as fundamental components of the LISA embedding do not correlate well with human on more linguisticsrelevant styles (e.g., simplification, linguistic acceptability).' This clearly identifies an actionable issue: the lack of correlation with linguistic styles. The reviewer also concludes: 'This probably makes the LISA more contentfocused, rather than stylefocused.' This is a direct action the authors could take: investigate the reasons for the lack of linguistic style correlation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'SFAM scorers' and 'LISA embedding' as the components of the LLM in question. This is a clear and accurate grounding. The reviewer also mentions 'linguisticrelevant styles' (simplification, linguistic acceptability) as the specific area of concern. This adds further specificity to the point.", "verifiability_rationale": "The reviewer makes a claim: 'their SFAM scorers which serve as fundamental components of the LISA embedding do not correlate well with human on more linguisticsrelevant styles (e.g., simplification, linguistic acceptability).' The reviewer *infers* that this lack of correlation is *probably* due to the LISA being 'more contentfocused.' While the claim about the lack of correlation is verifiable, the inference about the cause is not directly supported by evidence within the review point itself.", "helpfulness_rationale": "The reviewer points out a specific area of concern for the authors: the potential lack of correlation between SFAM scorers and linguistic styles. This is a relevant issue that could impact the effectiveness of their models. The reviewer suggests that this might mean the LISA is more contentfocused, which is a potential direction for further investigation. While the reviewer doesn't provide concrete solutions, they identify a problem that needs attention, making the review 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly names the dataset (DexYCB) and the concept of 'more recent handobject pose estimation pipelines,' indicating a direct action the authors should take. The action is also concrete, specifying where to look and what to consider.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'DexYCB' as a specific dataset, providing strong grounding. They also specify 'more recent handobject pose estimation pipelines' as a specific aspect of the evaluation, further enhancing grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the adequacy of the current evaluation by suggesting using a different dataset and method. While the review point itself doesn't provide evidence for or against this claim, it clearly states a suggestion that could be supported by external references or logical reasoning.", "helpfulness_rationale": "The reviewer clearly identifies a potential improvement to the experimental evaluation by suggesting the use of a more comprehensive dataset and evaluation pipeline. The suggestion is directly actionable and constructive, though it might not be universally applicable or exhaustive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the missing elements: 'the design of sequential models' and 'how the attention model is updated'. This directly points to actions the authors should take, making it explicit. While the reviewer doesn't provide the concrete steps, the identification of the missing information is a clear action.", "grounding_specificity_rationale": "The reviewer mentions specific components of the paper: 'the design of sequential models' and 'how the attention model is updated'. This grounds the criticism in specific parts of the paper, making it more clear what area needs improvement. However, the reviewer does not specify *how* these components are designed or updated, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer makes a claim: 'the paper lacks explicit explanation'. This is a statement that needs to be supported. However, the reviewer does not provide any evidence or references to back up this claim within the review point itself. The claim is stated, but not verified.", "helpfulness_rationale": "The reviewer points out a specific area where the paper could be improved by providing more details. This is a helpful suggestion because it directly addresses a potential bottleneck for the authors in understanding and implementing the proposed work. While the reviewer doesn't provide the solution, they clearly identify where it's needed, making the feedback actionable and relevant."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment is implicit about the action, suggesting the authors should make their code accessible. However, it lacks explicit instructions on how to do this. The action is somewhat vague as it doesn't specify the method of accessibility (e.g., through a specific repository link, a consent form).", "grounding_specificity_rationale": "The comment is not explicitly grounded to a specific part of the paper. It refers to the 'code' in general, without identifying a specific file, directory, or version control system. While the reviewer implies the relevant code, they don't explicitly point to it.", "verifiability_rationale": "The review point is a suggestion, not a claim requiring verification. There is no statement of fact or opinion being made. Therefore, it falls under 'X'.", "helpfulness_rationale": "The comment identifies a potential improvement for the authors (making code accessible), which is a valuable suggestion. However, it lacks specifics on *how* to achieve this improvement. The lack of detail makes it less than fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly names 'spikedriven token selection' and 'intra and interstage feature fusion' as areas needing clarification. These are specific processes within the hybrid architecture, making the reviewer's suggestion actionable by pointing to concrete components that require improvement.", "grounding_specificity_rationale": "The reviewer directly names 'spikedriven token selection' and 'intra and interstage feature fusion,' which are specific terms related to the hybrid architecture. This allows the authors to identify the exact sections or concepts being referred to, thus being fully grounded. The reviewer also specifies what is unclear about these processes ('could be clearer'), adding specificity.", "verifiability_rationale": "The review point states 'including pseudocode or flow diagrams might enhance the reader\u2019s understanding of the model\u2019s operation.' This is a suggestion for improvement, but the review itself does not provide any evidence or reasoning to support why pseudocode or flow diagrams would be necessary or effective. The claim is presented as a possibility rather than a wellsupported assertion.", "helpfulness_rationale": "The review point identifies specific areas of the method ('spikedriven token selection' and 'intra and interstage feature fusion') that are likely unclear to readers. By pointing out these specific processes, the reviewer provides a clear target for the authors to focus their explanation. While the review itself doesn't offer a complete solution, it does highlight a concrete problem, making it 3."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the proposed method is an 'incremental improvement' on AutoAugment, which is an implicit action. They also mention 'performance improvements are not very significant,' which suggests a desire for more substantial results. However, the reviewer does not explicitly state the specific areas that need improvement or provide concrete steps for the authors to take.", "grounding_specificity_rationale": "The reviewer mentions 'compared to recent methods' and specifically 'ImageNet, resnet50' and even provides a citation '18'. This clearly grounds the weakness in a specific experimental setup and a specific paper. The reviewer also specifies the weakness as 'performance improvements are not very significant' within this context.", "verifiability_rationale": "The reviewer makes the claim that 'performance improvements are not very significant' and provides supporting evidence by stating 'Also, the std is very large, which leads to doubts about generalizability.' This provides logical reasoning and justification for the claim.", "helpfulness_rationale": "The reviewer's comment is primarily critical, pointing out the lack of significant performance improvements and the large standard deviation, which raises doubts about generalizability. While they offer a potential explanation ('resnet50 is only 0.3 better than 18'), the overall tone is critical and questions the value of the proposed method. The reviewer does not offer concrete suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the problem: 'The comparison is rather weak' and 'lacking references to existing prior arts'. It also suggests a solution: 'A simple search with respect to the 5 experiment datasets also show significant performance gaps between the proposed method and latest methods'. This makes the comment actionable as the authors can directly address the missing comparisons and references.", "grounding_specificity_rationale": "The comment mentions '5 experiment datasets' in the context of the comparison being weak. While it identifies the *section* where the comparison is lacking, it doesn't explicitly state which specific part of the paper (e.g., the methodology section, the experimental results section) needs this comparison. Therefore, it's weakly grounded. The comment also specifies what is missing ('lacking references to existing prior arts' and 'significant performance gaps'), making it specific in that aspect.", "verifiability_rationale": "The comment makes a claim: 'The comparison is rather weak without any reference to existing prior arts such as 1'. This claim needs to be verified. While it mentions 'performance gaps', it doesn't provide a logical reasoning or specific examples to support this claim. There are no external references provided in the review point itself to back up the claim of 'weak' comparison and 'significant performance gaps'.", "helpfulness_rationale": "The review point identifies a weakness in the experimental comparison by the authors. It provides a direction for improvement by suggesting the inclusion of references to prior arts and analysis of performance gaps. However, it doesn't offer a specific solution or detailed guidance on how to implement these improvements. It's a highlevel suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The comment suggests quantifying data diversity, which implies an action, but it doesn't explicitly state what needs to be quantified or how. The suggestion is vague, making the action implicit rather than explicit. The comment also doesn't provide concrete steps on how to implement this quantification, making it less actionable.", "grounding_specificity_rationale": "The comment criticizes the lack of quantification in the argument for data diversity. While it implicitly refers to the data diversity aspect, it doesn't explicitly identify the specific section or table where this argument is made. The criticism is general and doesn't pinpoint a specific issue within the data diversity discussion.", "verifiability_rationale": "The comment states that the authors' argument for data diversity lacks quantification and suggests providing statistics. While it implies a lack of evidence, it doesn't provide specific examples of where the argument is made or why the lack of quantification is a problem. The suggestion is a recommendation, not a verifiable claim with supporting evidence.", "helpfulness_rationale": "The comment offers a suggestion to improve the data diversity argument by providing statistics. While the suggestion is relevant and could be helpful, it lacks specific details on what kind of statistics to provide and how this would directly benefit the authors' work. The suggestion is general and lacks concrete guidance, making it less helpful overall."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential issue with the paper's methodology (lack of a diversity measure and comparison with earlier works) but does not explicitly instruct the authors on how to address it. While it points out a missing element, it doesn't provide a clear action or concrete steps to take.", "grounding_specificity_rationale": "The comment explicitly mentions 'a more diverse set of positive (similar) instance pairs,' which clearly identifies the specific aspect of the paper being referred to. The reviewer is not making an educated guess; they are directly addressing a specific claim made in the paper.", "verifiability_rationale": "The comment contains the claim 'This claim is not backed sufficiently' and provides supporting evidence by stating 'no suggested measure of diversity' and 'no comparison with earlier works regarding the diversity of examples.' This provides clear justification for the claim.", "helpfulness_rationale": "The review points out a valid concern regarding the lack of a diversity measure and comparison in the paper. However, it does not offer any suggestions or guidance on how the authors should address this issue. The feedback is technically sound but lacks the constructive element of a suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state any actionable feedback or criticism of a specific aspect of the work. It poses a question for comparison rather than identifying a problem to solve.", "grounding_specificity_rationale": "The reviewer's question is general and does not specify which 'structured information' they are referring to. They are asking for a comparison in general, not about a specific part of the paper or method.", "verifiability_rationale": "The review point is a question for comparison, not a claim that needs verification. There is no assertion of truth or falsehood being made.", "helpfulness_rationale": "The review point raises a valid question about how the approach compares to existing methods. While it doesn't directly critique a flaw, it provides context and helps the authors understand their work in relation to the literature. It encourages the authors to clarify their approach and its expected performance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states two concrete actions: (1) include the objective function in experiments using Monte Carlo estimates, and (2) point out a potential issue with the inequality sign in Eq. 7. While the reviewer doesn't explicitly state that the inequality sign should be reversed, they clearly identify a potential problem and suggest further investigation. The actions are direct and provide a clear path for the authors to improve their draft.", "grounding_specificity_rationale": "The review point explicitly refers to 'Eq. 7' and 'Section 3.2', which are specific parts of the paper. It also mentions 'objective function in experiments' and 'training procedure', which are specific aspects of the method. This strong referencing makes the comment grounded in the specific details of the paper and the proposed method.", "verifiability_rationale": "The review point provides a claim by identifying a potential issue with the inequality sign in Eq. 7. It also provides some verification by suggesting checking the inequality sign and pointing to Section 3.2 for context. While it doesn't provide a complete explanation or external references for why the inequality sign might be wrong, it does offer a specific area for the authors to investigate and a clear observation that requires further consideration. The reasoning is present, though not fully elaborated.", "helpfulness_rationale": "The review point provides concrete suggestions and points to specific areas for improvement in the paper. By mentioning the objective function and the training procedure, it directly addresses potential weaknesses in these aspects. While the suggestions are relatively highlevel, they are actionable and directly relevant to the method described in the paper. This makes the review point helpful in guiding the authors towards specific improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a question about a trend in the plot (Grid, top right plot) and states that this trend should be explained. While the action of investigating the trend is implied, it is not explicitly stated. Therefore, the actionability is somewhat implicit.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Grid (Fig. 3, top right plot)' and then specifically mentions 'Disc. reward for SPACE and fPCPO'. This precise identification of the section and metrics demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer states a finding ('the Disc. reward for SPACE and fPCPO is going down') and claims that this trend should be explained. This is a claim that requires justification, making it 3. While the reviewer doesn't provide the explanation in this review point, the request for explanation itself is a form of verifiability.", "helpfulness_rationale": "The reviewer points out a potential issue (the downward trend in the reward) and asks for clarification. This is a valid point that could help the authors improve their work. While the authors haven't taken action based on this review yet, the potential for improvement makes this review 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "6", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'Key implementation details are missing' and 'resolutions at which images successfully achieve adversarial effects'. This indicates an explicit topic. However, it does not specify *how* to identify these missing details or *what* specific information is lacking. The action required is not fully clear.", "grounding_specificity_rationale": "The comment mentions 'images' and 'resolutions' but does not specify *which* images or *where* in the paper the adversarial effects are discussed. The connection to a specific section, table, or figure is missing. The author cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is more of a statement of fact ('Key implementation details are missing') than a claim that needs supporting evidence. There is no explicit assertion or suggestion that needs justification to be understood or accepted.", "helpfulness_rationale": "The comment identifies a valid concern regarding the lack of specific implementation details. It points to a potential area for improvement in the paper. However, it does not offer a direct solution or specific steps to address the issue. It highlights a missing piece of information that could hinder reproducibility or understanding."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a weakness ('It does not significantly simplify the overall complexity') and suggests an action ('explore improvements to the motion guidance strategy'). This fits the 'Explicit' category. However, the suggested action is broad and lacks specific details, making it 'Vague'.", "grounding_specificity_rationale": "The review clearly identifies a specific section ('data preprocessing') and a specific subsection ('motion guidance') within the paper. It also pinpoints the specific technique ('DDIM Inversion'). This is strong grounding. However, the suggestion to 'improve the motion guidance strategy' is a general direction and not a specific fix, making it 'Weakly Grounded'.", "verifiability_rationale": "The review point contains a claim ('This approach does not significantly simplify the overall complexity') which is an opinion or judgment about the method's effectiveness. However, it does not provide any evidence or reasoning to support this claim. It doesn't offer alternative methods or cite literature to back up its assertion. Therefore, it is '1'.", "helpfulness_rationale": "The review point identifies a potential weakness in the current approach (DDIM Inversion not simplifying complexity) and suggests a direction for improvement (exploring motion guidance strategies). While the suggestion is broad and lacks specific details, it still points towards a potential area for the authors to refine their approach. It's better than a completely neutral or negative comment."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete improvement based on the criticism of chunking into relation phrases. The reviewer criticizes the method without proposing a specific alternative or detailing how to implement a better approach. Therefore, no actionable step is identified.", "grounding_specificity_rationale": "The review point does not identify a specific aspect of the paper being discussed. The reviewer is broadly criticizing a methodological choice (chunking into relation phrases) without specifying which part of the paper this relates to. Therefore, the grounding is weak.", "verifiability_rationale": "The review point contains a claim that chunking into relation phrases has a potential disadvantage related to the heavy tail of relations. The reviewer provides a logical explanation for this potential issue, outlining the problem and its implications. However, the claim is not fully supported by specific examples or references within the review point itself. The reasoning is present, making it 3, but lacking concrete evidence within the point makes it not 5.", "helpfulness_rationale": "The review point criticizes a potential drawback of a methodological choice (chunking into relation phrases) without offering any suggestions or solutions. The reviewer states a problem but does not propose any improvements or alternative approaches. Therefore, the review point is not helpful in guiding the authors towards better practices."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a weakness in the experiments (lack of comparison with other methods) but does not provide any explicit or implicit instructions on how to address this weakness. The authors are left without a clear action to take. This makes the point 1 as it doesn't tell them what to do or how to do it.", "grounding_specificity_rationale": "The review point refers to 'the experiments' in general, without specifying a particular section, table, figure, or unique aspect of the paper. The reviewer does not clearly identify what is lacking in the experiments (e.g., specific comparisons, alternative methods). The grounding is weak because the authors cannot confidently determine the exact area being addressed. The specificity is also lacking as the point does not detail what needs to be improved within the experiments.", "verifiability_rationale": "The review point makes a statement about the current state of the experiments ('only focus on the comparison between various models proposed by authors and lack of comparison with other methods') without making any claims or opinions. It describes a fact rather than proposing something that needs verification. Therefore, there is X to be verified, making it a 'X'.", "helpfulness_rationale": "The review point identifies a valid point for improvement (the lack of comparison with other methods) but fails to provide any actionable suggestions or guidance on how to address this weakness. While the authors would understand the issue, they are left without a clear path forward. The point is informative but lacks the 'how' to be fully helpful, making it 3 as it points out a gap but doesn't fill it with concrete suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the MAVIS models should have a * in Tables 3 and 4, indicating a potential issue or area for improvement. This is a direct and actionable suggestion.", "grounding_specificity_rationale": "The reviewer explicitly refers to Tables 3 and 4 and specifically mentions the MAVIS models in relation to the * symbol. This demonstrates strong grounding as the reviewer can accurately pinpoint the relevant part of the paper and clearly identify the issue with the referenced models.", "verifiability_rationale": "The reviewer's claim that MAVIS models should have a * is supported by the convention used for other mathspecialized models in the tables. While it's an inference, it's a reasonable and logical conclusion based on the context.", "helpfulness_rationale": "This review point directly identifies a potential issue with the MAVIS models and suggests a concrete improvement. It is immediately actionable and likely to be helpful for the authors in understanding and categorizing their models."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out that KNNbased methods are widely studied and that this work provides few insights. While this is a valid observation, the reviewer does not explicitly state what specific aspect of the KNN implementation or the work is lacking in insights. The suggestion is very general and does not provide concrete steps for improvement. Therefore, while the reviewer identifies a weakness, they do not provide specific actionable feedback on how to address it.", "grounding_specificity_rationale": "The reviewer states that KNNbased methods are widely studied and that this work provides few insights. While the reviewer identifies a potential weakness, they do not specify which part of the paper or method this criticism refers to. The criticism is general and does not pinpoint a specific section, table, figure, or unique aspect of the work. Therefore, the reviewer's statement is 1 at all.", "verifiability_rationale": "The reviewer makes a claim that KNNbased methods are widely studied and that this work provides few insights. The claim about KNN methods being widely studied is generally verifiable by looking at existing literature in NLP. However, the claim that 'this work provides few insights' is subjective and lacks specific examples or references within the review point itself. Therefore, the claim is 3 as the first part is generally verifiable, but the second part lacks sufficient evidence within the review point.", "helpfulness_rationale": "The reviewer's point is 1, as it does not provide specific suggestions on how to improve the draft. Since the point lacks actionable feedback, it is not helpful for the authors to improve their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding more background information, which could be interpreted as an implicit action to expand the discussion in Section 2 and related work. However, the reviewer does not explicitly state how to expand or what specific information is needed, making the action vague. The lack of specific details makes it difficult to determine exactly what the authors should do after reading the comment.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 2 and related work' and 'adversarial examples, whitebox, greybox, and blackbox threat models'. This clearly identifies the specific parts of the paper and concepts being addressed, indicating strong grounding. The reviewer also suggests 'reviewing relevant surveys', which specifies the type of information needed.", "verifiability_rationale": "The review point itself does not contain a claim that needs verification. It is a suggestion to include more background information. There is no logical reasoning, common knowledge, or external references provided within the review point itself.", "helpfulness_rationale": "The review point suggests adding more background information on adversarial examples and threat models. This could be helpful for readers who are not familiar with these concepts and need more context to understand the paper. The suggestion is relatively clear and directly addresses a potential gap in the reader's understanding. However, it does not specify *how* to add this background information, making it less actionable in terms of implementation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The statement is phrased as a question, which can be interpreted as an implicit request for clarification. While not directly stating 'I don't understand,' it's a form of action. However, the lack of a specific example or context makes it less concrete than it could be.", "grounding_specificity_rationale": "The question explicitly mentions 'realworld applications,' which is a specific concept within the paper (if the paper discusses applications). This can be achieved through general comments that clearly imply the relevant parts without explicitly naming them. Therefore, it can be considered fully grounded. However, the comment does not specify what needs to be addressed in this part, making it underspecific.", "verifiability_rationale": "The statement is a question, not a claim requiring justification. Therefore, it has X and is classified as 'X'.", "helpfulness_rationale": "The reviewer explicitly states their uncertainty, which is a valuable feedback signal. While the question itself doesn't provide a solution, it points to a clear area where the authors need more information or clarification. Therefore, it is 3 in identifying a need for further explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem (mixing train and test set examples) and suggests a solution (separating train and test set examples and including hypernyms and nonhypernyms). This is an explicit action the authors can take to improve their draft. The suggestion is also concrete, providing a clear direction for the authors to follow.", "grounding_specificity_rationale": "The reviewer directly refers to 'testsets' and 'train set examples' by number (558 and 574ff). This is a very specific reference to a particular part of the paper. The suggestion to include hypernyms and nonhypernyms also points to a specific aspect of the data description, indicating a strong grounding in the paper's content. The reviewer is very specific about the data leakage issue and suggests a concrete way to improve the clarity of the data description.", "verifiability_rationale": "The reviewer makes a claim (suggestion for improvement) regarding the data description and the potential for mixing train and test set examples. While they don't provide specific evidence *for* this particular suggestion at this point, they offer a logical principle (improving clarity) and a specific suggestion (separating examples and including hypernyms/nonhypernyms) to achieve that goal. The suggestion itself is a verifiable action that the authors can take to improve their draft.", "helpfulness_rationale": "The reviewer identifies a potential flaw in the experimental setup (data leakage) and suggests a concrete way to improve the clarity of the data description. This directly addresses a practical issue for the authors and provides a clear direction for them to improve their draft. The suggestion is actionable and directly related to the identified problem."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point asks for specific results for the AdpCLR_full approach for the ResNet50 architecture, which is a direct request for action. While the request is specific, it is a clear and actionable instruction for the authors to provide the missing data.", "grounding_specificity_rationale": "The review point directly asks for results for a specific method (AdpCLR_full) and a specific architecture (ResNet50). This is a clear identification of the part of the paper being addressed, making it fully grounded. The request also asks for results 'like the result provided for AdpCLR_pre', which specifies what needs to be addressed in this part (i.e., the performance results for the given method and architecture).", "verifiability_rationale": "The request is a direct question asking for specific numerical results from the authors' own experiments. There is X being made, so the verifiability aspect is not directly applicable to this review point. However, if the results are indeed missing, this review would be considered 5 as it directly points out a gap in the information.", "helpfulness_rationale": "The review point directly requests specific numerical results for the AdpCLR_full approach on the ResNet50 architecture. This is a clear and actionable request that would directly benefit the authors by providing missing performance data for this specific configuration. The request is specific, grounded in the existing results table structure, and directly addresses a potential gap in the information."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer is asking a question about the concept of replay, not providing a direct action or suggestion. While the question implies a potential area for improvement, it doesn't explicitly state what needs to be done. The reviewer is implicitly asking for clarification on the relationship between N trajectories, replay, and the Dyna model, but doesn't provide a concrete action to address this.", "grounding_specificity_rationale": "The reviewer is asking a general question about the concept of replay in the Dyna model, without specifying which trajectories or aspects of the model are being considered. The question lacks a clear target or specific section within the paper. The reviewer is asking 'Are N trajectories similar concepts of replay in the Dyna model?' but doesn't identify what 'N trajectories' or 'similarity' refer to in a concrete way.", "verifiability_rationale": "The review point is a question, not a claim requiring verification. Verifiability applies to statements that make assertions or judgments, which are then supported or not. This review point is a request for information, not a critique or suggestion.", "helpfulness_rationale": "The review point is a question seeking clarification on a concept, not a critique or suggestion for improvement. While the question is valid, it doesn't directly guide the authors to enhance their draft. It seeks to understand the relationship between N trajectories, replay, and the Dyna model, but doesn't offer actionable feedback on how to improve the work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states an action: 'Look at Tables 16 and 17 and investigate why the results are the same when the 2hop EG is changed to 3hop EG'. The action is to investigate the discrepancy in the results.", "grounding_specificity_rationale": "The review point explicitly mentions 'Tables 16 and 17', grounding the comment to a specific part of the paper. It also specifies the change in the EG value and the identical results, making the grounding very specific.", "verifiability_rationale": "The review point makes a claim: 'Some experiment results are suspicious' and provides a specific example ('Tables 16 and 17 share the same result, even changing the 2hop EG into 3hop EG'). This claim is supported by the observation of identical results despite the change in EG, making it 3.", "helpfulness_rationale": "The review point identifies a potential issue (suspicious results) and provides a specific location (Tables 16 and 17) to investigate the discrepancy. While it doesn't provide a solution, it guides the authors to focus their attention on a specific part of their experimental results, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a statement of fact about the experimental results. While it identifies a trend ('advantages' and 'not very significant'), it does not explicitly state what needs to be changed or how the results should be improved. The action is implicit, requiring the authors to infer the need for further investigation or refinement based on the observed results.", "grounding_specificity_rationale": "The review point refers to 'Experimental results' generally, without specifying which particular results or aspects of the algorithm are being discussed. While it mentions 'advantages' and 'stateoftheart algorithms,' it does not pinpoint the exact area of discrepancy or improvement. The grounding is at a higher level, lacking specific references to a particular section, table, figure, or unique element.", "verifiability_rationale": "The review point is a statement of observed experimental results, which is a factual statement. There is no explicit claim being made that requires verification. It describes the current state of the results without offering a new hypothesis or assertion about the underlying causes.", "helpfulness_rationale": "The review point provides context for the experimental results, noting that while the proposed algorithms are competitive with stateoftheart, they do not show a significant advantage. This observation can be helpful for the authors to understand the current limitations of their algorithm and potentially motivate them to investigate further or refine their approach to achieve more substantial improvements."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue ('may be prone to LLM's overconfidence') and suggests an alternative approach ('it prefers its predictions even if it is wrong'). However, it does not explicitly state what actions the authors should take to address this. The suggestion is more of a perspective than a concrete action. Therefore, it is not fully actionable. While the concern is explicit, the lack of specific guidance makes it 2.", "grounding_specificity_rationale": "The review point discusses the 'persentence assessment protocol' and 'LLM's overconfidence' without specifying which particular aspect or component of the paper is being referred to. There is no mention of a specific section, table, figure, or unique element. Therefore, the review does not ground the discussion to a specific part of the paper, making it 1.", "verifiability_rationale": "The review point presents a statement of concern ('may be prone to LLM's overconfidence') and a suggestion ('it prefers its predictions even if it is wrong'). While the suggestion implies a potential issue, it is presented as a possibility rather than a definitive claim requiring evidence. The point does not explicitly state a claim that needs verification. Therefore, it is 1.", "helpfulness_rationale": "The review point raises a concern about the persentence assessment protocol's potential for LLM overconfidence and suggests considering alternative approaches. However, it does not provide specific, actionable steps for the authors to take to address this concern. The suggestion is too general and lacks concrete details. Therefore, the review point is 2 as it does not offer concrete guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a fact ('W6.3 \u2026 ensures smooth nonsemantic diversity modeling') and then asks a question ('Again, what makes this reflect only the nonsemantic diversity, but not the semantic diversity?'). While the reviewer identifies an action (pointing out a method for nonsemantic diversity), the action is not explicitly stated as a suggestion for improvement or clarification. The reviewer is asking *why* something is happening, not *how* to make it better. Therefore, while the action is identified, the reviewer does not explicitly direct the authors to take a specific action to improve their draft based on this observation.", "grounding_specificity_rationale": "The reviewer refers to 'W6.3' in the paper, which is a specific section. This demonstrates that the reviewer can identify the specific part of the paper being addressed. However, the reviewer does not explicitly state *what* is being minimized or *why* it's focused on nonsemantic diversity. The question about the distinction between nonsemantic and semantic diversity implies that the *what* and *why* are implicit.", "verifiability_rationale": "The reviewer states a fact ('W6.3 \u2026 ensures smooth nonsemantic diversity modeling') and then asks a question ('Again, what makes this reflect only the nonsemantic diversity, but not the semantic diversity?'). The reviewer is making a claim about the method's behavior but does not provide explicit justification or references to support this claim. The question itself is the justification, but it's not a logical reasoning or a reference to external knowledge. Therefore, the claim is not fully supported by explicit, sufficient, or robust evidence.", "helpfulness_rationale": "The reviewer's question directly addresses a potential ambiguity in the paper regarding the distinction between nonsemantic and semantic diversity. This is likely to be helpful for the authors in understanding the method better. However, the reviewer does not offer a direct solution or improvement suggestion based on this observation. The feedback is more of a clarification request than a direct improvement proposal."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point is not actionable as it is a question seeking clarification rather than a direct suggestion for improvement.", "grounding_specificity_rationale": "The review point is 1 as it does not explicitly refer to a specific part of the paper.", "verifiability_rationale": "The review point is not a claim and therefore does not have verifiability in the traditional sense. However, it raises a valid point about the interpretation of results, which could be considered a form of implicit claim needing justification.", "helpfulness_rationale": "The review point is not 5 as it is a question that does not provide a concrete path forward for the authors. It encourages critical thinking but does not offer actionable suggestions."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point mentions \"modified GromovHausdorff distances and hypergraph structures\" and states the method is \"likely increases time complexity.\" While the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B, a discussion of the computational costs associated with training would be beneficial. The reviewer identifies a potential problem (increased training cost) but doesn't provide concrete steps to mitigate it or explain why this is a significant issue for the authors. The mention of \"likely increases time complexity\" is a potential issue, not an explicit action. The suggestion to address it is implicit. The review points out a potential problem without providing clear, actionable steps. Therefore, it is 2. It hints at an issue, but lacks the explicit guidance needed for full actionability.", "grounding_specificity_rationale": "The review mentions \"modified GromovHausdorff distances and hypergraph structures.\" While it hints at a specific component, it doesn't explicitly state which section or subsection of the paper these modifications relate to. It's implied but not definitively stated. The review explains *what* might increase complexity (GromovHausdorff distances and hypergraphs) but doesn't specify *how* these modifications would be implemented or what specific issues arise during training. The review touches on specific technical components but doesn't clearly pinpoint the *section* of the paper or explain the *specific* problem with training. Therefore, it is 3. It mentions a potential issue related to a specific part, but the connection isn't fully established.", "verifiability_rationale": "The review point contains a claim: \"The proposed method is complex... Likely increases time complexity.\" This is a claim about the potential impact of the method. However, the review *mentions* the increased time complexity but doesn't provide *evidence* or *reasoning* to support this claim. It's a statement of potential, not a verified fact. The reference to Appendix B is about addressing inference efficiency, not training complexity. The claim is present, but the reasoning and common knowledge or external references provided are lacking. The review makes a claim about potential training complexity but doesn't provide any evidence or reasoning to back it up. Therefore, it is 1.", "helpfulness_rationale": "The review point identifies a potential issue (increased training cost) related to the proposed method. However, it doesn't offer any concrete suggestions or guidance on how to address this issue. The focus is on the complexity of the method rather than actionable steps for the authors. The reviewer points out a potential problem but doesn't offer any solutions or guidance for the authors. Therefore, it is 1. The review points out a potential problem but doesn't offer any solutions or guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the *limitation* of the proposed method and its relation to existing techniques. This suggests it contains an *implied* action: 'You should be more clear about how your method differs from contrastive decoding.' While the reviewer doesn't explicitly say 'You should add a section explaining the differences,' they imply it. However, the action is not fully concrete. The reviewer doesn't specify *how* the distinction should be made. Is it a table comparison? A paragraph explaining the theoretical differences? The action is implied but not fully concrete.", "grounding_specificity_rationale": "The reviewer criticizes the *method* but doesn't explicitly point to a specific section, table, or figure in the paper where the method is described. The reviewer makes a general statement about the lack of distinction. They don't say 'Look at Section 3,' 'Focus on the experimental setup in Table 2,' or 'Explain the differences in the methods section.' The reference is vague. While the reviewer identifies a problem with the method, they don't specify *what* part of the method is lacking clarity.", "verifiability_rationale": "The reviewer makes a claim: 'The paper does not adequately distinguish its proposed method from existing contrastive decoding techniques.' This is a statement of a deficiency. However, the reviewer doesn't provide any evidence or reasoning to *why* the method doesn't adequately distinguish itself. They don't cite specific papers or explain *how* the distinction is lacking. The claim is stated, but there's no supporting evidence or logical reasoning.", "helpfulness_rationale": "The reviewer points out a lack of clarity in the paper's contribution. This is a valid concern for the authors. However, the reviewer doesn't offer a specific solution or suggestion on how to address it. They criticize the *method* but don't provide a clear path forward. While the weakness is identified, there's no actionable feedback provided for the authors to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: \"Figure 4's tabular representation of node agent interactions is not intuitive.\" This clearly identifies an action the authors should take: redesigning the table. The action is also concrete, specifying the type of representation and the area affected. There is no ambiguity in the reviewer's intent.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"Figure 4\" and the specific \"tabular representation of node agent interactions\". This is a literal mention of the section and the specific element being referred to, indicating full grounding. The issue is also clearly stated as being \"not intuitive\", which is specific.", "verifiability_rationale": "The reviewer makes a claim about the table's intuitiveness: \"Figure 4's tabular representation of node agent interactions is not intuitive.\" While this is a claim, it lacks specific justification or examples within the review point itself. There's no external reference provided to support this claim. Therefore, it's not 5. However, the reviewer's belief implies a potential lack of clarity or ease of understanding, which could be verified by examining the figure.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: \"Could you consider redesigning the table to make it more intuitive, perhaps by using visual cues or breaking it down into smaller, more digestible parts?\" This directly addresses the identified problem and offers concrete steps for improvement. The reviewer's comment is directly aimed at helping the authors understand and use the information presented in the table."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about alternative frameworks and the impact of PU loss on calibration. While it suggests considering other baselines, it doesn't explicitly state an action the authors should take. Similarly, it asks about calibration impact but doesn't provide a concrete action. The questions are more about prompting further investigation than providing a clear next step. The implicit suggestion to explore calibration is vague and lacks specific guidance on how to do so.", "grounding_specificity_rationale": "The review point doesn't explicitly state a specific aspect of the PU framework or the PU loss. It uses general terms like 'frameworks' and 'examples with less irreducible uncertainty.' While it implies a concern about the PU framework, it doesn't pinpoint a specific section, table, or figure. The questions are broad and don't directly address a particular part of the paper. The lack of specificity makes it difficult for the authors to identify the exact area they need to focus on.", "verifiability_rationale": "The review point raises questions about the benefits of prioritizing learning on examples with less irreducible uncertainty and the impact of PU loss on calibration. These are valid points, but the review doesn't provide any evidence, reasoning, or references to support these claims. It's a questiondriven comment without any attempt to verify the proposed benefits or impacts. The lack of verifiability makes it difficult to assess the validity of the claims.", "helpfulness_rationale": "The review point raises questions about alternative frameworks and the impact of PU loss on calibration. While these are relevant questions, they don't offer concrete, actionable feedback for the authors. The questions are more about prompting further research or analysis than providing a clear next step. The review doesn't suggest any specific experiments, analyses, or changes the authors should implement based on these questions. The questions are more about exploring possibilities than providing direct guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a disagreement regarding the characterization of Transfer Learning (TL) and Finetuning (FT) in the introduction. They argue that describing TL and FT as sequential MultiTask Learning (MTL) is inaccurate. The reviewer correctly identifies that Finetuning is a sequential process, while Transfer Learning is a broader term encompassing various methods, including finetuning. This highlights a potential lack of clarity in the introduction regarding the nuances of these concepts. While the reviewer doesn't explicitly state an *implicit* action or suggestion, the identification of a potential misunderstanding creates an *implicit* call for clarification and a suggestion to revisit the definitions of TL, FT, and MTL.", "grounding_specificity_rationale": "The reviewer explicitly names the concepts being discussed: 'Transfer Learning (TL)', 'Finetuning (FT)', and 'MultiTask Learning (MTL)'. They also clearly explain the disagreement: 'TL is a broader term for the phenomenon of learnings from one task benefiting another task. Finetuning is a sequential way of doing it. Standard MTL is a parallel means to the same end.' This demonstrates strong grounding specificity as the reviewer accurately identifies the specific parts of the paper (or the concepts being discussed) and provides a clear explanation of the disagreement.", "verifiability_rationale": "The reviewer states a disagreement about the characterization of TL and FT in the introduction. This constitutes a claim that something is incorrect. While the reviewer doesn't provide external references or specific examples to *verify* the claim, the statement itself is a verifiable assertion based on the definitions of these terms. The reviewer *could* potentially provide references to support their claim, making it more verifiable, but the claim itself is present.", "helpfulness_rationale": "The reviewer identifies a potential point of confusion for the authors regarding the relationship between Transfer Learning, Finetuning, and MultiTask Learning. By pointing out the difference between sequential and parallel approaches, the reviewer highlights a specific area in the introduction that needs clarification. This is a helpful comment as it directs the authors to a specific section and encourages them to think about the nuances of these learning paradigms. The reviewer's suggestion to 'revisit the definitions' is a concrete action the authors can take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the lack of a 'Limitation section,' which is an explicit action indicating a missing element. However, it doesn't specify *where* this section should be added, making it less concrete.", "grounding_specificity_rationale": "The comment mentions 'a Limitation section' without specifying which section, table, figure, or unique element of the paper it refers to. While it identifies the *type* of section, it doesn't pinpoint its location or content.", "verifiability_rationale": "The comment contains a claim ('The paper lacks a Limitation section which is important') that can be verified by examining the paper's structure and content. It provides a factual observation that can be supported by common knowledge of good academic writing practices.", "helpfulness_rationale": "The comment directly points out a clear weakness in the paper (the absence of a standard section) and suggests an improvement area (adding a limitations section). While it doesn't provide specific instructions on *how* to add it, it offers a constructive suggestion for improvement, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests improvements to the 'theory behind diffusion models' and the 'CLIP guidance by means of global CLIP loss and local directional loss'. These are explicit suggestions for action, indicating a clear need for more detail or clarification in these areas. The reviewer is pointing out specific areas where the paper lacks sufficient explanation or guidance. Therefore, the review point is actionable as it directly suggests concrete changes to the paper.", "grounding_specificity_rationale": "The review point generally criticizes the lack of detail in the 'theory behind diffusion models', the 'CLIP guidance by means of global CLIP loss and local directional loss', and the 'works of (Choi et al. 2021, Meng et al. 2021)'. However, it does not explicitly identify the specific section, table, figure, or unique aspect of the paper being addressed in these criticisms. The reviewer is making general statements about the lack of explanation, which could apply to various parts of the paper. While the criticisms are relevant, the lack of specific grounding makes it difficult for the authors to pinpoint exactly where improvements are needed. Therefore, the grounding specificity is somewhat low as the reviewer does not clearly identify the specific part of the paper being addressed in their criticisms.", "verifiability_rationale": "The review point makes claims about the 'theory behind diffusion models' needing more detailed explanations, the 'CLIP guidance by means of global CLIP loss and local directional loss' being unclear, and the 'works of (Choi et al. 2021, Meng et al. 2021)' not being explained. These claims are generally verifiable based on common knowledge in the field and the general understanding of these concepts. For example, the lack of detail in diffusion model theory is a common issue, and the need for explanation of cited works is a standard academic practice. However, the review point does not provide specific examples or references to support these claims, making the verifiability somewhat lower. The claims are generally understandable and align with common practices, but lack specific evidence to strongly support them.", "helpfulness_rationale": "The review point provides suggestions for improving the paper, such as providing more detailed explanations of the 'theory behind diffusion models', clarifying the 'CLIP guidance by means of global CLIP loss and local directional loss', and explaining the 'works of (Choi et al. 2021, Meng et al. 2021)'. These suggestions are generally helpful as they directly point towards areas where the paper could be improved. However, the level of detail in these suggestions is somewhat vague. The reviewer suggests 'more detailed explanations' but doesn't specify what aspects need more detail. Similarly, the suggestions for clarifying CLIP guidance and explaining the cited works are broad. While the suggestions are relevant, the lack of specificity makes it less helpful than a more detailed critique. Therefore, the review point is 4 as it identifies areas for improvement, but the lack of specificity makes it less impactful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the suggestion: 'The title should include the term \"tensor completion\"'. This is a direct and clear action.", "grounding_specificity_rationale": "The reviewer not only identifies the specific aspect of the paper being addressed (the title and its relation to the specific application 'tensor completion') but also explicitly states the desired change: 'include the term \"tensor completion\"'. This demonstrates strong grounding as the specific part is accurately identified and the suggestion is concrete.", "verifiability_rationale": "The reviewer makes a claim: 'the title should include the term \"tensor completion\" because that is the only application of the new model that is presented in the paper.' However, the reviewer does not provide any evidence or justification for why the title is currently too broad or why including 'tensor completion' is necessary. The claim is made without supporting reasoning, common knowledge, or external references. Therefore, it is 1.", "helpfulness_rationale": "The reviewer provides a suggestion (high actionability) and identifies a specific aspect of the paper (grounding specificity). However, the reviewer does not provide any evidence or justification for why the title is currently too broad or why including 'tensor completion' is necessary. The claim about the title being too broad is not supported by any reasoning, common knowledge, or external references. Therefore, while the suggestion itself is helpful, the lack of justification makes the overall review less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem: 'the authors do not make any attempt to compare it to any other prior methods' and suggests a solution: 'Why not implement a simple baseline (for example, character frequencies, etc) and compare to it?'. This is a clear and direct action the authors can take.", "grounding_specificity_rationale": "The reviewer identifies a general area for improvement (lack of comparison to prior methods) but does not specify which part of the paper this is a problem for or why this comparison is crucial in the context of the submitted work. The reviewer suggests a *type* of baseline but doesn't pinpoint a specific issue or location within the paper where this comparison would be most beneficial.", "verifiability_rationale": "The reviewer makes a claim: 'Why not implement a simple baseline (for example, character frequencies, etc) and compare to it?'. However, they do not provide any logical reasoning, common knowledge, or external references to support this claim. The justification for this suggestion is missing.", "helpfulness_rationale": "The reviewer provides a suggestion for improvement (comparing to a baseline) which is relevant to the paper's content (empirical evaluation). While the suggestion is not fully justified, it offers a concrete direction for the authors to take, potentially leading to a more comprehensive evaluation. The reviewer's intent is to help the authors improve their draft by suggesting a specific type of analysis."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states 'Limited Practicality in Reducing Computational Load' and provides reasons like 'different tokens activate different channels' and ' difficulty in applying a uniform activation pattern'. These are direct statements of a potential issue and how it might arise. The reviewer also suggests 'all tokens to activate all channels' as a possible consequence, which is an action the authors could take or consider. The explanation of the potential problem is present, making it more than just a vague statement.", "grounding_specificity_rationale": "The review point discusses the limitations of a proposed method in a realworld setting. It does not explicitly refer to a specific part of the paper, such as a section, table, or figure. The reviewer is making a general statement about the method's potential challenges in applying uniform activation patterns. While the implications could be specific to certain parts of the model or data, the point itself does not pinpoint a specific element of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the method: 'Empirically, different tokens activate different channels, making it difficult to apply a uniform activation pattern across all tokens.' While they don't provide direct evidence within this point, the phrasing suggests this is a recognized issue or finding. The implication is that this is a verifiable limitation of the method. The reviewer presents this as a potential problem, suggesting it's a valid observation or finding, even if not explicitly cited within this specific review point.", "helpfulness_rationale": "The reviewer points out a potential drawback of the method: its limited practicality in reducing computational load. This is a critique of the method's potential impact. While it highlights a concern, it doesn't offer a constructive suggestion or improvement. The reviewer is pointing out a potential issue rather than proposing a solution or a positive aspect of the method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment identifies the problem of unclear task boundaries in the abstract and suggests that the proposed benchmark, metrics, and gating technique might help. However, it does not explicitly state how these elements should be used to address the identified problem. The authors are left to infer the connection between the stated problem and the proposed solutions.", "grounding_specificity_rationale": "The comment refers to the abstract and the general concept of 'actual tasks' when describing the problem. It does not explicitly point to a specific section, table, figure, or unique element of the paper where this demarcation issue is most relevant. The connection between the abstract's statement and the proposed solutions is implied but not explicitly linked to a specific part of the paper.", "verifiability_rationale": "The comment states a problem ('it is hard to demarcate task boundaries in actual tasks') and then describes the proposed solution ('a new benchmark, new metrics, and gating technique are proposed'). While the *claims* are present, the *verifiable link* between the problem and the proposed solution is not explicitly stated or justified. The comment presents the problem and the potential solution but doesn't provide a logical reasoning or external references to support the effectiveness of the solution in addressing the problem.", "helpfulness_rationale": "The comment highlights a key issue in the abstract \u2013 the lack of clarity on task boundaries \u2013 and points towards the proposed benchmark, metrics, and gating technique as potential solutions. While it doesn't explain *how* these solutions address the problem, it does identify a relevant area for the authors to focus their efforts and understand the motivation behind their work. The authors gain a starting point to understand the context of the paper."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a problem: 'I have some concerns about the sequence inference classifier that is used to filter data.' They also suggest a solution: 'It's unclear to me what kind of data passes this filter  the task of filtering data using the task description seems quite different from the original MNLI distribution. Some examples of the filtered data would be helpful to look at.' This clearly indicates an actionable issue for the authors. The authors need to understand what data is being filtered and why the filtering process differs from the original distribution. The reviewer provides a clear direction for improvement by asking for examples.", "grounding_specificity_rationale": "The reviewer mentions 'sequence inference classifier' and specifically asks 'What kind of data passes this filter' and 'Some examples of the filtered data would be helpful to look at.' This demonstrates strong grounding specificity. The authors can precisely identify the referenced part of the paper (the filtering process) and the issue (the unclear nature of the filter and the lack of examples). The request for examples makes the grounding even more specific.", "verifiability_rationale": "The reviewer states a concern: 'I have some concerns about the sequence inference classifier that is used to filter data.' This is a claim that needs to be verified. The reviewer then suggests a way to verify this claim by asking for 'Some examples of the filtered data would be helpful to look at.' This provides a clear method for the authors to understand the filtering process and the difference from the original distribution, thus supporting the claim. The suggestion for examples makes the claim verifiable.", "helpfulness_rationale": "The reviewer clearly states a problem and offers a concrete solution. They identify a lack of clarity regarding the filtering process and propose providing 'examples of the filtered data.' This directly addresses the authors' need for understanding and improving their draft. The suggestion for examples makes the review helpful and actionable for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of the experiments, such as the use of a single model (DALLE) and a small dataset. This directly points to an actionable suggestion for the authors to improve their experimental design. The reviewer's call for more comprehensive experiments is a clear indication of a need for action on their part.", "grounding_specificity_rationale": "The reviewer mentions 'chaotic equation numbering' and 'lack of indentation in Algorithm 1'. These are explicit and specific references to particular parts of the paper. The reviewer clearly identifies the section (equations/Algorithm 1) where these issues occur, demonstrating a strong grounding in the paper's structure and formatting.", "verifiability_rationale": "The reviewer directly links the limitations of the experiments to the 1 nature of the results. The statement 'Without comprehensive experiments, the effectiveness of the proposed methods cannot be validly verified' clearly indicates that the reviewer's concerns are wellsupported and verifiable by the authors through further experimentation. The reviewer's suggestions for improvement are based on the verifiability of the results.", "helpfulness_rationale": "The reviewer provides concrete suggestions for improvement, such as expanding the experiments and fixing the formatting issues. These suggestions are directly actionable and address specific weaknesses identified in the paper. The reviewer's overall assessment of the paper's need for editorial review is a valuable piece of feedback that empowers the authors to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer provides a suggestion for improvement by asking for practical applications, which is a direct action. However, the suggestion lacks specific details on how to identify these applications or what steps should be taken to implement them. The reviewer is vague about the nature of 'practical applications' and doesn't offer concrete steps for the authors to follow.", "grounding_specificity_rationale": "The reviewer points out a potential issue with the experimental setup (manipulated datasets) but doesn't explicitly state which part of the paper is unclear or needs clarification. The reviewer's comment is more of a critique of the methodology rather than a precise identification of a missing element in the paper.", "verifiability_rationale": "The reviewer makes claims about the practical applications and the flaw in the experiments, but provides no evidence or justification for these claims. The reasoning behind the critique of the experimental setup is missing, making it difficult to verify the validity of the criticism. The reviewer doesn't cite any external references or logical reasoning to support their claims.", "helpfulness_rationale": "The reviewer clearly states their desire for more practical guidance and identifies a flaw in the current methodology. This feedback is intended to be helpful for the authors. However, the lack of specific details in the suggestions and the missing reasoning for the critique make the feedback less impactful."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states they 'don't understand how the CALMIR selection of m' is done'. This indicates an implicit action or suggestion that the explanation of the selection process is lacking. While the reviewer asks a specific question ('Is it done exhaustively...'), the lack of immediate concrete information makes the action implicit rather than fully specified. The reviewer is asking for clarification, which is a direct and actionable suggestion, but the lack of immediate concrete information makes it only 2.", "grounding_specificity_rationale": "The reviewer directly asks a question about the method (CALMIR selection of m') and the practical implications of it. This implies the reviewer can identify the specific part of the paper being addressed (CALMIR). The reviewer also asks a specific question about whether it's done exhaustively, which further specifies the issue they are facing. The reviewer is pointing to a specific area of confusion and asking a targeted question.", "verifiability_rationale": "The reviewer states their lack of understanding regarding the CALMIR selection process and asks a specific question about exhaustiveness. While the reviewer claims a lack of clarity, the specific question about exhaustiveness provides some justification. The reviewer is stating an opinion (they don't understand) and asking a question to seek clarification, which can be considered a form of justification, albeit vague. The reviewer is making a claim (lack of understanding) and providing some evidence (the question about exhaustiveness) to support it.", "helpfulness_rationale": "The reviewer requests clarification on a specific technical detail of the CALMIR method. This is a direct and actionable suggestion aimed at improving the authors' understanding. The reviewer also raises a practical concern about the computational cost of the exhaustive search, which is relevant for the authors to consider. The reviewer is providing a clear action (request for clarification) and a relevant concern (computational cost), making the review point helpful in guiding the authors."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states \"input datafree\" detection methods as a category of backdoor detection. This is a clear action. However, it does not specify how these methods should be implemented or applied, making it somewhat vague on the concrete action.", "grounding_specificity_rationale": "The review point mentions \"input datafree\" detection methods in the context of the \"Robustness\" section. While it identifies the category of methods, it does not explicitly point to a specific part of the \"Robustness\" section or a specific aspect of the model being addressed. Therefore, the grounding is weak. While it clearly specifies what needs to be considered (new categories of detection methods), it does not specify which existing methods within that category are being referred to or why they are relevant to the \"Robustness\" section. This makes the specificity underspecific.", "verifiability_rationale": "The review point contains a claim: \"these methods should also be taken into consideration in the analysis of algorithm performance.\" The support for this claim comes from the general knowledge that input datafree methods exist and are a relevant category of backdoor detection. However, the review point does not provide specific examples of these methods, logical reasoning to support their existence, or external references to back up this claim. The justification is present but lacks key elements like examples or citations.", "helpfulness_rationale": "The review point is helpful because it suggests a concrete improvement to the analysis of algorithm performance by categorizing backdoor detection methods. It identifies a potential area for expansion and suggests a specific type of method (input datafree). While it doesn't provide detailed guidance on how to implement this suggestion, it clearly points towards a actionable direction for the authors. The reviewer is making a judgment that adding this category would be beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states two actions: 'improve the relation works section' and 'describe which view of the knowledge graph is part of the assumption.' While the actions are stated, they are not concrete enough to guide the authors on how to make these improvements. The reviewer identifies the areas needing attention but doesn't specify the steps or methods to achieve the improvements.", "grounding_specificity_rationale": "The reviewer refers to the 'relation works section' and the 'knowledge graph' as specific parts of the paper. The mention of 'incomplete' for the relation works section and the need to 'describe which view of the knowledge graph is part of the assumption' indicates a clear understanding of the specific areas being criticized. The reviewer pinpoints the sections and the specific issue within the knowledge graph.", "verifiability_rationale": "The reviewer makes a claim about the 'relation works section' being 'incomplete' and the need to 'describe which view of the knowledge graph is part of the assumption.' However, the reviewer does not provide any specific evidence or reasoning within this review point to support these claims. The statements are presented as observations or suggestions without backing.", "helpfulness_rationale": "While the reviewer identifies areas where the authors could improve their work, the review point lacks the necessary details and evidence to be truly helpful. The reviewer points out the 'incompleteness' of the 'relation works section' and the need to specify the 'view of the knowledge graph' in the assumption, but they do not provide any concrete examples or explanations to guide the authors on how to address these issues. The lack of verifiable evidence makes the review less impactful in providing actionable feedback."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out a potential issue with the update rules for intrinsic rewards but doesn't explicitly state how to fix it or what specific action the authors should take. The criticism is presented as a problem without a clear, actionable solution.", "grounding_specificity_rationale": "The reviewer mentions 'Eq.710' which grounds the comment in specific elements of the paper. However, they don't specify *what* is wrong with these equations or how they should be modified. The grounding is present, but the specificity of the issue is lacking.", "verifiability_rationale": "The reviewer states that the derivation of the intrinsic reward parameters is 'hardly convincing' but doesn't provide any specific evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up their assertion.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the theoretical support of a specific technical design. However, they fail to provide any justification or explanation for why they believe the derivation is unconvincing. Without this justification, the reviewer's point is not helpful for the authors as they cannot understand the basis for the criticism or how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer states their disagreement with the authors' claim explicitly: 'In my opinion'. This indicates a clear and direct statement of opinion. While the reviewer doesn't propose a specific alternative action, the disagreement implies that the reviewer believes the authors should reconsider their interpretation of 'small enough \u03b2'.", "grounding_specificity_rationale": "The reviewer refers to 'adaptive variance reduction property claimed by the authors' and '\u03b2 parameter'. This demonstrates a clear identification of the specific aspect of the paper being discussed. Furthermore, the reviewer explains what they believe is incorrect about the authors' interpretation of 'small enough \u03b2' and even suggests considering AdaGrad as an example, providing specific details.", "verifiability_rationale": "The reviewer presents a claim: 'In my opinion... takes away the adaptivity claim... not the case in adaptive methods such as AdaGrad.' This is a clear statement of opinion. The reviewer also provides an example (AdaGrad) to support their claim, indicating that the claim is supported by logical reasoning and a specific example.", "helpfulness_rationale": "The reviewer's point directly challenges a key claim made by the authors regarding the adaptivity of their method. This is a valuable point for the authors to consider and potentially refine their understanding. While the reviewer doesn't propose a concrete fix, they highlight a potential area of discrepancy, which can be helpful for improving clarity and addressing potential misunderstandings."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the *why* and *how* to further investigate the bestperforming model (DINOv2). They suggest comparing different augmentation techniques across various models and analyzing the results. This provides clear and actionable steps for the authors to take.", "grounding_specificity_rationale": "The reviewer mentions 'different augmentation techniques' and 'DINOv2' by name. While they refer to 'DINOv2' specifically, they don't pinpoint the exact section, table, or unique aspect of the paper where these are discussed. The mention of 'different augmentation techniques' is general, lacking specific details within the paper.", "verifiability_rationale": "The reviewer states a suggestion for further investigation ('It would be good to further investigate why and how to further improve the bestperforming model') without providing any specific evidence, reasoning, or references to support this claim. The suggestion is presented as a general direction for future work.", "helpfulness_rationale": "The reviewer offers a suggestion for further investigation into different augmentation techniques and DINOv2. While this is a valuable suggestion for future work, it doesn't directly identify a specific weakness or improvement needed in the current draft. It proposes an area for further exploration rather than addressing an immediate issue."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the potential confusion with the existing acronym 'FTL' and clearly suggests a change in terminology. The action is concrete: 'Perhaps a change of acronym is in order.' Authors can directly implement this suggestion by updating the paper's terminology.", "grounding_specificity_rationale": "The comment clearly identifies the specific issue: the potential confusion with the existing 'FTL' acronym. While it doesn't pinpoint a specific instance where this confusion manifests, the reference to the acronym itself is a strong form of grounding. The specificity is in identifying the *term* that is causing ambiguity, not a specific detail within a section or table.", "verifiability_rationale": "The comment doesn't directly state a claim about a factual error within the paper. It's more of a suggestion for improvement in terminology. However, it implicitly suggests that the current use of 'FTL' might be misleading, prompting authors to investigate further. If interpreted as a claim, it lacks specific evidence within the review point itself.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for improvement. It directly points to a potential area for clarification and encourages the authors to make a concrete change. The helpfulness is conditional on the actual usage of 'FTL' in the paper, but the suggestion itself is clear and directly actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a weakness in the selection of attacks (arbitrary, not stateoftheart) and requests more details (hyperparameters). While they don't explicitly state that the current selection is incorrect, they imply it's lacking in justification and completeness. The request for more details suggests an expectation for improvement, which can be seen as an implicit action. However, the lack of a clear, direct action the authors should take makes it less actionable than a strong critique with a clear solution.", "grounding_specificity_rationale": "The reviewer mentions specific attacks (like MIDIFGSM as an example) and requests details about hyperparameters like the number of iterations. This demonstrates a clear grounding of the criticism in specific elements of the paper and asks for details within those elements. The mention of MIDIFGSM indicates an awareness of other relevant attacks, and the request for iterations points to a specific implementation detail.", "verifiability_rationale": "The reviewer makes a claim that the suggested attacks are not stateoftheart and requests details about hyperparameters. This constitutes a claim that needs verification. They provide a reason for their claim (the existence of MIDIFGSM) and request information (iterations), which serves as partial verification. However, they don't provide concrete evidence or references to definitively prove the suggested attacks are not stateoftheart or that the hyperparameters are standard.", "helpfulness_rationale": "The reviewer's point is more of a critique and a request for more information rather than a direct, actionable suggestion for improvement. They highlight a weakness in the current approach (attack selection) and suggest improvements (justification, details). While it points to a need for better feedback, it doesn't directly instruct the authors on what to do with the current draft. Therefore, it's borderline helpful."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a limitation of the method but does not provide explicit or concrete steps for the authors to take to address this limitation. It states that the method is primarily effective for contrastive learning and may not work with MIM, but it doesn't suggest how the authors should modify their approach or investigate further.", "grounding_specificity_rationale": "The reviewer points out a limitation of the method in the 'limitations' and 'conclusion' sections, which implies a general concern about the method's applicability across different pretraining methods. However, they do not explicitly identify a specific part of the paper, table, or figure where this limitation is most relevant. The reviewer is inferring the issue rather than pinpointing a specific location.", "verifiability_rationale": "The review point states a limitation of the method in the 'limitations' and 'conclusion' sections. While it identifies a potential issue, it does not provide any specific evidence, references, or logical reasoning to support this claim. It is a statement of observation without justification.", "helpfulness_rationale": "The review point identifies a limitation of the method, which is valuable information for the authors to be aware of. However, it does not offer any suggestions or guidance on how to address this limitation. It is a negative comment about the method's limitations without providing any constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides a statement about the qualitative analysis but does not explicitly state how the two input sentences were determined. While the reviewer mentions 'Sec 4.5.5, Figure 1', this is a reference to a specific section and figure, indicating some level of grounding. However, the reviewer does not provide a concrete action on how to determine these examples or how to implement the attribution analysis. The request about normalization and the behavior of attribution maps on misclassified examples are also not explicitly stated as actions to be taken. Therefore, while there is some grounding, the lack of explicit action makes it 2.", "grounding_specificity_rationale": "The reviewer mentions 'Sec 4.5.5, Figure 1' which suggests some level of grounding as they are referring to a specific section and figure. However, the reviewer does not explicitly state which part of the paper the examples are located in, nor does they directly identify the qualitative analysis section. The reviewer also asks about the finetuning process, which is a question about grounding. Therefore, while there is some grounding, it is not fully explicit, making it 3.", "verifiability_rationale": "The reviewer states that they 'determined the two input sentences for qualitative analysis' and 'attribution values in Fig. 1 are 0 to 1'. This can be considered a claim. However, the reviewer does not provide a clear reasoning or justification for how they determined the examples, why the attribution values are 0 to 1, or how the attribution maps behave on misclassified examples. The lack of logical reasoning and external references makes this claim 3. The reviewer also asks about normalization, which is a request for justification, not a claim that needs verification.", "helpfulness_rationale": "The reviewer provides some information about the qualitative analysis and attribution values, which could be considered helpful. However, the lack of explicit actions and verifications makes the feedback 3. The reviewer asks 'how were two input sentences for qualitative analysis (Sec 4.5.5, Figure 1) determined?' and 'Did you normalize the vector norms?' These are requests for more information and clarification, rather than direct, actionable feedback. The reviewer also asks about the behavior of attribution maps on misclassified examples, which is a request for evaluation and further analysis. The feedback is present but lacks the concrete actions and verifications expected for 5 feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the desire for examples, specific tensor types, and validation. However, they do not specify *which* practical applications, *which* specific types of tensors, or *how* these examples validate the functions. The action is stated, but the implementation details are missing, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'practical applications' and 'specific types of tensors' in their suggestion. While they don't point to a specific section or table, they do identify the *area* where examples are needed. This can be considered weak grounding as the authors can infer the intended meaning. The specificity is also somewhat weak as they don't pinpoint a specific application or tensor type.", "verifiability_rationale": "The reviewer presents a suggestion: 'Include examples of practical applications where specific types of tensors need to be equivariant and clarify how these scenarios validate the advantages of using equivariant tensor functions.' This is a claim, as it suggests improvements. However, the reviewer does *not* provide any evidence, justification, or references to support this claim. The suggestion is made without any backing, making it 1.", "helpfulness_rationale": "The reviewer's suggestion is clear and identifies a potential area for improvement. However, the lack of specificity and the absence of any supporting evidence (like examples or references) make it difficult for the authors to understand the practical implications or how to validate the claim. While the *topic* is relevant, the *howto* is missing, making it somewhat unhelpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer implicitly suggests improvements by pointing out the lack of clarity in the methods (ERM, cRT, LWS) and the misalignment between the table and the section. While they don't explicitly state 'You should clarify Table 2' or 'You should discuss the relationship between Section 3.2.3 and Table 2', the implications are clear. The reviewer is indicating areas where the authors need to take action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 2' and 'Section 3.2.3', identifying the specific parts of the paper they are referring to. They also point out the *problems* within these sections, such as the lack of clarity for the methods and the misalignment. This demonstrates a clear understanding of the relevant parts and the issues within them.", "verifiability_rationale": "The reviewer states that the methods (ERM, cRT, LWS) are 'unclear' and that there is a 'misalignment' between the table and the section. However, they do not provide any evidence, references, or logical reasoning to support these claims within the review point itself. They are stating their *perception* of the issues, but without justification.", "helpfulness_rationale": "The reviewer points out specific issues with the tables and sections, which is helpful for the authors to be aware of potential problems. While they don't offer concrete solutions within the review point, identifying these areas of concern is a form of diagnostic feedback that can guide the authors' selfimprovement. The reviewer is informing the authors about potential weaknesses."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point presents two questions. The first question, 'Does this model be suitable on sarcastic/nonsarcastic utterances? The authors should provide more details for further analysis,' is an explicit action asking for more information. The second question, 'Why the eyemovement data would be useful for sarcastic/nonsarcastic sentiment classification beyond the textual features? The authors should provide more explanations,' is also an explicit action asking for further justification. Both questions directly prompt the authors to provide more details and explanations.", "grounding_specificity_rationale": "The review point explicitly mentions 'sarcastic/nonsarcastic utterances' in the first question and 'eyemovement data' and 'sarcastic/nonsarcastic sentiment classification' in the second question. This direct reference to specific aspects of the paper makes the grounding explicit and specific.", "verifiability_rationale": "The review point asks questions and provides suggestions for improvement. In the first part, 'The authors should provide more details for further analysis,' the reviewer is suggesting what kind of details are needed. In the second part, 'The authors should provide more explanations,' the reviewer is directly asking for further justification. While the suggestions don't provide concrete evidence, they are clear and point to areas where the authors' work could be improved. The logical reasoning is present in the suggestions to enhance the analysis and understanding of the model's application and the utility of different data types.", "helpfulness_rationale": "The review point provides clear questions and suggestions for improvement. The questions directly address potential limitations or areas needing further exploration. The suggestions, such as 'provide more details' and 'provide more explanations,' are actionable and directly encourage the authors to enhance their work. The reviewer is actively engaging with the authors' findings and prompting for further analysis and justification, which is beneficial for their understanding and improvement of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a lack of experiments and issues with the datasets and table formatting. However, it does not explicitly state how the authors should improve these aspects. The authors are left to infer the necessary steps, making the action implicit rather than explicit.", "grounding_specificity_rationale": "The comment mentions 'table1' and 'table2', which grounds the issue to specific parts of the paper. It also mentions 'smallscale/resolution datasets', which grounds the issue to a specific aspect of the experimental setup. However, it doesn't specify *which* particular experiment is lacking detail or *what specific characteristics* of the datasets make them smallscale/resolution.", "verifiability_rationale": "The comment states a factual observation about the limited experiments and smallscale datasets. While it implies a lack of rigor, it doesn't provide external references or logical reasoning to support this claim. The claim is present but lacks sufficient justification.", "helpfulness_rationale": "The comment identifies a valid weakness in the experimental section. However, it does not offer any specific suggestions or guidance on how the authors should address these issues. The feedback is limited to pointing out a problem without providing actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states their understanding of the method's effect on variance and asks a question about the implications. This is an *implicit* statement of their understanding. They aren't directly stating \"The method adjusts the variance...\" but rather inferring it. The action itself (asking about implications) is vague as they don't specify *which* privacy level or *how* utility is being considered.", "grounding_specificity_rationale": "The reviewer is asking a question about the method's impact on privacy. While they are referencing \"DPSGD\" and \"utility,\" they are *not* explicitly pointing to a specific section or table in the paper. The connection is implied. The comment specifies what needs to be addressed (privacy impact) but doesn't pinpoint the exact part of the paper being discussed.", "verifiability_rationale": "The reviewer *is* making a claim: \"I think it is just adjusting the variance level of DPSGD, it should influence the utility, but what we can lose in the privacy level should be presented.\" This is a clear statement of their understanding and their point of inquiry. However, the claim is **not** 5. They are making an assertion about the tradeoffs without providing specific evidence or analysis within their review point. They are asking a question that the paper hasn't fully addressed.", "helpfulness_rationale": "The reviewer is trying to understand the significance of a method and its tradeoffs. This is a valuable piece of feedback for the authors. However, the feedback is somewhat vague. The reviewer isn't providing a specific suggestion for improvement; they are questioning the *why*."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue (no closedform solution) and suggests looking at experimental details. While this provides a direction for the author to investigate, it doesn't explicitly state what needs to be done or how to implement the solution. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer refers to 'Equation (13)' which grounds the reference. However, they do not specify which part of the paper or table within the equation is problematic. The grounding is at the level of the equation itself, not a specific element within it.", "verifiability_rationale": "The reviewer states that 'Equation (13) doesn't seem to have a closed form solution in general.' This is a claim that something doesn't exist. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion to look at experimental details is a hint, but the review itself doesn't offer verification.", "helpfulness_rationale": "The reviewer points out a potential issue with Equation (13) and suggests looking at experimental details. While this could be helpful for the author to understand the practical aspects of the equation, the review itself doesn't provide concrete steps or solutions. It's more of a pointer to further investigation rather than a direct improvement suggestion."}
{"actionability_label": "High", "grounding_specificity_label": "Low", "verifiability_label": "High", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly points out a limitation of using Cartesian proximity as a proxy for task proximity, which is a direct and actionable insight for the authors. They are highlighting a potential flaw in their metric that needs to be addressed.", "grounding_specificity_rationale": "The reviewer doesn't explicitly identify a specific part of the paper they are referring to. While they ground the issue in the limitations of the metric itself, the specificity of *which part* of the paper is lacking this proposed metric is somewhat vague. They are more focused on the metric's limitations than on a specific section of the paper.", "verifiability_rationale": "The reviewer provides examples (maze and robotic tasks) to support their claim about the limitations of Cartesian proximity. These examples serve as verification for their point, and the reasoning is clear: in complex spaces, Euclidean distance doesn't equate to task proximity. The claim is thoroughly supported by explicit, sufficient, and robust evidence.", "helpfulness_rationale": "The reviewer's point is very actionable. They are directly informing the authors to consider the limitations of their metric and potentially reevaluate it for complex tasks. This is a clear benefit to the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'The experiments lack many implementation details.' This clearly identifies a missing action. The authors need to add specific details to reproduce the results. While the action is not inferred, it is explicit. However, the reviewer does not specify *what* details are missing, making the action somewhat vague.", "grounding_specificity_rationale": "The review point refers to 'the experiments' in general, without specifying which particular part of the paper or methodology is lacking details. The reviewer does not mention any specific section, table, figure, or unique element of the paper. Therefore, the grounding of the comment is weak. While the comment identifies a specific area (experiments), it does not clearly identify the *specific* part of the paper being addressed.", "verifiability_rationale": "The review point does not contain a claim that needs verification. It is a statement of a problem (lack of implementation details) rather than a proposition that requires logical reasoning, common knowledge, or external references to support. Therefore, it falls under the 'X' category of X.", "helpfulness_rationale": "The review point directly identifies a significant weakness in the paper: the lack of implementation details. This is a crucial piece of feedback for the authors as it directly impacts the reproducibility and understanding of their work. By highlighting this, the reviewer is empowering the authors to improve their paper for better clarity and reproducibility. This is a highly valuable piece of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the potential unfairness in the comparison due to the different region proposal methods used by SSUL and the paper. They further suggest concrete ways to address this, such as adopting Mask2Former for SSUL or generating object proposals unsupervised. These suggestions are clear and actionable for the authors, providing them with concrete steps to consider for a fairer comparison.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific comparison being made between the paper and SSUL. They specifically mention 'SSUL uses the offtheshelf saliencymap detector' and 'the paper uses the pretrained Mask2Former to produce the region proposals.' This precise identification of the methods being compared demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about a potential unfairness in the comparison. They then provide reasoning and suggestions for improvement, such as 'Mask2former is additionally trained on COCO and has much larger parameters than the offtheshelf detector' and 'What if SSUL also adopts Mask2Former to detect unseen classes?'. While not a direct citation of external work, the suggestions act as a form of justification and guidance, making the claim 3.", "helpfulness_rationale": "The review point is 5 because it is explicitly pointing out a potential flaw in the experimental setup and provides concrete, actionable suggestions for improvement. The reviewer clearly identifies the issue (unequal comparison due to different region proposal methods) and offers specific ways to address it (using Mask2Former or unsupervised proposal generation). This directly empowers the authors to consider and potentially refine their comparison methodology."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out a potential issue with the evaluation metrics but does not explicitly state what needs to be done or how to implement it. The reviewer mentions 'the metrics' generally and 'a style classifier' without specifying which ones or which classifier. They don't provide concrete steps for the authors to take.", "grounding_specificity_rationale": "The reviewer's comments are general and do not specify which part of the paper they are referring to. They mention 'the metrics' and 'a style classifier' without identifying a specific section, table, figure, or unique element within the paper.", "verifiability_rationale": "The reviewer presents a potential issue with the evaluation metrics but does not make a clear, verifiable claim that requires evidence or justification. They state 'For example, the style accuracy is based on a style classifier...' which is a statement of fact, but not a verifiable claim requiring support. They also say 'the transfer result based on the stylized input may not be easily verified' which is a potential issue but not a verifiable claim.", "helpfulness_rationale": "The reviewer's comment is more of a concern or potential problem with the evaluation metrics rather than a helpful suggestion. They state 'For example, the style accuracy is based on a style classifier, which may be very accurate to capture the styleness of the proposed algorithm.' This highlights a potential limitation but doesn't offer concrete steps for the authors to improve their metrics or address the style classifier's influence. The suggestions are speculative and do not empower the authors to make significant improvements."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The paper argues that the proposed method can take individual's preference into account, but it does not explicitly state how these preferences are generated on an individual level. The reviewer's point is that the paper implies a need for individual preference modeling but fails to provide a concrete mechanism or example. This makes the reviewer's expectation for a specific method unclear and the paper's explanation vague.", "grounding_specificity_rationale": "The reviewer's comment does not identify a specific part of the paper where the individual preference generation is discussed. The comment is a general question about the level of detail provided, without pointing to any specific section, table, figure, or unique aspect of the paper. Therefore, the grounding is weak as the reviewer cannot confidently determine which part of the paper they are referring to.", "verifiability_rationale": "The reviewer's comment identifies a lack of clarity regarding how individual preferences are generated as a weakness in the paper. However, the reviewer does not provide any evidence, examples, or references to support their claim about the missing information. The statement is a statement of a problem, not a claim that can be verified.", "helpfulness_rationale": "The reviewer's comment highlights a gap in the paper by pointing out the lack of detail regarding individual preference generation. While the comment identifies a need for more information, it does not offer any specific suggestions or actionable steps for the authors to take. The reviewer's comment is more of a request for clarification than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of clarity in the meaning of \"1200 frames\" and how the precision and recall values are computed. While the reviewer understands the concepts of precision and recall, the paper does not explicitly explain how these metrics are calculated in the context of the \"1200 frames\" range. This lack of explanation makes it difficult for the authors to understand the significance of the reported values and how they relate to the trajectory length. The reviewer is left to infer the meaning of \"1200 frames\" and the computation of the metrics, which is not ideal for actionable feedback.", "grounding_specificity_rationale": "The reviewer asks for clarification on the meaning of \"1200 frames\" and its relationship to precision, recall, and trajectory length. The paper does not explicitly define what \"1200 frames\" refers to in this context. The reviewer is unable to determine the specific aspect of the paper being addressed by this term. While the reviewer understands the general concept of trajectory length, the paper lacks a clear explanation of how this range is defined and how it relates to the performance metrics. This lack of grounding makes it difficult for the authors to understand the specific issue being discussed.", "verifiability_rationale": "The reviewer raises valid questions about the computation of the precision and recall values and the relationship between trajectory length and performance metrics. The paper does not provide sufficient context or references to support these claims. While the reviewer can infer that precision and recall are being used to evaluate the tracking performance, the paper does not explicitly state how these metrics are calculated in this context. The reviewer is left to assume the standard definitions of precision and recall, which might not be the exact implementation used in the paper. The lack of external references makes it difficult to verify the claims made in the review point.", "helpfulness_rationale": "The reviewer's questions highlight a significant gap in the explanation of the method. The paper does not provide sufficient details on how the precision and recall values are computed and how trajectory length affects the results. This lack of clarity makes it difficult for the authors to understand the significance of the reported results and how they can be used to improve their own work. The reviewer is left to infer the meaning of \"1200 frames\" and the relationship between trajectory length and performance metrics, which hinders their ability to build upon or reproduce the findings."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their desire for justification regarding the hyperparameter choices, indicating an action to be taken. The request for a costeffectiveness comparison is also a clear action. Therefore, the action is explicitly stated.", "grounding_specificity_rationale": "The reviewer questions the arbitrariness of the hyperparameter choices, implying a lack of explicit grounding in the paper regarding *why* these specific numbers were chosen. While the * grounds* for considering costeffectiveness are present, the * justification* for the specific numbers isn't explicitly stated by the authors in the paper itself. The specificity of the * grounds* is also lacking.", "verifiability_rationale": "The reviewer makes a claim that the design decisions seem arbitrary. This claim requires verification. The reviewer doesn't provide any external references or logical reasoning to support this claim within the review point itself. Therefore, the claim is not wellsupported.", "helpfulness_rationale": "The review point itself is a request for more information and analysis. While it doesn't immediately provide actionable feedback, the reviewer explicitly states their desired actions (justification and costeffectiveness comparison), indicating a desire for improvement. Therefore, it is 3, though not immediately so."}
{"actionability_label": "3", "grounding_specificity_label": "3: Partially Grounded and Not Specific", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The reviewer's point is partially actionable. They identify a potential issue with the model's complexity, but they don't explicitly state how the model is complex or where the complexity lies. The criticism is general, focusing on the 'complex approach' without specifying the components contributing to this complexity. While the reviewer mentions the Transformer's ability to capture global dependencies, they don't explain how the proposed model leverages this capability in a way that is more complex than necessary or how it differs from existing sequence models in a significant way.", "grounding_specificity_rationale": "The reviewer's point is partially grounded and not specific. They identify the motivation as capturing global dependencies and the model as being based on Transformers. This grounds the criticism to a specific aspect of the model. However, they don't specify *which* part of the model is being criticized or *how* the Transformer's capabilities are being utilized. The criticism is general, focusing on the 'complex approach' without pinpointing the exact problematic component or mechanism.", "verifiability_rationale": "The reviewer's point is 2. They make a claim about the 'complex approach' of the article and the 'lack of clarity in the motivation'. The claim about the Transformer's ability to capture global dependencies is generally accepted knowledge within the NLP community and doesn't require external references to be understood. However, the 'lack of clarity in the motivation' is subjective and depends on the specific details of the article. Without more context, it's difficult to definitively assess the verifiability of this claim.", "helpfulness_rationale": "The reviewer's point is not helpful. They express a negative opinion about the model's complexity and lack of clarity in the motivation. They don't offer any concrete suggestions for improvement or alternative approaches. Their feedback is primarily a critique of the current approach without providing actionable insights for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the desired improvement (providing videos) and points out a missing element (implementation details). The phrase 'not clear to me what policy gradient approach is used' directly identifies an actionable area for the authors to seek clarification. The suggestions are direct and do not require inference.", "grounding_specificity_rationale": "The review point explicitly mentions 'implementation details' and 'policy gradient approach'. These are specific parts of the paper or methodology being discussed, allowing the authors to directly identify the missing information. The mention of 'policy gradient approach' even specifies the exact area of concern.", "verifiability_rationale": "The review point states that the 'policy gradient approach is not clear'. This is a claim that can be verified by checking the main paper for a clear and detailed explanation of the chosen policy gradient method. While it doesn't provide a specific example, the lack of clarity is verifiable.", "helpfulness_rationale": "The review point clearly identifies a weakness in the paper (lack of clarity on implementation details) and provides a concrete suggestion for improvement (videos). This directly benefits the authors in understanding and reproducing the work."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer raises a valid point about the approximation in Equation 11, suggesting it might be an implicit action. However, the reviewer does not explicitly state how to implement or improve this approximation. The reviewer also points out a potential issue with the experimental setup in Figure 1, which could be considered an implicit action to improve the experiments. The lack of explicit instructions on how to address these points makes the actionability borderline.", "grounding_specificity_rationale": "The reviewer refers to Equation 11 and Figure 1, which can be considered a specific part of the paper. However, the reviewer does not explicitly state what is wrong with the approximation in Equation 11 or the experimental setup in Figure 1. The criticism is more general, pointing out potential limitations. Therefore, the grounding is weakly specified.", "verifiability_rationale": "The reviewer makes claims about the approximation in Equation 11 and the experimental setup in Figure 1 without providing any supporting evidence or justification. The claims are based on the reviewer's interpretation of the presented information. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer provides specific areas for improvement, such as considering the impact of layer order in the approximation and improving the experimental setup in Figure 1. However, the reviewer does not provide concrete suggestions on how the authors should address these issues. The criticism is more of a critique than a direct call for action. Therefore, the helpfulness is low."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review states \"addressing offlinetoonline learning adaption appears to be incremental\" and \"implementing online finetuning on the top of existing benchmarks is feasible.\" While it identifies a potential issue and a possible solution, it doesn't explicitly state what the authors should do. It presents the information but doesn't prompt the authors to take a specific action.", "grounding_specificity_rationale": "The review mentions \"offlinetoonline learning adaption\" and \"offline RL benchmarks\" generally. It doesn't pinpoint a specific section, table, figure, or unique aspect of the paper. The mention of \"existing benchmarks\" is broad. There's no clear indication of a specific part of the paper that needs improvement.", "verifiability_rationale": "The review makes claims like \"addressing offlinetoonline learning adaption appears to be incremental\" and \"implementing online finetuning on the top of existing benchmarks is feasible.\" However, these claims are presented as observations or suggestions without any specific evidence, logical reasoning, or references to external sources. There's no citation to support these claims.", "helpfulness_rationale": "The review points out a potential issue with the scope of offlinetoonline learning adaption and suggests a possible solution (online finetuning). However, it doesn't delve into the *reasons* why it's incremental or *why* online finetuning is feasible. It offers a highlevel suggestion without much depth or specific guidance. The language is somewhat informal (\"appears to be incremental\")."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a discrepancy in the results presented in Table 6 compared to Table 2. They highlight that a model (AT) finetuned on emotion classification data performs worse than another model (BERTsynth) despite the finetuning. This suggests that emotionawareness might not be beneficial. While the reviewer doesn't explicitly state the action to take, the implication is clear: authors should investigate why emotionaware models perform worse in this specific context. The reviewer identifies a clear issue that needs further investigation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 6' and 'Table 2' in the context of comparing model performance. They also refer to specific models like 'AT', 'BERTsynth', and 'GAS'. This demonstrates strong grounding specificity as the reviewer accurately identifies the relevant parts of the paper and the specific elements being discussed. The reviewer is pointing to a specific result and drawing a conclusion based on it.", "verifiability_rationale": "The reviewer draws a conclusion based on the F1 scores presented in the tables. They state that despite finetuning on emotion classification data, a model (AT) achieves a lower F1 score than BERTsynth. This conclusion is verifiable based on the numerical data provided in the tables. The reviewer provides the evidence (the F1 scores) to support their claim. While they don't explicitly cite external references, the comparison of the numbers within the provided text makes the conclusion verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable point for the authors. They highlight a discrepancy in the results and suggest that emotionawareness might not be useful in this specific context. This directly addresses a potential issue the authors might be facing and guides them towards further investigation. The reviewer's point is directly connected to the authors' own results and offers a clear takeaway. The reviewer is providing a valuable insight based on their own analysis of the data."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and Partially Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment suggests conducting more experiments with specific models (ViT) and noise models. While it implies actions, the specific steps or criteria for these actions are not explicitly stated. The suggestion to include multiplicative distortions is also implied but not detailed.", "grounding_specificity_rationale": "The comment mentions 'various models, such as Vision Transformers (ViT)' and 'more complex input noise models, such as those involving multiplicative distortions'. While it points towards specific areas, the exact section or unique aspect being addressed is not definitively identified. The mention of ViT is specific, but 'various models' makes it less grounded. The noise suggestion is partially specific but lacks detail.", "verifiability_rationale": "The comment claims that conducting more experiments with ViT will 'advantageously' address the research question and that including results under 'more complex input noise models' will 'provide a more comprehensive evaluation'. These are claims that are generally true but lack specific justification or references to external works. The reasoning is present but not rigorously supported.", "helpfulness_rationale": "The comment provides suggestions for improvement, specifically mentioning testing with ViT and evaluating under complex noise. While these suggestions are relevant, they lack the necessary detail to be truly actionable for the authors. The authors would need more guidance on *which* models to use and *how* to implement the noise. The suggestions are general and could be interpreted in multiple ways."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the discrepancy between the number of annotators mentioned in the paper (two) and the number implied by the author responses (four). The phrase 'That number should be four' clearly indicates the intended number of annotators. The reviewer provides a direct and specific suggestion to correct this inconsistency.", "grounding_specificity_rationale": "The reviewer mentions 'D.2 appendix' in their review point. This is a specific reference to a location in the paper. However, the reviewer does not explicitly state the number of annotators *in* the appendix. They imply the number based on the context of the author responses. Therefore, while the location is specific, the *content* of the appendix regarding the number of annotators is not directly mentioned in the review point.", "verifiability_rationale": "The review point does not contain a claim in the sense of suggesting a change or offering an opinion. The reviewer is pointing out a factual inconsistency. Therefore, there is X to verify.", "helpfulness_rationale": "The reviewer's point is helpful because it clarifies a potential misunderstanding or inconsistency in the paper. By pointing out the discrepancy and suggesting the number should be four, the reviewer provides a concrete piece of information that the authors can use to better understand the evaluation process and potentially correct any errors. This is a specific and actionable piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a potential improvement but doesn't specify *how* to achieve it. It lacks explicit and concrete instructions for improvement. While it identifies a weakness (lack of clear motivation), it doesn't provide actionable steps on how to address it.", "grounding_specificity_rationale": "The review point explicitly mentions \"encoder and decoder structure\" and \"proposed approach.\" This clearly identifies the specific part of the paper being addressed. It also suggests improving the understanding of these components, which is a specific goal. The authors can easily identify the section being referred to.", "verifiability_rationale": "The review point is a statement of opinion, not a claim requiring verification. There is no explicit assertion of something being wrong or needing improvement that needs to be supported by evidence.", "helpfulness_rationale": "The review point identifies a valid weakness (lack of clear motivation for the encoder/decoder) and suggests a concrete improvement (adding better motivation). While the review point itself isn't actionable, it points to a clear area for improvement for the authors. It's likely to be helpful for them to understand this weakness and consider the suggested improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The reviewer provides clear, actionable feedback. They explicitly state the lack of novelty, the 'plug and play' nature of the attacks, the absence of blackbox evaluation, and the limitation to untargeted attacks. These are all concrete suggestions for improvement that the authors can directly implement. The reviewer clearly identifies what is missing and *why* it is important for the authors to consider these aspects.", "grounding_specificity_rationale": "The reviewer's suggestions, while not explicitly stating the lack of grounding, imply a need for more specific guidance. They suggest comparing against existing methods and evaluating in more realistic settings (blackbox). While the *motivation* behind these suggestions isn't explicitly stated in the review point, the *actions* they imply are clear and actionable. The reviewer points towards what *should* be included, even if the *why* isn't fully elaborated.", "verifiability_rationale": "The reviewer's points are generally wellsupported by common knowledge in the field. For example, the statement about JS divergence being wellestablished is a logical reasoning point. However, the *lack* of blackbox evaluation and the suggestion to include targeted attacks could be seen as areas needing further clarification or justification. The reviewer's suggestions, while grounded, could benefit from more explicit references or examples to make them 5.", "helpfulness_rationale": "The reviewer's overall assessment is negative, highlighting significant shortcomings in the paper. They clearly articulate what is missing and why it is important for the authors. The suggestions for improvement are concrete and impactful. The reviewer's direct criticism of the limited novelty and the lack of comprehensive evaluation makes the paper highly detrimental to the authors if they don't address these points."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the weakness ('Results for CIFAR10 do not look impressive') and suggests a concrete improvement ('We would also like to see results for CIFAR100'). The action is clear: improve the CIFAR10 results and include CIFAR100 experiments.", "grounding_specificity_rationale": "The comment explicitly mentions 'CIFAR10 results' and 'CIFAR100'. This clearly identifies the specific part of the paper being addressed, making it fully grounded. It also specifies what is being criticized ('not look impressive') and what improvement is suggested ('see results for CIFAR100').", "verifiability_rationale": "The comment makes a claim ('Results for CIFAR10 do not look impressive') and points out a lack of direct comparison ('a direct comparison is absolutely mandatory'). While the claim itself is subjective and lacks direct evidence within the review point, the *lack* of comparison is a verifiable factual statement. The suggestion to 'see results for CIFAR100' implies a need for further verification through experimentation.", "helpfulness_rationale": "The comment directly identifies a weakness in the CIFAR10 results and provides a clear suggestion for improvement by including results on CIFAR100. This actionable feedback is directly helpful for the authors to understand the limitations of their model and guide further experimentation."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points out a *lack* of demonstration, not a direct request for action. While it implies the need for experiments, it doesn't explicitly say \"You need to show this with experiments\" or anything directly actionable like \"Add experiments on hierarchical datasets.\" The reviewer states a known property of hyperbolic space (implicit) but doesn't explicitly say *how* the experiments should be designed or what specific experiments are needed to demonstrate it. The reviewer identifies a *potential* issue (lack of demonstration) but is vague on how to apply the implied action.", "grounding_specificity_rationale": "The reviewer mentions \"hyperbolic space\" as the key concept. They can accurately pinpoint the section, table, figure, or unique aspect being addressed. However, they don't specify *which* experiment or *what specific part* of the hierarchical dataset experiment is lacking demonstration. The comment identifies a potential issue but doesn't pinpoint the exact area within the paper that needs improvement.", "verifiability_rationale": "The reviewer makes a claim about the experiments lacking demonstration and provides a general justification (\"It is known that hyperbolic space is well suited for hierarchical dataset\"). This justification, while not a detailed reference, provides a basis for the claim. The reviewer identifies a weakness in the experimental validation but doesn't provide specific examples or references to support the claim beyond the general knowledge.", "helpfulness_rationale": "The review highlights a relevant point that could guide the authors' experimental design or analysis. It's not a direct criticism of a flaw but a suggestion for improvement. The authors would likely need to either add experiments demonstrating the suitability of hyperbolic space or clarify why it's not relevant to their current work. This is a valuable piece of feedback that could help them refine their approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a question about the strengths of MixBoost and provides three potential reasons. This constitutes an explicit action, as the reviewer is directly addressing a point and asking for clarification. The action is also concrete, as the reviewer is specifying the potential reasons for the strengths.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'MixBoost' and asks about its 'main strength' and three specific potential reasons ('computational savings', 'generalization performances', 'use of Random Fourier Features'). This demonstrates strong grounding as the reviewer accurately identifies the paper and the specific aspects being discussed. The reviewer is also asking for clarification on the 'strengths', which is a specific attribute.", "verifiability_rationale": "The reviewer is asking a question, not making a claim that needs verification. The purpose is to seek clarification, not to assert something as true. Therefore, it does not fall under the 'Verifiability' aspect.", "helpfulness_rationale": "The reviewer is asking for clarification on the strengths of a method. This is a valid and potentially helpful request as it seeks to understand a core aspect of the work. While not a direct critique or suggestion, it directly addresses a relevant question about the paper. Therefore, it is 3."}
{"actionability_label": "Partially Actionable (3)", "grounding_specificity_label": "5 (5)", "verifiability_label": "3 (3)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer explicitly states an action: 'Moreover, the 'smaller training set' (l. 245) could be avoided by training the network with optimal parameters on the complete train+val.' This provides a clear direction for improvement. However, the reviewer does not explicitly state *how* to implement this action, such as identifying the optimal parameters or explaining why the complete train+val would be better. The action is implied but not fully detailed.", "grounding_specificity_rationale": "The reviewer refers to 'Review Point 243' and then mentions 'smaller training set' and 'train+val'. This demonstrates a clear attempt to identify the specific part of the paper being addressed. The references are explicit and point to specific elements of the paper.", "verifiability_rationale": "The reviewer makes a claim: '243 is rather surprising: \"Unlike previous works which use the test set for hyperparameter tuning\"'. This is a statement of opinion. The reviewer then provides a suggestion: 'Moreover, the 'smaller training set\" (l. 245) could be avoided by training the network with optimal parameters on the complete train+val.' This suggestion offers a concrete alternative and implies that the current approach might be problematic. While the suggestion is specific, it doesn't provide external references or logical reasoning to support why the complete train+val would be better. The claim is presented with a suggestion but lacks explicit verification.", "helpfulness_rationale": "The reviewer provides a suggestion for improvement: 'Moreover, the 'smaller training set\" (l. 245) could be avoided by training the network with optimal parameters on the complete train+val.' This is a direct suggestion for authors to make their paper better. While the suggestion is specific, it could be improved by providing more context or justification for why this change would be beneficial. However, it is a clear and actionable suggestion that directly addresses a potential issue."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a problem ('presentation is not good') but lacks a specific, actionable step. It's unclear what the reviewer expects the author to do. While it prompts the author to clarify, it doesn't directly guide them on how to make the presentation better.", "grounding_specificity_rationale": "The comment doesn't specify which part of the paper is affected by the 'bad presentation.' It doesn't mention any specific section, table, figure, or element of the presentation. The phrase 'just name a few' suggests the reviewer might be thinking of a few common presentation issues, but the comment itself doesn't identify the specific issue.", "verifiability_rationale": "The comment expresses an opinion ('The presentation is not good') and suggests the author should 'name a few' specific issues. This fits the definition of a claim. However, the comment itself doesn't explain *why* the presentation is bad or *what* those 'a few' issues might be. It lacks specific justification or references to support its assertion.", "helpfulness_rationale": "The comment identifies a weakness ('presentation is not good') but doesn't provide concrete steps or suggestions for improvement. It's vague and doesn't offer actionable advice. While it prompts the author to clarify, it doesn't directly guide them on how to make the presentation better."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly mentions a missing citation, making it an explicit statement. However, it lacks specific details on how the missing citation should be implemented or what impact it would have, making it only 2.", "grounding_specificity_rationale": "The reviewer mentions 'related work' generally, providing some grounding by indicating the area of concern. However, they do not specify a particular section, table, figure, or unique element within the paper that is affected by the missing citation, resulting in weak grounding. Additionally, the specificity of the issue is low as the reviewer doesn't pinpoint the exact paper or contribution within Rieck et al.'s work.", "verifiability_rationale": "The review point clearly states a claim ('you miss the work by Rieck et al. 2') but provides no supporting evidence, reasoning, or references to back it up. Therefore, it is 1.", "helpfulness_rationale": "The review point identifies a valid weakness (a missing citation) but does not offer concrete, actionable suggestions for the authors to improve their submission. It simply points out a deficiency without guiding specific changes, making it less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of only having upper bounds on the pseudoregret and suggests a concrete action: adding a remark about the implications for the exploration parameter gamma. The reviewer also infers that gamma=0 might be optimal based on this limitation, which is a clear indication of an actionable suggestion. The action of remarking on the implications for gamma is directly related to the identified weakness and provides a clear path for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'Alg 1' and 'Thm 3.1', which indicates a level of grounding as they are specific parts of the paper. While not explicitly naming a section or table, the reference to specific elements of the paper suggests an understanding of where the discussion is taking place. The reviewer also specifies the *what* (lack of highprobability bounds) and the *why* (gamma=0 seems optimal), indicating a degree of specificity in identifying the issue.", "verifiability_rationale": "The reviewer presents a claim: 'Since only upperbounds on the pseudoregret are provided, the exploration parameter gamma seems to be useless, isn't it?' This is a clear statement of opinion or judgment. The reviewer then provides a logical inference: 'The choice gamma=0 seems to be optimal.' This inference, while not explicitly supported by external references, is a logical deduction based on the information provided in the paper (lack of highprobability bounds). The reviewer is pointing out a consequence of the presented information, making the claim 3.", "helpfulness_rationale": "The reviewer's comment is 5 as it identifies a specific limitation in the paper's analysis (lack of highprobability bounds) and provides a concrete suggestion for improvement: adding a remark about the implications for the exploration parameter gamma. The reviewer's analysis is directly relevant to the paper's content and offers actionable guidance for the authors. The suggestion to add a remark is a clear and constructive way to address the identified weakness."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that LCA relaxation was referenced but never directly defined, indicating an implicit action. While the request for a definition is specific, the action itself (defining it) is not yet performed.", "grounding_specificity_rationale": "The reviewer clearly mentions 'line 150', indicating full grounding. The request to 'add a restatement of the definition from Wang et. al' further enhances the specificity.", "verifiability_rationale": "The reviewer's comment is a suggestion to define LCA relaxation, not a claim requiring verification. While it implies potential confusion, there's no explicit statement of a claim or supporting evidence provided in the review point itself.", "helpfulness_rationale": "The reviewer's comment is a clear and actionable suggestion for the authors, directly addressing a potential point of confusion. It guides them to the necessary information, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The reviewer identifies a lack of information regarding validation and test splits. This is an explicit statement of a missing element. However, the reviewer does not specify *what* information is missing or *how* it should be provided, making the action left open and vague.", "grounding_specificity_rationale": "The reviewer mentions 'validation and test splits' and their 'influence on model training'. While they identify a specific area of the paper (related to dataset description and model training), they do not explicitly name the section, table, figure, or unique aspect where this information is located. Furthermore, they do not specify *what* needs to be addressed in this part.", "verifiability_rationale": "The reviewer states 'the dataset is thoroughly described' and 'more information on how validation and test splits influence model training could strengthen reproducibility'. The statement about the thorough description could be considered a claim, although it's subjective. The second part, 'more information...', is a suggestion. However, the reviewer logically argues for the importance of this information, implying its existence without providing specific references or examples.", "helpfulness_rationale": "The reviewer points out a potential area for improvement by highlighting the lack of information on validation and test splits. However, they do not provide specific, actionable steps for the author to take or implement. The suggestion is general and lacks concrete guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests alternative regularization techniques (L2 regularization, data augmentation, adding noise) and the combination of ZeroLiers with other techniques. This clearly indicates an implicit action: the authors should consider these other regularization methods and explore their potential benefits. While not explicitly stated as 'do this,' the suggestions are clear and actionable.", "grounding_specificity_rationale": "The review point explicitly names several relevant regularization techniques (L2 regularization, data augmentation, adding noise) and the concept of combining regularization techniques (ZeroLiers with others). This clearly grounds the comment in the paper's content and identifies specific areas for improvement. It's not just a general comment; it pinpoints specific omissions and suggests concrete alternatives.", "verifiability_rationale": "The review point is not making a claim that *can* be verified. It's a suggestion for the authors to expand their discussion. There's no assertion of truth or falsehood. It's a request for more information or analysis.", "helpfulness_rationale": "The review point is very helpful. It directly addresses a practical limitation of the paper's scope (narrow focus on dropout). It provides concrete examples of alternative regularization techniques and suggests exploring combinations. This is exactly what researchers need \u2013 guidance on how to improve their work. It empowers the authors to take the next step in their investigation by considering a broader range of regularization strategies."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer poses a question about generalizing Assumption A to the function approximation setting. While they identify a potential area for improvement, they do not explicitly state how this generalization should be done or provide any concrete steps. The action is implied but not directly stated, making it somewhat implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'function approximation setting' and 'consistency' as areas for discussion. These are specific terms and concepts within the context of the paper, indicating that the reviewer can confidently identify the relevant part of the paper and the issue being addressed. This demonstrates full grounding. Furthermore, the reviewer specifies 'consistency' as the area of discussion, adding to the specificity.", "verifiability_rationale": "The reviewer suggests that the assumption could be generalized to the function approximation setting and that discussing consistency would be beneficial. This statement presents a suggestion as a claim, but the reviewer does not provide any evidence, reasoning, or references to support this suggestion. The claim is presented as a suggestion for improvement rather than a verifiable statement.", "helpfulness_rationale": "The reviewer's comment prompts the authors to consider generalizing Assumption A to a different setting and to discuss the consistency of this generalization. This is a relevant point that encourages the authors to think beyond the tabular setting and consider the broader implications of their assumption. While it doesn't provide a concrete solution, it identifies a potential area for further discussion and exploration, which can be helpful for improving the draft."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "UnderSpecific", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests making Table 1 one column wide and Figures 3, 5, and 6 two column wide. While these are explicit suggestions, the reviewer does not provide specific instructions on how to achieve these formatting changes. The action is implied rather than explicitly stated with implementation details.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 1' and 'figures 3, 5, and 6', indicating a clear identification of the specific parts of the paper being addressed. The grounding is strong as the sections are named.", "verifiability_rationale": "The reviewer states that the paper was 'not very easy to understand during first read' and suggests 'straightening up the content'. While the reviewer identifies a problem, the suggestion 'straightening up the content' is vague and lacks specific examples or references to external work. The verifiability is limited as there's no strong justification for the suggestions beyond general good practices.", "helpfulness_rationale": "The reviewer points out issues with formatting and clarity and suggests improvements like making tables and figures wider and restructuring the content. These suggestions are directly relevant to potential problems authors might face and offer a clear direction for improvement. While the specific implementation details are missing, the suggestions are actionable and address concrete issues."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the proposed change (\"repeat TextDPO baseline...with the generated images...as images for additional imagequestionanswer triplets...\") and the alternative hypothesis (\"My suspicion is that training with perturbed images at all is what is providing the additional performance benefit...\"), making it both explicit and concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"the generated images\" and the \"TextDPO baseline,\" clearly identifying the parts of the paper being addressed. However, the reviewer mentions \"blurring and pixelation perturbations\" without specifying the exact types or number, making the grounding somewhat weak as the scope of perturbations is not precisely defined.", "verifiability_rationale": "The review point contains a claim: \"My suspicion is that training with perturbed images at all is what is providing the additional performance benefit for your method, rather than the specific DPO objective you\u2019re using.\". The support for this claim is a hypothesis ('suspicion\") without concrete evidence or references.", "helpfulness_rationale": "The review point is 5 as it identifies a potential issue with the proposed method (that the performance gain might be due to data augmentation rather than the specific DPO objective) and suggests an alternative interpretation. This is valuable for understanding the method's effectiveness and guiding future research."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state what the authors should do or how they should proceed. It points out a lack of information but does not provide actionable steps. The statement 'A final assumption, is that there is no difference in expertise between Alice and Bob' is a statement of expectation, not a critique or suggestion for improvement that would be actionable.", "grounding_specificity_rationale": "The review point mentions Alice and Bob and the assumption of equal expertise. However, it does not explicitly identify the specific part of the paper where this assumption is made. The grounding is weak because the authors cannot confidently determine which part the comment addresses. The comment specifies what needs to be addressed (the assumption about expertise) but does not specify where in the paper this assumption is located.", "verifiability_rationale": "The claim in the review point, 'The human is expected to be able to competent finish the task and for Bob to linearly cut down the time taken to perform this task,' is a generalization and a statement of expectation, not a claim that can be verified with evidence or logical reasoning. There are no specific examples or references provided to support this claim. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point is a statement of expectation and a generalization about human performance in the context of the paper. It does not provide specific, actionable feedback or insights that would empower the authors to improve their draft. It does not identify any weaknesses or suggest any concrete changes. The comment is not helpful because it lacks specific and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitations of the mitigation strategy and the implications for generalizability. This is an explicit action. However, the reviewer doesn't offer specific, actionable suggestions for alternative mitigation strategies or how to adapt the framework. The suggestion is broad.", "grounding_specificity_rationale": "The reviewer refers to \"mitigation strategies,\" \"data sanitization,\" \"dataset specific,\" \"generally,\" \"LLMs,\" and \"datasets.\" While they mention these terms, they don't pinpoint a specific section, table, or figure in the paper. The reference is more conceptual. The reviewer explains *why* the mitigation strategy is problematic (datasetspecificity) and *why* this limits generalizability. However, they don't provide specific examples of where these issues arise in the paper's content.", "verifiability_rationale": "The reviewer makes a clear claim: \"The mitigation strategies \u2013 like sanitizing the data \u2013 would be very data set specific as well and might not be applicable more generally.\" This is a subjective opinion. The reviewer doesn't provide any evidence or justification for their claim about the paper's content or methodology. They are speculating about the limitations of the framework.", "helpfulness_rationale": "The reviewer's point is relevant for researchers working on data leakage and mitigation strategies. It highlights a practical limitation of the framework. While the reviewer doesn't offer solutions, they raise a valid concern that could influence how others use or build upon the framework. The critique itself is valuable and points to a practical limitation."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states they will provide a list of questions, implying they have identified weaknesses. However, they do not explicitly state which specific aspect of the paper is unclear. The promise of a list of questions suggests a future action rather than immediate actionable feedback. Therefore, while the reviewer indicates a problem, the lack of a concrete, actionable suggestion makes it not fully actionable at this point.", "grounding_specificity_rationale": "The reviewer mentions 'some aspects' of the paper being unclear but does not specify which part of the paper or unique element is affected. They do not provide any specific details about the nature of the unclearness. This lack of specificity means the comment is 1 at all.", "verifiability_rationale": "The reviewer states an 'impression' that the weaknesses could be fixed. This is a subjective statement without any supporting evidence or justification. There are no specific examples, references, or logical reasoning provided to back up this claim. Therefore, the claim is not supported by any verifiable information.", "helpfulness_rationale": "The reviewer indicates they have the 'impressions' that the weaknesses could be fixed. This suggests they have identified some weaknesses in their own perception. However, the review point itself does not provide any specific, actionable suggestions or examples to address these weaknesses. The reviewer promises a list of questions, which is the only concrete information provided. Without these specific suggestions, the review point is not helpful in improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question ('Are...related?') and requesting information ('what task...'). While not explicitly stating an action to be taken, the question directly points to a potential area of confusion or missing information for the authors. The request for the task is also a clear indication of a need for clarification. Therefore, it is considered **3** as the reviewer is directly referencing specific elements (audio signals, task conditions in Figure 2) and asking about their relationship.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'natural and synthetic audio signals' and 'task conditions referenced in Figure 2'. This direct mention indicates a clear grounding of the question in specific parts of the paper. However, the reviewer does not specify *which* aspects of the audio or task are being considered, making the grounding somewhat specific but not fully detailed. Therefore, it is considered **3**.", "verifiability_rationale": "The reviewer is asking a question ('Are...') rather than making a claim that needs verification. There is no assertion of something being true or false. Therefore, it does not fit into the 'Verifiability' category and is classified as **X (X)**.", "helpfulness_rationale": "The reviewer is asking a question about the relationship between specific elements of the experimental setup (audio signals, task conditions in Figure 2) and the task being performed. This directly points to potential areas of confusion or missing information for the authors. While it doesn't explicitly state what needs to be done, it highlights a crucial point that needs clarification. Therefore, it is considered **3** as it identifies a relevant area for improvement in the authors' understanding."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer identifies the problems (memory to register and personalize to user characterstics) but does not provide any suggestions on how to address them. The focus is on identifying the issues, not offering solutions.", "grounding_specificity_rationale": "The reviewer mentions 'other problems in open domain dialogue' and lists examples like 'memory to register and personalize to user characterstics.' These are general categories of problems within the field, not specific sections, tables, figures, or unique aspects of the paper.", "verifiability_rationale": "The reviewer makes a claim that the paper 'did not tackle other problems in open domain dialogue' and lists specific problems. However, the review does not provide any evidence or justification to support this claim.", "helpfulness_rationale": "The reviewer identifies areas for improvement but does not offer any concrete steps on how to achieve that. The suggestions are at a high level and don't provide specific guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'Authors have not given any statistical distribution on paper venues' and 'My intuition is that it's the arxiv papers that showcase this bias.' These are direct statements that identify a missing piece of information and suggest a specific next step (looking at venue distributions). The reviewer clearly indicates an action to be taken.", "grounding_specificity_rationale": "The review point mentions specific venues (ACL, EMNLP, Arxiv) when discussing the lack of statistical distribution. However, the core issue of the lack of distribution itself doesn't explicitly point to a *specific part* of the paper being addressed. The grounding is more focused on the *characteristics* of Arxiv papers rather than a specific location within the paper.", "verifiability_rationale": "The review point contains a claim: 'My intuition is that it's the arxiv papers that showcase this bias.' This claim is not explicitly supported by logical reasoning, common knowledge, or external references within the review point itself. The reviewer presents an opinion without providing evidence.", "helpfulness_rationale": "The review point clearly criticizes the lack of statistical distribution of papers across venues. It also suggests looking at venue distributions as a potential improvement. This provides a clear critique and a constructive suggestion for the authors, making it helpful in identifying areas for improvement."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "Not Verifiable", "helpfulness_label": "None", "actionability_rationale": "The review points out a suggestion for how to rearrange the paper's content. This suggests a potential action the authors could take. However, it's a general suggestion about the relative importance of sections, not a specific instruction on what to change in a specific part. The suggestion is explicit in stating the intention to shift focus, but implicit about the specific actions. It's also vague about the degree of rearrangement.", "grounding_specificity_rationale": "The reviewer doesn't explicitly state which parts of the paper they are referring to. They are making a general comment about the structure and content of the paper, specifically the focus on the proposed problem and framework versus the applications. The reviewer cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part \u2013 the balance between problem and application focus.", "verifiability_rationale": "The reviewer makes a claim: 'The author should probably focus more on the proposed problem and framework, instead of spending much space on the applications.' This is a statement of opinion. While the suggestion is presented as constructive feedback, there is no explicit logical reasoning, common knowledge, or external references provided to support the claim that focusing more on the problem and framework will improve the paper. The suggestion is a recommendation, not a definitive statement of what is wrong with the applications section or what needs to be improved in the problem formulation section.", "helpfulness_rationale": "The review point identifies a potential area for improvement by suggesting a shift in focus. It provides a general direction for restructuring the paper. However, it lacks specific details on how to achieve this balance. It's a suggestion rather than a prescriptive solution. While it offers a direction for the authors to consider, it doesn't provide concrete steps on what to do in the applications or problem sections."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states the reviewer's assessment of the paper's quality ('6  marginally above acceptance threshold'), indicating an awareness of the work's standing. However, it does not specify *what* aspects of the paper or the authors' work are being addressed. The phrase 'adequately addressed' is vague and lacks concrete details on how the limitations and societal impacts have been handled.", "grounding_specificity_rationale": "The comment does not refer to a specific part of the paper or the authors' work. It is a general statement about the overall quality and impact. There is no mention of sections, tables, figures, or unique elements of the paper being discussed.", "verifiability_rationale": "The comment contains a claim: 'The authors have adequately addressed the limitations and potential negative societal impact of their work.' However, it does not provide any evidence, reasoning, or references to support this claim. There are no logical arguments, citations, or specific examples given to back up the reviewer's judgment.", "helpfulness_rationale": "The review point is a declarative statement of the reviewer's opinion about the paper's quality and the authors' handling of its limitations. While it provides some information, it does not directly prompt the authors to improve specific aspects of their work. There are no explicit calls for more details, specific feedback, or actionable steps from the reviewer."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out a potential limitation of the dataset but does not specify any concrete actions the authors should take to address it.", "grounding_specificity_rationale": "The review refers to 'this dataset' and 'natural language is generated by patterns' without specifying a particular section, table, figure, or unique element of the paper being reviewed.", "verifiability_rationale": "The review makes a claim about the paper's potential limited impact but does not provide any specific examples, citations, or evidence to support this claim.", "helpfulness_rationale": "The review identifies a potential limitation of the dataset but does not offer specific suggestions for improvement or actionable steps for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly identifies a missing discussion of limitations and suggests a specific area for improvement (discussing limitations of MLE). This is a clear and actionable point for the authors.", "grounding_specificity_rationale": "The reviewer provides very specific references (masures 242 and competing measures) to support their claim about the lack of discussion on limitations. This demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the lack of discussion on the limitations of the proposed measure and the absence of experimental validation comparing it to other measures. This claim can be verified by examining the paper's content and methodology. The reasoning provided by the reviewer is also verifiable.", "helpfulness_rationale": "The reviewer's comment directly points out weaknesses in the paper's presentation (lack of discussion on MLE limitations) and methodology (lack of experimental validation against other measures). This is a helpful critique for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the 'lack of the results of finetuned opensource LLMs' and suggests 'consider adding this information'. This indicates an explicit action being taken. However, the comment does not specify *how* to add this information, making the action somewhat vague. Therefore, the comment is partially actionable.", "grounding_specificity_rationale": "The comment refers to 'finetuned opensource LLMs' and 'domain specific benchmark', which are specific terms related to the topic. While it doesn't point to a specific section or table, it clearly identifies the area where the missing information is relevant. This indicates some level of grounding. However, the comment doesn't specify *exactly* which finetuned models or *where* in the paper the results should be discussed, making the grounding somewhat underspecific. Therefore, the grounding is partially specific.", "verifiability_rationale": "The comment states that 'the results of finetuned opensource LLMs is quiet important to a domain specific benchmark'. This is a claim that something is important. However, the comment does not provide any logical reasoning, common knowledge, or external references to support this claim. It simply states the importance without justification. Therefore, the claim is not 5.", "helpfulness_rationale": "The comment identifies a 'lack of the results of finetuned opensource LLMs which is quiet important to a domain specific benchmark'. This points out a clear weakness in the draft \u2013 the absence of this crucial information. While it highlights a problem, it doesn't offer a concrete solution or actionable steps on how to address this weakness. Therefore, the comment is 3 in identifying a problem but lacks concrete suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for details about the regression model's training process, specifically the input and output, and how the parameter space of ridge regression differs between models with varying feature sizes. It also asks whether model performance is affected by the number of parameters. All these questions are directly and clearly stated, making it easy for the authors to understand what information is being requested.", "grounding_specificity_rationale": "While the review point doesn't explicitly name a specific section, table, figure, or unique aspect of the paper, it's asking for information about the *training process* of a regression model. This is a general request about how the model is built and trained. It doesn't pinpoint a specific element of the paper being addressed. Therefore, it's not fully grounded.", "verifiability_rationale": "The review point itself doesn't make a claim. It's a request for information. However, the *expected* answer would be a description of the training process, the differences in parameter space based on feature size, and an analysis of how model performance is affected by the number of parameters. This expected answer would be considered **5** because it's a description of a process and differences based on a defined factor (feature size).", "helpfulness_rationale": "The review point asks for crucial information about the model training process, which is directly relevant to understanding and potentially improving the model. The questions about the impact of parameters are also valuable. While it's not identifying a *weakness* in the authors' work, it's a request for information that could guide their implementation and experimentation. Therefore, it's **3** as it points the authors towards areas they might need to investigate further."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a potential error in notation (Eq 6) and suggests a specific correction (replacing the cross product symbol with a multiplication symbol). This constitutes an explicit action. Furthermore, the reviewer directly references 'eq 6 and related equations,' indicating a clear understanding of the specific part of the paper being addressed. The suggested correction is also concrete, specifying the exact symbol to be changed and the correct symbol to be used.", "grounding_specificity_rationale": "The reviewer directly points to 'eq 6 and related equations' and specifically mentions the 'cross_g' operator. This provides a clear and precise reference point within the paper. The reviewer's suggestion is directly tied to this specific part of the work, indicating full grounding. The reviewer also identifies a specific issue within the equation, suggesting a high level of specificity in pinpointing the problem.", "verifiability_rationale": "The reviewer states their belief about the operator in Eq 6. While this is a claim, the reviewer does not provide any external references or examples to support this claim within the provided review point. The justification is based on the reviewer's understanding of the mathematical context, which is a form of implicit justification. However, without explicit examples or references, the verifiability is somewhat limited within the scope of this review point.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: replace the cross product symbol in Eq 6 with a multiplication symbol. This is a specific and direct piece of feedback that the authors can easily understand and implement. The reviewer identifies a potential error and offers a concrete correction, making the feedback 5 and helpful for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests adding more ablation experiments, which is an explicit action aimed at demonstrating the effectiveness of the model. However, the reviewer does not specify how the ablation experiments would be conducted or what specific aspects of the model would be decoupled or reweighted. This lack of specificity makes it difficult to understand the exact action being proposed and how it would be implemented.", "grounding_specificity_rationale": "The reviewer suggests adding more ablation experiments. The paper does not explicitly state which part of the paper the ablation experiments would address. While the reviewer mentions 'the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection,' the paper does not currently discuss these specific components or their potential impact. Therefore, the reviewer's comment is 1 in the existing content of the paper.", "verifiability_rationale": "The reviewer suggests adding more ablation experiments. While the reviewer provides specific details about the *aspects* of the model that could be ablated, the paper does not currently provide any justification or evidence for why these specific ablations are important or how they would lead to a better understanding of the model. The suggestion lacks a clear connection to the identified weaknesses or areas for improvement in the current draft.", "helpfulness_rationale": "The reviewer suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model. While this is a valid suggestion for improving understanding and potentially the model itself, the review point lacks a clear connection to the specific problems or weaknesses identified in the current draft. The reviewer does not explain why these ablations are crucial for addressing the issues the authors are facing or what specific insights they hope to gain. The suggestion is a general direction for improvement, not a specific, actionable fix for a known problem."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The suggestions are both explicit and concrete. The reviewer explicitly states 'more complex datasets' and 'deep learning tasks', which are direct actions the authors can take. Furthermore, the reviewer provides specific examples of complex datasets (thousands of dimensions) and learning tasks (image datasets, deep learning tasks for breast cancer detection), making the actions concrete and actionable. The reviewer also suggests adaptive mechanisms as a baseline, which is a clear action to implement.", "grounding_specificity_rationale": "The reviewer explicitly mentions the type of datasets and tasks they suggest ('datasets with thousands of dimensions' and 'deep learning tasks'). While they don't specify a particular dataset or paper, they clearly identify the category of complexity they desire. The reviewer also mentions specific areas like 'image datasets' and 'breast cancer detection', which further grounds the suggestion. However, the suggestions are not fully grounded as they don't pinpoint a specific aspect of the current work that needs improvement in relation to these more complex scenarios.", "verifiability_rationale": "The reviewer makes a claim that 'the work can be done with more complex datasets and learning tasks'. This is a claim that can be verified. The reviewer provides suggestions for comparison ('adaptive mechanisms') as evidence for this claim. However, the suggestions are relatively highlevel and lack specific examples or citations to external works. While the claim is present and there's a suggestion for comparison, the lack of concrete examples or references makes it only 3.", "helpfulness_rationale": "The review point offers suggestions for improvement by mentioning 'more complex datasets' and 'deep learning tasks'. This is helpful as it guides the authors towards future research directions. The suggestions are actionable, as they point to concrete steps the authors can take. However, the suggestions are quite broad and lack specific details within the current work, making it 3 but not immediately actionable for addressing the current limitations."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises several points that, while not explicitly stating a solution, directly identify potential issues with the experimental setup and the justification for using PRESENCE. The questions about Figure 5 and Table 4, along with the uncertainty about the importance of reweighting, implicitly point out areas where the paper could be improved. While the reviewer doesn't propose concrete changes, they do identify areas needing clarification or further investigation.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'the relationship between temperature $\tau$ and the downstream performance shown in Figure 5' and 'the results from Table 4 (crosslingual zeroshot transfer)'. These are specific references to parts of the paper. The reviewer also asks about the 'importance of reweighting using a positive or negative $\tau$'. While this is a conceptual question rather than a specific section, it directly relates to the PRESENCE method and its parameters, making the grounding somewhat explicit.", "verifiability_rationale": "The reviewer's claim that 'some experiment results cannot convince me that PRESENCE is good enough' is presented without any specific evidence or references within the paper itself. The reviewer is making an interpretation of the results, not pointing out a clear flaw or missing information that could be verified logically, commonly known, or through external references. The claim is based on their own analysis of the presented results.", "helpfulness_rationale": "The reviewer's review raises valid concerns about the experimental results and the justification for using PRESENCE. By pointing out the lack of convincing evidence and the uncertainty surrounding the importance of reweighting, the reviewer provides valuable feedback that can help the authors improve their paper. While the reviewer doesn't offer a complete solution, they identify areas where the paper could be strengthened."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the results for k=1 are better than the baselines. This is an explicit action or suggestion that the authors should reevaluate their interpretation of the results in Table 2. However, the reviewer does not provide concrete steps on how to reevaluate or what specific aspects to focus on. The action is identified, but the implementation is vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 2' in their review point. This indicates a strong grounding as the reviewer can identify the specific part of the paper being addressed. Furthermore, the reviewer clearly specifies the result being discussed ('the results for k=1 are already better than the baselines'). This specificity allows the authors to understand exactly what the reviewer is pointing out.", "verifiability_rationale": "The reviewer makes a claim that the results for k=1 being better than baselines 'hints that the performance gain might be for a reason different from applying Eq.10'. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as an observation without any justification.", "helpfulness_rationale": "The reviewer points out a discrepancy in the results presented in Table 2, specifically that the performance for k=1 is better than expected. This is a valid observation that could potentially indicate an issue with the interpretation or the experimental setup. However, the reviewer does not provide any specific suggestions or actions for the authors to take based on this observation. The comment identifies a potential problem but does not offer a constructive solution."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the justification for using mixedinteger programming is 'not fully justified' and that its advantages over alternative approaches are 'unclear'. While the reviewer doesn't explicitly tell the authors *what* to do, they clearly identify a lack of justification and point towards areas for improvement. The reviewer implicitly suggests that the authors should provide a clearer rationale and compare their approach to alternatives. The criticism is focused on the *content* of the justification, rather than simply stating that the justification is missing. Therefore, while not explicitly actionable in the sense of directly telling them what to do, it points towards actionable items for the authors to address.", "grounding_specificity_rationale": "The reviewer makes a general statement about the lack of justification for mixedinteger programming. They do not specify a particular section, table, figure, or unique aspect of the paper where the justification is lacking. They are criticizing the *overall* approach to justification. Therefore, the grounding is weak because the reviewer cannot confidently identify the referenced part of the paper. The comment is broad and doesn't pinpoint a specific element for the authors to ground their criticism on.", "verifiability_rationale": "The reviewer claims that the justification for using mixedinteger programming is 'not wellsupported' and that its 'advantages over alternative approaches are unclear'. This implies a lack of logical reasoning, common knowledge, or external references to support the claim. The reviewer doesn't provide specific examples or references to back up their criticism. The claim is presented without sufficient justification or evidence. Therefore, the claim is not wellsupported by logical reasoning, common knowledge, or external references, making it 1.", "helpfulness_rationale": "The reviewer's criticism is about the *quality* of the justification for using mixedinteger programming. They point out a lack of justification and unclear advantages over alternatives. This feedback is likely to be helpful for the authors as it encourages them to think more critically about their methodological choices and provide a more robust rationale. While the criticism doesn't directly tell the authors what to do, it highlights a potential weakness in their writing and reasoning, making it a valuable piece of feedback. The reviewer's criticism is focused on improving the *quality* of the justification, which is a helpful goal."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem: 'Notation in Equation 1 is confusing (using c instead of o)'. This clearly indicates an implicit action: the reviewer is suggesting that the notation 'o' is more appropriate than 'c'. While the action is not stated directly, the implication is clear. The reviewer also suggests a specific change: 'Pedersen et al 2007 is missing in the reference section', which is a concrete action to take. Therefore, the action is implied but not entirely explicit. The reviewer also points to a specific equation (due to the line number reference), which implies a specific part of the paper is being addressed. The suggestion to use 'o' is also a specific action to take. Therefore, the action is implied but not entirely concrete. The reviewer also points to a specific equation (due to the line number reference), which implies a specific part of the paper is being addressed. The suggestion to use 'o' is also a specific action to take. Therefore, the action is implied but not entirely concrete.", "grounding_specificity_rationale": "The reviewer refers to 'Equation 1' by line number (361), which explicitly identifies the part of the paper being addressed, indicating full grounding. The reviewer also suggests a specific change to the notation, indicating a specific aspect of the referenced part that needs improvement. Therefore, the grounding is fully grounded and the specificity is about the notation within Equation 1.", "verifiability_rationale": "The reviewer makes a claim: 'Notation in Equation 1 is confusing'. This is a statement of a problem. The reviewer then suggests a potential solution: 'Pedersen et al 2007 is missing in the reference section'. While this is a suggestion, it's not explicitly supported by a reference or logical reasoning *within the review point itself*. The reviewer's suggestion to use 'o' is also a suggestion, not a claim requiring verification. Therefore, the claim is stated but not fully supported by evidence within the review point.", "helpfulness_rationale": "The reviewer identifies a potential issue (confusing notation) and suggests a concrete improvement (using 'o'). This makes the comment actionable and helpful in guiding the authors to improve their draft. However, the reviewer does not provide any specific evidence or justification for why the 'c' notation is problematic or why the 'o' notation is better. The comment is a suggestion without further elaboration or supporting arguments. Therefore, while the comment is helpful in terms of identifying an area for improvement, it lacks supporting evidence to back up the claim."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of novelty in the combination of SSMs and Attention, citing MEGA and Blockstate Transformer. They also suggest discussing and ablating the similarities, which are concrete actions the authors should take. While the reviewer doesn't provide a direct explanation of *how* the combination is similar to prior work, the implications are clear.", "grounding_specificity_rationale": "The reviewer points to the 'results' section where the comparison to MEGA is made and provides a link to the Blockstate Transformer paper. They also suggest 'discussing and ablated' the similarities, which can be inferred from the cited work. While the paper doesn't explicitly state 'Figure 5 looks very similar to the proposed architecture in Mega' within the text, the reviewer's statement strongly implies this similarity. Therefore, the grounding is strong but could be made more explicit by directly referencing Figure 5.", "verifiability_rationale": "The reviewer makes a claim about the similarity of the proposed architecture to MEGA and the similarity of S++ to MEGA. While they provide a citation for MEGA, they don't explicitly explain *why* the architecture is similar or provide specific examples of the differences between S++ and their work. The link to Blockstate Transformer is helpful but doesn't fully verify the claim. The claim is present but lacks detailed justification.", "helpfulness_rationale": "The reviewer's point is that the paper needs to better acknowledge prior work and clarify its novel contributions. This is a valuable suggestion for improving the clarity and impact of the paper. While the reviewer doesn't provide a specific, detailed suggestion on *how* to improve the paper, the reviewer's point is clear and directly addresses a potential weakness in the paper's narrative."}
{"actionability_label": "5", "grounding_specificity_label": "Somewhat Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the reason for reporting results on knowledge transfer in only a few environments, which is 'to avoid redundancy'. This is a clear and direct statement of the intended action. The reviewer also identifies the specific aspect of knowledge transfer reporting that is missing, which is 'results'. This makes the action very concrete. Therefore, the reviewer's point is 5.", "grounding_specificity_rationale": "The reviewer is asking 'Is there a specific reason...'. This implies they are looking for a specific justification for the limited reporting. However, the paper does not explicitly state a specific reason related to a particular part of the paper being discussed (knowledge transfer) for the decision to report results only on a few environments. The reason could be general avoidance of redundancy, but this is not tied to a specific aspect of the knowledge transfer section. Therefore, while the reviewer is asking for a specific point, the grounding of that request is weak.", "verifiability_rationale": "The reviewer claims there is a lack of a specific reason for reporting results on knowledge transfer in only a few environments. The paper does not explicitly state a reason for this selective reporting, nor does it provide a justification for why results were not reported on all environments. There is no logical reasoning, common knowledge, or external references provided to support this claim. Therefore, the claim is not wellverified.", "helpfulness_rationale": "The reviewer's point is that the paper lacks a specific reason for reporting results on knowledge transfer in only a few environments. While this points to a potential area for clarification, the review itself does not offer a specific suggestion or actionable improvement. The reviewer is asking 'Is there a specific reason...'. The paper does not provide this specific reason, making the reviewer's point somewhat lacking in constructive feedback. Therefore, the review point is 3 as it highlights a potential issue, but it does not offer a solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the 'lack of specific ablation experiments' and suggests 'detailed ablation comparisons'. This directly points to a missing element and proposes a concrete next step for the authors to take. The reviewer identifies the specific area of the paper (ablation studies) and suggests a specific type of experiment (detailed ablation comparisons). This makes the action both explicit and concrete.", "grounding_specificity_rationale": "The reviewer mentions 'specific ablation experiments'. This clearly identifies the specific part of the paper being addressed. The use of the word 'specific' further emphasizes the targeted nature of the suggestion. The reviewer accurately pinpoints the section and even provides a detail about the type of ablation studies.", "verifiability_rationale": "The reviewer states a claim that 'the performance improvement could be attributed to the pretrained weights rather than the method proposed in the manuscript' and suggests 'specific ablation experiments' to address this. This claim is supported by logical reasoning (the possibility of pretrained weights influencing results) and the proposed solution directly addresses the identified issue by providing a means to verify the contribution of the proposed method. The reviewer provides a clear justification for their claim and suggests a concrete way to verify it.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the manuscript (lack of specific ablation studies) and provides a concrete suggestion (detailed ablation comparisons). This directly helps the authors improve their work by guiding them on how to further investigate the performance improvements and validate their method more rigorously. The reviewer's point directly addresses a potential ambiguity in the results interpretation."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a *limitation* of a lemmatizer, which implies an *implicit* action: 'This is a problem that needs to be addressed.' While the *identification* of the problem is explicit, the *action* to fix it is not. The level of *concreteness* is also limited as it doesn't specify how to address the issue. This aligns with the definition of a review being *2*.", "grounding_specificity_rationale": "The review point does not explicitly mention a specific part of the paper it is addressing. It is a general statement about a potential *limitation* of a lemmatizer. Therefore, the grounding is *weak*. However, the point clearly specifies the *type* of lemmatizer limitation and the * kind of words* affected, as well as the *impact on realworld texts* and *evolving vocabularies*. This provides a good level of *specificity*.", "verifiability_rationale": "The review point presents a *concern* about the lemmatizer's behavior with certain words. It does not contain a clear claim or suggestion for improvement that is directly supported by evidence or logical reasoning within the review point itself. Therefore, it is *1*.", "helpfulness_rationale": "The review point raises a relevant concern about a potential limitation of lemmatization, particularly for realworld texts with evolving vocabularies. This is a pertinent issue for authors who might be using lemmatizers. While it doesn't offer a solution, it highlights a potential problem, making it *3* in identifying an area for further investigation or discussion."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a problem with the experimental setup in Table 2 and suggests an alternative approach. They identify the issue as the use of pretrained DGCNN for semantic segmentation, which makes the comparison of different completion methods less meaningful. This clearly indicates an actionable suggestion for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions the pretrained DGCNN and the comparison of segmentation metrics in Table 2. They also explain *why* this comparison is not meaningful, indicating a clear understanding of the specific aspect of the paper being discussed. This demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the comparison of segmentation metrics being 'not too meaningful' and provides a clear explanation for this, stating that it's because the methods are combined with pretrained DGCNN. This claim is supported by logical reasoning, making it 5.", "helpfulness_rationale": "The reviewer provides a clear critique of the experimental setup in Table 2, specifically pointing out the flaw of using pretrained DGCNN for all methods. They suggest an alternative approach of comparing the completion methods without the pretrained DGCNN. This critique is directly actionable and provides valuable guidance for the authors, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a general observation about the practicality of statistical rules. It does not explicitly state an action the authors should take or provide concrete steps to address the issue. The concern is broad and lacks specificity.", "grounding_specificity_rationale": "The review point is a general statement about the difficulty of applying statistical rules in realworld scenarios. It does not specify which rules, sections, or aspects of the paper are being referred to, nor does it provide any specific examples or references.", "verifiability_rationale": "The review point contains a claim about the difficulty of getting statistical rules in realworld applications and suggests that datadriven rules might be feasible. However, it does not provide any evidence, references, or logical reasoning to support this claim. The statement is a general observation without specific backing.", "helpfulness_rationale": "The review point raises a valid concern about the practical limitations of statistical rules, which could be relevant to the authors. However, it lacks specific details about which rules are problematic and does not offer concrete suggestions for improvement, making it 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly suggests a comparison with specific methods ('dynamic sparse trainingbased' and 'other sparsitybased methods'), indicating an intention to address a potential gap. However, the comment lacks detail on *how* this comparison should be conducted, making the action somewhat vague.", "grounding_specificity_rationale": "The comment explicitly mentions 'dynamic sparse trainingbased' and 'other sparsitybased methods,' clearly identifying the specific area of comparison. This strong identification of the section or type of method demonstrates high grounding specificity.", "verifiability_rationale": "The comment states that the comparison is 'missing' without providing any justification or reasoning for why this comparison is absent. There is no logical reasoning, common knowledge, or external references to support this claim.", "helpfulness_rationale": "The reviewer expresses an interest in seeing this comparison, suggesting it could be valuable for the authors. While the suggestion is present, the lack of verifiability might limit the perceived helpfulness as the exact nature and importance of the missing comparison are unclear."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue with the paper's logic: 'It sounds like the reason that $p_\u03b8(y|x)$ is intractable is because $p_\u03b8(z|x)$ is intractable, but this doesn't have to be the case.' This is a clear and direct identification of a potential flaw in the paper's reasoning. The reviewer then provides a counterexample, which further clarifies the issue. Therefore, the reviewer's point is explicit and actionable, as the authors can directly identify the potential flaw in the paper's logic and the conditions under which it might be incorrect.", "grounding_specificity_rationale": "The reviewer explicitly references the statement in the paper about the intractability of $p_\u03b8(y|x)$ and $p_\u03b8(z|x)$: 'The intractability of $p_\u03b8(y|x)$ in a latent variable model is due to the intractability of $p_\u03b8(z|x)$'. This direct reference to a specific claim within the paper makes the grounding quite explicit. However, the reviewer doesn't pinpoint a specific element within the paper (like a table or a particular section) but rather highlights a claim made within the explanation. Therefore, while the grounding is explicit, it's underspecific as it doesn't identify a concrete part of the paper being addressed.", "verifiability_rationale": "The reviewer makes a clear claim: 'It sounds like the reason that $p_\u03b8(y|x)$ is intractable is because $p_\u03b8(z|x)$ is intractable, but this doesn't have to be the case.' This claim is supported by a logical explanation: 'Both the posterior and the likelihood can be tractable but $p_\u03b8(y|x)$ may still be intractable (for instance, a Bernoulli likelihood with a Gaussian posterior)'. This logical reasoning and the provided counterexample make the claim verifiable. The reviewer provides sufficient justification and evidence to support their point.", "helpfulness_rationale": "The reviewer's comment is highly constructive and directly addresses a potential ambiguity in the paper's reasoning. They clearly identify a specific issue: the paper's implication that the intractability of $p_\u03b8(y|x)$ *must* be due to the intractability of $p_\u03b8(z|x)$, given that $p_\u03b8(y|x|z)$ is tractable. The reviewer then provides a logical explanation and a concrete counterexample (Bernoulli likelihood with a Gaussian posterior) to illustrate why this implication isn't necessarily true. This constructive feedback empowers the authors to reconsider their understanding and potentially correct their reasoning. The reviewer's point is actionable and provides valuable insight into the underlying statistical concepts."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a problem (inaccessible datasets) but does not provide any specific actions or suggestions on how to address it. It lacks concrete steps for improvement.", "grounding_specificity_rationale": "The review point refers to 'inaccessible collected datasets' without explicitly identifying a specific part of the paper or methodology being affected. The grounding is weak as the reviewer cannot confidently determine which aspect of the paper is being discussed.", "verifiability_rationale": "The review point states a fact (the datasets are inaccessible) but does not present a claim that requires verification. There are no logical reasoning, common knowledge, or external references provided to support a statement. It is a factual observation, not a claim.", "helpfulness_rationale": "The review point identifies a valid limitation (inaccessibility of datasets) that could hinder reproducibility. However, it does not offer any concrete solutions or actionable steps for the authors to address this issue. It points out a problem but doesn't provide guidance on how to fix it."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly asks if an equation is missing before a specific phrase ('where p is the firing rate') in Section 3.4.1. This is a direct and concrete request for the authors to check for something specific in a particular location. While it doesn't directly tell them what to do, it clearly identifies a potential area of confusion or missing information, making it actionable in the sense that addressing this would likely improve clarity.", "grounding_specificity_rationale": "The reviewer's comment explicitly references 'Section 3.4.1' and the phrase 'where p is the firing rate'. This strong referencing demonstrates a high level of grounding specificity. The authors can easily identify the section and the relevant point within that section where the potential missing equation might be located.", "verifiability_rationale": "Although the comment doesn't contain a claim in the sense of stating an opinion, it poses a question about the existence of an equation. This question is verifiable through a search or inspection of the specified section. While it doesn't provide a definitive answer, the process of verifying the presence or absence of the equation is verifiable, making it 3.", "helpfulness_rationale": "The reviewer's question directly addresses a potential gap in the clarity of Section 3.4.1. By asking about a missing equation, they are prompting the authors to investigate a specific point of confusion. This is a helpful and focused suggestion that, if addressed, could improve the paper's readability and understanding."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing element: 'lacking the evaluation of sentiment word detection and correction'. They also clearly indicate the intended action: 'conduct experiments'. The action is directly linked to the stated problem.", "grounding_specificity_rationale": "The reviewer mentions 'sentiment word detection and correction' and 'SWRM', providing some grounding. However, they don't specify *where* within the SWRM system or *what specific aspects* of the evaluation are needed. The grounding is present but not fully precise.", "verifiability_rationale": "The reviewer provides a clear claim: 'since the key ideas of SWRM are the detection and correction of possible sentiment word errors, I think it is necessary to conduct experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates.' They also provide logical reasoning ('necessary') and examples ('sentiment word position detection module and the predicted sentiment word candidates') to support this claim.", "helpfulness_rationale": "The reviewer clearly identifies a significant weakness ('lacking the evaluation') and provides a strong justification for addressing it ('to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates'). This directly points out a need for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states what is missing in the result tables: the results of KMLMXLMR_large and KMLMlarge without logical reasoning. This clearly indicates an implicit action for the authors: to locate and examine these missing performance metrics. While not stated directly, the reviewer implies a need to understand the performance of these specific configurations.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific missing information: the results for KMLMXLMR_large and KMLMlarge without logical reasoning. The reviewer also implicitly identifies the specific missing baseline by referring to 'KMLMlarge without logical reasoning'. This strong specificity indicates that the reviewer understands exactly what data is missing and what it represents.", "verifiability_rationale": "The reviewer's comment points out a specific gap in the reported results. This can be considered verifiable because the authors can directly check the tables for these specific configurations and their corresponding performance metrics. The reviewer's request itself suggests a potential issue that could be investigated further.", "helpfulness_rationale": "The reviewer's comment is directly addressing a gap in the reported experimental results. By pointing out the missing values for KMLMXLMR_large and KMLMlarge without logical reasoning, the reviewer is guiding the authors to a specific area for further investigation or clarification. This is a helpful comment because it directly points to actionable steps the authors can take to understand their model's performance."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the underperformance of incontext learning baselines compared to the backbone model. This is a clear observation and a direct action the authors could take: investigate the variance and baseline design. While the reviewer doesn't specify *how* this underperformance occurs, they identify a discrepancy, making it actionable.", "grounding_specificity_rationale": "The reviewer mentions 'incontext learning baselines,' specifically 'static fewshot' and 'chainofthought' methods. This grounds the comment to a specific type of baseline. However, the reviewer does not specify a particular section, table, or figure within the paper. The comment focuses on the *types* of baselines and attributes to their potential issues (large variance, uncareful design) rather than pinpointing a specific element of the paper being discussed.", "verifiability_rationale": "The reviewer presents a claim: 'These are likely due to the very large variance of the results or the uncareful design of the baselines.' This is a claim that requires verification. The reviewer suggests potential reasons for the underperformance but does not provide specific references, examples, or logical reasoning to support this claim within the review point itself.", "helpfulness_rationale": "The reviewer raises a valid point about the need for further explanation regarding the underperformance of incontext learning baselines. This comment identifies a significant issue and suggests a direction for improvement (explaining the discrepancy). While the reviewer doesn't provide a complete solution, they offer a clear direction for the authors to focus their investigation, making it a helpful suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the 'claim that GFNSeqEditor can produce novel sequences with improved properties lacks clarity regarding the key innovation driving these contributions.' This indicates that while the reviewer identifies a need for better explanation, the action suggested (better articulating the innovation) is not explicitly stated in the review point itself. The reviewer is pointing out a gap in the information provided, rather than directly instructing the authors on what to do.", "grounding_specificity_rationale": "The reviewer states that the 'key innovation' is unclear. This means the authors cannot confidently determine what part of the paper or what aspect of the method the reviewer is referring to. The comment does not specify the unique elements or sections of GFNSeqEditor that are responsible for the claimed improvements. Therefore, the grounding of the comment is weak as the authors cannot precisely identify the referenced part.", "verifiability_rationale": "The reviewer makes a claim that 'GFNSeqEditor can produce novel sequences with improved properties.' However, this claim is not supported by any evidence, references, or logical reasoning within the review point. The reviewer does not explain *how* these novel sequences are produced or *why* they have improved properties. The verifiability of this claim is low as there is no justification provided.", "helpfulness_rationale": "The reviewer's suggestion to 'better articulate what novel techniques or insights lead to the claimed improvements' is a direct and actionable suggestion for the authors. This provides a concrete direction for the authors to improve their description and clarify the method's unique value. The review point identifies a weakness and offers a clear path to address it, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a weakness (the proposed approach being less at risk to biases) and suggests an experiment to address it. This constitutes an implicit action, as the authors would need to conduct the experiment to verify the claim. However, the specifics of the experiment are not provided, making the action less concrete.", "grounding_specificity_rationale": "The comment refers to the 'proposed approach' and 'risk of biases' generally, without specifying which part of the paper or method this relates to. There is no mention of a specific section, table, figure, or unique element of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim that the proposed approach is less at risk to biases than other methods. This claim is not supported by any evidence or reasoning within the review point. The reviewer suggests an experiment as a way to demonstrate this, but the experiment itself is not presented in this review point.", "helpfulness_rationale": "The reviewer's point is helpful in that it suggests a concrete action the authors could take (conducting an experiment) to address the identified weakness. However, the lack of supporting evidence for the claim itself makes the reviewer's point less helpful overall. The authors still need to perform the experiment themselves to verify the claim."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the mismatch between the general applicability of realworld problems and the method's limitation to discrete stateaction spaces. They identify the specific sentence in the manuscript as the source of the problem and explain that this makes the criticism actionable.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific sentence in the manuscript as the source of the problem, demonstrating strong grounding. They also clearly explain why this sentence is problematic, making the criticism specific.", "verifiability_rationale": "The reviewer provides a clear explanation of why the motivation is weak. They identify the core issue: the mismatch between the general applicability of the problem and the method's limitation to discrete stateaction spaces. This explanation is logical and directly points to the problem, making the criticism verifiable.", "helpfulness_rationale": "The reviewer provides a direct and constructive criticism. They clearly explain the weakness and why it's a problem. This makes the review helpful for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point presents two explicit claims about the experiment results and suggests an implicit action to improve the presentation. However, the claims lack concrete details. The first claim about the results not being competitive doesn't specify which SOTA methods or the nature of the minor improvements. The second claim about Table 1's clarity doesn't identify specific issues. The suggestion to move the baseline is implied but not explicitly stated as an action.", "grounding_specificity_rationale": "The review point does not explicitly mention any specific part of the paper or method. The claims are general statements about the results and presentation without pointing to a particular section, table, or figure. Therefore, the grounding is weak as the authors cannot confidently determine where the issue lies.", "verifiability_rationale": "The review point contains claims that are not supported by any evidence or justification. The competitiveness of the results and the clarity of Table 1 are stated as opinions without providing any references or logical reasoning to back them up. The suggestion to move the baseline is also presented without any supporting arguments.", "helpfulness_rationale": "The review point identifies potential weaknesses in the results and the presentation, which could be helpful for the authors to consider. The suggestions, while not explicitly stated as actions, point towards areas for improvement. However, the lack of specificity makes the feedback less actionable and potentially less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to specify the target of copyright mechanisms, which is a direct and concrete action they can take to improve their draft. The request is clear and directly addresses a potential ambiguity in the copyright scenario.", "grounding_specificity_rationale": "The review point explicitly refers to the 'copyright scenario' and asks to differentiate between the interests of the 'model owner' and the 'endusers'. This clearly identifies the specific part of the paper and the specific issue within that part, providing strong grounding. The reviewer also uses clear and direct language to specify the desired information.", "verifiability_rationale": "The review point is not making a claim that requires verification. It is a request for clarification and information about a specific aspect of the paper. Therefore, it does not fall under the 'verifiability' aspect as it does not present a claim to be supported or refuted.", "helpfulness_rationale": "The review point is helpful because it directly points out a potential area of confusion or lack of clarity for the authors regarding the copyright scenario. By asking for a clarification, the reviewer guides the authors to improve the manuscript's explanation of this important aspect."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a gap in the authors' understanding (lack of theoretical justification/explanation). While it *doesn't* explicitly tell the authors what to do, it points to a specific area needing clarification. This is 2. It points to an action (understanding the mechanism), but the mechanism isn't stated.", "grounding_specificity_rationale": "The review point is 1 at all. It does not identify a specific area in the paper. The comment is highly unspecific.", "verifiability_rationale": "The review point presents a statement about the behavior of the adapters as observed in experiments. It doesn't make a definitive claim about *why* this behavior occurs. It's more of an observation than a claim requiring verification. This is not verifiable.", "helpfulness_rationale": "The review point highlights a lack of understanding, which could be helpful for the authors to improve their work. However, because it doesn't provide a solution or point to specific areas, its helpfulness is limited. It's better than nothing, but not very helpful. This is 3 as it points to a crucial gap in understanding."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a direct question about the statement made in the paper, implying an action to understand the reasoning behind the claim. While the action is implicit, the reviewer clearly states a need for explanation.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'line 154' and discusses concepts directly related to 'local models' and 'decision boundaries'. They are pointing to specific parts of the paper and the topic of discussion, making the grounding strong.", "verifiability_rationale": "The reviewer presents a claim about the triviality of local models away from decision boundaries and suggests an alternative approach based on probability differences. While the paper makes the claim, it doesn't explicitly prove or justify it, and the reviewer's suggestion points to a lack of sufficient verification within the paper.", "helpfulness_rationale": "The reviewer is directly asking for clarification on a point in the paper and suggesting an alternative approach. This is highly relevant to improving the authors' understanding and potentially the method itself. The suggestion to use probability differences is a concrete idea for how to explore the issue."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the issue: 'the experiments only report results on ImageNet' and provides a clear action: 'without including results on classic datasets such as CIFAR10 and CIFAR100'. This directly tells the authors what needs to be done.", "grounding_specificity_rationale": "The reviewer refers to 'the experiments' generally, which doesn't pinpoint a specific section, table, or figure. While they imply the results are in a section discussing experimental outcomes, they don't explicitly name it. However, they clearly specify the *what* \u2013 missing results on classic datasets \u2013 which adds some level of specificity regarding the issue.", "verifiability_rationale": "The review point makes a claim: 'the experiments only report results on ImageNet' and 'without including results on classic datasets such as CIFAR10 and CIFAR100'. This is a factual statement about the paper's content. The reviewer directly states this observation without needing to infer or provide external references to support it.", "helpfulness_rationale": "The review point is clear, identifies a specific area for improvement (missing experimental results), and provides a direct suggestion for the authors to take action. It directly addresses a gap in the information provided by the authors and offers a concrete next step."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer requests clarification on the discrepancy between the text description and the figure regarding the softmax layer in the DinoSR part. While the reviewer doesn't explicitly state an action, the request implies a desire for the authors to understand the standard implementation. The authors could infer the need to consult the original DinoSR paper for the softmax layer, making the action somewhat implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the DinoSR part in Figure 1' and 'the encoder, according to the text description, does not include that layer.' This clearly identifies the specific part of the paper being addressed, making the grounding explicit. The reviewer also points to a discrepancy with the original DinoSR paper, further specifying the issue within that part.", "verifiability_rationale": "The reviewer states that 'the DinoSR part in Figure 1 is confusing' and 'the figure in the original DinoSR paper is very clear.' This constitutes a claim that can be verified by comparing the figure in the submitted paper with the figure in the original DinoSR paper. While the claim itself is verifiable, the lack of specific examples or references makes the verifiability somewhat lacking.", "helpfulness_rationale": "The reviewer points out a potential source of confusion for the authors regarding the DinoSR part. While it might not be a critical flaw, identifying such potential sources of confusion and suggesting a reference to the original paper could be helpful for the authors to understand the standard implementation and avoid similar confusion in the future. The reviewer's request is a valid point that could improve the clarity of the paper for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'I think some related work on causal inference needs to be reviewed.' This clearly identifies an action: reviewing the paper and potentially adding related work on causal inference. While the specific *type* of causal inference work isn't mentioned, the action itself is direct and identifiable. Therefore, the review point is actionable.", "grounding_specificity_rationale": "The review point does not specify a particular section, table, figure, or unique aspect of the paper that it is addressing. It simply suggests considering related work on causal inference in general. Therefore, the comment is 1.", "verifiability_rationale": "The review point contains a claim: 'I think some related work on causal inference needs to be reviewed.' However, this claim is not supported by any logical reasoning, common knowledge, or external references within the review point itself. There is no justification provided for why this related work is important or what specific issues it addresses. Therefore, the claim is 1.", "helpfulness_rationale": "The review point suggests considering related work on causal inference, which is a relevant and potentially helpful direction for the authors. While the suggestion is general and doesn't provide specific details about which causal inference work to review or how it should be integrated, it still points the authors towards a useful area of research. Therefore, the review point is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly suggests using the LLM2Vec encoder, which is a clear action. However, it doesn't provide specific details on how to implement this change or what steps are needed to integrate it into the current framework. The reviewer points to the potential redundancy of sections 3.1 and 3.2 and suggests LLM2Vec could avoid it, but the exact method of achieving this isn't detailed.", "grounding_specificity_rationale": "The reviewer explicitly mentions sections 3.1 and 3.2 as the areas where the LLM2Vec encoder could be used. This clearly identifies the specific part of the paper being addressed. The reviewer also states that the current approach in these sections is redundant and that LLM2Vec could avoid this redundancy, specifying the potential improvement within this section.", "verifiability_rationale": "The reviewer claims that the paper could have avoided the redundancy in sections 3.1 and 3.2 by using the LLM2Vec encoder, which is already cited. However, the reviewer does not provide any specific evidence or reasoning to support this claim. They state the reasoning is unclear, and the benefit of LLM2Vec in this context is not explicitly demonstrated or justified.", "helpfulness_rationale": "The review point suggests a potential improvement (using LLM2Vec) and highlights a potential issue (redundancy). However, it lacks concrete evidence to support the claim that LLM2Vec would effectively address this issue. The reasoning for not adopting LLM2Vec is stated as unclear, and the request for ablation studies is a valid point for further investigation but doesn't provide immediate helpfulness to the authors in the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of realworld problems in the experiments, which is an implicit action to identify a missing element. While not stated directly as 'implying the need for realworld problems', the implication is clear. However, the suggestion to 'include realworld problems' is a concrete action that can be directly implemented.", "grounding_specificity_rationale": "The review point explicitly mentions 'the experiments section' as the area lacking realworld problems, providing clear grounding. The suggestion to 'include realworld problems' is also specific, indicating a clear understanding of what needs to be done.", "verifiability_rationale": "The claim is that 'only synthetic objective functions are used, there are no realworld problems'. This claim is verifiable as it points to a specific limitation in the experimental setup. The suggestion to 'include realworld problems' is a logical next step, although it doesn't provide a specific example of a realworld problem, it's a clear direction.", "helpfulness_rationale": "The review point is 5 as it directly identifies a limitation in the experimental evaluation (lack of realworld problems) and provides a clear and actionable suggestion for improvement ('include realworld problems'). This directly empowers the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states a finding and proposes a potential reason. While not a direct suggestion of *how* to analyze the benchmarks, it points to a concrete next step. Therefore, it's considered implicit but directly related to the finding, making it 3.", "grounding_specificity_rationale": "The review mentions \"explanationfocused cues\" and \"listenerfocused parts\" without explicitly naming a specific section or table in the paper. The discussion revolves around the *nature* of these cues and parts, not a specific instance. Therefore, the grounding is weak as the authors can only infer the focus is likely on the results section discussing these cues and potentially a table comparing them, but it's not a direct reference. The specificity is underspecific as it doesn't pinpoint a missing element within those cues or parts.", "verifiability_rationale": "The review contains a claim: \"This can be because LLMs may rely more on language style than on informational depth.\" This is a statement of a potential reason for the observed finding. However, the claim is presented as a possibility or a potential explanation, without providing any evidence or justification within the review point itself. It's a hypothesis.", "helpfulness_rationale": "The review points out a finding and offers a potential explanation. While not a direct solution, it highlights a limitation in the current work and suggests a way to potentially address it. This provides some value to the authors in understanding the limitations of their own approach (or similar approaches). Therefore, it's considered 3 as it identifies a weakness and offers a potential direction for further research."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the acronym 'DU' is mentioned without a clear definition. This makes the action explicit. However, the comment does not provide concrete guidance on how the authors should define 'DU'. The action is somewhat vague as the authors are not given a specific action to take beyond identifying the missing definition.", "grounding_specificity_rationale": "The comment explicitly mentions the acronym 'DU', which can be directly identified in the paper. Therefore, the grounding is considered full. The comment also clearly identifies the issue as the lack of definition for 'DU', making the specificity high.", "verifiability_rationale": "The comment contains a claim: 'The paper makes heavy use of acronyms, which affects readability. Notably, the acronym \"DU\" is mentioned without a clear definition.' This claim is not supported by any evidence or justification within the review point itself. The verifiability is 1 because the point itself doesn't provide a solution or evidence to support the claim.", "helpfulness_rationale": "The comment identifies a potential issue (lack of definition for 'DU') that could affect the clarity and readability of the paper. It suggests that the authors should define it. This is a constructive suggestion and therefore helpful. However, it doesn't provide a definitive solution or guarantee that defining 'DU' will resolve any readability issues. The helpfulness is somewhat because it points towards a potential improvement area."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks specific questions about how the variance is estimated, indicating a lack of explicit detail in the original paper regarding this calculation. While the topic is relevant, the *lack of detail* makes it difficult to directly apply the information, thus making it 3 but lacking concrete details.", "grounding_specificity_rationale": "The reviewer infers the assumption of sentence independence and questions the estimation method. The paper focuses on the *form* of the distribution (p(q|s)) without necessarily pinpointing the *section* or *equation* where this assumption is made (if it is). Therefore, the grounding is weak \u2013 the reviewer infers the implication. The reviewer also questions the dimensionality of the covariance matrix, which further contributes to the lack of specific grounding.", "verifiability_rationale": "The reviewer's questions about the estimation method and the dimensionality of the covariance matrix demonstrate a clear understanding of the underlying concepts and a desire for more information. This makes the comment 3, as the questions point to a gap in the explanation. However, the *answer* to the question is not provided in the review itself, so it's not 5.", "helpfulness_rationale": "The reviewer's questions directly address a potential weakness in the methodology by highlighting the simplifying assumption of sentence independence and the lack of detail in the variance estimation. This points to a potential area for improvement in the original paper. Therefore, the comment is 3, as it identifies a potential issue. However, the *impact* of this comment depends on whether the original paper actually makes the simplifying assumption and whether the reviewer's suggestion is a significant improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the observation (MIL accuracy higher) and asks for an explanation. This is an explicit action \u2013 they want to understand something. While the action is not concrete in terms of *how* the MIL model performed better, the request for an explanation makes it actionable in the sense that the authors should investigate and provide a justification for this discrepancy.", "grounding_specificity_rationale": "The reviewer explicitly references \"Fig. 7\" and \"NSCLC dataset\". This is strong grounding as the reviewer is pointing to a specific part of the paper and a specific aspect within that part. The reviewer also specifies the comparison between the \"MILbased baseline model\" and the \"converged models\", adding further specificity to the referenced part.", "verifiability_rationale": "The reviewer presents a claim: \"For Fig. 7, the initial accuracy of MILbased baseline model were higher than the converged models, especially for the converged models, why?\". This claim is not supported by any evidence or references within the review point itself. There are no logical reasoning steps, common knowledge, or external references provided to justify this observation. Therefore, it is 1 based on the information given in the review point.", "helpfulness_rationale": "The reviewer is asking a question to understand a discrepancy in their results. While this is a valid point for improvement and can help the authors understand their model better, the lack of context about the \"converged models\" and the specific experimental setup makes it difficult to provide truly actionable feedback. The reviewer is asking *why* a particular model performed better, but without further information, the authors cannot provide a concrete explanation. Therefore, it is 3 as it points to a potential issue, but it needs more context to be fully helpful."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "UnderSpecific", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential improvement (exploring other datasets) but doesn't explicitly state the action to be taken. While it implies considering other datasets, the specific steps or modifications are not mentioned. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The review point explicitly mentions \"the MuAViC dataset\" as the primary focus of the paper. This clearly identifies the specific part of the paper being addressed. The issue being pointed out is the limited exploration of this specific dataset.", "verifiability_rationale": "The review point contains a claim: \"It would be beneficial to consider other datasets to explore the generalization of the proposed method across diverse data sources.\" This is a statement of suggestion and a potential benefit. However, within the *review point itself*, there are no supporting evidence, examples, or references to external works that would verify this claim. The *paper* might have evidence, but the review point doesn't provide it.", "helpfulness_rationale": "The review point identifies a potential limitation (the narrow focus on one dataset) and offers a suggestion (exploring other datasets). This points towards a valuable direction for future work. However, it lacks specific details on *how* to implement this suggestion or what concrete improvements can be expected from doing so."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their request for confidence intervals as an action. The request is clear and directly addresses the perceived lack of clarity in the reported values in Table 1. The reviewer is indicating they want a specific improvement to the paper.", "grounding_specificity_rationale": "The reviewer's request is implicitly tied to Table 1, as they specifically mention 'the performance of different fairness improvement techniques' being reported in that table. While the table itself isn't explicitly referenced, the reviewer is clearly referring to it. The request is specific: 'add confidence intervals'.", "verifiability_rationale": "The reviewer identifies a lack of clarity in the reported values as a claim. They then propose 'add confidence intervals' as a way to verify this claim and provide a more verifiable justification. The suggestion is logical and directly addresses the identified issue.", "helpfulness_rationale": "The reviewer's request for confidence intervals is a clear and actionable suggestion to improve the clarity and interpretability of the results presented in Table 1. It directly addresses a potential weakness in the presentation of the findings."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review points out that some choices are not justified or clear, which implies an action (improving justification). However, it doesn't specify *how* to do this, making it only 3.", "grounding_specificity_rationale": "The review mentions 'some choices' without specifying which ones. This indicates weak grounding as the exact part of the paper being criticized is not clearly identified.", "verifiability_rationale": "The review states that some choices are not justified or clear. This is a statement of a problem, not a claim that requires verification. Therefore, there is X to evaluate for verifiability.", "helpfulness_rationale": "The review identifies a valid issue (lack of justification for some choices) but offers very general suggestions ('improve justification'). Without specific, actionable steps, the feedback is 3 but lacks the impact of more concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states concerns about the hyperparameter tuning process, indicating an awareness of a potential issue. However, the reviewer does not specify *how* the grid search is conducted, making the actionable part of the comment somewhat vague. The lack of detail makes it difficult to understand the exact steps or considerations involved in the tuning process.", "grounding_specificity_rationale": "The reviewer mentions 'grid search' and its impact on 'FLOPs' and 'accuracy' in the context of the polarization regularizer. While they imply a connection to the hyperparameter tuning, they do not explicitly identify *which* part of the paper or method they are referring to. The grounding is present but not as precise as it could be.", "verifiability_rationale": "The reviewer makes claims about the hyperparameter tuning process, stating that it has 'two hyperparameters' and makes it 'laborious'. However, the paper itself does not explicitly state these details or the lack of a clear objective function for the grid search. The reviewer's claims are not supported by evidence within the provided text, making the verifiability low.", "helpfulness_rationale": "The reviewer identifies a potential issue with the hyperparameter tuning process of the polarization regularizer. While they describe the concerns, they do not offer any solutions or suggestions for improvement. The comment primarily highlights a potential weakness rather than providing actionable feedback, making it less helpful for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states what information is missing ('accuracies of the target model using different defenses against the FGSM attack are not shown') and implies the consequence of this missing information ('it is unclear the difference between the known attacks and the unknown attacks'). The action to take is clear: look at Figure 1 for the missing information.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1' as the location of the missing information, and it also specifies the type of information: 'accuracies of the target model using different defenses against the FGSM attack'. This clearly identifies the section and content the authors should focus on.", "verifiability_rationale": "The comment contains a claim ('it is unclear the difference between the known attacks and the unknown attacks') and provides some implicit justification by stating that the *lack of information in Figure 1* is the reason for this uncertainty. However, it doesn't explicitly provide examples or references to back up this claim.", "helpfulness_rationale": "The review point directly points out a specific weakness in the paper (the missing information in Figure 1) and explains *why* this weakness is important (it hinders the understanding of the difference between known and unknown attacks). While it doesn't propose a solution, it is a clear diagnostic comment that guides the authors to a specific area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem 'Some figures are hard to read' and provides a concrete action to improve it by suggesting 'consider using a logscale'. This is a clear and actionable step for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly identifies the issue as 'Some figures are hard to read', which is a specific observation about the paper's content. The suggestion to use a 'logscale' is also a specific action to try. The authors can directly identify the problem and the proposed solution.", "verifiability_rationale": "The review point contains a claim that some 'figures are hard to read'. The suggestion to use a 'logscale' provides a justification for this claim by offering a concrete method to potentially address the issue. While it doesn't guarantee the figures will be perfectly readable, it offers a clear direction for improvement.", "helpfulness_rationale": "The review point directly identifies a clear weakness ('Some figures are hard to read') and offers a specific and actionable suggestion ('consider using a logscale') to improve it. This provides the authors with a concrete next step to take to address the identified problem."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a weakness in the paper but does not explicitly state what the authors should do to address it. The criticism is presented as a finding rather than a direct instruction for improvement.", "grounding_specificity_rationale": "The reviewer mentions the 'case where augmentation information is useful' and 'example cases flowers and birds,' which points to a general idea in the paper. While they don't explicitly name a section or table, they do identify a specific area of the paper being discussed.", "verifiability_rationale": "The reviewer makes a claim that the claim in the introduction ('augmentation information is useful') was not validated in the experiment. This claim could be supported by referencing the experimental setup and results (or lack thereof) and suggesting specific datasets for validation.", "helpfulness_rationale": "The reviewer identifies a specific weakness in the paper (lack of validation) and suggests a concrete way to address it (using specific datasets). This provides the authors with a direction for improvement, even if the exact steps are not fully specified."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the problem: 'However, there are no theoretical analyses, and it is unclear from empirical evaluations that GEMS converges to Nash equilibrium'. It identifies the missing elements but does not specify how to address this lack of analysis or how to make GEMS converge to Nash equilibrium. The action is identified but not made concrete.", "grounding_specificity_rationale": "The comment explicitly refers to 'those opponents' and 'the Nash equilibrium' within the context of the GEMS framework. It also mentions 'theoretical analyses' and 'empirical evaluations', which are specific aspects of the framework. The authors can identify the specific parts being addressed.", "verifiability_rationale": "The comment contains a claim that 'there are no theoretical analyses' and 'it is unclear from empirical evaluations that GEMS converges to Nash equilibrium'. It provides some justification by stating what is missing. However, it does not suggest specific methods or references for conducting these analyses or evaluations. The claim is supported by identifying the gap but lacks specific examples or references to back up the claim.", "helpfulness_rationale": "The comment is relevant to understanding potential limitations of the GEMS framework and encourages authors to investigate the theoretical foundations and empirical validation of their claims. It points to a potential area for improvement by highlighting the lack of analysis. However, it does not provide specific steps or suggestions on how to conduct the suggested analyses."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the issues with Equation (1): unclear purpose, potential mixup between loss function and optimization problem, and unusual constraint notation. These are concrete statements about what's wrong and are actionable for the authors to clarify or correct.", "grounding_specificity_rationale": "The reviewer *explicitly* refers to \"Equation (1)\". This is a very strong example of explicit grounding. The authors know *exactly* which part of the paper is being criticized. Furthermore, the reviewer *specifically* lists the issues: unclear purpose, potential mixup, and unusual constraint notation. These are concrete details about what's wrong with that equation.", "verifiability_rationale": "The reviewer makes a claim that Equation (1) is unclear and mixes concepts. While the reasoning for this claim is present (pointing out the potential mixup and unusual notation), it could be more robust with explicit definitions or examples. The reviewer attempts to justify their claim by explaining the potential confusion.", "helpfulness_rationale": "The reviewer's point is very specific and directly addresses a potential ambiguity in a mathematical formulation. This is likely to be very helpful for the authors in understanding and implementing the method. By pinpointing the exact equation and the specific issues, the reviewer provides targeted feedback that is actionable and grounded in the paper's content."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a question and requests 'explanations' to understand why adding LIVEN data worsens NMT performance. This constitutes an explicit action, as the reviewer is directly asking for information to apply to the authors' situation. However, the request for 'explanations' is quite general and lacks specific details on what kind of explanations are needed or how to interpret them. Therefore, while the action is explicit, the concreteness of the action is limited.", "grounding_specificity_rationale": "The reviewer refers to 'line 257' and 'LIVEN parallel data' when making the suggestion. While they don't explicitly state the exact content of line 257, they imply it's relevant to their question. This suggests a level of grounding, as the reviewer is referencing a specific part of the paper. However, the grounding is not fully explicit, as the reviewer doesn't provide the exact content or a clear indication of which specific aspect of line 257 they are referring to. The specificity of the suggestion is also limited, as the reviewer doesn't specify what they mean by 'why it makes the NMT system perform worse' or what specific aspects of the LIVEN data might be causing this issue.", "verifiability_rationale": "The reviewer requests 'more discussions/explanations' to understand why adding LIVEN data worsens NMT performance. This can be considered a form of 'claim' as the reviewer is making a suggestion based on their understanding or observation. The 'verification' comes from the request itself, as the authors would need to look into the provided explanations to understand the issue. However, the request is quite general and doesn't provide specific examples, references, or logical reasoning to support the claim. The verifiability is therefore limited, as the authors would need to conduct further investigation to validate the reviewer's point.", "helpfulness_rationale": "The reviewer directly addresses a potential issue identified by the authors (the performance drop) and requests further explanation. This is a clear and actionable suggestion aimed at improving the authors' understanding and potentially addressing their confusion. The request for 'explanations' makes it 3, as it provides a direction for the authors to investigate and potentially improve their model. However, the request is quite general and doesn't offer specific guidance or potential solutions, making it 3 but not 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states \"the paper provides some unsubstantiated conjectures about the 'finetuning as exposure of existing capabilities in LMs'.\" This points to a potential issue in the paper. However, it does not explicitly state what the authors should do about this, nor does it provide specific steps or actions to take. The action is implied but not clearly defined. For example, it doesn't specify whether the authors should look for evidence in the methods or the results section, or what kind of analysis they should perform. Therefore, while the issue is identified, the specific action and how to implement it are not clearly laid out.", "grounding_specificity_rationale": "The review point mentions \"the 'finetuning as exposure of existing capabilities in LMs'\" without specifying which part of the paper this refers to. The reviewer cannot confidently identify the section, table, figure, or unique aspect of the paper being addressed. The reference is vague and general. For example, it doesn't point to a specific section in the paper or any particular data or argument related to this concept. Therefore, the grounding of the reference is weak.", "verifiability_rationale": "The review point makes a claim: \"the paper provides some unsubstantiated conjectures about the 'finetuning as exposure of existing capabilities in LMs'.\" However, it does not provide any evidence, reasoning, or references to support this claim. It presents the statement as if it were a fact without any logical justification or external references. The verifiability is low because there is no basis for accepting or rejecting this statement. For example, there are no citations to external works or logical arguments within the review point itself to back up this assertion. Therefore, the claim is not wellsupported.", "helpfulness_rationale": "The review point identifies a potential issue in the paper regarding the connection between finetuning and existing capabilities in LMs. However, it does not provide any specific guidance or suggestions on how the authors should address this issue. The review points out a problem but doesn't offer concrete steps or insights on how to investigate or resolve it. For example, it doesn't suggest specific experiments, analyses, or comparisons that the authors should perform. Therefore, while the problem is highlighted, the feedback lacks actionable steps for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a potential improvement by including NaturalSpeech 3 as a baseline, which could be an action, but it doesn't explicitly state how to implement or compare it with FACodec.", "grounding_specificity_rationale": "The review point suggests including NaturalSpeech 3 as a baseline but doesn't specify where in the paper this should be discussed or what aspects of the comparison should be made.", "verifiability_rationale": "The review point is not a claim that requires verification. It's a suggestion for future work or an addition to the related work section.", "helpfulness_rationale": "The review point suggests a potentially useful addition (NaturalSpeech 3) to the existing work (FACodec), which could be helpful for the authors in future research or as a related work section."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their opinion about the unfairness of the experimental setup. They suggest that the proposed method's use of 4 weeks of data for inference should be used for training other methods. While they don't explicitly say 'You should train other methods on this data,' the implication is clear and directly points to a potential improvement in the experimental design. This constitutes an explicit action or suggestion.", "grounding_specificity_rationale": "The reviewer mentions '4 weeks of data for inference' and 'training other methods'. This clearly identifies the specific aspect of the paper being addressed, making the grounding strong. They also specify what needs to be done \u2013 training on this data. However, they don't explain *why* this is a problem or how it should be addressed beyond the suggestion itself.", "verifiability_rationale": "The reviewer makes a claim about the unfairness of the experimental setup. They state, 'If the proposed method has first 4 weeks data for inference, then other methods should use them for training  it is just the proposed method can't train with them.' This is a claim that needs to be supported. While the reviewer suggests a logical solution, they don't provide external references or concrete examples to back up the claim that the proposed method's inference data should be used for training other methods. The reasoning is present but lacks external validation.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improving the experimental setup. They identify a potential flaw in the current setup and propose a concrete change \u2013 training other methods on the data currently used for inference by the proposed method. This is a direct and actionable suggestion that could significantly impact the fairness and validity of the experiments. While the reviewer doesn't explicitly point out a problematic part of the paper, their suggestion directly addresses a potential issue within the experimental design."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'The paper should also report results on the speedup obtained compared to the dense and SparseGPT models...'. This action is also concrete, as it specifies the experiment to be performed and the parameters to be varied (model size and sparsity category). The reviewer clearly indicates what the authors should do and provides the details of how to do it.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly mention a specific section, table, figure, or unique aspect of the paper that necessitates this speedup experiment. While the reviewer implies that this experiment is important for evaluating efficiency, they do not pinpoint the exact location or specific detail within the paper that would benefit from this analysis. Therefore, the grounding is weak, as the authors would need to infer the relevance of this experiment.", "verifiability_rationale": "The claim in the review point is that the paper should include results on speedup compared to dense and SparseGPT models. This claim is 3 because the reviewer provides a clear suggestion for an experiment that would be relevant to the paper's topic (efficient inference). However, the claim lacks specific references to external works or detailed explanations of *why* this experiment is crucial for the paper's contribution. The reviewer assumes the authors would find this experiment useful, but doesn't provide explicit justification or citations to support this claim.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the authors: they should include results on the speedup of their model compared to dense and SparseGPT models. While the grounding is weak (as explained above), the suggestion is directly relevant to improving the paper's evaluation of efficiency. It points to a specific area where the authors could strengthen their analysis and provide a more comprehensive comparison of their model's performance. This level of guidance is generally considered helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer implies an action of investigating the impact of sequential bias on VisDial results but does not provide specific steps or details on how to do so. The action is implied rather than explicit and concrete.", "grounding_specificity_rationale": "The reviewer mentions 'VisDial results' generally but does not specify which part of the results or why they are concerned. The reference is broad and lacks precision, indicating a lack of grounding. The specificity of the concern is also lacking as the reviewer does not detail the nature of the issue.", "verifiability_rationale": "The reviewer makes a claim about the impact of sequential bias on VisDial results but does not provide any supporting evidence, examples, or references. The claim is presented without any logical reasoning or justification, making it 1.", "helpfulness_rationale": "The reviewer raises a valid concern about a potential limitation of VisDial. However, their suggestion for improvement is very general ('to investigate further') and does not offer specific directions or actionable steps. The helpfulness is limited as the reviewer does not provide concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a trend in the experimental results, indicating that LTAP performs better than ATO and RReg for head classes and worse than ATO and RReg for tail classes. This is an explicit observation. However, the reviewer does not specify which head or tail classes exhibit this behavior, nor does they suggest concrete actions for the authors to take to address this issue. The action is implied but not explicitly stated or detailed.", "grounding_specificity_rationale": "The reviewer refers to 'experimental results on the ImageNetLT dataset,' which is a specific reference. They also mention 'head classes' and 'tail classes,' which are specific categories within the dataset. This strong referencing of specific parts of the paper and the observed differences in performance between these parts demonstrates high grounding specificity. The comment clearly identifies the issue within the referenced dataset and specifies the performance differences between head and tail classes.", "verifiability_rationale": "The reviewer makes a claim: 'there appears to be a contradiction between the stated goal of strengthening parameter protection for tail classes in LTAP and the observed performance improvements.' This constitutes a claim. The reviewer's claim is supported by the observed trend in the results, which is logical reasoning. However, the reviewer does not provide specific examples of the performance differences or external references to back up their claim. While the reasoning is present, the lack of specific examples or external support makes it 3.", "helpfulness_rationale": "The reviewer points out a potential inconsistency between the experimental results and the stated goal of LTAP. This observation is relevant to the authors and highlights a potential area of confusion or a need for further clarification. While the reviewer identifies a problem, they do not offer specific, actionable steps for the authors to take to address it. The feedback is present but lacks concrete guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out a reliance on LLMs for reward computation, which implies an implicit action (identifying a problem) but doesn't explicitly state how to address it. The authors are informed about the issue but not directly guided on how to resolve it.", "grounding_specificity_rationale": "The review criticizes the reliability of LLMbased evaluation but doesn't specify which part of the evaluation process or the generated documentations is affected. It broadly states the concern without pinpointing the exact area of the paper being evaluated.", "verifiability_rationale": "The review states a concern about the reliability of LLMbased evaluation but does not offer any claims or evidence to support this concern. It presents a problem without providing any justification or analysis.", "helpfulness_rationale": "The review raises a potential issue (reliance on LLMs) without offering any constructive suggestions or analysis of how this impacts the authors. It's a critique of a potential problem, not a helpful suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points to 'more empirical examples' and 'comparing to SOTA performance' as areas for improvement. While they suggest a *method* (Eq 12) for this, the *specific actions* to take are not explicitly stated. The reviewer also states 'Eq 12 might do some of this, but it is extremely unclear', indicating a lack of concrete steps based on Equation 12.", "grounding_specificity_rationale": "The reviewer mentions 'more empirical examples' and 'comparing to SOTA performance' and even refers to 'Eq 12'. This indicates that they can identify specific parts of the paper they are referring to. However, they do not specify *what* these empirical examples should be, *how* to compare to SOTA, or *what* the expected outcome should be. The reference to Eq 12 is also vague.", "verifiability_rationale": "The reviewer states 'Eq 12 might do some of this, but it is extremely unclear' as a claim. However, they do not provide any evidence or justification for this claim. There is no logical reasoning, common knowledge, or external references to support this assertion.", "helpfulness_rationale": "The reviewer identifies a problem (unclear Eq 12) and suggests improvements (more empirical examples, SOTA comparison). However, the specific actions and guidance they offer are vague. They do not tell the authors *how* to make Eq 12 clearer or *what* empirical examples or SOTA comparisons would look like."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explains what they find difficult about the problem and mentions the assumption about hidden observations. However, they do not explicitly state the next step the authors should take to address this difficulty or how to implement the suggested changes. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer uses phrases like \"a constant alphafraction of the observations are hidden/removed,\" which implicitly refers to the data or the problem setup. However, they do not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The grounding is present but not fully explicit.", "verifiability_rationale": "The reviewer makes a claim that the assumption is restrictive and provides a justification by stating that the remaining data is sufficient for accurate recovery. This justification is present, making the claim verifiable. However, the explanation could be more rigorous and provide concrete examples or references to support the claim.", "helpfulness_rationale": "The reviewer points out a potential limitation or constraint in the problem setup by highlighting the constant alpha fraction of removed observations. This is a relevant feedback point for the authors, as it raises questions about the robustness and generalizability of their approach. While it doesn't directly provide a solution, it encourages the authors to consider the implications of their assumptions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a contradiction between a figure and a table. While the reviewer doesn't explicitly tell the authors what to do, they clearly point out a discrepancy, making it *somewhat* actionable.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 1' and 'the last two columns of Table 1', making it fully grounded. They also clearly state the nature of the contradiction, making it fully specific.", "verifiability_rationale": "The reviewer makes a clear claim of a contradiction between the figure and the table. While they don't provide proof, the contradiction itself is a verifiable statement.", "helpfulness_rationale": "The reviewer identifies a clear discrepancy between visual and tabular data, which is likely to be a significant issue for the authors. The comment is concise and directly points to the problem, making it 5 in guiding the authors to investigate the contradiction."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the method's extensibility and asks a question, but it does not explicitly state what action the authors should take. The concern is about the impact on shared parameters, but the specific action or solution is not provided.", "grounding_specificity_rationale": "The review point raises a concern about extensibility and asks a question about shared parameters. It does not explicitly identify a specific part of the paper or methodology being affected. The concern is general, not tied to a particular section, table, figure, or unique aspect.", "verifiability_rationale": "The review point raises a concern about a potential limitation of the method (extensibility) and asks a question. It does not contain a clear claim that can be verified. The concern is presented as a question, suggesting uncertainty rather than a definitive statement that needs justification.", "helpfulness_rationale": "The review point raises a valid concern about a potential limitation of the method (extensibility) and asks a relevant question. It provides context for the authors' thinking but does not offer a solution or concrete suggestions. It highlights a potential issue that the authors might be struggling with."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a potential inefficiency in the eyetracking analysis process (analyzing everything) and suggests a more selective approach (focusing on relevant parts of the sentence). While it doesn't explicitly state 'You should only analyze regressions to later parts of the sentence,' the implication is clear. The reviewer suggests a change in methodology, which is actionable but not entirely concrete as it lacks specific details on 'relevant parts'.", "grounding_specificity_rationale": "The comment is general about the eyetracking data selection and filtering process. It doesn't specify which parts of the paper or analysis are causing perplexity. The reviewer is commenting on the *process* of analysis rather than pinpointing a specific section or table. The authors are left to interpret what 'relevant parts of the sentence' means.", "verifiability_rationale": "The comment presents a potential issue (eyetracking data selection being perplexing) and offers a solution (focusing on relevant parts of the sentence). This can be interpreted as a claim that the current approach is problematic. The reviewer provides an alternative approach as evidence for their claim. The reasoning is practical but lacks specific references or examples to support the claim fully. It's 3 because it offers a justification, but it's not backed by concrete evidence or citations.", "helpfulness_rationale": "The review points out a potential inefficiency in the eyetracking analysis process and suggests a more targeted approach. This is a constructive suggestion aimed at improving the methodology. However, it lacks specific details on *which* parts to focus on or *how* to define 'relevant'. The suggestion is valuable but doesn't provide a complete solution or clear implementation steps, making it 3 but not entirely impactful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly names 'InitNO' and 'StableDiffusionv14' and points out a specific discrepancy in the 'textimage alignment' metric within the 'Appendix'. This is an explicit statement identifying a potential issue. Furthermore, the reviewer concretely states that 'InitNO\u2019s alignment is lower than that of StableDiffusionv14', providing a clear and actionable comparison.", "grounding_specificity_rationale": "The reviewer mentions 'Appendix' as the location of the claimed improved textimage alignment for 'InitNO'. However, they do not specify which section, table, or figure within the Appendix contains this information. While the general location is mentioned, the specific element is not explicitly identified, making the grounding somewhat implicit.", "verifiability_rationale": "The reviewer states that 'The credibility of Appendix results for InitNO is questionable' and 'Though the paper InitNO reported improved textimage alignment on StableDiffusionv14, Table 6 shows InitNO\u2019s alignment is lower than that of StableDiffusionv14.' However, the reviewer does not provide any external references, logical reasoning, or examples to support this claim. The statement is presented as a fact without any justification.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the authors: 'doublecheck the appendix'. This is a direct and helpful piece of feedback that guides the authors to investigate a specific part of their paper where a discrepancy has been identified. This helps them potentially uncover and address an implementation or reporting error."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests a concrete action: 'It may be worth considering dropping some of the sub/superscripts for convenience where possible'. This clearly indicates an actionable recommendation for the authors.", "grounding_specificity_rationale": "The review point mentions 'equations, the notation' as a specific area of concern, providing some grounding. However, it does not explicitly identify the specific equations, subscripts, or superscripts being addressed. The suggestion is general: 'dropping some of the sub/superscripts' without specifying which ones or how many. Therefore, while it touches on a specific topic, it lacks the precise identification of the problematic elements.", "verifiability_rationale": "The review point is a suggestion for improvement, not a claim requiring verification. It does not contain a statement that needs to be supported by evidence or logical reasoning. It is a practical suggestion, not a theoretical assertion.", "helpfulness_rationale": "The review point directly addresses a common issue for authors: the complexity of notation in equations. The suggestion to simplify notation is practically useful for improving readability and accessibility. While it doesn't provide a complete solution, it offers a concrete direction for the authors to consider. The mention of the tradeoff (loss of precision) also adds value by acknowledging potential consequences."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of detail and justification for the dataset size and cost, as well as the data collection process. While the information might be present in the paper, the reviewer's comments are vague and do not explicitly state what needs to be done. The reviewer's suggestions for improvement are not directly actionable, but rather point to areas where the authors should provide more detail.", "grounding_specificity_rationale": "The reviewer's comments are not explicitly pointing to a specific part of the paper or dataset. They are criticizing the *lack* of detail in the dataset description and the explanation of 'regulatory requirements'. The reviewer's comments are general and do not specify *which* aspects of the dataset are small or problematic. They also don't pinpoint the exact sections of the paper where 'regulatory requirements' are discussed.", "verifiability_rationale": "The reviewer's comments are not explicitly stating a claim that requires verification. They are pointing out weaknesses and suggesting improvements. While there's an implied claim that the dataset is limiting, it's not explicitly stated as a claim requiring verification. The reviewer's comments are more about identifying gaps in the information provided rather than making a claim that needs to be supported.", "helpfulness_rationale": "The reviewer's comments are constructive and point to specific areas for improvement. They are suggesting ways the authors could strengthen their analysis and provide more detail. While the feedback is not directly telling the authors *what* to do, it offers valuable insights and constructive criticism. The reviewer's suggestions are relevant to the paper's content and methodology."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their curiosity about the visualization and raises a specific concern about normalization, which is an implicit action to understand and address the issue. While the action is not directly proposing a solution, it is a clear indication that they are interested in this aspect of the paper.", "grounding_specificity_rationale": "The reviewer directly refers to 'the third column of Fig. 7,' which is a very specific part of the paper. This demonstrates strong grounding as the reviewer can easily identify the referenced section. The request for clarification on the normalization process further specifies the area of concern within that specific part.", "verifiability_rationale": "The review point does not contain a claim or suggestion. It is a question seeking information. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The review point identifies a potential issue (unclear visualization) and asks for clarification on a specific part of the paper. While it highlights a weakness, it does not directly propose a solution or provide sufficient information to resolve the issue. Therefore, it is 3 in pointing out a problem but lacks direct actionoriented content."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out the lack of rigorous investigation into the heuristic approach of assignment entropy maximization and suggests evaluating the benefits of this method. They also mention the absence of discussion on potential negative societal impacts. These are clear suggestions for improvement that authors can directly implement. The reviewer identifies specific areas for improvement and provides a clear direction for action.", "grounding_specificity_rationale": "The reviewer identifies specific areas within the work that could be further explored, such as the investigation of assignment entropy maximization and its benefits, as well as the discussion of potential negative societal impacts. They even suggest an ablation experiment for evaluating the benefits. While the reviewer doesn't explicitly state which part of the paper they are referring to when mentioning 'assignment entropy maximization,' the suggestion of an ablation experiment implies a clear understanding of where the investigation should focus. The reviewer also points out the lack of discussion on societal impacts, which is a specific area that needs attention.", "verifiability_rationale": "The reviewer states that the investigation of assignment entropy maximization is 'rather heuristic' and lacks 'rigorous investigation.' However, the reviewer does not provide specific evidence or reasoning to support this claim. They suggest evaluating the 'advantages' of using assignment entropy maximization but do not explain *why* this evaluation is needed or *how* it should be conducted. Similarly, the reviewer points out the absence of discussion on 'potential negative societal impacts' but does not provide any justification for why this is a concern or how it should be addressed. While the reviewer identifies gaps, they do not provide sufficient information to verify these gaps.", "helpfulness_rationale": "The reviewer provides clear and actionable suggestions for the authors. They suggest conducting a 'rigorous investigation' of assignment entropy maximization and evaluating its 'advantages.' They also recommend discussing the 'potential negative societal impacts' of the work. These suggestions are specific and directly address potential weaknesses or areas for improvement in the authors' work. The reviewer's comments are not vague; they offer concrete directions for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states the number of baseline models, which is '1'. This makes it directly actionable for the authors to check their own experimental section and verify this information. While it doesn't specify the *type* of baseline or how this impacts the results, it clearly identifies a factual piece of information that needs attention.", "grounding_specificity_rationale": "The comment explicitly refers to 'the experimental section' where the baseline models are located. This is a clear and specific reference, making it fully grounded. It also specifies the *number* of baseline models ('1'), which is concrete information about the content of that section.", "verifiability_rationale": "The comment makes a claim about the number of baseline models ('1'). While this claim can be verified by counting the baselines in the paper, it lacks deeper justification or reasoning. It doesn't explain *why* there's only one or what the implications are for the experimental results. Therefore, it's 3 as it points out a factual observation, but the *justification* is missing.", "helpfulness_rationale": "The comment identifies a potential limitation in the experimental design \u2013 the lack of multiple baseline models. While it points out this issue, it doesn't offer any specific advice on how the authors should address it or what steps they should take. The authors would still need to independently verify the number of baselines and then consider the implications of this limitation on their results."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point states 'some baselines and literature comparisons are missing' which is an implicit instruction for the authors to identify and include these elements. While it points out a gap, it doesn't explicitly state 'add X, Y, and Z' making it not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions 'baselines' and 'literature comparisons' generally without specifying which ones or where they should be found. This indicates a lack of precise identification, making it weakly grounded. While it points out a missing element, it doesn't specify what needs to be compared, making it not specific.", "verifiability_rationale": "The statement 'While comparison to traditional QAT is significantly more memory expensive' is a factual statement supported by common knowledge in the field. It doesn't present a claim that requires verification.", "helpfulness_rationale": "The review point identifies a missing element (baselines and literature comparisons) but doesn't actively guide the authors on how to add them or why they are important. It highlights a gap in information rather than providing concrete solutions."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks 'How to define attribute?' and 'What is the difference between attribute?'. These are direct questions that the author should be able to answer. The request is clear and directly addresses a potential point of confusion. The reviewer is asking for a definition and a comparison, which are concrete actions the author needs to perform.", "grounding_specificity_rationale": "The reviewer asks about 'attributes' generally, without specifying a particular section, table, figure, or unique element of the paper. The reference to 'attributes' is vague and does not pinpoint a specific part of the paper being addressed. The reviewer is asking about a general concept, not about something specific within the document.", "verifiability_rationale": "The reviewer is not making a claim. They are asking a question about a concept. Therefore, there is X to verify. The nature of the request itself is the evidence.", "helpfulness_rationale": "The reviewer is asking for clarification on a potentially confusing concept (attributes). While it doesn't directly point out a flaw, it's a valid request for improvement. Authors often need help understanding fundamental concepts. The request for more detailed instructions is a valid suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a limitation of the theory but does not explicitly state how to address this limitation or provide concrete steps for improvement. It's a statement of a problem, not a directive solution.", "grounding_specificity_rationale": "The review point is a general statement about the theory's ineffectiveness in addressing adversarial perturbations. It does not specify which part of the theory or which aspect of robustness is being criticized. The grounding is weak as the specific section or concept is not identified.", "verifiability_rationale": "The review point is a subjective assessment of the theory's limitations and does not contain a claim that requires verification. It's a statement of opinion rather than a statement of fact that needs evidence.", "helpfulness_rationale": "The review point identifies a limitation of the theory but does not offer any suggestions or guidance on how to improve the situation. It fails to provide actionable feedback to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their confusion about the term 'scenario\" and the concept of \"agnostic.\" While they don't provide specific details on what is unclear, they are pointing to areas where clarification is needed. This makes the comment 3 in that it points to a specific area for improvement. However, the lack of detail makes it less concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'scenario\" and \"agnostic,\" indicating that the comment grounds the feedback in specific parts of the paper or concepts. However, they do not specify *how* these are unclear or what needs to be addressed in them. This makes the grounding somewhat specific but lacking in detail.", "verifiability_rationale": "The reviewer states they are confused and ask for clarification. This is a request for information, not a claim that needs verification. Therefore, it does not fall under the verifiability aspect.", "helpfulness_rationale": "The reviewer directly asks for clarification on the unclear aspects of the paper. This is a very direct and helpful request for the authors. It immediately addresses a potential weakness and seeks to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer poses a question ('Why the method named after \"Maestro\"?') which implicitly suggests a lack of clarity or appropriateness of the naming. However, the action is not explicitly stated; the reviewer is inferring the need for explanation. The action is vague as it doesn't specify what needs to be explained or how the naming should be improved. Therefore, it's 2.", "grounding_specificity_rationale": "The reviewer states \"Why the method named after \"Maestro\"?\" without specifying which method they are referring to. The reference to \"Maestro\" could be many methods. The reviewer also doesn't explain *why* this method is named after Maestro or what makes it seem weird. The grounding is weak as the specific method is not identified, and the reason for the comment is not clearly explained. Therefore, it's 1 and Not Specific.", "verifiability_rationale": "The reviewer makes a claim: \"It is never introduced and seems weird to me.\" This is a subjective assessment. The reviewer doesn't provide any evidence or reasoning to support why the method hasn't been introduced or why its naming is weird. The claim is presented without sufficient justification or references. Therefore, it's 1.", "helpfulness_rationale": "The reviewer asks a question and provides a reason for it ('It is never introduced and seems weird to me'). This suggests they are highlighting a potential issue or area of confusion that the authors might not have considered. While it doesn't directly offer a solution, it points to a specific area that needs attention. Therefore, it's 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that some points are 'slightly overclaimed'. While the reviewer identifies a potential issue, the action of correcting this is somewhat vague. The reviewer *knows* some points are overclaimed, and *knows* the proposed method doesn't consider feedforward layers. The vagueness lies in the 'slightly overclaimed' part.", "grounding_specificity_rationale": "The reviewer's comment, 'Some text is described as if the proposed method considers all components in transformer networks,' directly identifies a specific aspect of the paper (transformer networks and their components) where the description might be inaccurate. The reviewer is pinpointing a section and its characteristics. However, the reviewer cannot confidently determine which part the comment addresses. Further, the comment clearly specifies what needs to be addressed in this part (the lack of consideration for feedforward layers).", "verifiability_rationale": "The claim that 'some points are slightly overclaimed' is not supported by any evidence or justification within the review point. The reviewer states this as a judgment, but doesn't provide any logical reasoning, common knowledge, or external references to back it up. The description of the proposed method as considering 'all components in transformer networks' is presented as a fact, not necessarily a flaw supported by evidence.", "helpfulness_rationale": "The review point identifies a potential mischaracterization of the proposed method. While it points out a problem, it doesn't offer a specific suggestion for improvement or provide a strong justification for the overclaiming. The reviewer *identifies* the *potential error* but doesn't offer a concrete solution or strong reasoning for it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out the lack of motivation for the chosen experimental design but does not explicitly state what actions the authors should take or how to implement these actions. While the reviewer identifies a problem, the specific steps to address it remain unclear.", "grounding_specificity_rationale": "The reviewer mentions 'experiments design' and specific finetuning methods, which could be considered a form of grounding. However, the reviewer does not specify what is wrong with the 'no variations' or 'up to 18 games' finetuning methods, nor does the review point clearly identify the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer states that the experiments design is 'not clearly motivated' but does not provide any evidence or justification for this claim. There is X extraction or logical reasoning provided to support the statement.", "helpfulness_rationale": "The review point identifies a potential issue with the experimental design but does not offer any specific recommendations or explanations to address this issue. The feedback is primarily a diagnosis without a cure."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing modality cases (MissV, MissA) and the concept of testing under different missing ratios. It suggests that the method's performance should be evaluated under these conditions. This provides a clear direction for improvement, making the action explicit and concrete.", "grounding_specificity_rationale": "The review point refers to the method's performance and the tables where results are missing. While it doesn't explicitly name the specific section or table, the context implies a focus on the results presented in tables 1 and 2. This can be considered weakly grounded as the reviewer understands the context of the results being discussed. However, the specific nature of the missing results (MissV and MissA) and the suggestion to test under different missing ratios are clear, making it somewhat specific.", "verifiability_rationale": "The review point makes a claim about the method's performance not being wellevaluated under missing modality cases. This claim is verifiable based on the reviewer's understanding of the experimental setup and the missing information in the tables. The reasoning is clear and directly points to a specific area for improvement.", "helpfulness_rationale": "The review point clearly identifies a weakness in the paper's evaluation \u2013 the lack of testing under different missing modality scenarios. This directly helps the authors understand a limitation of their work and provides a direction for future improvement. The suggestion to test under different missing ratios is a concrete and actionable piece of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a change is needed: \"Including ablation study on the effect of using image feature would be needed.\" This clearly indicates an actionable suggestion. The action is to include an ablation study, which is a concrete and direct request.", "grounding_specificity_rationale": "The reviewer specifically points out a problem related to \"the conditions\". This demonstrates strong grounding as the reviewer can accurately pinpoint the part of the paper being addressed. The suggestion to \"include an ablation study on the effect of using image feature\" further clarifies the specific issue and the proposed solution.", "verifiability_rationale": "The review point makes a claim about the current state of the conditions: \"even those conditions are not changed during browsing the web shop.\" This is a verifiable statement. The suggestion to \"Including an ablation study on the effect of using image feature would be needed.\" provides a clear and logical way to verify this claim. An ablation study is a standard experimental method to determine the impact of a specific feature.", "helpfulness_rationale": "The review point is highly specific and directly addresses a potential weakness in the paper: the lack of change in conditions during web browsing. The suggestion to include an ablation study is a clear and actionable step that would directly help the authors improve their draft by verifying the impact of image features. The reviewer's point is welldefined and provides a concrete direction for improvement."}
{"actionability_label": "Not Applicable", "grounding_specificity_label": "2", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, not a directive, so it does not provide explicit instructions on what the authors should do. It's a query prompting further investigation, not a clear instruction.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper being addressed. It's a general question about the model's performance in challenging settings without referencing any specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The review point is a question, not a claim that needs verification. While the reviewer's expectation that the paper will demonstrate performance in challenging settings is an implicit assumption, the review point itself doesn't contain a claim requiring evidence.", "helpfulness_rationale": "The review point raises a relevant question about the model's performance in challenging settings and suggests exploring different architectures. While it doesn't directly tell the authors how to improve, it points towards a valuable area of exploration and highlights a potential limitation of the current work."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the authors' misunderstanding of identifiability. It identifies the specific issue (authors' incorrect understanding) and implies the consequence (lack of identifiability due to insufficient data). This is an explicit action that the authors can take to reevaluate their understanding.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper or a specific issue. It is a general statement about the authors' understanding of identifiability. The grounding is conceptual rather than pointing to a specific section or detail.", "verifiability_rationale": "The comment itself does not contain a claim that needs to be verified. It is a statement about the authors' understanding. However, it sets up a scenario where the authors might make a claim about their model's identifiability later, making it indirectly related to verifiability in that context.", "helpfulness_rationale": "The comment is helpful because it identifies a crucial error in the authors' understanding of a fundamental statistical concept. This correction can guide the authors in revising their approach and potentially their model. While it doesn't provide a direct solution, it highlights a significant issue that needs attention."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states a finding ('the results show no particular benefit...') but does not provide any explicit or implicit instructions for the authors on what to do next. There are no concrete actions or suggestions for improvement.", "grounding_specificity_rationale": "The review point is very general, referring to 'the results' without specifying which part of the paper or experiment is being discussed. It also doesn't point to a specific section, table, or figure.", "verifiability_rationale": "The review point makes a claim ('the results show no particular benefit...') but does not provide any evidence, references, or logical reasoning to support this claim. While it suggests a potential improvement ('It would be beneficial to explore alternative baselines'), this suggestion is not tied to the identified claim and lacks specific details.", "helpfulness_rationale": "The review point identifies a potential weakness ('no particular benefit') and suggests a general improvement ('explore alternative baselines'). However, it lacks specific, actionable steps for the authors to take to investigate this further. The suggestion is too broad and lacks concrete details on how to implement the improvement or what specific changes to make."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out specific implementation details of the method, such as the need for a vocoder pretrained on 60khour LibriLight and the lack of information on GPU hours for the pretraining process. They also highlight the difference in speed between the diffusionbased vocoder and DSP/WarpNet. These are explicit actions or suggestions that the authors can directly implement or address. For example, the authors could request the time cost data or consider optimizing the diffusionbased vocoder for faster inference. The reviewer also mentions the potential for slower inference speed, which is a direct action the authors could take to improve their draft by addressing this limitation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'WaveFiT vocoder,' 'LibriLight dataset,' and 'GPU hours' in the context of the training process. This provides clear grounding as the reviewer identifies specific parts of the paper being addressed. Furthermore, the reviewer implicitly refers to the 'waveform space' in the inference process, indicating an understanding of the specific aspect being discussed. While not a direct mention of 'waveform space,' the context implies a specific area of the paper. The reviewer's focus on the training and inference processes further clarifies the specific aspects being addressed.", "verifiability_rationale": "The reviewer makes a claim about the efficiency of the method, stating that training requires a vocoder pretrained on 60khour LibriLight and training a WaveFiT vocoder from scratch, lacking information on GPU hours. They also claim that the inference process, incorporating a diffusionbased vocoder, will result in slower inference speed compared to DSP and WarpNet. This claim is supported by the information provided about the training process and the nature of waveform space. The reviewer logically connects the need for pretrained models in training to the potential for slower inference in the inference phase. The claim about slower inference is directly supported by the description of the diffusionbased vocoder's operation in the waveform space.", "helpfulness_rationale": "The reviewer provides specific and actionable feedback regarding the implementation details of the method. They highlight the need for time cost information during the pretraining phase and point out the potential for slower inference speed in the inference phase. These are concrete suggestions that the authors can directly address to improve their draft. The reviewer's comments are not vague or general; they directly point out specific areas where the authors' work could be improved. The information provided by the reviewer is directly relevant to the authors' goals of optimizing their method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a limitation ('such generalization is not explored') regarding a specific aspect of the framework (generalization of the scoring function). This indicates a clear action the authors could take: to investigate and implement this generalization. The statement also suggests a specific area for improvement (the framework itself). The reviewer proposes a concrete action: 'exploring it'.", "grounding_specificity_rationale": "The review point mentions 'generalization of the scoring function' and 'gold document' without specifying the exact location or element within the framework that is lacking grounding. While it identifies a potential area for improvement, it doesn't clearly point to a specific section, table, figure, or unique aspect of the paper that needs addressing. The reviewer is speculating about a future extension rather than pinpointing a current, identifiable gap. The comment lacks a clear connection to a specific part of the paper being discussed.", "verifiability_rationale": "The review point does not present a claim that requires verification or support. It is a suggestion for future work rather than a critique of the current state of the paper. There is no logical reasoning, common knowledge, or external references provided to support any claim. The statement is a limitation and a suggestion, not a claim that needs to be proven.", "helpfulness_rationale": "The review point identifies a potential limitation of the framework and suggests exploring this limitation. While this is a constructive suggestion for improvement, it does not directly critique the current state of the authors' draft. It does not point out specific errors, missing information, or areas needing immediate attention. The comment is forwardlooking and does not offer immediate help in improving the current draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to include 'success rate at each conversation turn' in the framework's evaluation. This is a direct action, making it explicit. Furthermore, the reviewer specifies the location of this information, namely 'at each conversation turn,' which provides a concrete detail on where the success rate should be included. The action is also concrete, as the reviewer clearly states what they want to include and where.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'success rate at each conversation turn' in the review point. This directly identifies the specific metric and the specific point in the conversation process where this metric should be evaluated. The comment is not only identifying a specific part of the paper (the evaluation process) but also specifying the exact location within that part (each conversation turn). This constitutes full grounding as the section, table, figure, or unique aspect being addressed is precisely identified.", "verifiability_rationale": "The reviewer states their suggestion clearly and provides a brief justification: 'This data can offer insights into the framework's comparative performance throughout the recommendation process, helping readers to assess its effectiveness in a more nuanced manner.' While the reviewer doesn't provide a citation or a detailed explanation of how this success rate would be calculated, the statement itself is logically sound and provides a basis for verification. The reviewer is making a claim about the value of this data, and the reasoning, while brief, is understandable and logical.", "helpfulness_rationale": "The reviewer clearly states their intention and provides a rationale for why this information is valuable. They suggest including 'success rate at each conversation turn' to 'offer insights into the framework's comparative performance throughout the recommendation process, helping readers to assess its effectiveness in a more nuanced manner.' This is a direct and actionable suggestion for the authors, making it 5. The reviewer is not just pointing out a problem but also offering a concrete solution and explaining its potential benefits."}
{"actionability_label": "5", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem of the paper being dense and suggests a concrete solution by recommending the use of actual lists instead of numbered lists where appropriate. This indicates a clear action that the authors can take to improve their draft.", "grounding_specificity_rationale": "The reviewer mentions 'the paper in general' and 'numbered lists in the paragraphs' but does not specify a particular section, table, figure, or unique aspect of the paper. While they identify the type of element, they lack the precision to pinpoint the exact location and the specific issues with it. The comment specifies what needs to be addressed (numbered lists) but not where exactly in the paper.", "verifiability_rationale": "The reviewer makes a claim about the paper being 'very dense' and suggests that 'numbered lists in the paragraphs might be easier to read as actual lists.' While the suggestion is a potential improvement, the claim about the paper's density and the specific issue with numbered lists lacks supporting evidence or logical reasoning. There are no external references provided to back up these claims.", "helpfulness_rationale": "The reviewer identifies a valid issue (paper density and the potential benefit of using actual lists) and offers a suggestion. However, the feedback lacks specific details on *how* the density affects readability or *why* a particular numbered list is hindering understanding. The suggestion is general and could be expanded upon to be more helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment implies an action by suggesting the authors investigate spectral cues, but it doesn't explicitly state what needs to be done or provide specific steps. The phrasing 'begs the question' suggests a desire to understand the underlying mechanisms, which could involve investigating spectral cues, but the exact action is not defined.", "grounding_specificity_rationale": "The comment does not refer to a specific part of the paper or identify a particular issue. It is a general question about the mechanisms of classifiers and fake image detectors. There is no mention of a specific section, table, or figure in the paper being discussed.", "verifiability_rationale": "The comment presents a hypothesis or question ('whether other 'fake image detectors' are fundamentally using the same spectral cues'). This can be considered a claim that requires verification. However, the review point itself does not provide any evidence or reasoning to support or refute this claim. The suggestion to investigate spectral cues is a potential verification method, but the claim itself is not directly verified within the review point.", "helpfulness_rationale": "The comment raises a relevant question about the underlying mechanisms of classifiers and fake image detectors. It could potentially guide the authors to further research or investigations. However, it doesn't directly point out specific weaknesses in the authors' draft or provide concrete suggestions for improvement. It's more of an exploratory question than a direct critique or solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a problem with visualization quality compared to the ground truth. However, it lacks a direct, actionable suggestion on how to improve the visualization. The request for analysis is vague and doesn't specify a concrete area within the authors' paper to address.", "grounding_specificity_rationale": "The review point mentions a specific research area (Classincremental learning for semantic segmentation reusing neither old data nor old labels) but doesn't explicitly refer to a specific part of the authors' paper. The request for analysis is general and doesn't target a particular section or figure in the authors' draft.", "verifiability_rationale": "The review point identifies a claim that the visualization results are 'terrible' compared to the ground truth. However, it doesn't provide any specific evidence or reasoning to support this claim. The statement is a subjective observation without justification.", "helpfulness_rationale": "The review point requests an analysis of satisfied and terrible cases. While relevant, this is a request for information rather than a direct, actionable suggestion on how to improve the authors' draft. It doesn't provide specific steps or concrete advice."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point mentions 'limitations or issues in those previous works' but does not explicitly state what these limitations are or how they impact the current work. While the reviewer points out a 'similar implementation process to previous work on GAN,' they do not specify which aspects of the implementation are similar or how this similarity might be problematic. The lack of explicit action or suggestion makes it difficult for the author to take concrete steps based on this feedback.", "grounding_specificity_rationale": "The review point mentions 'a large body of previous work' and 'limitations or issues in those previous works' but does not specify which particular work or which specific aspect of those works is being referenced. The reviewer also mentions a 'similar implementation process to previous work on GAN' without pinpointing the exact similarity or the specific impact on the current work. The lack of specificity in identifying the relevant part of the paper makes it difficult to understand the exact issue being raised.", "verifiability_rationale": "The review point contains the claim 'The actually implementation process is similar to previous work on GAN.' This claim is not supported by any evidence or logical reasoning within the review point. The reviewer states a similarity but does not provide any justification or examples to back this claim up. Without verifiable support, the claim remains speculative and lacks a basis for action.", "helpfulness_rationale": "The review point raises a concern about the paper's reliance on previous work and the similarity to GAN implementations. However, it lacks specific details and actionable suggestions. While the reviewer identifies a potential issue, they do not provide concrete steps or explanations of why this similarity might be problematic. The lack of specific and actionable feedback makes this review point less helpful for guiding improvements to the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer directly asks a question about a potential improvement to the policy selection process. They suggest incorporating information available during the clustering step (patient characteristics) that was not used during policy training. This is a clear and explicit suggestion of an action to be taken to improve the draft (policy training). The reviewer is asking for the authors to consider a potentially beneficial change.", "grounding_specificity_rationale": "The reviewer explicitly identifies the information available during the clustering step (patient characteristics) and explains why this information was not used during policy training. They are able to pinpoint the specific aspect of the paper being addressed (policy training) and provide details about the missing information. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer is not making a claim that can be verified or falsified with a single fact. They are posing a question about a design choice. Therefore, there is no verifiable claim in this review point.", "helpfulness_rationale": "The reviewer's question directly addresses a potential inefficiency in the policy selection process. They suggest that the information used for clustering could have been used to improve policy training. This is a relevant and actionable suggestion that could help the authors improve their draft. While it's a question, it's a question with a clear practical implication, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, not a suggestion or action. The reviewer is asking 'Appendix C: Why is NeRF's rendering quality worse than NeuS / Geo NeuS?' This is a request for information or an explanation, not a proposed change or action to be taken.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Appendix C' in their review point, indicating a clear identification of the section being referenced. However, they do not specify *what* is wrong with NeRF's rendering quality within that appendix. They are asking a general question about the comparison, not about a specific element within Appendix C.", "verifiability_rationale": "The reviewer presents a claim: 'NeRF's rendering quality is worse than NeuS / Geo NeuS'. However, they do not provide any evidence, reasoning, or references to support this claim within their review point. They are asking for an explanation, but not providing a basis for evaluating the claim itself.", "helpfulness_rationale": "The review point is a question intended to highlight a potential lack of clarity or detail in the original paper regarding the comparison of NeRF and NeUS/GeoNeUS. While the question is valid and could be helpful for the authors to understand the discrepancy, the review point itself does not offer a concrete suggestion or action. Therefore, it is not 5 on its own."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'This hints, that purely unsupervised large scale pretraining might not be suitable for NLP applications'. This directly points to a potential area for improvement. The phrase 'This hints that' suggests the reviewer is inferring a conclusion from an observation made in Section 3.7. While not a direct instruction on how to improve, it clearly identifies a potential weakness or area for discussion. The reviewer also points to a specific section (3.7) and specific types of pretraining (unsupervised large scale) and application (NLP), making the potential action quite concrete, even if the reviewer doesn't explicitly state what to do next.", "grounding_specificity_rationale": "The reviewer mentions 'Section 3.7' as the location of the observation. While this provides some grounding, it is a general reference and doesn't pinpoint the exact part of Section 3.7 where the observation is made. The reviewer also doesn't specify *what* is being hinted at within that section. Therefore, while the section is mentioned, it lacks the precision needed for full grounding.", "verifiability_rationale": "The reviewer expresses doubt about the conclusion 'purely unsupervised large scale pretraining might not be suitable for NLP applications', stating it is a 'very bold assumption'. This indicates a lack of sufficient evidence or justification within the manuscript to support this claim. The reviewer is questioning the *justification* for this conclusion, suggesting the evidence presented in Section 3.7 is not strong enough to make such a definitive statement. The claim is presented as an interpretation rather than a clearly supported fact or deduction.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the manuscript ('This hints, that purely unsupervised large scale pretraining might not be suitable for NLP applications') and suggests an alternative direction ('focusing on supervised learning'). While the review points out a potential issue, it doesn't explicitly state what the authors should do next. The reviewer is offering a suggestion, but it lacks specific details on how to implement the shift to supervised learning or what specific changes are needed. Therefore, while the review points out a potential problem, it doesn't offer a fully constructive and actionable suggestion for the authors to implement immediately."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing related work and provides concrete suggestions for improvement. The suggestions are direct and actionable, indicating a clear direction for the authors. The reviewer mentions specific sections and papers, making the suggestions clear.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific sections (2.1, 2.2), papers (A, B, DCN 18, CUB, 3), and aspects of related work (qualitatively and quantitatively, transductive label propagation) that should be included. The reviewer also suggests specific ways to address these missing elements, indicating high grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the missing related work and suggests ways to address it. While the reviewer doesn't provide evidence to *prove* the missingness, the suggestions for qualitative/quantitative discussion and inclusion in Table 3 provide implicit justification for how the information should be presented. The reviewer points towards a method of addressing the issue, making it 3.", "helpfulness_rationale": "The reviewer directly points out specific weaknesses in the related work section and provides clear suggestions for improvement. The suggestions are actionable and specific to the mentioned papers and aspects of related work. This makes the review very helpful for guiding the authors on how to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The comment explicitly states the error in Figure 2, identifying the incorrect addition operator and correctly points out that the Hadamard product should be used. The action is to replace the addition with the Hadamard product, which is a clear and specific action to take.", "grounding_specificity_rationale": "The comment explicitly mentions 'figure 2', clearly identifying the specific part of the paper being addressed. The comment also specifies what is wrong (addition) and what should be there (Hadamard product), making it highly specific within the context of Figure 2.", "verifiability_rationale": "The comment makes a claim about the incorrect operation in Figure 2. This claim is supported by the understanding of standard matrix operations, where addition and Hadamard product are distinct. While not explicitly citing external references, the logical reasoning based on common knowledge supports the claim.", "helpfulness_rationale": "The comment is highly specific, pointing out a clear error in Figure 2 and suggesting the correct operation. It provides a direct and actionable improvement for the authors to make, which is to replace the addition with the Hadamard product in the context of Figure 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states they 'acknowledge the authors' response' and 'acknowledged the improvement in the smoothness assumption'. This indicates a clear action taken by the reviewer to understand the authors' revision. Furthermore, the reviewer points out 'limitations are only partially addressed' and 'the discrepancy between the theoretical and practical updates of SABA', which are specific areas needing attention. The reviewer's tone suggests they found the authors' response informative and helpful.", "grounding_specificity_rationale": "The reviewer refers to 'weakness 2' and the 'finite sum assumption' and 'SABA update discrepancy'. While they mention the 'assumptions', they don't explicitly point to a specific section, table, or unique element of the paper. This makes the grounding somewhat weak. However, the reviewer does specify the *types* of weaknesses (partially addressed, discrepancy between theoretical and practical updates) and even gives a reason for the discrepancy (mentioned briefly, *not* properly addressed). This adds some level of specificity.", "verifiability_rationale": "The reviewer states 'The authors have thoroughly addressed my concerns in their revision and response.' This is a claim requiring justification. They also states 'In particular, concerning weakness 2, they now achieve optimal rates...'. This is another claim requiring justification. The reviewer provides *partial* justification by stating the authors *mention* the finite sum assumption in the abstract and the discrepancy briefly. However, they explicitly state it's *not* properly addressed. This shows an attempt to verify, but the level of detail in the verification is limited.", "helpfulness_rationale": "The reviewer explicitly states they 'increased the score from 7 to 8' after reviewing the authors' response. This indicates that the authors' response provided them with valuable information and improved their assessment of the paper. The reviewer also points out specific areas that were addressed (partially) and those that were not (the discrepancy between theoretical and practical updates). This suggests the review pointed to actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the claim about UnKE's supposed knowledge preservation and presents direct experimental results contradicting it. This is explicit and concrete, as the reviewer directly points out the discrepancy between the claim and the evidence in the tables.", "grounding_specificity_rationale": "The reviewer directly references UnKE and its claimed causedriven optimization. While the general concept of knowledge preservation might be implied, the specific method is mentioned. The reviewer also specifies the metrics (MMLU, SrcAcc, TgtAcc) used to measure knowledge retention and compares them to the baseline. This makes the grounding fully explicit and the specificity clear.", "verifiability_rationale": "The review point contains a claim that UnKE's ability to retain original knowledge is worse than the baseline. The reviewer provides specific experimental results (MMLU, SrcAcc, TgtAcc) from tables (Table 2 and Table 3) to support this claim. This provides logical reasoning and concrete evidence.", "helpfulness_rationale": "The review point identifies a clear discrepancy between the paper's claim about UnKE's knowledge retention and the experimental results. By pointing out the specific metrics (MMLU, SrcAcc, TgtAcc) and the tables where the lower performance is evident, the reviewer provides specific and actionable feedback to the authors. This helps them understand the issue and potentially revise their claims or explanations."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests looking at the appendix for more information, which is a suggestion rather than a direct action the author should take. Actionability requires the reviewer to specify what the author should do, not where to find information.", "grounding_specificity_rationale": "The reviewer mentions the 'Week explanation for the intention of BWTP/GLBW' but doesn't specify which part of the paper or explanation is unclear. They also don't provide specific examples of what is wrong with the current explanation. The comment is general and doesn't pinpoint the issue.", "verifiability_rationale": "The review point does not contain a claim or assertion that needs verification. It is a suggestion for improvement rather than a statement that requires evidence or justification.", "helpfulness_rationale": "The review point identifies a potential weakness (the explanation in the appendix) and suggests a solution (looking at the appendix). While it doesn't directly tell the author what to do, it points towards a concrete improvement. It could be helpful if the author follows the suggestion, but it's not definitively helpful *now*."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of 'include the proof' and provides a specific location 'at the very end of Section 3'. This is an explicit and concrete action with a clear target.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 3', which is a specific part of the paper. This indicates full grounding as the reviewer can directly identify the referenced section.", "verifiability_rationale": "The review point is a suggestion to include the proof, not a claim that something is missing or incorrect. There is no logical reasoning, common knowledge, or external references involved. It is a suggestion, not a verifiable claim.", "helpfulness_rationale": "The review point directly identifies a potential weakness (omitted proof) and provides a clear and actionable suggestion (include it in the revision). This is 5 for the authors as it directly addresses a potential gap in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement 'Since the NPPs lack any direct dependence on magnitudes, they perform worse than ETAS' is explicit in identifying a reason for the performance difference. However, it is somewhat vague in its application. While it states that NPPs lack dependence on magnitudes, it doesn't specify *which* magnitudes or provide a clear mechanism through which this lack of dependence leads to the observed performance difference. The action of identifying this lack of dependence is clear, but the subsequent action of explaining the performance difference based on this is not fully concrete.", "grounding_specificity_rationale": "The comment 'Since the NPPs lack any direct dependence on magnitudes, they perform worse than ETAS' does not explicitly identify a specific part of the paper or methodology being discussed. The reference to 'NPPs' and 'ETAS' is general and does not pinpoint a particular section, table, figure, or unique aspect of the paper. The comment is about the general performance of these models, not about a specific issue within a specific section. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The claim 'Since the NPPs lack any direct dependence on magnitudes, they perform worse than ETAS' is presented as a claim. However, the reasoning 'Since the NPPs lack any direct dependence on magnitudes' is a general statement and lacks specific examples or references to support the claim that NPPs *actually* perform worse than ETAS. There is no logical reasoning, common knowledge, or external references provided to back up the assertion about the performance difference. The claim is made without sufficient justification.", "helpfulness_rationale": "The review point 'Since the NPPs lack any direct dependence on magnitudes, they perform worse than ETAS' is not particularly helpful. While it identifies a potential reason for a performance difference, it lacks any supporting evidence or justification. The statement is presented as a general claim without providing any concrete examples or references. This makes it difficult for the authors to understand the basis for the criticism and how to address it. The lack of verifiability makes the comment less actionable and less valuable."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer correctly identifies the existence of Equations 3 and 4 outlining the connectivity patterns. However, the criticism lies in the *lack of explicit guidance* on *how* to apply these equations to the specific architectures (UNet, ResNet, MobileNet). While the equations themselves are explicit, the *steps* or *procedures* for their implementation are missing, making the action implicit rather than explicit. The reviewer's inability to proceed with the implementation due to this lack of clarity supports the idea that the action is not readily actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Equations 3 and 4' and then names the specific architectures 'UNet, ResNet, and MobileNet' where the implementation details are lacking. This demonstrates a clear and precise identification of the relevant parts of the paper being addressed. The reviewer can confidently pinpoint the section, tables, or unique aspects being discussed. Therefore, the grounding is strong.", "verifiability_rationale": "The reviewer states that the implementation details are 'unclear' and that there are 'serious problems' when trying to apply the connections to complex architectures. This constitutes a claim that the paper lacks sufficient justification or evidence. The reviewer provides logical reasoning (the lack of guidance makes it difficult) and implicitly references the absence of implementation details in the paper (Tables 1, 4, 5). While there are no direct external references provided within the review point itself, the *lack* of such references within the paper serves as implicit support. The claim is wellsupported by the reviewer's observation of the missing details.", "helpfulness_rationale": "The reviewer clearly identifies a significant issue: the lack of implementation details for the described connectivity patterns. This directly points to a weakness in the paper and is therefore a helpful criticism. However, the reviewer does not offer *suggestions* on how to implement these connections. They identify the problem but don't provide guidance on the solution. Therefore, while the review highlights a concrete area for improvement, it doesn't actively guide the author on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement directly points out a limitation of the current annotation method (reliance on automatic scripts) and suggests exploring alternative annotation methods like MQM and DA. This is an explicit action the authors could take. However, the suggestion is quite general and lacks specific details on how to implement these alternatives, making it somewhat vague on how to apply it.", "grounding_specificity_rationale": "The reviewer uses specific terms like 'HTER label,' 'automatic scripts,' 'MQM,' and 'DA' to pinpoint the issue and suggest a solution. This demonstrates strong grounding as the authors can easily identify the specific parts of the paper being discussed. However, the reviewer doesn't specify *why* automatic scripts are a problem for MQM and DA in other languages, making the specificity somewhat underdefined.", "verifiability_rationale": "The reviewer states a claim about the limitations of automatic scripts for scaling annotations. However, they do not provide any evidence or justification for this claim. There are no logical reasoning steps, common knowledge references, or external citations to support the statement.", "helpfulness_rationale": "The reviewer identifies a potential issue with the annotation process and suggests exploring alternative annotation methods. While this is a valuable feedback point, it lacks specific details on how to implement these alternatives. The feedback is helpful in identifying a problem but doesn't offer concrete solutions, making it somewhat limited in its helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The review point asks 'How does overall performance depend on $m$ in $G_m$?' which is a question about the relationship between a variable and a function. While it points to a potential issue, it doesn't explicitly state what needs to be done or how to address it. The reviewer is asking for clarification on the current implementation or analysis. This is a request for more information rather than a direct instruction on how to improve the draft.", "grounding_specificity_rationale": "The review point mentions '$G_m$' but does not specify which particular $G_m$ or where in the paper this function is defined. The variable '$m$' is also not explicitly linked to a specific part of the methodology or implementation. The grounding is weak because the reviewer cannot confidently determine which aspect of the paper they are addressing. The specificity is low because the issue is general (dependence on $m$) rather than a specific detail within a defined section or table.", "verifiability_rationale": "The review point itself does not contain a claim or a statement that requires verification. It is a question. While the answer to this question might be a claim (e.g., 'performance degrades with increasing $m$'), the review point itself lacks supporting evidence or justification. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The review point raises a relevant question about the dependence of performance on a variable within a function. This is a valid concern that could highlight a potential issue or area for improvement in the draft. While it doesn't directly provide a solution, it encourages the author to investigate the relationship between the variable, the function, and the overall performance. This can be a helpful prompt for the author to identify problems or areas for further analysis."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a 'theorypractice gap' and suggests a specific area for the authors to comment on. This is an explicit action. The reviewer clearly identifies 'sparse neural nets' and 'Farrell, Liang, and Misra ECTA 2021' as the specific area. This is concrete. The implied action is for the authors to read the suggested paper and consider how CausalStonet might relate to it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'sparse neural nets' and names a specific paper, 'Farrell, Liang, and Misra ECTA 2021'. This clearly grounds the discussion in a specific part of the paper and provides a concrete example. The reviewer also specifies the type of gap (theorypractice) in this context.", "verifiability_rationale": "The reviewer presents a claim: 'As we know, almost all theoretical works on deep learning do not reflect practice.' While this is generally true, it's a broad statement and could benefit from a citation (which the reviewer doesn't provide *in this point*). The suggestion to comment on another paper is also a claim requiring action. The reviewer provides a specific example (Farrell, Liang, and Misra ECTA 2021) and a related concept (difficult to fit sparse nets). This provides some support, but it's not a direct citation within this review point itself.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors. They are pointing to a specific area that could improve the paper's practical relevance. The suggestion is relatively easy to understand and directly relevant to the authors' work."}
{"actionability_label": "4", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem of the manuscript being densely packed and suggests concrete actions to address it, such as making tables smaller and relocating some to the Appendix. These actions are direct and actionable, indicating a clear understanding of how the authors can improve their draft. The reviewer also suggests reducing the size of certain figures, which are concrete actions the authors can take. The reviewer's suggestions are not implicit and require the authors to take specific steps to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'figures and tables' and their 'closeness to the text' as the specific part of the paper being addressed. They also suggest 'relocating some to the Appendix' and 'reducing the size of certain figures'. These are explicit references to specific elements of the paper, demonstrating a clear understanding of where the issues lie. The reviewer's suggestions are directly tied to these identified elements.", "verifiability_rationale": "The reviewer provides suggestions for improving the presentation of the manuscript, such as making tables smaller and relocating some to the Appendix. These suggestions are not claims that require verification. The reviewer is proposing actions rather than making statements that need to be proven or supported by external references. The reviewer's suggestions are practical and actionable, but they don't require any logical reasoning or external references to be considered valid.", "helpfulness_rationale": "The reviewer provides specific and actionable suggestions for improving the presentation of the manuscript. They identify the problem of the manuscript being densely packed and offer concrete solutions, such as making tables smaller, relocating some to the Appendix, and reducing the size of certain figures. These suggestions are directly linked to the identified problem and are likely to be helpful for the authors in improving their draft. The reviewer's comments are focused on practical aspects of formatting and layout, which are directly relevant to the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1 1", "helpfulness_label": "2 2", "actionability_rationale": "The reviewer states that the ReCPE method is 'too strategic' and 'intuitively proposed,' indicating an explicit action: criticizing the approach. However, the reviewer does not specify *how* to make it more strategic or *how* to improve it beyond suggesting exploring theoretical foundations. This lack of concrete steps makes the action somewhat vague and 1.", "grounding_specificity_rationale": "The reviewer criticizes the 'strategic' nature and the lack of a 'strong guarantee in theory' of the ReCPE method. While they identify the issue, they do not specify *which* part of the method or paper they are referring to. The criticism is general and does not point to a specific section, table, figure, or unique aspect of the ReCPE method. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim: 'the ReCPE method proposed in this article is too strategic' and 'there seems to be no strong guarantee in theory.' However, they do not provide any evidence, references, or logical reasoning to support these claims. They simply state the problems without offering any justification or examples. Therefore, the claim is 1.", "helpfulness_rationale": "The reviewer provides a critical assessment of the ReCPE method, highlighting its 'strategic' nature and the lack of a 'strong guarantee in theory.' While this points to a significant weakness, the reviewer does not offer any specific, actionable suggestions or steps to address these issues. The suggestion is too general and lacks concrete guidance. Therefore, the review is not particularly helpful in providing direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is an explicit question about the applicability of the work to generation tasks. While it directly asks for information, it doesn't provide concrete steps or suggestions on how to achieve this. The action is implied but not explicitly stated and requires further investigation to be implemented.", "grounding_specificity_rationale": "The reviewer is asking about the applicability of the work to generation tasks. While the paper likely discusses the general framework, the specific mention of 'generation tasks' is not explicitly tied to a particular section, table, figure, or unique aspect of the paper. The reviewer is asking a general question about a potential extension, not about a specific part of the current work. Therefore, the grounding is weak as the authors would need to infer the relevance of the work to generation tasks.", "verifiability_rationale": "The review point is a question, not a claim. Therefore, it does not contain a claim that requires verification. The nature of the question itself doesn't provide any evidence or justification.", "helpfulness_rationale": "The review point raises a relevant question about the potential scope of the work beyond NLU tasks. It encourages the authors to consider the applicability of their framework to generation tasks. While it doesn't provide a direct solution, it prompts further thought and potentially future work. Therefore, it is 3 in guiding the authors towards exploring related areas."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states that $N_d$ is not defined, which is a direct and actionable piece of information for the author. The reviewer clearly identifies the missing definition as being at 'l.145ff'. This provides the author with a clear location to seek clarification or definition.", "grounding_specificity_rationale": "The comment explicitly mentions 'l.145ff', indicating the specific location in the document where the issue occurs. This provides strong grounding as the author can directly go to that line to find the definition. The comment also specifically mentions '$N_d$ is not defined', which is a clear indication of the specific issue.", "verifiability_rationale": "The comment identifies a factual error: that the variable $N_d$ is not defined. While it doesn't provide a specific reference or explanation for *why* it's undefined, it clearly points to a location where the definition should be. This makes it 3 as the location of the issue is explicitly stated.", "helpfulness_rationale": "The comment is 5 as it directly points out a specific, actionable issue in the document. By stating that $N_d$ is not defined at 'l.145ff', the reviewer provides the author with a clear target for their attention. This is a concrete piece of feedback that directly aids in improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment 'Appendix is not cut from the main paper' states a fact but does not provide an explicit instruction or suggestion for the author to take. There is no indication of what should be done with the appendix.", "grounding_specificity_rationale": "The comment refers to the general term 'appendix' and does not specify which part of the appendix is problematic or needs attention. It is a general statement about the appendix's existence.", "verifiability_rationale": "The comment 'Appendix is not cut from the main paper' is a statement of fact and does not contain a claim that requires verification.", "helpfulness_rationale": "The comment identifies a structural issue (the appendix being in the main paper) but does not offer any suggestions for improvement or actionable steps for the author."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out a discrepancy in the results presented in table 1 and asks for clarification. While the action is implied (identifying a potential issue), the explicit action of 'pointing out the discrepancy' is clear. The vagueness lies in the lack of a direct suggestion on how to address this discrepancy.", "grounding_specificity_rationale": "The reviewer refers to 'the results in table 1,' 'the ternary potential,' 'the proposed model,' 'existing models,' and '2 modalities setup.' While they identify the general area of concern, they do not explicitly name the specific table or the exact models within the paper. The grounding is present at the level of the table and the general concepts, but not at the level of specific elements within the paper.", "verifiability_rationale": "The reviewer makes a claim about the results in table 1, stating that the ternary potential seems to be the main improvement and that without it, the proposed model is not outperforming existing models in a 2modality setup (except HieCoAtt). This claim is made without providing specific evidence or references within the review point itself. The reasoning is based on their interpretation of the table, not on explicit statements within the paper.", "helpfulness_rationale": "The reviewer's review point primarily identifies a discrepancy in the results and asks for clarification. While this is a valuable observation, it does not provide actionable feedback on how the authors should improve their draft. The reviewer does not propose specific steps or suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states what information would be useful for assessing the 'applestoapplesness' of comparisons, which is a direct and actionable suggestion for improving the clarity and rigor of the experimental evaluation. The reviewer directly points out the missing information needed to understand the experimental setup and how it ensures fair comparisons.", "grounding_specificity_rationale": "The review point explicitly names the specific aspects it wants to be noted: 'data augmentations', 'architecture', and 'objective'. This directly identifies the specific parts of the paper (or experimental setup) being discussed, making it fully grounded. The reviewer provides clear and specific elements that help the authors understand the experimental details.", "verifiability_rationale": "The information requested in the review point is factual and directly relates to the experimental setup and methodology. The reviewer provides clear and logical reasoning to justify the request, explaining why this information is important for assessing the 'applestoapplesness' of the comparisons. There are no ambiguities or missing external references required to understand the request, making it 5. The reviewer provides a clear and logical explanation of why this information is important and how it would help the authors.", "helpfulness_rationale": "The review point is highly relevant and directly addresses a practical concern for authors comparing different fewshot classification methods. By requesting information about data augmentations, architecture, and objective, the reviewer provides concrete and actionable feedback that can significantly improve the authors' understanding of the experimental setup and how it affects the results. This information is directly helpful for authors trying to understand and reproduce the experiments or to improve their own methods."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out potential overstatements of hyperpruning's performance claims and criticizes the choice of LSTM and LSH networks. While these are valid concerns, the reviewer doesn't explicitly state what specific action the authors should take based on these observations. They suggest exploring alternative architectures and benchmarks, but don't provide concrete steps within the review point itself.", "grounding_specificity_rationale": "The reviewer mentions 'the architectures being used (LSTM and LSH networks)' and 'the PTB benchmark' as areas of concern. However, they don't explicitly state which specific section, table, or figure these relate to. The grounding is implied rather than directly pointing to a specific element of the paper.", "verifiability_rationale": "The reviewer states that 'the architectures being used (LSTM and LSH networks) seem not to be state of the art for language modeling' and that 'the PTB benchmark is a very small data set'. While these are observations, the reviewer doesn't provide external references or logical reasoning within the review point itself to support these claims. The verifiability relies on the reader's general knowledge of the field.", "helpfulness_rationale": "The review point raises valid concerns about the paper's claims regarding hyperpruning's performance and the limitations of the experimental setup. It encourages the authors to consider alternative architectures and larger benchmarks. While the reviewer doesn't offer direct solutions within the review point, it points to areas where the authors might need to refine their approach or broaden their evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment implicitly suggests that the appendix lacks sufficient experimental details. While it doesn't explicitly state an action like 'Include X, Y, and Z in the appendix,' the request implies a need for more information. However, the action of 'including' is vague and doesn't specify *what* should be included.", "grounding_specificity_rationale": "The comment explicitly states that 'neural networks' and 'hyperparameters' are missing from the appendix. This directly identifies the specific part of the paper being addressed, providing strong grounding. The comment also specifies what is missing ('neural networks' and 'hyperparameters').", "verifiability_rationale": "The comment is a judgment about the completeness of the experimental details in the appendix. It doesn't make a claim that can be verified with evidence or references. It's a suggestion for improvement rather than a statement requiring justification.", "helpfulness_rationale": "The comment is a clear suggestion for improvement by asking for more specific experimental details in the appendix. This directly addresses a potential area for weakness in the paper's presentation and encourages the authors to be more transparent about their methodology. While it doesn't criticize the *style* of the appendix, it points to a specific area where more information would be beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that section 5.1 *does not seem to provide useful info regarding why the new model is superior*. This is an **implicit** action pointing to a missing element (the reason for superiority) within the specified section (5.1). While the action of identifying the missing information is clear, the reviewer doesn't explicitly say \"Add this information to section 5.1,\" making it implicit.", "grounding_specificity_rationale": "The review point explicitly mentions the section number (5.1) and the specific piece of information that is lacking (\"why the new model is superior\"). This provides a clear and precise reference point for the reviewer, making it fully grounded. It also specifies exactly what is missing within that section.", "verifiability_rationale": "The review point is a statement of observation ('section 5.1 does not seem to provide useful info...\") about the content of the paper. While the reviewer's opinion is likely based on their own assessment of section 5.1, the review point itself doesn't provide any concrete evidence or references to *verify* this claim. It's a subjective assessment of the information present.", "helpfulness_rationale": "The review point is highly informative and points the authors directly to a specific location (section 5.1) and a specific gap in the information (the reason for the model's superiority). This provides a clear direction for the authors to improve their paper. While it doesn't tell them *what* to put in section 5.1, it's a very useful piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment implicitly suggests an action by stating 'A comparison is necessary.' However, it lacks specific details on what needs to be compared.", "grounding_specificity_rationale": "The comment refers to 'singleIMP' generally and 'transferability' broadly, lacking specific identification of the relevant part or aspect. The claim about transferability is not detailed.", "verifiability_rationale": "The comment contains a claim ('the singleIMP might also have this transferability though not as strong'), but it lacks supporting evidence or justification for this claim.", "helpfulness_rationale": "The comment identifies a potential weakness ('the singleIMP might also have this transferability though not as strong') and suggests a comparison ('A comparison is necessary'). However, the specifics of the comparison and the evidence for the claim are missing, making it less helpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states they don't see any specific ethical concerns with the proposed methods. This implies a lack of actionable feedback related to ethics or other actionable limitations. The limitations mentioned are also general and do not point to a specific area needing improvement in the paper itself. Therefore, the review point lacks explicit or implicit actionable feedback for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'ethical concerns' generally, without specifying a particular section, table, figure, or unique aspect of the paper. The limitations are also described in a general manner, lacking specific references to parts of the paper. Therefore, the review point does not clearly identify the specific part of the paper being addressed. The grounding is weak as the reviewer is not pinpointing a specific element of the paper being criticized.", "verifiability_rationale": "The reviewer states their lack of ethical concerns is a general observation, not a claim requiring verification. The suggestion to check humanfactors literature is a recommendation, not a claim that needs to be supported by evidence within the review point itself. Therefore, the review point does not contain a claim that needs to be verified. It is essentially a statement of opinion without supporting evidence.", "helpfulness_rationale": "The reviewer explicitly states they don't see any specific ethical concerns with the proposed methods. The limitations are also general and do not provide specific actionable feedback for the authors. The suggestion to check humanfactors literature is a recommendation, not a critique of the paper itself. Therefore, the review point does not offer useful and actionable feedback to the authors."}
{"actionability_label": "4", "grounding_specificity_label": "Somewhat Grounded and Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the limitation of the experiments being conducted on 'toy dataset such as MNISTfashion' and implies this restricts the scalability of the proposed model selection approach. The suggestion to 'compare the proposed approach with other neural network pruning methods' is a concrete action the reviewer is proposing.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed model selection approach' which is reasonably clear, although not a direct section reference. The issue of scalability is specific to the method's description.", "verifiability_rationale": "The review point poses a question about the scalability of the model selection approach and suggests a comparison with other pruning methods. While the reviewer identifies a potential limitation, they do not provide any evidence or logical reasoning to support this claim about the limitations of MNIST or the proposed approach.", "helpfulness_rationale": "The review point raises a relevant question about the scalability of the proposed model selection approach and suggests comparing it with other neural network pruning methods. This is a constructive comment that could help the authors understand the limitations and potential areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the mathematical formulation issues at specific line numbers (345, 347, 374) and the inconsistency in index notation (lines 344 and 374). While the reviewer identifies the *what* (e.g., 'should be max', 'should be ith'), they do not provide explicit instructions on *how* to correct these issues. The actions are implicit, requiring the authors to infer the necessary changes.", "grounding_specificity_rationale": "The reviewer provides specific line numbers (345, 347, 374) and explicitly mentions the mathematical symbols involved in the identified issues. For example, they point out the potential error at line 345 and the inconsistency in the use of 'i' at lines 344 and 374. This clearly indicates that the reviewer is identifying specific parts of the paper being addressed.", "verifiability_rationale": "The reviewer claims that the paper contains mathematical formulation issues and provides specific examples of potential errors. While they do not provide external references to support these claims, the logical implication is that these are genuine problems within the paper. The reviewer's statements are verifiable by examining the specified line numbers and mathematical expressions. The claim is supported by the identified inconsistencies.", "helpfulness_rationale": "The reviewer identifies several specific mathematical formulation issues within the paper. While the reviewer points out the *problems* (e.g., potential 'max' instead of 'min', incorrect index usage), they do not provide explicit guidance on *how* to correct them. The reviewer's feedback is focused on identifying areas for improvement, which can be helpful for the authors to focus their revision efforts. However, the lack of concrete solutions makes the review point less directly helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the *lack of experiments* with different numbers of particles and asks a question about their *importance*. This is an explicit statement of a missing element and a desire for clarification. However, the comment does not specify *how* to conduct these alternative experiments or *what* the expected outcomes might be. The action is implicit \u2013 the authors should infer the need for such experiments and the importance of the parameter \u2013 but it is not explicitly stated or detailed.", "grounding_specificity_rationale": "The comment refers to 'experiments' in general, without pinpointing a specific section, table, figure, or unique aspect of the paper. It doesn't explicitly mention any specific aspect of the paper related to particle numbers. While the authors can infer the general area for improvement (experiment design), they cannot precisely identify the referenced part or the issue within it.", "verifiability_rationale": "The comment contains a claim in the form of a question: 'It would have been nice to see experiments...'. However, this claim is not supported by any logical reasoning, common knowledge, or external references within the review point itself. There is no justification provided for why such experiments would be beneficial or what the expected outcomes might be. The claim is presented without sufficient evidence or explanation.", "helpfulness_rationale": "The comment identifies a potential area for improvement (experiment design) and asks about its importance. While it highlights a potential missing element, it does not offer concrete suggestions or guidance on how to implement the suggested improvements. The feedback is somewhat general and lacks specific actionable steps for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of a comparison on plasticity evaluation metrics and names a specific metric (covariance metric 1). This directly points to a deficiency and suggests a concrete improvement, making it explicit and concrete. The reviewer is directly identifying what needs to be addressed and how it should be addressed.", "grounding_specificity_rationale": "The review point explicitly mentions 'plasticity evaluation metrics' and further specifies the metric as 'covariance metric 1'. This allows the authors to accurately pinpoint the section or aspect of the paper being discussed, making the grounding fully grounded. The authors can directly identify the missing comparison and the specific metric involved.", "verifiability_rationale": "The review point contains a claim about the missing comparison and suggests a specific improvement (including such a comparison). While it doesn't provide a detailed justification for why this comparison is necessary or beneficial, it offers a clear direction for the authors to take. The suggestion itself can be considered verifiable by the authors when they decide to conduct the comparison. Therefore, it is 3 as the suggestion provides a basis for verification by the authors.", "helpfulness_rationale": "The review point clearly identifies a gap in the paper (lack of comparison on a specific metric) and suggests a concrete improvement (including such a comparison). This is immediately actionable for the authors, providing them with a clear next step to take. The suggestion is specific and directly addresses the identified gap, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states two actions: 'What are A,B, C, D in Table 5' and 'Also, there should be some explanation as to why positive paths lead to monotonic solution and under what scenarios?'. These are both direct and explicit actions that the authors should be able to take to improve their draft. The reviewer is not asking for a general principle but rather specific information needed to understand and potentially improve the model or analysis described in the paper.", "grounding_specificity_rationale": "The reviewer explicitly identifies 'Table 5' as the specific part of the paper needing clarification. They then ask very specific questions about the content of this table ('What are A,B, C, D in Table 5') and the relationship between positive paths and monotonic solutions ('Also, there should be some explanation as to why positive paths lead to monotonic solution and under what scenarios?'). This demonstrates a strong grounding as the reviewer can accurately pinpoint the section and identify the specific issues within it.", "verifiability_rationale": "The reviewer is not making a claim in the traditional sense of criticizing something as 'bad'. However, they are pointing out a deficiency: 'Table 5 needs better explanation' and 'there should be some explanation as to why positive paths lead to monotonic solution'. This implies a lack of sufficient justification or clarity in the paper's presentation. While not a direct claim, the reviewer is providing a justification for the need for further explanation, making it 3 by highlighting the missing elements and the logical consequence of their absence.", "helpfulness_rationale": "The reviewer provides clear and actionable suggestions for improving the draft. They are directly addressing specific areas of confusion and potential weaknesses. The reviewer is not just pointing out a problem but also offering potential solutions or areas for further clarification. This makes the review 5 for the authors as they can directly use the information to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states 'In practice it costs long time to get a single US accuracy' which is an action. However, it does not specify how to make a cheap estimation, making it only 3.", "grounding_specificity_rationale": "The review point mentions 'US accuracy', 'DS accuracy', 'power law prediction' and refers to 'Figure 1'. While it mentions these elements, it doesn't explicitly point to a specific section, table, figure, or unique aspect of the paper it's addressing. The connection to Figure 1 is implied but not explicitly stated as 'Regarding the discussion in Figure 1...'", "verifiability_rationale": "The review point makes claims about the saturation of the curve and the limitations of early predictions and power law scaling. However, it provides no supporting evidence, references, or logical reasoning to back these claims. It's purely a statement of observation and concern.", "helpfulness_rationale": "The review point raises valid concerns about the limitations of early predictions and power law scaling. However, it doesn't offer concrete suggestions or guidance on how to address these limitations or how to use power law prediction effectively for model selection in practice. It's more of a critique and a question, offering no practical solutions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'ablation studies' and 'isolate the impact,' indicating a direct action to be taken. It clearly suggests what needs to be done and how it should be applied.", "grounding_specificity_rationale": "The comment explicitly mentions 'epsilon sampling's strong performance,' clearly identifying the specific aspect of the paper being addressed. It also specifies 'factors underlying epsilon sampling's strong performance,' indicating a clear understanding of what needs to be improved.", "verifiability_rationale": "The comment contains a claim ('The authors should provide ablation studies...') that requires justification. However, it does not provide specific examples or references to support the suggestion of ablation studies. The reasoning is present but lacks concrete details.", "helpfulness_rationale": "The comment directly points out a missing element (ablation studies) and suggests its inclusion. This is a clear and actionable piece of feedback for the authors, guiding them to improve their experimental evaluation. While it doesn't provide specific details on *what* ablation studies to run, it identifies a concrete area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer states they want to see an additional experiment, but the specific action of conducting this experiment is not explicitly stated. The suggestion is implicit.", "grounding_specificity_rationale": "The reviewer explicitly names a specific paper ('Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness') and a specific defense mechanism ('mode connectivity based defense'). This provides strong grounding. They also mention the paper's finding about finetuning, adding further specificity.", "verifiability_rationale": "The reviewer's suggestion is logical and connects to the existing literature. However, the specific details of how to conduct the experiment are not fully specified, making it somewhat inferable.", "helpfulness_rationale": "The reviewer's suggestion is very valuable. It directly addresses a potential limitation of the proposed attack by evaluating its effectiveness against a relevant defense mechanism. This could significantly enhance the paper's impact and robustness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the absence of 'codes' during the review process. While the reviewer doesn't explicitly state an action to take, the implication is to look for these 'codes'. The action is present, making it more actionable than a purely negative statement. However, the lack of detail on *how* these codes would be used makes it less concrete.", "grounding_specificity_rationale": "The reviewer mentions 'codes' as the reason for the lack of transparency. While 'codes' is a specific term, the reviewer doesn't specify *where* these codes are intended to be used or what aspect of the review process they relate to. The reference is general, making it weakly grounded.", "verifiability_rationale": "The reviewer makes a statement about the 'transparency' of claims based on the absence of 'codes'. This is a judgment or claim, but the reviewer doesn't provide any evidence or reasoning to support this claim. There's no logical deduction or external reference provided to back up the assertion that missing codes directly leads to less transparent claims.", "helpfulness_rationale": "The reviewer suggests including 'codes' to improve the transparency of claims. While this is a potential improvement, the reviewer doesn't explain *why* the absence of codes specifically hinders transparency or what kind of 'codes' would be beneficial. The suggestion is present, but the reasoning for its helpfulness is lacking."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "3 (3)", "verifiability_label": "4 (4)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point states \"3) is not necessary.\" While this implies an action (that point should be unnecessary), it doesn't explicitly state what needs to be done to make it unnecessary or how to implement this change. The action is implied but not concrete.", "grounding_specificity_rationale": "The reviewer refers to \"3)\" without specifying which part of the paper this refers to. The content being unnecessary is also vague. The reviewer doesn't specify what is currently using 4 scenarios or how the change should be made, making it not specific.", "verifiability_rationale": "The reviewer makes a claim (\"3) is not necessary\") and provides a reason for this claim (\"I encourage the authors to validate the proposed approach in Waymax...\", which serves as justification). The claim is supported by logical reasoning and a suggestion for improvement, making it 4.", "helpfulness_rationale": "The review point suggests a future improvement and provides context for why it might be beneficial. While the suggestion is valuable, it doesn't directly address the current state of the draft. It's a forwardlooking comment rather than a direct improvement suggestion for the current version, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the similarity to RTDNet and the key difference (visual features). They also explicitly mentions LMA. This is an explicit action. Furthermore, the reviewer clearly states *what* is different (3D pose, LMA) and *why* they think it might not be significant (LMA's known effectiveness). This is concrete. The reviewer is pointing out a potential limitation or area for further investigation, making it actionable.", "grounding_specificity_rationale": "The reviewer doesn't explicitly name a section or table. They refer to \"transformerbased TAPG method,\" \"visual features,\" \"3D pose,\" and \"Laban Movement Analysis.\" While they mention LMA, they don't specify a particular section or table where this is discussed. This is weak grounding. However, the reviewer does specify what needs to be addressed in this part (the effectiveness of LMA). This makes it somewhat specific.", "verifiability_rationale": "The reviewer makes a claim: \"the technical contribution is not very significant\" and 'such a choice may not bring enough insights.\" This is a claim. The reviewer provides a reasoning for this claim: \"To my understanding, the transformerbased TAPG method has been studied in previous works such as RTDNet (ICCV2021). The main difference between RTDNet and the proposed method lies in the visual features. This paper additionally considers 3D pose and the action features obtained by Laban Movement Analysis (LMA). However, LMA has been proven to be effective in dance action recognition, it is not that surprising to see that the use of additional features could improve the performance.\" This reasoning is verifiable by checking the novelty of the individual components and the overall contribution.", "helpfulness_rationale": "The reviewer's point is to help the authors understand the limitations of simply adding new features. This is 5 for guiding future work and contextualizing the contribution. It provides a valuable perspective on the incremental nature of research and the importance of considering existing knowledge when introducing new features."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a potential improvement in the implementation (more experimental comparisons for different merging strategies) but does not explicitly state what needs to be done. It suggests exploring different design choices, which is a general direction rather than a specific action.", "grounding_specificity_rationale": "The comment mentions 'tree construction' which is more specific than 'the paper' but does not pinpoint a specific section, table, or unique aspect of the tree construction implementation. It refers to 'different design choices' generally, making the grounding somewhat weak.", "verifiability_rationale": "The comment claims that 'more experimental comparisons are needed' but does not provide any justification or evidence for this claim. It states a need for improvement without explaining why or providing supporting reasoning.", "helpfulness_rationale": "The comment identifies a specific area for improvement in the implementation (tree construction) and suggests exploring different design choices. It provides a clear direction for the authors to take, even if it lacks specific details. It helps the authors understand what needs revision and why (the potential for better performance)."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action: 'report these baselines' and further clarifies *which* baselines: 'These are reported in the ReBART paper...'. This directly points to a missing element and how to fix it.", "grounding_specificity_rationale": "While the reviewer mentions 'Table 2', they don't specify the exact row, column, or data point that's missing. The grounding is at the table level, not a specific element within the table. The reviewer also doesn't describe *what* is missing within the table.", "verifiability_rationale": "The reviewer makes a claim: 'Table 2 in the paper is not complete'. While this is a valid observation, the *reason* it's not complete is linked to the ReBART paper, which is external to the specific sentence quoted. There's no direct, selfcontained justification within the sentence itself.", "helpfulness_rationale": "The reviewer's point is clear and directly addresses a deficiency. The suggestion to 'report these baselines' is a concrete and actionable step for the authors. This directly helps them improve their paper."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitations of the evaluation on the HSERGB dataset and provides concrete suggestions for improvement. They state, 'Why only three scenes are chosen from HSERGB dataset?' and then suggest, '. How about the performance on other sequences?'. This indicates an explicit action the authors could take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'HSERGB dataset' and focuses on a specific issue within it ('why only three scenes are chosen'). They even implicitly point to a lack of specificity by suggesting testing on 'other sequences,' implying they know what's missing. The reviewer can confidently identify the part of the paper being addressed.", "verifiability_rationale": "The reviewer poses a question ('Why only three scenes are chosen from HSERGB dataset?') which can be interpreted as a claim or a request for justification. While the reviewer suggests testing on 'other sequences' as a way to verify their point, this is more of a suggestion for further evaluation rather than a direct attempt to verify the reason for choosing the initial three scenes. The reasoning behind the selection of those specific three scenes is not provided.", "helpfulness_rationale": "The reviewer directly addresses a common concern in academic reviews \u2013 limited evaluation \u2013 and provides a clear direction for improvement. While the specific reason for choosing the three scenes is missing, the general point about the need for more comprehensive testing is valuable feedback for the authors. The reviewer's suggestion to test on 'other sequences' is actionable."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests using more bits for embeddings and questions the interpretation of bitembeddings as word representations. While these are valid points for discussion, the review does not explicitly state what the authors should do. The suggestions are presented as questions and potential improvements rather than clear, actionable steps. The action is implied but not clearly defined. It's not like the authors are told, \"Use more bits for embeddings.\" They're presented with a possibility and a question.", "grounding_specificity_rationale": "The reviewer makes a general comment about the interpretation of bitembeddings without explicitly pointing to a specific section, table, figure, or unique aspect of the paper. They are discussing a concept in general terms. The grounding is implicit, as the reviewer doesn't name a specific part of the paper they are referring to. The comment is about a general issue with the interpretation, not a specific element.", "verifiability_rationale": "The reviewer claims that the model might be memorizing the data because the bitembeddings don't show semantic relations for oddranked words. This is a claim that requires justification. While the reviewer presents a hypothesis, they do not provide any concrete evidence or logical reasoning to support this claim. The reasoning is present but lacks concrete support. The claim about the interpretation of bits is presented as a question, suggesting a lack of immediate verification.", "helpfulness_rationale": "The reviewer raises a valid point about the interpretation of bitembeddings and asks a pertinent question. This could be helpful for the authors to understand the limitations of their current approach. However, the other aspects of the review point are weak. The suggestion about using more bits for embeddings is speculative and lacks evidence. The overall feedback is therefore limited in its impact and helpfulness."}
{"actionability_label": "2 (2)", "grounding_specificity_label": "2 (2)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point implicitly points out a limitation (the need for human annotation) but doesn't explicitly state a concrete action or solution to mitigate this limitation. It suggests a problem rather than a direct instruction.", "grounding_specificity_rationale": "The review point mentions 'human annotation' generally, which is a broad term and doesn't specify which part of the paper or method is affected. It doesn't clearly identify the specific issue or area needing clarification.", "verifiability_rationale": "The review point states a limitation ('human annotation is subjective') but doesn't provide any evidence or justification for this claim. It presents a statement of fact without supporting reasoning or references.", "helpfulness_rationale": "The review point provides valuable information by highlighting a practical challenge in achieving semantic meaning due to the reliance on human annotation. This information can help authors understand the limitations of the method and potentially explore alternative approaches or mitigation strategies. While it doesn't offer a solution, it provides context that can be helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states two actions: 'Pretrain a CausalLM using this dataset' and 'Compare its performance against ObscuraCoder'. Both actions are direct and specific. The first action involves training a model, and the second involves evaluating its performance against another model. The reviewer clearly identifies the models and the dataset used for pretraining. The action of comparing performance is also a clear and direct action. The reviewer does not leave much ambiguity about what needs to be done for either action.", "grounding_specificity_rationale": "The review point explicitly mentions 'this dataset' and 'ObscuraCoder'. The reviewer can accurately pinpoint the specific dataset and the specific model being compared against. The mention of 'mixed with other datasets used by ObscuraCoder' also provides a clear reference point. The reviewer does not mention any ambiguous or inferred references to parts of the paper.", "verifiability_rationale": "The claim is that pretraining a CausalLM on this dataset and comparing its performance against ObscuraCoder will help attribute improvements to the deobfuscation objective. The 'claim' is the suggestion of this experiment. The 'verification' comes from the logical reasoning that comparing performance against a baseline (ObscuraCoder) can help isolate the impact of the deobfuscation objective. The common knowledge is that performance comparisons are a standard way to evaluate model improvements. The external references would be the existing literature on model pretraining and evaluation. The claim is supported by the logical connection between the proposed experiment and the goal of attributing improvements.", "helpfulness_rationale": "The review point suggests a concrete experiment: pretraining a CausalLM and comparing its performance. This directly relates to the stated goal of understanding the impact of the deobfuscation objective. The suggestion to compare against ObscuraCoder provides a clear benchmark. While the *method* of attributing improvements isn't specified, the suggestion is a valuable step towards achieving the stated goal. The reviewer provides a clear direction for the authors to follow."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests a potential error in the implementation of a loss function, implying a specific action that the authors could take to potentially improve their results. The suggestion is to modify the loss calculation, which is a concrete action.", "grounding_specificity_rationale": "The reviewer specifically mentions \"L264L266\" and refers to the \"loss equation\" within that section. This demonstrates strong grounding as they are not just referring to a general part of the paper but a specific location. They also specify the relationship between the two losses within that equation, making it highly specific.", "verifiability_rationale": "The reviewer makes a claim about the potential error in the loss equation. They suggest a specific alternative implementation (adding the geometric loss to the reconstruction loss). This claim is verifiable because the alternative is clearly defined and actionable. The reviewer is not asking for a general discussion about loss functions but providing a concrete suggestion for improvement.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for improvement. They identify a potential issue in a specific part of the paper and offer a concrete alternative. This is 5 as it directly points the authors towards a potential area for adjustment and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review points out a *difference* in application between MLM and autoregressive models. While it identifies a *weakness* in the current method (MLM not being used more), it doesn't directly tell the author *what* to change or *how* to implement it. The suggested change is to 'employ' autoregressive models, which is a highlevel instruction lacking specific steps.", "grounding_specificity_rationale": "The review mentions 'MLM' and 'autoregressive language models' generally. It doesn't specify *which* section, table, figure, or unique aspect of the paper it's referring to. While it points to a *difference* in application, it doesn't pinpoint the exact location within the paper where this difference is occurring.", "verifiability_rationale": "The review states 'Even though MLM is important and used in many applications, the method should also be employed in the autoregressive language models, which are used more in realworld applications.' This is a statement of opinion or a suggestion for improvement. It doesn't present a claim that can be verified with evidence or logical reasoning. It's a recommendation based on a perceived gap.", "helpfulness_rationale": "The review identifies a potential area for improvement in how MLM is applied. It highlights a discrepancy between the importance of MLM and its current usage in autoregressive models. While it doesn't provide specific steps, it points to a relevant gap and suggests a potential direction for future work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues with the proposed method compared to GANs and points out the lack of details on how to avoid vanishing gradients and model collapse in the method section. This provides clear, actionable feedback for improvement.", "grounding_specificity_rationale": "The reviewer identifies the problems with GANs and the proposed method without directly specifying the section, table, or unique aspect of the paper where this information is lacking. The grounding is implied but not explicitly pointed out.", "verifiability_rationale": "The reviewer states that the claim about the proposed method's advantages over GANs and the absence of details on addressing vanishing gradients and model collapse is not supported by evidence or justification within the review point itself. The claim is presented as a statement of uncertainty.", "helpfulness_rationale": "The reviewer provides specific and actionable feedback regarding the lack of clarity on the proposed method's advantages over GANs and the missing details on how vanishing gradients and model collapse are addressed. This feedback directly helps the authors understand areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the experimental setup, specifically why ablations are performed on modified models (BART and BART+Longformer) instead of the original model (GraphSum). This is a valid question that seeks clarification on the rationale behind the experimental design. While the question itself isn't explicitly actionable, it points to a potential lack of clarity in the experimental methodology, which could hinder the interpretability of the results. The reviewer is implicitly asking for justification of the chosen ablation targets.", "grounding_specificity_rationale": "The reviewer's question is about the *why* behind the ablation targets. While it doesn't directly identify a specific part of the paper being addressed, the question implies a lack of clarity in the experimental design. The grounding specificity is low because the comment doesn't pinpoint a specific aspect of the paper being discussed. The reviewer is asking *where* the ablations are happening, not *what* they are happening.", "verifiability_rationale": "The reviewer's question is about the *validity* of the ablation targets. It's not about whether the statement is a claim or how it's supported, but rather *why* those specific models were chosen for ablation. The verifiability is low because the comment doesn't provide a justification for the choice of ablation targets. The reviewer is asking for *evidence* or *reasoning* behind the experimental design.", "helpfulness_rationale": "The reviewer's question is about the *value* of the information provided. While the question itself is about the experimental setup, it's framed as a request for clarification rather than a direct critique of the information given. The helpfulness is medium because the question highlights a potential area of confusion for the authors, but it doesn't directly point out a flaw in the presented information."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential inconsistency between the removal of previous SciBERT reports and the cursory analysis of model outcomes. While this suggests a weakness, the reviewer does not explicitly state what the authors should do to address this. They imply a concern but don't provide explicit steps or actions. Therefore, it is not fully actionable, as the authors need to infer the need for further analysis.", "grounding_specificity_rationale": "The reviewer mentions 'previous SciBERT reports' and 'cursory analysis of the outcomes of the models'. While they identify areas of the paper, they do not specify which exact section, table, figure, or unique aspect of the paper is being referred to. The references are general, making it difficult to pinpoint the exact location of the issue. Therefore, the grounding is weak and not specific.", "verifiability_rationale": "The reviewer states a potential inconsistency between the removal of previous SciBERT reports and the cursory analysis of model outcomes. However, they do not provide any evidence, reasoning, or external references to support this claim. The statement is presented as a possibility without verification. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer points out a potential issue (the inconsistency between the removal of SciBERT reports and the cursory analysis) and highlights that the current paper does not mention this. This points to a potential problem and a lack of awareness of it. While it identifies a weakness, it does not provide concrete guidance on how to address it. Therefore, it is 3 in identifying a problem but lacks actionable suggestions."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a phrase ('...even more better...') as potentially problematic, which is an explicit action. However, they do not specify what is wrong with the phrase or suggest an alternative. This makes the action somewhat vague and less actionable. While the reviewer also states their belief that Figure 4(b) indicates faster training, they do not explain why they find this interpretation unconvincing or suggest an alternative interpretation. This makes the action partially actionable but not fully explicit. The reviewer explicitly suggests a longer discussion of related work, which is an explicit action and a concrete suggestion. They identify a gap in the paper's discussion and offer a specific improvement.", "grounding_specificity_rationale": "The reviewer refers to the phrase '...even more better...' without specifying where in the text it appears, making the grounding weak. However, when discussing Figure 4(b), the reviewer explicitly refers to 'Figure 4(b)' and 'faster training', providing a clear reference point, making the grounding full. The reviewer refers to the 'field of pruning' generally when suggesting a longer discussion of related work, which is a weak ground because they don't specify which parts of the pruning field are missing from the paper's discussion.", "verifiability_rationale": "The reviewer states their belief that the phrase '...even more better...' is inappropriate but does not provide any evidence or reasoning to support this claim, making it 1. Similarly, the reviewer believes the interpretation of Figure 4(b) is not convincing but does not provide any specific examples or justifications, making this claim 1. The reviewer suggests a longer discussion of related work but does not explain why the current related work section is insufficient or provide specific examples of missing related work, making this claim 1.", "helpfulness_rationale": "The reviewer identifies a potential issue with the phrasing but does not offer any suggestions or solutions, making this comment not helpful. The reviewer points out a potential flaw in the interpretation of Figure 4(b), which could be helpful for the authors to understand, but they do not provide any specific guidance or alternative interpretations, making it only slightly helpful. The reviewer suggests a longer discussion of related work, which is a concrete and actionable suggestion that could significantly improve the paper, making this comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the error in the derivative of n^(1/2) and provides the correct derivative. The action is clearly stated and concrete.", "grounding_specificity_rationale": "The reviewer does not explicitly state the location of the derivative within the paper (e.g., 'In equation X, the derivative...'). While the error is specific to the mathematical expression n^(1/2), the connection to a specific part of the paper is implied but not explicitly identified. The specificity is in the mathematical expression itself.", "verifiability_rationale": "The reviewer makes a claim about the incorrect derivative and provides the correct derivative, which is a wellestablished mathematical fact. The claim is supported by logical reasoning and a clear explanation of the correct calculation.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for correcting a mathematical error in the paper. This actionable feedback is directly helpful for the author to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests the authors need to 'refine the writing' but does not specify what exactly needs to be changed. While it points to a problem (unclear paper), it lacks concrete, actionable steps for the authors to follow. The action is implied but not explicitly stated in a way that guides the authors to specific edits or improvements.", "grounding_specificity_rationale": "The reviewer mentions 'the introduction part' and 'show much background about the cognitive models.' While they identify a general area (introduction) and a specific topic within it (cognitive models), they do not explicitly point to a specific section, table, figure, or unique element within the introduction that needs improvement. The grounding is present but not fully precise.", "verifiability_rationale": "The review point makes a judgment about the clarity of the paper and the need for 'refinement of writing' but does not provide any specific examples or references to support these claims. The reviewer states what they believe is wrong but does not explain *why* or provide *evidence* for their assessment. The claim is made without sufficient justification or supporting information.", "helpfulness_rationale": "The review point identifies a problem (unclear paper) but does not offer any specific suggestions or guidance on how to address it. While it points to the need for 'refinement of writing,' it doesn't provide concrete examples of what needs to be changed or how the writing should be improved. The feedback is present but lacks actionable steps for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a difference in performance between DFA and backpropagation on a NLP task and suggests this discrepancy is important. This directly identifies a potential issue and proposes an action (emphasizing it). The reviewer is pointing out a concrete difference and suggesting a specific improvement, making it 5.", "grounding_specificity_rationale": "The reviewer mentions 'a NLP task' generally. While they imply a 'standard' task, they do not explicitly identify a specific section, table, figure, or unique aspect of the paper where this performance difference is observed. The grounding is weak because the authors cannot confidently determine the referenced part without further context.", "verifiability_rationale": "The reviewer states a fact: 'DFA performance lags substantially behind backprop performance'. This is a claim that needs to be supported. However, the reviewer does not provide specific evidence or references to backpropagation's superior performance on this task. The claim is presented without sufficient justification or examples, making it 3.", "helpfulness_rationale": "The reviewer points out a potential issue (the performance difference between DFA and backpropagation) and suggests an improvement to the paper (emphasizing this difference). This is a clear identification of a weakness and a suggestion for a concrete action the authors can take. The reviewer is providing actionable feedback that directly benefits the authors, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states the 'lack of a baseline' for dimensional reduction methods in optimal transport estimation and suggests 'SRW and FROT' as specific baselines. This is an explicit statement of a weakness and a direct suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The review point directly refers to 'dimensional reduction methods in optimal transport estimation' and names specific methods 'SRW and FROT'. This clearly identifies the specific part of the paper being addressed and specifies the issues within it, making it 5.", "verifiability_rationale": "The review point claims that 'SRW and FROT should be included as baselines'. While this is a valid suggestion, the review point itself does not provide any evidence or justification for why these methods are specifically relevant as baselines. Therefore, the claim is 1 based solely on the information provided in this review point.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper: the lack of a specific baseline for dimensional reduction methods in optimal transport estimation. It provides concrete suggestions for improvement by naming relevant methods. This directly addresses the authors' work and offers actionable feedback, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'has not yet discussed,' which clearly indicates an action the authors should take. It directly points to a specific area (advantages and disadvantages of transductive learning) that needs attention. The action is also concrete, as the authors know exactly what is missing and where it should be addressed.", "grounding_specificity_rationale": "The comment explicitly mentions 'transductive learning' by name, which is a specific term within the field. Furthermore, it specifies the 'advantages and disadvantages' of this learning method, making the area of discussion very clear and specific.", "verifiability_rationale": "While the comment doesn't contain a direct claim about the state of discussion, it implies a lack of information or consideration regarding the advantages and disadvantages of transductive learning. This could be considered somewhat inferential, as it suggests that a discussion should have taken place. However, it lacks specific examples or references to external works, making the verifiability somewhat lacking.", "helpfulness_rationale": "The comment identifies a valid area for improvement by highlighting the lack of discussion on the advantages and disadvantages of transductive learning. This points to a potential gap in the authors' analysis or presentation. However, it doesn't provide specific guidance on how to address this gap or what information should be included in the discussion. It's more of a pointer to an area that needs work rather than a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment implicitly suggests adding a formal statement about invariance, but it doesn't explicitly state the action or how to implement it. It's an implied request.", "grounding_specificity_rationale": "The comment doesn't specify which part of the paper (section, table, figure) is being addressed. It refers to \"the contractivity\" and \"the invariance of the contractivity\" generally.", "verifiability_rationale": "The comment doesn't make a claim that requires verification. It's a suggestion for improvement.", "helpfulness_rationale": "The comment identifies a valid area for improvement (formalizing invariance) but lacks specific details on how to achieve this, making it 3 but lacking actionable steps."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states they disagree with the paper's acceptance due to the lack of application/evaluation for uncertainty saliency maps. This directly points to a request for evaluation, making the review actionable. The reviewer also states they disagree that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself, which implies a request for clarification or justification regarding the trustworthiness of uncertainty measures. Both of these requests are concrete actions the authors should take.", "grounding_specificity_rationale": "The reviewer mentions 'uncertainty saliency maps' generally. While they imply a concern about their evaluation, they don't explicitly identify a specific section, table, or figure within the paper that needs addressing. The reviewer's disagreement about the trustworthiness of uncertainty measures is also general and doesn't pinpoint a specific element within a section. Therefore, while the reviewer identifies a potential area for improvement, they don't clearly specify *which* part of the paper or *what* aspect of the uncertainty saliency maps or their trustworthiness they are referring to.", "verifiability_rationale": "The reviewer states they disagree that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. This is a claim that requires justification. The reviewer doesn't provide any specific examples or references to support their disagreement. The justification for why the explanation might be more trustworthy is missing. Therefore, the claim is made but lacks sufficient supporting evidence or justification.", "helpfulness_rationale": "The reviewer states they disagree with the paper's acceptance based on the lack of evaluation of uncertainty saliency maps. While this highlights a potential weakness, it doesn't directly instruct the authors on *how* to improve their paper. The reviewer's disagreement about the trustworthiness of uncertainty measures is also a statement of opinion without providing concrete guidance. The review primarily points out a lack of improvement rather than offering specific, actionable steps for the authors to take within the review itself."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a gap in the discussion but doesn't offer a specific, actionable suggestion. The request for a comparison to 'other methods' is implied but not a direct action. The reviewer identifies the *issue* (importance of diffusion models) but doesn't specify *how* to address it or *what* the alternative methods might be.", "grounding_specificity_rationale": "The reviewer mentions 'the importance of using the diffusion model' and its relevance to 'style transfer'. This indicates some level of grounding as the specific topic is mentioned. However, the reviewer doesn't pinpoint a specific part of the paper or provide details about the diffusion model's functionality. The focus remains on the general topic rather than a specific element within the paper or method.", "verifiability_rationale": "The reviewer states a potential issue ('One issue not discussed is the importance of using the diffusion model') but doesn't provide any evidence or reasoning to support this claim. The request for a comparison to 'other methods' is presented as a question, not a verifiable statement. The reviewer identifies a potential gap but doesn't explain why it's a gap or how it should be addressed.", "helpfulness_rationale": "The reviewer identifies a valid concern (a missing discussion on the importance of diffusion models) which is a relevant point for authors. However, the reviewer doesn't offer any suggestions or actions to address this concern. The feedback is presented as a question and observation rather than a constructive suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the multiview latent attack 'enhances the model\u2019s meta generalizability' and suggests a 'discussion or comparison in the related work section' to enhance understanding. These statements are direct and point to specific improvements. While the reviewer doesn't provide the 'how' of the enhancement, the intent is clear and actionable for the authors.", "grounding_specificity_rationale": "The reviewer refers to 'multiview latent attack' and 'multiview training' generally. However, they also provide specific examples of 'task augmentation metalearning methods 1,2,3'. This indicates a degree of grounding as the authors can infer the specific related work they are referring to.", "verifiability_rationale": "The reviewer makes a claim that 'multiview training is quite similar to the task augmentation metalearning methods'. While this is a judgment, it lacks explicit justification or references within the review point itself. The similarity is implied but not explicitly supported by examples or citations within this specific review point.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement: 'a discussion or comparison in the related work section'. This is a direct and actionable recommendation that directly addresses a common need for authors to understand the context and limitations of new methods. While the 'how' of the comparison isn't specified, the suggestion itself is valuable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a missing ablation study, which is an implicit action. However, it doesn't specify how to conduct this ablation or what metrics to use, making it vague and not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions 'Age' and 'FaceID' features without explicitly stating which section or table they belong to. This implies a level of grounding but isn't precise.", "verifiability_rationale": "The review point makes a claim about the missing impact of 'Age' and 'FaceID' features. This claim is not supported by any external references or logical reasoning within the review point itself. The verifiability relies on the authors conducting their own experiments to determine the impact.", "helpfulness_rationale": "The review point identifies a specific area for improvement (missing ablation study) and suggests a concrete action (conducting an ablation study). This provides valuable feedback to the authors and is likely to be helpful in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"The Table 2 and Fig. 5 were not mentioned in the manuscript.\" This is an explicit action identifying a specific location (Table 2 and Fig. 5) where information is missing from the manuscript. Furthermore, the reviewer suggests \"I suggest move the discussion to the main manuscript.\" This is a concrete action and a clear recommendation for improvement. The reviewer also points out the *specific* missing information \"What do the values stand for in Table 2 and Fig. 5?\", indicating a clear action to understand the meaning of the data. Therefore, the reviewer provides clear and actionable feedback.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"Table 2 and Fig. 5.\" This is a literal mention, indicating full grounding. The reviewer also asks specific questions about the content of these figures and tables, such as \"What do the values stand for in Table 2 and Fig. 5?\" and \"Why giving the detailed discussion in Appendix?\" These specific questions demonstrate a clear understanding of the information being pointed out and the reasons for its placement. The reviewer's questions are not just general but directly address the missing information and its presentation.", "verifiability_rationale": "The reviewer's comment is primarily a request for clarification and a suggestion for improvement. While it doesn't explicitly state a claim that requires verification, the questions \"What do the values stand for in Table 2 and Fig. 5?\" and \"Why giving the detailed discussion in Appendix?\" imply a need for understanding and justification. The reviewer is asking for evidence or reasoning to support the placement and interpretation of the data. Therefore, it can be considered 2 as it contains implicit elements that require justification.", "helpfulness_rationale": "The reviewer's comment directly points out a significant issue: the missing information in the main manuscript (Table 2 and Fig. 5) and suggests a concrete improvement: moving the discussion to the main manuscript. This directly addresses a lack of clarity and provides a clear recommendation for the authors to improve their understanding of the results. The reviewer's specific questions about the values and the discussion further highlight the need for this clarification and the desire for improved presentation. This comment is 5 and directly helpful to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the expectation of \"more LLMrelated results\" and provides a clear reason: \"I expect to see more LLMrelated results in the paper experiment. The author only conducted experiments on llama27B and mtbench, and I expect to see more LLM results such as llama370B, Mistral7B, etc.\" This is a direct and actionable suggestion. The reviewer clearly identifies the missing LLM experiments and suggests specific examples. This is a clear call for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"LLaTa method\" and the specific experimental setups used \"LLaMA27B\" and \"MTBench\". They also connect the experiments to the stated purpose of the LLaTa method. While they don't name *all* the expected LLMs, they strongly imply the need for a broader evaluation across different LLM architectures. The reviewer grounds the suggestion in the context of the paper and the specific methods being used. The specificity is good, as they identify the need for more LLM experiments.", "verifiability_rationale": "The reviewer makes a claim: \"I expect to see more LLMrelated results in the paper experiment.\" However, they do not provide any justification or reasoning for *why* they expect this. There is no logical reasoning, common knowledge, or external references provided to support this expectation. The statement is presented as a suggestion for more experiments without explaining the basis for that suggestion.", "helpfulness_rationale": "The reviewer's suggestion is to include \"more LLM results such as llama370B, Mistral7B, etc.\" This is a valid and helpful suggestion for improving the paper. It points to a specific area where the experimental validation is lacking and suggests concrete steps to address it. However, it's not a direct fix for any identified weaknesses in the current experiments. It's a request for additional evidence."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the relationship between DFSDT and selfconsistency + CoT and Treeofthoughts, providing a clear action. However, the reviewer does not specify how to address the concern about generalizability to other LLMs, making the action somewhat implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'selfconsistency + CoT' and 'Treeofthoughts', providing strong grounding. The reviewer also explicitly mentions the concern about 'other types of LLMs', further grounding the issue. The comment clearly identifies the specific parts of the paper (techniques) and the issue (unclear performance on other LLMs).", "verifiability_rationale": "The reviewer makes a claim about the 'unclear performance' of DFSDT on 'other types of LLMs'. However, the reviewer does not provide any specific evidence or reasoning to support this claim. The claim is presented as a potential issue that needs further investigation, but lacks concrete verification.", "helpfulness_rationale": "The reviewer points out a potential area for the authors to consider regarding the generalizability of their method. By highlighting the potential overlap with existing techniques and the lack of clarity on performance across different LLMs, the reviewer provides valuable context and potential avenues for further research or discussion. This feedback is helpful for the authors to understand the limitations and scope of their proposed method."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review points out a general principle (acknowledging contributions) but does not explicitly state what the author should do to implement this. While it implies the importance of proper citation, it lacks specific instructions or actions for the author.", "grounding_specificity_rationale": "The review makes a general statement about the importance of proper citation and the inappropriate nature of claiming novelty without it. It does not specify which part of the paper this applies to, nor does it detail what needs to be done in that part. The reviewer is commenting on a broader issue rather than a specific element of the paper.", "verifiability_rationale": "The review makes a claim: 'It's very inappropriate to propose an identical method while claiming you are the first.' It provides some implicit support by stating the reviewer understands the importance of proper citation, which could be seen as a basis for justifying the claim. However, it lacks explicit examples, references, or a clear logical reasoning to fully verify the claim.", "helpfulness_rationale": "The review raises a valid concern about the lack of proper citation when claiming novelty. It highlights a potential issue that could affect the paper's integrity. While it doesn't offer specific solutions or actionable steps for the author, it points out a problem that needs addressing, making it 3 in identifying a potential flaw."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a performance difference between two models (XDC and MMV) and asks a question seeking clarification. While the reviewer identifies a gap in understanding, the action is not explicitly stated. The reviewer identifies the models and asks a question, which is an explicit statement but lacks a clear next action.", "grounding_specificity_rationale": "The reviewer names specific models (XDC, MMV, R(2+1)D18, fullysupervised pertaining baseline) and asks a specific question about the performance difference and the potential role of the backbone architecture. This demonstrates good grounding and specificity.", "verifiability_rationale": "The reviewer presents a factual observation (the performance comparison) and asks a question that requires further information or justification. The request for an explanation about the backbone architecture is a logical request for verification. The claim that MMV shows better performance than XDC is verifiable based on the provided information.", "helpfulness_rationale": "The reviewer identifies a relevant comparison between models and their baselines. The question about the potential reason for the performance difference is directly relevant to understanding the model's behavior. The request to explain the role of the backbone architecture is a valuable inquiry for understanding model performance. While the reviewer doesn't explicitly suggest *how* to improve the models, they are pointing out a discrepancy that needs further investigation, which can ultimately lead to improvements. Therefore, it's 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states the writing is 'too verbose and hard to follow'. While this points to a potential area for improvement, the reviewer does not explicitly state what specific action the author should take to address this. The suggestion to 'focus on a main idea or two' is a general direction rather than a concrete action item. Therefore, the comment identifies a problem but lacks specific actionable steps.", "grounding_specificity_rationale": "The reviewer's comment, 'The writing is too verbose and hard to follow,' does not specify which part of the paper is difficult to follow. They do not mention any specific section, table, figure, or unique aspect of the paper. The comment is a general statement about the overall writing quality. Therefore, the comment is 1 in the specific parts of the paper.", "verifiability_rationale": "The reviewer's comment, 'The writing is too verbose and hard to follow,' is a subjective assessment and opinion about the paper's clarity. It does not contain a claim that requires verification through logical reasoning, common knowledge, or external references. Therefore, the comment does not contain a claim that needs to be verified.", "helpfulness_rationale": "The reviewer suggests focusing on 'a main idea or two' as a way to improve the paper. While this is a relevant suggestion given the identified weakness ( verbosity), it is presented as a general direction rather than specific, actionable steps. The reviewer does not provide any concrete examples or detailed guidance on how to achieve this. Therefore, the comment identifies a potential weakness and offers a somewhat general suggestion for improvement, making it 3 but not entirely helpful."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that 'providing these resources would be beneficial' and suggests that this would 'enhance clarity and reproducibility'. This indicates a clear action the authors should take. However, the comment does not specify *how* to provide these resources or what kind of code and supplementary documentation are needed. The action is implied but not explicitly stated in detail.", "grounding_specificity_rationale": "The comment refers to 'code' and 'supplementary documentation' but does not specify which section, table, figure, or unique aspect of the paper these relate to. While the reviewer can infer the missing parts, they are not explicitly identified. The grounding is present in the general area of code and documentation, but the specific reference within the paper is lacking.", "verifiability_rationale": "The comment contains a claim: 'providing these resources would be beneficial'. This claim is supported by the reasoning: 'This would enhance clarity and reproducibility'. These are logical statements that are generally accepted as true in the context of research and development. While external references are not provided, the benefits are based on common understanding and expected outcomes.", "helpfulness_rationale": "The review point directly identifies a practical limitation (lack of code and supplementary documentation) and offers a clear and actionable suggestion (providing these resources). The suggestion directly addresses the identified limitation and proposes a concrete improvement. While the specific *type* of code or documentation is not specified, the general area is clear, making the feedback immediately helpful for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the missing related work (REM) and suggests it as a simpler alternative. This directly points to an actionable suggestion for the authors to include and compare their method with REM.", "grounding_specificity_rationale": "The reviewer mentions 'ensembles and uncertainty estimation', which are concepts discussed in the 'Method' section of the paper. While not a direct section reference, the topic is central to the method, indicating full grounding.", "verifiability_rationale": "The reviewer claims REM's effectiveness in a relevant setting and suggests it as a simpler alternative. This is a reasonable inference based on the general principles of ensembles and their benefits in handling uncertainty, making it 3.", "helpfulness_rationale": "The reviewer suggests a simpler alternative (REM) that could potentially improve the authors' approach. This is a valuable suggestion that could save authors time and effort. The lack of a citation in the review point itself is a minor issue, but the core point is helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states a 'lack of novelty' and 'gives me the impression' that the methods have been cleverly combined. While this suggests a lack of explicit actionability, the reviewer doesn't provide a specific, actionable suggestion. The comment is more of a critique than a direct instruction for improvement.", "grounding_specificity_rationale": "The reviewer makes a general statement about the lack of novelty in the combination of methods. They do not specify a particular section, table, figure, or unique aspect of the paper that lacks novelty. Therefore, the comment does not identify a specific part of the paper being addressed.", "verifiability_rationale": "The reviewer's statement about the 'lack of novelty' is a claim that requires justification. However, the review point does not provide any external references, logical reasoning, or examples to support this claim. The statement is presented as an opinion without evidence.", "helpfulness_rationale": "The reviewer's comment is a critique of the novelty of the proposed methods. While the reviewer identifies a potential weakness, they do not offer any specific suggestions for improvement or alternative approaches. The comment is primarily negative and lacks constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review points out a practical limitation \u2013 needing to finetune a model for each language. This suggests a lack of direct, generalizable improvement. While the reviewer states the problem, they don't offer any suggestions on how to address it. They are pointing out a weakness without proposing a solution.", "grounding_specificity_rationale": "The review mentions \"for each target language a different model needs to be finetuned.\" This explicitly states which part of the paper it addresses, making it fully grounded. The comment also clearly specifies what needs to be addressed in this part, making it specific.", "verifiability_rationale": "The comment states a question about the scalability of the approach and identifies the reason as the need for finetuning per language. This is a factual observation about the current implementation, not a claim that needs verification.", "helpfulness_rationale": "The review points out a limitation of the proposed approach but does not offer any suggestions or insights on how to address it. They are pointing out a weakness without proposing a solution."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests adding 'more details for readers unfamiliar with bAbI or question answering' and clarifies that 'valid words' means 'possible answer words for the given story and question.' While it identifies a potential area for improvement, it doesn't explicitly state *what* action the author should take. The reviewer implies the need for more context but doesn't specify *where* or *how* to add it.", "grounding_specificity_rationale": "The review point explicitly refers to 'Eq.20' and the concept of 'valid words.' This demonstrates a degree of grounding as the reviewer identifies a specific part of the paper (an equation) and a specific concept within that part. While it doesn't pinpoint a specific section or table, the reference to an equation provides a degree of grounding. The explanation of 'valid words' is also somewhat specific to the bAbI task.", "verifiability_rationale": "The review point states a suggestion ('Eq.20: A bit more details...') without providing any external references, logical reasoning, or justification for why more details are needed. It's a suggestion for improvement rather than a statement of a verified issue.", "helpfulness_rationale": "The review point identifies a potential area for improvement by suggesting more background information for readers unfamiliar with bAbI. However, the suggestion lacks specific details on *where* to add the background or *how* to define 'valid words' in a way that's practically helpful for unfamiliar readers. While the intent is helpful, the lack of concrete guidance makes it less helpful overall."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that 'interestedregionbased adversarial attacking is not a novel idea' and provides a specific citation (Yao et al., CVPR 2019). This is a clear and direct statement of an action the author should take (research related work) and how to implement it (refer to the provided paper). The reviewer is not leaving any ambiguity about what needs to be done.", "grounding_specificity_rationale": "The reviewer explicitly names the 'interestedregionbased adversarial attacking' technique and provides a specific citation (Yao et al., CVPR 2019). This demonstrates a high level of grounding as the authors can easily identify the referenced part of the paper and the specific issue being addressed.", "verifiability_rationale": "The reviewer makes a claim that 'interestedregionbased adversarial attacking is not a novel idea' and provides a specific reference to support this claim. This claim is thoroughly supported by logical reasoning (the existence of prior work) and external references (the cited paper). The evidence is clear and directly relevant to the claim.", "helpfulness_rationale": "While the reviewer points out a potential issue with the novelty of the technique, they do not directly suggest concrete improvements or alternative approaches. The feedback is more of a critique than a direct guide for improvement. Therefore, it is helpful in identifying a potential area for concern but does not actively help the author revise their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the components of the proposed methods: 'coding helps, execution, consistency, distallation'. This indicates an explicit action or suggestion regarding the method. However, the reviewer does not specify *how* these components are implemented or what specific issues they are intended to address. The lack of detail makes the action somewhat vague and less actionable in terms of providing specific modifications to the draft.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed methods' in a general sense, without specifying a particular section, table, figure, or unique aspect of the paper. The reference is broad and lacks precision. Furthermore, the reviewer describes the components as 'effective' without providing specific examples or details about their implementation within the paper. This lack of specificity means the reviewer does not clearly identify what needs improvement in the draft.", "verifiability_rationale": "The reviewer makes a claim: 'the contribution of this paper may not be significant enough.' This is a statement of opinion. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a possibility without evidence, making it 1.", "helpfulness_rationale": "The reviewer expresses a negative opinion about the paper's contribution, stating 'the contribution of this paper may not be significant enough.' While this is a helpful observation for the authors to consider, the review lacks specific, actionable feedback. The reviewer does not identify specific weaknesses in the paper or suggest concrete improvements. The feedback is primarily about the overall significance, which is valuable but lacks the depth of specific, actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the issue: 'the publicly available history conversation, when used for training models, still provides some assistance in answering the final question'. It also suggests a solution: 'to address this issue'. The reviewer further elaborates by suggesting an experiment: 'performing an experiment to remove the history conversation'. This indicates a clear and direct action to be taken, making it 5.", "grounding_specificity_rationale": "The comment refers to 'multiturn data' and 'publicly available history conversation'. These are specific parts of the dataset. However, the reviewer does not explicitly state which specific dataset or section of the paper this refers to. While the specific elements are mentioned, the exact part of the paper or dataset being addressed is not definitively identified. Once the reviewer implies 'the dataset used for training', the grounding becomes more explicit. The comment does specify what is being addressed: the potential assistance provided by the history conversation, which clearly indicates what needs to be improved.", "verifiability_rationale": "The comment contains a claim: 'the publicly available history conversation, when used for training models, still provides some assistance in answering the final question'. This is a statement that requires verification. However, the comment does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion to 'perform an experiment to remove the history conversation' is a proposed solution, not a claim that needs verification. The lack of supporting evidence makes the claim 1.", "helpfulness_rationale": "The review points out a potential issue in the training data, specifically the assistance provided by the history conversation. This is a relevant concern for authors working on dialogue systems or similar tasks. The suggestion to perform an experiment to remove the history conversation is a constructive and actionable suggestion that could help the authors improve their model. While the review doesn't definitively prove the existence of data leakage, it raises a valid concern and offers a concrete way to investigate it, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question about whether TTUR was used, which implies a desire for clarification. While not directly instructing the authors on what to do, the question points to a potential weakness in their understanding or reporting. The suggestion to compare with VSD+TTUR indicates a desire for improvement in their analysis. The reviewer is prompting the authors to consider an alternative method and its potential benefits.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'TTUR proposed by DMD2 (Yin et al. 2024a)' and the 'Figure 7' in their comment. This provides a clear and specific reference point for the authors to locate and understand the relevant information. The suggestion to compare with VSD+TTUR further clarifies the intended improvement.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are simply asking a question and suggesting a comparison. There is no assertion of fact or opinion being presented that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer is asking a question to seek clarification about a methodological choice and suggesting a relevant comparison. This is generally helpful for the authors as it helps them understand their own work better and potentially improve their analysis. While it doesn't directly instruct them on what to do, it guides them towards further investigation and potentially better analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "1", "actionability_rationale": "The reviewer raises a potential issue regarding the definition of OOD actions and the assumption made in the paper. While the reviewer identifies a *potential* gap, the paper *claims* to address this by defining OOD actions and making an assumption. The reviewer's comment is a critique, not a direct instruction on how to fix it. Therefore, the actionable aspect is weak. It's not *explicitly* stating the problem needs fixing the definition, and it's not *concrete* on how to do it. It's an *implicit* critique.", "grounding_specificity_rationale": "The reviewer clearly states their understanding of the definition of OOD actions (line 109) and the assumption made in Assumption 3.1. They directly compare these two, showing a clear understanding of specific parts of the paper. The grounding is strong because the reviewer can precisely identify the sections being discussed. The criticism is also specific to the *relationship* between the definition and the assumption. Therefore, grounding specificity is high.", "verifiability_rationale": "The reviewer provides a clear statement of what they believe is a contradiction within the paper. They state the definition of OOD actions and the assumption and highlight the potential issue. This is a direct claim that can be verified by examining the cited sections. The reasoning is logical. Therefore, verifiability is high.", "helpfulness_rationale": "The core of the review point is a *critique*. It doesn't offer a direct solution or improvement suggestion. It questions the *merit* of the theoretical result, which is a metacomment about the paper's contribution, not a direct action for the authors. Therefore, helpfulness is low."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer states that the analysis is 'shallow' and lacks 'takeaways or conclusions'. This implies an explicit action: the authors should have learned something meaningful from the analysis. However, the reviewer doesn't specify *what* those takeaways should be, making the action vague. The lack of concrete suggestions makes it difficult for the authors to know exactly how to improve their analysis based on this comment alone.", "grounding_specificity_rationale": "The reviewer criticizes the analysis as 'shallow' and suggests it's 'better suited for the appendix'. While the reviewer mentions the appendix as a specific section, they don't explicitly state *why* the analysis is better suited there or what specific improvements are needed. The reviewer's comment is general and doesn't pinpoint a specific part of the analysis that needs improvement. Therefore, the grounding is weak as the authors can't confidently determine the specific issue.", "verifiability_rationale": "The reviewer states the analysis is 'shallow' and lacks 'takeaways or conclusions'. This is a judgment based on the reviewer's experience, not direct evidence within the paper. There's no specific reference to external work or logical reasoning provided to support this claim. The reviewer's statement is an opinion, making it 1.", "helpfulness_rationale": "The reviewer provides a clear critique of the analysis and suggests a concrete action: 'move to the appendix' or 'integrate appendix content into the main text'. This directly benefits the authors by guiding them on how to improve their work. The reviewer's suggestion is specific and actionable, making the comment 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing information: 'the metric of Table 1 is not clearly stated' and 'the experimental details like backbone choice, learning rate, optimization schedules are not provided'. This directly points to the need for the authors to clarify these aspects.", "grounding_specificity_rationale": "The reviewer implies the relevance of Table 1 to the missing metric but doesn't explicitly name the metric or the specific experimental details. They say 'the metric of Table 1' which is an implicit reference to the table, but doesn't pinpoint the exact element within the table that is unclear. The reviewer also doesn't specify which backbone, learning rate, or optimization schedule is missing.", "verifiability_rationale": "The reviewer makes a claim about the experimental results being unclear ('As to the experimental results, the metric of Table 1 is not clearly stated'). They also identify the specific areas where information is missing ('the experimental details like backbone choice, learning rate, optimization schedules are not provided'). This claim is supported by the identified missing information, making it 3.", "helpfulness_rationale": "The reviewer provides clear and actionable feedback on weaknesses and areas for improvement. They specifically identify the missing information (metric of Table 1, backbone choice, learning rate, optimization schedules) and suggest that this information should be provided. This feedback is directly helpful for the authors to understand and improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the advantage of POMDPs (not observing the target variable Y) and then points out that the paper doesn't leverage this advantage. It further specifies the *implication* of this advantage: 'how previous decisions changes the data observable to the decisionmaker'. This is a clear, actionable suggestion for the authors to consider.", "grounding_specificity_rationale": "The review point refers to 'previous decisions' and 'data observable to the decisionmaker'. While it doesn't explicitly name a section or table, the context strongly implies a sequential decisionmaking process where past actions influence future observations. The reviewer is also specific about the elements involved in this process.", "verifiability_rationale": "The review point presents a statement of what *should* be the case based on the principles of POMDPs. It implies that if the paper is modeling sequential decisions, the history of decisions should influence the observable data. While it doesn't provide external references, the logic connecting previous decisions to observable data in POMDPs makes this claim 3.", "helpfulness_rationale": "The review point is 5 as it identifies a specific limitation of the paper's approach within the context of POMDPs. It provides a clear direction for the authors to consider: how their model handles sequential decisions and the observability of the state. This actionable feedback is likely to be beneficial for improving their draft."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "5 (5)", "verifiability_label": "1 (1)", "helpfulness_label": "2 (2)", "actionability_rationale": "The reviewer states the values of pretraining tokens_per_sample (256) and batch_size=64, but does not explicitly recommend any specific changes or actions based on these values. The suggestions are presented as observations, not actionable steps.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'pretraining tokens_per_sample' and 'batch_size=64', indicating they are referring to specific parts of the paper and providing specific values.", "verifiability_rationale": "The reviewer states 'I don\u2019t think this is enough for a regularsize program' and 'I don\u2019t think using batch_size=64 for pretraining is enough' without providing any specific evidence or references to support these opinions. These are opinions and judgments about the adequacy of the settings.", "helpfulness_rationale": "The reviewer points out a potential issue with the experimental setup (pretraining tokens_per_sample and batch_size) but does not offer specific, actionable feedback or propose alternative approaches. The suggestions are more observational than prescriptive within the review point itself."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'This work lacks enough ablation experiments' and provides concrete suggestions for what to try, such as 'can the clustering algorithm be replaced with other approaches, e.g. KMeans?' and 'Given an ancestry, how does the model perform when being applied to differentsized descendant models?' These suggestions directly tell the authors what to investigate and how to do it.", "grounding_specificity_rationale": "The comment does not specify which part of the paper it is referring to. It makes a general claim about the lack of ablation experiments without pointing to a specific section, table, figure, or unique aspect of the paper. The reviewer is conveying a concern about the overall work without being precise about the location of the issue.", "verifiability_rationale": "The comment contains a claim ('This work lacks enough ablation experiments') but does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestions for improvement are helpful, but the initial statement lacks justification.", "helpfulness_rationale": "The comment identifies a valid weakness (lack of ablation studies) and provides concrete, actionable suggestions for improvement. This directly empowers the authors to enhance their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests benchmarking on the HIMIA dataset, which is a concrete action. However, the reviewer does not explicitly state how this benchmarking should be performed or what specific improvements are expected from this comparison. The action is implied rather than explicitly stated and implemented.", "grounding_specificity_rationale": "The reviewer mentions 'the scenario' and 'datasets such as HIMIA' as areas for improvement. While the reviewer identifies a general area (realtime data), they do not pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. The grounding is weak as the reviewer provides general suggestions without clearly linking them to a specific part of the paper.", "verifiability_rationale": "The reviewer suggests 'simulating realtime data' and 'benchmarking on the HIMIA dataset' as potential improvements. This constitutes a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support why these actions are necessary or beneficial. The claim is presented as a suggestion without sufficient justification or evidence.", "helpfulness_rationale": "The reviewer suggests benchmarking on the HIMIA dataset and simulating realtime data as potential improvements. While the reviewer provides concrete suggestions for improvement, the lack of explicit details on how to implement these suggestions makes the feedback somewhat general. The helpfulness is limited by the lack of specific guidance on the *how* of the suggested actions."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the mismatch between the introduction's focus on breast cancer and the paper's broader claims. They also suggest a concrete action: adjusting the framing of the introduction. This action is directly derived from the comment, making it explicit. The reviewer also points out that the loss function is evaluated over multiple datasets, including those outside breast cancer, further clarifying the intended scope. The suggestion to focus on the loss function and its applications is a clear and actionable recommendation for the authors.", "grounding_specificity_rationale": "The reviewer's primary criticism is the mismatch between the introduction and the paper's scope. While they don't pinpoint a specific section or table being addressed, they clearly identify the *area* of concern: the framing of the introduction. They are also specific about the *types* of mismatch: breast cancer vs. general semantic segmentation and distribution shifts. However, the *action* they suggest \u2013 adjusting the framing \u2013 is broad and not tied to a specific part of the paper.", "verifiability_rationale": "The reviewer makes a claim: there is a mismatch between the introduction's focus on breast cancer and the paper's broader claims. This claim is verifiable based on the information provided in the paper's abstract and introduction. The reviewer provides logical reasoning to support their claim, stating that the introduction focuses on breast cancer while the paper and contributions are not particularly focused on breast cancer. They also mention evaluating the loss function over multiple datasets and showing its extension to other problems, further supporting the claim of a mismatch. The claim is supported by explicit statements and logical connections.", "helpfulness_rationale": "The reviewer's point is valid and identifies a necessary change for the paper. They suggest framing the review around the loss function and its applications, which is a relevant and actionable suggestion for the authors. However, the criticism itself is quite general and doesn't pinpoint a specific issue within the introduction or the loss function's description. While it's a helpful suggestion, it lacks the specificity needed for pinpointing a particular problem."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the absence of agreement statistics in section 3.1 or 3.2 and directly suggests including them. This is an explicit action and a concrete suggestion on how to improve the draft.", "grounding_specificity_rationale": "The review point explicitly states the absence of agreement statistics in section 3.1 or 3.2. This directly identifies the specific part of the paper being addressed, making it fully grounded. It also specifies what is missing (agreement statistics) and what should be done (include them), making it specific.", "verifiability_rationale": "The review point is a statement of fact, not a claim. It does not require verification or justification. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point highlights a potential issue (missing agreement statistics) that could be relevant to the authors. By pointing out the absence of this information, it encourages the authors to check for it. While it doesn't directly solve the problem, it provides a direction for improvement, making it moderately helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer's point about the lack of novelty in the individual components and the inspiration from existing goalconditioned RL methods is an actionable insight for the authors to acknowledge the existing work and focus on the integration aspect. However, the reviewer doesn't *specifically* recommend any actions or provide concrete steps to make the integration novel. The suggestion is more general.", "grounding_specificity_rationale": "The reviewer doesn't explicitly point to a *specific* part of the paper where the lack of novelty is occurring. They are more general about the *combination* of techniques.", "verifiability_rationale": "The reviewer makes a claim about the straightforwardness of consecutive subtrajectories and the lack of novelty in the integration, which are 3. The claim about inspiration from goalconditioned RL is explicitly mentioned and can be considered verifiable. However, the claim about the straightforwardness of subtrajectories is less substantiated within the review point itself.", "helpfulness_rationale": "The reviewer is pointing out a potential weakness in the paper's contribution by highlighting the lack of novelty in the individual components and the inspiration from existing methods. This is a helpful critique as it points out a potential area for improvement in the paper's contribution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the theoretical justification for using identity mapping in attention modules. While the question implies a desire for more information, it does not explicitly state an action the authors should take. They are seeking clarification rather than a direct instruction.", "grounding_specificity_rationale": "The reviewer mentions 'identity mapping' in the context of an attention module but does not specify which part of the module or the exact issue they are addressing. The reference is general, making it difficult to pinpoint the specific aspect being questioned.", "verifiability_rationale": "The reviewer is not making a claim that something is wrong with identity mapping. They are suggesting further discussion, which is a request rather than a statement requiring verification. The comment does not contain a claim that needs to be supported.", "helpfulness_rationale": "The reviewer is asking a question about the theoretical basis of identity mapping. While this question could be valuable for the authors to understand the underlying concepts, it does not directly provide actionable advice on how to improve their draft. The comment is a request for clarification, not a statement that actively helps the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The question is direct and asks for an explanation, which can be acted upon by the author. While it doesn't explicitly state an action, it implies the need for clarification, which can be addressed with an action. The reviewer is asking for the reasoning behind their choice, which the author can then use to understand and potentially improve their model design.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'decoderonly transformers' and asks 'why'. This directly targets a specific model type. The reviewer is pointing to a specific design choice, and the author needs to identify the specific aspect being considered within that model type. This can be achieved through a literal mention of the model type and asking for the reasoning behind it.", "verifiability_rationale": "The review point itself does not contain a claim. It is a question posed to the author. Therefore, it does not have verifiability as defined in the provided definitions, which focuses on claims and supporting evidence. The *answer* to this question could potentially be a claim if the author provides a justification for their choice, but the question itself is not a claim.", "helpfulness_rationale": "The question is relevant and seeks to understand the reasoning behind a design choice. This can be helpful for the author to clarify their thinking and potentially identify areas for improvement. While it doesn't directly tell the author what to do, it encourages them to articulate their reasoning, which can be beneficial for their understanding and the overall quality of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an actionable suggestion for the authors to improve their qualitative analysis by including proportions of each error category. It also implies how to implement this action by mentioning 'details,' 'error categories,' 'underlying cause,' and 'mitigating them.' This suggests a clear and direct path for the authors to follow.", "grounding_specificity_rationale": "The review point generally does not identify a specific part of the paper being addressed. While it mentions 'qualitative analysis' and 'error categories,' it doesn't pinpoint a particular section, table, or unique aspect of the paper. Although it mentions a specific paper (Turpin et al.), it doesn't explicitly state which part of their own work this relates to. The comment is more about the general approach to analysis rather than a specific element within their paper.", "verifiability_rationale": "The review point itself is a statement of opinion and suggestion, not a claim that requires verification. It doesn't present a fact that needs to be supported by evidence. Therefore, it doesn't have a claim to be verified.", "helpfulness_rationale": "The review point provides a clear direction for the authors to improve their qualitative analysis. It suggests specific areas for improvement, such as including proportions and discussing the underlying causes. While it could be more specific about which parts of the paper to focus on (as discussed in grounding specificity), it offers a valuable and actionable direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explains the authors' reasoning for not using certain baselines (data requirements) and suggests an alternative approach (applying baselines with simple data filling). While it identifies the issue and proposes a solution, it doesn't explicitly state the action the authors should take to implement this validation.", "grounding_specificity_rationale": "The review point mentions specific machine learning techniques (Reinforcement Learning, RNNs, Wasserstein GANs) and a baseline (Markov chain approach) but does not explicitly link them to specific sections or subsections of the authors' paper.", "verifiability_rationale": "The review point makes a claim about the chosen baselines but does not provide any justification or evidence to support this claim.", "helpfulness_rationale": "The review point is helpful in that it explains the authors' reasoning for their baseline choice and suggests a concrete way to empirically validate it. However, it lacks explicit action steps for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing element: 'simple prompt for these two LLMs, and then compare it with the GEVAL method.' This is a clear, direct request for a specific experiment. The reviewer is asking for a concrete action to be taken, which is to evaluate the performance of GPT3.5 and GPT4 using basic prompts before applying the GEVAL method. This action is both explicit and concrete, as the reviewer clearly defines what the comparison should be.", "grounding_specificity_rationale": "This review point does not explicitly refer to any specific part of the paper (e.g., a section, table, figure, or unique element). The focus is on the general performance of the LLMs and the comparison with the GEVAL method. Therefore, the grounding is weak, as the authors cannot precisely identify the referenced part. The comment is highly unspecific.", "verifiability_rationale": "The review point does not contain a claim or suggestion. It is a statement of what the authors should do or should not do. While it points out a potential weakness in the evaluation process, it doesn't present a claim that requires verification. Therefore, it doesn't fit the criteria for verifiability, which involves supporting a claim with evidence or reasoning.", "helpfulness_rationale": "The review point clearly identifies a significant gap in the evaluation of the GEVAL method. By not including a baseline comparison with simple prompts, the authors fail to establish the added value of their method over standard LLM performance. This is a crucial piece of information for understanding the contribution and effectiveness of GEVAL. The reviewer's comment is directly addressing a need for more comprehensive evaluation, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point directly addresses a specific technical detail about the computation of NE gaps in multiagent environments. It identifies a potential issue with the information required for this computation, which is a clear and actionable point for the authors to consider.", "grounding_specificity_rationale": "The review point explicitly mentions the need for 'full knowledge of the game payoffs' and 'knowledge of policies of the other agents' to compute NE gaps. This directly identifies the specific components required for the calculation, providing a clear grounding for the reviewer's concern.", "verifiability_rationale": "The reviewer states a belief about the information required for computing NE gaps. While the claim itself might not be universally verifiable without further context or citations in this specific review point, the *claim* that 'this requires full knowledge of the game payoffs unlike the base policies which only get updated based on observed rewards' is potentially verifiable by examining the standard methods for computing NE gaps and policy updates. The reviewer is making a claim that can be supported or refuted with evidence from the relevant literature or algorithms.", "helpfulness_rationale": "The review point raises a valid concern about the information requirements for computing NE gaps. However, it doesn't provide a specific, actionable suggestion or improvement for the authors. It primarily highlights a potential limitation or area for further consideration rather than directly guiding them on how to update their weights. Therefore, while it raises a valid point, it doesn't directly help them improve their draft in a practical sense."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The statement 'The paper primarily compares the proposed methods with DiffUCO' is explicit because it directly names the method being compared to and uses the word 'primarily,' indicating it is the main focus of the comparison. The action being pointed out is 'comparing with DiffUCO,' and this action is clearly stated.", "grounding_specificity_rationale": "The comment 'The paper primarily compares the proposed methods with DiffUCO' is fully grounded because it explicitly mentions 'DiffUCO,' a specific method. The authors can easily identify the section or method being referred to by the name. The comment is also somewhat specific because it identifies the comparison as 'primary,' indicating it is the main focus of the comparison.", "verifiability_rationale": "The statement 'The paper primarily compares the proposed methods with DiffUCO' is a claim because it makes an assertion about the paper's content. This claim is 3 because the reviewer can infer that the paper likely contains a section or paragraph discussing the related work or experimental setup that would reveal the primary comparison method. While the exact details of the comparison might not be explicitly stated in the review point itself, the *act* of comparing with DiffUCO is implied to be the primary focus.", "helpfulness_rationale": "The review point 'The paper primarily compares the proposed methods with DiffUCO' is 3. While it doesn't directly suggest what other comparisons should be made or what other relevant baselines exist, it highlights a potential limitation in the paper's evaluation. By pointing out the limited scope of comparison, the reviewer provides the authors with a concrete piece of feedback that they can use to potentially broaden their evaluation in future work. This is more helpful than a completely negative comment that doesn't offer any specific direction."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the absence of 'explicitly defining the local subtasks and their corresponding policies, nor the relationship between them, nor providing a complete proof of this equivalence.' These are all actionable items that the authors can directly address. The reviewer clearly identifies what is missing and suggests what should be present.", "grounding_specificity_rationale": "The reviewer refers to the 'exposition of the decomposition method' and the 'relationship between local subtasks and policies' and the 'proof of this equivalence.' While they point to these aspects, they don't explicitly identify the specific section, table, or unique element where these are discussed. The reviewer implies they understand where these concepts are generally located, making it weakly grounded.", "verifiability_rationale": "The reviewer criticizes the paper for being 'repetitive and superficial' and for 'lacking a complete proof.' The 'lack of a complete proof' is a verifiable claim as the reviewer explicitly states what is missing. However, the criticism about 'repetitive and superficial' is a subjective assessment and lacks specific examples or references, making it less verifiable. The claim about the missing proof is supported by the reviewer's statement of what is absent.", "helpfulness_rationale": "The review point primarily criticizes the paper's exposition and identifies missing elements. While it points out areas for improvement, it doesn't offer a direct solution or prescription for the authors to follow. It's a critique of the current state rather than a constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the 'performance curve of each algorithm during the training' is missing. This directly identifies an action the authors should take, which is to examine or attempt to reproduce the training curves. The action is also concrete, as the specific element being referred to is clearly defined.", "grounding_specificity_rationale": "The comment explicitly mentions 'performance curve of each algorithm during the training'. This clearly identifies the specific part of the paper being addressed, making the grounding fully grounded. The comment also specifies what is missing, which is the curve itself, making the specificity high.", "verifiability_rationale": "The comment does not contain a claim. It is a statement of observation about the missing information. Therefore, it does not fall into any of the verifiability categories. The appropriate label is 'X' for X.", "helpfulness_rationale": "The comment identifies a missing piece of information (performance curves) that is crucial for understanding and reproducing the experimental setup. While it doesn't directly recommend an action, pointing out the missing element is helpful for the authors to identify potential issues or areas for further investigation. It is 3 because it highlights a specific aspect that needs attention."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the computational cost of the method as O(N^2), which is an explicit action. However, it does not provide concrete guidance on how to mitigate this cost. The reviewer identifies the problem but doesn't offer specific steps or alternative approaches. Therefore, while the action is stated, the lack of concrete guidance makes it somewhat vague in terms of actionable steps for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions 'Gaussian kernelbased graph construction method (Definition 2)' and 'largescale graphs with O(N^2) time complexity'. This directly and accurately identifies the specific part of the paper and the issue being addressed. The information is grounded and specific to the method and its complexity.", "verifiability_rationale": "The claim that the method has a computational complexity of O(N^2) for largescale graphs is a clear statement that can be verified by understanding the nature of Gaussian kernel calculations and their scaling behavior. The information provided directly supports the claim without needing external references or logical reasoning to infer it.", "helpfulness_rationale": "The review point identifies a potential limitation of a proposed method by pointing out its high computational cost for largescale graphs. This information is relevant to authors considering using this method and highlights a practical constraint. While it doesn't offer solutions, it provides a clear piece of information that can help authors make informed decisions. Therefore, it is 3 in identifying a relevant issue."}
{"actionability_label": "4", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer clearly identifies a discrepancy between the experimental results and the authors' default implementation. They state that case (3) performs best but the default is case (1). This is a direct and actionable point for the authors to consider. The reviewer also disagrees with the authors' explanation for choosing case (1), which further highlights a potential area of confusion or lack of clarity in the authors' reasoning. The reviewer is likely to use this information to understand the paper better or potentially implement the betterperforming reweighting scheme.", "grounding_specificity_rationale": "The reviewer's comment is general and does not pinpoint a specific part of the paper that they believe is missing or unclear. They are criticizing the authors' explanation for their choice of reweighting scheme. While their *criticism* might be valid, the *review point itself doesn't ground* a specific part of the paper. The reviewer is not asking for clarification on a particular section, table, or figure.", "verifiability_rationale": "The reviewer presents a claim: 'I disagree with the author's explanation that \u201cTo ensure the performance of the smallest network, we adopt the reweighting manner (1) in practice\u201d'. However, the reviewer does not provide any evidence or justification for their disagreement within this specific review point. They are stating their opinion based on their own experiments. The paper does not explicitly state the authors' explanation in this exact phrasing, but the reviewer's disagreement stems from the fact that case (3) performs better, contradicting the authors' stated reason for choosing case (1).", "helpfulness_rationale": "The reviewer's point is 5. They identify a potential issue with the authors' default implementation based on their own experiments. They highlight a discrepancy between the results and the default choice, suggesting that the authors should consider using case (3) instead. This is a constructive criticism that can help the authors improve their understanding of their method and potentially enhance the performance of their slimmable networks. The reviewer is likely to use this information to guide their authors in revising their paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states a discrepancy between the paper's claim and the results. While the reviewer claims the paper makes a specific statement about finetuning multiplicity for tabular LLMs, the reviewer does not explicitly state what the authors should do to address this discrepancy. The action is implied but not stated.", "grounding_specificity_rationale": "The reviewer refers to the paper's claim about 'finetuning multiplicity specifically for tabular LLMs'. While the reviewer doesn't provide a literal section number, the reference to the context ('finetuning multiplicity') and the data type ('tabular LLMs') suggests a degree of grounding. However, the reviewer does not specify *which* part of the paper this claim refers to, making it not fully grounded.", "verifiability_rationale": "The reviewer makes a claim that the 'main results are general and do not leverage any unique characteristics of tabular data or LLMs.' However, the reviewer does not provide any evidence or references to support this claim. The statement is presented as an assertion rather than a wellreasoned argument.", "helpfulness_rationale": "The reviewer points out a potential issue with the results not aligning with the paper's focus. However, the reviewer does not offer any concrete suggestions or guidance on how the authors should address this discrepancy. The feedback is presented as a critique rather than a constructive suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out a potential error in the mathematical formulation (double summation) and requests clarification on the function f(.). This is a clear indication of an actionable suggestion aimed at improving the technical correctness and clarity of the paper. The reviewer directly identifies the area needing clarification and the specific element (f(.)) that requires attention.", "grounding_specificity_rationale": "The reviewer directly references a specific equation (just above eq. 3) and asks for details about the function f(.). This demonstrates a high level of grounding as the reviewer can accurately pinpoint the section and element of the paper being discussed. The request for clarification on f(.) also indicates a desire for specific details about this referenced element.", "verifiability_rationale": "The reviewer's comment can be interpreted as a claim that the paper lacks sufficient detail regarding the double summation and the function f(.), requiring clarification. While not a definitive statement of an error, the request itself is a form of justification needed to verify the validity of the proposed method. The reviewer also requests details on simulating multiple layers, which can be considered a request for verifiable information to understand the challenges compared to singlelayer methods.", "helpfulness_rationale": "The reviewer's comments are highly specific and directly address potential areas for improvement in the paper. The request for clarification on the double summation and the function f(.) is a concrete and actionable feedback that can help the authors improve the technical details. The comparison to existing multilayered garment simulation methods (TailorNet, Patel et al. 2021) is also a valuable suggestion that can help the authors position their work and highlight the challenges of their approach. These points are directly actionable and provide clear guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer is asking for clarification on a specific mathematical expression and its relationship to a proposed method. While the *content* of the question is technical, the *act* of asking for clarification on a specific point within the paper suggests a lack of clear grounding of the *review point* within the paper's content. The reviewer *knows* the paper exists, but they need more information to understand the specific point being raised. The request itself isn't a complete lack of helpfulness, as the reviewer is clearly trying to understand a technical detail, but it's not directly actionable in terms of improving the paper's content.", "grounding_specificity_rationale": "The reviewer is asking a question *about* a specific mathematical expression and its relationship to a proposed method. While the *content* of the question is technical, the *act* of asking for clarification on a specific point within the paper suggests a lack of clear grounding of the *review point* within the paper's content. The reviewer *knows* the paper exists, but they need more information to understand the specific point being raised. The reviewer isn't *identifying* a gap in grounding within the paper itself, but rather *asking for clarification on a specific element.", "verifiability_rationale": "The reviewer is asking a question that implies a claim: 'Why is the supremum...?' and 'Based on this definition, how to prove that the proposed GRADE reduces this supremum?'. The request for proof implies a lack of clear justification or supporting evidence for the claim. While the reviewer is asking for a logical reasoning and common knowledge (or external references), the specific request for a *proof* suggests a potential gap in the provided explanation or the supporting evidence might be insufficient or difficult to follow. The reviewer is asking for a logical and precise explanation.", "helpfulness_rationale": "The reviewer is asking a question that requires a deep understanding of a specific mathematical expression and its relationship to a proposed method. While the request for clarification is a form of feedback, it's not immediately actionable in terms of improving the paper's content. The reviewer isn't providing a concrete suggestion or improvement based on the question. The helpfulness is limited to the potential for future action based on the clarification, but the current review point itself doesn't directly address a need for improvement in the paper's content."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for 'results and analysis' and specifically mentions 'lenient dialogue samples'. This is a clear and direct request for information. The reviewer is also asking a question ('will the performance drop?') which implies a prediction based on the analysis. The request is concrete in asking for 'results and analysis' and the question is specific to the potential impact on 'performance'. Therefore, the review point is 5 as it directly points to areas for improvement and provides a clear direction for the author.", "grounding_specificity_rationale": "The reviewer is asking for 'results and analysis on the lengthy dialogue samples'. While the *type* of dialogue is specified as 'lenient dialogue samples', the specific *samples* are not identified. The request is about *seeing* something rather than identifying a specific part of the paper. The 'analysis' aspect is also vague. The reviewer is asking for a general analysis rather than a specific analysis of a particular section or table. Therefore, the grounding is weak as the specific part of the paper is not clearly identified.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a request for information ('results and analysis') and a question ('will the performance drop?'). There is no assertion that something is wrong or that a change is needed, nor is there a claim that something will definitely happen. The reviewer is outlining a request rather than making a statement that needs to be supported. Therefore, there is no verifiable claim in this review point.", "helpfulness_rationale": "The review point is 3 as it directly points to potential areas for improvement in the author's work by asking for 'results and analysis' on 'lenient dialogue samples' and questioning the 'performance drop'. This suggests the reviewer has identified a potential issue or area where the author might need assistance. However, the request lacks specificity. The reviewer does not specify *which* lengthy dialogue samples or what kind of 'results and analysis' are needed. The question about the 'performance drop' is also general. The lack of specificity makes it less helpful as the author has a broad range of potential improvements to consider."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly names the missing modality and suggests including more, making it 5.", "grounding_specificity_rationale": "The reviewer clearly specifies the type of datasets lacking and even suggests a solution, making it 5.", "verifiability_rationale": "The claim about datasets being visually focused is supported by citations, making it 5.", "helpfulness_rationale": "The suggestion to include more modalities is relevant to improving the dataset's robustness and is a clear direction for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a similarity to existing work without explicitly stating a concrete action the authors should take. While the reviewer implies the similarity is a negative point, they don't provide a direct comparison or suggest a specific change to the model or related work section. The action is implied but not explicitly stated or actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific works ('Visual Prompt Tuning & Prompt Learning for VisionLanguage Models') and describes the similarity ('the oraclecontext model is very similar to some prompt tuning works'). This clearly grounds the reference to external work and specifies the nature of the similarity.", "verifiability_rationale": "The reviewer makes a claim by stating that the oraclecontext model is very similar to some prompt tuning works. While the reviewer doesn't provide explicit justification or references within this specific review point, the statement itself is a claim that could be verified. The lack of immediate references within the review point itself doesn't negate the existence of the claim.", "helpfulness_rationale": "The reviewer identifies a potential redundancy in the related work section by pointing out the similarity of the oraclecontext model to existing prompt tuning works. This directly highlights a weakness in the paper and suggests a concrete improvement: addressing the related work section. The reviewer provides a clear suggestion for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the weakness: 'the paper only discussed the observed phenomenon, and do not seem to deepen the research area by providing more insights how to use the consequences of these observations to design better resilient system.' It also suggests a concrete action: 'Given these observations, can we join a proposed defense method to make it more closely resemble a hierarchical system, so as to demonstrate the usefulness and significance of the observed results?'. The reviewer directly identifies the lack of actionable feedback and provides a specific suggestion for improvement, making it actionable.", "grounding_specificity_rationale": "The reviewer's comment is general and does not explicitly identify a specific part of the paper being addressed. While the suggestion to 'join a proposed defense method to make it more closely resemble a hierarchical system' is concrete, the initial statement about 'the paper only discussed the observed phenomenon' is broad and doesn't pinpoint a section, table, figure, or unique aspect of the paper. Therefore, the grounding is weak.", "verifiability_rationale": "The review point contains a claim: 'the paper only discussed the observed phenomenon, and do not seem to deepen the research area by providing more insights how to use the consequences of these observations to design better resilient system.' The reviewer suggests a potential improvement by 'joining a proposed defense method to make it more closely resemble a hierarchical system'. However, the reviewer does not provide any specific examples, references, or logical reasoning to support the claim that the paper lacks deeper insights and practical applications. The suggestion is a potential solution, not a verification of the claim. Therefore, the claim is present but not 5.", "helpfulness_rationale": "The review point identifies a potential area for improvement by suggesting a way to enhance the practical significance of the research. The reviewer explicitly states a weakness ('the paper only discussed the observed phenomenon...') and offers a concrete suggestion ('join a proposed defense method...'). While the suggestion is not a direct verification of the weakness, it provides a clear direction for the authors to consider. The reviewer's comment is helpful in prompting the authors to think about the practical implications of their findings and how they can be used to design more resilient systems. However, it doesn't provide direct evidence or proof of the identified weakness, making it less impactful than a review that directly points out a flaw with supporting evidence."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement is somewhat explicit about the LLM's 'knowledge' but lacks specificity on how this knowledge is being used or what it entails. While it implies a potential issue, it doesn't directly instruct the authors on what to do or how to improve their draft based on this LLM knowledge. The action is implied but not explicitly stated and lacks detail on how to apply it.", "grounding_specificity_rationale": "The statement refers to 'LLMs' knowledge' generally, without pinpointing a specific section, table, figure, or unique aspect of the paper. It doesn't identify a specific part of the paper being addressed. The grounding is weak because the authors cannot confidently determine which part the comment addresses. The specificity is also low as it doesn't detail what needs to be addressed in this general area of LLM knowledge.", "verifiability_rationale": "The statement itself doesn't contain a claim that can be verified. It's a subjective assertion about the LLM's knowledge and its impact on trust. There are no logical reasoning, common knowledge, or external references provided to support this statement. It's a statement of concern rather than a claim requiring verification.", "helpfulness_rationale": "The review point is about the LLM's 'knowledge' and a lack of 'reliability or trust' but does not provide any specific advice or actionable steps for the authors to improve their draft. It's a metacomment about the LLM's capabilities rather than a direct critique or suggestion of changes to the authors' work. There are no concrete actions or improvements suggested based on this point."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly asks for clarification on the use of masked selfattention in the YFuture encoder and its comparison to ProbSparse. It also asks about the impact on computational efficiency given the experimental setup described in Appendix E.2. The reviewer directly identifies the areas of the paper being discussed and asks for explanations, making the actions explicit. However, the reviewer does not provide concrete steps or modifications the authors should take, making it only partially actionable.", "grounding_specificity_rationale": "The reviewer refers to 'YFuture encoder' and 'masked selfattention' without explicitly naming a specific section, table, or unique element within the paper. While these are concepts within the model architecture, the specific component isn't directly pinpointed. However, the reviewer does reference 'Appendix E.2', which grounds the discussion to specific experiments. The grounding is somewhat specific as it relates to a particular part of the paper and its components, but not with the highest level of precision.", "verifiability_rationale": "The reviewer poses questions about the efficiency of masked selfattention compared to ProbSparse and the impact of forecasting horizons being larger than history lengths. These are claims that the reviewer is making as suggestions for improvement or areas requiring clarification. However, the reviewer does not provide any evidence, reasoning, or references to support these claims within the review point itself. The claims are stated without sufficient justification or backing.", "helpfulness_rationale": "The review point asks specific questions about a potential architectural choice (masked selfattention) and its implications for computational efficiency. These are relevant considerations for authors. However, the reviewer does not provide any answers or insights to these questions within the review point. The questions remain unanswered, and no concrete suggestions are offered. Therefore, while the questions are relevant, the lack of answers makes the review point not helpful in its current form."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The statement explicitly names 'theoretical analysis of why deep layer parameters are more suitable for distillation' as a 'lacking' element. This directly points to a gap in the paper's reasoning and provides a clear direction for improvement. The reviewer is not inferring this; they are stating it clearly.", "grounding_specificity_rationale": "The comment explicitly refers to 'theoretical analysis', 'deep layer parameters', and 'distillation'. It accurately pinpoints the specific aspect of the paper being addressed. This can be achieved through literal mentions of sections, tables, figures, etc., and by mentioning unique elements of the paper. The reviewer provides clear identification of the referenced part.", "verifiability_rationale": "The comment contains a claim ('a lack of theoretical analysis') and identifies what needs to be addressed ('why deep layer parameters are more suitable for distillation'). However, it does not provide any justification or examples to support this claim. The reasoning is missing, making it partially verifiable.", "helpfulness_rationale": "The comment identifies a specific area where the paper could be improved \u2013 the theoretical justification for using deep layer parameters in distillation. This is a valuable piece of feedback as it guides the authors to investigate and strengthen their reasoning. However, the comment does not offer specific suggestions on *how* to conduct this analysis, making it 3 as it points to a need for further work rather than providing a complete solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem (important details in the appendix) but doesn't explicitly state the action the authors should take. It implies moving details to the main text but doesn't specify how or what to move.", "grounding_specificity_rationale": "The comment mentions 'paper details' and 'appendix' but doesn't specify a particular section, table, figure, or unique element within the paper that needs addressing. It identifies the location broadly but not the specific part of the paper.", "verifiability_rationale": "The comment states a problem ('A lot of the important paper details are in the appendix. The paper is not sufficiently selfcontained.') but doesn't provide any justification, reasoning, or references to support this claim. It's a statement of fact, not a claim requiring verification.", "helpfulness_rationale": "The comment directs the authors to a specific location (appendix) where important details are likely located. This provides a clear direction for them to find information, making it 3 in guiding their search, even if the exact action isn't specified."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer identifies a limitation in the authors' experimental setup (dataset size) but does not provide specific instructions on how the authors should address this. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer's comment is general and does not specify which part of the paper or method they are referring to. There is no mention of a specific section, table, or figure.", "verifiability_rationale": "The reviewer makes a claim about the dataset size being potentially insufficient. While this could be verifiable, the reviewer does not provide specific examples or references to support this claim.", "helpfulness_rationale": "The comment identifies a potential issue but lacks specific, actionable suggestions for the authors. It is a valid observation but not a constructive critique."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the practicality of an assumption but does not explicitly state what action the author should take or how to determine the practicality. The reviewer points out a potential implementation detail that lacks a clear solution or actionable step.", "grounding_specificity_rationale": "The reviewer refers to 'assumption 3.2' and 'overloading the library with ASD subroutines,' suggesting they can identify the specific part of the paper being addressed. However, they do not specify what needs to be addressed in this part, such as how to determine its practicality or what steps to take. The reviewer identifies a potential area of concern but doesn't pinpoint the exact location or detail within the paper.", "verifiability_rationale": "The review point raises a question about the practicality of an assumption but does not contain a clear claim or opinion that requires verification. It's a statement of a potential issue rather than a definitive assertion that needs supporting evidence.", "helpfulness_rationale": "The review point raises a concern about the practicality of an assumption and asks a question about 'how hard is it?' This is a question that highlights a potential area of difficulty for the author but does not provide any actionable feedback or solutions. It does not directly help the author improve their draft by providing concrete steps or clarifications."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a potential issue ('less excitement') but does not explicitly state an action or provide concrete guidance on how to address it. While it mentions a 'methodology commonly used in data augmentation,' it doesn't explain how this methodology might lead to less excitement or what changes the authors should make. The action is implied but not explicitly stated, making it 2.", "grounding_specificity_rationale": "The review point does not specify which part of the paper is being addressed. It refers to 'a methodology commonly used in data augmentation' without linking it to a specific section, table, figure, or unique aspect of the paper. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part. This makes it 1 and specific.", "verifiability_rationale": "The review point does not contain a claim. It is a statement of observation ('Less excitement') rather than a definitive assertion or suggestion that requires verification. Therefore, it is not verifiable as it lacks a claim to be supported.", "helpfulness_rationale": "The review point identifies a potential issue ('less excitement') but does not offer concrete solutions or actionable advice to the authors. It is a statement of observation rather than a constructive suggestion for improvement. Therefore, it is not helpful on its own as it does not empower the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the discrepancy between the authors' claim ('multiimage IMP significantly can improve the quality of the LIPs in the crossdomain setting') and the visual evidence in Figure 4 ('However, from Fig. 4, the multiIMP shows essentially the same performance as others.'). The reviewer directly points out the need for the authors to reexamine their results. The action is clear: investigate the results in Figure 4. The information needed to act upon is also provided (Section 4, Figure 4). This is a concrete action with clear instructions.", "grounding_specificity_rationale": "The review point explicitly references 'Section 4' and 'Fig. 4'. The reviewer clearly identifies the specific section and figure where the discrepancy is observed. Furthermore, the reviewer specifies the *nature* of the discrepancy: 'multiIMP shows essentially the same performance as others.' This is a highly specific critique of what is incorrect in the authors' claim. The grounding is strong, and the specificity is high.", "verifiability_rationale": "The review point contains a claim ('the authors' claim ... is incorrect') and this claim is directly supported by the visual evidence in Figure 4. The reviewer provides a clear observation based on the figure, making the verifiability high. There is no need for external references or logical reasoning to verify the point; it's directly observable from the figure.", "helpfulness_rationale": "The review point is very helpful. It directly points out a clear error in the authors' interpretation of their own results. The reviewer provides a specific observation from Figure 4 that contradicts the authors' claim. This is a constructive criticism that guides the authors on where to look for evidence and how to reevaluate their findings. The feedback is actionable and directly addresses a specific claim."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'the results of this proposed method is not better than existing methods.' This is a clear indication of an actionable limitation. While it doesn't specify *how* or *where* the method is lacking, it provides a clear direction for improvement: the proposed method needs to perform better than existing methods. The reviewer is pointing out a clear weakness in the proposed approach.", "grounding_specificity_rationale": "The comment mentions 'the rank in VLN Leaderboard is 22th' and compares it to 'existing methods'. This attempts to ground the comment in a specific performance metric. However, it doesn't specify *which* aspects of the proposed method are lacking or *why* it is not better than existing methods. The grounding is present but not very specific.", "verifiability_rationale": "The comment contains a claim: 'the results of this proposed method is not better than existing methods.' This claim is supported by the ranking and the comparison to existing methods. While the specific references are not fully analyzed for verifiability in this context, the core idea of the claim is verifiable based on the provided information. The reviewer is stating a fact that can be supported by external data or common knowledge in the field.", "helpfulness_rationale": "The comment identifies a clear weakness in the proposed method \u2013 its underperformance compared to existing methods. This provides the authors with a specific area for improvement. However, the comment is somewhat general and doesn't offer specific suggestions or directions on *how* to improve the method. It highlights a problem but doesn't provide a detailed solution, making it 3 but not very actionable in terms of specific changes."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the explanation is 'not convincing'. This implies that the reviewer did not find the explanation to be direct or apparent. The reviewer did not explicitly state what action the authors should take, making it less explicit than other aspects. The lack of clarity in the explanation means the authors don't know how to apply the feedback, making it less actionable.", "grounding_specificity_rationale": "The reviewer does not specify which part of section 2.2 they are referring to when they say the discussion is 'not convincing'. They provide a general critique of the explanation of how semantic similarity is modeled. Therefore, the reviewer cannot confidently identify the specific section, table, figure, or unique aspect being addressed, making the grounding weak. The comment does not specify what needs to be addressed in this part, making it not specific.", "verifiability_rationale": "The reviewer's statement that the discussion is 'not convincing' does not present a clear claim that can be verified using logical reasoning, common knowledge, or external references. The reviewer is expressing a lack of confidence in the explanation, not necessarily pointing to a missing element that can be proven. Therefore, there is X to be evaluated for verifiability.", "helpfulness_rationale": "The reviewer states that the discussion in section 2.2 is 'not convincing of how semantic similarity is modelled with the proposed approach'. This indicates that the reviewer has identified a weakness in the paper's explanation. While the reviewer doesn't explicitly state what actions the authors should take, the identification of a lack of clarity in the explanation makes it 3 in highlighting an area for improvement. The reviewer's statement encourages the authors to revisit and clarify their explanation of the semantic similarity modeling."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem (over 10 parameters, difficulty in estimating with limited data, timevarying nature) and suggests concrete actions (discuss uncertainty, provide sensitivity analysis). Authors can directly identify modifications they should apply to their draft by addressing the uncertainty in parameter values and conducting sensitivity analysis to understand how variations in these parameters affect model performance and predictions.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the SEPAI3R3O model' and 'these parameters'. They also refer to 'limited realworld observations' and 'timevarying further exacerbates the challenge of estimation from scarce data'. This clearly identifies the specific part of the paper being addressed and the issue within it.", "verifiability_rationale": "The reviewer makes a claim about the difficulty of estimating parameters in the SEPAI3R3O model given limited data and timevarying nature. While this is a generally accepted challenge in model fitting, the reviewer doesn't provide specific external references or examples within this review point to support this claim. However, the implications of this issue are wellknown in the field of statistical modeling and machine learning.", "helpfulness_rationale": "The reviewer directly addresses a practical issue faced by the authors (parameter estimation with limited data and timevarying parameters) and offers concrete suggestions for improvement (discuss uncertainty, provide sensitivity analysis). These suggestions are actionable and would empower the authors to address the identified bottleneck in their model."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer provides a clear statement of criticism and asks a question, indicating an attempt to identify a potential issue. However, the criticism is somewhat general and lacks specific details about which assumption or parameter is being referred to. The question, 'how much can we trust the output or the output by which test methods should we trust more?' further suggests a lack of concrete action that can be taken based on the comment. The criticism is present, but the lack of specificity makes it less actionable than a highly specific suggestion.", "grounding_specificity_rationale": "The reviewer refers to 'causal parameters across domains' and names specific tests (MC, IB, and HSIC) without explicitly stating which part of the paper or method they are referring to. While the mention of specific tests provides some grounding, the lack of context or reference to a specific section, table, or figure makes the grounding weak. The reviewer does not explicitly state which assumption they are criticizing, making it difficult to pinpoint the exact issue. The mention of 'parameters' is general and does not specify which parameters are being discussed.", "verifiability_rationale": "The reviewer makes a claim about the assumption being a consequence of not having latent confounders and expresses uncertainty about the reliability of the methods without knowing how parameters change. This indicates a claim is being made. The reviewer attempts to provide some reasoning by stating that the performance of the proposed method and the relative performances of MC, IB, and HSIC test would depend on how the parameters are changing. However, the connection between the assumption and latent confounders is not clearly established or justified. The reviewer acknowledges the uncertainty about the parameter changes, which weakens the verifiability of the claim. The reasoning provided is somewhat vague and lacks specific examples or references to support the claim.", "helpfulness_rationale": "The reviewer raises a critical point about an assumption and questions the reliability of certain methods based on the potential variability of parameter changes across domains. This is a valuable point of critique and raises important questions for the authors. However, the criticism is somewhat general and lacks specific suggestions for improvement. While the reviewer provides context by mentioning specific tests, the overall feedback is more about identifying a potential issue than offering concrete solutions. The lack of specific guidance makes the feedback less helpful than a constructive critique."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a problem (questionable novelty, unclear connection to the title, weak narrative) but does not specify how to address it. It lacks a concrete action or suggestion for improvement.", "grounding_specificity_rationale": "The review point mentions general terms like 'structural optimization method,' 'paper title,' and 'narrative' but does not pinpoint a specific section, table, figure, or unique element within the paper that is problematic. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point expresses an opinion ('questionable,' 'unclear,' 'weak') without providing any supporting evidence or justification. There is no logical reasoning, common knowledge, or external references to back up the claim. The claim is not verifiable because it lacks sufficient support.", "helpfulness_rationale": "The review point is not actionable, as it does not suggest specific changes or improvements. It is also 1, lacking supporting evidence or justification. Therefore, it is unlikely to provide the authors with concrete guidance on how to improve their draft. While it identifies a potential issue, it does not offer a clear path forward, making its helpfulness minimal."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review points out a potential issue with the proof's assumption regarding lambda. While it doesn't explicitly state what the author should do, it raises a concern that the proof might need to explicitly exclude lambda=0.5 or be revised to align with standard mixup practices. This implies an action, but it's not a direct instruction.", "grounding_specificity_rationale": "The review identifies a potential flaw in the proof's assumption about lambda. It doesn't explicitly state which part of the paper the proof is referring to (e.g., a specific equation or section). The reviewer can infer the issue relates to the proof but doesn't pinpoint the exact location within the proof.", "verifiability_rationale": "The review contains a claim: 'The assumption in this proof may not be correct.' It provides some supporting information: 'The proof also requires the lambda not to be 0.5. But in standard mixup, the mixed sample can be generated in the case of lambda being 0.5.' This provides some context and a potential reason for the concern, but it doesn't definitively prove the proof is incorrect. The evidence is not 5.", "helpfulness_rationale": "The review points out a potential issue with the proof's assumption regarding lambda. While it raises a concern, it doesn't directly tell the author how to fix it. It encourages the author to investigate the proof further. The feedback is focused on identifying a potential problem rather than providing explicit, actionable steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states two actions they want the authors to take: 'highlight which set of equations have the same form as the Riccati equation' and 'extract some of the currently inlined math into environments'. These actions are direct and specific, allowing the authors to directly implement them. The reviewer clearly identifies the location of the equations (the paragraph above Theorem 3.1) and the desired outcome (highlighting and extracting).", "grounding_specificity_rationale": "The reviewer explicitly states the location of the equations to be highlighted ('the paragraph above Theorem 3.1'). This provides strong grounding for the authors to identify the relevant equations. However, the reviewer does not specify *which* equations within that paragraph have the same form as the Riccati equation, nor does he specify the exact sections of the math to be extracted into environments. The grounding is good for the location but less specific for the exact equations and environments.", "verifiability_rationale": "The reviewer's suggestion to highlight equations and extract math environments is based on their understanding of the paper's structure and the general knowledge of mathematical derivations in academic papers. While the reviewer doesn't provide a specific citation or logical reasoning beyond their interpretation, the suggestion is a reasonable and actionable improvement. The claim is implicitly supported by the common practice of presenting mathematical derivations in dedicated environments for clarity. Therefore, it is 3.", "helpfulness_rationale": "The reviewer provides two concrete suggestions for improvement: highlighting equations related to the Riccati equation and extracting inlined math into environments. These suggestions are directly actionable and address specific areas where the author could improve their paper's presentation and readability. The reviewer's request is clear and directly leads to concrete steps the authors can take to enhance their work. The helpfulness is high because the suggestions are specific, actionable, and directly relevant to improving the paper's clarity and organization."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies areas where clarity could be improved (certain sections, transitions, subjective terms) but doesn't explicitly state what needs to be changed. While the suggestion to use statistical evidence is a potential action, the review doesn't mandate its use or provide specific examples of how to apply it. The lack of concrete steps makes it partially actionable.", "grounding_specificity_rationale": "The review point explicitly names 'certain sections' and 'transitions' as areas needing improvement, and it specifically mentions 'significant' as a subjective term that could benefit from statistical evidence. This clearly identifies the specific parts of the paper being addressed and the specific issue within those parts. Therefore, it is fully grounded.", "verifiability_rationale": "The review point makes a claim that 'using statistical evidence would clarify the meaning of 'significant'' which is a claim that can be supported by common knowledge and practices within the scientific community. While the suggestion to use pvalues is a common practice, the claim itself is generally accepted knowledge and has verifiable support. Therefore, it is 3.", "helpfulness_rationale": "The review point identifies a specific area of writing clarity and suggests a potential improvement (using statistical evidence). It provides direction for the authors to take, encouraging them to consider more rigorous methods for assessing significance. While it doesn't demand specific changes, it offers valuable guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the paper lacks detailed information on graph construction, including how to define edges and construct graphs for nonEuclidean datasets. This directly points out a missing action and provides a clear direction for improvement. The reviewer is not inferring what needs to be done, but rather pointing out what is missing.", "grounding_specificity_rationale": "The review point explicitly mentions 'graph construction' as the area where detailed information is missing. While it doesn't specify the exact section or table, the concept is quite clear and directly relevant to the paper's content. This indicates a level of grounding, as the reviewer is referring to a specific aspect of the paper.", "verifiability_rationale": "The review point makes a claim that 'the detailed information for graph construction is missing.' This is a clear statement that can be verified by examining the paper. While the reviewer doesn't provide the missing information or the reason for its absence, the claim itself is verifiable based on the reviewer's observation of the paper's content.", "helpfulness_rationale": "The review point is 5 because it directly identifies a gap in the paper's description of graph construction. It provides a clear and actionable suggestion for the authors to improve their work by including this missing information. The reviewer is not making assumptions about the authors' understanding but rather pointing out a specific area that needs clarification or detail."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "actionable", "grounding_specificity_label": "3", "verifiability_label": "actionable", "helpfulness_label": "helpful", "actionability_rationale": "The reviewer explicitly states a problem (unclear Table 4, lack of clarity on the impact of the attention model) and directly asks a question to seek clarification: 'Table 4: what are the visual / textual representations used in each method? otherwise it is unclear whether the endtoend performance gain is due to proposed attention model.' This directly addresses the need for information and is a clear action the reviewer is taking.", "grounding_specificity_rationale": "The reviewer mentions 'Table 4' but does not specify which part of the paper or section this refers to. While the request for 'visual / textual representations' is specific, the initial reference to 'Table 4' is weakly grounded. The reviewer could have been more specific by mentioning 'Table 4 in Section 5' or 'Table 4 showing performance gains'.", "verifiability_rationale": "The reviewer makes a claim: 'the endtoend performance gain is due to proposed attention model.' This claim is verifiable if the reviewer can provide details about the representations in Table 4 and how the attention model contributes to the performance gains. The request for 'visual / textual representations used in each method' is the evidence needed to verify this claim.", "helpfulness_rationale": "The reviewer's question directly addresses a potential point of confusion regarding Table 4 and the attribution of performance gains. By asking for clarification on the representations, the reviewer is seeking to improve the understanding and potentially the clarity of the paper. This is a helpful feedback point for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out areas for improvement, such as the lack of 'driving force' and 'illustration' for the studied problems. While they identify specific issues like 'uncertainty calibration' and 'small datasets,' they don't explicitly state how the authors should address these. The suggestions are implied rather than directly actionable. For example, the reviewer suggests 'organizing and summarizing' the issues, but doesn't specify which sections or tables need this organization. Therefore, while the problems are relevant, the lack of explicit action steps makes it less actionable.", "grounding_specificity_rationale": "The reviewer mentions specific problems like 'uncertainty calibration' and 'small datasets,' indicating some level of grounding. However, they don't explicitly state which sections, tables, or unique aspects of the paper these issues relate to. The reviewer uses general terms like 'the studied issues' and 'the problems,' which makes it difficult to pinpoint the exact location of the problem within the paper. Therefore, while the issues are mentioned, the lack of specific references makes the grounding underspecific.", "verifiability_rationale": "The reviewer criticizes the 'insufficient description' of 'uncertainty calibration' and suggests 'new readers' find it unfriendly. They propose 'organizing and summarizing' the issues as a solution. However, the reviewer doesn't provide any alternative ways to describe the issues or any external references to support their claim. The criticism is based on the current state of the description without offering any positive suggestions or justifications for why it's insufficient. Therefore, the claim is not supported by any evidence or alternatives, making it 1.", "helpfulness_rationale": "The reviewer clearly identifies specific problems with the current version of the paper, such as the 'lack of driving force' and the 'insufficient description' of 'uncertainty calibration.' They directly point out what is missing and suggest concrete improvements like 'organizing and summarizing' the issues. This directly addresses the authors' needs for a clearer and more comprehensive presentation of the studied problems. The suggestions are specific and actionable, providing a clear path for improvement. Therefore, the review provides valuable and constructive feedback that empowers the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a gap in the literature regarding the combination of PACtuning and other finetuning techniques. While it suggests a potential area of research, it doesn't explicitly state an action or provide concrete steps on how to explore this combination. The action is implied but not directly stated.", "grounding_specificity_rationale": "The review point explicitly mentions 'PACtuning' and 'other finetuning techniques such as pruning and data augmentation'. This clearly identifies the specific parts of the paper (or the concepts) being addressed, making the grounding fully explicit.", "verifiability_rationale": "The review point is a statement of fact: 'there are no results exploring the incorporation...'. While it implies a lack of evidence, it doesn't provide specific examples, references, or logical reasoning to support this claim. The verifiability is limited as it relies on the authors' knowledge and the current state of the field, rather than a direct citation or logical deduction from a premise.", "helpfulness_rationale": "The review point identifies a relevant gap in the literature and suggests a potential area for future research. It provides a clear direction for the authors to explore, making it 3 in guiding their work. However, it doesn't directly suggest specific methods or experiments to conduct, thus not being 5 in terms of actionable steps."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out specific weaknesses in the experimental section, such as the lack of ImageNet experiments and the marginal improvement of the proposed method over baselines. While the reviewer suggests improvements, the action is not explicitly stated. The reviewer implies that the authors should conduct ImageNet experiments and investigate the significance of the proposed method.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific papers (1 Zagoruyko et al. DiracNets: Training Very Deep Neural Networks Without SkipConnections. and 2 Qi et al. Deep Isometric Learning for Visual Recognition. ICML 2020.) as examples of alternative methods. This clearly indicates that the reviewer can identify the specific parts of the paper or relevant concepts being addressed.", "verifiability_rationale": "The reviewer provides specific examples of alternative methods and their papers, which serves as evidence for the weaknesses in the proposed method. The reviewer also points out the lack of ImageNet experiments as a weakness that could be further investigated. The claim that the proposed method only has marginal improvement over the baselines is supported by the experimental results mentioned in the review point.", "helpfulness_rationale": "The reviewer clearly identifies weaknesses in the paper's experimental validation and provides concrete suggestions for improvement, such as conducting ImageNet experiments and investigating the significance of the proposed method. The suggestions are actionable and directly address the identified limitations."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a comparison between the robustness and immunizability of the proposed method and the method proposed in Yu et al. 2021. This is a clear and direct action that the authors can readily follow and implement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'robustness' and 'immunizability' as the aspects to be compared and names the specific paper 'Yu et al. 2021' as the basis for this comparison. This provides clear grounding and identifies the specific section or concept being addressed.", "verifiability_rationale": "The reviewer makes a claim that there is a lack of comparison between the robustness and immunizability of the two methods. This claim is verifiable by the authors themselves, as they can perform the comparison and potentially identify areas for improvement in their method based on the findings of Yu et al. 2021.", "helpfulness_rationale": "The reviewer states that this comparison would be 'helpful' for the authors in improving their draft. This claim is verifiable by the potential benefits of understanding the comparison, such as identifying weaknesses in their method or areas where their method excels."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the algorithm's purpose ('proposes an algorithm...to produce arguably 'better' samples') and suggests an improvement ('a plot of time complexity...'). This constitutes an explicit action. However, the reviewer does not specify *how* the algorithm achieves 'better' samples or provide concrete steps for improvement. The suggestion of a time complexity plot is a concrete action, but the general feedback lacks specific details.", "grounding_specificity_rationale": "The reviewer mentions 'adaptive topk decoding' and 'm', which implies a specific aspect of the algorithm. However, they do not explicitly state the *section*, *table*, *figure*, or *unique element* of the paper where this algorithm is described. Therefore, the grounding is weakly grounded. The reviewer also suggests a time complexity plot as an improvement, which is somewhat specific, but the general feedback lacks detail on what needs to be improved in the algorithm itself.", "verifiability_rationale": "The reviewer states a desire to clarify something ('that please let me know if I am misunderstanding something'). This constitutes a claim. However, the reviewer does not provide any evidence, justification, or external references to support this claim. The suggestion of a time complexity plot is a potential improvement, not a verifiable claim about the existing work.", "helpfulness_rationale": "The reviewer's primary feedback is about the potential benefits of the proposed algorithm and suggests an improvement. While they express a desire for clarification, the feedback itself does not identify specific weaknesses or actionable steps for the authors based on this review. The lack of concrete criticisms makes the feedback less helpful in guiding the authors towards improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that the postprocessing effort is unclear but does not specify what action they would like the authors to take or how to clarify this. The comment is a statement of a problem without a proposed solution.", "grounding_specificity_rationale": "The reviewer mentions 'postprocessing effort' in general, without specifying which part of the paper or analysis this refers to. They also do not detail what is unclear about this effort. The comment is too vague to pinpoint the specific issue.", "verifiability_rationale": "The reviewer makes a claim that the 'postprocessing effort here is not clear' but does not provide any evidence, reasoning, or references to support this claim. The statement is presented as an observation without justification.", "helpfulness_rationale": "The reviewer points out a lack of clarity in the 'postprocessing effort' but does not explain why this lack of clarity is a problem for the authors or how it affects their work. The comment is a statement of a problem without a clear explanation of its significance or impact."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a missing action: 'have the author(s) run the codes...'. This is a direct and explicit instruction. While it doesn't provide specific details on how to run the code or what parameters to use, it clearly identifies an action that needs to be taken. Therefore, it is considered explicit.", "grounding_specificity_rationale": "The review point explicitly refers to 'the author(s)' and 'the codes'. This directly identifies the specific part of the paper and the tools involved. Therefore, it is fully grounded. The review also mentions 'multiple seeds' and 'reported the mean', which are specific details about the experimental setup and reporting. Therefore, it is also specific.", "verifiability_rationale": "The review point does not contain a claim in the sense of stating an opinion or judgment. It is a request for information or clarification. Therefore, it does not have supporting evidence or justification. It falls under the 'X' category.", "helpfulness_rationale": "The review point identifies a potential weakness in the authors' reporting by pointing out the absence of information about running codes with multiple seeds and reporting the mean. While it doesn't directly tell the authors what to do, it highlights a specific area where they might have missed important details for reproducibility and robustness. This makes it 3 in identifying a gap in their reporting."}
{"actionability_label": "Medium", "grounding_specificity_label": "High", "verifiability_label": "Low", "helpfulness_label": "Medium", "actionability_rationale": "The review point explicitly states the question about the difference between the BCI and IHC4BC datasets and why the experimental setup differs. It also points out the discrepancy in results for specific models across different tables. The reviewer is implicitly suggesting that this discrepancy needs attention. While the reviewer doesn't directly tell the authors what to do, they are identifying a potential issue in the presented results, which is a form of actionable feedback.", "grounding_specificity_rationale": "The review point explicitly mentions 'Table 3' and 'Table 2' as well as specific models 'InceptionV3' and 'ResNet'. This clearly identifies the specific parts of the paper being referenced, indicating strong grounding. The reviewer is also specifying what is missing (results for these models) and where it is missing (the mentioned tables), making the grounding very specific.", "verifiability_rationale": "The review point makes a claim about the inconsistency in the reported results for specific models across different tables. However, it does not provide any justification or evidence for this claim. The reviewer is stating an observation that requires verification but doesn't offer any logical reasoning, common knowledge, or external references to support it. Therefore, the claim is 1 based on the information provided in the review point.", "helpfulness_rationale": "The review point identifies a potential inconsistency in the reported results. While this could be helpful for the authors to identify and investigate, the reviewer does not provide any specific guidance or suggestions on how the authors should address this issue. The reviewer is pointing out a problem that the authors might need to explore on their own, rather than directly guiding them on how to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the desire for a 'thorough description' of the results in Fig 4, which is a direct request for action. However, the 'how' of this description is not specified, making it somewhat vague. While the reviewer wants more detail, the exact nature of this detail is not defined.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Fig 4', which grounds the comment to a specific part of the paper. However, the request is for a 'thorough description' of the *results* shown in the figure, which is a general request for more information rather than pinpointing a specific element within the figure that needs improvement. Therefore, while grounded, the specificity of the request is limited to the figure as a whole.", "verifiability_rationale": "The review point does not contain a claim or assertion. It is a request for more information or clarification about the results presented in Fig 4. Since there is X, there is no verifiable aspect to evaluate.", "helpfulness_rationale": "The review point is a request for more detail on the results in Fig 4. While this information can be helpful for the authors to understand the findings better, it is not a constructive critique or a specific suggestion for improvement. It is more of a request for clarification than a critique or actionable feedback, making it 3 but not highly so."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The review points to a relevant work and suggests a type of comparison, implying an action, but it doesn't explicitly state the action to be taken.", "grounding_specificity_rationale": "The review explicitly mentions '11' and refers to 'the method part' or 'more details,' clearly identifying the relevant section.", "verifiability_rationale": "The review suggests a specific way to improve the comparison, which can be considered a claim. The suggestions to compare in the method or with more details provide some justification.", "helpfulness_rationale": "The review points to a relevant missing element (11) and suggests a way to improve the comparison (more details). While the suggestion is not fully specific, it offers a helpful direction for the author."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their concern about the justification of the word removal and cleaning process, indicating an awareness of a potential issue. While they don't specify the exact action to take, they clearly identify a potential flaw in the methodology. This makes the comment actionable in the sense that it points to a potential area for improvement or further investigation. However, the action is not concretely defined, making it somewhat implicit.", "grounding_specificity_rationale": "The reviewer refers to 'the paper's process of removing words with identical English counterparts in the class label translation and cleaning' and even provides a citation related to vocabulary creation. This clearly identifies the specific aspect of the paper being addressed, making the grounding fully grounded. The reviewer also explains *why* they think the process might not be fully justified, adding some specificity to the issue.", "verifiability_rationale": "The reviewer makes a claim that 'the paper's process ... may not be fully justified'. They provide a citation to a survey paper, which, while not a direct proof, offers external knowledge relevant to the issue of shared words in vocabulary creation. This provides some level of support for the claim, making it 3.", "helpfulness_rationale": "The reviewer points out a potential issue with a specific part of the paper (the word removal and cleaning process) and provides a reason for their concern. This is likely to be helpful for the authors as it identifies a potential area for improvement or clarification. The reviewer's suggestion to consult a survey paper further enhances the potential for helpfulness."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point is a statement of opinion ('might be better') without specific suggestions for improvement. It doesn't directly tell the authors what to change or how to apply it. The action is implicit, and the concrete steps are missing.", "grounding_specificity_rationale": "The reviewer mentions 'LLaVA' and 'InstructBLIP' as examples of 'large visionlanguage models,' which grounds the suggestion to specific elements of the paper. However, the suggestion to 'draw some conclusions for large visionlanguage models' and 'studying more models' are somewhat vague and lack specific examples or criteria for selection.", "verifiability_rationale": "The review point suggests 'It might be better to study more models.' This is a suggestion or recommendation, which can be interpreted as a claim that the current focus is limiting. However, the comment doesn't provide a logical reasoning or external references to support this claim. The suggestion itself is somewhat general and lacks specific examples or criteria for selection.", "helpfulness_rationale": "The review point identifies a potential limitation (reliance on specific models) but doesn't offer concrete, actionable steps for the authors to take. It's a suggestion for improvement but lacks specific guidance on how to implement it. The benefit is incremental, as it prompts the authors to consider a broader range of models, rather than providing a clear path forward."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the discrepancy between Figure 7 and Table 3 regarding OpenCLIP's performance and asks for an explanation. This is a clear and direct request for action, making it 5. The reviewer identifies the specific issue (lack of significant improvement in object localization despite potential benefits of using Register) and suggests a solution (further explanation). This demonstrates a clear understanding of the need for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 7,' 'Table 3,' 'OpenCLIP,' and 'object localization' in their review point. This demonstrates a high level of grounding specificity as the reviewer accurately identifies the parts of the paper and the specific issue being addressed. The mention of 'Register' further clarifies the context of the issue.", "verifiability_rationale": "The reviewer claims that there is a significant reduction in performance for OpenCLIP in Figure 7, yet no significant improvement in object localization in Table 3. This constitutes a claim that requires verification. While the claim itself is not definitively verifiable without the actual data from the figures and tables, the request for an explanation implies that the authors have observed this discrepancy and believe it warrants further investigation. The reviewer's request to 'further explaination' suggests an attempt to justify or provide evidence for this claim, making it 3.", "helpfulness_rationale": "The reviewer's review point directly addresses a practical concern for the authors: the discrepancy in OpenCLIP's performance and the lack of improvement in object localization. The reviewer explicitly asks 'what it means for the adoption of Register,' which is a highly relevant and actionable question for the authors. The request for an explanation directly addresses a need for improvement and provides a clear direction for the authors to focus their attention. This makes the review point 5 in guiding the authors towards a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of clarity about how the 3D point cloud is used in the GAN training process. While the reviewer understands the general concept of using a latent code z for GAN training and modulating weights, the specific role of the point cloud is not clearly explained. The reviewer identifies this as a missing detail that needs to be addressed. The action is implicit (the reviewer *should* be able to infer the point cloud's role), but the action itself (identifying the missing detail) is vague as the exact mechanism is not specified.", "grounding_specificity_rationale": "The reviewer mentions 'Section 3.3' in their review, indicating they can identify the specific part of the paper being addressed. This demonstrates 'Full Grounding'. However, the reviewer then states, 'In particular, Section 3.3 explains how the latent code z is used to modulate the weights of the rendering network, but the how is the Point cloud used in this stage?'. This indicates that while the section exists, the specific details of how the point cloud is used within that section are not provided. Therefore, the grounding is present but not fully specific.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity regarding the use of the 3D render and GAN objective. This claim is supported by the statement, 'It is unclear how the 3D renders are used along with G.' The reasoning is that the reviewer understands the general concept of GANs but is missing the specific implementation details for this particular application. The evidence is the reviewer's own confusion about the 3D rendering's role. Therefore, the claim is supported by logical reasoning and the reviewer's observation of a lack of detail.", "helpfulness_rationale": "The reviewer's point is directly aimed at improving the clarity and completeness of Section 3.3. They are providing a suggestion for improvement by asking for more details on how the 3D rendering and GAN objective are combined. This is a clear and actionable suggestion. The reviewer understands the general concepts involved, making the grounding somewhat complete, but the specific implementation details are missing. Therefore, the feedback is helpful because it points to a genuine gap in the explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue (increased hyperparameters, lack of convincing evidence for parameter insensitivity) but doesn't explicitly state what the authors should do. They are highlighting a concern, which could be actionable, but lacks specific guidance.", "grounding_specificity_rationale": "The reviewer refers to 'the QIF model,' 'the LIF model,' 'hyperparameters,' and 'parameter insensitivity,' which implies they are referring to specific parts of the paper. They also specify the nature of the supporting evidence (simple architectures and datasets). While not a direct citation, the context makes the grounding relatively clear, and the specificity of the issue is evident.", "verifiability_rationale": "The reviewer makes a claim ('the supporting evidence relies heavily on simple architectures and datasets, which is not convincing') but provides no evidence or justification for this claim. They are stating an opinion without backing.", "helpfulness_rationale": "The reviewer raises a valid concern about the experimental setup and the strength of the claims made. However, they don't provide specific suggestions or guidance on how the authors should address this. The impact is indirect."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out 'marginal improvements over baselines' and suggests 'other PLMs better than BERT' as potential alternatives. While they identify a limitation of the current approach, they do not provide specific steps or actions to address this limitation. The suggestions are presented as possibilities but lack concrete implementation details. Therefore, the reviewer's comments are vague and lack actionable information for the authors.", "grounding_specificity_rationale": "The reviewer raises a general concern about the significance of the improvements and suggests exploring 'other PLMs better than BERT' and discussing 'computational costs or realworld scenarios.' They do not explicitly identify a specific part of the paper or methodology where these concerns are directly relevant. The questions are broad and do not pinpoint a particular section, table, figure, or unique aspect of the paper. Therefore, the reviewer's comments are 1 at the specific level of the paper.", "verifiability_rationale": "The reviewer asks, 'I wonder if we should pursue such a sophisticated framework to achieve this level of performance.' They suggest exploring 'other PLMs better than BERT' and discussing 'computational costs or realworld scenarios.' While they offer *some* justification for exploring alternatives, they do not provide concrete evidence or examples to *verify* their claims. The suggestions are reasonable hypotheses but lack rigorous backing within the review itself. Therefore, the reviewer's comments are 3 but lack strong supporting evidence.", "helpfulness_rationale": "The reviewer poses a question, 'I wonder if we should pursue such a sophisticated framework to achieve this level of performance.' They also suggest exploring 'other PLMs better than BERT' and discussing 'computational costs or realworld scenarios.' While these suggestions are actionable and directly address the concern about the significance of the improvements, the reviewer does not provide any concrete evidence or examples to *support* these suggestions within the review itself. The suggestions are presented as possibilities but lack definitive proof. Therefore, the reviewer's comments are 3 but lack definitive evidence to fully support the suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a lack of clarity regarding 'harassignment' and 'soft assignment' in the methodology description. While the reviewer identifies a potential issue, the review does not explicitly state what action the authors should take or how to address the lack of clarity. The reviewer is asking a question about the methodology rather than providing a direct instruction. Therefore, the action is implicit, making it 2.", "grounding_specificity_rationale": "The reviewer explicitly names 'harassignment' and 'soft assignment' in the methodology description, clearly identifying the specific part of the paper being addressed. However, the reviewer does not specify what is wrong with the explanation or how the authors should improve their understanding of these assignments. The grounding is present, but the specificity is lacking.", "verifiability_rationale": "The reviewer states, 'Is it unclear to you whether the authors have reported an experiment allowing to prove their conjecture?' This is a claim requiring justification. The reviewer does not provide any evidence or reasoning to support this claim. The verifiability is low as there is no supporting information provided.", "helpfulness_rationale": "The reviewer's primary concern is the lack of clarity regarding 'harassignment' and 'soft assignment' and the question about an unreported experiment. This directly impacts the authors' ability to understand and potentially validate the conjecture. The reviewer does not offer any actionable feedback or verification, making it unhelpful in its current state."}
{"actionability_label": "4", "grounding_specificity_label": "UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a limitation of the methods and suggests a direction for improvement by applying them to 'new clients'. This is an implicit action suggesting testing on a broader range of clients. While the specific *how* of this application isn't detailed, the reviewer provides a clear *what* (new clients). Therefore, it's not '1' as it implies a concrete next step, but it's not fully explicit.", "grounding_specificity_rationale": "The review point discusses the applicability of the methods to 'federated learning problems' and the distinction between 'crosssilo' and 'general federated learning'. While it mentions these general concepts, it doesn't explicitly identify a specific section, table, figure, or unique element within the paper being criticized. The grounding is present but at a higher level of generality, making it underspecific.", "verifiability_rationale": "The review point presents a statement about the limitations of the methods and suggests a potential area for future work (applying to new clients). It doesn't explicitly claim that the methods are only suitable for crosssilo settings or that they are ineffective in general federated learning. There is no assertion that requires logical reasoning, common knowledge, or external references to be considered verifiable. It's a statement of observation and suggestion, not a claim needing validation.", "helpfulness_rationale": "The review point identifies a limitation of the presented methods and suggests a potential area for improvement by applying them to 'new clients'. While it points out a valid concern and offers a constructive suggestion, it doesn't provide specific, actionable steps on how to implement this suggestion or what data or experiments would be needed. It's a somewhat negative comment followed by a potential positive direction, but without concrete guidance, it's not 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly defines 'distributional generalization' in the context of regression and provides a concrete example of how it manifests in smooth regression models. The action is clearly stated, and the method of achieving it (understanding the concept and its implications) is also specified.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'distributional generalization' in the context of 'regression'. They also provide a concrete example (smooth regression models) to illustrate the concept, making it clear what is being referred to within this specific domain.", "verifiability_rationale": "The reviewer makes a claim about 'distributional generalization' in the setting of regression and provides an example. While not explicitly citing external sources, the information is generally accepted knowledge within the field of machine learning and statistics. The claim is supported by logical reasoning and a clear example.", "helpfulness_rationale": "The reviewer's comment directly addresses the concept of 'distributional generalization' in the context of regression, providing a definition and an illustrative example. This is directly relevant and helpful for an author who might be encountering this concept or needing clarification. The information is presented clearly and concisely."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action (reviewing and updating references) but does not specify how to carry out this action. It lacks concrete details on which papers are out of date and how they are relevant.", "grounding_specificity_rationale": "This comment is 1 at all. It does not identify a specific area in the paper. The comment is highly unspecific.", "verifiability_rationale": "The comment contains a claim ('references and baselines are out of date') and, while it suggests a connection to the ease of finding results, it doesn't explicitly state how this claim is verified or supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The comment identifies a valid concern (outdated references) and offers a general suggestion (include more recent work). However, it lacks the specific details needed to be truly helpful. Authors would likely need more specific guidance on which papers to include and how to evaluate their relevance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a need for 'more indepth analysis' regarding highdimensional action spaces. This is a clear and actionable suggestion.", "grounding_specificity_rationale": "The reviewer refers to 'highdimensional action spaces' and provides a specific example of such a space ('complex robotic manipulators'). This demonstrates strong grounding as the specific part of the paper being addressed is clearly identified.", "verifiability_rationale": "The reviewer makes a claim about the need for 'more indepth analysis' in a specific area. While they don't provide external references to *prove* this suggestion is beneficial, the suggestion is logically derived from the observation made in the introduction about the challenges of highdimensional spaces. It's a reasonable and logical next step.", "helpfulness_rationale": "The review point is 5 as it directly points out a limitation in the experimental analysis and provides a clear direction for future work. The suggestions are concrete and directly relevant to the paper's core topic and potential impact. It helps authors understand what needs revision and why."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for information on 'how much extra computation is need to achieve such good results'. This is a direct and explicit request for a specific type of information, making it 5. The authors can directly identify the missing information they need to address the comment.", "grounding_specificity_rationale": "The reviewer refers to 'the experimental results' as the part of the paper where the missing information should be. While the reviewer doesn't explicitly name the section, table, or figure, they can reasonably infer that 'the experimental results' refers to a specific section of the paper. This allows the authors to identify the relevant section where the missing information might be located. However, the reviewer doesn't specify *what* exactly is missing within that section, making it somewhat specific in terms of the location but not fully specific in terms of the content.", "verifiability_rationale": "The reviewer states that 'there is no information on how much extra computation is need to achieve such good results'. This is a claim that needs to be verified. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a fact without any backing. Therefore, the verifiability is low as there is no evidence provided to support the claim.", "helpfulness_rationale": "The review point raises a valid concern about the computational cost associated with the good experimental results. It suggests that the authors should investigate whether the performance is robust to changes in computational resources or model parameters. This is a relevant point for the authors and provides a direction for them to explore further. While the suggestion is general, it is still a helpful direction for the authors to consider. The reviewer is pointing out a potential area for improvement or further investigation in the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement implies a lack of convincingness in the evaluation, which can be interpreted as an implicit action. However, the specifics of what is not convincing are not detailed, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer is referring to the 'evaluation and the results' in general, not a specific section or table. There is no explicit mention of a particular part of the paper being addressed, making the grounding weak. The criticism is broad, affecting the entire evaluation process, not a specific aspect.", "verifiability_rationale": "The reviewer states that the evaluation and results are 'not very convincing' without providing any specific examples, references, or logical reasoning to support this claim. This statement is presented as a judgment without justification, making it 1.", "helpfulness_rationale": "The review point criticizes the evaluation process itself, stating it is 'not very convincing' and lacks 'statistically significant' improvements. This is a negative statement about the evaluation's quality and does not offer any actionable feedback or suggestions for improvement, making it not helpful to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The reviewer states that 'several questions require subjective answers' which is an implicit statement about a potential issue with the questions themselves. While they identify the *type* of issue (subjective answers), they don't explicitly tell the authors *how* to determine which questions are subjective or *how* to address them. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer states 'several questions' which is a general reference to the questions. While they imply these are the questions being discussed, they don't specify which section, table, figure, or unique element of the paper these questions relate to. The grounding is weak because the authors have to infer the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim that 'several questions require subjective answers'. This claim could be considered 3 if the authors were to investigate the nature of these questions through methods like interannotator agreement or by examining existing literature on what constitutes a subjective question in their field. However, the reviewer doesn't provide specific examples or references to support this claim, making it 3 but lacking robust evidence within the review itself.", "helpfulness_rationale": "The reviewer's comment is primarily about the *nature* of the questions and suggests methods to *investigate* them. While this is valuable information for the authors to consider, it doesn't directly provide actionable feedback on how to *improve* their current draft. It's more of a suggestion for future analysis rather than a direct improvement suggestion."}
{"actionability_label": "2", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the evaluation of the method but does not explicitly state what the authors should do to improve their draft based on this criticism. It identifies limitations in the evaluation process (single dataset, limited NLP tasks) but does not provide concrete, actionable steps for the authors to take to address these limitations. Therefore, it is not directly actionable for the authors to improve their draft based on this review point.", "grounding_specificity_rationale": "The review point explicitly mentions 'a single dataset' and 'limited NLP tasks (intent recognition)' as areas of concern. These are specific aspects of the paper being evaluated. The authors can infer that the reviewer is pointing out issues related to the evaluation's scope and the types of NLP tasks considered. While not explicitly stating 'improve the evaluation' as a step, the mention of specific limitations allows the authors to understand what needs to be addressed. Therefore, it is grounded, although the action is somewhat implicit.", "verifiability_rationale": "The review point makes claims about the evaluation being 'weak' and lists specific limitations ('only a single dataset, and limited NLP tasks'). This constitutes a claim that requires verification. The reviewer provides some justification for the 'weak evaluation' by stating the limitations, which can be considered logical reasoning. However, the justification lacks external references to support the claim of 'weak evaluation'. Therefore, it is 3, as it provides some reasoning but lacks external support.", "helpfulness_rationale": "The review point criticizes the evaluation of the method. While it identifies areas for improvement in the evaluation process, it does not offer specific, actionable feedback to the authors on how to improve their draft based on these criticisms. The criticism is about the evaluation, not about specific weaknesses in the authors' work that need improvement. Therefore, it is not particularly helpful for the authors to improve their draft based on this review point."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action to be taken: 'Figure 3: class semantic feature should be labeled as 's\" instead of \"c\"'. This is a clear and direct instruction for the author. The action is to change the label from \"c\" to 's\" in Figure 3. The method is implied as correcting the figure.", "grounding_specificity_rationale": "The reviewer explicitly identifies the part of the paper being addressed as 'Figure 3'. This is a literal mention of a specific element in the paper. Furthermore, the suggestion is to change the label of the 'class semantic feature' within this figure. This is a very specific instruction about a particular part of the paper and a very specific change being made.", "verifiability_rationale": "The review point itself does not contain a claim about the *state* of the label. It's more of a suggestion. However, the *implied* claim is that the current label ('c') is incorrect and the suggested label ('s') is the correct one. This is an inferential claim. The reviewer does not provide any evidence or reasoning to support why 'c' is wrong and 's' is right. They are just making a suggestion.", "helpfulness_rationale": "The review point directly points out a potential error in the figure's label and provides a clear, actionable suggestion for correction. The author can directly identify the issue in Figure 3 and the specific action to take is to change the label from 'c' to 's'. This is a very helpful and specific piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the similarity between the method and face swapping and highlights the key difference (3DMM vs. real faces). This is an explicit statement of comparison. While the reviewer doesn't specify *how* this difference is significant, the intent is clear. The reviewer also suggests a comparison, which is a concrete action pointing towards a specific type of analysis.", "grounding_specificity_rationale": "The reviewer mentions 'stateoftheart face swapping algorithms' and suggests a 'comparison'. While the reviewer implies the relevance of this category, they don't specify *which* algorithms or *how* the comparison should be conducted. The reviewer could be more explicit about the specific aspects of the comparison needed.", "verifiability_rationale": "The reviewer makes a claim about the similarity to face swapping and suggests a comparison. They also attempt to justify this by mentioning deepfake technology and the difference in face source. However, the reviewer doesn't provide specific examples, citations, or detailed reasoning to support this claim or the need for the comparison. The justification is highlevel and lacks concrete evidence.", "helpfulness_rationale": "The reviewer points out a relevant similarity to an existing technique (face swapping) and suggests a comparison. This is a relevant observation that could help the authors understand the novelty and potential limitations of their method. While the suggestion for comparison is vague, the core idea is actionable and informative. The reviewer's intent is to draw attention to a relevant area of research."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the experimental results on word embeddings in Tables 1 and 2 are not very compelling and suggests comparing them to Gaussian embeddings, the chief baseline from the literature. This directly points to a specific area of the paper that needs improvement and provides a clear action for the authors to take.", "grounding_specificity_rationale": "The review point mentions 'word embeddings in Tables 1 and 2' and 'Gaussian embeddings, the chief baseline from the literature.' While it identifies the type of embeddings and the location of the tables, it does not explicitly state which section of the paper contains the description of the experiments in Tables 1 and 2. The connection to 'the literature' implies the reviewer has external knowledge, making the grounding somewhat implicit.", "verifiability_rationale": "The review point makes a claim that 'the experimental results on word embeddings in Tables 1 and 2 are not very compelling' and suggests comparing them to Gaussian embeddings. However, it does not provide specific examples, data, or references within this review point to support why the results are not compelling or why the comparison is necessary. The claim is made, but the reasoning is not explicitly detailed within this review point.", "helpfulness_rationale": "The review point identifies a specific weakness in the experimental results (word embeddings not being compelling) and suggests a concrete action (comparing to Gaussian embeddings). This directly addresses a potential area for improvement in the authors' work. While the helpfulness is subjective, the review clearly points to a problem and offers a solution, making it potentially helpful."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the similarity between the proposed method and existing IRL methods, highlighting the minor differences in the task and reward function. This is a clear and direct statement of an explicit action the authors should consider emphasizing or exploring further.", "grounding_specificity_rationale": "The reviewer does not specify a particular section or table in the paper where the proposed method is discussed. While they mention the 'proposed method,' they don't pinpoint its location. This makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer does not make any claims that require verification. They are stating an opinion about the contribution's size. Therefore, there is X to evaluate for verifiability.", "helpfulness_rationale": "The reviewer criticizes the contribution as 'somewhat small' if the only difference is the task and reward function change. This suggests the feedback is focused on the incremental nature of the contribution, making it less helpful for the authors in significantly improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states the 'novelty is limited' and the 'main contribution is a new ITrelated dataset.' While the reviewer identifies a potential issue (limited novelty) and suggests a contribution (the dataset), they do not explicitly state what the authors *should* do to address this. The reviewer points out a problem but doesn't provide a clear, actionable step for the authors to take. Therefore, while the reviewer highlights a potential weakness, the action is not explicitly stated, making it 2.", "grounding_specificity_rationale": "The reviewer makes a general statement about the paper's novelty and the dataset's contribution. They do not explicitly identify a specific part of the paper or dataset being discussed. The reviewer refers to 'the paper' and 'the dataset' in a general sense, without pinpointing a specific section, table, figure, or unique aspect. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim that 'the novelty is limited' and 'the main contribution is a new ITrelated dataset.' However, they do not provide any evidence, references, or logical reasoning to support these claims. The reviewer presents these statements as findings without backing them up. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer points out a potential weakness (limited novelty) and suggests a contribution (the dataset). While this raises a concern for the authors, it doesn't directly guide them on how to improve their work based on this observation. The reviewer highlights a potential issue but doesn't offer concrete, actionable advice. Therefore, the review point is not 5 for the authors in directly addressing their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states a fact about the paper's lack of an ablation study. It does not provide explicit instructions or suggestions on how the authors should address this deficiency. The authors are not told to add, remove, or modify anything based on this comment alone.", "grounding_specificity_rationale": "The review point explicitly mentions 'Ablation study.' This indicates a grounding in the topic. However, it does not specify which part of the paper or what aspect of the model is being referred to as the subject of the ablation study. The comment lacks specificity about the details of the ablation.", "verifiability_rationale": "The review point states a claim that the paper lacks an ablation study. However, it does not provide any justification or reasoning for why an ablation study is needed or what the expected outcomes might be. There are no external references or logical arguments supporting this claim.", "helpfulness_rationale": "The review point identifies a deficiency in the paper (the lack of an ablation study) but does not offer any suggestions or guidance on how the authors should address this issue. It is a critique of the paper's completeness rather than a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a weakness (marginal contribution) but doesn't specify how to improve it. It lacks concrete, actionable steps. While it identifies the issue, it doesn't provide explicit or implicit instructions on how to address it.", "grounding_specificity_rationale": "The comment is a general statement about the paper's contribution, not about a specific section or aspect. It doesn't identify a particular part of the paper being addressed.", "verifiability_rationale": "The claim that the contribution is marginal is an opinion, and the review doesn't provide evidence (citations, logical reasoning) to support this claim. It mentions previous works but doesn't explain why the current contribution is specifically marginal compared to them.", "helpfulness_rationale": "The comment identifies a problem (marginal contribution) but doesn't offer specific, actionable solutions or guidance on how to address it. It's a critique without constructive improvement suggestions."}
{"actionability_label": "1: Not Actionable", "grounding_specificity_label": "1", "verifiability_label": "1: Not Verifiable", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The review point is a question asking for an explanation of the authors' attribution for the performance difference between w2gm and w2g in the analysis of SWCS. It does not provide an explicit action or suggestion, but rather seeks clarification.", "grounding_specificity_rationale": "The review point asks a question about the 'analysis of SWCS' without specifying which part of the paper or analysis this refers to. It does not identify a specific section, table, or unique element of the paper.", "verifiability_rationale": "The review point is a question, not a claim that requires verification. It does not contain a statement that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The review point is a question seeking clarification, not a suggestion for improvement or a critique of the authors' work. It does not provide any actionable feedback that would help the authors improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the potential equivalence between the TW model and the TR model by suggesting a mathematical transformation. They also propose a 'discussion' to justify TW over TR. While the core idea is presented, the 'how' of the fusion is not detailed, making it somewhat vague on how to implement the inferred action.", "grounding_specificity_rationale": "The reviewer explicitly mentions the TR model, its core tensor C, and the idea of representing it with a TR. They also suggest 'fusing' this TR with the cores G_n. This demonstrates strong grounding specificity as the reviewer accurately identifies the specific part of the paper (the TR model and its components) being addressed. The suggestion to 'discuss' the justification further reinforces the specific focus on these elements.", "verifiability_rationale": "The reviewer proposes a mathematical argument for the equivalence, which requires logical reasoning. They also suggest a 'discussion' to justify TW over TR, implying the need for external references or established practices. While the reasoning is present, the request for a 'discussion' suggests a need for more detailed justification and potentially external references to be considered 5.", "helpfulness_rationale": "The reviewer directly addresses a potential weakness in the paper (the lack of justification for TW over TR) and offers a constructive suggestion for improvement by analyzing the equivalence. The comment is clear, specific, and directly targets a potential area for enhancement. The reviewer's comment is 5 and provides a clear direction for the authors to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the toolset for the VQA task and the toolset for the reasoning task are not the same. This is a clear statement of an issue, and the reviewer suggests creating a general tool set, which is a concrete action the authors could take.", "grounding_specificity_rationale": "The review point specifically mentions the 'VQA task' and the 'reasoning task' and highlights the difference in their toolsets. This demonstrates strong grounding as the reviewer accurately identifies the specific parts of the paper being addressed.", "verifiability_rationale": "The review point makes a claim about the difference in toolsets but does not provide any logical reasoning, common knowledge, or external references to support this claim. The reviewer simply states the observation without explaining why it's a problem or how it should be addressed.", "helpfulness_rationale": "The review point is 3 because it identifies a clear issue (difference in toolsets) and suggests a concrete improvement (general tool set). However, the lack of verifiability makes it less helpful because the authors don't understand *why* the toolsets are different or *why* a general tool set would be beneficial. The suggestion is good, but the reviewer doesn't explain the problem well enough for the authors to fully grasp the need for the suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an improvement in the evaluation methodology by using a simpler baseline. While the suggestion is clear, it doesn't explicitly state how to implement this change or what the expected outcome is. The action is implied but not explicitly stated as a concrete step.", "grounding_specificity_rationale": "The review point suggests a baseline using 'multiple random feature orders' without specifying which features are being ordered or how the randomness is implemented. The grounding is at a high level, lacking specific details about the features or the randomization process.", "verifiability_rationale": "The review point makes a claim about the potential of this baseline to differentiate between the effectiveness of metacontrollers and simple feature diversity. However, it lacks specific justification or examples to support this claim. The reasoning is present but lacks detailed explanation or references.", "helpfulness_rationale": "The review point suggests a change in the evaluation methodology by introducing a simpler baseline. While this could be helpful for understanding the impact of feature order, the review point itself doesn't provide concrete steps on how to implement this change or what specific improvements to expect from the paper. The suggestion is indirect and lacks specific guidance on how the paper should be modified."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out that the related work section is 'severely lacking' and that the paper 'completely omits lexically constrained decoding methods' as baselines. While the reviewer doesn't explicitly state an action, the implication is that the authors should improve the related work section and include these methods. This can be considered an implicit action. The reviewer does specify the *type* of methods to include, making the action somewhat concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the related work section' and specifies the absence of 'lexically constrained decoding methods'. This clearly identifies the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer makes claims about the state of the related work section ('severely lacking') and the omission of specific methods ('completely omits'). These claims can be verified by examining the paper's content and the baselines used. The reviewer does not provide specific examples within the paper to support these claims, making it '4'.", "helpfulness_rationale": "The reviewer's point directly addresses a significant weakness in the paper (the lack of a comprehensive related work section and relevant baselines) and provides clear suggestions for improvement (improving the related work and using the missing baselines). This feedback is both clear and actionable, making it 5 for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states that 'a lot of important baseline models and datasets are missing' and then names two specific examples: 1 SimVLM and 2 OFA. While the reviewer identifies a problem, the action is implicit. The reviewer does not explicitly state what needs to be done or how to address the missing information. The reviewer could have suggested adding specific models or datasets, but they did not. The reviewer's statement points to a need for improvement but does not provide concrete steps for the authors to take.", "grounding_specificity_rationale": "The review point explicitly mentions 'important baseline models and datasets' and then names two specific examples: 'SimVLM' and 'OFA'. The reviewer names specific elements of the paper being addressed. While the reviewer uses the term 'important', which is somewhat subjective, the subsequent naming of specific models and datasets grounds the discussion. The reviewer does not mention specific sections, tables, or figures, but they do identify concrete elements of the paper that are lacking.", "verifiability_rationale": "The review point makes a claim: 'Because a lot of important baseline models and datasets are missing, the comparison is not comprehensive.' The reviewer then provides supporting evidence by listing two specific examples: 1 SimVLM: Simple Visual Language Model Pretraining with Weak Supervision and 2 OFA: Unifying Architectures, Tasks, and Modalities Through a Simple SequencetoSequence Learning Framework. The claim is supported by the provided examples, which are concrete and specific to the field.", "helpfulness_rationale": "The review point identifies a weakness in the comparison due to missing baseline models and datasets. While the reviewer points out a problem, they do not offer specific, actionable suggestions for the authors to improve their draft. The reviewer's comment highlights the lack of comprehensive evaluation but does not provide concrete steps or guidance on how the authors should address this gap. The reviewer could have suggested adding specific models or datasets, but they did not."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the lack of new data and clarifies the nature of the data as derivative. This is a clear and actionable criticism.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'new data that is collected or will be released' and then specifies '3D pose estimates from existing datasets.' This is a 5 criticism.", "verifiability_rationale": "The reviewer makes a claim about the data being derivative and provides a clear explanation of why this is the case. This claim is wellsupported by logical reasoning.", "helpfulness_rationale": "The reviewer's comment is directly addressing a potential concern for the reader (finding new data) and points to a likely issue (derivative data). This is a 5 and direct critique."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the *specific* learning rate schedule used for Lsoftmax and Asoftmax on CIFAR and Face Verification. This provides a clear action for the authors to take: 'Consider the specific learning rate schedule used for Lsoftmax and Asoftmax on CIFAR and Face Verification.' The reviewer also implies a potential issue with this specificity, suggesting the authors should be mindful of this detail.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the specific learning rate schedule used for Lsoftmax and Asoftmax on CIFAR and Face Verification.' This directly identifies the specific part of the paper being addressed, providing strong grounding. The reviewer also specifies what is being criticized about this specific schedule, further enhancing specificity.", "verifiability_rationale": "The reviewer makes a claim: 'The authors criticise Lsoftmax and Asoftmax for requiring an annealinglike training procedure, but this method itself has a very specific learning rate schedule for experiments on CIFAR and Face Verification.' This claim is supported by the specific details provided about the learning rate schedule and its application to the mentioned datasets, making it 5.", "helpfulness_rationale": "The review provides a clear criticism and a specific suggestion for the authors to consider. The reviewer points to a potential issue (the specific learning rate schedule) and offers a direction for the authors to look (considering similar details). This makes the review highly constructive and actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks 'What can I learn from the visualizations about which elements are crucial for detecting a chair for example'. This indicates a desire for actionable insights. However, the review point stops at identifying the handle as a transformed feature and doesn't provide concrete steps or guidance on how to use this information to improve the model or analysis. The action is stated, but the execution and application are missing.", "grounding_specificity_rationale": "The reviewer mentions 'the visualizations' as the basis for their questions, indicating a general reference to the results. They also specifically ask about the handle, adding a degree of specificity. However, the review point doesn't explicitly state which visualization or section of the results is being referred to. While the focus on the handle adds a layer of specificity to the *what*, the *where* or *how* is ambiguous.", "verifiability_rationale": "The reviewer makes claims about what can be learned from the visualizations, such as 'is it consistent across a wide range of chairs?'. However, these claims are not supported by any evidence or reasoning within the review point itself. There is no logical reasoning, common knowledge, or external references provided to back up these claims. The claims are presented without sufficient justification.", "helpfulness_rationale": "The reviewer's questions are relevant and address a potential gap in the analysis. They are asking about the consistency and prominence of the handle feature, which could be helpful for the authors. However, the review point primarily focuses on asking questions rather than providing concrete suggestions or actionable feedback on how to address these questions or improve the analysis. The review is more about inquiry than providing direct guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states a suggestion: 'should it not '... must incur a competitive ratio of at most $b$.'' (not 'at least') ?'. This is a clear action, and the reviewer directly implies the necessary correction. The phrasing 'must incur a competitive ratio of at most $b$' clearly indicates the intended meaning, making the action straightforward to implement.", "grounding_specificity_rationale": "The reviewer directly references 'Section 2.2' and the specific claim about the competitive ratio. The comment is precise and identifies the exact location and detail being questioned. The reviewer also provides a brief explanation of why 'at least' might be wrong in this context, further enhancing the grounding.", "verifiability_rationale": "The reviewer provides a clear claim: the text incorrectly uses 'at least' instead of 'at most' for the competitive ratio. The reviewer then provides a logical argument and a specific example (x=1) to demonstrate why 'at most $b$' is the correct interpretation in this context. This provides strong evidence to support the claim.", "helpfulness_rationale": "The reviewer's comment is 5 because it identifies a specific, actionable, and verifiable error in the text. The suggestion to change 'at least' to 'at most' is clear and directly addresses the identified issue. Furthermore, the reviewer provides a logical explanation and a concrete example to support their claim, making the feedback easily understandable and actionable for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the issue ('missing proper expression') and suggests a concrete action ('apply proper expression'). This makes the action clear and directly actionable for the authors.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific part of the paper being addressed ('the third face image in Figure 2'). This allows the authors to directly locate the relevant element. The comment also specifies what is missing ('proper expression').", "verifiability_rationale": "The review point contains a claim ('the third face image in Figure 2 lacks proper expression'). However, it does not provide any justification or reasoning for this claim within the review point itself. It only states the problem without explaining why it's a problem or how to fix it.", "helpfulness_rationale": "The review point identifies a specific area for improvement ('the third face image in Figure 2') and suggests a concrete action ('apply proper expression'). While it doesn't explain *why* the expression is lacking or *how* to achieve 'proper expression', it clearly points to a potential issue that needs attention. This makes it 3 as it highlights a specific element that requires attention."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action: 'including an example created by BERT and comparing them with one created by the proposed model may be helpful.' This action is also concrete, as it specifies the type of comparison. The reviewer is suggesting a direct comparison to understand the performance relative to BERT.", "grounding_specificity_rationale": "The comment explicitly mentions 'BERT' and 'the proposed model', clearly identifying the specific parts of the work being referenced. The comment also specifies the intended comparison: 'created by' and 'compared with'. This provides clear grounding and details the specific aspect being addressed.", "verifiability_rationale": "The comment contains a claim ('may be helpful') but does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no evidence that the comparison will necessarily be informative or beneficial. The statement is presented as a suggestion or expectation, not a verified fact.", "helpfulness_rationale": "The review point suggests a comparison between BERTgenerated examples and the proposed model's examples. While this is a valuable suggestion for understanding the model's performance, the review point itself does not actively identify a specific weakness or provide concrete steps for improvement. It is a suggestion for future work, not a current improvement. The helpfulness is conditional on the results of the comparison, which are not guaranteed."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the issue: 'For the code summarization task and the code search task, the dataset size of Vault and CSN should be the same'. This clearly identifies an action the reviewer desires to be taken: to ensure equal dataset sizes. Furthermore, the comment explains *why* this is important: 'in order to demonstrate that Vault is better in terms of data quality than CSN'. This makes the action both explicit and directly tied to the problem.", "grounding_specificity_rationale": "The comment explicitly mentions 'Vault', 'CSN', and 'dataset size'. It directly refers to these specific datasets and the relevant attribute (dataset size). The reviewer is very clear about which parts of their work they are referring to. The comment is not just general; it pinpoints the specific experimental setup being questioned.", "verifiability_rationale": "The comment points out a logical inconsistency in the reviewer's own reasoning. If the reviewer believes Vault is better because of data quality, and they believe data quality is tied to dataset size, then the datasets should be of comparable size. The comment highlights this logical flaw: 'the dataset size of Vault and CSN should be the same in order to demonstrate that Vault is better in terms of data quality than CSN'. While the comment doesn't provide external references to support this claim, it identifies a logical requirement for a valid comparison. Therefore, it is 3, as it points out a necessary condition for the stated goal, even if it doesn't provide independent evidence.", "helpfulness_rationale": "The comment directly addresses a potential issue with the experimental setup by highlighting the discrepancy in dataset sizes and its implications for comparing Vault and CSN. It provides a clear direction for the authors to consider: 'the dataset size of Vault and CSN should be the same'. This is a valuable piece of feedback that directly points to a potential flaw in the methodology and encourages the authors to reevaluate their experimental design. The comment is actionable and directly relevant to the research question."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that some important concepts are not explained well, such as 'actionrepeat' and 'dithering phenomenon'. This indicates an implicit action: the reviewer wants these concepts explained. However, the reviewer does not provide specific guidance on *how* to explain these concepts. The action is identified, but the concrete steps for implementation are missing.", "grounding_specificity_rationale": "The reviewer explicitly names specific concepts ('actionrepeat' and 'dithering phenomenon') that are problematic. This indicates strong grounding as the reviewer can accurately pinpoint the referenced parts of the paper. However, the reviewer does not specify *what* is wrong with these concepts or *where* in the paper they are discussed. The grounding is precise, but the specificity about the issue is lacking.", "verifiability_rationale": "The review point does not contain a claim. It is a request for clarification and explanation of certain terms. Therefore, it does not have verifiability in the sense of a claim being supported or unsupported.", "helpfulness_rationale": "The reviewer requests clarification on specific concepts. While this is a relevant piece of feedback, the review point itself does not provide a concrete action for the author to take. The request for explanation is a suggestion, not a direct instruction on how to improve the draft based on this feedback."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a concrete action the authors can take: 'I believe authors first generate a text using the instruction model and then reencode the text using an encoder. Why not do something like this: create an instruction embedding g(f(s)) from state encoding f(s). Pass this instruction encoding directly to the executor (as opposed to generated text). Then you can add an auxiliary objective which will try to bring g(f(s)) closer to the gold instruction encoding. This might work better as you are not adding discretization in between which can fail due to a single wrong decoding (say as based on a tie).'", "grounding_specificity_rationale": "The reviewer's suggestion is a general improvement idea for instruction following, not specifically targeting a problematic aspect or section within a particular paper. While it implies a potential area for improvement, it doesn't pinpoint a specific part of the authors' work that needs addressing.", "verifiability_rationale": "The reviewer provides a logical explanation for their suggestion (bypassing discretization), but it's a general idea and doesn't directly address a specific problem the authors might be facing. It lacks specific examples or references to the authors' work. The suggestion is based on the general principle of avoiding discretization errors in instruction following, which is verifiable but not necessarily specific to a particular issue.", "helpfulness_rationale": "The reviewer's suggestion is likely to be helpful in the long run by improving the authors' understanding of instruction following and potentially their framework. It offers a different perspective on how to achieve instruction following. However, it's not immediately actionable for addressing a specific problem the authors are currently facing. It requires the authors to implement a different framework."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement is explicit as it directly states the lack of novelty. It is also concrete as it suggests considering alternative approaches or strengthening the contribution, providing a clear action for the authors. Therefore, it is 5.", "grounding_specificity_rationale": "The comment refers to 'the proposed model' generally, without specifying a particular section, table, figure, or unique aspect of the model. While the topic is clear, the specific element being addressed is not. Therefore, it is weakly grounded. The comment identifies a weakness (lack of novelty) but doesn't specify what needs to be addressed in this part. Therefore, it is not specific. Combining these, it is 2.", "verifiability_rationale": "The statement 'The novelty of proposed model is not significant' is a claim or judgment about the paper. However, the review point does not provide any evidence, justification, or references to support this claim. There is no logical reasoning, common knowledge, or external references cited to back up the assertion. Therefore, it is 1. Since there is X, it is also not 'X'.", "helpfulness_rationale": "The review point states a negative assessment of the novelty without offering any constructive suggestions or pointing to specific areas for improvement. It is a critique without actionable feedback. Therefore, it is 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their concern about the dataset's class distribution and provides a concrete example of how it might affect accuracy. The statement 'it seems to me that the proportion of each class used for the pool subset makes this particular dataset somewhat easier rather than harder...' is a clear actionability statement. Furthermore, the reviewer elaborates on the specific class imbalance (fewer observations for certain classes) and how this could lead to misleading accuracy scores, making the action even more explicit.", "grounding_specificity_rationale": "The reviewer's criticism is not directly grounded at the paper level but rather at the dataset level. While the *evaluation metric* (accuracy) is tied to the dataset, the reviewer is commenting on a general property of the dataset (class imbalance). The grounding is weak because the paper being reviewed likely uses a different dataset or the reviewer is commenting on a general issue. The specificity is present in the reviewer's identification of the problem (class imbalance) and the examples of classes with few observations (6, 7, 9).", "verifiability_rationale": "The reviewer makes a claim about the dataset's properties (class imbalance affecting accuracy). The 'support' comes from the reviewer's reasoning that accuracy is a poor measure in such cases. However, this support is based on observation and potential implication rather than explicit logical reasoning, common knowledge, or external references. There is no external reference or detailed logical explanation provided to back up the claim. The claim is present, but the verifiability is limited.", "helpfulness_rationale": "The reviewer's point is clear and directly relevant to the evaluation process. They are highlighting a potential issue with the accuracy metric when applied to a dataset with imbalanced classes. This criticism is helpful in identifying a potential flaw in the evaluation methodology. However, the reviewer does not offer any suggestions or solutions to address this issue, making the criticism somewhat focused on the problem itself rather than proposing improvements."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly addresses a potential weakness or improvement suggestion, though it is somewhat vague. The reviewer acknowledges agreement with a general statement but focuses on the specific claim about the 'main' contribution of the paper. While the reviewer doesn't provide a direct action, they suggest improvements, indicating a degree of actionability. However, the lack of clarity in the suggested improvements makes the actionability somewhat limited.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific claim about the 'main' contribution of the paper and the potential issue with the payoff calculation in Table 1. They reference specific sections (Table 1) and suggest a connection to existing work (Vapnik's work). This demonstrates a high level of grounding specificity as the reviewer accurately pinpoints the relevant parts of the paper and provides specific details about the issue.", "verifiability_rationale": "The reviewer provides specific details about the potential issue with the payoff calculation in Table 1 and suggests a connection to existing literature (Vapnik's work). This provides evidence for verifiability. The reviewer is asking for clarification and connecting their observation to prior work, which is a valid request. While the reviewer doesn't provide a definitive answer, they offer a clear direction for investigation, making the claim 3.", "helpfulness_rationale": "The review point is helpful as it directly addresses a potential weakness or improvement suggestion. The reviewer highlights the claim about the 'main' contribution and raises a valid point about the payoff calculation. While the suggestions are somewhat vague, they point in a helpful direction for the authors. The reviewer's engagement with the paper demonstrates a desire to improve understanding and context, which is a valuable contribution. The suggestions, even if not fully addressed, are actionable and contribute to the overall feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: \"It is recommended to explore another UDA method based on selftraining.\" This is a clear, explicit action the reviewer is proposing.", "grounding_specificity_rationale": "The review point mentions \"UDA method based on selftraining\" but doesn't specify a particular section, table, figure, or unique element within that category. The reviewer provides a general direction but not a precise location within the paper to focus on.", "verifiability_rationale": "The review point contains a claim about the proposed method: \"the proposed method solely focuses on domainalignment methods.\" However, the reviewer's suggestion to explore selftraining is a recommendation, not a claim requiring verification based on the provided text.", "helpfulness_rationale": "The review point identifies a potential limitation of the proposed method (focusing solely on domain alignment) and suggests a relevant alternative area (selftraining UDA). This provides a direction for improvement and is relevant to the field. While the suggestion is valuable, it's a general direction rather than a specific, actionable fix for the *current work*. It's more of a recommendation for future work or a different approach."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out that the reliability diagrams don't make the proposed methods look better and highlights specific pathologies. While this points to a potential issue, it doesn't explicitly state what needs to be changed or how to address the identified problems. The reviewer's comment is about the interpretation of the diagrams rather than a direct instruction on how to improve them.", "grounding_specificity_rationale": "The reviewer refers to the 'reliability diagrams (Fig 1, top)' and 'accuracy vs confidence plots'. While they are referencing a specific part of the paper (the diagrams), they don't explicitly identify a *unique* element or section within that part. They are pointing to a general area of the paper.", "verifiability_rationale": "The reviewer makes a claim: 'the reliability diagrams (Fig 1, top), that is the accuracy vs confidence plots, certainly don't make the proposed methods look better... and in fact exhibit some pretty notable pathologies (highaccuracy spikes in low confidence regimes, e.g.)'. This claim is supported by the reviewer's observation of the pathologies in the diagrams. The reasoning is clear and directly relates to the visual representation of the methods' performance.", "helpfulness_rationale": "The reviewer's comment directly addresses the interpretation of the reliability diagrams and raises questions about the proposed methods. While they don't offer a direct solution, their critique highlights a potential weakness in the presentation or analysis of the methods. This could be helpful for the authors to understand the limitations of their approach, although it doesn't immediately provide actionable steps for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point discusses potential future scenarios and alternative approaches to backdoor attacks and defense. It doesn't explicitly tell the authors what to change in their current draft or how to address the limitations discussed. The suggestions are more about exploring possibilities than providing direct instructions for improvement.", "grounding_specificity_rationale": "The review point discusses general limitations of the evaluated methods and suggests considering 'finetuning only on a partial subset of D' and 'backdoor removal techniques.' It doesn't pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. The discussion is highlevel and doesn't directly relate to the paper's core methodology or experiments. The references are general and not specific to any part of the paper.", "verifiability_rationale": "The review point presents suggestions and alternative ideas. While it offers insights into potential limitations and future directions, it doesn't make specific claims about the current paper that require justification or evidence. The language is more about exploring possibilities than making definitive statements about the work. The claims, if any, are not explicitly stated and verified.", "helpfulness_rationale": "The review point offers insights into potential limitations and future research directions. While it's relevant to the broader context of backdoor attacks and defenses, it doesn't directly provide actionable feedback on improving the specific paper being reviewed. The suggestions are more about exploring alternative approaches than directly addressing the paper's weaknesses. The feedback is not specific to the paper under review and does not offer concrete steps for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about a potential methodological issue (using the original adjacency matrix instead of the normalized one from the original GCN paper) and its implications. It does not explicitly state what the authors should do or how to address this issue. The reviewer is asking for justification or an ablation study, but not directly instructing the authors on how to implement a change.", "grounding_specificity_rationale": "The reviewer refers to 'the original GCN (Kipf and Welling)' and 'this paper'. While they don't provide a specific section number, they are referencing a specific prior work and the submitted paper. This implies they are pointing to a specific area of the paper, making it somewhat grounded. However, the lack of a precise section reference makes it not fully grounded.", "verifiability_rationale": "The review point contains a claim that the paper uses the original adjacency matrix without explanation or ablation study, and it asks a question ('I wonder if there is a reason...') about this. This claim could potentially be verified by checking the paper for explanations or ablation studies. However, the paper itself doesn't explicitly state the reason for this choice or lack of ablation.", "helpfulness_rationale": "The review point raises a valid concern about a potential methodological choice and asks a question. However, it doesn't directly tell the authors what to do or explicitly state the reasons for the choice of the original adjacency matrix. It's more of a probing question than a direct suggestion for improvement, making it less helpful in terms of directly guiding the authors' work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the missing link for WMT'14, making it a clear action for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'WMT'14 training corpora,' providing clear grounding. They also specify the missing link, adding to the specificity.", "verifiability_rationale": "The reviewer points out an inconsistency but doesn't make a claim that requires verification.", "helpfulness_rationale": "While the reviewer points out a potential issue, the helpfulness depends on the authors' prior knowledge. It's a potential concern, but not a definitive instruction."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment implicitly suggests that knowing the bounds of matrices A_t and B_t is important for hyperparameter selection. While it implies a need for this information, it doesn't explicitly state an action the author should take (e.g., 'Find the bounds in the methodology section'). The action is inferred.", "grounding_specificity_rationale": "The comment asks about 'adaptive matrices A t and B t' without explicitly identifying which part of the paper these matrices are located in or providing any context for why these specific matrices are relevant. The reviewer would need to search the paper to find this information, indicating a lack of explicit grounding.", "verifiability_rationale": "The comment is a request for information about the bounds of specific matrices. It doesn't contain a claim or assertion that needs verification. It's a question or a diagnostic point rather than a statement that requires logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The comment is a request for information about the bounds of specific matrices. While it might be helpful for the author to understand their role in hyperparameter selection, it doesn't directly provide actionable steps or insights to improve the draft. It's more of a diagnostic question than a prescriptive improvement suggestion."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "1", "verifiability_label": "Not Verifiable", "helpfulness_label": "None", "actionability_rationale": "The review point states a fact ('The novelty isn't particularly high') and poses a question ('How about experimental results...'), neither of which provide explicit instructions on what the author should do.", "grounding_specificity_rationale": "The review point makes a general statement about the novelty without specifying which part of the paper or work is being referred to.", "verifiability_rationale": "The review point makes a claim ('The novelty isn't particularly high') but does not provide any evidence, references, or logical reasoning to support this statement.", "helpfulness_rationale": "The review point raises a valid concern about the novelty and prompts a question, but it does not offer specific, actionable feedback or suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the desired action: 'All results on comparing pairs of models would strongly benefit from adding error bars...'. It clearly indicates what should be added (error bars) and why (to show differences are beyond noise). The action is not inferred but directly stated.", "grounding_specificity_rationale": "The comment refers to 'comparing pairs of models' as the specific area of the paper being addressed. While it doesn't pinpoint a specific table, section, or figure, it clearly identifies the type of analysis or experiment being discussed. The grounding is through a general description of the work being evaluated.", "verifiability_rationale": "The comment contains a claim: 'All results... would strongly benefit...'. This claim is supported by the logical reasoning that adding error bars helps demonstrate statistical significance, which is a common goal in research. While it doesn't provide specific examples of where error bars are needed, the reasoning is clear and logical.", "helpfulness_rationale": "The comment is directly relevant to the authors, suggesting a concrete improvement (adding error bars) to their model comparisons. It clearly explains the benefit of this improvement (demonstrating significance). The suggestion is actionable and directly addresses a common need in research evaluation."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points to a specific section of the paper (page 2, line 81) and states that the 'full state' is not defined properly. While this points to a potential area for improvement, the reviewer does not explicitly state what constitutes a 'full state' or how it should be defined. The action is implied but not directly stated. Therefore, it is 2 as it points to an action but lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Page 2, line 81' and states that 'Full state is not defined properly.' This clearly identifies the specific part of the paper being addressed and the issue with it. The grounding is literal and specific.", "verifiability_rationale": "The reviewer makes a claim that 'Full state is not defined properly' but does not provide any evidence or examples to support this claim. The verifiability of this statement is unclear as there is no basis for judging its validity. Therefore, it is 1.", "helpfulness_rationale": "The reviewer's request for clarification on the 'full state' is a common and often necessary part of the review process. It can help the author by highlighting a potential ambiguity. While it doesn't directly tell them *how* to define it, it *identifies a potential issue*. Therefore, it is 3 in pointing out a potential area for clarification."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "1 (1)", "verifiability_label": "6 (X)", "helpfulness_label": "1 (Not Helpful)", "actionability_rationale": "The criticism is implicit and vague. While the *absence* of new proposals is implied, the reviewer doesn't directly state what the authors should do to address this weakness. The criticism is more of a judgment about the paper's contribution rather than a direct instruction for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'neural architecture encoding' in general, without specifying a particular section, table, figure, or unique aspect within that field. The reference is broad and lacks precision, making it difficult to identify exactly what needs improvement.", "verifiability_rationale": "The review point doesn't contain a claim that needs verification. It's an overall assessment of the paper's contribution, stating that it's a 'good empirical study' but 'lacking of new proposals for neural architecture encoding.' This is a judgment about the paper's state, not a claim requiring evidence.", "helpfulness_rationale": "The review point identifies a weakness (lack of new proposals) but doesn't provide any actionable feedback or suggestions for the authors to improve their work. It's a critique of the paper's contribution without offering concrete steps or insights."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states a goal ('improve fairness') and mentions a specific technique ('holdout data distribution'). It doesn't explicitly tell the author *how* to achieve this. While the reviewer identifies a problem and a potential solution strategy, they lack specific, actionable steps. For example, they don't specify which parts of the data distribution to hold out or how to measure the impact on fairness.", "grounding_specificity_rationale": "The reviewer refers to 'the authors' claim' and 'the underline data distribution'. While they are pointing to aspects of the authors' method, they don't explicitly identify a specific section, table, figure, or unique element of the paper. The reference is more general, making it weakly grounded. Furthermore, while they mention 'imputation' and 'fairness', they don't specify *how* the data distribution is held out or what metrics are used to assess fairness, making it underspecific.", "verifiability_rationale": "The reviewer states a claim: 'The authors claim that the solution they provided have a low discrimination risk (while minimally sacrificing utility) and improve the fairness of models.' However, they do not provide any evidence, reasoning, or references to support this claim. The statement is presented as a fact without justification.", "helpfulness_rationale": "The review point provides a potential direction for improvement (improving fairness by holding out data distribution) but lacks specific, actionable steps. It also states a claim ('the authors claim...') without providing any evidence or justification. Without specific guidance on how to implement the suggestion or verify the claim, the review point offers no concrete help to the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment suggests using ReferIt data but doesn't specify how to implement this action.", "grounding_specificity_rationale": "The comment is a general suggestion about using a dataset and doesn't refer to a specific part of the paper.", "verifiability_rationale": "The review point is a suggestion, not a claim that needs verification.", "helpfulness_rationale": "The comment offers a potential improvement and a logical next step, but lacks specific guidance on implementation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks for clarification on a specific section of the paper (243245) and requests explanations for specific calculations and methodological choices. These are direct requests for information that would directly improve the draft. The reviewer also asks for specific details about the kNN method used, which is a concrete action to understand the implementation. While the reviewer doesn't state explicitly what they *should* do, the implied action is to understand the unclear explanation and the rationale behind the calculations and method.", "grounding_specificity_rationale": "The reviewer explicitly points to a specific section of the paper (243245) when stating their lack of understanding. This indicates a clear identification of the part of the paper they are struggling with. However, the reviewer's request for elaboration is more of a desire for information rather than a clear specification of *what* is unclear within that section. The questions about the 5*3 calculation, the choice of kNN, the k value, and the distance metric are all specific requests for details about the method, indicating a strong grounding in the specific methodological choices.", "verifiability_rationale": "The reviewer does not make any claims or judgments about the paper. They are asking questions and seeking information, not stating why something is wrong or suggesting improvements. Therefore, there is X being made, and the verifiability criteria do not apply as there is no statement to verify.", "helpfulness_rationale": "The reviewer's request for clarification on an unclear explanation directly addresses a potential weakness in the draft. They are asking for actionable feedback on how the paper can be improved. The questions about the 5*3 calculation, the choice of kNN, the k value, and the distance metric are all requests for specific details that would directly help the authors understand and potentially improve their work. While the review doesn't explicitly state a solution, the implied action is to understand the issues and potentially implement changes based on the information provided."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: 'The background of SharpnessAware Minimization (SAM) should be described in detail.' This clearly indicates an action the authors should take. However, the reviewer does not specify *how* the background should be described. Is it a highlevel overview, a deep dive into the mathematical details, or a discussion of its implications for the training process? The lack of specificity makes the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'SharpnessAware Minimization (SAM)' by name, which clearly identifies the specific concept being addressed. They also mention 'background,' which points to the section where SAM is typically introduced. This explicit identification of the concept and its location in the paper indicates strong grounding. However, the reviewer does not specify *what specific aspects* of the background are lacking or *why* a more detailed background is needed. The grounding is present, but it's not fully specific.", "verifiability_rationale": "The reviewer makes a claim: 'The background of SharpnessAware Minimization (SAM) should be described in detail.' This is a statement of what needs to be done. The reviewer's request is clear and actionable. They are suggesting that the current background is insufficient and that a more detailed explanation is necessary. While the reviewer doesn't provide specific examples of what is missing or why detail is needed, the request itself is a clear claim that can be verified by examining the existing background. The reasoning is implicit but the action is stated.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'The background of SharpnessAware Minimization (SAM) should be described in detail.' This directly addresses a potential weakness in the paper (lack of clarity on SAM's background) and offers a concrete improvement (a more detailed explanation). While the reviewer doesn't specify *which aspects* of the background need more detail, the suggestion is clear and directly helpful for the authors. The reviewer is not asking for a proofread or a different approach, but rather for more information on a core concept."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests 'comprehensive comparisons' and 'specific examples' but does not explicitly state what action should be taken. The suggestions are vague and lack concrete steps on how to implement them.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'languageassisted' and 'visionassisted' approaches, as well as 'image guidance' and 'coloraugmentation' as examples. This clearly identifies the specific parts of the paper being addressed and what needs to be improved within them.", "verifiability_rationale": "The reviewer makes a claim about the 'lack of comprehensive comparisons' and suggests 'valuable insights' by proposing specific examples. However, the reasoning behind these suggestions is not explicitly detailed or supported by external references. The claim is present, but the verification is implicit.", "helpfulness_rationale": "The reviewer directly points out a weakness ('lack of comprehensive comparisons') and offers concrete suggestions ('utilizing related reference normal images' and 'coloraugmentation for kNN baseline'). These suggestions are directly helpful to the author in improving their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper 'does not mention this line of work' and suggests the proposed model is a 'special case' of collective entity linking. This provides a clear direction for the authors to improve their work by including related work and clarifying the relationship to their model. The reviewer identifies an action (mentioning related work) and provides a concrete suggestion (collective entity linking).", "grounding_specificity_rationale": "The reviewer mentions 'a closely related line of work' and 'collective entity linking' as examples. While they don't pinpoint a specific section or table, they clearly identify the area of related work and even the specific concept. This allows the authors to understand the nature of the missing information and the relevance of the suggested area.", "verifiability_rationale": "The reviewer makes a claim that the paper 'does not mention this line of work' and suggests the proposed model is a 'special case' of collective entity linking. This is a claim that can be verified by checking the related work section of the paper. While the reviewer doesn't provide specific examples of missing information, the suggestion to check related work and the claim about the model being a 'special case' provide some basis for verification. However, without concrete examples or references, the verifiability is not fully established.", "helpfulness_rationale": "The reviewer's comment is highly valuable for the authors. By pointing out the absence of related work and suggesting a connection to their model, the reviewer provides a clear direction for improvement. The suggestions are specific enough to guide the authors in their revisions and potentially lead to a better understanding of their model's novelty and place within the existing literature. The reviewer's comment is actionable and directly relevant to the paper's content."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue with the log likelihood function and suggests an experiment. The criticism about truncation is explicit, and the suggestion for comparison is also explicit. However, the reviewer does not specify *how* to truncate or *why* it would lower sensitivity, leaving the authors with a general idea but no concrete steps to take. The questions about query functions are explicit requests for clarification, but they don't propose a specific action to address the identified issue.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the log likelihood function' and 'the sensitivity' in the context of Algorithm 1 and 'd data sources'. This clearly identifies the specific part of the paper being addressed. The criticism about truncation and the suggestion for comparison are also clearly linked to this specific part. The questions about query functions further pinpoint the area of concern. The reviewer provides a clear understanding of the framework's components.", "verifiability_rationale": "The reviewer makes a claim: 'Truncating the log likelihood function can also lower the sensitivity.' This is a statement that can be verified. However, the reviewer does not provide any justification or reasoning for this claim. They suggest an experiment ('It would be interesting to see the comparison') but don't explain *why* they think it would work or what the implications might be. The lack of explanation makes the claim somewhat 1.", "helpfulness_rationale": "The reviewer's assessment is that some points are 'minor' and the inconsistency about query functions is a 'wonder'. While the criticism about truncation is potentially valuable, the lack of justification makes it less helpful than it could be. The suggestions for further investigation are interesting but don't provide concrete guidance. The questions about query functions are helpful in identifying a gap but don't propose a solution. The overall helpfulness is moderate due to the lack of specific action items and justifications."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a change in the evaluation process by mentioning the limitation of the current dataset and proposing a larger and more diverse one. While this is a relevant suggestion, it does not explicitly state what action the authors should take to implement this change. The suggestion is general and lacks specific steps or guidance on how to achieve this.", "grounding_specificity_rationale": "The review point mentions the MD17 dataset and suggests evaluating on a 'larger and more diverse dataset, including more complex molecules and materials.' However, it does not specify which molecules or which complex datasets are missing. The reviewer is making a general suggestion about the type of dataset, not a specific reference to a particular section, table, figure, or unique element of the paper.", "verifiability_rationale": "The review point contains a claim suggesting the benefit of using a 'larger and more diverse dataset, including more complex molecules and materials.' This claim is generally verifiable as it points to a common goal in scientific evaluation \u2013 to improve the robustness and generalizability of methods. However, it lacks specific examples or references to external works to support this suggestion.", "helpfulness_rationale": "The review point suggests exploring a 'larger and more diverse dataset, including more complex molecules and materials.' This is a relevant and helpful suggestion for the authors as it encourages them to consider a more comprehensive evaluation of their method. While it doesn't provide specific steps on how to implement this, it points towards a beneficial direction for their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a weakness in ConceptWeaver's ability to handle more concepts, which can be seen as an implicit action pointing towards a specific area for improvement. However, it lacks explicit instructions on how to apply this feedback to the reviewed paper.", "grounding_specificity_rationale": "The review point mentions 'ConceptWeaver' specifically, providing some grounding. However, it doesn't explicitly identify a specific section, table, figure, or unique aspect of ConceptWeaver's capabilities that necessitates improvement in the reviewed paper. The weakness is identified at a general capability level.", "verifiability_rationale": "The review point makes a subjective judgment that the submitted paper has 'better qualitative results' compared to ConceptWeaver. This claim lacks supporting evidence or logical reasoning. It's a direct comparison without providing specific examples or references to back it up.", "helpfulness_rationale": "The review point is not particularly helpful as it primarily compares the reviewed paper to ConceptWeaver without providing specific, actionable feedback on how to improve the paper based on this comparison. The weakness identified is at a general capability level rather than pointing to a specific issue in the reviewed paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a potential solution involving subspace clustering and matrix completion, which can be considered an action. However, it doesn't specify which part of the submission is problematic, making it less actionable than it could be. The reviewer suggests a method but doesn't detail how to apply it to the current work.", "grounding_specificity_rationale": "The reviewer refers to 'subspace clustering' and 'matrix completion,' which are specific concepts. They also suggest a 'potential solution,' indicating they understand the general area. However, they don't pinpoint the exact section, table, or figure in the paper where these concepts might be relevant or where the problem lies. The grounding is present but not fully specific to a particular part of the submission.", "verifiability_rationale": "The reviewer makes a claim that the problem 'reduces to subspace clustering with missing data' and suggests a 'potential solution' involving 'alternating between matrix completion and subspace clustering.' While there's a logical connection and a suggestion for a method, there's no external reference or concrete evidence provided to support these claims within the review point itself. The claims are presented as possibilities rather than certainties.", "helpfulness_rationale": "The review point offers a suggestion for a potential solution related to subspace clustering and matrix completion. While this could be helpful for guiding future work or understanding the authors' approach, it doesn't directly identify and explain specific weaknesses or improvements needed for the current submission. The reviewer's statement '1) above' is vague and doesn't clearly refer to a specific issue in the paper. Therefore, while the suggestion is relevant, the lack of direct feedback on the submission's shortcomings makes it 3 but not 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'If the teacher model has limitations or biases, these could propagate to CCKTDet++, affecting performance and potentially introducing unintended biases.' This is a clear and direct action the reviewer is taking, identifying a potential issue related to the teacher model. The reviewer is suggesting that the authors should be aware of this potential problem.", "grounding_specificity_rationale": "The reviewer mentions 'teacher models' generally, without specifying a particular section, table, figure, or unique aspect of the paper. While the reviewer is referencing the model used in the proposed method (CCKTDet++), they don't explicitly link it to a specific part of the *reviewed paper*.", "verifiability_rationale": "The reviewer states a potential consequence: 'affecting performance and potentially introducing unintended biases.' However, the reviewer does not provide any specific evidence, examples, or references to support this claim. The statement is presented as a possibility, not a certainty.", "helpfulness_rationale": "The reviewer raises a relevant concern for the authors regarding the reliance on teacher models. They highlight a potential weakness that could affect the performance and introduce biases. While the reviewer doesn't offer a definitive solution, they point out a practical issue that the authors should be aware of. The suggestion to 'could' propagate to CCKTDet++ indicates a degree of uncertainty but still highlights a potential problem."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue (performance not improving) related to the 'comparison objects' in the 'comparison experiment'. However, it does not explicitly state what needs to be done to address this issue. While it implies that using different or newer comparison objects might be beneficial, it doesn't provide a direct action or a clear path to improvement. Therefore, it is 2 as it points to an action but doesn't fully specify how to take it.", "grounding_specificity_rationale": "The review point refers to 'comparison objects' and 'comparison experiment' without specifying which ones are being referred to. It doesn't provide any unique identifier or context for these elements. Therefore, it is 1 at all.", "verifiability_rationale": "The review point states an observation ('performance has not been greatly improved') based on a potential factor ('comparison objects are very old'). However, it does not provide any justification or reasoning for why this is the case, nor does it cite any external references to support this claim. The observation is presented as a fact without any supporting evidence. Therefore, it is 1.", "helpfulness_rationale": "The review point identifies a potential problem (performance not improving) related to the 'comparison objects' in the 'comparison experiment'. However, it does not offer any specific suggestions or explanations for why this is happening or how to address it. It simply states the observation without providing actionable insights. Therefore, it is 2 as it points to a problem but doesn't offer solutions."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly asks a question about the mechanism of how masks are handled in CNN layers, but it doesn't directly state an action or provide a concrete step to take. It's a question seeking clarification.", "grounding_specificity_rationale": "The review point explicitly mentions 'CNN layers (representation block)', which is a specific part of the architecture. However, the question itself is broad about how masks are handled, not specific to the representation block's implementation.", "verifiability_rationale": "The review point is a question seeking information about how masks are handled in CNN layers, not a definitive claim that needs verification. There's no explicit statement requiring justification or support.", "helpfulness_rationale": "The review point is a valid question for seeking information about the handling of masks in CNN layers. However, it doesn't directly identify a weakness or suggest a concrete improvement, making it less helpful for guiding authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the observation that 'without dropout' has larger training loss and asks for an explanation. This is a direct and actionable question. The reviewer also asks how activation clipping might reduce model capacity, which is a concrete question about a potential mechanism. Once the observation is identified, the reviewer proposes a potential solution (reducing model capacity), making it actionable.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 8' and mentions 'without dropout' and 'activation clipping'. This demonstrates a clear attempt to pinpoint the specific part of the paper being addressed. The reviewer's questions directly relate to these elements, indicating strong grounding. The reviewer is also asking for a specific explanation of how activation clipping might reduce model capacity, which is a clear request for detail within a specific part of the paper.", "verifiability_rationale": "The reviewer presents an observation ('without dropout has larger training loss') and a hypothesis ('activation clipping may reduce model capacity'). This constitutes a claim. The reviewer asks for an explanation of why this might be the case, which requires logical reasoning and justification. While the connection between dropout and loss is generally understood, explicitly linking it to activation clipping necessitates further justification or a reference to relevant literature. The request for how activation clipping might reduce capacity is a request for specific examples or references.", "helpfulness_rationale": "The reviewer's comment is 5. They directly point out a potential issue (higher training loss without dropout) and offer a potential explanation (activation clipping reducing capacity). This is not just a criticism but also a suggestion for improvement. The reviewer is asking for a specific explanation and a specific potential solution, which is very constructive for the authors. The request for an explanation is a clear call for improvement in the paper's understanding of the impact of dropout and activation clipping."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion about the paper's potential impact on largescale matting datasets. While it suggests the paper is important for this area, it doesn't explicitly state what needs to be improved or how the authors should apply this understanding. The connection between the reviewer's view and actionable steps for the authors is not clearly established.", "grounding_specificity_rationale": "The review point discusses the significance of the paper in the context of largescale matting datasets. However, it does not explicitly refer to a specific section, table, figure, or unique aspect of the paper. The reviewer is making a general statement about the paper's potential impact, not pointing to a particular problem or contribution within a defined part of the paper.", "verifiability_rationale": "The review point is a statement of opinion ('In my point of view') about the paper's importance for matting datasets. It does not present a claim that requires verification or support through logical reasoning, common knowledge, or external references. There is no assertion that something is missing, unclear, or needs improvement in the paper itself, only a general assessment of its potential impact.", "helpfulness_rationale": "The review point expresses an opinion about the paper's potential to advance research in largescale matting datasets. While this highlights a potential positive impact, it does not provide specific feedback or actionable suggestions on how the authors' current work could be improved or how their research could contribute to this area. The review lacks concrete guidance for the authors on addressing any identified weaknesses or areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review points out a limitation in the *quantity* of adversarial examples. While it identifies a problem, it doesn't provide a clear, verifiable action for the authors to take. It's likely **not fully actionable** as it doesn't specify how to increase the number or what specific steps to follow. It's **2** because it identifies a potential issue, but lacks a specific recommendation.", "grounding_specificity_rationale": "The reviewer states the adversarial examples are \"adversarial examples\" and the distribution is 'some distribution.\" This is a general statement. While it implies a *type* of example and a *general idea* of the distribution, it doesn't pinpoint a *specific* section, table, figure, or unique aspect of the paper. The reviewer doesn't provide a specific reference point within the paper. It's **weakly grounded** because the reviewer can *infer* the nature of the problem, but not its precise location.", "verifiability_rationale": "The reviewer states the number of examples is \"too small.\" This is a claim that something is lacking. However, the review *doesn't provide any justification* for why a specific number is \"too small\" or *why* this is a problem for demonstrating a \"distribution.\" The threshold for \"too small\" is subjective and not explained. It's **1** because there's no explanation of *why* the number is too small or *why* this is a problem.", "helpfulness_rationale": "The reviewer clearly identifies a limitation in the *quantity* of adversarial examples and suggests a specific improvement (having more examples). It's a direct and actionable suggestion. It's **5** because it directly addresses a potential weakness and offers a clear next step."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a potential issue with the method (channelsparse gradients might not save time or memory) and suggests a direction for investigation (looking into framework support). This constitutes an explicit action or suggestion that authors can directly identify modifications they should apply to their draft. While the level of detail on how to implement this action is not fully provided, the reviewer points out a concrete area for further investigation.", "grounding_specificity_rationale": "The comment explicitly mentions 'channelsparse gradients' and specifically criticizes 'most frameworks only support dense gradients for inputs and parameters'. This directly identifies the specific part of the paper being addressed, providing clear grounding. The suggestion to 'do them with the full set' further pinpoints a specific aspect within the 'Qualitative Studies' section. The reviewer demonstrates a clear understanding of the technical details being discussed in the paper.", "verifiability_rationale": "The comment provides a claim that 'most frameworks only support dense gradients for inputs and parameters, so zeroing out a particular channel may not alter the computation performed'. The reviewer attempts to support this claim by stating that this is a common practice. However, the explanation is somewhat vague and lacks specific references to external works or detailed reasoning about how this limitation affects the proposed method. While the reasoning is present, it could be more robust and detailed.", "helpfulness_rationale": "The review identifies a potential issue with the method's efficiency and points out a lack of evidence in common frameworks. While the criticism is valid and highlights a potential limitation, the reviewer's suggestions, such as 'do them with the full set', are constructive and directly address a specific aspect of the experimental evaluation. The comment is grounded in specific technical details and provides a clear direction for further investigation. However, the lack of detailed reasoning and the focus on a potentially minor point (framework support) might make it less impactful overall."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the authors' claim about not considering sparsity or low rank and offers an alternative explanation based on concentrationofmeasure. This directly addresses the authors' perspective and provides a clear action for them to take, which is to reexamine their understanding. The reviewer also points out that the results are likely extensions of existing work, which is a direct statement of an action the authors should consider. While the reviewer doesn't provide specific details on *how* to implement these actions, the statements are clear and direct, making them actionable.", "grounding_specificity_rationale": "The reviewer refers to 'sparsity or low rank' and 'concentrationofmeasure' without explicitly pointing to a specific section or equation in the paper. While the concepts are general, the *claims* about the authors' understanding are specific. The reviewer is not providing a precise location within the paper, but rather a general critique of the authors' interpretation. Therefore, the grounding is weak as the authors cannot confidently pinpoint the referenced concept. However, the reviewer is also making a claim about the novelty of the results, which is a specific point of contention, making the grounding somewhat specific in that context.", "verifiability_rationale": "The reviewer makes claims about the authors' understanding of the paper's novelty and contribution. While they don't provide direct evidence to disprove the authors' claims, they offer alternative interpretations and point to existing literature as potential connections. This provides a basis for verifiability through logical reasoning and comparison to existing work. The reviewer doesn't provide specific examples or references within the review point itself, but the *suggestion* of connections to existing literature implies a potential source of verification. The lack of concrete evidence within the review point makes the verifiability somewhat low, but the reviewer's reasoning suggests a potential pathway for verification.", "helpfulness_rationale": "The review point raises questions about the authors' assessment of their work's novelty and contribution. It suggests that their work might be related to existing results and that they might have overlooked sparsity or low rank. This could be helpful for the authors to consider alternative perspectives and potentially update their understanding. However, if the authors are correct in their assessment, the reviewer's comments might be perceived as diminishing the value of their work. The helpfulness is moderate as it prompts a reevaluation, even if it's potentially negative for the authors."}
{"actionability_label": "Not Applicable", "grounding_specificity_label": "Not Applicable", "verifiability_label": "Not Applicable", "helpfulness_label": "3", "actionability_rationale": "The reviewer implies an action by suggesting the limitations section should be more detailed, but doesn't explicitly state what needs to be improved or how it should be done. The action is implied but vague.", "grounding_specificity_rationale": "The reviewer mentions 'the Limitations section' but doesn't specify which part or provide examples of what is missing or unclear. The grounding is implied but not precise.", "verifiability_rationale": "The review point is a statement of opinion about the writing style, not a claim that requires verification. Therefore, verifiability is not applicable.", "helpfulness_rationale": "The reviewer points out a potential issue with the paper's presentation and understanding of its scope. While relevant, it doesn't offer a concrete suggestion for improvement, making it 3 but not highly so."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a weakness in the novelty of the method and suggests a potential cause (modified version of PatchCore with denoising). This directly identifies a problem and proposes a solution, making it a concrete action. The reviewer identifies the *action* (identifying the weakness) and the *how* (suggesting the modification).", "grounding_specificity_rationale": "The reviewer mentions 'PatchCore' and 'denoising process,' which are specific technical details of a previous work. While they don't explicitly name 'memory bank,' the context strongly implies it. The reviewer also identifies the *area* of weakness (novelty) within the method. The grounding is explicit in pointing to a previous work and a modification.", "verifiability_rationale": "The reviewer makes a claim about the novelty being weak and provides a *potential explanation* (modified version of PatchCore with denoising). This potential explanation, while not a direct citation, points to a specific area for investigation. The reviewer identifies the *claim* (novelty is weak) and offers a *method* for verification (looking at the modification).", "helpfulness_rationale": "The reviewer clearly identifies a potential weakness in the method's novelty and suggests a possible cause. This directly points to a direction for improvement. While it doesn't pinpoint *exactly* where the weakness lies, it provides a concrete direction for the authors to consider. The reviewer's statement is directly actionable and relevant to the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a problem (lack of instructions) but doesn't explicitly state the next steps the authors should take. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer refers to the 'repository' and 'code' generally, without specifying a particular file, function, or the nature of the issues.", "verifiability_rationale": "The reviewer states a problem (lack of instructions) but doesn't provide direct evidence or justification for this claim within the review point itself. The suggestions are recommendations, not verifiable claims.", "helpfulness_rationale": "The reviewer identifies a concrete issue and offers general directions for improvement, but lacks the specific details needed for immediate action."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the finding from the model ablation results in Table 3, indicating a clear action the authors should take: investigate the impact of the global representation g_v on the model's performance and understand why it appears more crucial than other components. The action is also somewhat concrete as the reviewer points out the implication of this finding for the 'major claim of interpretable VQA'.", "grounding_specificity_rationale": "The review point explicitly mentions 'model ablation results in Table 3', which is a specific location within the paper. Furthermore, it specifies the 'global representation g_v' and its implication 'opens back door for grounded QA'. This provides a clear and specific reference point for the authors to understand the results and their potential impact.", "verifiability_rationale": "The review point contains a claim: 'Such results slightly depart from the major claim of interpretable VQA where correct answers are anchored on correct visual content.' However, the verifiability of this claim within the provided text is limited. While the claim is stated, there are no specific references or examples provided to support or refute this departure from the major claim. The reviewer points out a discrepancy but doesn't provide concrete evidence within their review point.", "helpfulness_rationale": "The review point identifies a discrepancy between the experimental results (model ablation in Table 3) and the stated claim of the interpretable VQA model. While this discrepancy is a valuable piece of feedback, the review point itself does not offer any specific guidance or suggestions for the authors on how to address this issue. The reviewer states the observation but doesn't provide a constructive response or next steps for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the need for a comparison with MoMask and identifies the location (ablation studies in Table 4 and motion tokenizer section). The phrasing 'Given that the proposed approach also utilizes RVQVAE, such comparisons would provide a more comprehensive understanding of the model\u2019s relative effectiveness' is a direct action suggesting a specific improvement. The action is concrete as it specifies the comparison and the location.", "grounding_specificity_rationale": "The review point explicitly mentions 'stateoftheart RVQVAE models, such as MoMask' and refers to the 'ablation studies on the motion tokenizer' in 'Table 4' and the 'motion tokenizer' section. This provides a clear and specific reference point for the comparison. The grounding is fully grounded as the specific model and the location of the missing comparison are explicitly mentioned.", "verifiability_rationale": "The review point contains a claim: 'Given that the proposed approach also utilizes RVQVAE, such comparisons would provide a more comprehensive understanding of the model\u2019s relative effectiveness.' This claim is logically reasoned as it explains the expected benefit of the comparison. The evidence for this claim is common knowledge in the field \u2013 comparing against stateoftheart models is a standard practice for demonstrating the effectiveness of a new method. The claim is supported by logical reasoning and common knowledge.", "helpfulness_rationale": "The review point is 5 as it directly points out a significant gap in the experimental evaluation \u2013 the lack of comparison with a relevant stateoftheart model. This is a concrete and actionable suggestion for the authors to better understand the performance of their motion tokenizer within the context of existing RVQVAE models. The reviewer is providing specific information about what comparison is missing and where it should be added."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer states that the difference between the 'primarysecondary' relationship and 'nuclearity' is unclear and not precisely defined. While the reviewer identifies a problem, they do not explicitly state what the 'primarysecondary' relationship is, nor do they specify how the 'nuclearity' is unclear or how it needs to be defined. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer mentions 'primarysecondary' relationship and 'nuclearity' as the unclear and undefined concepts. While they mention these terms, they do not explicitly identify the specific section, table, figure, or unique aspect of the paper where this relationship is discussed, nor do they pinpoint where the definition of 'nuclearity' is lacking. The grounding is implied rather than explicitly stated.", "verifiability_rationale": "The reviewer states that the 'primarysecondary' relationship is mentioned a lot in the paper, however, its difference with the nuclearity is unclear and not precisely defined. The reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The claim is stated without any justification.", "helpfulness_rationale": "The reviewer points out a potential area for improvement in the paper by highlighting the lack of clarity regarding the relationship between the 'primarysecondary' relationship and 'nuclearity'. This suggests that the authors could benefit from a clearer explanation of these concepts and their interrelation. The reviewer's comment identifies a genuine gap in the paper's explanation and encourages the authors to improve their writing."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the observation that the effect of the mask ratio varies across datasets. It also implies that this variation necessitates more tuning. The action of identifying this discrepancy and suggesting more tuning is a direct and clear instruction for the authors. While the reviewer doesn't provide concrete steps on how to adjust the ratio, the need for adjustment itself is a clear action.", "grounding_specificity_rationale": "The review point mentions 'mask ratio' and 'datasets' but does not specify which particular datasets are involved or how the effect differs between them. The reviewer refers to 'limitations' but does not provide specific examples or details about what is lacking in the discussion regarding the mask ratio. Therefore, the grounding of the issue is weak.", "verifiability_rationale": "The review point states an observation ('the effect of mask ratio seems to be very different for different datasets') and suggests a solution ('...will lead to more tuning'). While the reviewer points to 'limitations' which might imply the information exists but isn't clearly presented, they do not explicitly justify why this discrepancy is significant or how it impacts the work. The reasoning provided is at a high level and lacks specific examples or references to support the claim.", "helpfulness_rationale": "The review point identifies a practical issue: the varying impact of the mask ratio across datasets, which requires more tuning. This is relevant to the authors' workflow and can help them understand a limitation in their current setup or analysis. However, the reviewer does not provide specific guidance on how to choose an appropriate mask ratio or how this variation affects the overall results. The feedback is present but lacks concrete suggestions, making it 3 but not entirely."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem ('difficult to follow') but doesn't specify what needs to be improved or how to do it. The suggestion ('improve the writing') is implicit and lacks concrete details.", "grounding_specificity_rationale": "The comment refers to the 'paper' generally and doesn't identify a specific section, table, figure, or unique aspect being difficult to follow. There is no explicit mention of a specific part of the paper being addressed.", "verifiability_rationale": "The comment contains a claim ('I think the paper could benefit from another round of proofreading') but lacks specific justification or evidence. While it identifies a potential issue, the reasoning is vague and doesn't point to concrete examples or references.", "helpfulness_rationale": "The comment identifies a potential area for improvement ('difficult to follow') but lacks specific details or actionable steps. While it encourages improvement, it doesn't provide concrete guidance on what to do or how to address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly states that the term 'STG layer' has never been mentioned in the manuscript. While it identifies the missing information, it doesn't specify where in the text this term should be found, making it vague on how to apply the action. Therefore, it is considered explicit but vague.", "grounding_specificity_rationale": "The comment does not explicitly identify the section, table, or unique element where the 'STG layer' is mentioned in Figure 2. The reviewer has to make an educated guess about its meaning. This indicates weak grounding as the authors cannot confidently determine the referenced part. However, the comment clearly specifies what is missing \u2013 the mention of 'STG layer' in the text, making it specific to that aspect.", "verifiability_rationale": "The comment contains a claim: 'the term \u201cSTG layer\u201d in Fig. 2 has never been mentioned throughout the manuscript.' However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. It simply states that the term has not been mentioned. Therefore, it is considered 1.", "helpfulness_rationale": "The comment identifies a factual deficiency: the term 'STG layer' is used in Figure 2 but is not mentioned in the text. While it points out this issue, it does not suggest any improvements or provide any context to help the authors understand what 'STG layer' refers to. Therefore, it is considered 1 in terms of providing actionable feedback or clarifying terminology."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the improvements are limited and that the method underperforms in FiQA and CONALA. This indicates an explicit action or suggestion, as the reviewer points out a specific issue. However, the reviewer does not provide concrete steps or modifications that the authors should implement to address this limitation. The action is implied rather than directly stated as an action to be taken.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'improvements,' 'underperformance,' 'FiQA,' and 'CONALA.' The mention of 'FiQA' and 'CONALA' clearly identifies the specific datasets or experimental settings where the issue occurs. This demonstrates strong grounding as the reviewer pinpoints the exact context of the problem. The criticism is specific to the performance on these datasets.", "verifiability_rationale": "The reviewer makes a statement about the performance of the methodology, specifically mentioning that improvements are limited and there is underperformance in certain datasets. This constitutes a claim. However, the reviewer does not provide any evidence, references, or logical reasoning to support this claim within the review point itself. The claim is presented as an observation without justification.", "helpfulness_rationale": "The reviewer identifies a performance issue with the methodology on specific datasets. This is a valid concern for researchers and can be helpful in identifying areas for improvement. However, the review point lacks any suggestions or actionable steps for the authors to address this issue. The reviewer points out the problem but does not provide guidance on how to fix it, making it less helpful than a review point that offers concrete solutions."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer asks a question ('What are the contributions/advantages beyond 1?') and requests clarification on a comparison. While the reviewer implies an action (clarifying the comparison), the action itself is vague and lacks detail on how to apply it. The authors would need to go back to the paper and look at the comparison section (if any) to understand what is unclear. Therefore, the action is implicit and vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions '1 Differentially private model personalization. NeurIPS 2021' as the paper being compared to. This is a clear identification of a specific paper, making the grounding fully grounded. The reviewer also states that the comparison is unclear, which specifies the issue within this identified paper.", "verifiability_rationale": "The reviewer presents a question ('Comparisons with 1 are not clear.') and requests information ('What are the contributions/advantages beyond 1?'). There is X that needs verification. The review is a request for clarification and understanding, not a statement that requires logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer points out a potential weakness (unclear comparison) but does not provide a concrete solution or actionable steps for the authors to take. The request is for clarification and understanding, not a directive with a clear resolution. Therefore, it does not directly help the authors improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out that the explanation of the rebalancing step method is not explicit. The comment implies the need for improvement but does not clearly state what the rebalancing step does or how it helps in making the multimodal learning less greedy. The action is implicit, and the details are lacking, making it vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'rebalancing step method' and the 'average feature of previous samples' without the paper explicitly identifying the section or table where this method is described. The grounding is weak because the authors cannot confidently determine which part the comment addresses. While the concept of rebalancing is general, the specific implementation details are not clearly linked to a particular section or table.", "verifiability_rationale": "The reviewer claims that the analysis in the full text is lacking, and the justification for using the average feature of previous samples to stop the unimodal branch training is not provided. The claim is not supported by explicit reasoning, common knowledge, or external references. The paper does not logically explain why this approach is valid or provide examples or references to back it up.", "helpfulness_rationale": "The reviewer states that the rebalancing step method is not well described and lacks analysis in the full text. This makes the advice less helpful for the authors as they cannot understand the method's purpose or how to implement the suggested improvement. The lack of clarity and justification hinders the authors' ability to learn from the review."}
{"actionability_label": "3", "grounding_specificity_label": "2: 4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks 'what are the differences from and advantages over EATA?' and 'can we identify harmful OOD instances with entropy metric instead of energy one?'. These are direct questions about comparisons and alternatives, making them partially actionable. The reviewer identifies an implicit action: they want to understand the relationship between the 'Reduce' method and EATA, and they want to explore a potential modification. However, they don't provide concrete steps on how to perform these actions.", "grounding_specificity_rationale": "The reviewer refers to 'Section 4.1' and 'the 'Reduce' part' in their review point. This indicates a clear identification of the specific section and aspect of the paper being discussed, demonstrating strong grounding. They are asking questions directly related to this section and aspect, showing they can accurately pinpoint the relevant information.", "verifiability_rationale": "The reviewer poses questions about the 'Reduce' method and its comparison to EATA, and suggests using entropy instead of energy. While these are valid points for clarification and exploration, the review point itself does not contain a claim that is explicitly supported by evidence or reasoning within the review text. The reviewer is asking questions rather than making statements that require verification. Therefore, it is 2 as there is X being made that needs justification.", "helpfulness_rationale": "The reviewer's point is relevant to understanding and potentially improving the 'Reduce' method. They are asking about a comparison and suggesting an alternative approach. While the review point doesn't directly provide solutions or detailed explanations, it highlights areas where more information or clarification would be beneficial for the authors. Therefore, it can be considered 3 as it points to areas for improvement and further understanding."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests comparing against deterministic control, which is an explicit action. However, the specifics of this comparison are not detailed, making the action somewhat vague and not fully concrete.", "grounding_specificity_rationale": "The review point mentions 'deterministic policy' and 'deterministic control,' which could be interpreted as identifying a specific aspect of the paper. However, the reviewer does not specify *which* deterministic policy or control mechanism they are referring to, making the grounding weak. The issue being suggested (comparative analysis) is also not clearly detailed, leading to underspecificity.", "verifiability_rationale": "The review point presents a suggestion ('it might be interesting to see how...') without providing any specific evidence, reasoning, or references. It lacks a claim that can be verified.", "helpfulness_rationale": "The review point suggests exploring a comparison with deterministic methods. While relevant, it does not provide concrete guidance on how to perform this comparison or what specific aspects of the proposed method to analyze in relation to the deterministic approach. The suggestion is more exploratory than directly helpful for improving the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential issue in Table 4 and asks a question. While the reviewer doesn't explicitly state what needs to be changed, they identify a specific area (the 3rd column of Table 4) and ask about its label and a relationship between two variables. This points to a potential problem and asks for clarification. While not a direct instruction, it's a clear indication of a weakness that needs attention.", "grounding_specificity_rationale": "The reviewer refers to 'Table 4' and specifically asks about the 3rd column. This explicit mention of the table and the column clearly identifies the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer's question about the column header and the relationship between 'Corr' and 'CauAnt' implies a potential inconsistency or area needing clarification. While the reviewer doesn't explicitly state a claim that requires verification, their question itself serves as the basis for potential verification. If the column header is indeed 'ATE', and 'Corr' implies 'CauAnt', this needs to be confirmed.", "helpfulness_rationale": "The reviewer's comment directly points to a potential error in Table 4 and raises a question about a relationship between variables. This is highly relevant to the authors who are likely examining this table. The comment highlights a specific area that needs attention and encourages the authors to doublecheck their results and interpretations. It provides a clear direction for potential improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests two actions: 'making the connection to prior work clearer' and 'annotating or zooming in on the figures.' These are direct actions that the authors can take to improve their draft, making it actionable.", "grounding_specificity_rationale": "The reviewer mentions 'the methods section' as an area where the mechanism isn't anchored in prior work. While a specific part isn't named, the general area is pointed out. However, the suggestion to 'annotate or zoom in on the figures' is vague and doesn't pinpoint a specific element within the figures that needs improvement. The grounding is present at a higher level, but the specificity is lacking.", "verifiability_rationale": "The reviewer states 'even after the experiments section, there's only a vague sense of it' regarding the connection to prior work. This is a claim that needs justification. While the reviewer suggests making the connection clearer, the *how* of doing so isn't explicitly detailed or supported by external references or logical reasoning within the review point itself. The suggestion to annotate the figures is also vague and lacks a clear rationale for why specific annotations are needed.", "helpfulness_rationale": "The review point offers suggestions for improvement, such as clarifying the connection to prior work and annotating the figures. While these suggestions are relevant, they are somewhat general and lack concrete examples or detailed guidance. The reviewer also mentions an 'exception' in the methods section where the mechanism is made clear, which partially addresses the lack of clarity but doesn't fully resolve the issue. The suggestions are helpful but could be more specific and detailed to be fully impactful."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests that the pretrained mechanism is 'complicated'. This implies an action: to clarify or simplify the mechanism. While the action is implied, the reviewer does not explicitly state what needs to be clarified or how to do it. The reviewer points out a potential weakness (complicated) but doesn't offer concrete steps for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'a major concern is the limited novelty' and 'the pretrained mechanism applied to the task of fewshot graph learning'. While they identify the *area* of concern, they don't explicitly point to a *specific* part of the paper or provide a clear context for their suggestion. The reviewer is vague about which part of the paper needs improvement and how it relates to the pretrained mechanism.", "verifiability_rationale": "The reviewer doesn't make a claim that anything is wrong or needs to be changed. They express a concern and a suggestion for improvement ('complicated' implies a need for clarification or simplification). However, they don't provide any external references or logical reasoning to support their claim. The reviewer's suggestion is based on their interpretation of the mechanism's complexity, not on verifiable information.", "helpfulness_rationale": "The reviewer explicitly states a concern ('limited novelty') and suggests a potential improvement ('complicated' implies a need for clarification or simplification). This is a clear and actionable suggestion. The reviewer identifies a potential weakness and offers a specific direction for improvement (clarification). While the suggestion is somewhat general, it clearly points towards a helpful outcome for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states a *what* (the paper empirically validates) and a *why not* (they don't collapse), but lacks a *how* or actionable next step for the authors. It identifies a gap in understanding. While the reviewer explicitly states the *what* and *why not*, the lack of a concrete suggestion on how to address this gap makes the action vague.", "grounding_specificity_rationale": "The reviewer mentions \"the paper\" generally, without pinpointing a specific section, table, figure, or unique aspect of the paper. The comment is not identifying a specific part of the paper being addressed, making it 1.", "verifiability_rationale": "The claim is that \"it does not provide theoretical understanding on why they do not collapse.\" This is a statement of opinion or judgment. The reviewer states a limitation but does not provide any evidence, examples, or references to support this claim. There is no logical reasoning or external references given to back up the claim.", "helpfulness_rationale": "The review points out a significant limitation in the paper's contribution \u2013 the lack of theoretical understanding. This is valuable information for the authors who are looking to understand the underlying mechanisms. However, the review doesn't *suggest* how the authors can gain this understanding. The helpfulness is limited because the reviewer doesn't offer actionable advice to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "Partially Verifiable", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that the visual analysis in Section 4.4 is unclear regarding the data source (training vs. testing). This is an explicit statement of a missing piece of information. While the reviewer doesn't *say* *what* is unclear, the *action* of clarifying the data source is concrete. Therefore, the actionability is present but could be considered somewhat vague as the reviewer doesn't identify a specific action to take beyond clarifying the data source.", "grounding_specificity_rationale": "The reviewer mentions \"Sec. 4.4\" which provides some grounding. However, they do not explicitly state whether the visual analysis in that section is based on training or test images. They imply a lack of clarity. Therefore, the grounding is not fully explicit. The specificity is also lacking as the reviewer does not detail what is unclear about the visual analysis or the implications of the unclear data source.", "verifiability_rationale": "The reviewer states a fact: \"The proposed method does not require the pose estimation in the inference, so test image does not have pose maps.\" This is a factual statement and can be considered verifiable. However, the reviewer then states a question: \"It is not clear if the visual analysis on Sec.4.4 is the result on training images or test images.\" This is a statement of uncertainty, not a claim requiring verification. Therefore, while the first part is verifiable, the second part is not.", "helpfulness_rationale": "The reviewer points out a lack of clarity regarding the data source for a visual analysis. This directly impacts the authors' ability to understand and potentially reproduce or build upon the work. The question about whether the visual analysis is on training or test images highlights a potential ambiguity that could hinder understanding and further development. Therefore, the review point is not entirely helpful as it does not provide concrete suggestions or corrections."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The suggestion to apply DEER to LEM and UnICORNN is quite explicit. It clearly states what the authors *should* do. While the *how* of applying DEER isn't detailed, the *what* is. This makes the action clear and directly actionable for the authors.", "grounding_specificity_rationale": "The reviewer *mentions* other methods (LEM, UnICORNN) but doesn't explicitly state which *part* of the paper they are referring to. They are implying it's related to the methods discussed in the paper. However, the reviewer doesn't specify *how* DEER would be applied to these methods or what the expected outcome would be. The grounding is weak because the specific method being applied to isn't clearly identified within the paper's context.", "verifiability_rationale": "The reviewer presents a claim: 'It would have been interesting to see the DEER method applied to some of the other methods such as LEM or UnICORNN...'. This is a suggestion and doesn't provide any specific evidence or reasoning to *support* this claim within the review point itself. The claim is not verifiable based solely on the provided review point.", "helpfulness_rationale": "The reviewer directly addresses a potential area for improvement and suggests a concrete experiment. The suggestion is not just a criticism but a constructive idea for future work. It offers a clear next step for the authors to explore the potential of applying DEER to other methods. This makes the review point highly relevant and actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem ('presentation is hard to follow') and suggests a solution ('too many notations are used'). However, it doesn't explicitly state *how* to implement this solution. The action is implied but lacks concrete details.", "grounding_specificity_rationale": "The comment is very general and does not specify a particular part of the paper, table, figure, or unique element that is causing the difficulty. It simply states 'the presentation is hard to follow.' This is a broad statement with no pinpoint reference.", "verifiability_rationale": "The comment is a statement of observation about the presentation being hard to follow. It doesn't make a claim that requires verification or support. It's a descriptive statement.", "helpfulness_rationale": "The comment points out a valid issue ('presentation is hard to follow') and suggests a general direction for improvement ('too many notations are used'). While it lacks specific steps, it does offer a direction for the author to take. It's not completely uninformative, but it could be more specific."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'It would be good to include some results of GPT4V' and suggests exploring this through ChatGPT's UI. This is an explicit action that is also concrete, as it tells the authors exactly what to do and how to approach it.", "grounding_specificity_rationale": "The review point refers to 'GPT4V' and 'ChatGPT's UI', which are specific elements within the paper or the authors' work. This allows the authors to identify the exact area where the suggestion is being made, making it fully grounded. Furthermore, the suggestion to 'experiment with GPT4V using ChatGPT's UI' adds specificity to the action being recommended.", "verifiability_rationale": "The review point contains a claim, which is the suggestion to 'experiment with GPT4V using ChatGPT's UI'. While this is a valid suggestion and points towards a potential improvement, it lacks specific details about how this experiment should be conducted or what the expected outcomes would be. Therefore, it is not 5, as it doesn't provide a clear, logical reasoning or specific examples to support the claim beyond the general idea of exploring advanced AI tools.", "helpfulness_rationale": "The review point suggests an experiment with GPT4V, which is a valuable direction for the authors, especially if they are working on tasks related to text analysis or evaluation. While it doesn't provide specific details about the experiment, it offers a concrete suggestion for further investigation and potential improvement. This makes it 5 as it guides the authors towards a potentially beneficial area of exploration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'why CoPur could do better,' indicating an intention to discuss this aspect. However, it doesn't provide specific details on *how* CoPur achieves better results or what modifications the authors should consider. The action is identified, but the concrete steps for implementation are missing, making it only 3.", "grounding_specificity_rationale": "The comment refers to 'the theoretical analysis' generally. While it identifies the area needing improvement, it doesn't specify which part of the analysis or what specific elements within that analysis are problematic. The grounding is implied but not precise, making it 2.", "verifiability_rationale": "The comment presents a claim that the theoretical analysis is 'extensive' and that the reasons for CoPur's improvement aren't fully explained. However, it doesn't provide specific examples, references, or logical reasoning to support this claim. The claim is stated, but the evidence to verify it is lacking, making it 3.", "helpfulness_rationale": "The review points out areas for improvement (the theoretical analysis and the comparison with baselines) and suggests the authors discuss more. While this is a valuable suggestion, it doesn't provide specific guidance on *how* to improve these aspects. The feedback is relevant, but the lack of concrete advice limits its helpfulness. The suggestion is present, but the guidance is missing, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The criticism about the metrics being mostly for 3D NVS and the lack of clarity in the evaluation protocol is not explicitly stated as an actionable suggestion. While the reviewer identifies a problem, they don't pinpoint specific areas within the NVS process where these metrics are lacking or propose concrete improvements. The criticism is general and doesn't directly lead to actionable feedback for the authors.", "grounding_specificity_rationale": "The reviewer's statement that 'the reported metrics are mostly for 3D NVS' is 1 as it lacks specificity. The reviewer does not identify a particular section, table, figure, or unique aspect of the paper where these metrics are primarily used. The criticism is general and doesn't pinpoint the exact location of the issue within the NVS process. The lack of clarity regarding camera parameters is also not specifically grounded to a particular part of the paper or methodology.", "verifiability_rationale": "The reviewer's claim that 'the reported metrics are not good' and 'the evaluation protocol is not clear enough' is not verifiable. The reviewer states these issues without providing specific examples or references to the methodology or results. There is no logical reasoning, common knowledge, or external references provided to support these claims. The criticism is general and lacks the necessary detail to be considered verifiable.", "helpfulness_rationale": "The reviewer's assessment that the criticism about the metrics and protocol is 'not helpful' is not helpful because it lacks specific details and actionable suggestions. The reviewer states the issues generally without providing concrete examples of how the metrics or protocol could be improved. The criticism is vague and doesn't offer any specific guidance for the authors. Therefore, the overall assessment is not helpful due to the lack of specificity and actionable feedback."}
{"actionability_label": "1: Not Actionable", "grounding_specificity_label": "3", "verifiability_label": "1: Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential issue (disjointedness) and suggests a solution (integration), but it doesn't provide specific, actionable steps for the authors to take. The suggestion to 'integrate' is broad and lacks concrete details on how to achieve this integration. Therefore, while it points to a problem, it doesn't offer explicit or concrete instructions for improvement, making it not actionable.", "grounding_specificity_rationale": "The comment generally refers to 'pretraining and regularization' without specifying a particular section, table, figure, or unique element of the paper. While it mentions 'the two parts,' it doesn't pinpoint the exact area within the paper where the disjointedness is most evident. The authors cannot confidently determine which part the comment addresses. However, the comment does specify what needs to be addressed in this part \u2013 the disjointedness of pretraining and regularization. Therefore, it has weak grounding specificity.", "verifiability_rationale": "The comment expresses an opinion or judgment about the presentation of pretraining and regularization, stating that they appear to be 'incremental additions' and 'distract from the coherence of the paper.' This is a subjective assessment without any supporting evidence or logical reasoning. There is X being made that requires verification. Therefore, the comment does not contain a claim that can be supported by logical reasoning, common knowledge, or external references, making it not verifiable.", "helpfulness_rationale": "The comment identifies a potential area for improvement (the disjointedness of pretraining and regularization) and suggests that these components should be 'integrated.' While this points to a valid concern, it lacks specific, actionable guidance on how to achieve this integration. The suggestion is general and doesn't provide concrete steps or strategies for the authors to follow. Therefore, while the comment highlights a potential issue, it doesn't offer sufficiently detailed or constructive feedback to be 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the importance of Renyi divergence is not well explained. While the reviewer doesn't provide specific details on *how* it's not explained, the statement itself identifies an actionable area for improvement. The reviewer clearly identifies a deficiency in the explanation.", "grounding_specificity_rationale": "The reviewer mentions 'Renyi divergence' and 'differential privacy' but doesn't specify *where* in the paper or *what aspect* of the explanation is lacking. The mention of these terms provides some grounding, but the lack of precision in identifying the specific part being addressed makes the grounding weak. The reviewer also states that the explanation is 'not well explained,' which is a general statement about the explanation's quality rather than a specific detail about what is missing.", "verifiability_rationale": "The reviewer makes a claim that the explanation is 'not well explained.' This is a claim that *could* be supported by providing examples of where the explanation is unclear or by referencing other explanations that are considered clearer. While the reviewer doesn't provide external references or logical reasoning to verify the claim, the claim itself is verifiable in principle. The lack of specific examples of the lack of explanation makes it less '5' but it's not '1' as the claim is clear.", "helpfulness_rationale": "The reviewer explicitly asks for a better explanation of Renyi divergence's importance. This is a direct request for improvement and indicates a clear need for additional information. The reviewer's desire for clarification suggests that the current explanation is hindering their understanding or ability to implement something based on it."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential area for improvement (simplicity and clarity) and criticizes something (mathematical theories). However, it does not specify *how* the authors should go about achieving this. It's a general direction rather than a concrete action.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper or section that needs improvement. It is a general suggestion about the overall approach to the paper.", "verifiability_rationale": "The comment is a suggestion, not a claim that requires verification. It does not state that something is incorrect or missing, but rather offers a potential improvement.", "helpfulness_rationale": "The comment points out a potential area for improvement (simplicity and clarity) and criticizes something (mathematical theories). While it doesn't provide specific steps, it offers a general direction for the authors to consider. It's better than a completely unhelpful comment, but lacks the specificity of a more detailed suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and Somewhat Specific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a potential improvement (further study of the threshold) but doesn't explicitly state what action to take or how to implement it. It implies an action but lacks detail.", "grounding_specificity_rationale": "The comment identifies the concept of ablation but doesn't specify *where* the ablation study should be performed (e.g., different ranges of the threshold). It mentions the threshold but not the specific implementation details. The author can infer the need for further study but not the exact steps.", "verifiability_rationale": "The comment states a claim ('the impact of the predefined threshold \u03f5 should be further studies') but doesn't provide any justification for why this is important or how to perform the study. It lacks supporting evidence or reasoning.", "helpfulness_rationale": "The comment identifies a missing analysis (the impact of the predefined threshold \u03f5) and suggests a concrete direction for improvement (further studies). It provides a clear weakness and a suggestion for action, making it 3. However, it doesn't offer a specific alternative value or detailed explanation *why* the threshold is important, limiting its helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem: 'Only RougeL is used for evaluation' and the consequence: 'which makes the evaluation not that reliable'. They also mention the specific context: 'Especially for some classification tasks, RougeL is not sensitive enough'. This indicates a clear identification of an issue and its scope.", "grounding_specificity_rationale": "The reviewer mentions 'RougeL' and 'classification tasks'. While not a direct section reference, these are specific enough terms to ground the comment to the paper's content. The reviewer also specifies the *type* of task where the issue is prominent, adding further specificity.", "verifiability_rationale": "The reviewer makes a claim: 'Only RougeL is used for evaluation'. This is a factual statement. They also provide a justification: 'which makes the evaluation not that reliable'. This is a generally accepted understanding of evaluation metrics. Furthermore, they specify the context: 'Especially for some classification tasks, RougeL is not sensitive enough'. This provides a specific example to support their claim, making it more verifiable.", "helpfulness_rationale": "The reviewer points out a clear limitation in the evaluation process used for the paper. They identify a specific metric (RougeL) and a specific task (classification) where this metric is known to be less reliable. While they don't propose a solution, they highlight a significant weakness that the authors should be aware of to improve their evaluation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem ('The definitions of variables do not properly match the formula') and points to a specific location (lines 580588) and a specific element within an equation (Equation 3). This indicates a clear and direct action the authors should take: 'Check the definitions of variables in lines 580588 and ensure they correctly match the formula in Equation 3.' The reviewer provides the necessary information to implement this action.", "grounding_specificity_rationale": "The reviewer provides a highly specific reference to a location in the paper (lines 580588) and a specific element within an equation (Equation 3). They also state the *specific problem* they are encountering ('The definitions of variables do not properly match the formula'). This strong specificity allows the authors to directly identify the issue and understand exactly what needs to be addressed.", "verifiability_rationale": "The reviewer states a problem ('The definitions of variables do not properly match the formula') but does not provide any justification or evidence for this claim. They do not explain why the definitions are incorrect, how they should be corrected, or provide any references to support their assertion. Therefore, the claim is not supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer's point is that the definitions in the specified location and equation are incorrect. While this is a valid observation, it doesn't directly suggest a concrete improvement or actionable step for the authors. The reviewer is pointing out a problem, but not providing a solution or a generalizable insight that would help them improve their work. It's a diagnostic comment rather than a prescriptive one."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer poses a direct question about the methodological choice of using a single vector per class and requests justification for this approach. This constitutes an explicit action or suggestion, guiding the authors towards a specific consideration. The request for justification further enhances the actionability by prompting a rationale for the chosen method.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify a specific part of the paper or methodology being addressed. The focus is on a general methodological choice (using a single vector per class) and a request for justification. While the paper's overall assumption is implied, the reviewer doesn't pinpoint where this assumption is being challenged or how the single vector strategy conflicts with it. Therefore, the grounding is weak as the authors cannot confidently determine the referenced aspect.", "verifiability_rationale": "The reviewer poses a question and requests justification for a specific methodological choice. This constitutes a claim (the single vector strategy might be conflicting with the samplespecific assumption) that needs to be supported. While the justification is implied, the reviewer doesn't provide concrete examples or references to back up their claim. Therefore, the verifiability is somewhat lacking as the claim needs to be further substantiated.", "helpfulness_rationale": "The reviewer directly challenges a methodological choice (using a single vector per class) and asks for justification. This is a clear and actionable feedback for the authors, guiding them to reconsider their approach and understand the potential limitations. The request for justification makes the feedback more constructive and helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a need for clarification regarding the intent discovery experiment setting and the comparability of the reported SOTA to baselines. This constitutes an actionable suggestion, as it directly points to a potential issue in the experimental setup that needs to be addressed to improve the understanding of the results.", "grounding_specificity_rationale": "The reviewer refers to 'the intent discovery experiment setting' and 'intent discovery experiment results,' clearly identifying the specific aspect of the paper being addressed. This indicates strong grounding as the reviewer is directly referring to a specific part of the methodology and findings.", "verifiability_rationale": "The reviewer identifies a potential issue (the assumption of a known number of intent classes and its impact on the comparability of results) but does not provide any specific evidence or justification for this concern. While the grounding is specific, the lack of verification makes this a 3 point.", "helpfulness_rationale": "The reviewer raises a valid concern about the experimental setup and the comparability of the reported SOTA to baselines. This points to a potential flaw in the methodology or the interpretation of the results. While the reviewer does not directly provide a solution, highlighting this issue is helpful for the authors to critically evaluate their work and potentially identify areas for improvement in their experimental design or analysis. The concern itself is valuable information for improving the work, even without a direct solution."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review points out limitations and potential issues but doesn't provide specific, actionable steps the authors should take to address them. For example, it mentions the 'supposedly' working dseparation criteria and the reliance on corruption labels in experiments, but doesn't specify how these should be improved or what actions the authors should take to address these issues.", "grounding_specificity_rationale": "The review refers to specific aspects of the methodology and experiments, such as 'dseparation criteria,' 'intervened graph,' 'known variables,' 'causal relationships,' and 'experiments on the corrupted CIFAR and ImageNet,' indicating that the authors can identify the specific parts of the paper being addressed.", "verifiability_rationale": "The review does not make any claims that require verification. It expresses appreciation for the experiments and points out limitations and potential issues without providing evidence or references to support its statements.", "helpfulness_rationale": "The review points out limitations and potential issues in the work but does not provide concrete, actionable feedback or suggestions for improvement for the authors. It expresses appreciation for the experiments but doesn't offer specific guidance on how to address the identified limitations."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their position and provides a reason for their concern. They are stating that the reliance on gradientbased saliency methods might not align with the underlying feature selection mechanisms in the human brain. This is a clear statement of an issue and a reason for it.", "grounding_specificity_rationale": "The reviewer mentions 'gradientbased saliency methods,' 'feature map channels,' 'feature selection mechanisms,' and 'human brain' as related concepts. While they mention these terms, they don't explicitly identify the specific part of the paper or method they are referring to. The connection between these terms is implied but not explicitly stated. The reviewer is general in their reference.", "verifiability_rationale": "The reviewer presents a claim that 'the reliance on gradientbased saliency methods to evaluate the importance of feature map channels may not align with the underlying feature selection mechanisms in the human brain.' This is a claim that needs to be verified. The reviewer argues that it might not align, implying a lack of direct evidence or justification for the alignment. The reasoning is present, but the evidence is missing.", "helpfulness_rationale": "The reviewer raises a valid concern about the methodological choice of using gradientbased saliency for feature map channels in the context of feature selection and its biological plausibility. This raises a helpful question for the authors and points to a potential limitation of their analysis. The reviewer is suggesting that this method might not be the most appropriate for their specific research question. The reviewer's point is clear and raises a valid concern about a methodological choice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the model used (Pythia) and implies the issue (not SOTA). This is explicit. However, the reviewer does not specify *why* Pythia is not SOTA or what implications this has for the paper. The action is 'pointing out the model choice', which is somewhat general.", "grounding_specificity_rationale": "The reviewer explicitly names the model (Pythia) and also mentions a specific characteristic of this model ('not stateoftheart (SOTA) though it does have the advantage of available checkpoints'). This indicates strong grounding as the specific part of the paper (the model choice) is clearly identified. The mention of 'available checkpoints' further specifies the context.", "verifiability_rationale": "The reviewer makes a claim about the model (Pythia) and its characteristic ('not stateoftheart (SOTA) though it does have the advantage of available checkpoints'). However, the reviewer does not provide any justification or evidence for this claim. There is no logical reasoning, common knowledge, or external references provided to support the assertion that Pythia is not SOTA or that available checkpoints are an 'advantage' in this context.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the paper (using Pythia, a model that is not stateoftheart) and suggests a reason for this choice ('though it does have the advantage of available checkpoints'). While the reviewer points out a relevant factor, they do not explicitly recommend a different model or explain the implications of using a nonSOTA model for the paper's specific context. The suggestion is present, but the lack of concrete action makes it 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point presents several questions and suggestions, indicating an attempt to guide the authors. However, it lacks specific, actionable steps. The reviewer asks 'Is the failure of existing works attributed to the incompleteness of offline RL algorithms or the lack of image representation learning?' which is a question prompting the authors to consider different possibilities, but doesn't provide a clear action. Similarly, the reviewer asks 'Can this task be intuitively completed solely with the provided offline data?' and 'If not, is there an alternative data source that the community can leverage to address this challenge?' These are questions that require the authors to consider different options, but don't provide explicit instructions on how to address them. While the topic of the suggestions is concrete (offline RL, image representation learning), the action isn't clearly defined. The reviewer doesn't say, 'You should develop a new offline RL algorithm,' but rather asks *what might be causing the problem*.", "grounding_specificity_rationale": "The first part of the review point, 'More information or resource should be provided to challenge the community to solve the image observation version of Franka Kitchen,' is vague. It doesn't specify *where* the information should be provided or *what specific resources* are needed. The reviewer mentions 'offline RL algorithms' and 'image representation learning' as potential causes of failure. While these are relevant areas, the connection back to the *specific Franka Kitchen task* isn't explicitly stated. The reviewer implies these areas are relevant, but doesn't pinpoint the exact part of the Franka Kitchen task that needs clarification. The suggestion about an 'alternative data source' is vague.", "verifiability_rationale": "The review point contains several claims and questions. The claim 'Is the failure of existing works attributed to the incompleteness of offline RL algorithms or the lack of image representation learning?' is presented as a question the authors should consider, not as a verifiable statement with evidence. Similarly, the claim 'Can this task be intuitively completed solely with the provided offline data?' is a question about the data's sufficiency, not a verifiable statement. The claim 'If not, is there an alternative data source that the community can leverage to address this challenge?' is also a question. The reviewer does not provide any external references or logical reasoning to support these claims. They are presented as questions the authors should consider, not as verifiable statements with evidence.", "helpfulness_rationale": "The review point raises valid concerns about the Franka Kitchen task and suggests potential areas for improvement. It points out a potential gap in current approaches. However, the review doesn't offer concrete, actionable steps for the authors to take. It's more of a diagnostic than a prescriptive critique. The reviewer asks 'Is the failure of existing works attributed to the incompleteness of offline RL algorithms or the lack of image representation learning?' which is a question prompting the authors to consider different possibilities, but doesn't provide a clear action. Similarly, the reviewer asks 'Can this task be intuitively completed solely with the provided offline data?' and 'If not, is there an alternative data source that the community can leverage to address this challenge?' These are questions that require the authors to consider different options, but don't provide explicit instructions on how to address them. While the reviewer identifies a problem, the lack of specific guidance makes it less helpful than a critique that offers clear solutions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'Could you provide some insight why the multilingual model is \"noticeably weaker\"'. This directly points to the issue and asks for an explanation, making it 3 in identifying the problem. However, it doesn't offer a concrete solution or guidance on how to address it, thus not fully reaching the level of high actionability.", "grounding_specificity_rationale": "The comment explicitly mentions 'ET>En' and 'LV>EN' evaluations, clearly identifying the specific part of the paper being referred to. This indicates strong grounding as the authors can easily pinpoint the section being discussed. Furthermore, the comment asks 'why' the model is weaker in these evaluations, which is a specific question about the observed phenomenon within this context.", "verifiability_rationale": "The comment contains a claim: 'the multilingual model is \"noticeably weaker\" on the ET>En and LV>EN evaluations'. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. It simply states the observation without explaining *why* it is the case.", "helpfulness_rationale": "The comment identifies a weakness in the model's performance on specific evaluations and asks for an explanation. While this is a valuable piece of feedback, it does not offer a concrete action or suggestion on how to improve the model or address the identified weakness. It's more of a request for clarification than a directive improvement suggestion."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue: '29 percent accuracy with table assembly tasks is rather low' and 'the Euclidean distance error units in Table 1 seem very high'. While it doesn't explicitly state the *action* to take, the reviewer implies that the high error needs to be addressed. High error in table assembly often points to debugging issues in the assembly logic or visualizing the results. Therefore, the reviewer provides a clear indication of what needs to be investigated or improved, making it actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'Table 1' and discusses 'Euclidean distance error units' and 'position errors'. This clearly grounds the comment to a specific part of the paper and the nature of the error being observed. The reviewer is not making a general comment but is focusing on a specific result presented in the paper.", "verifiability_rationale": "The review point makes a claim about the 'high' nature of the Euclidean distance error. While it doesn't provide a direct citation for what constitutes a 'high' error, the reviewer's statement is based on their calculation or observation of the error values in Table 1. The reasoning is implicit, relying on the reader's understanding of the expected error range for such tasks. Therefore, while the claim is somewhat supported, it lacks explicit references or examples, making it 3.", "helpfulness_rationale": "The review point identifies a problem ('high' error) and suggests a potential area for improvement ('visualization'). While it doesn't offer a specific, actionable fix, it points towards a common technique used to understand spatial data and potentially debug the assembly process. By highlighting a potential solution area, the reviewer provides some direction for the authors, making the review 3 in guiding improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out a potential issue with the paper's contribution ('does not reach a conclusion' and 'the article suggests that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences'). However, it doesn't explicitly state what the authors should do to address this. The suggestion is more of an observation than a direct instruction for improvement.", "grounding_specificity_rationale": "The review refers to the 'conclusion' of the paper and the 'ability of existing sentiment analysis models' to handle certain sentence types. While it identifies the general area of discussion, it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. The reference is broad and inferential.", "verifiability_rationale": "The review makes a claim about the capabilities of existing sentiment analysis models without providing any evidence, reasoning, or references to support this assertion. It simply states what it believes the models can do.", "helpfulness_rationale": "The review raises a valid point about the potential lack of novelty in the paper's contribution. However, it doesn't offer concrete, actionable suggestions for the authors to make their work more impactful or distinct. It's more of a critique pointing out a potential issue rather than a constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The statement explicitly mentions 'the labeler's strategy that is already predefined' as the reason for the limited contribution of the algorithm design. This directly points to a need for improvement in the labeler's strategy, making the action somewhat explicit. However, the reviewer does not specify *how* the labeler's strategy should be improved, making the action somewhat vague and not fully concrete.", "grounding_specificity_rationale": "The review refers to 'the labeler's strategy' as the specific part of the algorithm design being criticized. While it identifies a specific area, it does not pinpoint a specific section, table, figure, or unique element within the paper. The reviewer uses general terms, making the grounding somewhat weak.", "verifiability_rationale": "The review contains a claim: 'the theoretical results are does not belong too much surprising information and has limited contribution to the algorithm design, since the algorithm design is mainly based on the labeler's strategy that is already predefined.' The reviewer attempts to support this claim by stating 'The algorithm design is mainly based on the labeler's strategy that is already predefined.' This provides a reason for the assessment, making the claim 3.", "helpfulness_rationale": "The review points out a potential weakness in the algorithm design ('the labeler's strategy that is already predefined') and suggests that this contributes to the 'limited contribution to the algorithm design.' This identifies a meaningful area for improvement. However, the review does not offer specific, actionable steps for the authors to take to address this weakness. It lacks concrete suggestions for how to improve the labeler's strategy or how to make the theoretical results more surprising. Therefore, while the review is relevant, it is not 5 due to the lack of specific action items."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of detail regarding the effectiveness of reverse chaining in multiAPI planning. This is an explicit action the reviewer suggests the authors take \u2013 go back and add more detail. While the reviewer doesn't specify *what* details are missing, they clearly identify the *area* where detail is lacking. The reviewer could have been more specific about *why* it's not detailed, but the action itself is clear.", "grounding_specificity_rationale": "The reviewer criticizes the paper for focusing on *comparing multiple tools or methods in API calling & planning & reduces research contribution*. This criticism is not tied to a specific section, table, figure, or unique element of the paper. The reviewer is broadly criticizing the *focus* of the paper. They are not pointing to a specific part of the paper that they believe needs improvement. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point contains two claims:\n1. \"How reverse chain proved to be effective in multiAPI planning is not delineated in detail\"  This claim is 3 as the reviewer states a lack of detail. However, they don't provide a reason *why* it's not detailed or suggest *how* it should be detailed.\n2. \"This article focuses on comparing multiple tools or methods in API calling & planning & reduces research contribution\"  This claim is not wellsupported by evidence. The reviewer makes a generalization about the paper's focus and its impact on research contribution without providing specific examples or references. Therefore, the verifiability of the second claim is low. Overall, the verifiability is partially verifiable because one part of the claim is 3, but the other is not wellsupported.", "helpfulness_rationale": "The review point provides a specific criticism about the lack of detail in the explanation of reverse chain's effectiveness and a general criticism about the paper's focus on comparisons. The reviewer suggests that this reduces the research contribution. While the criticism is valid and points to a missing element, the reviewer does not offer specific, actionable suggestions for improvement. They identify the *area* where detail is lacking but don't provide concrete steps the authors should take to address it. Therefore, the feedback is 3 as it highlights a meaningful weakness, but it lacks specific guidance on how to fix it."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states a recommendation to reject the paper. While this is an action, it does not provide specific details on what needs to be changed or improved. The action is stated, but the subsequent steps are missing, making it less actionable in the sense of guiding improvement.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper that is problematic. It only states a general opinion about the paper's quality and recommends rejection without pinpointing the exact issue. Therefore, the grounding is weak as the authors cannot determine where to focus their improvements based on this comment alone.", "verifiability_rationale": "The review point contains a claim (the recommendation to reject the paper) but does not provide any justification or evidence for this claim. There are no logical reasoning, common knowledge, or external references supporting the recommendation. The claim is made without any backing, making it 1.", "helpfulness_rationale": "The review point is a simple recommendation to reject the paper. While this is a valid critique, it does not offer any specific suggestions or guidance on how to improve the paper. The authors are left without any actionable steps or insights to address the perceived weaknesses, making it only marginally helpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the choice of Masked Language Models (MLMs) without providing explicit guidance or suggestions on how the authors should proceed or what changes they should make. It's a query for justification, not a directive for action. Therefore, it lacks explicit and actionable information for the authors.", "grounding_specificity_rationale": "The review point asks a general question about the choice of MLMs and LMs without specifying which part of the paper this choice pertains to. It doesn't mention any specific section, table, figure, or unique element of the paper. The reviewer is asking for a reason for a general methodological decision, not about a specific aspect of the work.", "verifiability_rationale": "The review point is a question, not a statement that requires verification. It doesn't present a claim that needs to be supported by logical reasoning, common knowledge, or external references. It's a request for explanation, not a statement that needs to be proven.", "helpfulness_rationale": "The review point is relevant to the authors as it seeks to understand the rationale behind their choice of MLMs. This can be helpful for the authors to reflect on their methodological decisions and potentially make improvements or provide context to their work. While it doesn't directly guide them on what to do, it prompts them to think critically about their choices."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment implicitly states an action by pointing out a lack of clarity regarding the encoding process and suggesting an additional experiment. While it doesn't explicitly name the action, the reviewer implies that the authors should clarify the encoding and demonstrate effectiveness on YNet experiments. The reviewer is suggesting improvements rather than directly instructing the authors on what to do.", "grounding_specificity_rationale": "The comment explicitly mentions 'how is the map encoded?' and 'experiments proposed in YNet'. This demonstrates strong grounding specificity as the reviewer accurately identifies the specific aspects of the paper that need clarification or evaluation. They are not just saying 'the method needs improvement,' but rather pinpointing very specific areas of potential weakness or missing evaluation.", "verifiability_rationale": "The comment contains a claim that the authors should have shown effectiveness on YNet experiments. The reviewer suggests this as a missing evaluation. While the comment doesn't provide a definitive answer on *how* to encode the map, it provides a clear suggestion for additional experiments. The claim is supported by the suggestion to evaluate on a standard framework (YNet), making it 3.", "helpfulness_rationale": "The review points out two distinct and actionable areas for improvement: clarifying how the map is encoded and demonstrating effectiveness on YNet experiments. While both are valid points, the review doesn't offer a single, unified piece of advice that directly addresses both issues simultaneously. It highlights areas where the authors need to be clearer and more comprehensive in their evaluation. Therefore, it provides clear direction for improvement, but it's not a highly constructive critique that offers a specific solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comparison is explicit about the models and the metric (r2). However, it doesn't suggest any concrete actions the authors should take next. The reviewer states a fact but doesn't provide guidance on how to address the lack of significant improvement.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed model' and 'MSA Transformer,' which could be considered grounded if they correspond to specific sections or previously defined models. The metric 'r2' is also a specific element. However, the reviewer doesn't specify *why* the models are not much better in terms of r2.", "verifiability_rationale": "The reviewer makes a claim ('the proposed model is not much better...') without providing any supporting evidence or justification within the review point itself. There is no logical reasoning, common knowledge, or external references provided to support this statement.", "helpfulness_rationale": "The review point identifies a weakness (lack of significant improvement in r2) but does not offer any suggestions or actionable steps for the authors to take. It simply states a fact without providing guidance on how to address it."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states they 'don't know what an \"ensemble of independent measures on the full feature space\" means' and requests 'more mathematical details here'. While they understand the *concept* of an ensemble, the specific terminology and its connection to the scaling are unclear. The action is implied (the reviewer wants more information), but it's not explicitly stated what specific action needs to be taken by the authors to understand the concept. The vagueness of the request makes it difficult to pinpoint the exact action needed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'top of page 6: \"In the previous paragraphs we set forth evidence in support of the hypothesis that large chunks of the final representation of wide DNNs behave approximately like an ensemble of independent measures of the full feature space. This allowed us to interpret the decay of the test error of the full networks with the network width observed empirically in Fig. 2\"'. This clearly points to a specific section of the paper. However, the reviewer doesn't specify *which* part within that section is unclear. The grounding is present, but it's not specific to a particular element (e.g., a definition, a figure, a specific claim).", "verifiability_rationale": "The reviewer makes a claim: 'I don't know what an \"ensemble of independent measures on the full feature space\" means, or why it explains the scaling, so would appreciate much more mathematical details here.' This constitutes a claim that needs verification. The reviewer requests 'mathematical details' as a way to understand the concept and its relation to the observed scaling. While the request is for evidence, it's not explicitly linked to external references or logical reasoning within the provided text. The claim is somewhat supported by the request for details, but lacks specific references or a clear logical flow.", "helpfulness_rationale": "The reviewer provides a clear and actionable request: 'I don't know what an \"ensemble of independent measures on the full feature space\" means, or why it explains the scaling, so would appreciate much more mathematical details here.' This directly addresses a potential area of confusion for the authors and provides a specific direction for improvement. The reviewer is asking for clarification and more information, which is a constructive way to suggest improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking two questions: 'Did authors tried using BlenderBot vs 2.0 with incorporated knowledge?' and 'it would be very interesting to see how the dialogs can be improved by using domain ontologies from the SGD dataset.' These are questions that require the authors to reflect on their own work and consider future directions. There are no explicit instructions or suggestions on what the authors should do. The reviewer is not prompting the authors to take a specific action. Therefore, the review point lacks explicit and actionable guidance.", "grounding_specificity_rationale": "The reviewer's questions are general and do not specify which part of the paper or which aspect of the work they are referring to. They are asking about the authors' experience with a specific tool (BlenderBot v2.0) and their perception of how dialogs can be improved. There is no explicit mention of a specific section, table, figure, or unique element of the paper. The reviewer is making a general suggestion about exploring a new approach. Therefore, the review point does not identify a specific area in the paper that the authors need to address.", "verifiability_rationale": "The reviewer is suggesting that the authors could explore using BlenderBot v2.0 with incorporated knowledge and that this could improve dialogs by using domain ontologies from the SGD dataset. While the reviewer is not making a definitive claim that this will work, they are offering a suggestion that could be investigated. This can be considered 3 as the suggestion implies a potential area for further exploration and improvement. However, there is no concrete evidence or justification provided by the reviewer to support this claim. The suggestion is based on a general idea rather than a specific, verifiable statement.", "helpfulness_rationale": "The reviewer is offering a suggestion about exploring a new tool and its potential benefits for improving dialogs. While the suggestion is general and does not provide specific instructions on how to implement it, it is still a suggestion that could be valuable for the authors. It encourages them to think about future directions and potentially improve their work. Although it is not a direct solution to a specific problem, it can still be helpful in guiding their research and development. Therefore, the review point offers a suggestion that, while not immediately actionable, has the potential to be helpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point does not suggest any concrete actions or improvements for the authors. It criticizes the lack of information about the GPT4 evaluation process.", "grounding_specificity_rationale": "The review point does not specify which part of the paper or methodology it is referring to. It is a general critique about the evaluation process.", "verifiability_rationale": "The review point makes a claim about the lack of clarity in the GPT4 evaluation process but does not provide any evidence or reasoning to support this claim.", "helpfulness_rationale": "The review point is a critique of the evaluation process and does not offer any suggestions or insights that would be helpful for the authors of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer is asking for a definition and explanation of 'argwise consistency' and 'predwise consistency' (or 'accuracy'). They are also asking how these relate to 'label agreement'. The reviewer is suggesting that if the 'predwise consistency' is low, then the 'label agreement' for inconsistent predicates should also be low. This is a valid point. Actionability is high because the reviewer is directly addressing a potential source of confusion and providing a clear direction for the authors to understand the concepts.", "grounding_specificity_rationale": "The reviewer is not specifying a particular part of the paper they are referring to when discussing the confusion between consistency and accuracy. They are broadly mentioning these concepts. Grounding specificity is low because the reviewer does not identify a specific section, table, or figure where this confusion arises.", "verifiability_rationale": "The reviewer provides a clear and logical explanation of the concepts of 'argwise consistency', 'predwise consistency' (or 'accuracy'), and 'label agreement', and their relationship. The explanation is based on common knowledge in the field of natural language processing and machine learning. Verifiability is high because the information is clearly presented and logically sound.", "helpfulness_rationale": "The reviewer's point is 5 for the authors. By clarifying the difference between 'argwise consistency' and 'predwise consistency' (or 'accuracy'), and explaining how they relate to 'label agreement', the reviewer is providing valuable information that can help authors better understand and improve their models. The reviewer's suggestion that low 'predwise consistency' implies low 'label agreement' for inconsistent predicates is a key insight. Helpfulness is high because the information is directly relevant to improving model performance and addresses a potential source of confusion for authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'providing more details' as a suggestion for improvement. This directly points to a lack of explicit action. While the reviewer also suggests 'providing the code of their implementation' as a way to achieve reproducibility, this is presented as a solution rather than a direct action the authors should take to improve their draft. The suggestion to provide more details is a clear indication of an actionable point.", "grounding_specificity_rationale": "The reviewer mentions 'neural network parametrization of the reverse process' and 'how position embeddings are being provided' as areas where more details are needed. This points to a specific area within the paper. However, the reviewer does not explicitly state the exact section, table, or figure where this information is lacking, nor does it pinpoint the exact nature of the missing information (e.g., the specific type of position embedding or the implementation details). Therefore, while the reviewer identifies a specific area, the lack of precise grounding makes it somewhat underspecified.", "verifiability_rationale": "The reviewer states 'providing more details' as a suggestion for improvement. This can be considered a claim that the paper lacks sufficient detail in the area of 'neural network parametrization of the reverse process' and 'position embeddings'. The reviewer then suggests 'providing the code of their implementation' as a way to achieve reproducibility. While this provides some form of support, it is not directly linked to the specific mention of 'position embeddings'. The claim about the lack of detail is somewhat supported by the suggestion to provide code, but the connection could be clearer. Therefore, the claim is 3, as there is a potential link to support it, but the support is not fully explicit or directly tied to the mentioned area.", "helpfulness_rationale": "The reviewer's suggestion to 'provide more details on the neural network parametrization of the reverse process (in particular how position embeddings are being provided)' directly addresses a potential lack of clarity or understanding in the paper. This suggestion is explicitly aimed at improving the authors' draft. While the suggestion is general and lacks specific details, it is a clear and actionable feedback that directly targets a potential weakness in the paper's presentation. Therefore, the review point is 5 as it directly addresses a potential area for improvement in the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the first paragraph of section 3.3 contains a repeated paragraph. While it doesn't directly tell the author *how* to fix it, it clearly identifies the location and the nature of the problem, making it 3.", "grounding_specificity_rationale": "The comment explicitly mentions 'the first paragraph of section 3.3' and states that it contains a 'repeated paragraph'. This allows the author to precisely identify the section and the issue, making it 5.", "verifiability_rationale": "The comment itself doesn't contain a claim in the sense of an opinion or suggestion. However, it points to a specific instance of a potential problem ('a repeated paragraph') within a defined section. This provides a basis for the author to investigate and potentially find the duplicate content, making it 3 as it hints at a problem that can be verified.", "helpfulness_rationale": "The comment identifies a specific issue ('a repeated paragraph') within a defined section ('the first paragraph of section 3.3'). This provides the author with a clear location to investigate and potentially address the problem, making the review 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks a question about the sustainability of synthetic data, which can be interpreted as an implicit request for clarification or a suggestion for improvement. However, it doesn't provide a concrete action or solution. It's a question prompting further discussion rather than a direct instruction.", "grounding_specificity_rationale": "The reviewer asks a question about a general technique (synthetic data generation) and doesn't specify which part of a paper or concept they are referring to. They imply a concern for 'onthefly generation' but don't point to a specific section, table, or figure. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses. The specificity is also weak as the question is about a general concept (sustainability) rather than a specific issue within that concept.", "verifiability_rationale": "The review point is a question, not a declarative statement containing a claim. Therefore, it doesn't have verifiable content and scores 'X'.", "helpfulness_rationale": "The review point raises a valid concern about the potential limitations of synthetic data in a specific context ('onthefly generation'). This concern is worth addressing and can guide improvements. However, the review point itself doesn't offer any suggestions or solutions, making it 3 in identifying a problem but not in providing actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states: \"The authors should consider RNA abundance when building datasets.\" This is a clear, direct instruction on what the authors should do.", "grounding_specificity_rationale": "The review point mentions \"the challenge of RNA folding\" and \"building datasets.\" While it relates to the paper's topic, it doesn't explicitly pinpoint a specific section, table, or unique aspect of the paper being addressed. The suggestion to \"consider RNA abundance\" is also quite general.", "verifiability_rationale": "The review point contains the claim: \"the likelihood of alternative RNA structures arising are mostly dictated by biological circumstances, which the authors do not examine.\" This is a statement about a perceived limitation or area for improvement. However, the review point itself does *not* provide any evidence or references to support the claim that the authors *do not examine* biological circumstances. It's a statement of intent or a perceived gap, not a claim backed by evidence within the review itself.", "helpfulness_rationale": "The review point identifies a valid limitation (the lack of consideration for biological factors in the challenge of RNA folding) and suggests a concrete improvement (considering RNA abundance in dataset building). However, the suggestion is quite general and lacks specific details on how to implement this. While it points to a valuable area for improvement, the lack of concrete guidance makes it less helpful than a more specific suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the concern about the single entropic regularization coefficient (\u03b7=1200) and suggests an action: 'acknowledge this choice'. This is a clear and direct action that the authors can readily implement. The reviewer points to the potential weakness of this choice and suggests a course of action, making it 5.", "grounding_specificity_rationale": "The reviewer refers to 'the numerical results' in their review point. While they don't specify a particular section, table, or figure, the phrase 'the numerical results' clearly identifies a specific part of the paper being discussed. This indicates a degree of grounding, although not as precise as referring to a specific section or table by name. Therefore, it can be considered somewhat grounded.", "verifiability_rationale": "The reviewer makes a claim that 'this is a weak regularization term' based on the single coefficient used. However, they do not provide any specific evidence or reasoning within the review point to support this claim. The reviewer suggests it's 'suspicious' but doesn't offer a concrete reason why it's weak or how it might affect the results. Therefore, the claim is made without sufficient justification or supporting evidence within the review point itself. This makes it 3.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement: 'acknowledge this choice'. This is a direct and actionable piece of feedback that the authors can use to improve their draft. The reviewer identifies a potential weakness and offers a concrete direction for the authors to follow, making the review point 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a discrepancy between the paper's description of data sources and the information in Table 1 regarding the Vlachos and Riedel 2014 dataset. While the reviewer identifies the *specific* table and the *type* of missing information, they do not explicitly state what action the authors should take based on this discrepancy. The authors would need to investigate further to understand the reason for the missing evidence.", "grounding_specificity_rationale": "The reviewer explicitly identifies the 'Vlachos and Riedel 2014 dataset' in Table 1 and states that 'it has no Evidence'. They also mention that the paper states 'we also collected the sources used by the journalists in the analysis provided for the verdict. Common sources include tables with statistics and reports from governments, think tanks and other organisations, available online'. This clearly grounds the comment to a specific part of the paper and provides specific information about the missing evidence. The reviewer also points to the general description of data sources in the paper, further specifying the expected information.", "verifiability_rationale": "The reviewer states a fact: 'In Table 1, it is stated that the Vlachos and Riedel 2014 dataset has no Evidence, however in the paper it is stated that \u201cwe also collected the sources used by the journalists in the analysis provided for the verdict. Common sources include tables with statistics and reports from governments, think tanks and other organisations, available online\u201d'. This is a claim that requires verification. However, the reviewer does not provide any logical reasoning, external references, or examples to support this claim. The statement is presented as a factual observation without any justification.", "helpfulness_rationale": "The reviewer's comment highlights a potential issue in the dataset description provided in Table 1. While the information is factual, the reviewer points out a discrepancy with the general description of data sources in the paper. This could be helpful for the authors to be aware of a potential inconsistency. However, the reviewer does not provide any specific guidance or suggestions on how the authors should address this discrepancy. The comment is informative but lacks actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point asks for details about the simulation parameters used in the paper. While it implies that the authors are interested in understanding the specific simulator setup, it does not directly instruct or suggest any actions that the authors should take. The request is more about information gathering than active feedback or guidance.", "grounding_specificity_rationale": "The review point explicitly mentions 'simulator parameters,' which are directly relevant to the paper's methodology. The reviewer is pointing to a specific aspect of the paper and asking for details within that aspect. This demonstrates a clear understanding of where the information is needed.", "verifiability_rationale": "The review point does not contain a claim or assertion. It is a request for information rather than a critique or evaluation of the paper. Therefore, it does not meet the criteria for verifiability, which involves supporting a point with logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point asks for details about the simulation parameters used in the paper. This information is crucial for understanding the experimental setup and potentially reproducing the results. By asking for this information, the reviewer is hindering the authors' ability to improve their work, as they need to understand *how* the simulator was used to make meaningful suggestions. This is not helpful for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the potential weakness of the sparseCL and kNL masking loss for certain classes and identifies the hyperparameters $s$ and $k$ as crucial. They also suggest a concrete improvement by reducing the reliance on crossvalidation. The action is clearly identified and the method of improvement is stated.", "grounding_specificity_rationale": "The reviewer refers to specific components of the method, namely 'sparseCL', 'kNL', and the hyperparameters '$s$' and '$k$'. The suggestion to 'reduces' reliance on crossvalidation implicitly refers back to the initial empirical selection of these parameters. The reference to specific elements is strong, indicating full grounding. The suggestion to 'reduces' is also specific.", "verifiability_rationale": "The reviewer makes a claim about the importance of the hyperparameters $s$ and $k$ and suggests reducing reliance on crossvalidation. However, the reviewer does not provide any evidence or justification to support these claims. The reasoning is purely based on the reviewer's observation and suggestion for improvement without any supporting arguments or references.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the method and provides a suggestion for improvement. The suggestion is clear and actionable. However, the lack of verifiable evidence makes it difficult to assess the actual impact or effectiveness of the suggested change. The feedback is present but lacks the necessary supporting arguments to be fully convincing."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests an alternative technique (simulated annealing) and mentions a library (OpenTuner) which can adaptively use different search techniques. This provides a clear action for the authors to take, which is to compare optimization times with OpenTuner. The suggestion is direct and actionable.", "grounding_specificity_rationale": "The reviewer refers to 'OpenTuner' and 'simulated annealing' as the specific aspects of the paper being addressed. This is a clear identification of the relevant parts, and the suggestion to compare optimization times is specific to these identified components.", "verifiability_rationale": "The reviewer makes a claim suggesting that the optimization times should be compared with OpenTuner. They also suggest a method for doing this by using simulated annealing. This claim is verifiable as the authors can implement OpenTuner and compare the optimization times.", "helpfulness_rationale": "The reviewer provides a suggestion for improvement by proposing the use of simulated annealing and a comparison of optimization times with OpenTuner. This is a clear and actionable suggestion that directly addresses a potential area for improvement in the optimization strategy."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "3 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point criticizes the novelty of the approach but doesn't explicitly state what the authors should do to improve their work based on this criticism. The criticism itself is a statement of fact, not a direct instruction for action.", "grounding_specificity_rationale": "The reviewer states that 'there are many works have introduced diffusion model into anomaly detection area' without specifying which works or providing any examples within the review point itself. While the topic is specific, the lack of naming concrete examples makes the grounding less strong.", "verifiability_rationale": "The reviewer makes a claim about the novelty of the approach but doesn't provide any evidence, reasoning, or references to support this claim within the review point itself. The claim is presented as a statement of fact without justification.", "helpfulness_rationale": "The reviewer's point about limited novelty is a valuable piece of feedback that highlights a potential weakness in the paper's contribution. While it doesn't directly suggest improvements, it points out a crucial limitation for the reader."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The criticism about grammar errors is implicitly actionable as it points to a problem that needs fixing. However, it is vague as it doesn't specify which parts of the paper have errors or how these errors impact the understanding. The criticism about Figure 2's axes being unlabeled is explicitly actionable as it directly identifies a missing element that needs to be added. It is also specific as it points to a concrete issue with a specific figure.", "grounding_specificity_rationale": "The criticism about grammar errors cannot confidently identify which part of the paper has errors, making the grounding weak. However, the criticism about Figure 2's axes is explicitly mentioned by name ('axes'), making the grounding full. The criticism about parameterefficient KD is also explicitly mentioned by name ('approach'), making the grounding full. The criticism about the teacher's knowledge being friendly is not explicitly mentioned by name, making the grounding weak.", "verifiability_rationale": "The criticism about grammar errors is a subjective judgment and does not provide any verifiable evidence or reasoning. Therefore, it is 1. The criticism about Figure 2's axes being unlabeled is a factual statement and is fully verified as the axes are indeed missing. The criticism about parameterefficient KD is also a factual statement and is fully verified. The criticism about the teacher's knowledge being friendly is a subjective judgment and does not provide any verifiable evidence or reasoning. Therefore, it is 1.", "helpfulness_rationale": "The criticism about grammar errors is not very helpful as it is vague and doesn't provide specific suggestions. The criticism about Figure 2's axes being unlabeled is 5 as it directly identifies a concrete issue that needs to be addressed. The criticism about parameterefficient KD is also 5 as it points to a specific area that needs improvement. The criticism about the teacher's knowledge being friendly is not very helpful as it is a subjective judgment."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment suggests making the error analysis 'quantitive,' which is a concrete action the authors can take to improve the analysis.", "grounding_specificity_rationale": "The comment directly refers to 'error analysis in 5.2,' providing full grounding. The comment specifies what needs to be addressed (making it quantitive).", "verifiability_rationale": "The comment suggests making the analysis 'quantitive,' which could be seen as supporting the idea that the current analysis is lacking, though it lacks explicit external references or logical arguments within the comment itself.", "helpfulness_rationale": "The comment identifies a weakness ('error analysis in 5.2 is crappy') and offers a concrete suggestion ('more quantitive error analysis will help'). While it doesn't provide a specific reason *why* it's crappy, it guides the authors on how to improve it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests an alternative metric (ProxyA distance) to evaluate distribution alignment, which is a concrete action. It also implies a need to check the figures, which is a clear action to take.", "grounding_specificity_rationale": "The review point explicitly refers to 'Fig. 6c, 6d' and 'ProxyA distance', which are specific elements of the paper. It also clearly states the observation about the similarity of the figures.", "verifiability_rationale": "The review point contains a claim ('Fig. 6c, 6d seem to be exactly the same') but does not provide any supporting evidence or justification for this claim. There is no logical reasoning, common knowledge, or external references provided to back up this observation.", "helpfulness_rationale": "The review point raises a valid concern about relying solely on tSNE and suggests an alternative. This is a helpful point. However, the question about the similarity of figures 6c and 6d without further discussion or analysis makes the overall helpfulness somewhat limited."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point asks for the rationale behind a specific implementation choice (cross entropy for a subset of phrases) and the performance of an alternative approach (reinforcement algorithm). Both of these are direct requests for information that can help the authors understand and potentially improve their methodology. The reviewer is prompting the authors to explain *why* they chose cross entropy and to compare its performance with another method.", "grounding_specificity_rationale": "The reviewer refers to specific parts of the paper, such as the 'method' and the 'phrases' (P \u2013 floor(t/m)) and 'all phrases'. This provides some grounding. However, the reviewer is asking for the *rationale* behind the method's application to these specific phrases, which is not explicitly stated in the review point itself. Similarly, the performance of the alternative algorithm is not explicitly stated. The grounding is present but not fully explicit or complete.", "verifiability_rationale": "The review point makes claims about the rationale behind the use of cross entropy and the performance of the reinforcement algorithm without providing any supporting evidence or justification within the review point itself. The claims are presented as questions or statements that require the authors to infer or deduce information not explicitly stated in the review point.", "helpfulness_rationale": "The review point raises valid questions about the justification of a methodological choice and the performance of an alternative approach. These questions are relevant to the authors and could guide them in understanding their work better and potentially making improvements. The reviewer is prompting the authors to think critically about their methodology and consider alternatives."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the validation of the crossmodality adaptation in specific papers, making the action explicit. However, it lacks specific details on how the validation was performed, making it vague. Therefore, the action is explicitly stated but vague on how to execute it.", "grounding_specificity_rationale": "The comment explicitly mentions the specific papers (1 BEVDepth, 2 2DPASS) and states that the paper did not discuss them in related work. This clearly identifies the specific part of the paper being addressed, making the grounding 5.", "verifiability_rationale": "The comment contains a claim ('This paper did not discuss them in related work.') and states that the crossmodality adaptation has been validated in specific papers. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The claim is stated without justification.", "helpfulness_rationale": "The comment criticizes the paper's related work section by pointing out the absence of discussion about validated crossmodality adaptation methods. While it identifies a potential area for improvement, it does not offer concrete suggestions or actionable steps for the authors to take. It highlights a lack of information rather than providing direct guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing generation results (BLEU scores) in Table 1 and suggests including them. This is an explicit action that is also concrete, as the reviewer clearly identifies the specific metric to add. The reviewer directly informs the authors of a potential improvement.", "grounding_specificity_rationale": "The reviewer does not specify which part of the paper (e.g., which table or section) is being addressed when mentioning the missing generation results. The reference is general.", "verifiability_rationale": "The reviewer states that the paper only presents test loss and suggests including BLEU scores. This is a claim that is supported by the information provided. The reasoning is that including BLEU scores would provide a more comprehensive evaluation of the model's performance, especially regarding the quality of the generated output. This claim is verifiable by considering the purpose of different evaluation metrics.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the current evaluation (lack of generation metrics) and provides a concrete suggestion for improvement (including BLEU scores). This actionable feedback directly addresses a potential area for enhancement in the authors' work."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the *lack* of experiments and provides a clear direction for the authors to *add experiments* to validate the theoretical analysis, specifically for the discussions on different regimes. This is an explicit action that the authors can directly implement.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper (the 'theory paper' is a general description). Therefore, it cannot be grounded at all. It also does not specify what experiments should be conducted, making it not specific. The comment is about the *need* for experiments, not a specific section or detail within the paper.", "verifiability_rationale": "The comment is a suggestion or recommendation, not a claim that requires verification. It does not present a judgment, opinion, or assertion that needs supporting evidence. Therefore, it does not fall under the 'verifiability' aspect.", "helpfulness_rationale": "The comment directly addresses a clear weakness for the authors: the lack of experimental validation for their theoretical work. It provides a specific and actionable suggestion: *to conduct experiments to validate the analysis, especially for the discussions on different regimes*. This is a clear and helpful direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question but doesn't explicitly state what needs to be done or how.", "grounding_specificity_rationale": "The comment is a general suggestion and doesn't specify which part of the paper it relates to.", "verifiability_rationale": "The comment contains a suggestion but doesn't provide a clear reason or method for implementing it, nor does it cite any external references.", "helpfulness_rationale": "The review point is relevant and potentially insightful, but it lacks the specific details needed to be immediately actionable. It's a valuable suggestion but could be more concrete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing information: \"the Q function is w.r.t. \u03bc, which is the piece that makes Eq. 4 solve the _costrained_ optimization of Eq.\". This directly points out a lack of clarity regarding a specific mathematical detail. The reviewer is suggesting the authors should look for this detail in their description of advantageweighted regression. This is an explicit and concrete action to improve the draft.", "grounding_specificity_rationale": "The review point explicitly mentions \"advantageweighted regression\" and further specifies the missing detail as \"the Q function is w.r.t. \u03bc\". This clearly identifies the specific part of the paper and the specific element within that part that is lacking. The reviewer is not leaving any room for interpretation regarding where the information should be found. This is 5.", "verifiability_rationale": "The review point makes a claim: \"The description of advantageweighted regression misses a key piece...\". This is a verifiable statement. The reviewer then provides a specific reason for this claim: \"the Q function is w.r.t. \u03bc, which is the piece that makes Eq. 4 solve the _costrained_ optimization of Eq.\". This justification is based on the understanding of the underlying mathematical formulation and how the Qfunction's dependency on the policy (\u03bc) is crucial for the constrained optimization. This provides a clear logical reasoning for why the reviewer believes the description is lacking.", "helpfulness_rationale": "The review point is 5 because it directly identifies a specific and potentially confusing aspect of advantageweighted regression. By pinpointing the missing detail about the Qfunction being conditioned on \u03bc, the reviewer provides a concrete piece of information that the authors can use to improve their understanding and implementation of this method. This specific feedback is actionable and directly addresses a potential area of confusion, making it very helpful for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the multistage nature of the proposed method, which could be interpreted as an implicit suggestion that simpler methods might be preferable. However, the lack of explicit instructions on how to apply this feedback makes it difficult to act upon directly. The reviewer could have stated something like, 'Consider a singlestage approach like these existing methods,' to make the actionable.", "grounding_specificity_rationale": "The reviewer mentions 'many existing pruning methods' and 'multiple stages' without specifying which methods or detailing the exact nature of the multistage process. This lack of specificity makes it difficult for the authors to pinpoint the exact areas of improvement. The comment is vague and requires further clarification.", "verifiability_rationale": "The reviewer makes a claim about the proposed method's complexity compared to existing methods. While this is a reasonable observation, the reviewer doesn't provide direct evidence or examples to support this claim. The lack of specific references or logical reasoning makes it partially verifiable.", "helpfulness_rationale": "The reviewer raises a valid point about the tradeoff between complexity and simplicity. This highlights a potential area for improvement in the proposed method. While the reviewer doesn't offer concrete solutions, the feedback points to a relevant concern that could guide the authors' revision process. This feedback, even without specific solutions, is helpful in identifying areas for potential improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a disagreement with the change in the quantile function and asks for justification. This directly points to a potential weakness or area for improvement that the authors can address. The request for supporting data is a clear action the authors should undertake.", "grounding_specificity_rationale": "The reviewer refers to 'the new quantile function (3)' and 'the existing function (2)', clearly identifying the specific part of the paper being discussed. They also specify the change in multiplicative factors, further pinning down the exact issue. The reference to 'justification' and 'supporting data' implies a specific element within the paper that needs clarification.", "verifiability_rationale": "The reviewer makes a claim that the change is 'unjustified' and asks for 'supporting data'. However, within this review point itself, there is no evidence provided to support this claim. The reviewer is stating an opinion without backing it up within the text of this review.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the paper by questioning the justification for a new quantile function. They also suggest an improvement by asking for supporting data. This directly addresses a need for the authors to clarify or strengthen a specific aspect of their work."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'Figure 3 is confusing, please improve' and questions the 'contribution over SWEBench'. These are direct actions or suggestions for improvement. The reviewer is asking the authors to address a specific issue (Figure 3 being confusing) and to evaluate their contribution relative to an existing benchmark. These actions are clear and directly address potential weaknesses or areas for improvement in the authors' work.", "grounding_specificity_rationale": "The reviewer does not specify which part of the paper Figure 3 refers to. They are making a general statement about its confusion. The reviewer also critiques the contribution without explicitly linking the fault localization and LLM aspects to a specific section or table in the paper. They are making general claims about these aspects without pointing to a specific part of the paper they are referring to.", "verifiability_rationale": "The reviewer's arguments about fault localization and LLMs are based on logical reasoning and common knowledge in software engineering. They are not presenting a claim that requires external evidence or references. The statements are wellsupported by logical reasoning and common practices in the field.", "helpfulness_rationale": "The review point is constructive and directly asks the authors to improve Figure 3 and to evaluate their contribution. The reviewer provides specific points of critique (fault localization and LLMs) that the authors can address. The request for improvement is clear and actionable."}
{"actionability_label": "4", "grounding_specificity_label": "Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer is asking a question about the methodology for selecting topics for a complementary attribute in topic control experiments. While they don't explicitly state an action, they imply a need for clarification on how this selection process works, which can be interpreted as an implicit action. The request for 'guidelines' suggests a desire for concrete information.", "grounding_specificity_rationale": "The reviewer's question is quite specific, focusing on the process of selecting topics for a complementary attribute within the context of topic control experiments and a defined number of topics. This strong specificity suggests the comment is grounded in a particular aspect of the methodology.", "verifiability_rationale": "The reviewer is pointing out a missing element in the methodology rather than making a claim that can be verified. They are highlighting a gap in their understanding or documentation, but they are not providing evidence or references to support their point.", "helpfulness_rationale": "The reviewer's comment highlights a missing and important detail in the methodology. While it doesn't directly tell the authors what to do, it points to a gap in their understanding or documentation. This makes it helpful in identifying a missing piece, even if it doesn't provide a solution directly."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states the problem of a single realworld manipulation case and implies a lack of evidence for generalizability, indicating an explicit action to consider this issue.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'realworld manipulation' and then specifically refers to 'a single case', demonstrating strong grounding. They also mention the 'described system identification method' and its 'improvement simtoreal policy deployment', further grounding the discussion in specific technical aspects.", "verifiability_rationale": "The reviewer makes a claim ('It is not convincing...') but does not provide any supporting evidence or justification within this review point. They are stating an opinion without logical reasoning, common knowledge, or external references in this specific instance.", "helpfulness_rationale": "The reviewer raises a valid concern about the limited evidence supporting the generalizability of the system identification method. This points out a potential weakness and encourages the authors to consider the limitations of their approach. However, the reviewer does not provide specific examples or detailed reasoning to fully address the authors' needs."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer raises a concern about the quality of ShortcutQA edits and asks for clarification on 'answerable'. While the reviewer implies an action (improving the draft based on ShortcutQA), they do not explicitly state the action or how to implement it. The vagueness makes it difficult to assess the actionability of the review point.", "grounding_specificity_rationale": "The reviewer mentions 'ShortcutQA' and 'edits' but does not specify which part of the paper or analysis this refers to. The question about 'answerable' is also general. Therefore, the grounding of the review point is weak.", "verifiability_rationale": "The reviewer expresses skepticism about the quality of ShortcutQA edits but does not provide any evidence or justification for this belief within the review point itself. Therefore, the verifiability of the review point is 1 based on the information provided.", "helpfulness_rationale": "The reviewer raises concerns about the quality of ShortcutQA and asks for details and examples. While these are valuable, they point to a potential issue rather than directly suggesting a concrete improvement to the draft. Therefore, the helpfulness of the review point is 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a desire for clarity and provides a clear, specific action: adding a 'forward pointer' to the 'definition of deep'. This is a direct and actionable suggestion, making it 5.", "grounding_specificity_rationale": "The comment refers to 'the definition of deep,' which implies a specific part of the paper related to that concept. While it doesn't pinpoint a section or table, the reference is specific enough to be considered grounded. The comment also specifies the suggestion: adding a forward pointer. Therefore, it is somewhat specific as it identifies the area and the type of improvement.", "verifiability_rationale": "The comment does not contain a claim. It is a suggestion for improvement. Therefore, it falls under the 'X' category.", "helpfulness_rationale": "The comment identifies a potential area for improvement (lack of clarity) and provides a specific suggestion (adding a forward pointer). This is a direct and actionable piece of feedback that is likely to be helpful for the author."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point is a question posed to the authors, asking about the possibility of model selection for determining the optimal number of archetypes (k) within the presented framework. While this question prompts the authors to consider a practical aspect of the framework, it does not directly instruct them on how to perform this model selection. Therefore, the review point lacks explicit action or guidance on how to apply the concept. The authors are not being asked to identify an action or provide a solution, but rather to acknowledge the existence of a potential action.", "grounding_specificity_rationale": "The review point directly addresses a core parameter of the framework, 'k', which represents the number of archetypes. The reviewer is asking about model selection for this parameter within the *specific framework presented*. This demonstrates an attempt to understand how the framework handles a crucial parameter. The authors can identify the specific part of the framework being addressed (the model selection process for 'k'). Therefore, the review point is grounded in the specific framework being discussed. However, it doesn't explicitly state *how* to perform model selection within this framework, making it underspecific.", "verifiability_rationale": "The review point asks a question about a practical aspect of the framework (model selection for 'k'). While the authors can infer that model selection is a relevant concept for determining 'k', the review point itself doesn't explicitly state *which* model selection techniques are applicable or *how* to implement them within the framework. The verifiability of this point depends on the authors' prior knowledge of model selection techniques and their ability to apply them to the framework. The point is not a direct claim requiring justification, but rather a question prompting the authors to consider a practical implication. Therefore, the verifiability is somewhat implicit.", "helpfulness_rationale": "The review point directly addresses a practical concern for the authors using the framework. The reviewer is asking about a common and important parameter ('k') and its selection process. This is a clear request for information that could potentially improve the authors' understanding and usage of the framework. While the point itself doesn't provide a solution, it points to a practical area where the authors might need assistance. Therefore, the review point is 3 in identifying a need for improvement or clarification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly asks 'Where is Theorem 1?' This is a direct and clear instruction for the author to locate a specific element. The action is not inferred and is very concrete: 'Look for Theorem 1'.", "grounding_specificity_rationale": "The reviewer asks 'Where is Theorem 1?' and specifies the location as 'at the beginning of page 6'. This clearly identifies the specific part of the paper being referred to. The author can easily identify the section and then look for the theorem within it.", "verifiability_rationale": "The reviewer states a fact: 'At the beginning of page 6 you directly have Theorem 2 but there are no Theorem 1.' This is a claim that can be verified by checking the specified location. While it doesn't provide external references, the absence of Theorem 1 is a verifiable fact within the paper itself.", "helpfulness_rationale": "The reviewer points out the *absence* of Theorem 1. While this is a factual observation and identifies a potential issue, it doesn't provide any specific guidance or suggestions on how the author should address this missing theorem. The reviewer doesn't ask 'How should I add Theorem 1?' They only ask where it is. Therefore, the feedback is limited to identifying a problem without offering a solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states an assumption about the existence of a short, informative subsequence for long document summarization. While they don't explicitly demand a fix, the statement itself is a clear claim that can be acted upon. The reviewer is pointing out a potential limitation of Transformer models in this context.", "grounding_specificity_rationale": "The reviewer's point is about the generalizability of an assumption across different tasks and model limitations. They don't specify which part of the paper this assumption pertains to, nor do they detail what might be missing or insufficient. The reference to 'within a longer text' and 'subsequence shorter than the length limit of pretrained Transformers' is general and doesn't target a specific element of the paper.", "verifiability_rationale": "The reviewer raises a concern about the assumption's generalizability, suggesting it might not hold for long document summarization. However, they do not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a question and a potential limitation, lacking evidence.", "helpfulness_rationale": "The reviewer's point is valuable in highlighting a potential limitation of Transformer models in the context of long document summarization. By questioning the assumption, they are providing feedback that could guide further research or improvements in model design. However, they do not offer a concrete solution or alternative approach, making the feedback somewhat limited in its immediate helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides an explicit suggestion by pointing out a lack of clarity and asking a specific question about generating multiple graphs. While the suggestion itself isn't a direct instruction on what to do, it clearly indicates an area needing improvement and a request for more detail. The question directly addresses a potential implementation issue, making it somewhat concrete.", "grounding_specificity_rationale": "The reviewer refers to 'line 180' and asks a specific question about 'multiple different graphs'. This indicates that the reviewer has identified a specific part of the paper and is pointing out a lack of clarity within that part. However, the reviewer does not explicitly state how to generate these graphs or provide a detailed explanation of their creation. Therefore, while the reviewer has some grounding in the specific line and the problem of unclear graphs, they do not fully specify the method of generation.", "verifiability_rationale": "The reviewer makes a claim by stating 'some parts are not clear to me' and then poses a question to seek clarification on how multiple graphs are generated. This constitutes a claim that needs to be supported. The reviewer's request for clarification implies a need for logical reasoning or external references to understand the graph generation process. While the request itself acts as the justification, it lacks immediate concrete examples or explicit references.", "helpfulness_rationale": "The reviewer's comment is directly addressing a perceived weakness in the paper and actively seeks clarification on a specific point. By asking a question, they are providing a concrete suggestion for improvement and are trying to resolve an ambiguity. This type of feedback is generally helpful as it points to a specific area needing attention and encourages the author to provide more detail."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the experiments are 'limited in scope' and provides specific examples of the experiments and the manifolds used. While the reviewer doesn't directly suggest an *action* on how to improve the experiments, they imply a need for more complex experimentation. The criticism is clear and points to a specific area for improvement.", "grounding_specificity_rationale": "The reviewer specifically mentions 'the experiments,' 'the two simulation experiments,' 'the unit sphere,' and 'spiral curves.' This demonstrates strong grounding as the reviewer accurately identifies the specific parts of the paper being addressed. The reviewer also specifies the *nature* of the manifolds used, further enhancing the grounding.", "verifiability_rationale": "The reviewer makes a claim that the experiments are 'limited in scope' and that the unit sphere is a 'special case' due to its geometry. However, the reviewer does not provide external references or logical reasoning to *justify* why these experiments are limited or why a more complex manifold would be beneficial. The justification is implicit, relying on the reviewer's assessment of the complexity and learnability of the unit sphere.", "helpfulness_rationale": "The reviewer provides specific examples of the experiments and clearly articulates the limitations in their scope and complexity. This makes the criticism relatively easy to understand and identify within the paper. However, the criticism is primarily about the *lack* of complexity, which is a valid point, but it doesn't directly *teach* the authors *how* to design better experiments. It points to a direction for improvement, but doesn't offer a concrete, actionable solution within the review itself."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential weakness ('lack of naturalness' and 'not fully using the huge ability of the LLM') but does not explicitly state how to improve the template or suggest specific changes. While it points to an area for improvement, the action is not directly stated or concrete.", "grounding_specificity_rationale": "The comment refers to 'current knowledge' and 'specific template' but does not explicitly identify a specific section, table, figure, or unique element of the paper where the issue lies. The grounding is weak because the exact location of the problem is not pinpointed.", "verifiability_rationale": "The comment contains a claim ('obvious weakness') but does not provide any supporting evidence or justification for this claim. It lacks logical reasoning, common knowledge, or external references to back up the assertion.", "helpfulness_rationale": "The comment identifies a potential area for improvement ('lack of naturalness' and 'not fully using the huge ability of the LLM') but does not provide any specific guidance or suggestions on how to achieve this. The feedback is a statement of a problem without offering concrete steps for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue ('the number of baselines is a bit small') and suggests a consequence ('which degrades its universality and generality'). This is an explicit statement identifying a specific aspect of the paper (number of baselines) and provides a clear direction for improvement. While it doesn't specify *how* to increase the number of baselines, it clearly points to a concrete weakness.", "grounding_specificity_rationale": "The reviewer mentions 'baselines' generally, without explicitly pointing to a specific section, table, or figure. While the term 'baselines' is common, the reviewer doesn't provide a precise reference point. Therefore, the grounding is weak. However, the reviewer does specify the *impact* of the small number of baselines ('degrades its universality and generality'), making the specificity somewhat clear.", "verifiability_rationale": "The reviewer makes a claim about the number of baselines and its potential negative impact. However, they do not provide any specific evidence, reasoning, or references to support this claim. The statement is presented as a deduction or observation without justification. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer identifies a valid concern regarding the number of baselines and its potential limitations. By pointing out this issue, the reviewer provides the authors with a clear direction for improvement. While the comment doesn't offer specific suggestions for increasing the number of baselines, it does highlight a concrete weakness that needs addressing. Therefore, it is helpful but not overly detailed."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing information: 'the mixture of corpus size used, or software stack which is known to matter in practice'. This directly identifies what needs to be known, making the action clear and actionable. The reviewer also suggests a concrete improvement: 'informing the authors about the specific corpus sizes and software stacks used in their tokenizer training.' This indicates a direct action the authors can take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'tokenizer training information' and further narrows it down to 'corpus size' and 'software stack'. This demonstrates a clear identification of the specific part of the paper being addressed, making the grounding very strong. The reviewer also specifies what is missing within that area, further enhancing specificity.", "verifiability_rationale": "The reviewer makes a claim: 'There\u2019s no information about the tokenizer training either...'. This is a clear statement of a problem. The reviewer then suggests a logical next step: 'informing the authors about the specific corpus sizes and software stacks used in their tokenizer training.' While this doesn't provide a citation, it's a reasonable suggestion based on general knowledge of tokenizer training, making it 3.", "helpfulness_rationale": "The reviewer directly suggests a concrete action for the authors: 'informing the authors about the specific corpus sizes and software stacks used in their tokenizer training.' This is a clear and actionable piece of feedback that directly addresses a potential issue in the authors' work."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "5 (5)", "verifiability_label": "1 (1)", "helpfulness_label": "5 (5)", "actionability_rationale": "The reviewer asks a direct question about the necessity of the proposed method's components compared to prior work. While they don't explicitly state an action the authors should take, they clearly identify a gap in the justification for the added complexity. The question is specific and actionable in the sense that it prompts the authors to provide a clearer rationale.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'A' and asks a question directly related to the proposed method's components (cotraining, positive mining, alternate optimization). This clearly grounds the comment in the specific paper and the method being discussed. The question is also specific about the contribution over prior work.", "verifiability_rationale": "The reviewer asks a question about the necessity of the method's components without providing explicit justification or references within the review point itself. The question implies a lack of clear reasoning or supporting evidence for the added complexity.", "helpfulness_rationale": "The reviewer's question directly addresses a potential weakness in the justification of the proposed method. It probes whether the added complexity is truly necessary, which is a crucial question for the authors to answer. A good justification would provide evidence or reasoning for why these steps are important."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The review points out a potential issue (computational cost) but lacks specific guidance on how to address it, making it only partially actionable.", "grounding_specificity_rationale": "The review discusses general aspects of the approach (scalability, realworld applications) without pinpointing a specific part of the paper being affected, making it 1.", "verifiability_rationale": "The review contains a claim about the potential limitations of the approach but doesn't provide any evidence or justification for it, making it 1.", "helpfulness_rationale": "The review identifies a potential problem but offers no solutions or suggestions, making it not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer disagrees with the authors' claim about the prevalence of nonuniform label noise. While the reviewer provides a specific example (Clothing1M) and a citation to support their claim that nonuniform label noise is not uncommon in practice, the action the reviewer implies is not explicitly stated. The reviewer suggests the authors should acknowledge this, but the exact action or change needed is not specified. Therefore, it is 2 as the action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer mentions 'nonuniform label noise' and points to the Clothing1M dataset as evidence. This indicates a degree of grounding as the specific part of the paper (or a related concept) is identified. However, the reviewer does not explicitly state how nonuniform label noise in Clothing1M relates to the authors' specific work or the type of nonuniform noise they are considering. The grounding is weak because the connection to the authors' context is not clearly established.", "verifiability_rationale": "The reviewer presents a claim: 'nonuniform label noise is not too common in practice' (disagreement with the authors). This claim is supported by the reference to the Clothing1M dataset and the cited paper. The evidence provided is logical and based on external references. The reviewer explicitly mentions a specific dataset and a source, making the grounding clear. The claim is also specific in stating that nonuniform label noise is not too common. Therefore, the verifiability is 5 as the claim is supported by clear and robust evidence.", "helpfulness_rationale": "The reviewer disagrees with the authors' claim about the prevalence of nonuniform label noise and provides a specific example (Clothing1M) and a citation to support their view. This raises a valid point about the authors' assumption and encourages them to consider a broader range of noise types or validate their assumption. While the reviewer does not explicitly suggest a concrete change, the disagreement and the evidence provided make the review point helpful in highlighting a potential inconsistency or limitation in the authors' perspective. The helpfulness is moderate as it points out a potential issue without directly guiding the authors to a solution."}
{"actionability_label": "2", "grounding_specificity_label": "1 and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The statement is implicit in the sense that it points out a potential limitation (small sample size) that could affect the reliability of the findings. It doesn't directly tell the authors what to do. However, it is vague and lacks detail on how to apply it. The authors would need to consider the implications of the small sample size and potentially replicate the study with a larger sample to address this issue.", "grounding_specificity_rationale": "The reviewer is referring to the 'evaluation' as a whole, not a specific part of the paper. They are stating a fact about the number of samples used in the evaluation. There is no specific section, table, or unique element being addressed. The comment is about the evaluation process, not a specific part of the paper.", "verifiability_rationale": "The statement is a factual observation about the sample size used in the evaluation. It doesn't present a claim that requires verification or justification. The information is directly stated, and there are no external references or logical reasoning needed to accept it.", "helpfulness_rationale": "The reviewer is pointing out a potential weakness in the methodology (small sample size) that could affect the reliability of the findings. This is a valuable point for the authors to consider. It encourages them to be aware of the limitations of their study and potentially replicate with a larger sample to strengthen the validity of their results. While it doesn't directly tell them how to fix the issue, it highlights a potential problem that needs addressing."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The reviewer points out a potential limitation of the method being tailored to similar MILP tasks, which implies a need for action (to consider different problem types), but the action isn't explicitly stated.", "grounding_specificity_rationale": "The reviewer explicitly names the area of concern: the applicability of the method to 'significantly different combinatorial optimization problems,' which is a specific aspect of the paper.", "verifiability_rationale": "The reviewer expresses a concern about the method's generalizability but doesn't present a specific claim that requires verification. It's a suggestion for further consideration rather than a declarative statement with supporting evidence.", "helpfulness_rationale": "The reviewer identifies a potential limitation of the method but doesn't provide any specific suggestions or actions for the authors to take. It's a critique of the method's scope without offering concrete improvements."}
{"actionability_label": "4", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their intention to understand the 'Rerank and Adv' baselines, indicating a clear and direct action. Once this action is identified, the reviewer also asks specific questions about their relevance to InterFair and their competitiveness, providing concrete details on how to apply the suggested understanding.", "grounding_specificity_rationale": "The reviewer identifies a lack of clarity regarding the 'Rerank and Adv' baselines in the Results section. While they mention the 'brief description,' they do not pinpoint specific sections or elements within that description that are unclear. The reviewer's questions about the connection to InterFair and competitiveness are general and do not specify which parts of the description require justification or examples. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part. The specificity is also underspecific as the reviewer does not clearly detail what is wrong or missing in these baselines.", "verifiability_rationale": "The reviewer makes a claim that the authors 'try to gap this bridge' in the Results section, L256261, which can be verified. They also ask about the competitiveness of these baselines, which is another verifiable claim. However, the claim about 'gapping the bridge' is vague and lacks specific justification or examples. The competitiveness is also a general statement without supporting evidence or references. Therefore, the verifiability is somewhat lacking in depth and specificity.", "helpfulness_rationale": "The reviewer's statement directly indicates helpfulness. They are pointing out a gap in the information provided regarding the 'Rerank and Adv' baselines. By highlighting the lack of clarity and the need for better explanation, the reviewer is providing actionable feedback that could help the authors improve their draft. The questions about the connection to InterFair and competitiveness are also directly aimed at improving the authors' understanding."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement explicitly names the comparison to 'baselines' and mentions the metrics 'cycle counting' and 'ZINC'. This indicates an explicit action or suggestion: to improve the comparison to these baselines on these metrics. While it doesn't specify *how* to improve the comparison, it clearly identifies the area for improvement. Therefore, it is considered explicit but somewhat concrete as it points to a specific area needing attention.", "grounding_specificity_rationale": "The statement mentions 'baselines,' 'cycle counting,' and 'ZINC,' which are specific elements of the paper. However, it doesn't explicitly identify *which* baseline is being referred to, nor does it specify *how* the comparison is being performed. The grounding is weak because the authors can only make an educated guess about the specific baselines and metrics involved. The specificity is also underspecified as it doesn't detail the nature of the insufficiency.", "verifiability_rationale": "The statement makes a claim: 'The comparison to other baselines on cycle counting and ZINC is insufficient.' However, it does not provide any justification or evidence to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the comparison is indeed insufficient. Therefore, the verifiability is 1 as there is no supporting evidence.", "helpfulness_rationale": "The statement points out a potential weakness in the experimental evaluation by highlighting the 'insufficient' comparison to baselines on specific metrics. This directly informs the authors to revisit their experimental design and analysis for these aspects. While it doesn't provide specific *how* to improve the comparison, it identifies a gap in their evaluation, making it 3 in guiding further investigation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the need for an explanation regarding the effectiveness of a specific combination of mask snippets compared to most similar ones. This is a direct and clear request for information, making it 5. The reviewer identifies the specific aspect of the method (the mask combination) and the comparison (most similar ones) they are interested in, indicating a strong understanding of the relevant parts of the paper and a clear action to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'a specific combination of mask snippets' and 'most similar ones', indicating a clear identification of the specific parts of the paper being referred to. This demonstrates strong grounding as the reviewer can accurately pinpoint the sections being discussed. Furthermore, the reviewer asks 'why' this specific combination is effective, which requires a detailed explanation of the differences and the underlying reasons for its effectiveness, adding to the specificity of the request.", "verifiability_rationale": "The reviewer states that the paper 'would benefit from a clear explanation'. This can be interpreted as a claim that the current explanation is lacking or insufficient. However, the reviewer does not provide any specific examples, references, or logical reasoning to support this claim. There is no evidence that the reviewer has conducted any investigation or has a specific idea of how to improve the explanation. Therefore, the verifiability is low as there is no justification for the claim that the paper needs a better explanation.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the paper (the lack of explanation for the effectiveness of a specific mask combination) and suggests that the paper would benefit from addressing this. This indicates a genuine concern and a desire for improvement. However, the reviewer does not offer any specific suggestions or insights on how to address this weakness. The request is vague and lacks actionable advice. Therefore, the helpfulness is low as the reviewer identifies a problem but does not provide any concrete solutions or guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state any actions or suggest concrete modifications to the SLQ method. While it identifies a weakness ('limited competitiveness'), it doesn't provide specific steps on how to address it or improve the method. The language is more about stating the performance difference.", "grounding_specificity_rationale": "The review point does not explicitly refer to specific sections, tables, figures, or unique aspects of the paper being reviewed. It refers to 'SLQ,' 'CRD method,' 'F1 score,' 'conductance values,' 'Figure 3,' and 'Figure 4' in a general way. While these terms are specific, the reviewer doesn't pinpoint the exact location or detail within the paper that is causing the performance issue.", "verifiability_rationale": "The review point makes claims about the performance of SLQ compared to CRD and ACL. It attempts to verify these claims by referencing 'Figure 3' and 'Figure 4' and mentioning the 'F1 score and conductance values'. However, it lacks detailed explanations or specific references to external works to support these claims. The reasoning is present but could be more robust with concrete evidence.", "helpfulness_rationale": "The review point identifies a weakness ('limited competitiveness') in the SLQ method. It provides some context by mentioning 'F1 score and conductance values' and comparing it to 'CRD' and 'ACL'. It also points to 'Figure 3' and 'Figure 4' as evidence. However, it does not offer concrete, actionable suggestions for improving the SLQ method or explain *why* it might be less competitive. The review is more about pointing out a problem than suggesting a solution."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states: 'the selection of baselines is very limited to naive/old models.' This comment identifies a weakness in the experimental setup but does not provide explicit instructions or concrete details on how the authors should improve their draft based on this observation. The reviewer points out the lack of specific information about the nature of the 'naive/old models' and how they relate to the authors' work, failing to offer actionable steps for the authors to take.", "grounding_specificity_rationale": "The review point mentions 'naive/old models' but does not explicitly identify the specific part of the paper where these models are being used or evaluated. It also does not specify what is lacking in these models (e.g., specific theoretical components, experimental design choices, evaluation metrics). The reviewer's statement is general and does not pinpoint the exact area or issue within the paper related to the baselines.", "verifiability_rationale": "The review point contains a claim: 'the selection of baselines is very limited to naive/old models.' However, it does not provide any supporting evidence or justification for this claim within the review itself. The reviewer does not cite specific examples of why these baselines are naive or old, nor does it offer references to support this assertion. The claim is presented without sufficient backing or explanation.", "helpfulness_rationale": "The review point identifies a valid concern regarding the limited selection of baselines and suggests adding more 'naive/old models' for robust performance comparisons. However, this suggestion is general and lacks specific guidance on how the authors should go about adding these baselines. The reviewer does not provide concrete steps or criteria for selecting the new baselines, nor does it explain how this addition will lead to significant improvements in the authors' work. The suggestion is vague and lacks actionable details."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that the choice of target structures is 'unclear' and raises the question of whether the method can be generalized. While the reviewer implies an action of investigating other structures, the comment does not explicitly state what needs to be done or how to apply this action. The action is implied but not directly requested.", "grounding_specificity_rationale": "The reviewer mentions 'other target structures' but does not explicitly identify which structures or why they are important. The grounding is weak as the authors cannot confidently determine which part the comment addresses. However, the comment does specify what needs to be addressed in this part (investigating other structures). The specificity is low as the reviewer doesn't provide details on how to investigate or what to expect.", "verifiability_rationale": "The reviewer makes a claim that the choice of target structures is 'unclear' and raises a question about generalizability. This claim is not supported by any logical reasoning, common knowledge, or external references within the review point itself. The reasoning is based on the lack of justification for the limited scope. There are no external references provided to support this claim.", "helpfulness_rationale": "The review point does not provide any actionable feedback or justification for the lack of broader experimentation. The reviewer raises a question about generalizability but does not instruct the authors on how to address it. The comment is more of a concern or a point for further discussion rather than a direct instruction or suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the limitation of the knapsack problem scope and suggests medical diagnosis as a more realistic alternative. This directly points to a specific area for improvement.", "grounding_specificity_rationale": "The reviewer discusses the limitations and suggestions at a high level, without specifying which section or aspect of the paper is lacking.", "verifiability_rationale": "The reviewer makes a claim about the limited application scope but doesn't provide any evidence or logical reasoning to support this claim.", "helpfulness_rationale": "The reviewer identifies a potential future research direction but lacks specific, actionable feedback on how to improve the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out specific weaknesses in the method's performance, particularly in terms of robustness and sensitivity, and provides evidence from Figure 3. While the reviewer identifies areas for improvement, the suggestions are somewhat general. For example, the reviewer states, 'the method does not seem to improve on the robustness and sensitivity,' which is a clear indication of a lack of improvement. However, the reviewer doesn't explicitly state *how* the method fails to improve these aspects, making the actionable suggestion somewhat vague. The reference to Figure 3 highlights the reviewer's awareness of specific results, but the lack of detailed guidance on how to address these issues makes the overall actionable feedback somewhat limited.", "grounding_specificity_rationale": "The reviewer mentions 'fig 3' as a point of reference, which provides some level of grounding by identifying a specific figure in the paper. However, the reviewer does not explicitly state which part of Figure 3 is problematic. The statement, 'the method does not seem to improve on the robustness and sensitivity as claimed in the motivation of using evolutionary methods in the first place,' is a general critique of the method's performance without pinpointing the exact issue within Figure 3. Therefore, while the reviewer implicitly refers to a specific part of the paper, they do not clearly identify the problematic section, table, figure, or unique aspect. This lack of specificity makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer makes a claim about the method's performance not aligning with the stated motivation, specifically regarding robustness and sensitivity. This claim is supported by the reference to Figure 3 and the observation about the method being 'noisier' in certain domains. The reviewer provides some supporting evidence by pointing to specific results in the figure. However, the verifiability could be improved by providing more explicit reasoning or references to external works that support the claim about the method's limitations in robustness and sensitivity. While the mention of Figure 3 provides a basis for verification, the lack of detailed explanation or citations weakens the overall verifiability.", "helpfulness_rationale": "The reviewer provides a direct critique of the method's performance, stating that it does not improve on robustness and sensitivity as claimed. This is a clear and helpful statement that identifies a potential weakness in the method. The reviewer also points to specific results in Figure 3, which provides concrete evidence to support their claim. While the critique is valid, it could be more helpful by offering specific suggestions for improvement based on the observations in Figure 3. As it stands, the reviewer provides a valid point of criticism, making it 3."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "1 (1)", "verifiability_label": "1 (1)", "helpfulness_label": "2 (2)", "actionability_rationale": "The review point asks a question, not a directive, and does not specify an action for the authors to take.", "grounding_specificity_rationale": "The review point refers to 'more sophisticated or more aggressive removal methods' without specifying which part of the paper or method is being discussed, indicating a lack of specific grounding.", "verifiability_rationale": "The review point is a question, not a declarative statement containing a claim that needs verification.", "helpfulness_rationale": "The review point is a question prompting further investigation, but it does not directly identify a weakness or suggest a specific improvement for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a factual error in the paper's description of the topic and suggests a relevant area of research. While the reviewer states a fact ('the topic of the paper is interpretable methods') and suggests a connection ('explainable AI'), the action is not explicitly stated. The reviewer doesn't directly tell the authors what to do or how to fix the issue. The suggestion is more of a pointer than a direct action.", "grounding_specificity_rationale": "The reviewer makes a general statement about the paper's topic and suggests a related field. They do not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The reviewer mentions the topic of the paper ('interpretable methods') but does not specify what part of the paper this refers to. The reviewer also does not provide specific examples of work in this area.", "verifiability_rationale": "The reviewer makes a claim about the paper's content ('the topic of the paper is interpretable methods') and suggests a related concept ('explainable AI'). This is a claim that needs to be verified. However, the reviewer does not provide any evidence or justification for this claim. The connection between the two terms is generally understood in the field, but the reviewer is highlighting a potential point of confusion for the authors. There is no logical reasoning, common knowledge, or external references provided to support this claim.", "helpfulness_rationale": "The reviewer points out a factual error in the paper's description of the topic and suggests a relevant area of research. While the reviewer's point is likely to be helpful for the authors in understanding the relationship between explainable AI and interpretability, the feedback is somewhat vague. The reviewer does not provide specific details about what is incorrect or what specific work should be cited. The suggestion is more of a pointer than a direct action or a clear recommendation for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer is asking for information about the training data used in experiments. While the *purpose* of the experiments is implied, the *specific data* is not explicitly stated. The reviewer is essentially prompting the authors to locate this information within the paper, which requires them to actively search and identify the relevant section. This makes it 3 but not entirely concrete as the specific dataset is missing.", "grounding_specificity_rationale": "The reviewer is asking for details about the experiments and the data used. This implies referencing specific sections, tables, or even unique elements within those sections of the paper. Therefore, the information is grounded. However, the request is quite general and does not specify *which* experiments or *what* kind of data. This lack of specificity makes it only weakly grounded.", "verifiability_rationale": "The reviewer is asking a question about the training data. This is a request for information, not a statement that needs to be verified or supported by evidence. Therefore, it does not contain a claim that requires verifiability.", "helpfulness_rationale": "The reviewer is asking for information about the training data used in experiments. While this information is likely relevant to understanding the results and potentially improving the model, the request itself does not directly guide the authors on how to use or modify the draft based on this information. It's a question rather than a suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of clarity regarding 'parts thereof' in the captions, indicating an implicit action (understanding the need for clarity) but a lack of explicit guidance. While they identify a potential area for improvement (clarity in captions), the lack of specificity makes it difficult to pinpoint actionable steps. The reviewer doesn't *immediately* suggest what to do.", "grounding_specificity_rationale": "The reviewer mentions 'captions but also parts thereof' which, while not explicitly naming a section, points to a general area within the caption format. This can be considered 'weak grounding' as they can infer the issue relates to caption elements. However, the reviewer doesn't provide a specific example of which 'part thereof' is unclear, nor does they specify *why* the argument about filling in blanks being 'hard' is 'unconvincing'.", "verifiability_rationale": "The reviewer makes a claim that 'Not clear what we mean by not only the complete captions but also parts thereof' and 'generally argument around why filling in the blanks is hard is unconvincing here.' This is a claim that requires verification. The reviewer doesn't provide any external references or logical reasoning to support their claim about the unconvincing argument. The statement is based on their perception of the lack of justification.", "helpfulness_rationale": "The reviewer identifies a potential issue (lack of clarity in captions) and a perceived weakness in the justification provided. While they identify an issue, the lack of specific suggestions or detailed reasoning makes the feedback less helpful. They don't offer concrete alternatives or improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3: Partially Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the caveats regarding the differentiability of function g and the modeseeking nature of reverse KL. While the exact section or equation isn't mentioned, the mention of 'reverse KL' strongly suggests the reviewer is referring to a specific concept within the paper. The request for comment ('please comment') further indicates an implicit desire for clarification or assessment. Therefore, the action is stated, making it explicit. However, the reviewer doesn't specify *how* to apply these caveats or what actions the authors should take. The actions are implied but not concretely defined, making it implicit. Overall, the reviewer points out important considerations that could hinder implementation, making it actionable but not fully explicit or concrete.", "grounding_specificity_rationale": "The reviewer refers to 'reverse KL' and mentions 'differentiability of the function g'. While they don't explicitly state the section or equation number, the mention of 'reverse KL' is a strong indicator they are referring to a specific concept within the paper. The request for clarification suggests they are trying to understand a specific implementation detail. Therefore, the reviewer can identify the area of concern, making it grounded. However, the reviewer doesn't specify *which* function g or provide a detailed explanation of *how* reverse KL is modeseeking in this specific context. The criticism is about a general property of reverse KL rather than a specific detail within the paper. Therefore, the grounding is partial. The reviewer doesn't provide specific examples or details within the review point itself to enhance understanding, making the specificity partially met.", "verifiability_rationale": "The reviewer makes claims about the differentiability of function g and the modeseeking nature of reverse KL. These are statements that can be verified. However, the reviewer does not provide *reasons* for why the differentiability assumption might be unrealistic or *examples* of how reverse KL can be modeseeking in this specific context. They also don't cite specific literature to support these claims. Therefore, while the claims are stated, the supporting evidence is missing, making it 1.", "helpfulness_rationale": "The reviewer provides specific criticisms regarding the differentiability assumption and the potential limitations of using reverse KL for covering all modes in rare event sampling. They also suggest exploring recent work on normalizing flows to address this. These points are actionable and directly relevant to the implementation of the flows. While the reviewer doesn't offer a complete solution, they clearly identify areas that require attention and suggest potential directions for improvement. Therefore, the review points out important considerations and suggests potential solutions, making it 5."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "3 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point suggests a *potential issue* (noises in annotations) but doesn't explicitly state what needs to be *done*. It's a hypothesis rather than a direct instruction.", "grounding_specificity_rationale": "The review mentions \"ViStruct Suite\" and its \"visual event detection stage,\" indicating an awareness of a specific part of the system. It also specifies \"noises in annotations\" within this stage and even mentions the \"offtheshelf semantic role labeling system,\" providing details about the potential issue.", "verifiability_rationale": "The review contains a claim (\"annotations in the visual event detection stage might contain noises\") but does not provide any supporting evidence or justification.", "helpfulness_rationale": "The review identifies a potential issue (noises in annotations) but doesn't offer specific suggestions or guidance on how to address it. It's a negative observation without concrete solutions."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out the absence of time complexity analysis and running time reporting in the paper, which are concrete actions the authors should undertake. Additionally, the reviewer suggests a specific comparison (search time vs. stateoftheart algorithms) which is also a concrete action. The reviewer also identifies a difference in node pair selection policy, which is an explicit observation and suggests a comparison, again a concrete action.", "grounding_specificity_rationale": "The reviewer refers to the 'maximum common subgraph detection problem' and 'NPhard' without explicitly naming a specific section or table, which makes the grounding weak. However, the reviewer's suggestion to compare with stateoftheart algorithms implies they are referring to specific algorithms discussed in the paper, making the grounding somewhat specific. The reviewer also mentions 'MCSP and MCSP+RL' without explicitly naming a section or table, further supporting the idea of weak grounding but with a hint of implicit reference to specific algorithms.", "verifiability_rationale": "The reviewer makes claims about the missing time complexity analysis and the potential benefit of comparing search time. The 'claim' about the missing analysis is 3 as the reviewer identifies a gap. The 'claim' about the search time comparison is also 3 as it suggests a potential improvement. The reasoning is clear and the suggestions are concrete.", "helpfulness_rationale": "The reviewer provides concrete suggestions for the authors, including identifying the time complexity of the proposed algorithms and comparing their search time with stateoftheart algorithms. These suggestions directly address important aspects of algorithm evaluation and improvement. The reviewer also highlights a difference in node pair selection policy, which is a relevant point for comparison."}
{"actionability_label": "5", "grounding_specificity_label": "1 and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the absence of quality control and manual evaluation in a data collection process, which are direct actions that could be taken to improve the data. The mention of 'automatic modelbased approach' further clarifies the context and the potential impact of this missing step.", "grounding_specificity_rationale": "The review point does not specify which part of the paper or data is affected by the lack of quality control and manual evaluation. It is a general statement about the data collection process, making the grounding weak. The comment is about a process, not a specific element within a paper or data set.", "verifiability_rationale": "The review point makes a claim about the absence of quality control and manual evaluation. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. It's a statement of fact about the process, but without justification.", "helpfulness_rationale": "The review point identifies a potential weakness in the data collection process by highlighting the lack of quality control and manual evaluation. While it points out an area for improvement, it does not provide specific suggestions or guidance on how to address this issue. It is a critique of a process, not a direct solution."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point suggests an alternative to using labeled data but doesn't specify the exact steps or actions the author should take to implement the Frechet bound comparison.", "grounding_specificity_rationale": "The review mentions 'labeled data' and 'unlabeled data' but doesn't clearly identify the specific aspect of the paper or methodology being addressed. It broadly mentions the 'training process' and 'model evaluation' without pinpointing a specific section, table, figure, or unique element.", "verifiability_rationale": "The review points out the suggestion of comparing Frechet bounds and dev set performance but doesn't provide a clear rationale or justification for why this comparison is valuable. It states the suggestion but lacks explicit reasoning or references.", "helpfulness_rationale": "The review is relevant and suggests a potential solution to a common problem, but it lacks specific actionable steps and doesn't clearly explain why this particular approach is beneficial for the author. It identifies a weakness and suggests an alternative but doesn't provide concrete guidance on implementation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4: 3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a limitation of the proposed method, stating it is 'only applicable to problems with low dimensional input spaces'. While this is a valid observation, the reviewer does not explicitly state how to *improve* the method based on this limitation. The action is implied but not directly stated as a concrete step. The mention of 'curse of dimensionality' is a consequence of the limitation, not a direct action the authors should take.", "grounding_specificity_rationale": "The reviewer mentions 'low dimensional input spaces' and 'dimensionality in the experiments is 3'. This provides some grounding by referencing a specific aspect of the method and the experimental setup. However, the reviewer does not specify *what* needs to be done to address the dimensionality limitation. The grounding is present but the action is missing, making it somewhat specific without a clear direction.", "verifiability_rationale": "The reviewer makes a claim that the method is 'only applicable to problems with low dimensional input spaces' and provides a justification based on the 'curse of dimensionality' and the use of 'finite set points' in 'surrogate modeling of the shape constraint'. This justification, while not a direct citation, is based on general knowledge of machine learning challenges. The claim is supported by logical reasoning and common knowledge, making it 3.", "helpfulness_rationale": "The reviewer identifies a limitation of the proposed method, which can be valuable feedback for the authors. While the comment is not a direct suggestion for improvement, it points out a specific scenario where the method might not perform well. This information can help the authors understand the scope and limitations of the method, making the review 3 in identifying potential areas for caution or alternative approaches."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point does not contain explicit or implicit actions or suggestions. It is a critique of the results rather than a direct instruction on how to improve the method.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper being addressed. It is a general critique of the results presented in Tables 1 and 2.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a statement about the interpretation of the results, not a new assertion that needs supporting evidence.", "helpfulness_rationale": "The review point provides valuable feedback by highlighting the lack of significant improvement supported by the results. It helps the authors understand the limitations of the presented method based on the observed standard deviations. This information is useful for planning future work and not overstating the method's effectiveness."}
{"actionability_label": "High", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the difficulty of generating synthetic tabular data and provides specific examples like 'multiple entries in a table are associated with the same entity, resulting in additional relationships in the table.' This indicates a clear and direct action the authors should take: acknowledge the complexity of generating synthetic data and the challenges posed by multiple entries and relationships.", "grounding_specificity_rationale": "The reviewer mentions 'synthetic tabular data' and 'multiple entries in a table are associated with the same entity' which are specific aspects of the paper. While it doesn't explicitly point to a specific section or table, it clearly identifies the type of data and the nature of the challenge. This can be considered 'Weak Grounding' as the authors can infer the specific area being addressed.", "verifiability_rationale": "The reviewer makes a claim about the difficulty of generating synthetic tabular data and highlights the specific challenge of multiple entries and relationships. This is a claim that can be supported by general knowledge about the complexity of data generation and relationship modeling. Therefore, it is '3' as the claim is implied but lacks specific examples or references.", "helpfulness_rationale": "The reviewer criticizes the perceived difficulty of generating synthetic tabular data, particularly highlighting the challenges of multiple entries and relationships. While this points to a potential area for improvement in the draft, it doesn't directly provide actionable advice or solutions. It's more of a critique than a helpful suggestion. Therefore, it is '2' as it raises a concern but doesn't offer concrete guidance."}
{"actionability_label": "None", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out missing information but doesn't specify what is missing or how this lack of information is a problem for the authors. The statement 'this is important' is a general observation, not a specific action for the authors to take.", "grounding_specificity_rationale": "The review mentions 'annotation training details and guidelines' and 'this is important as professional translators usually have issues with such kind of nonstandard tasks.' However, it doesn't explicitly state which section or part of the paper these details should be added or what specific aspect of the task is causing issues. The reviewer identifies the *what* but not the *where*.", "verifiability_rationale": "The review makes a claim that 'this is important' and 'professional translators usually have issues with such kind of nonstandard tasks.' However, it doesn't provide any specific evidence or references to support these claims. The reviewer states a general observation without backing it up with logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review identifies a potential issue ('annotation training details and guidelines are missing') but doesn't provide any suggestions or actions for the authors to address it. The statement 'this is important' is a subjective assessment of the impact, not a concrete suggestion for improvement. The reviewer points out a problem but doesn't offer a solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is questioning the *reasoning* behind the presentation of results in Table 1, specifically the bolding of 'EX/NORB' and the interpretation of the statistical significance. While they are pointing out a potential issue, they are not explicitly stating what action should be taken. The reviewer is implicitly suggesting that the formatting and the statistical analysis might need reevaluation. Therefore, the actionability is '3' as the potential for action exists, but it's not a direct instruction.", "grounding_specificity_rationale": "The reviewer is directly referencing 'Table 1' in their comment, which clearly identifies the specific part of the paper they are addressing. This demonstrates 'Full Grounding'. Furthermore, the reviewer is asking a specific question about the statistical significance of the values within that table, indicating a clear specification of what might be incorrect. Therefore, the grounding specificity is '5'.", "verifiability_rationale": "The reviewer makes a claim that the bolding of 'EX/NORB' in Table 1 is questionable and that the statistical significance of the difference between 0.59+/0.12 and 0.58+/0.11 is uncertain. However, the reviewer does not provide any evidence, reasoning, common knowledge, or external references to support this claim. They are simply stating their interpretation without backing it up. Therefore, the verifiability is '1'.", "helpfulness_rationale": "The reviewer's comment is helpful in that it points out a potential issue with the presentation of results in Table 1 and raises a valid question about the statistical significance. This can guide the authors to reexamine their formatting and analysis. However, the comment does not directly suggest concrete changes to the draft itself. It is more about improving the *presentation and analysis* of the results rather than directly improving the content of the draft. Therefore, the helpfulness is '3'."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the issue: 'It seems it's not using the tracklet based metrics here, but the paper didn't give details on that.' This directly points to a missing metric, which is an explicit action the authors should take. However, the comment doesn't explicitly state the action of 'learning the metric' or how to implement it.", "grounding_specificity_rationale": "The comment mentions 'video level supervision experiment' and the 'metric' but doesn't explicitly point to a specific section, table, or unique aspect of the paper where this information is supposed to be found. The reviewer is inferring the need for this information, making the grounding weak.", "verifiability_rationale": "The comment makes a claim: 'It seems it's not using the tracklet based metrics here...'. However, this claim is not supported by any logical reasoning, common knowledge, or external references within the review point itself. The reviewer is stating an observation about the absence of information.", "helpfulness_rationale": "The comment clearly identifies a missing piece of information ('the tracklet based metrics here' and 'details on that'). This is a direct criticism of a lack of detail in the paper, which is likely to be helpful for the authors who might be working on similar experiments. However, the comment doesn't provide the missing information itself."}
{"actionability_label": "3  3", "grounding_specificity_label": "3  3", "verifiability_label": "1  1", "helpfulness_label": "3  3", "actionability_rationale": "The reviewer explicitly states their guess about personrelated features and provides a mechanism (models learning these features) that is directly tied to the concept of 'person blocking'. This makes the action quite explicit. However, the reviewer does not propose a specific action or suggestion to address this potential issue, only asking for clarification.", "grounding_specificity_rationale": "The reviewer refers to 'person blocking' and 'models' in a general sense, which provides some grounding. They also mention 'Fig. 4', which specifically grounds the discussion to a figure in the paper. However, they do not explicitly identify the specific part of the paper (e.g., a section, table, or figure number) that is being addressed by their hypothesis.", "verifiability_rationale": "The reviewer presents a hypothesis about 'personrelated features' but does not provide any evidence, justification, or references to support this claim. They are asking for clarification on this guess, not making a verifiable statement.", "helpfulness_rationale": "The review point is a clarifying question about a potential hypothesis. While it can be helpful for the authors to understand this potential mechanism, it does not directly point out a flaw in the work or suggest a concrete improvement. Therefore, it is 3 but not directly actionable in terms of identifying and correcting an issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests a specific technique (TFIDF and dense retrieval) for evidence sentence extraction. This is an explicit suggestion of a method. However, the reviewer does not explicitly state what the author should do with this information or how it should be applied to improve the paper. The suggestion is present, but the action is implied rather than explicitly stated.", "grounding_specificity_rationale": "The reviewer mentions 'evidence sentence extraction' as the context for suggesting the technique. This implies a connection to a specific area of the paper. However, the reviewer does not explicitly identify a specific section, table, figure, or unique aspect of the paper where this evidence extraction is lacking. The grounding is implied but not precise.", "verifiability_rationale": "The reviewer suggests a technique that is a known method in information retrieval. While the suggestion itself is verifiable, the context is about whether the author has tried it. The reviewer is not providing a claim that requires verification or justification. This is more of a question prompting the author to think about their own process rather than a critique that needs to be supported.", "helpfulness_rationale": "The reviewer asks a question about whether the author has tried a specific technique. While this can be helpful for the author to understand their own experience, it does not directly point out a weakness or provide actionable feedback on how to improve the paper. It's a question about the author's own process, not a critique of the paper's content or structure."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point implicitly suggests that the timeseries prediction model has limitations, particularly in capturing spurious correlations like the UK and Russia example. While it doesn't explicitly state an action or provide concrete steps, the suggestion to analyze countries with poor prediction based on their trajectories and the Laplacian eigenvectors implies a clear action: investigate and explore these relationships. The reviewer is guiding the authors towards a specific area of analysis, making the action somewhat explicit, though not fully detailed.", "grounding_specificity_rationale": "The reviewer mentions 'timeseries prediction' generally and then uses 'COVID19 dataset' as an example. While the concept of timeseries prediction is grounded, the specific section or table where the limitations are discussed is not explicitly named. The suggestion about the Laplacian eigenvectors is abstract and lacks a clear reference to a specific part of the paper. Therefore, the grounding is partial, as the reviewer can infer the relevance of timeseries prediction and the dataset but doesn't pinpoint the exact location or section.", "verifiability_rationale": "The review point doesn't make a claim that needs verification. It's more of a suggestion for further investigation and analysis. There's no assertion that something is wrong or needs to be changed; it proposes a method to explore potential issues. Therefore, the concept of verifiability doesn't directly apply to this review point as it's not presenting an opinion or judgment that requires evidence.", "helpfulness_rationale": "The review point is 5 as it identifies a potential area for improvement in the timeseries prediction model by highlighting the issue of spurious correlations. The suggestion to analyze countries with poor prediction based on their trajectories and the Laplacian eigenvectors provides a concrete direction for the authors to explore and potentially refine their model. This feedback is actionable and guides the authors towards a specific area of investigation, making it a valuable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks for clarification on the authors' description of their work as a 'learning framework'. While they don't explicitly state what needs to be changed, they imply a desire for more detail or confirmation about this framing. This can be seen as an implicit action to seek more information about the 'learning framework'.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'a learning framework' as the context for their comment. They then further specify the components of this framework as 'modified loss and architecture'. This clearly identifies the specific part of the paper being addressed and the issues within it. The grounding is literal and specific.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are asking for clarification on the authors' description. This falls under the category of 'Normal Statements' as it doesn't contain a subjective opinion, suggestion, or judgment about the paper.", "helpfulness_rationale": "The reviewer's primary goal is to seek clarification on the authors' description of their work. While this clarification could potentially lead to improved writing or understanding, the review itself doesn't directly provide actionable feedback on how to improve the draft content. Its primary function is to seek understanding, not to directly guide changes."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer identifies a limitation in the customization of prompts for individual architectures and suggests exploring more universal features. While the reviewer points out a problem, the suggestion is quite broad and lacks specific concrete steps or proposed methods. It's a direction for future work, not a direct, actionable fix.", "grounding_specificity_rationale": "The reviewer mentions specific architectures (CLIP, DINOv2) and the need for separate training of prompts, demonstrating a degree of grounding. However, the reviewer doesn't elaborate on *why* these architectures pose a problem or *how* to make prompts more universal.", "verifiability_rationale": "The review point clearly states a problem ('This specificity can limit crossmodel generalization') and proposes a solution ('it would be beneficial to explore if and how prompts could be designed with more universal features'). However, it does not provide any evidence or justification to support these claims.", "helpfulness_rationale": "The review point offers a relevant highlevel suggestion about the limitations of architecturespecific prompts and the potential benefits of more universal prompts. However, it lacks specific details on what constitutes an 'architecturespecific prompt' or how to achieve 'more universal features'. The suggestion is more of a direction for future research than specific, actionable feedback for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests actions such as 'compare to other models' and 'evaluate against contemporary timeseries forecasting architectures'. While it doesn't explicitly state these actions in a single sentence, the implications are clear. It also identifies a problem ('lack of baselines' and 'antiquated techniques'), which implies a need for action. The suggestion to 'evaluate the model against contemporary timeseries forecasting models' is a concrete action.", "grounding_specificity_rationale": "The review point explicitly mentions 'baselines' and 'timeseries forecasting models'. It also implies a comparison with 'contemporary' models, which can be inferred from the context. Furthermore, it provides a specific resource ('https://github.com/thuml/TimeSeriesLibrary/tree/main') to evaluate against these models, indicating a clear reference to a specific aspect of the paper.", "verifiability_rationale": "The review point makes a claim about the 'current methodology' being 'more effective or novel for fMRI forecasting compared to contemporary timeseries forecasting architectures'. However, it does not provide direct evidence or citations to support this claim. While it suggests an evaluation, it doesn't explicitly state how this evaluation would demonstrate the superiority or novelty of the current methodology. The suggestion to 'evaluate the model against contemporary timeseries forecasting models' is a potential area for investigation, but the claim itself lacks explicit verification.", "helpfulness_rationale": "The review point is 5 as it directly addresses a common concern in research: the lack of baselines and the use of 'antiquated techniques'. It provides clear directions for the authors to improve their work by 'comparing to other models' and 'evaluating against contemporary timeseries forecasting architectures'. The specific mention of the 'TimeSeries Library' repository provides a concrete resource for the authors to implement these suggestions. The review point is relevant, actionable, and directly addresses a potential limitation of the current methodology."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's comment is a direct statement of a perceived weakness: 'The only baselines presented in the paper are standard MLPs.' This is an explicit action or suggestion that the authors should consider stronger baselines. The reviewer does not explicitly state how to apply this action, making it implicit. The comment is clear and identifies the issue, but it doesn't provide specific guidance on what constitutes a 'stronger baseline'.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly pointing to a specific part of the paper. The comment is a general statement about the baselines used. The reviewer does not mention any specific section, table, figure, or unique element of the paper when making this comment. The comment is a general critique of the experimental setup rather than a specific issue within a particular section.", "verifiability_rationale": "The reviewer's claim is that 'the only baselines presented in the paper are standard MLPs.' This is a factual statement. The reviewer does not provide any external references or logical reasoning to support this claim. The statement is presented as an observation about the current baselines.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the lack of strong baselines in the paper, even though the work is primarily theoretical. The comment is a clear statement of expectation and suggests a potential improvement to the experimental setup. While the reviewer doesn't provide specific details on what a 'stronger baseline' would be, they clearly express a desire for more rigorous comparisons. This is a valuable point for the authors to consider and potentially address in future work or revisions."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The reviewer implies that the authors should compare the proposed method to the two cited works, but the exact action (e.g., compare algorithms, compare performance metrics) is not explicitly stated. The reviewer suggests including them in the experimental results, which is an implicit action but lacks specific guidance on how to integrate them. Therefore, while the intent is actionable, the lack of explicit instructions makes it 2.", "grounding_specificity_rationale": "The reviewer mentions 'two prior works cited by the authors,' which provides some grounding by identifying the specific works. However, the reviewer does not specify which unique aspect or section of these papers needs to be addressed. The reference is general, and the specific element being compared is not detailed. Therefore, while the works are mentioned, the specific part within those works is not clearly identified, making it 2.", "verifiability_rationale": "The reviewer states that the proposed method is 'very similar' to the two prior works. This constitutes a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim within the review point itself. The similarity is asserted without further justification. Therefore, the claim is not supported by any evidence within the provided text.", "helpfulness_rationale": "The reviewer's point about comparing the proposed method to the cited works and including them in the experimental results is relevant and addresses a potential gap in the literature comparison. However, the review point lacks specific details on *how* the comparison should be done or *what* aspects should be compared. The suggestion to include them is present but lacks concrete guidance, making it 3 but not fully informative for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states an action: 'check for existing visualization systems for interpretable reinforcement learning'. This action is explicit. However, the reviewer also states that 'there do not exist visualization systems built for interpretable reinforcement learning that effectively address the broader goals we have identified'. The reviewer does not explicitly state how to apply this action or what the 'broader goals' are. Therefore, while the action is explicit, it is vague on how to carry out this action because the 'broader goals' are not defined.", "grounding_specificity_rationale": "The reviewer mentions 'visualization systems built for interpretable reinforcement learning'. This provides some grounding by mentioning a specific technical area. However, the reviewer also states 'that effectively address the broader goals we have identified'. The phrase 'broader goals' is not clearly defined or identified, making the grounding underspecific. The reviewer is trying to ground the claim about nonexistent systems in the specific goals they are working on, but the goals are not yet fully defined to the reviewer.", "verifiability_rationale": "The reviewer makes a claim: 'there do not exist visualization systems built for interpretable reinforcement learning that effectively address the broader goals we have identified'. This is a declarative statement without any supporting evidence or justification. The reviewer does not provide any logical reasoning, common knowledge, or external references to back up this claim. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer points out a lack of clarity in the context of their statement about visualization systems. While the reviewer identifies a potential issue, they do not offer any suggestions or actions to address this lack of clarity. The comment is declarative but does not provide actionable feedback. Therefore, the helpfulness of this comment is limited."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue with the independence of AAL and SLS, which could be considered an implicit action. However, the reviewer does not explicitly state what needs to be done to investigate this independence.", "grounding_specificity_rationale": "The reviewer refers to 'AAL' and 'SLS' and 'Tables (14)', which grounds the comment. However, the reviewer does not specify *how* the independence is impacting the results shown in these tables.", "verifiability_rationale": "The reviewer makes a claim about the independence of AAL and SLS and the slight improvements shown in Tables (14). However, they do not provide logical reasoning, external references, or specific examples to support this claim beyond stating the observation.", "helpfulness_rationale": "The reviewer raises a valid concern about the methodology and the stability of improvements, which is helpful for the authors to identify potential issues with their approach. However, the reviewer does not offer a direct solution or suggestion to address this concern."}
{"actionability_label": "2", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests *what* to do (explore different tasks/datasets) but doesn't explicitly state *how* to do it. This makes it implicit.", "grounding_specificity_rationale": "The review point *mentions* the limitations (limited task, dataset) but doesn't specify *which* part of the paper these limitations relate to. It also doesn't explain *why* these limitations are a problem.", "verifiability_rationale": "The suggestion is to 'explore different tasks or utilize multiple datasets.' This is a suggestion for future work, not a claim requiring verification. Therefore, there is X to be verified.", "helpfulness_rationale": "The suggestion to explore different tasks and datasets is relevant and directly addresses the identified limitation of limited scope. It provides a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests replacing simulated data with realworld data. While this is a valid suggestion, the action is not explicitly stated. The reviewer implies the need for realworld data but does not specify how to obtain or use it. The suggestion is vague and lacks concrete steps. For example, the reviewer doesn't specify which experiment should use realworld data or how the data would be collected. The reviewer also doesn't explain how realworld data would be better for fitting than simulated data, leaving the reader to assume this without justification.", "grounding_specificity_rationale": "The reviewer mentions 'Heat Equation,' 'Damped Wave,' and 'NavierStokes' and suggests 'realworld data.' While the reviewer identifies the types of data being simulated and suggests an alternative, they do not explicitly point to a specific section, table, or figure in the paper. The reviewer's mention of the equations helps to ground the comment somewhat, as it refers to specific aspects of the paper. However, the suggestion of realworld data is quite broad and doesn't pinpoint a specific element within the paper that needs addressing.", "verifiability_rationale": "The reviewer states, 'simulated data will be much easier to fit.' This is a claim that needs to be supported. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to back up this claim. The statement is presented as an assertion without any explanation of why simulated data would be easier to fit than realworld data. There is no external reference provided to support this claim.", "helpfulness_rationale": "The reviewer suggests replacing simulated data with realworld data. While this is a valid point that could improve the experimental design and potentially the robustness of the results, the review does not provide specific guidance on how to achieve this. The reviewer does not specify which experiments should use realworld data, how this data would be obtained, or how the analysis would be conducted. The suggestion is general and lacks concrete steps, making it difficult for the authors to implement the advice. The reviewer also does not explain the benefits of realworld data over simulated data in the context of their specific experiments."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'Another limitation of the study is the absence of a dedicated image quality metric for evaluating the performance of image generation models. In particular, the inclusion of, e.g., interclass or intraclass Frechet Inception Distance (FID) as a quantitative assessment would greatly enhance the comprehensiveness of the evaluation and comparison between different models.' This clearly indicates an explicit action: 'include interclass or intraclass FID'. Furthermore, the reviewer provides a specific metric and even suggests which variant, making the action concrete. Therefore, this review point is 5.", "grounding_specificity_rationale": "The reviewer is suggesting a new metric (FID) specifically for evaluating image generation models. They are not just saying 'we should consider more metrics,' but specifically 'this' metric for 'this' purpose. They also suggest 'interclass or intraclass' variants, further specifying the focus. This strong specificity clearly indicates that the reviewer can identify the relevant part of the paper and the specific issue within it. Therefore, this review point is 5.", "verifiability_rationale": "The reviewer makes a claim that 'Another limitation of the study is the absence of a dedicated image quality metric for evaluating the performance of image generation models. In particular, the inclusion of, e.g., interclass or intraclass Frechet Inception Distance (FID) as a quantitative assessment would greatly enhance the comprehensiveness of the evaluation and comparison between different models.' This is a claim that is supported by the logical reasoning that adding such a metric would provide a quantitative assessment and enhance evaluation. While the reviewer doesn't provide specific examples of *how* this would improve evaluation beyond mentioning it, the claim itself is wellsupported. Therefore, this review point is 4.", "helpfulness_rationale": "The reviewer suggests adding a specific metric (FID) to address a potential limitation in the evaluation of image generation models. They are directly addressing the need for a dedicated image quality metric. The suggestion is concrete, naming a specific metric and its application domain. This directly contributes to improving the evaluation process. Therefore, this review point is 5."}
{"actionability_label": "2", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, not a directive. While the reviewer is asking for information, the specific action to be taken is implicit. The reviewer is wondering *if* something can be used, but the mechanism isn't specified, so the action isn't clearly defined or actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"vision transformers,\" which grounds the question to a specific area. However, the reviewer is asking about the *applicability* of a mechanism, not the content of the mechanism itself. The grounding is present, but the specificity of the mechanism is missing, making it only 2.", "verifiability_rationale": "The review point is a question, not a claim. Questions are classified as 'X' when they are factual statements without claims, opinions, or suggestions. There is X being made that requires verification.", "helpfulness_rationale": "The review point is a question, not a critique or suggestion. Questions, by themselves, don't directly provide actionable feedback. They prompt further inquiry. While the question is relevant, it doesn't offer concrete guidance or identify a clear weakness in the draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks 'Why does the precision of IMLE be better than the proposed Adaptive IMLE?' This is an implicit request for an explanation of a difference. The reviewer also asks 'The proposed method can be applied to any fewshot synthesis problem; do the authors try to apply the method in different domains?' This is an explicit request for action (to apply the method) and a question about the results. While the request for explanation is implicit, the request to apply the method and ask about results is explicit. The lack of specific action makes it less than fully actionable.", "grounding_specificity_rationale": "The reviewer asks 'Why does the precision of IMLE be better than the proposed Adaptive IMLE?' This question does not explicitly identify a specific part of the paper being addressed. The reviewer also asks 'The proposed method can be applied to any fewshot synthesis problem; do the authors try to apply the method in different domains?' While the paper mentions 'fewshot texttoimage synthesis' in the abstract, it doesn't explicitly state which specific part of the proposed method or the comparison is being discussed. The questions are general and do not pinpoint a specific element of the paper.", "verifiability_rationale": "The reviewer asks 'Why does the precision of IMLE be better than the proposed Adaptive IMLE?' This is a claim that requires justification and explanation. The reviewer also asks 'The proposed method can be applied to any fewshot synthesis problem; do the authors try to apply the method in different domains?' This is a factual question that can be verified by checking the paper for experiments on different domains. The 'why' part of the question is verifiable based on the method description, and the 'if' part is verifiable by examining the experimental setup and results.", "helpfulness_rationale": "The reviewer's questions are directly related to the paper's content and aim to understand its limitations and potential. The questions are relevant to the authors (the reviewer is an author). However, the questions are somewhat openended and do not provide concrete suggestions for improvement or further research. They are more about seeking clarification and understanding rather than proposing actionable changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states 'Experimental results are a bit lacking' and then asks a specific question 'are all the modules necessary?'. While the initial statement is general, the question directly points to a specific area needing improvement. The lack of explicit instructions on *how* to determine necessity makes it less concrete than 'improve the experimental section'.", "grounding_specificity_rationale": "The reviewer states 'Experimental results are a bit lacking' which is a general statement without pinpointing a specific section or table. However, the reviewer then asks a specific question 'are all the modules necessary?' which clearly identifies the area of concern. This provides some level of grounding, but it's not as precise as directly mentioning a section or table.", "verifiability_rationale": "The reviewer states 'Experimental results are a bit lacking' which can be considered a claim that needs verification. However, the reviewer does not provide any specific evidence or references to support this claim about the lacking results or the module necessity. The question itself is a request for information, not a definitive statement requiring proof.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the experimental section ('Experimental results are a bit lacking') and asks a specific question ('are all the modules necessary?'). While it points to an area for improvement, it lacks concrete suggestions or references to guide the authors on how to address this weakness. It's more of a diagnostic question than a prescriptive improvement suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states an action (exploring behavior with more layers) and provides concrete implementation details (32 and 64 layers). This directly informs the authors on what to do next.", "grounding_specificity_rationale": "The review point uses the general term \"layers\" without specifying a particular part of the model or architecture. It doesn't provide details on *which* layers or *how* the layers would be implemented. This makes it difficult for the authors to understand the exact scope and implementation of the suggestion.", "verifiability_rationale": "The review point contains a suggestion (It's interesting to know how the network behaves with a more layers like 32 and 64), which can be considered a claim in the sense that it proposes an area for investigation. However, it lacks specific justification or evidence to support this interest. It's more of an encouragement than a concrete claim requiring verification.", "helpfulness_rationale": "The review point does provide a direction for the authors to explore (behavior with more layers) and suggests specific numbers (32 and 64). This is better than a completely unhelpful comment. However, it lacks specific guidance on *how* to investigate this further, *why* these specific numbers are relevant, or *what* they might expect to find. The \"interesting\" aspect is subjective and doesn't provide concrete actionable steps. It's not *not helpful*, but it's also not a deeply informative or actionable suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the action: \"perform significance tests.\" It is a direct instruction on how to address the identified issue.", "grounding_specificity_rationale": "The comment refers to \"MT\" and \"ST,\" which are likely abbreviations for \"Moving Target\" and \"Stationary Target,\" respectively. While the reviewer understands these terms, they do not explicitly state which section, table, or figure contains the experimental results. The comment specifies what is wrong (limited improvement) and what needs to be done (significance tests), but not the exact location of the relevant data.", "verifiability_rationale": "The comment contains a claim: \"The improvement of MT over ST is very limited.\" It also suggests a solution: \"The authors should perform significance tests to ensure the reliability of the experimental results.\" The suggestion to perform significance tests is a logical and verifiable method to address the identified issue.", "helpfulness_rationale": "The review clearly identifies a weakness (limited improvement) and provides a concrete and actionable suggestion (significance tests). This directly addresses a potential concern for the authors regarding the reliability of their experimental results. The suggestion is specific enough to guide the authors in their analysis."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an improvement (error analysis) but doesn't explicitly state how to implement it or what specific changes are needed. The action is implied but not concrete.", "grounding_specificity_rationale": "The reviewer refers to 'the method' generally and mentions 'GPT4o' as a component. While GPT4o is named, the specific part of the method or the unique aspect of GPT4o being discussed is not explicitly identified. The grounding is weak.", "verifiability_rationale": "The review point contains a claim ('i would have liked to see some error analysis...') but it is not supported by any evidence, justification, or references. It is presented as a suggestion for improvement rather than a verifiable statement.", "helpfulness_rationale": "The review point identifies a valid area for improvement (error analysis) but lacks specific details on how to conduct it. While the suggestion is relevant, the lack of concrete guidance makes it less helpful than a review point with more specific recommendations."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a *lack* of an error analysis, which is a weakness. They suggest it *would be beneficial*, implying a desired action, but they don't explicitly tell the authors *what* to do about it. The suggestion is vague and doesn't provide concrete steps for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'error analysis' and 'SetCSE' but doesn't specify *where* in the paper this analysis should be conducted or *what specific aspects* of SetCSE are being evaluated. The mention is general and lacks precision.", "verifiability_rationale": "The reviewer's comment is a statement of opinion ('there is no mention') and suggestion ('would be beneficial') rather than a claim that requires verification. There's no logical reasoning, common knowledge, or external references provided to support the suggestion.", "helpfulness_rationale": "The reviewer's comment is a critique of the draft (lack of error analysis is a weakness) and a suggestion for improvement. However, the suggestion is vague and doesn't provide concrete steps for the authors to take. It lacks the detailed guidance needed for the authors to act on it effectively."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out potential limitations of the measuring tool and alternative scenarios. It doesn't directly instruct the authors on how to address these limitations or alternatives. The suggestions are speculative and don't provide actionable steps.", "grounding_specificity_rationale": "The review refers to 'measuring toolknowledge' and 'prompting' in general terms. It doesn't specify which part of the paper or method this relates to. The scenarios discussed (shared weights, alternative prompts) are highlevel possibilities.", "verifiability_rationale": "The review presents potential limitations and alternative scenarios without providing concrete evidence or data to support these claims. It's speculative and doesn't offer any verifiable insights.", "helpfulness_rationale": "The review raises valid concerns about the limitations of the measuring tool and suggests alternative approaches. However, it doesn't offer concrete, actionable steps for the authors to address these issues. The suggestions are speculative and don't provide a clear path forward."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their opinion about the MuJoCo environment's suitability for HA3C, which can be seen as an implicit suggestion for improvement. However, the reviewer does not provide concrete, actionable steps on how to address this issue or what alternative environments might be suitable. The suggestion to 'find other tasks' or 'even artificial tasks' is a direction, but lacks specific implementation details.", "grounding_specificity_rationale": "The reviewer connects the observed marginal improvement to the 'structure of the problem' and the difference between 'current state' and 'history'. This demonstrates an attempt to ground the comment in a specific aspect of the problem. However, the reviewer does not explicitly point to a specific section, table, or figure in the MuJoCo paper. The suggestion is more about exploring different problem structures rather than pinpointing a specific issue within the MuJoCo environment itself.", "verifiability_rationale": "The reviewer makes a claim about the MuJoCo environment's suitability for HA3C based on their opinion about the complexity of causal relationships. However, they do not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a suggestion for improvement rather than a justified argument.", "helpfulness_rationale": "The reviewer provides an interpretation of the numerical results, suggesting that the marginal improvement might be due to the limitations of the MuJoCo environment. This offers a potential explanation for the authors' performance. However, the reviewer does not offer specific, actionable suggestions on how the authors could address this issue or find suitable environments. The suggestions are highlevel and lack concrete implementation details."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their desire for 'key insights or takeaways derived from the experiments' and 'generalizable and hold broader significance for the community'. This indicates a clear expectation of actionable feedback. However, the reviewer does not specify *where* in the paper this lack of insight is occurring. They are criticizing the *overall* presentation of results rather than pointing to a specific section or table. Therefore, while the reviewer's expectation is clear, the paper doesn't explicitly identify the area where the lack of insight is an issue, making it partially actionable.", "grounding_specificity_rationale": "The reviewer's comment is a general critique of the paper's presentation and the nature of the results. They are not explicitly pointing to a specific section, table, or figure in the paper and asking for clarification or improvement. The reviewer is making a statement about the *type* of insights the paper should have provided, rather than a direct critique of a specific element within the paper. Therefore, the reviewer's comment is 1 in a specific part of the paper.", "verifiability_rationale": "The reviewer is not making a claim that the paper is missing something. Instead, they are stating a desired outcome: 'I would like to see some key insights or takeaways derived from the experiments'. This is a statement of expectation, not a claim that something is incorrect or missing. Therefore, the reviewer's statement does not contain a claim that can be verified.", "helpfulness_rationale": "The reviewer's comment directly addresses the need for more specific and insightful feedback from the paper. They are suggesting that the current aggregate numbers are not sufficient and that the paper should focus on providing key takeaways that are generalizable. This is a valuable and actionable suggestion for the authors, as it guides them towards a more impactful and useful study. The reviewer is clearly indicating what kind of feedback they believe is missing, making their comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the claim 'GAN has been the de facto choice for vocoders.' and then provides specific examples of alternative vocoders like WaveNet, WaveRnn, and diffusionbased approaches. This clearly identifies an action to take \u2013 to reconsider the choice of vocoder or incorporate elements from the mentioned alternatives.", "grounding_specificity_rationale": "The review point explicitly states 'Sec 3.1' before making the claim about GANs being the de facto choice. This directly identifies the section being addressed, making the grounding very clear.", "verifiability_rationale": "The review point contains a claim ('GAN has been the de facto choice for vocoders.') and provides specific examples of alternative vocoders (WaveNet, WaveRnn, diffusionbased approaches) as evidence. This provides clear references and logical reasoning to support the claim.", "helpfulness_rationale": "The review point directly identifies an inaccurate statement in the paper and provides specific alternatives. This is immediately actionable for the authors and helps them understand the limitations of using GANbased vocoders."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a problem ('not fully explained or empirically justified') but doesn't specify how to improve things or which aspects are lacking explanation. It's a general statement about the approach, not a specific action to take.", "grounding_specificity_rationale": "The review point mentions 'the approach' as the area of concern. While it points to a general area, it doesn't pinpoint a specific section, table, figure, or unique element within the paper. The issue is broadly about the 'design choices' within that approach.", "verifiability_rationale": "The review point states 'the choice of token similarity metric' without providing any evidence (logical reasoning, references, or examples) to support the claim that it's not welljustified. It's a statement of a problem, not a claim with supporting evidence.", "helpfulness_rationale": "The review point is a general critique of the approach and design choices. It doesn't pinpoint specific weaknesses or offer concrete solutions for particular issues. It's a broad statement rather than a targeted suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out specific notational inconsistencies in equations (4) and (6). They state 'Equation (4): LHS has T and W but RHS does not' and 'Equation (6): formulas for the mean and variance have j on the LHS but not on the RHS.' These are direct and actionable observations about the mathematical formulation.", "grounding_specificity_rationale": "The reviewer directly references the specific equations (4) and (6) when pointing out the notational inconsistencies. They state 'Equation (4)' and 'Equation (6)', indicating a clear understanding of the location of the issue within the paper. Furthermore, they specify the exact notational differences, such as 'T and W' on the LHS and 'j on the LHS but not on the RHS'. This level of detail demonstrates a strong grounding in the specific part of the paper being discussed.", "verifiability_rationale": "The reviewer points out potential errors in the mathematical formulation of equations (4) and (6). While they identify the *what* (notational inconsistencies), they do not provide any external references or logical reasoning to support the claim that these inconsistencies are significant or likely to cause problems. The comment is a direct observation of the equations without further justification.", "helpfulness_rationale": "The reviewer's comment directly identifies potential errors in the mathematical formulation of equations (4) and (6). This is a 5 and specific piece of feedback for the authors. They are not just pointing out a general weakness, but rather a specific technical issue that needs to be addressed. This kind of feedback is likely to be very helpful for the authors in debugging and improving their model."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of the evaluation, such as the small number of models used and the lack of evaluation on image distortion. These are clear actions or suggestions that the authors should take to improve their work. The reviewer also suggests discussing potential countermeasures, which is a direct action to address the identified weaknesses. The criticism is clear and directly points to areas for improvement in the evaluation process.", "grounding_specificity_rationale": "The reviewer mentions 'less than 20 models,' 'lack of evaluation regarding the distortion of the image after the warping,' and 'lack of discussion on the potential countermeasures against the proposed approach.' While the reviewer doesn't explicitly name a specific section, table, or figure being addressed, they clearly point to specific aspects or components of the work that need improvement. This can be considered weak grounding as the connection to a particular part of the paper is not explicit. However, the reviewer does specify what needs to be addressed in these aspects (e.g., 'insufficient models,' 'image distortion').", "verifiability_rationale": "The reviewer makes a claim that 'only less than 20 models are constructed during the evaluations, which is far from enough to demonstrate the effectiveness of the approach.' The reviewer then provides reasons for this claim, such as 'lack of evaluation regarding the distortion of the image after the warping' and 'lack of discussion on the potential countermeasures against the proposed approach.' These reasons act as evidence to support the claim, making it thoroughly verifiable. The reviewer provides logical reasoning and specific examples (or the lack thereof) to justify their statement.", "helpfulness_rationale": "The reviewer provides specific criticisms and suggestions regarding the evaluation process. They identify weaknesses (insufficient models, lack of distortion evaluation, lack of countermeasure discussion) and suggest concrete improvements. The reviewer's comment directly addresses the evaluation methodology and proposes actionable steps. The feedback is clear and directly points to areas where the authors can enhance their work. The comment is not vague or general, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the question about Table A3 and provides a clear action: 'Perhaps put them in separate tables, and glosses would be helpful.' This is a direct and concrete instruction for the authors.", "grounding_specificity_rationale": "The comment explicitly refers to 'Table A3' and asks about 'discourse particles' versus 'discourse + imported vocab'. It pinpoints the specific part of the paper and clearly defines the categories being considered. This is a high level of grounding and specificity.", "verifiability_rationale": "The comment presents a question and offers suggestions for investigation ('Perhaps put them in separate tables, and glosses would be helpful'). While these suggestions are valuable, they don't provide concrete evidence or references within the review point itself to *verify* the nature of the entries in Table A3. The verifiability depends on the authors' subsequent analysis of the table, not just the review point.", "helpfulness_rationale": "The review point raises a valid concern about the consistency of Table A3 and offers a concrete suggestion for improvement ('Perhaps put them in separate tables, and glosses would be helpful'). While the suggestion itself isn't a definitive answer, it provides a clear direction for the authors to take, making it 5 in guiding their next steps."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review points out a missing comparison, which can be interpreted as an implicit action: 'You should add a comparison to stateoftheart subset selection methods.' However, the specifics of how to do this are not provided, making it only partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'stateoftheart subset selection methods' which provides a general area, but doesn't specify a particular section, table, figure, or unique element within the paper. This indicates weak grounding as the authors can only make an educated guess about where to focus.", "verifiability_rationale": "The review states that the experiments 'lack the comparison to stateoftheart subset selection methods.' This is a claim that needs to be supported. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to back up this claim. The claim itself is verifiable, but the lack of supporting evidence makes it 1 in terms of providing concrete guidance.", "helpfulness_rationale": "The review identifies a specific area for improvement in the experimental section \u2013 the lack of comparison to stateoftheart methods. This directly points to a actionable suggestion for the authors to add this comparison. While the suggestion lacks specifics, the *action* of adding the comparison is clear, making the review helpful in guiding the authors towards a concrete change."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a problem (vague novelty) but doesn't offer a specific solution or actionable step. It's a diagnosis, not a prescription.", "grounding_specificity_rationale": "The comment doesn't pinpoint a specific part of the paper where the vagueness of novelty manifests. It's a general statement about the overall novelty.", "verifiability_rationale": "The review point states a problem (vague novelty) but doesn't make a claim that requires verification. It's a suggestion for improvement, not a critique needing evidence.", "helpfulness_rationale": "The review point identifies a potential issue (vague novelty) but lacks specific guidance or actionable steps for the authors to address it. It's a general suggestion, not a detailed critique."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'it would be important' and 'make such a benchmark more usable and available to the community.' These are direct actions the authors should take. However, the reviewer does not specify the exact steps or modifications needed to achieve this, making it only partially actionable. The reviewer suggests 'evaluation benchmarks of the user simulator' and 'showing how smaller models perform.' While the action of 'using' these benchmarks is implied, the concrete steps to 'implement' or 'design' these benchmarks are not provided.", "grounding_specificity_rationale": "The reviewer mentions 'evaluation benchmarks of the user simulator' and 'smaller models' performance. This provides a reasonably clear area of focus, making it somewhat grounded. However, the reviewer does not specify the exact type of benchmarks, the specific metrics used, or the unique aspects being evaluated, making it only weakly grounded. The reviewer also specifies the 'purpose' as 'showing how smaller models perform,' which adds to the specificity, but the lack of detail about the benchmarks themselves contributes to the weaker grounding.", "verifiability_rationale": "The reviewer presents a suggestion and a motivation for it. The reviewer states that 'it would be important to use such evaluation benchmarks' and 'this would make such a benchmark more usable and available to the community.' While there's an implied claim that this is a valuable suggestion, the reviewer does not provide explicit evidence or logical reasoning to support this claim. The connection between 'evaluation benchmarks of the user simulator' and 'showing how smaller models perform' is implied rather than explicitly stated or logically deduced from established principles.", "helpfulness_rationale": "The review point directly addresses a potential weakness in the original draft by suggesting a specific and actionable improvement: 'use such evaluation benchmarks of the user simulator to show how smaller models perform as user simulators.' This provides a clear direction for the authors to take, making the review point 5. The reviewer connects the suggestion to the practical benefit of improving the community's ability to assess and utilize smaller models, which is a relevant and actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point directly asks about the impact of openset detectors on the proposed method's performance. This is an explicit action, as the authors should be able to answer this question with a clear explanation. Furthermore, the question is specific to the 'performance of the proposed method', which provides a concrete direction for the authors to consider.", "grounding_specificity_rationale": "The review point asks about the impact of openset detectors on the 'performance of the proposed method' without specifying which particular aspect or component of the method is being affected. While it identifies a general area of concern, it doesn't pinpoint the exact location within the paper where this impact is relevant. Therefore, it is not fully grounded to a specific part of the paper.", "verifiability_rationale": "The review point is a question, not a claim that requires verification or justification. It doesn't present a new hypothesis or assertion that needs to be supported by evidence. Therefore, it does not contain a verifiable statement.", "helpfulness_rationale": "The review point raises a potential issue regarding the use of openset detectors and their impact on the proposed method's performance. While it doesn't directly offer a solution or specific guidance, it points to a potential area for improvement or clarification for the authors. It is a relevant observation that could guide the authors' further development or analysis. However, it doesn't provide a definitive answer or actionable steps, making its helpfulness borderline."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point presents two distinct issues. The first issue asks for the definition of a symbol ('*') in Table 1 next to 'oracle goals'. This is an explicit request for a definition, which is a clear and concrete action the authors need to take. The second issue asks for clarification on the term 'fromscratch' in Table 5 and points out a discrepancy with the text suggesting pretraining. This is also an explicit request for clarification and definition, a clear and concrete action the authors need to take. Both issues are directly addressable and the authors should be able to provide the necessary information.", "grounding_specificity_rationale": "The first part of the review point asks about the symbol '*' in Table 1. The authors can identify the specific location (Table 1) and the element ('oracle goals') where the symbol appears, making the grounding weakly grounded. The second part asks about the term 'fromscratch' in Table 5. While the authors can identify the table, they need to infer that it refers to model initialization, making the grounding weakly grounded as well.", "verifiability_rationale": "The first part of the review point asks for the definition of a symbol in a table. The authors can identify the symbol ('*') and the table (Table 1), making the grounding weakly grounded. The claim is that this symbol is unexplained, which is verifiable by checking the rest of the paper. The second part asks for clarification on the term 'fromscratch' in Table 5 and points out a discrepancy with the text. The authors can identify the table, but they need to infer that 'fromscratch' refers to model initialization, making the grounding weakly grounded. The claim that this term is unclear and inconsistent with the text is 1 as the authors need to check the surrounding text to confirm the inconsistency.", "helpfulness_rationale": "The review point raises two valid concerns: the meaning of a symbol in a table and the definition of a term related to model training. Both are actionable and would likely help the authors understand the experimental setup better. The first issue directly asks for a definition, which is a helpful action. The second issue asks for clarification on a term that seems to contradict the text, which is also a helpful action to resolve a potential confusion. While the feedback is not groundbreaking, it directly addresses potential ambiguities."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'According to Table 1, transferability appears to increase with higher noise intensity.' This is an explicit action identifying a trend. They then ask 'Wouldn\u2019t it be expected that as inputs are increasingly deformed by noise, different neurons are activated to reduce confidence in the source samples, thus increasing misclassification?' This is a direct question prompting the authors to consider the implications of their findings. While the reviewer doesn't directly state how to apply this, the question itself is a concrete action that the authors could investigate further.", "grounding_specificity_rationale": "The reviewer refers to 'Table 1' and discusses the relationship between 'transferability,' 'noise intensity,' and 'misclassification.' This clearly grounds the discussion to a specific part of the paper and the variables being analyzed. The reviewer also asks a question about the expected behavior of the system based on their understanding of noise, which directly relates to the variables discussed in Table 1.", "verifiability_rationale": "The reviewer makes a claim about the expected behavior of the system based on their understanding of noise and its effect on neural activations. This claim could be considered 3 if the authors can provide a logical explanation or reference supporting their reviewer's understanding of the expected behavior. However, the reviewer also states that 'These results do not appear exciting to me.' This statement is subjective and difficult to verify definitively. While the reasoning behind the expected behavior might be verifiable, the overall sentiment expressed is not.", "helpfulness_rationale": "The reviewer's question about the expected behavior of the system based on their understanding of noise and its effect on neural activations is a valuable contribution to the authors' understanding. This question directly addresses the observed trend in Table 1 and prompts them to consider the implications of their findings. However, the reviewer's statement that 'These results do not appear exciting to me' is subjective and could be interpreted as a lack of appreciation for the authors' work. This negative sentiment could slightly reduce the overall helpfulness of the review point."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly mentions the need for ablation studies (implicit) and the lack of ablation studies in the current paper (explicit). It also suggests improving figure font size (implicit). While the suggestions are concrete, the lack of clarity on *which* ablation study is needed and the implicit nature of the other suggestions make it 3.", "grounding_specificity_rationale": "The reviewer states that adding ablation studies is needed (weakly grounded), and that the current paper lacks them (weakly grounded). The suggestion to improve figure font size is also weakly grounded. However, the suggestion to explain the results in Figure 6(a) is fully grounded as it specifically refers to a particular figure and its aspect.", "verifiability_rationale": "The reviewer claims that adding ablation studies is needed (1), that the current paper lacks them (1), that figure font size is too small (1), and that Figure 6(a) results are weird and require explanation (1). The claims lack specific evidence or justification.", "helpfulness_rationale": "The review point provides specific suggestions for improvement, such as adding ablation studies, improving figure font size, and explaining the results in Figure 6(a). While the *rationale* for *why* these are important might be missing, the suggestions are concrete and directly address potential issues. Therefore, the review point is 3 as it points towards actionable improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer states that the main learning framework Equation (18) is not explained and asks for details on the balancing and penalty terms. While the reviewer explicitly mentions the lack of explanation, the implicit action is to understand the balancing and penalty terms to implement Equation (18). This makes it 3 but could be more concrete if the equation itself or a clearer explanation were provided.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Equation (18)' and asks about the 'balancing term' and the 'penalty term'. This directly identifies the specific part of the paper and the specific issues being addressed, indicating strong grounding.", "verifiability_rationale": "The reviewer makes a claim that 'Equation (18) is not explained' and provides a reason ('How to implement the balancing term and the penalty term?'). This claim is supported by the lack of explanation and the request for details, making it verifiable.", "helpfulness_rationale": "The reviewer identifies a significant weakness ('technical clarity is weak') and provides a clear direction for improvement ('How to implement the balancing term and the penalty term?'). This directly helps the authors address a specific issue, making the review 5."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem: 'the projection results and the decision boundaries should also be updated' and suggests a solution: 'It is essential to clarify how well these fixed tessellations with the updated predictions capture the model's behavior'. This is a clear and actionable criticism.", "grounding_specificity_rationale": "While the reviewer mentions 'Voronoi tessellation' and '2D projections', these are methods used for visualization, not specific parts of the paper. The reviewer is criticizing the *presentation* of information in the paper, not a specific detail within the paper itself. The connection between these terms and the paper's content isn't immediately obvious without reading the paper.", "verifiability_rationale": "The reviewer makes a clear claim: 'the projection results and the decision boundaries should also be updated' and 'the use of 2D projections to represent highdimensional decision boundaries raises concerns'. The reviewer provides supporting evidence for both claims. For the first, they provide logical reasoning ('As feature vectors update during training, the projection results and the decision boundaries should also be updated'). For the second, they provide a reference point ('results can vary significantly based on the selected projection method and parameters').", "helpfulness_rationale": "The reviewer clearly identifies a potential issue with the visualization method and provides a constructive suggestion. They are not just stating an opinion; they are pointing out a potential flaw in the methodology and suggesting a solution ('It is essential to clarify how well these fixed tessellations with the updated predictions capture the model's behavior. In addition, the use of 2D projections to represent highdimensional decision boundaries raises concerns, as results can vary significantly based on the selected projection method and parameters'). This indicates that the reviewer believes this feedback will be helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the absence of an ablation study and a comparison to methods from the past decade. While they don't specify *how* these should be performed, they clearly identify the *missing* elements. This makes the comment 3 as it points to specific areas that need improvement in the experimental validation.", "grounding_specificity_rationale": "The reviewer's comment is a general statement about the paper lacking an ablation study and comparisons to past methods. They do not specify which section, table, figure, or unique aspect of the paper is affected. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The reviewer makes a claim about the paper's shortcomings, specifically stating that there is no ablation study and no comparison to methods in the past decade. This claim is verifiable based on the absence of these elements in the paper. However, it lacks specific examples or references to support the claim, making it 3.", "helpfulness_rationale": "The reviewer identifies a valid weakness in the paper's evaluation, specifically the lack of an ablation study and comparisons to past methods. However, the comment lacks specific suggestions on how to address these shortcomings. It points out a problem but doesn't provide concrete guidance on how to improve the experimental validation, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a desired change in the *type* of theoretical results and the *complexity* of the models. This directly tells the authors what to look for or what kind of research to do.", "grounding_specificity_rationale": "The comment does not specify which part of the paper the theoretical results are being discussed in relation to. It's a general suggestion.", "verifiability_rationale": "The comment itself does not make a claim that can be verified or unverified. It's a suggestion for future work, not a critique of the current paper. Therefore, it doesn't have verifiable content in the sense of identifying specific issues to address.", "helpfulness_rationale": "The comment suggests a direction for future research, which can be helpful for the authors if they are looking to expand their work or explore related areas. However, it's a somewhat general suggestion and doesn't pinpoint specific issues in the current draft, making it less immediately actionable for immediate improvements."}
{"actionability_label": "4", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for 'more ablation studies'. This is an action or suggestion. However, the reviewer does not specify *how* these ablation studies should be designed or *why* the existing ones are insufficient. The action is implied but not concretely defined.", "grounding_specificity_rationale": "The reviewer mentions 'ablation studies' in general. While the intent is clear (to demonstrate necessity), the reviewer does not specify *which* ablation studies are needed or *why* the existing ones are insufficient. The grounding is present in the general concept of 'ablation studies' but lacks the specificity of mentioning a particular section or table.", "verifiability_rationale": "", "helpfulness_rationale": "The reviewer identifies a weakness in the paper: the lack of sufficient ablation studies to demonstrate the necessity of DA Inversion. The reviewer's suggestion to 'more ablation studies should be provided' directly addresses this weakness. However, the *quality* and *specificity* of these suggested ablation studies are not defined, making the helpfulness somewhat subjective and dependent on the implementation of these suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer's question implicitly suggests that the clustering might be unnecessary. While they don't explicitly state an action to be taken, the question encourages the authors to clarify the role of the clustering, implying a need for action to improve the method. However, the action isn't directly stated, making it somewhat implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 3.3' and 'keypoints' when questioning the necessity of the clustering. This demonstrates a clear attempt to refer to a specific part of the paper, indicating strong grounding. The mention of 'keypoints' is a specific element within that section, showing a good understanding of the relevant part.", "verifiability_rationale": "The reviewer's question raises a valid point about the justification for the clustering. While the paper might implicitly justify its existence, the reviewer's question suggests a lack of explicit and clear reasoning. The need for clarification implies that the justification, if present, is not readily apparent or is potentially flawed. Therefore, it can be considered somewhat justified but not 5 based on the information provided in the review point itself.", "helpfulness_rationale": "The reviewer's question directly addresses a potential design flaw (the unnecessary clustering) and encourages the authors to clarify its purpose. This question is highly valuable for guiding the authors to improve their method by removing the clustering if it's indeed not needed. Therefore, the reviewer's question is a strong indicator of the potential for improvement and is 5 in that regard."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions 'Fig2a' and suggests a concrete action 'reducing learning rate' to address the observed trend. The action is direct and provides a clear path for the authors to implement changes.", "grounding_specificity_rationale": "The review point explicitly refers to 'Fig2a' and discusses a specific trend ('forgetting is not as drastic...') within that figure. This allows the authors to accurately identify the section being addressed and understand the specific issue.", "verifiability_rationale": "The review point contains a claim about the observed trend in Fig2a. While it doesn't provide external references to *prove* the trend, it clearly identifies the trend based on the visual information presented in the figure. The claim is directly linked to the content of the figure.", "helpfulness_rationale": "The review point identifies a specific trend in a figure and suggests a concrete action to address it. The suggestion is clear and actionable for the authors. However, it doesn't provide a deep dive into the reasons behind the trend or explore alternative solutions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a suggestion for improvement: \"The author should highlight the data dependent (on the covariance spectrum) nature of their approximation results (maybe in the abstract)\". This is an explicit action.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"approximation results\" and the specific factor influencing them, \"covariance spectrum\". This clearly grounds the feedback to a specific part of the paper.", "verifiability_rationale": "The reviewer provides a clear justification for the suggestion: \"It is totally fine to have a data dependent bound\". This provides a logical reasoning for why the highlighted aspect is important.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement. They identify a specific area where the paper could be strengthened (\"highlighting the data dependent nature of their approximation results\") and provide a concrete action ('should highlight\"). The reviewer also provides a justification for the suggestion (\"It is totally fine to have a data dependent bound\"). This suggests that the reviewer has a good understanding of the paper's content and the potential benefits of the suggested improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point asks for clarification on the meaning of RMSD, which is an implicit action that requires the author to infer the specific context. While the reviewer provides a clear distinction between the two interpretations of RMSD, the action itself is not explicitly stated.", "grounding_specificity_rationale": "The review point does not explicitly mention any specific part of the paper or figure. It is a general question about the interpretation of RMSD. Therefore, the grounding is weak as the reviewer cannot confidently determine which part of the paper is being addressed.", "verifiability_rationale": "The review point does not contain a claim. It is a question seeking information rather than making a statement that requires verification.", "helpfulness_rationale": "The review point identifies a potential ambiguity in the interpretation of RMSD and provides a clear distinction between the two possible meanings. This directly addresses a potential point of confusion for the author and provides a direction for clarification. While the action of clarifying is implicit, the reviewer's request is specific and directly related to understanding a figure, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point asks a question about the possibility of a smooth regret scaling while maintaining proven bounds. While it doesn't explicitly state an action to be taken by the authors, it implicitly suggests an area for further investigation and potential improvement. The reviewer is prompting the authors to explore a specific aspect of their theoretical analysis. Therefore, it can be considered partially actionable as it identifies a potential area for action (further research or algorithm modification).", "grounding_specificity_rationale": "The review point refers to 'phase transitions in the \"actual regret scaling\"'. While it points to a specific concept within the paper, it doesn't provide a precise section number or a clear indication of which unique element of the paper it's addressing. The authors would need to infer the exact area based on this reference. Therefore, it can be considered weakly grounded.", "verifiability_rationale": "The review point presents a claim: 'Could there be a smooth regret scaling (i.e. not displaying phase transitions) for which the proven bounds still holds?'. However, it does not provide any explicit justification, examples, or references to support this claim. The reviewer is asking a question that requires the authors to explore the theoretical properties of regret bounds and phase transitions. There is no logical reasoning, common knowledge, or external references provided to back up this claim. Therefore, it can be considered 1 as presented.", "helpfulness_rationale": "The review point asks a very specific and relevant question about a potential improvement to the authors' work. It highlights a potential area for further research or a modification to their theoretical analysis. By pointing out this specific question, the reviewer is helping the authors identify a potential weakness or area that needs further exploration. While it doesn't directly tell the authors how to achieve this smooth regret scaling, it guides them towards a specific direction. Therefore, it can be considered 3 in identifying a potential research direction or improvement opportunity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that a comparison to 'previous robust RL methods' is missing. This is a clear indication of an actionable suggestion. The reviewer further specifies the methods they believe are relevant (RARL, GAD, EG), making the action even more concrete. The suggestion is to include this comparison, which is a direct and actionable step for the authors.", "grounding_specificity_rationale": "The reviewer not only states that a comparison is missing but also explicitly names the methods (RARL, GAD, EG) that should be included. This strong identification of specific parts of the paper being addressed makes the comment highly grounded. Furthermore, the reviewer explains *why* this comparison is important, adding clarity and specificity to the suggestion.", "verifiability_rationale": "The reviewer makes a claim: 'Seems like comparison to previous robust RL methods are missing'. This claim is supported by the reasoning that existing robust RL methods are cited (e.g., RARL) but not compared to. The reviewer provides specific examples (RARL, GAD, EG) and explains the relevance of the comparison, making the claim verifiable through logical reasoning and examples.", "helpfulness_rationale": "The reviewer's point directly addresses a potential gap in the related work section by highlighting the absence of a comparison to relevant robust RL methods. This is a valuable piece of feedback for the authors as it helps them understand how their work fits within the existing literature and what novel contributions it might have. The suggestion is clear and directly addresses a potential weakness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states what is missing in the paper: details about the hyperparameters $k_1, k_2, k_3$, the specific networks used, and the learning objectives. This makes the action of providing these details explicit. However, the comment does not specify *how* these details should be provided (e.g., specific ranges for $k_1$, type of network architecture, or specific loss functions). Therefore, while the action is explicit, it is vague on the implementation, making it 3.", "grounding_specificity_rationale": "The comment refers to the 'choice' of $k_1, k_2, k_3$, networks, and learning objectives. While the reviewer can infer that these choices are likely made in the methodology or experimental setup section of the paper, they do not explicitly name a specific subsection, table, or figure. Therefore, the grounding is weak as the authors have to infer the location of the referenced part. However, the comment does specify *what* is missing, which makes the specificity somewhat clear.", "verifiability_rationale": "The comment itself does not contain a direct claim. Instead, it implies a concern that the lack of detail regarding the choice of $k_1, k_2, k_3$, networks, and learning objectives might hinder the reproducibility or understanding of the work. While this is a valid concern, the comment does not provide any specific evidence or references to support this claim. Therefore, while the comment points to a potential issue, it is not 5 without further information or justification.", "helpfulness_rationale": "The comment is constructive and directly points out a potential weakness in the paper: the lack of sufficient detail regarding the choice of hyperparameters, networks, and learning objectives. This is a valuable piece of feedback for the authors, as it helps them identify areas where they need to provide more information for the reviewers to fully understand and potentially reproduce the work. The comment is clear and directly suggests improvements, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point is a question about a relationship involving a negative sign. While it implicitly suggests a potential issue with the proportional relationship, it does not explicitly state what action the authors should take. The lack of clarity on the 'HIS' term and the negative inverse of mean response time makes it difficult to pinpoint an actionable step.", "grounding_specificity_rationale": "The review point refers to 'HIS' and 'mean response time'. While it points to specific elements of the paper, it does not explicitly name the section, table, or figure where these are discussed. The lack of a clear reference point makes it weakly grounded.", "verifiability_rationale": "The review point is a question about a relationship, not a claim that needs verification. It does not present a statement that requires logical reasoning, common knowledge, or external references to be considered verifiable.", "helpfulness_rationale": "The review point is a question about a relationship that is counterintuitive due to the negative sign. It highlights a potential issue but does not explain why it is negative or provide guidance on how the authors should address it. The lack of a clear explanation and actionable advice makes it not helpful."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks 'Is there any reason for why the particular sparse representation learning method is chosen?'. This question implies an implicit reason rather than an explicit one. While the reviewer's question is relevant, the paper does not provide a clear rationale for selecting this specific method, making it less actionable for the authors. The lack of explicit reasoning makes it difficult for the authors to understand the motivation behind the choice and potentially replicate or build upon the work.", "grounding_specificity_rationale": "The reviewer's comment focuses on the *choice* of a sparse representation learning method. While the method itself is a specific part of the paper, the reviewer doesn't explicitly identify *which* section or table of the paper is being questioned regarding its suitability. The grounding is weak because the reviewer doesn't point to a specific element within the paper that needs clarification. The comment is more about the *method* rather than a specific aspect of the paper's content.", "verifiability_rationale": "The reviewer states, 'Furthermore, in the experiments part, FTA should also be compared as a baseline. It is unclear why you compare it in a supervised learning setting but omit in a RL setting. The performance on a SL setting does not invlidate/validate another. As an empirical paper, I think a rigorous comparison is necessary.' This comment contains a claim (the need for FTA as a baseline and the inconsistency in its inclusion). However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The lack of justification makes the claim 1.", "helpfulness_rationale": "The reviewer's comment is relevant and raises important questions about the experimental setup and the justification for the chosen method. The questions are openended and point to areas where the paper could be improved. While the reviewer's questions are valuable for guiding future work, they are not presented as direct, actionable suggestions or justifications, making the feedback somewhat open to interpretation and less directly helpful for immediate implementation. The questions are relevant but lack specific guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states 'p.4, l.154 describes a particular choice of shift and scaling, and the authors state that 'this choice is the more appropriate.'' While the reviewer identifies the location, the specific choice and the reasoning for it being 'more appropriate' are not detailed. The action is identified (pointing to a location and describing a choice), but the action itself is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'p.4, l.154', indicating a degree of grounding. However, the description of the content at that location ('a particular choice of shift and scaling') is vague. The reviewer also states 'the authors state that 'this choice is the more appropriate.'', which is a specific statement about the content, but the choice itself is not specified, leading to a lack of specificity in the description of the content.", "verifiability_rationale": "The comment contains a claim: 'this choice is the more appropriate.' However, this claim is not supported by any logical reasoning, common knowledge, or external references. The reviewer does not provide any evidence or justification for why this specific choice is considered more appropriate.", "helpfulness_rationale": "The comment is 1. The reviewer states an opinion ('this choice is the more appropriate.') without providing any supporting evidence or justification. While the reviewer points to a specific location, the lack of explanation makes it unhelpful for the authors to understand why this choice is better. There are no concrete suggestions or actions provided."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue with the term 'partial inference' in the title and suggests a revision. This indicates an explicit action. The reviewer also points to the specific area of concern, which is 'GFlowNets', and suggests a concrete change, 'revise'. This suggests a clear action to be taken. Therefore, the actionability is high.", "grounding_specificity_rationale": "The reviewer mentions 'GFlowNets' and 'partial inference' in the context of the title and the general discussion of the paper. However, they do not explicitly state which specific section, table, or unique aspect of the paper they are referring to. The reviewer implies the issue is related to the title and the general discussion, which is a general reference. Therefore, the grounding is weak. The reviewer also specifies the *topic* as 'partial inference' in relation to 'GFlowNets', which adds some specificity to the *subject matter*, but it doesn't pinpoint a specific part of the paper. Therefore, the specificity is low.", "verifiability_rationale": "The reviewer states that they 'take issue with the use of 'partial inference' in the title and 'partial inference' elsewhere'. This constitutes a claim. However, the reviewer does not provide any specific evidence, examples, or references to support their claim that 'partial inference' is problematic. The reviewer simply states their *opinion* about the terminology. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer clearly identifies a potential issue with the use of the term 'partial inference' in the title and suggests a revision. This is a direct and actionable suggestion. The reviewer points to a specific area of concern ('GFlowNets') and proposes a clear action ('revise'). While the reviewer doesn't provide specific details about *why* 'partial inference' is problematic, they clearly state the *problem* and suggest a *solution*. Therefore, the review is 5 as it provides a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'many other matrices' and 'none of them are discussed.' This is an explicit statement of what is missing and is very concrete. The reviewer implies a desire for the authors to consider these other metrics, making it actionable.", "grounding_specificity_rationale": "The reviewer does not explicitly state which specific similarity metrics are missing. They say 'many other matrices,' which is vague. They also don't pinpoint a specific aspect of 'stealthiness.' While the topic is specific, the details are not.", "verifiability_rationale": "The reviewer presents a claim: 'the paper only measures bertscore...'. They also state that 'other metrics exist and are relevant' as a reason for this limitation. While they don't provide explicit evidence for the existence of these metrics in this review point, the reasoning is generally sound and supported by common knowledge in the field. The claim is wellsupported by the understanding of evaluation metrics.", "helpfulness_rationale": "The reviewer clearly identifies a limitation in the evaluation methodology (only using BertScore) and offers a concrete suggestion (consider other metrics). This directly points out a problem and proposes a solution, making the review 5 for guiding authors."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the need to highlight issues with existing estimators and define basic notation, indicating an intention to point out problems. However, the reviewer does not provide specific, actionable steps beyond stating the existence of these issues. For example, they mention 'more convenient for applications' but don't specify which applications or how they are more convenient. The lack of concrete suggestions makes it difficult to act upon the feedback.", "grounding_specificity_rationale": "The reviewer does not explicitly identify the specific part of the paper they are referring to when mentioning 'basic notation is not defined' or the issues with estimators. They mention these issues generally without pinpointing the relevant sections or tables. This lack of specificity means the reviewer does not clearly identify the area needing improvement.", "verifiability_rationale": "The reviewer makes claims about the issues with existing estimators and the undefined notation, which could be considered claims. However, they do not provide any logical reasoning, common knowledge, or external references to support these claims. For example, they state 'the dimensionality p (p.2 or Eq. 3) the unit ball S p (p. 2) an outer product ( v ) \u2297 2 (Alg. 1) a constraint set \u0398 (Alg. 2) the constant d 2 (Thm. 2, Eq. 5) is still mysterious' without explaining why these are mysteries or how they impact the estimators. The lack of justification makes the claims 1.", "helpfulness_rationale": "The reviewer identifies areas where improvements are needed, such as clarifying applications and addressing issues with estimators. However, the feedback lacks specific details and actionable steps. For instance, they mention 'basic notation is not defined' but don't specify which notation needs clarification or where in the paper it should be defined. The lack of concrete suggestions makes it difficult for the authors to understand exactly what needs to be improved and how. The vague nature of the feedback reduces its helpfulness."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer's question directly points to a missing piece of information needed to understand the method. They are asking which specific perceptual loss functions are new, implying they are aware of the paper's claim and seeking clarification. This is an explicit and concrete action the authors should take.", "grounding_specificity_rationale": "The reviewer is referring to the general description of the perceptual loss functions in the 'Perceptual Loss Functions' component of the method section. They are not explicitly pointing to a specific section, table, figure, or unique element of the paper. Therefore, the grounding is weak as the authors need to search the paper to find the relevant information.", "verifiability_rationale": "The reviewer makes a claim that the paper's claim of novelty for certain loss functions is potentially incorrect, based on their familiarity with common loss functions in medical imaging. This claim requires some level of justification or clarification, making it 3. The reviewer is not providing a direct citation, but their point about common usage provides a basis for verification.", "helpfulness_rationale": "The reviewer's question is directly relevant to understanding the method and identifying potential issues. By asking which specific loss functions are new, they are seeking crucial information that would significantly improve the authors' understanding and potentially the reproducibility of their work. This is a helpful and actionable question."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out the lack of significant improvement and the lackluster comparison on the ZINC dataset. While they don't explicitly state what the authors should do, they identify the areas where improvements are needed. The criticism is relatively concrete, pointing to the *type* of improvement (significant) and the *area of concern* (ZINC dataset comparison).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'experimental results,' 'reallife datasets,' and 'ZINC dataset.' This clearly identifies the specific part of the paper being addressed, making the grounding 5.", "verifiability_rationale": "The reviewer makes claims about the lack of significant improvement and the lackluster comparison on the ZINC dataset. While they don't provide specific examples or citations to *why* these issues are significant or how they impact the results, the claims are logically inferable from the absence of evidence presented in the paper. The reasoning is that if the results are not showing significant improvements, then that is a valid observation. Similarly, if the comparison on ZINC is weak, that is also a valid observation based on the presented data.", "helpfulness_rationale": "The reviewer highlights a fundamental issue with the experimental evaluation, pointing out the lack of significant improvement and the lackluster comparison on the ZINC dataset. This is a valuable piece of feedback for the authors as it encourages them to focus on demonstrating more substantial results and strengthening their analysis of the ZINC dataset. While it doesn't provide a specific solution, it prompts the authors to address a key weakness in their experimental evaluation."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer implicitly raises a potential issue: the general trend that larger models often perform better, and the specific scenario of a smaller model (SLM) performing better than a larger model (BSM) due to limited data. While the reviewer doesn't explicitly state what the author should do, they point to a potential discrepancy and a scenario where it might arise. The action is implicit, requiring the author to consider the general trend and the specific data constraints.", "grounding_specificity_rationale": "The reviewer does not explicitly refer to a specific part of the paper, model, or experiment. They raise a general question about the performance of smaller and larger models under limited data conditions. There is no mention of specific sections, tables, figures, or unique elements of the paper that would allow the authors to pinpoint the issue. The grounding is based on general knowledge of model performance.", "verifiability_rationale": "The review point does not contain a claim that needs to be verified. It is a question posed to the authors. Therefore, it does not fall under the verifiability categories.", "helpfulness_rationale": "The reviewer raises a relevant and insightful question. They highlight a potential discrepancy between the expected outcome (BSM usually better) and a specific scenario (SLM with limited data). This question encourages the author to consider alternative explanations and potentially improve their understanding of their model's performance. While it doesn't provide a solution, it prompts further thought and analysis, making it 3 in guiding the author's process."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a *problem* (inconsistent notation) and suggests an *action* (the authors should check the notation). While the reviewer doesn't explicitly state *why* the notation is inconsistent, they clearly identify *where* the inconsistency exists (Alg 1, Fig 2, Fig 3, Fig 4). The authors can infer that they need to check these specific parts of the paper to identify the inconsistency. The action is somewhat implicit as the authors need to infer the location of the issue.", "grounding_specificity_rationale": "The reviewer explicitly states that the notation is inconsistent, especially with 'nu'. They also point out the inconsistency in specific locations, such as 'Figures 2 & 3' and 'Algorithm 1'. This clearly identifies the specific parts of the paper being referred to, making the grounding very strong. The reviewer provides concrete examples of where the inconsistency is mentioned, and they also specify the potential variable causing the issue ('nu').", "verifiability_rationale": "The reviewer identifies a *potential issue* (inconsistent notation) without providing a claim or suggestion for improvement. While the reviewer highlights a problem that could affect the clarity and correctness of the paper, they do not offer any logical reasoning, external references, or examples to *justify* why this inconsistency is a problem. The comment is primarily a statement of observation rather than a claim that requires verification.", "helpfulness_rationale": "The reviewer identifies a *potential problem* (inconsistent notation) that could lead to confusion or errors. This could be helpful for the authors to identify a potential issue in their implementation or presentation. However, the reviewer does not offer a specific *suggestion* for how to fix the notation. Without a proposed solution, the comment is somewhat limited in its helpfulness. The authors would need to investigate the notation themselves to confirm the inconsistency, which reduces its immediate helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests 'More experiments should be conducted' and implies these experiments should be 'in more challenging tasks such as dexterous manipulations in Adroit'. While the core action of conducting more experiments is clear, the lack of detail regarding the *type* of experiments or the *metrics* to evaluate the new experiments makes it 3. The inclusion of a specific example ('dexterous manipulations in Adroit') provides a degree of direction, but further elaboration would be beneficial.", "grounding_specificity_rationale": "The review point explicitly mentions 'dexterous manipulations in Adroit'. This directly points to a specific aspect of the Adroit environment. The suggestion to conduct 'more challenging tasks' further implies a need to evaluate performance on difficult scenarios. This explicit reference to a specific part of the paper and the suggestion to use this part for further evaluation makes it 5.", "verifiability_rationale": "The review point presents a suggestion ('More experiments should be conducted') without providing any justification or evidence. It doesn't explain *why* these additional experiments are needed or *how* they would demonstrate the method's effectiveness beyond the current tasks. The statement is a suggestion without any supporting arguments, examples, or references. There's no logical reasoning or external evidence provided to back up the claim.", "helpfulness_rationale": "The review point clearly identifies a potential weakness ('the effectiveness of the proposed method') and suggests a concrete improvement ('conducted more experiments in more challenging tasks'). However, it lacks any justification for *why* these additional experiments are necessary or *how* they would validate the method's effectiveness. The suggestion is present but lacks supporting evidence. The authors know what needs improvement, but the reviewer doesn't provide a strong rationale for *why* those improvements are needed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the summary of Williams et al. (2019); Lyu et al. (2021); Boursier et al. (2022); Wang & Ma (2023) is 'not very fair' and claims that 'some of these papers are only assuming the data is linearly separable.' This is an explicit statement about the assumed level of separability. However, the reviewer does not provide a concrete suggestion for how the summary should be improved. The action is implicit \u2013 the summary should acknowledge the orthogonally separable assumption. Therefore, while the reviewer identifies a potential area for improvement, the lack of a concrete suggestion makes it 2.", "grounding_specificity_rationale": "The reviewer mentions specific papers (Williams et al., Lyu et al., Boursier et al., Wang & Ma) in the introduction. However, they do not explicitly state which section, table, or unique aspect of the paper they are referring to. The reviewer's comment is more about pointing out a potential flaw in the summary rather than pinpointing a specific element within the summary. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer claims that the assumption of 'the feature direction of each arbitrary training sample could act as a perfect linear classifier' is 'even stronger' than what the summary implies and refers to 'orthogonally separable data'. However, the reviewer does not provide a citation or any other evidence to support this claim about the summary lacking sufficient justification or being incorrect. The claim is based on the reviewer's interpretation of the summary. Therefore, the verifiability is borderline.", "helpfulness_rationale": "The reviewer's point is that the summary is 'not very fair' and contains a potentially unfair assumption. While this impacts the authors' understanding and potentially their work, the reviewer does not offer any concrete suggestions for improvement or alternative approaches. The feedback is primarily critical without constructive suggestions. Therefore, the helpfulness is somewhat limited."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of the Taylor expansion's validity when weights are not close to zero. This is an explicit action identifying a potential flaw in the method. The reviewer also implies a solution by suggesting that the influence function might not reflect influence correctly and the weights might be unreliable, which is a concrete action.", "grounding_specificity_rationale": "The reviewer directly addresses the 'influence function' and its 'Taylor's firstorder expansion'. This is a literal mention of specific parts of the paper, making the grounding very explicit. The reviewer also specifies the *consequence* of the approximation being invalid, further enhancing the specificity.", "verifiability_rationale": "The reviewer makes a claim: 'the explanation of the influence function holds only when the upweight (i.e. parameter weights in this paper's context) is very close to 0.' This claim is supported by the reasoning: 'Otherwise, the theoretical approximation of each sample's contribution from Taylor's firstorder expansion is not valid any more.' This logical reasoning verifies the claim. The reviewer also states the *consequence* of this limitation: 'the influence function might not reflect each sample's influence correctly and the weights produced might be unreliable.' This provides further justification for the claim.", "helpfulness_rationale": "The reviewer provides a clear critique of a specific methodological aspect, highlighting a potential flaw and its implications. This critique directly points to a limitation of the persample weight tuning method and suggests that the influence function might not be reliable under certain conditions. This information is valuable for the authors to understand the limitations of their approach and potentially explore alternative methods or adjust their training process. While the reviewer doesn't explicitly suggest a solution, the identification of this limitation is a significant contribution to the authors' understanding."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests addressing the issue of centering for partial shapes and scenes. This is an implicit action, as the authors are encouraged to investigate and potentially modify their centering method. The reviewer does not explicitly state how to implement this action, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Centering' and 'partial shapes and scenes' as the area of concern. This clearly identifies the specific aspect of the paper being addressed, making it fully grounded.", "verifiability_rationale": "The reviewer states that 'Centering is welldefined for complete shapes but not necessarily for partial shapes.' This is a claim that can be verified by understanding the typical definition of centering and the nature of partial shapes. However, the reviewer does not provide a detailed explanation or external references to support this claim, making it somewhat lacking in justification.", "helpfulness_rationale": "The reviewer identifies a potential limitation of the method (centering for partial shapes) and suggests a direction for improvement (addressing this issue). This is a valuable feedback point for the authors, making it 5. The 'as an aside' comment about the experiment with 50% missing points, while slightly less direct, doesn't diminish the core helpfulness of addressing the centering issue for partial shapes."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests an action: 'try to ensemble models trained with the proposed negative augmentations and without it'. This is a clear instruction on what the authors should do next. The action is also quite concrete, specifying the type of ensembling and the purpose of the experiment.", "grounding_specificity_rationale": "The review point refers to 'the proposed negative augmentations', which are explicitly defined in the paper as 'negative samples that only share the texture sematic with the anchor images'. This allows the reviewer to precisely identify the part of the paper being addressed. Furthermore, the suggestion to 'try to ensemble models trained with the proposed negative augmentations and without it' directly specifies the experiment to be conducted within this defined area.", "verifiability_rationale": "The review point makes a claim: 'it would be good to try to ensemble models trained with the proposed negative augmentations and without it and see whether this could improve the performance'. This claim is supported by the reasoning that the paper 'proposed to learn less about the texture semantics'. The suggestion is logically derived from the identified limitation and proposes a concrete experiment to potentially address it. The implication of 'see whether this could improve the performance' provides a clear direction for the authors to follow.", "helpfulness_rationale": "The review point is 5 as it directly addresses a potential weakness in the proposed method (the potential loss of texture information by only focusing on shared semantics). It provides a clear and actionable suggestion for an experiment that the authors can readily implement. The suggestion is specific about the type of models to ensemble and the expected outcome (improved performance). The logical connection between the identified limitation and the proposed solution makes the review point very informative and helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the transition probabilities and points out a discrepancy between claims and implementation. While it implies a potential issue, it doesn't explicitly state what needs to be done or how to address it. The reviewer is essentially asking for clarification or a correction, which is a form of actionable feedback, but lacks specific steps.", "grounding_specificity_rationale": "The review point mentions 'all possible transition probabilities' and refers to specific sections (page 5 and Appendix B) and equations (Eq. 7 and the implied reference to Eq. 6). This indicates some grounding as the paper sections and equations are mentioned. However, it doesn't explicitly state what is wrong with the transition probabilities or how the equations relate to this specific issue, making the grounding somewhat implicit.", "verifiability_rationale": "The review point raises a concern about a discrepancy between claims and implementation. While it implies a potential issue, it doesn't provide any specific evidence, references, or logical reasoning to support this concern. The reviewer is stating an observation without further justification, which is 1.", "helpfulness_rationale": "The review point points out a potential issue related to transition probabilities and sample efficiency. While this is likely relevant to the authors if they are implementing or understanding the method, it doesn't offer specific guidance or suggestions on how to address the problem. It's more of a pointer to a potential area of concern than a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly asks a question about a missing detail ('how the authors form clusters for tokens in Figure 1?') within Section 3. This implies an action should be taken to understand the process, making it actionable. The reviewer is asking for a specific piece of information that is not explicitly stated, which the authors need to discover themselves.", "grounding_specificity_rationale": "The reviewer refers to 'Section 3' and 'Figure 1', which are specific parts of the paper. They also use the technical term 'tokens'. This indicates a strong grounding of the comment within the paper's content. The reviewer is asking about a specific aspect ('tokens') within a specific section and figure, making it highly specific.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. Instead, they are pointing out a lack of information and asking for clarification on how clustering is performed. While the act of seeking information can be seen as a form of implicit guidance, the reviewer is not providing a basis for logical reasoning, common knowledge, or external references. Therefore, it is 1 in the sense that the authors need to find the information themselves, but the *act* of seeking information can be considered a form of implicit guidance.", "helpfulness_rationale": "The reviewer directly addresses a potential area of confusion for the authors (lack of clarity in Section 3) and asks for a crucial detail ('how the authors form clusters for tokens in Figure 1'). This is a very direct and helpful suggestion. It points to a specific area where the authors might struggle and asks for a specific piece of information that would resolve that struggle. This is 5 because it directly addresses a potential weakness and guides the authors to seek a specific detail."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitation of SimNPO due to manual hyperparameter tuning and provides specific details about the impact. The reviewer states \"SimNPO introduces two additional hyperparameters that must be manually adjusted to achieve optimal performance, significantly increasing the complexity and time cost of experiments.\" This directly identifies the problem and its consequences. The reviewer also states \"This greatly limits the potential application of this method for large language models in realworld settings.\" This provides a clear direction for potential improvements or workarounds.", "grounding_specificity_rationale": "The reviewer accurately identifies the specific aspect of SimNPO (the two additional hyperparameters) and clearly specifies the issue. The reviewer states \"SimNPO introduces two additional hyperparameters that must be manually adjusted to achieve optimal performance, significantly increasing the complexity and time cost of experiments.\" This explicitly mentions \"SimNPO\" and its \"two additional hyperparameters,\" clearly identifying the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer presents a claim about the limitations of SimNPO based on a factual observation, but lacks specific citations to support the claim. The statement \"SimNPO introduces two additional hyperparameters that must be manually adjusted to achieve optimal performance, significantly increasing the complexity and time cost of experiments.\" is a claim. While the statement is a critique, it's based on a factual observation about the method's design. The *implication* is that this limitation *hinders* realworld application. The reviewer doesn't explicitly *cite* any external work to *prove* this is a significant limitation, but it's a generally accepted understanding in the field regarding the practical challenges of tuning hyperparameters.", "helpfulness_rationale": "The reviewer clearly identifies a practical limitation that would be relevant for practitioners, highlighting the increased complexity and time cost. The reviewer states \"SimNPO introduces two additional hyperparameters that must be manually adjusted to achieve optimal performance, significantly increasing the complexity and time cost of experiments.\" This statement directly identifies a practical limitation that would be relevant for practitioners using or considering SimNPO. The reviewer clearly states *why* this is a problem and *what* the consequences are."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the work is 'relegating too much emphasis on affordance prompting' and provides the 'Pick&place example' as evidence. While the reviewer identifies a potential issue and a specific example, they do not explicitly state what modifications or actions the authors should take to address this. The reviewer implies the need for a shift in emphasis but doesn't provide concrete steps on how to achieve this.", "grounding_specificity_rationale": "The reviewer refers to 'affordance prompting' generally and then narrows it down to 'Pick&place example'. They also state that the 'Pick&place example does not show enough the advantage of affordance prompting'. The reviewer can accurately pinpoint the specific part of the paper being addressed and clearly identifies the issue with this part, which is the lack of clear demonstration of affordance prompting's advantage in the example.", "verifiability_rationale": "The reviewer makes a claim that 'the work is relegating too much emphasis on affordance prompting, but this prompting is overengineered. For instance, Pick&place example does not shows enough the advantage of affordance prompting'. This is a claim that requires justification. However, the reviewer does not provide explicit reasoning, common knowledge, or external references to support this claim about the Pick&place example. The claim is presented as a statement of opinion rather than a claim supported by evidence.", "helpfulness_rationale": "The reviewer's comment identifies a potential imbalance in the paper's focus and provides a specific example ('Pick&place') to illustrate this point. While the feedback is relevant and points to a potential area for improvement, it lacks strong justification for the specific example and doesn't offer concrete suggestions for the authors to address the issue. The feedback is somewhat general and doesn't provide clear guidance on how the authors should modify their work."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action needed: 'Ablation studies are needed...'. This directly informs the authors on what type of analysis to perform to assess the necessity of each component in the algorithmic pipeline. The action is clearly defined and does not require any inference from the reviewer.", "grounding_specificity_rationale": "The review point refers to 'all parts of the proposed algorithmic pipeline' without specifying which part is being addressed. While the *concept* of an algorithmic pipeline is mentioned, the *specifics* of that pipeline are not identified. The reviewer doesn't pinpoint a unique section, table, or element of the paper. The comment lacks specificity regarding the *aspects* of the pipeline that require investigation.", "verifiability_rationale": "The review point presents a claim: 'Ablation studies are needed...'. However, it does not provide any justification or reasoning for why this is necessary. There is no logical explanation, common knowledge, or external references provided to support the suggestion. The claim is stated without any backing.", "helpfulness_rationale": "The review point identifies a potential weakness in the methodology (the lack of ablation studies) and suggests a concrete improvement (conducting ablation studies). This directly guides the authors towards investigating the necessity of each component in the algorithmic pipeline. The suggestion is actionable and addresses a specific area for improvement, making it 5 for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point is a question, not a direct instruction or recommendation. While it raises a valid point about the potential cost of instructiontuning, it does not explicitly state what action the authors should take or what they should do next. The reviewer is asking for clarification or further information rather than providing a clear, actionable step.", "grounding_specificity_rationale": "The review point explicitly mentions the 'instructiontuning stage' and 'taskspecific finetuning,' indicating a clear grounding in the specific aspect of the paper being discussed. It also raises a specific question about the potential cost difference, further emphasizing the specificity of the referenced part.", "verifiability_rationale": "The review point is a question about a claim (the necessity of the instructiontuning stage) but does not present any evidence or justification for that claim. It does not contain a claim that can be verified using logical reasoning, common knowledge, or external references. It's a question posed without any supporting arguments.", "helpfulness_rationale": "The review point is a question that highlights a potential concern (the added cost of instructiontuning) but does not directly offer a solution or a clear recommendation to the authors. While it raises a valid point, it doesn't provide actionable advice or guidance on how to address the concern. It's more of a request for clarification than a helpful suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the evaluation setup is outdated and suggests using more advanced models. This is a clear and direct action to improve the setup. The reviewer also identifies the specific models being criticized (Llama1 and Mistralv0.1) and suggests a specific improvement (testing on more challenging datasets). This makes the action both explicit and concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific models (Llama1 and Mistralv0.1) as being outdated. This demonstrates strong grounding as the author can accurately pinpoint the referenced part of the paper (the evaluation setup and the models used). Furthermore, the reviewer suggests a specific improvement (testing on more challenging datasets) and provides an example (instruction tuning on Alpaca/OASST), which clearly specifies what needs to be addressed. This combination of explicit identification and specific suggestions indicates high grounding specificity.", "verifiability_rationale": "The reviewer makes a claim that the evaluation setup is outdated. While the reviewer *suggests* using more advanced models, the initial point is a claim that is presented as a fact. The reviewer does not provide any external references or logical reasoning to support the claim that the current models are outdated. Therefore, while the reviewer identifies a problem and suggests a solution, the initial claim itself is not welljustified.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the evaluation setup (the use of outdated models) and provides a specific suggestion for improvement (testing on more advanced models and more challenging datasets). This actionable feedback is directly aimed at helping the authors improve their draft. The reviewer's suggestion is concrete and provides a clear direction for further evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem ('lack of logical coherence') but does not provide specific, actionable steps or suggestions on how to address it. It remains at a high level of generality.", "grounding_specificity_rationale": "The review point mentions the 'second section' but does not identify a specific subsection, table, figure, or unique element within that section as being problematic. The grounding is weak because the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point makes a claim ('lack of logical coherence') but does not provide any supporting evidence or justification for this claim. It lacks both logical reasoning and references to specific parts of the paper or external knowledge.", "helpfulness_rationale": "The review point identifies a weakness ('lack of logical coherence') in a specific section ('second section'). While it doesn't provide concrete suggestions for improvement, it highlights an area that needs attention and implies that this disorganization contributes to the content being 'somewhat disorganized'."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point is a request for clarification, not a directive with an explicit action. The author is asking *how* to access the posts, not what to do with them.", "grounding_specificity_rationale": "The comment is about Reddit posts, which are *external* to the paper itself. There's no mention of specific sections, tables, figures, or unique elements of the *paper* being discussed. The focus is on the *context* of the paper's discussion.", "verifiability_rationale": "The comment is a request for information, not a statement of opinion or claim. It doesn't make a judgment about the paper or suggest improvements based on evidence.", "helpfulness_rationale": "The comment seeks clarification on how to access Reddit posts. While it's a helpful step in the author's process of gathering information for their review, it doesn't directly address a weakness or suggest a concrete improvement to the paper itself. It's more of an internal process step."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a missing comparison. While it identifies a gap, it doesn't explicitly *tell the author* what to do. It's a *statement* of a problem, not a direct instruction for improvement. Therefore, it's not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions 'recent works' and '1' (assuming this is a specific citation). However, they don't explicitly state *which* recent works are missing or *why* they are relevant. The grounding is weak because the referenced works are not precisely identified. The specificity is also low as the mention of 'recent works' is general and lacks detail on the relevance to the paper's content.", "verifiability_rationale": "The review states a problem: 'The paper lacks comparisons with recent works'. This is a clear claim that something is missing. However, the reviewer does not provide any logical reasoning, examples, or references to support this claim. The verifiability is low because the claim is stated without sufficient evidence or justification.", "helpfulness_rationale": "The review identifies a valid weakness in the paper (lack of comparison with recent works). However, it does not offer any suggestions or guidance on how to address this weakness. It's a *statement* of a need for more comparisons, not a directive to make them. Therefore, it's not particularly helpful in providing actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is directly asking a question about the applicability of TSG in a specific scenario. The action is explicitly stated as 'Will TSG work...?' which is a clear and direct action the authors should take to understand the limitations of TSG.", "grounding_specificity_rationale": "The reviewer is specifically asking about diffusion models that 'do not embed class labels into timestep (for example, UViT)'. This is a very clear and explicit grounding of the discussion to a specific type of diffusion model and provides an example (UViT) to further pin down the context.", "verifiability_rationale": "The point itself is not a claim that needs verification. It's a question prompting for information about the applicability of TSG in a specific context. Therefore, it doesn't fall under the 'Verifiability' aspect which focuses on claims and supporting evidence.", "helpfulness_rationale": "While the question is relevant and asks a pertinent question about a potential limitation of TSG, it doesn't directly provide actionable advice or guidance on how to improve the draft. It's more of a diagnostic question than a prescriptive solution. Therefore, it's 3 in identifying a potential area for improvement, but not in providing concrete steps."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing components required for reproducibility: 'training code', 'dialogue dataset', and 'model checkpoints'. These are concrete actions that the authors should take to allow for verification of the claims and experimentation with the model.", "grounding_specificity_rationale": "The reviewer mentions 'training code', 'dialogue dataset', and 'model checkpoints' without specifying the exact section, table, figure, or unique aspect of the paper where these are located. While the terms are accurate, the lack of precise grounding makes it '2'.", "verifiability_rationale": "The review point contains a claim: 'Unless the authors release their training code, dialogue dataset, as well as model checkpoints, I find it very challenging to reproduce any of the claims in this paper.' This claim is not supported by any external references or logical reasoning within the review point itself. The reviewer is stating their expectation based on the lack of information.", "helpfulness_rationale": "The review point is 5 as it directly addresses a practical issue: the lack of reproducibility. By explicitly stating the missing components, the reviewer provides a clear and actionable direction for the authors to improve their draft and allow for verification of their claims."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The comment states a fact ('The main result is a bit obvious') but does not provide explicit instructions on how to act on this observation to improve the draft.", "grounding_specificity_rationale": "The comment refers to 'gradient boosting' and 'functional space' in general, without specifying a particular section, table, figure, or unique aspect of the paper. It does not clearly identify what is specifically wrong with this general statement.", "verifiability_rationale": "The comment contains a claim ('The main result is a bit obvious') that is supported by a reason ('since gradient boosting is minimizing objectives in functional space'). However, the claim is subjective, and the connection between the claim and the reason could be clearer.", "helpfulness_rationale": "The comment identifies a known property of gradient boosting but does not provide specific, actionable feedback on how this observation can be used to improve the authors' draft. It is more of a factual observation than a constructive suggestion for change."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer states the contribution is 'insufficient' and doesn't 'explicitly express' it. They also mention 'limited related work' and 'no appropriate analysis'. While the reviewer identifies a problem, they don't provide specific actions or concrete steps on how to address it. The actions are implied rather than explicitly stated.", "grounding_specificity_rationale": "The reviewer mentions 'contribution', 'related work', and 'analysis' generally, without specifying which part of the paper is lacking. They don't name a specific section, table, figure, or unique aspect of the paper. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer makes a claim that the 'contribution of this work is insufficient and is not explicitly expressed within the paper'. This is a clear statement of opinion. The reviewer then provides reasons why the contribution is insufficient, such as 'I regret to say that this work appears incomplete. The details provided in the paper do not adequately explain the specifics of the proposed model. There is limited related work mentioned, and no appropriate analysis is provided.' These reasons are logical and point to specific shortcomings in the paper's content, making the claim verifiable.", "helpfulness_rationale": "The reviewer's point highlights a significant weakness in the paper \u2013 the lack of clear information about its contribution and related work. This is a crucial piece of feedback for the authors. While the reviewer identifies the 'area' of weakness (contribution, related work, analysis), they don't explicitly state what the authors should do to address these issues. They point to where the information is missing, making the feedback somewhat general."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the issues with the figures (lack of clarity, missing labels) and suggests improvements. However, the specific actions or modifications needed are not detailed. For example, the reviewer mentions 'improve clarity' but doesn't specify how this should be achieved.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 2a' and 'Figure 2b' and mentions 'training steps'. While the figures are mentioned, the specific section or table within the paper being addressed is not explicitly identified. The reviewer also mentions 'training steps' but doesn't specify if this refers to outerloop iterations or raw experience, making it partially specified but not fully grounded. The issues raised (lack of clarity, missing labels) are specific to the figures, but the exact location within the paper is not.", "verifiability_rationale": "The reviewer presents the figures as evidence for their claim that the results are 'not clear' and 'not wellwritten'. However, the reasoning behind these claims is not explicitly provided. While the figures themselves can be considered implicit evidence, there are no external references or logical reasoning steps explicitly stated to support the assessment of the figures' clarity or writing quality.", "helpfulness_rationale": "The reviewer identifies issues with the figures and suggests improvements. However, the feedback provided is at a high level and lacks specific, actionable suggestions. For example, the reviewer states the figures are 'not clear' but doesn't suggest specific techniques to improve clarity or provide examples of what is unclear. The feedback is present but lacks concrete guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises a valid point about the potential inconsistency in using different computational metrics for cost across various hardware. While the question itself is direct, it requires the authors to infer the underlying issue \u2013 the potential ambiguity in cost measurement.", "grounding_specificity_rationale": "The reviewer explicitly states a potential inconsistency in cost measurement by highlighting the use of different hardwarespecific metrics. This directly points to a lack of clarity in how cost is defined or measured in the original paper, making the grounding explicit and specific.", "verifiability_rationale": "The reviewer's point is more of a question about the definition of 'cost' in the context of different hardware. It doesn't present a claim that can be verified with external evidence. It points to a potential ambiguity in the original paper's methodology, not a verifiable deficiency.", "helpfulness_rationale": "The review point is a valid observation about a potential inconsistency in cost measurement. However, it doesn't offer a concrete solution or actionable guidance for the authors. It's a question that could lead to clarification but doesn't actively improve the draft itself. Therefore, it's not 5 in terms of providing direct improvement guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point directly asks for specific implementation details regarding the Sinkhorn algorithm iterations and their impact on training speed. The reviewer explicitly states 'What is the maximum iterations you set in the experiment?' and follows up with 'Will these iterations significantly slow down the training speed?'. These are clear questions that authors can directly use to understand and potentially adjust their training parameters. The request is for concrete information that can be directly applied to their work.", "grounding_specificity_rationale": "The reviewer refers to 'this paper' and 'that paper' when asking about the Sinkhorn algorithm, indicating an attempt to ground the comment in the specific literature. While the initial references might be broad, the subsequent questions about the 'maximum iterations you set in the experiment' and their 'impact on training speed' are more specific. The reviewer is asking for details relevant to their own implementation and training process, showing an effort to provide targeted information. However, the initial grounding could be more precise by directly referencing the specific sections or algorithms discussed in the reviewed paper.", "verifiability_rationale": "The review point does not contain a claim in the sense of a statement requiring justification or proof. The reviewer is simply asking questions. Therefore, according to the provided definitions, the comment falls under 'X'. However, the reviewer's questions are framed in a way that implies a desire for verifiable information. They are asking for specific implementation details ('What is the maximum iterations you set in the experiment?') and the expected outcome of those details ('Will these iterations significantly slow down the training speed?'). This suggests a desire for information that can be verified or confirmed, even though no explicit claim is made.", "helpfulness_rationale": "The review point is asking for specific implementation details and their potential impact on training speed. This information can be directly used by the authors to understand their training process, potentially identify bottlenecks, and make informed decisions about their experimental setup. The reviewer is essentially providing guidance on how to optimize their training process based on the observed iterations. While not a direct critique or suggestion of improvement, the information provided can be very helpful for the authors to understand and potentially adjust their training parameters. The reviewer is prompting for actionable information."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the major weakness and suggests a specific improvement (theoretical results). The criticism is clear and points to a specific area for improvement.", "grounding_specificity_rationale": "The reviewer mentions \"the teacher policy's state action visiting distribution\" and \"the expert's distribution.\" While they don't explicitly name the sections or tables, they refer to specific components of the method. This is weak grounding. The reviewer clearly specifies the *type* of theoretical investigation they suggest (\"its output probability is used as the reward for the student policy. It is unclear whether the student policy can still perform correct distribution matching. I would like to see some theoretical results on this.\"). This is highly specific regarding the suggestion, but the grounding of the concept is weaker.", "verifiability_rationale": "The reviewer makes a clear claim about a potential weakness in the method. However, they do not provide any evidence or justification for their claim. They state the *potential problem* but don't explain *why* it's a problem or how the current approach might be flawed. They also don't suggest any *specific experiments* to test their hypothesis. The claim is stated without supporting evidence or reasoning.", "helpfulness_rationale": "The reviewer's suggestion is vague. While they identify a potential issue, they don't explain *why* it's a problem, *how* the current method might be flawed, or *what specific steps* the authors should take to address it. This makes it difficult for the authors to act on the suggestion. The criticism lacks concrete details and actionable steps, making it less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'reasons should be analyzed and discussed.' This is a clear action item for the authors to improve their draft. The reviewer identifies that the proposed method does not perform well in some classes, indicating a lack of clarity or detail in those areas. While the action is stated, the reviewer does not specify *how* to analyze or discuss the results, making it less concrete.", "grounding_specificity_rationale": "The reviewer mentions 'Table 3' and 'some classes' in their review point. This demonstrates strong grounding as the authors can accurately pinpoint the section and table being addressed. However, the reviewer does not specify *which* classes are problematic, making the grounding less specific regarding the nature of the poor performance.", "verifiability_rationale": "The reviewer makes a claim: 'the proposed method does not perform well in some classes.' This is a statement that requires justification. The reviewer suggests 'reasons should be analyzed and discussed' as a next step. While this provides a direction for further investigation, it does not provide specific examples, references, or logical reasoning within the review point itself to support the claim. Therefore, it is not 5.", "helpfulness_rationale": "The reviewer identifies a weakness in the experimental results ('the proposed method does not perform well in some classes') and suggests a direction for improvement ('reasons should be analyzed and discussed'). This provides a clear indication of an area that needs attention and encourages further investigation. However, the reviewer does not provide specific guidance on *how* to analyze or discuss the results, making the feedback somewhat general and less directly actionable for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the action to take ('test MTT on unseen tasks') and provides a clear, actionable step. There's no ambiguity about what needs to be done.", "grounding_specificity_rationale": "The reviewer doesn't explicitly state which section or table contains the MTT description, relying on the assumption the reviewer knows where to find it. While the *area* of improvement (testing on unseen tasks) and the *general* direction of analysis (variation under different settings) are suggested, the specific tasks and datasets are not named, making it underspecific.", "verifiability_rationale": "The reviewer makes several suggestions that are generally valid points in research and offer directions for improvement. While not backed by specific evidence *within this review point*, they are plausible and actionable.", "helpfulness_rationale": "The reviewer provides clear suggestions for improving the experimental design (testing MTT on unseen tasks) and the analysis (further discussion of results). While not explicitly pointing out a specific weakness, the suggestions are generally helpful for improving the overall quality of the work."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point is a statement about a potential issue (lack of randomization) rather than a direct instruction on how to address it. While it implies a need for checking, it doesn't explicitly state what needs to be done. Therefore, it is 2 as it points to an action but lacks explicit guidance on how to implement it.", "grounding_specificity_rationale": "The reviewer is discussing a potential methodological issue (learning effects) related to the data collection process for the 5 layouts. They are not explicitly pointing to a specific part of the paper or a specific detail within the current draft that needs addressing. The grounding is in the *process* of data collection rather than a specific element of the paper. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer states a potential issue (learning effects) but does not provide any evidence, citations, or logical reasoning to support this claim. There is no verification provided for the existence or impact of learning effects in this context. Therefore, the claim is 1.", "helpfulness_rationale": "The review point raises a potential methodological concern (lack of randomization) that could affect the validity of the results. However, it does not directly provide the authors with a solution or actionable steps to address this issue. It highlights a potential problem but doesn't offer a constructive suggestion. Therefore, it is 3 in identifying a potential area for improvement in their methodology, but it doesn't directly help them improve their current draft. The helpfulness is limited as it's a metacomment about the data collection process rather than a direct suggestion for improvement of the draft itself."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states their lack of understanding regarding the role of node ordering. While they identify a potential issue, they do not explicitly state what the problem is or how it should be addressed. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer mentions 'random ordering of the atoms in a specific point in the composition space' and 'node ordering'. While they point to a specific area, they do not clearly define the issue within that area. The grounding is weak because the authors cannot confidently determine which part the comment addresses. The specificity is also low as the comment does not detail what needs to be addressed in this part.", "verifiability_rationale": "The reviewer states their lack of understanding regarding the role of node ordering. This constitutes a claim that needs to be supported. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support their claim. The claim is presented without sufficient justification or evidence.", "helpfulness_rationale": "The reviewer's comment directly points to a lack of understanding the authors might have. By highlighting a specific area of confusion, the reviewer is providing a clear point for the authors to seek clarification. This directly helps the authors improve their draft by addressing a specific gap in their knowledge."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment includes an implicitly stated action or an action that can be inferred. However, the action itself is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The authors cannot confidently determine which part the comment addresses. Further, the comment does not specify what needs to be addressed in this part.", "verifiability_rationale": "The claim contains a claim (i.e., an opinion, judgment, or suggestion) that goes beyond merely stating facts. However, it does not specify what needs to be addressed in this part.", "helpfulness_rationale": "The comment fails to identify meaningful weaknesses or suggest improvements, leaving the authors with no actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies weaknesses in the dataset selection and splitting procedures, which are implicit actions. The reviewer suggests providing more clarity on the pool of datasets, selection criteria, and the rationale behind the chosen splitting method. These are actionable suggestions that guide the authors on how to improve their methodology. While not explicitly stating the exact steps to take, the reviewer points out areas where more detail is needed, which is a form of actionable feedback.", "grounding_specificity_rationale": "The review point does not explicitly mention any specific part of the paper (e.g., a particular section, table, or figure) in relation to the dataset selection or splitting procedures. The reviewer's suggestions are general and apply to the overall methodology. Therefore, the grounding specificity is low as the authors cannot pinpoint the exact area being addressed.", "verifiability_rationale": "The review point identifies weaknesses in the dataset selection and splitting procedures but does not provide any external references or logical reasoning to support these criticisms. The reviewer suggests providing details on the pool of datasets and the selection process, which are generally accepted practices but lack specific citations within this context. The criticism is based on the reviewer's experience and understanding of standard practices, but without explicit references within the review point itself, it is not 5.", "helpfulness_rationale": "The review point directly addresses significant weaknesses in the authors' methodology, specifically the lack of clarity in dataset selection and splitting procedures. The reviewer provides clear suggestions for improvement, such as specifying the pool of datasets, the selection criteria, and the rationale for the chosen splitting method. These suggestions are actionable and would significantly enhance the authors' understanding and the reproducibility of their work. While the reviewer doesn't offer a completely new method, the identification of the missing information is a valuable contribution to the authors' process."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the 'lack of a critical comparison' in the ablation study as a significant weakness. They clearly identify the missing baseline as a model that has already been refined with efficient architectural changes and then undergoes either consistency or progressive distillation. This is a direct and observable criticism of the experimental setup. While the core idea of the ablation study (efficient model) might be present, the reviewer correctly points out the missing crucial element of comparison against a relevant baseline.", "grounding_specificity_rationale": "The reviewer's point about the missing baseline is not about weak grounding. They are clearly identifying a specific part of the paper (the ablation study) and pointing out what *should* be discussed within that section. The comment is directly addressing a specific aspect of the work, indicating strong grounding in terms of identifying the relevant section. The criticism is about the *content* of that section, not the *identification* of the section itself.", "verifiability_rationale": "The reviewer makes a claim about the *relevance* of the missing baseline to the ablation study. This claim is wellsupported by the logic of benchmarking against a more informed starting point (an already efficient model) rather than a random one. The reviewer provides a clear reasoning for why this comparison is important. The claim is specific and directly addresses a potential flaw in the experimental design. The evidence provided by the reviewer is logical and directly supports the claim.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improving the ablation study. They propose a specific baseline that would allow for a more meaningful comparison and potentially lead to more robust conclusions. This criticism directly points to a concrete and beneficial change that could be made to the work. The suggestion is specific and directly addresses a potential weakness in the experimental design. The reviewer's comment is not just a critique but also a potential solution, making it 5 for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "1 and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a potential issue with the tasks but lacks explicit and concrete actions the authors should take. It implies improvements but doesn't specify how or what to change.", "grounding_specificity_rationale": "The review point doesn't explicitly identify which tasks are problematic or suggest improvements to specific parts of the paper. It makes a general observation about the difficulty of the tasks.", "verifiability_rationale": "The review point contains a claim about the difficulty of the tasks but doesn't provide any evidence or reasoning to support it. The suggestions for referencing other projects are potential improvements, not verifiable claims about the current paper.", "helpfulness_rationale": "The review point points out a potential issue and suggests a general direction for improvement, but it lacks specific, actionable steps for the authors to take."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a potential issue ('The comparison in Table 2 is a bit unfair') and links it to a specific detail ('the training data size of LEPA'). This is an explicit statement of a problem. The comment also mentions 'the 'Without Plan/Without SelfReflection' settings', providing a specific target for the comparison. Therefore, the action is clearly identified and the action itself is identified. The comment also provides a reason ('likely') for why the comparison might be unfair, making it more than just identifying the problem.", "grounding_specificity_rationale": "The comment explicitly mentions 'LEPA's training data' and 'the 'Without Plan/Without SelfReflection' settings in the context of Table 2. This directly identifies the specific part of the paper being addressed. The comment is fully grounded because it names the specific elements being compared. The comment also clearly specifies what is being criticized ('the comparison in Table 2 is a bit unfair'), detailing the issue within the mentioned parts.", "verifiability_rationale": "The comment contains a claim ('The comparison in Table 2 is a bit unfair'). The comment also mentions a potential reason for the unfairness ('the training data size of LEPA is likely bigger') and references lines 349360 and the LUMOS paper. However, it does not provide direct evidence or logical reasoning to definitively prove that LEPA's training data is indeed larger. The reference to LUMOS is a potential external reference, but its effectiveness depends on the reader's access and understanding. Therefore, the claim is supported by an inference and potential external information, making it 3.", "helpfulness_rationale": "The comment raises a valid concern about a potential unfair comparison in the experimental setup due to the likely larger training data size of LEPA. While the comment doesn't offer specific solutions or modifications to the experimental design, it points out a potential flaw that could affect the validity of the results presented in Table 2. By highlighting this issue, the reviewer provides the authors with a direction to investigate and potentially address the problem. This level of detail is better than doing nothing and demonstrates an understanding of the experimental context. Therefore, the review provides some helpful direction, but it lacks concrete suggestions for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests using the GLUE benchmark and mentions the lack of real datasets, making it actionable. While the suggestion could be phrased more directly, the reviewer implies a clear need for improvement in the experimental setup.", "grounding_specificity_rationale": "The review point mentions the lack of real datasets and suggests using the GLUE benchmark, which is specific. However, it doesn't explicitly identify a section or table in the paper being addressed, leading to weak grounding.", "verifiability_rationale": "The review point contains a claim about the lack of real datasets and provides reasoning for this, making it verifiable. The suggestions for improvement are logical and point to established benchmarks.", "helpfulness_rationale": "The review point is directly relevant to the experimental setup, identifies a limitation, and offers concrete, actionable suggestions, making it 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the action needed: 'add details' and specifies where these details should be added: 'main paper'. The action is concrete, indicating exactly what the authors should do. The phrase 'solve the optimization' implies a need for explanation or additional information to address the optimization problem.", "grounding_specificity_rationale": "The review point mentions 'optimization' and 'main paper', but it does not specify which optimization or which section of the main paper should be addressed. The grounding is weak because the reviewer cannot confidently determine the exact part of the paper being addressed. While the reviewer implies the need for more information, they don't pinpoint the exact location or nature of the missing details within the main paper.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion or request for the authors to add more information. There is no logical reasoning, common knowledge, or external references provided to support the suggestion itself. The reviewer is stating what the authors should do, not what needs to be proven or justified.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper (lack of details on optimization) and provides a specific action for the authors to take (add those details to the main paper). This is a helpful suggestion as it directly addresses a concrete issue and guides the authors in improving their work. While it doesn't specify *how* to solve the optimization, it clearly points in the direction of providing more information, which is a valuable piece of feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the exclusion of specific models but does not provide any explicit or implicit action for the authors. It does not tell them *how* to address this or what to do next. The reviewer is expressing a concern, not a directive.", "grounding_specificity_rationale": "The reviewer mentions 'LLaVAseries and QwenVL' generally, without specifying *why* they are excluded or *where* in the evaluation they relate. The authors cannot pinpoint the specific aspect of the evaluation that these models are intended to address. The grounding is weak because the authors are not directed to a specific section or table.", "verifiability_rationale": "The reviewer states a fact ('These are commonly adopted LVLMs') but does not provide any logical reasoning, common knowledge, or external references to support their exclusion. The claim is presented without sufficient evidence or justification. There is no clear verification process described.", "helpfulness_rationale": "The review point is about the evaluation process itself, not about specific weaknesses in the paper being evaluated. It's a metacomment about the evaluation methodology. While it raises a valid concern, it doesn't directly contribute to improving the paper's content or methodology. The helpfulness is limited because it doesn't directly address the paper's weaknesses."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states an action: 'should also include'. However, it lacks specific details on *which* captions/descriptions or *how many* OCR datasets to include. The action is stated, but the implementation is vague.", "grounding_specificity_rationale": "The review point does not specify a particular section, table, figure, or any unique element of the paper where the suggested improvements are needed. It is a general suggestion to include captions and OCR datasets.", "verifiability_rationale": "The review point is a suggestion for improvement rather than a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support the suggestion itself.", "helpfulness_rationale": "The review point suggests adding captions and OCR datasets, which are relevant and potentially beneficial for improving the paper's clarity and completeness. While the specifics are missing, the direction of improvement is clear."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the contradiction between Assumption 3.1 and eqn. 7. They clearly identify the action needed: that eqn. 7 should align with the assumption. The reviewer also points out the lack of clarity in the relationship between TKD and IYOR, implying a need for clarification. The reviewer's suggestion is direct and actionable, indicating a clear understanding of the issue and a concrete path for improvement. The reviewer's comment directly identifies a flaw and suggests a specific correction, making it 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Assumption 3.1' and 'eqn. 7', demonstrating a clear and precise identification of the specific parts of the paper being addressed. This strong identification of the relevant sections and the specific issue within them constitutes full grounding. The reviewer also points out the *type* of claim being made in each (assumption vs. equation defining the relationship), further enhancing the specificity. The reviewer's comment is not just about identifying a section, but about identifying the *nature* of the problem within that section.", "verifiability_rationale": "The reviewer makes a clear claim: that eqn. 7 contradicts Assumption 3.1. They provide evidence for this claim by stating the assumption and pointing to the equation. The reviewer suggests a resolution: that eqn. 7 should align with the assumption. This claim is verifiable through a logical comparison of the statements in Assumption 3.1 and eqn. 7. The reviewer provides the necessary information to understand the contradiction and the desired consistency. The reviewer's comment is a clear statement of a problem and a suggestion for a solution based on logical consistency, making it 5.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential inconsistency in the paper's treatment of the relationship between TKD and IYOR. They clearly state the contradiction and suggest a specific change (eqn. 7 should align with the assumption). This is a 5 and constructive suggestion that directly improves the clarity and consistency of the paper. The reviewer's comment is clear, specific, and directly addresses a potential problem, making it 5 for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question about the clarity of weaknesses, not a direct instruction for the author to make improvements. It asks 'It is not clear if question 3 (weakness 2 and 4) mentioned above indicates other limitations.' This is a statement of uncertainty, not an explicit action or suggestion.", "grounding_specificity_rationale": "The review point refers to 'question 3 (weakness 2 and 4)'. While it mentions a question number, it does not explicitly identify the specific section, table, figure, or unique aspect of the paper that this question refers to. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point is a statement of opinion: 'It is not clear if question 3 (weakness 2 and 4) mentioned above indicates other limitations.' This is a subjective assessment and does not contain a claim that requires verification or justification. It is a question, not a claim.", "helpfulness_rationale": "The review point is a question about the clarity of weaknesses, not a suggestion for how to improve the paper. It does not provide any actionable feedback or guidance to the authors on how to address the identified issue. The value is in identifying a potential problem, but not in offering a solution."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point directly asks a question about a design choice (using lastlayer hidden states) and proposes an alternative (middle layers) based on a stated benefit (probing). This constitutes an implicit suggestion for improvement and a clear direction for the authors to explore an alternative approach. The reviewer is essentially asking for clarification and a potential avenue for improvement, which is a form of actionable feedback.", "grounding_specificity_rationale": "The review point mentions 'middle layers' as an alternative to 'lastlayer hidden states' but does not explicitly refer to a specific section, table, or figure in the paper where this discussion should take place. The justification is general ('a number of works has identified').", "verifiability_rationale": "The review point presents a suggestion rather than a claim. It proposes exploring middle layers as an alternative to lastlayer hidden states but does not provide a definitive justification or evidence for why middle layers are superior in this specific context. It lacks external references or logical reasoning to support the suggestion.", "helpfulness_rationale": "The review point is 5 because it identifies a potential weakness or area for improvement (the use of lastlayer hidden states) and offers a clear suggestion for the authors to consider (exploring middle layers). The reviewer is directly prompting the authors to investigate an alternative approach based on established benefits, which is a valuable piece of feedback. The suggestion is actionable and directly addresses the question posed."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of motivation in terms of use cases, which directly relates to the paper's objectives and significance. They also state that using GUE to determine the model architecture and training objective seems arbitrary and incongruous, which is an explicit action identifying a problem with the methodology. Furthermore, they point out that the learned representations are optimized for a narrow set of tasks, indicating a lack of generalizability, which is another explicit action highlighting a limitation. All these points are concrete and directly address the paper's content.", "grounding_specificity_rationale": "The reviewer broadly criticizes the methodology and its connection to the evaluation framework (GUE) without specifying which part of the paper they are referring to. They mention 'using GUE to determine which tokenization, model architecture, and training objective to be used for the generative model' but do not pinpoint the exact section or concept being criticized. While the implications of this choice are discussed, the initial statement lacks a clear reference point within the paper.", "verifiability_rationale": "The reviewer makes claims about the limitations of the methodology and evaluation, such as 'seems arbitrary and potentially incongruous' and 'will be optimized for the relatively narrow set of tasks presented in GUE, and may have very little generalizability'. While these claims are supported by logical reasoning (the potential mismatch between the evaluation framework and the model's learned representations), they lack specific examples or citations to external works to back them up. The reasoning is present, but the evidence is missing, making it 3.", "helpfulness_rationale": "The reviewer provides a clear critique of the methodology and its limitations, highlighting the lack of motivation and the potential lack of generalizability. While they identify significant shortcomings, they do not offer specific suggestions or actionable improvements. The feedback is diagnostic but lacks prescriptive elements, making it 3. The reviewer's point is valuable in pointing out areas for improvement, but it doesn't directly guide the authors on *how* to fix the issues."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem ('clunkily') and suggests a solution ('major editing pass'). While it mentions the need for editing, it doesn't explicitly state what needs to be edited or how to go about it. The action is implied but not stated directly.", "grounding_specificity_rationale": "The comment is very general and does not specify which parts of the paper are 'clunkily' written or what specific issues need addressing. It lacks any reference to a particular section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The comment states a problem ('clunkily') and suggests a solution ('major editing pass'). However, it does not provide any specific evidence or justification for why the writing is clunky or why editing is necessary. It's a statement of desire, not a claim backed by observation or analysis.", "helpfulness_rationale": "The comment identifies a problem ('clunkily') and suggests a general solution ('major editing pass'). While it points to an area for improvement, it lacks specific details on what needs to be edited or how to achieve the desired outcome. The author is left with a broad instruction without concrete guidance."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses several specific questions about the theoretical properties and assumptions of the SITE estimator and the implications of the implicit objective function. These questions directly relate to the method and its potential limitations, providing clear opportunities for the authors to consider and potentially improve their approach. The reviewer is explicitly asking for information that can directly impact their understanding and application of the method.", "grounding_specificity_rationale": "The reviewer's questions are about the general properties of the SITE estimator and the objective function. They do not explicitly point to a specific section, table, or figure of the paper being addressed. The questions are more about the theoretical underpinnings rather than a direct reference to a particular aspect of the work.", "verifiability_rationale": "The reviewer is posing questions about the validity and assumptions of the SITE estimator and the objective function. While these questions are relevant to understanding the method, they do not present a claim that requires verification based on logical reasoning, common knowledge, or external references. The questions are more about seeking clarification of concepts than validating a statement.", "helpfulness_rationale": "The review point raises several relevant questions about the theoretical properties and assumptions of the SITE estimator and the implicit objective function. While these questions are valuable for understanding the method, they do not directly point out a specific weakness in the authors' current work or suggest a concrete improvement. The feedback is more about seeking clarification than providing actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about a potential limitation: 'Is Objectlevel Understanding capable of handling interactive segmentation for multiple objects simultaneously?' and proposes a hypothesis: 'Since Objectlevel Understanding relies on Mask Guidance from previous interactions, if the target object changes between clicks, OIS may struggle to shift focus to the new target due to constraints from the previous mask.' While the reviewer identifies a potential issue, the suggested action is not explicitly stated. The reviewer doesn't provide a concrete step the authors should take to address this limitation.", "grounding_specificity_rationale": "The review point mentions 'Objectlevel Understanding' and 'interactive segmentation for multiple objects simultaneously'. However, it does not explicitly identify a specific section, table, or unique aspect of the paper being addressed. The connection to 'Mask Guidance from previous interactions' is implied but not directly linked to a specific element in the paper.", "verifiability_rationale": "The review point contains a claim: 'This limitation could reduce the method's practical utility.' However, the reviewer does not provide any specific evidence or references within the review point to support this claim. The explanation is based on a hypothesis rather than verified information.", "helpfulness_rationale": "The review point raises a valid concern about a potential limitation of the Objectlevel Understanding method regarding its ability to handle interactive segmentation for multiple objects simultaneously. The reviewer suggests that the reliance on Mask Guidance from previous interactions might lead to difficulties when the target object changes between clicks. This raises a practical concern for users of the method and provides a clear area for the authors to investigate and potentially address."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a limitation of the proposed system by stating, 'the assumption that these anomalies would be aligned with concepts.' While this is a valid point, the reviewer does not explicitly state how this alignment should be achieved or what specific actions need to be taken. The statement identifies a problem but lacks concrete action. The reviewer also mentions, 'How realistic is this assumption? The knowledge of concepts implies that the user know a lot about the domain.' This is a question about the actionability of aligning anomalies with concepts, not a direct action itself.", "grounding_specificity_rationale": "The reviewer states, 'Anomaly detection systems are usually used in scenarios, where the type of anomalies is not known.' This statement is not directly tied to a specific part of the paper or system being reviewed. While the reviewer later connects this to 'concepts,' the initial statement is general. However, the reviewer then says, 'For example many intrusion and fraud detection systems have some anomaly detector to detect anomalous samples, which are rare and might be attacks.' This provides a specific example, grounding the discussion in a practical scenario. The reviewer also mentions, 'But the proposed system assumes that these anomalies would be aligned with concepts.' This is a direct statement about the alignment of anomalies with concepts, which can be considered a specific part of the system's functionality. The reviewer further elaborates, 'How realistic is this assumption? The knowledge of concepts implies that the user know a lot about the domain.' This provides a specific explanation of the implication of the assumption.", "verifiability_rationale": "The reviewer states, 'Anomaly detection systems are usually used in scenarios, where the type of anomalies is not known.' This is a factual statement. The reviewer then says, 'For example many intrusion and fraud detection systems have some anomaly detector to detect anomalous samples, which are rare and might be attacks.' This provides a specific example, making the claim more verifiable. However, the reviewer does not provide external references or logical reasoning to support the claim that 'But the proposed system assumes that these anomalies would be aligned with concepts.' This assumption is presented without further justification or evidence.", "helpfulness_rationale": "The reviewer raises a critical question about the core assumption of the proposed system: 'How realistic is this assumption? The knowledge of concepts implies that the user know a lot about the domain.' This question directly challenges a fundamental aspect of the system's design and its applicability. The reviewer further asks, 'The proposed system assumes that these anomalies would be aligned with concepts. How realistic is this assumption? The knowledge of concepts implies that the user know a lot about the domain.' This question is insightful and directly addresses a potential limitation. The reviewer also states, 'The knowledge of concepts implies that the user know a lot about the domain.' This is a valid point that highlights a potential requirement for domain expertise. The reviewer concludes with, 'The proposed system assumes that these anomalies would be aligned with concepts. How realistic is this assumption? The knowledge of concepts implies that the user know a lot about the domain.' This reinforces the core point and its implications."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'I\u2019d like to see the authors also include a discussion...'. This action is further specified by naming the areas that need discussion: 'limitations/challenges of HLOP', 'experimental design', 'downsides of HLOP', and 'limitations of the evaluation process'. The action is not just a general suggestion but a concrete instruction on what kind of discussion is desired. Therefore, the action is explicitly stated and concretely defined.", "grounding_specificity_rationale": "The review point explicitly mentions specific areas of the paper that require discussion: 'limitations/challenges of HLOP', 'experimental design', 'downsides of HLOP', and 'limitations of the evaluation process'. This indicates that the reviewer can accurately pinpoint the sections or aspects of the paper being addressed. While the reviewer does not provide specific examples within these areas, the identification of the sections themselves is a clear indication of grounding. Therefore, the comment explicitly mentions which part of the paper it addresses, and it is obvious to the authors. The comment specifies what needs to be addressed in this part.", "verifiability_rationale": "The review point contains a claim in the form of a suggestion: 'I\u2019d like to see the authors also include a discussion...'. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support why this discussion is needed or beneficial. The statement is presented as a request for improvement without any backing. Therefore, the claim is present but not verifiable by the provided evidence.", "helpfulness_rationale": "The review point is 5 because it directly addresses potential weaknesses the authors might have regarding HLOP and the evaluation process. By explicitly stating the need for a discussion on limitations and challenges, the reviewer guides the authors to areas where their work might be lacking or unclear. This is a valuable piece of feedback that directly points to actionable improvements for the authors. The request is clear and directly addresses potential gaps in the authors' understanding or the paper's presentation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point does not identify a specific weakness or problem in the current draft. It suggests an *action* for the authors to take (evaluate on newer LMs) but does not critique the existing evaluation process or identify a flaw that needs addressing within the current work.", "grounding_specificity_rationale": "The review point explicitly states the *ground* for the suggested evaluation: 'Many more language models have been released after GPT2... FlanT5 (Scaling InstructionFinetuned Language Models) and/or Llama.' This clearly identifies the specific models being referenced. It also * specifies the *purpose* of the suggested evaluation: 'Evaluating the effectiveness of the proposed gating scheme on these recently proposed LMs' which clearly states what needs to be done with this information.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for the authors to perform an additional evaluation, not a statement that needs to be supported by evidence or reasoning within the current work.", "helpfulness_rationale": "The review point suggests a valuable next step for the authors: evaluating their gating scheme on recently released language models. This is a concrete suggestion that, if followed, could potentially improve the paper's contribution. While it doesn't directly improve the current draft, it provides a clear direction for future work, making it helpful in the context of guiding the authors' research and development."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point is a statement of opinion ('Some more recent works... need to be cited...'). It doesn't explicitly tell the author what to do or how to improve their method. While it implicitly suggests a need for citations, the action of citing is not concretely defined. Therefore, it is not 5. The action is implicit but vague.", "grounding_specificity_rationale": "The review point states 'Some more recent works... need to be cited...'. The reviewer identifies the 'recent works' as the specific part of the paper being addressed. However, they do not specify which recent works or provide any details about why they are relevant or need to be cited. Therefore, the grounding is weakly implied but not fully specific.", "verifiability_rationale": "The review point contains a claim ('Some more recent works... need to be cited...'). However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion to cite recent works is presented as a potential improvement without any justification. Therefore, the claim is 1.", "helpfulness_rationale": "The review point suggests citing some recent works to address potential similarities with the proposed method. While this points towards a helpful direction, it does not provide specific guidance on which works to cite or how to perform the citation. The suggestion is vague and lacks concrete details, making it not 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests adding detail about UNK handling and citing a strategy, which is an implicit action. However, the specifics of how to handle UNKs or the benefits of a dictionarybased strategy are not provided, making the action vague. The reviewer also suggests a citation, which is a concrete action, but the lack of justification for *why* this is needed makes the overall actionability borderline.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'how UNKs are being handled by the neural decoder' and 'dictionarybased strategy'. This directly points to specific parts of the paper and details what needs to be addressed, indicating strong grounding. They also suggest a 'citation', which is a specific action related to a part of the paper.", "verifiability_rationale": "The reviewer states a suggestion (adding detail or citing a strategy) without providing any justification or evidence. There is no logical reasoning, common knowledge, or external references provided to support why this suggestion is necessary or beneficial. The claim is made without sufficient support.", "helpfulness_rationale": "The reviewer points out a potential lack of clarity for the authors regarding UNK handling and citations. This directly addresses a potential information gap and could be helpful for the authors to understand the methodology better. While the reviewer doesn't provide specific solutions, they identify an area where the authors might need more information, which is generally helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests comparing 'Other SOTA code summarization methods, like using pretrained models' to the existing methods. This is a clear and direct action that the authors should take. While the suggestion is broad, it is still an explicit instruction, indicating a desire for a comparison.", "grounding_specificity_rationale": "The review point explicitly mentions the area of 'code summarization methods,' which grounds the comment to a specific part of the paper. However, it does not specify which SOTA methods or how this comparison should be conducted. The specificity of the action is limited.", "verifiability_rationale": "The review point makes a recommendation ('should be compared') which can be considered a claim. While the suggestion is implied (a logical next step in evaluating summarization methods), it lacks explicit justification or references to external works. The reasoning is based on the absence of a comparison in the current experiments.", "helpfulness_rationale": "The review point directly recommends comparing 'Other SOTA code summarization methods, like using pretrained models' to the existing methods. This is a clear and actionable suggestion that directly addresses a potential weakness in the experimental setup and provides a concrete direction for improvement. It is helpful because it guides the authors on what to investigate further."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the questions and concerns regarding the results in Table 3, specifically asking 'In the Table 3, the result of Scheduled Bernoulli on RTE is even better than AttendOut. What is the reason that AttendOut has lower variance?' and 'What is the statistical significance value when comparing Scheduled Bernoulli and AttendOut?'. These are direct and clear actions the reviewer is taking based on the paper's content.", "grounding_specificity_rationale": "The reviewer refers to 'Table 3' and specifically mentions 'attend_out' and 'scheduled_bernoulli' methods. This provides a clear grounding of the issue. They are also asking specific questions about the variance and statistical significance of these methods within the table. The references are explicit and point to specific elements of the paper.", "verifiability_rationale": "The reviewer makes a claim about the discrepancy in variance and the need for statistical significance. They are asking for a justification of this claim. While the request for a 'specific' statistical significance value suggests a need for more detailed information, the underlying claim about the variance discrepancy is verifiable by examining the data in Table 3 and potentially applying statistical tests. The reasoning, though not explicitly detailed in the review point itself, is implied to be the standard statistical methods for comparing means.", "helpfulness_rationale": "The reviewer is pointing out a potential issue with the presented results in Table 3. While they are asking for more information (variance and statistical significance), they are not directly providing actionable improvements or suggestions based on this observation. The review is primarily about identifying a lack of clarity and requesting further analysis, rather than offering concrete guidance on how to improve the methods or results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a specific suggestion (using different prediction lengths) that directly addresses the issue of 'longterm forecasting'. The suggestion is clear and actionable, indicating a direct understanding of how to improve the experimental setup. The reviewer implies that the current prediction lengths are not appropriate for the claim of longterm forecasting and offers a concrete alternative.", "grounding_specificity_rationale": "The reviewer explicitly states the specific prediction lengths they believe are more appropriate for 'longterm forecasting'. This demonstrates strong grounding as the authors can directly identify the referenced part of the paper (the prediction lengths) and understand the issue being pointed out. The reviewer provides concrete examples of the suggested lengths, further enhancing the grounding.", "verifiability_rationale": "The reviewer makes a claim that the current prediction lengths do not reflect 'longterm forecasting' and suggests using alternative lengths. This claim is verifiable by examining the original dataset or the experimental setup to confirm the intended time frame. The reviewer provides specific examples of the suggested prediction lengths, which helps in verifying the claim and understanding the intended scope of 'longterm'.", "helpfulness_rationale": "The reviewer's comment is 5 as it directly addresses the validity of the 'longterm forecasting' claim by suggesting a change in the experimental setup. The specific alternative prediction lengths provide a clear and actionable direction for the authors to improve their draft. This comment is not just critical but also constructive, offering a concrete improvement suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment does not explicitly state an action or suggestion for the authors. While it points to a potential issue in the paper, it doesn't tell the authors what to do or how to address it. The reviewer is questioning the plausibility of a scenario described in the paper, but doesn't provide concrete steps for the authors to take.", "grounding_specificity_rationale": "The comment mentions 'a sample' and 'an equation,' which grounds the discussion to a specific aspect of the paper. However, it does not specify *which* sample or *which* equation is being referred to. The reviewer is discussing a general issue related to a sample and an equation, but lacks the specificity to pinpoint the exact location. Therefore, it can be considered 'Weakly Grounded'.", "verifiability_rationale": "The comment contains a claim: 'The difference between the confidence and the accuracy for one sample is not reasonable when using it in Eq.' However, it does not provide any justification or evidence to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the difference is 'not reasonable'. The reviewer is raising a concern but doesn't explain why it's an issue or what should be done. Therefore, the claim is '1'.", "helpfulness_rationale": "The comment identifies a potential issue in the paper by pointing out a discrepancy between confidence and accuracy in an equation. However, it does not provide any guidance or suggestions on how to address this issue. The reviewer is raising a concern but doesn't offer concrete steps or insights for the authors to follow. Therefore, the comment is '2' as it points to a problem but lacks actionable advice."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their desire for an alternative method to account for distribution shifts. This is a clear and actionable suggestion for improvement. The reviewer identifies a limitation of the existing method and proposes a concrete direction for addressing it.", "grounding_specificity_rationale": "The reviewer refers to a 'specific statistical method' (calculating divergence using residuals) and the need to 'account for the shift'. While they don't provide the exact formula or implementation details, the context strongly implies they are referring to a specific method. The issue of 'distribution shift' is also a specific and welldefined problem. Therefore, the reviewer's reference is grounded and specific.", "verifiability_rationale": "The reviewer makes a statement about the limitations of the existing method and the need for an alternative. This statement, while a question, implies a potential claim that can be supported by literature on domain adaptation or transfer learning. If the reviewer were to provide a specific solution, the claim would be 5. As it stands, the reviewer's statement itself points towards a verifiable claim.", "helpfulness_rationale": "The reviewer's suggestion to 'adopt the method to account for the shift' is a highly relevant and actionable improvement. It directly addresses the identified limitation of the existing method and offers a concrete direction for enhancing the authors' work. The suggestion is clear and directly addresses the problem."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests including a runtime comparison, which is a relevant improvement for deep learning methods. However, it lacks specific details on how to implement this comparison, making it less actionable. The reviewer implies the authors should perform this comparison but doesn't specify the methods, datasets, or evaluation metrics.", "grounding_specificity_rationale": "The comment suggests including a runtime comparison of different deep learning methods. While it implies the authors should consider this, it doesn't explicitly identify a specific part of the paper where this information is needed or how it would address a current issue. The reviewer assumes the authors will find this relevant, but the comment doesn't pinpoint the exact location or problem.", "verifiability_rationale": "The comment is a suggestion for improvement rather than a claim that can be verified. It doesn't provide any evidence or reasoning to support why a runtime comparison should be included. It's a desire, not a statement that can be logically proven or supported by external references.", "helpfulness_rationale": "The comment is relevant to the evaluation of deep learning methods, as runtime is a crucial factor for practical applications. However, the suggestion is quite general and lacks specific details, making it less immediately helpful. The reviewer doesn't specify which methods to compare, how to measure runtime, or what datasets to use, leaving the authors with a broad but unguided direction."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the current architecture and suggests comparing it to other architectures. While they don't provide specific implementation details of the current architecture, the suggestion to compare is a clear action the authors can take. The reviewer also draws an analogy to the other parts of the framework, which further suggests a concrete next step.", "grounding_specificity_rationale": "The reviewer mentions the ECG encoder specifically, which is good grounding. However, they don't specify which 1D CNN layers or the exact configuration of the average pooling. They suggest alternative architectures but don't detail how these would be implemented or how they would be applied to the ECG encoder. The grounding is present but not very specific.", "verifiability_rationale": "The reviewer makes a claim about the existence of better architectures. However, they don't provide specific examples or justification for why these architectures would be superior. They suggest exploring similar comparisons to other parts of the framework, which implies a need for more evidence or reasoning to support their claim.", "helpfulness_rationale": "The reviewer suggests exploring more advanced architectures and drawing an analogy to the other parts of the framework. This provides a general direction for improvement. However, the suggestion is quite broad and lacks specific details on *why* these architectures are better or *how* the authors should go about implementing and comparing them. The helpfulness is limited because the feedback is not very specific or actionable."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the abstract inaccurately suggests a defense methodology is proposed and correctly identifies the abstract as the specific part of the paper being discussed. It also clearly suggests a concrete action: rephrasing the abstract.", "grounding_specificity_rationale": "The review refers to the abstract specifically, even though it doesn't use explicit section references. The suggestion to rephrase the abstract directly targets this specific part of the paper.", "verifiability_rationale": "The reviewer makes a claim about the abstract's wording but doesn't provide specific evidence *within this review point* to *prove* the inaccuracy. However, the suggestion to rephrase is a potential action based on this claim.", "helpfulness_rationale": "The review identifies a factual error in the abstract and provides a clear suggestion to correct it. This directly addresses a potential source of confusion for readers. The suggestion is concrete and actionable."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point suggests improvements to the related work section by mentioning the lack of comparisons to recent methods using new activation functions. While it points out a potential area for improvement, it doesn't explicitly state what the authors should do to address this. The suggestion is more about highlighting a gap rather than providing a direct action. Therefore, it is not 5 as it doesn't directly instruct the authors on how to implement the comparison or why it is necessary.", "grounding_specificity_rationale": "The review point mentions 'recent methods' and 'activation functions' as areas where comparisons are lacking. This provides some grounding as it identifies specific aspects of the paper that could be improved. However, it doesn't pinpoint a specific section, table, or unique element within the paper where these comparisons should be made. The grounding is somewhat broad, making it less specific.", "verifiability_rationale": "The review point makes a claim about the lack of comparisons to recent methods using new activation functions. This is a claim that could be supported by examining the paper's related work section. However, the reviewer doesn't provide specific examples of missing citations or evidence within the paper to support this claim. The claim is present, but the supporting evidence is missing, making it 3 but lacking robustness.", "helpfulness_rationale": "The review point identifies a potential gap in the related work section by pointing out the absence of comparisons to recent methods. This is a constructive suggestion that could help the authors improve their paper by providing a more comprehensive overview of the field. While it doesn't directly tell the authors what to write, it highlights an area for improvement. Therefore, it is 3 in guiding the authors towards a more thorough related work section."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the 'straightforward method' (length extrapolation) but doesn't explicitly state what needs to be changed or how the authors should apply this feedback. While it implicitly suggests an alternative evaluation setting, the action of implementing this change is not detailed enough to be considered fully actionable. Therefore, the feedback is implicit and lacks concrete steps for the authors to follow.", "grounding_specificity_rationale": "The review point criticizes 'length extrapolation' in general, without specifying a particular aspect of the paper or the authors' work. It doesn't identify a specific section, table, figure, or unique element of the paper that needs improvement. The grounding is weak because the authors can only make an educated guess about what the reviewer is referring to.", "verifiability_rationale": "The review point makes a claim about the 'effectiveness of the straightforward method' and suggests an 'improved evaluation setting' but does not provide any evidence or reasoning to support these claims within the review itself. It presents them as statements of opinion rather than verifiable facts or logical arguments. Therefore, the claims are not supported by the provided text.", "helpfulness_rationale": "The review point raises a valid concern about the value of research on length extrapolation if models are wellfinetuned and suggests an alternative evaluation setting. However, it does not offer concrete, actionable advice for the authors on how to address this concern or implement the suggested change. The feedback is more of a critique and suggestion for change rather than direct guidance for improvement. Therefore, the feedback is somewhat general and lacks specific steps for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for clarification on a specific point in the paper (Section 2.4) regarding the training and testing environments of the autoencoder. This constitutes an explicit action. While the action itself is not concretely detailed in the review point, the reviewer does suggest a methodological improvement (crossvalidation), which is a concrete action. Therefore, the actionability is high as the reviewer identifies a missing detail and points towards a specific improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 2.4' and asks about the 'training environment', 'testing environments', and suggests considering 'crossvalidation'. This demonstrates strong grounding as the reviewer directly refers to a specific section and the relevant concepts. The reviewer also implicitly points out a missing detail (the specific environments) and suggests a standard practice (crossvalidation), making the grounding specificity high.", "verifiability_rationale": "The reviewer poses a question directly addressing a potential weakness or missing detail in the paper (the experimental setup for the autoencoder). This constitutes a claim. The reviewer's question implicitly suggests that the current description might be lacking in detail or justification, particularly regarding the choice of environments and the use of crossvalidation. While not explicitly stated as a reference, the suggestion implies a need for more robust evidence or explanation. Therefore, the verifiability is high.", "helpfulness_rationale": "The reviewer's comment is directly actionable. They identify a missing piece of information (the specific training and testing environments) and suggest a concrete improvement (crossvalidation). This directly empowers the authors to clarify their methodology and potentially strengthen their results. The comment is also specific, directly addressing a methodological aspect of the paper. Therefore, the review point is 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a *problem* (lack of comparison) and *acknowledges* a *positive trend* (statistic of refinements), but it doesn't provide a clear, actionable step for the author to take. It's more of a suggestion for improvement rather than a direct instruction. The comment is about the *process* of refinement and generation quality, not a specific action to perform on a specific part of the paper.", "grounding_specificity_rationale": "The comment is quite general. It talks about \"refinement during inference\" and \"generation quality\" in general, without pinpointing a specific section, table, figure, or element of the paper. The statistic of refinements is a general observation, not a specific reference to a particular part of the paper. The comment lacks specificity. It doesn't mention any particular section, table, figure, or element of the paper. The statistic of refinements is a general observation, not a specific reference to a part of the paper.", "verifiability_rationale": "The comment states a *desire* for a comparison and improvement. This is a suggestion, not a claim that *something is wrong* or *something needs to be done*. There's no assertion that the current approach is lacking or needs justification. The comment is a suggestion or a desire for a feature, not a claim that requires evidence. The comment is about the *potential* benefits of a comparison, not a statement about the current state of the paper requiring verification.", "helpfulness_rationale": "The comment suggests a valuable improvement (comparison for better generation) but doesn't *teach* the author *how* to implement it. It's a suggestion for future work, not a direct instruction for improvement. The lack of specific guidance on *how* to achieve this comparison makes it less helpful. The comment is about the *potential* benefits of a comparison, not a direct instruction on how to implement it. The comment is more about suggesting a future research direction than providing immediate actionable feedback for the author's current work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point contains implicit suggestions for improvement. The phrase 'something missing (threshold?)\" implies that a threshold value is needed for something, suggesting a potential action to be taken. However, the specific action and how to implement it are not explicitly stated. The phrase \"did you do this partitions randomly?\" suggests a question about the methodology, implying a potential issue that needs addressing, but it doesn't explicitly state what needs to be done. While there are implicit suggestions, they lack the explicit and concrete nature required for high actionability.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. The phrases 'something missing (threshold?)\" and \"did you do this partitions randomly?\" are general and do not pinpoint a section, table, figure, or unique aspect of the paper. The reviewer is referring to a general concern about missing information or the methodology of partitions without specifying where or what it relates to. Therefore, the grounding is weak.", "verifiability_rationale": "The review point contains an implied concern about the methodology (partitions) but lacks explicit claims that can be verified. The phrase \"did you do this partitions randomly?\" implies a question about the methodology, suggesting a potential issue. However, the review point does not provide any evidence or references to support this concern. The implied concern is vague and lacks specific examples or justifications. The lack of a clear claim makes it difficult to assess verifiability.", "helpfulness_rationale": "The review point is 3 in identifying a potential issue with the methodology (partitions) and raising a question about randomness. However, it lacks concrete suggestions for improvement or specific evidence to support the concern. The implicit nature of the review point makes it less helpful than a point with explicit suggestions or verifiable claims. The reviewer is prompting for clarification but doesn't provide a clear path forward or evidence that the current process is flawed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The request for a comparison of training times is explicit, but it doesn't directly tell the authors how to *improve* their draft. It asks for information about the training time of MDP and the alternative approach. While it implies that MDP might be more efficient, it doesn't provide concrete steps for the authors to take based on this information.", "grounding_specificity_rationale": "The reviewer is asking about the training time of two specific approaches: MDP and ImageNet pretraining + individual dataset finetuning. However, the request lacks specificity. The reviewer doesn't identify a specific part of the paper or dataset being addressed, nor does they specify which MDP model is being referred to or how the individual dataset finetuning is being performed. The grounding is implied but not explicit.", "verifiability_rationale": "The review point is a request for information (a comparison of training times) rather than a statement containing a claim. Therefore, it doesn't have verifiability in the defined sense. Verifiability applies to claims that are supported by evidence.", "helpfulness_rationale": "The request for a comparison of training times is relevant to the authors' concerns about the computational cost and efficiency of different approaches. It highlights a practical consideration and points to a potential area for improvement (potentially choosing MDP over the more resourceintensive alternative). However, it doesn't directly instruct the authors on how to improve their draft. It's a request for information that could be helpful but doesn't actively guide the authors towards a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the author's claim about GPDE's design and compares it to GraphCON. While the specific implementation details of the incremental improvement are not fully elaborated, the core idea of substituting the static encoder is clearly mentioned. This provides a clear action for the author to consider.", "grounding_specificity_rationale": "The review point explicitly mentions 'GPDE', 'spike ODE', 'graph ODE', and 'GraphCON1' by number. This allows the author to identify the specific models being discussed and understand the context of the comparison. Furthermore, the specific change of substituting the 'static encoder of GraphCON with an SNN' is also mentioned, providing a detailed point of reference.", "verifiability_rationale": "The review point presents a claim about the author's understanding of GPDE's design and then points out a specific architectural change in GPDE compared to GraphCON. This claim can be verified by examining the GPDE paper and comparing it to the GraphCON paper. The specific mention of 'substituting the static encoder of GraphCON with an SNN' provides a basis for verification, although a full comparison would be needed to confirm the accuracy of the author's initial claim.", "helpfulness_rationale": "The review point provides valuable information for the author. It highlights a potential misunderstanding or misrepresentation of GPDE's design relative to GraphCON. By pointing out the specific change of substituting the static encoder with an SNN, the review helps the author understand the incremental improvement and potentially refine their understanding of GPDE's architecture. This information is actionable and directly relevant to the author's work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the proposed method does not outperform Jiang et al. significantly on three metrics: Penetration(Dep), CR, and SimDisp(Mean). While the reviewer points out the lack of significant outperformance, the action is not explicitly stated. The reviewer could have suggested specific improvements or areas for modification based on the identified weaknesses.", "grounding_specificity_rationale": "The reviewer mentions specific metrics (Penetration(Dep), CR, SimDisp(Mean)) where the proposed method does not significantly outperform Jiang et al. This indicates some grounding as the reviewer is referring to specific aspects of the method's performance. However, the reviewer does not explicitly state which *section* of the paper or *unique element* is being addressed in relation to these metrics. The grounding is implied rather than explicitly pointed out.", "verifiability_rationale": "The reviewer makes a claim: 'In Penetration(Dep), In CR, In SimDisp(Mean), Ours(100.00%) only outperforms Jiang et al.(99.97%) for 0.03%. In SimDisp(Mean), Ours(1.74) is even worse than Jiang et al.(1.52).' This claim is supported by the provided numerical data. The reasoning is clear and the evidence is present, making this claim 5.", "helpfulness_rationale": "The reviewer criticizes the proposed method's performance, stating that it does not significantly outperform Jiang et al. on the specified metrics. This is a direct feedback on the authors' work and provides a clear direction for improvement. While the criticism is general, it is still helpful for guiding the authors to focus on areas where their method underperforms."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues with the related work section and provides suggestions for improvement. The first part directly addresses the lack of comparison to OOD detection work, and the second part suggests renaming the subtitles. These are clear and actionable suggestions for the authors.", "grounding_specificity_rationale": "The reviewer mentions the term 'vFSAD' and its relation to OOD detection in timeseries data, providing a specific context. They also explicitly state that the 'Policy' and 'Evaluation tasks' subtitles are misleading and not relevant. While not pointing to a specific section, the discussion is grounded in a specific area of research and the content of the related work. The specificity is high as the reviewer clearly identifies the issues.", "verifiability_rationale": "The reviewer makes claims about the related work section lacking comparison to OOD detection and the subtitles being misleading. However, they do not provide any justification or evidence to support these claims. The statements are presented as observations without logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer provides specific examples of missing comparisons to related work and suggests concrete improvements to the subtitles. These suggestions are directly aimed at helping the authors improve their draft by providing context and clarity. The suggestions are actionable and directly address potential weaknesses."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem ('the effect of memory size is ambiguous') and proposes a concrete action ('An ablation study...'). This clearly indicates a direct action the authors should take.", "grounding_specificity_rationale": "The review point does not specify which part of the paper or analysis is affected by the ambiguity of memory size. It does not point to a specific section, table, or figure. The reviewer suggests an ablation study but doesn't detail where it should be conducted or what specific results are missing.", "verifiability_rationale": "The review point contains a claim ('the effect of memory size is ambiguous') and provides a suggestion ('An ablation study...'). This claim is verifiable because ablation studies are a standard method for justifying parameter choices like memory size. The suggestion is logically sound and directly addresses the stated problem.", "helpfulness_rationale": "The review point directly identifies a weakness ('the effect of memory size is ambiguous') and offers a clear, actionable suggestion ('An ablation study...'). This is a direct and helpful comment for the authors, guiding them to a standard method for addressing the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer implicitly suggests that the definition of GNN should be provided earlier in the paper. While the reviewer doesn't explicitly state 'Missing definition' or 'Add a definition here', the lack of a definition at the point where the abbreviation is first used can be interpreted as an actionable point for the authors to check for the definition later in the paper. The action is to look for the definition, which is a clear and direct action.", "grounding_specificity_rationale": "The reviewer can identify the specific part of the paper where the full definition of GNN is located (end of page 2, Section 2). While the reviewer doesn't explicitly name the section or page, the information is sufficient for the authors to find the definition. The grounding is present, although not as explicit as it could be.", "verifiability_rationale": "The reviewer's comment is a suggestion for improved writing practice (providing definitions earlier). However, the reviewer does not provide any logical reasoning, examples, or external references to support why this is a necessary or harmful requirement. The claim is that the definition should be earlier, but there's no justification for this claim based on the provided definitions. The evidence is purely based on a suggestion for better writing practice, lacking any supporting arguments.", "helpfulness_rationale": "The reviewer's comment is a critique of the paper's organization, specifically the late appearance of the definition of GNN. While the reviewer points out a potential issue, they do not offer any specific suggestions or actionable steps for the authors to take. The comment is more about pointing out a problem than providing a solution. The impact is negative, as it doesn't directly guide the authors on how to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point implicitly suggests that the proposed loss function's effectiveness might be limited to specific scenarios and not generalize well. While the reviewer points out a potential issue, the explicit action to take is not directly stated. The implication is that the loss function needs to be evaluated on other datasets or that its design needs to be reconsidered to achieve consistent performance.", "grounding_specificity_rationale": "The comment explicitly mentions the 'DAVIS dataset,' '2019val,' and '1' (referring to a specific paper). This clearly identifies the specific part of the paper being addressed and provides a unique reference point. The reviewer also specifies the comparison being made ('effectiveness of the proposed loss function on such algorithms does not guarantee the effectiveness on topperforming ones'), which clearly indicates what needs to be addressed.", "verifiability_rationale": "The comment contains a claim ('Effectiveness of the proposed loss function on such algorithms does not guarantee the effectiveness on topperforming ones') and provides supporting evidence. The comparison with stateoftheart results (e.g., 65.6% J mean on 2019val by 1) serves as logical reasoning and external reference to support the claim.", "helpfulness_rationale": "The review point identifies a performance gap for baseline methods on the DAVIS dataset and suggests the proposed loss function might not be universally effective. This is a relevant observation that could guide the authors to investigate their loss function's performance on different datasets or consider alternative approaches. The grounding specificity is high as the context (DAVIS dataset, 2019val) is clearly identified, and the verifiability is also high due to the comparison with stateoftheart results."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking for clarification on the reporting of results for a specific method (twostep decoding) and a specific setting (Table 1 with decoder downsampling). This implies a need for explicit information about how results are presented and whether the twostep method is included in those results. While the reviewer doesn't explicitly state what the results are, the act of asking for clarification about their location and content makes the request actionable. The reviewer is directly asking for information that would allow them to understand the reported results in the context of the twostep method.", "grounding_specificity_rationale": "The reviewer is asking about the results for the 'twostep decoding method' and specifically mentions 'Table 1 with decoder downsampling'. This clearly identifies the specific method and the location of the results being referred to. The reviewer is asking a direct question about the presence and nature of these results, indicating a strong grounding in the request. The reviewer is specifying the exact method and the table where they expect to find relevant information.", "verifiability_rationale": "The reviewer states, 'I might be missing something, but I could not figure out if the results for the proposed twostep decoding method are reported anywhere in the paper.' This indicates a lack of immediate clarity regarding the reporting of results for the specific method. While the reviewer doesn't explicitly state what the results are, the fact that they are unsure if they are reported at all suggests a need for verification. The reviewer is asking a question that requires checking the paper for specific information, making it verifiable but potentially lacking the necessary details to be fully certain.", "helpfulness_rationale": "The reviewer's question directly seeks to improve their understanding of the results and potentially the implementation of the twostep decoding method. While the question itself doesn't directly propose a solution, it points to a potential area for improvement in the paper's presentation of results. The request for clarification is a helpful indication that the reviewer is struggling to understand a key aspect of the paper and would benefit from more detailed information. The question is about improving the authors' understanding, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action ('increase') that is likely to be implemented. While the exact method isn't specified, the action is clear and actionable.", "grounding_specificity_rationale": "The review point mentions 'figures' but doesn't specify which figures. This can be considered weakly grounded as the authors can infer the issue relates to figures in general. The issue is also somewhat underspecific as it points out a problem ('too small') without detailing its impact.", "verifiability_rationale": "The review point contains a suggestion ('increase the font size') which can be interpreted as a recommendation. While generally accepted as beneficial for readability, it lacks specific justification or references. It's more of a suggestion than a critical criticism with supporting evidence.", "helpfulness_rationale": "The suggestion directly addresses a practical issue (readability) and provides a clear direction for improvement. It empowers the authors to make a change and is generally understood to be beneficial."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'only synthetic problems are considered in the experiments' and suggests 'incorporate realworld problems'. This is an explicit action to address a limitation in the scope of the experiments. The reviewer is directly identifying a problem and proposing a concrete solution.", "grounding_specificity_rationale": "The reviewer implicitly refers to the 'problems' section or the 'problem formulation' part of the paper when they say 'only synthetic problems are considered'. They are pointing out a lack of discussion or analysis regarding the realworld relevance of these problems. The reviewer is identifying a specific area within the paper that needs attention.", "verifiability_rationale": "The statement 'It seems only synthetic problems are considered in the experiments' is a claim that can be verified by examining the description of the problems in the paper. While the evidence for this claim would be the experimental setup description, the reviewer is making a specific observation about the scope of the problems considered. The claim is supported by the information present in the paper, making it 3.", "helpfulness_rationale": "The review point clearly identifies a limitation in the scope of the experiments by pointing out the lack of consideration for realworld problems. This is a valuable piece of feedback for the authors as it highlights an area for improvement and potentially a gap in the current evaluation. The reviewer is directly addressing a relevant aspect of the work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests comparing their Natural Language Explanation (NLE) explainer with other NLE interpretability tools. This is an explicit action, as they are recommending a comparison. However, the reviewer does not specify which other NLE tools should be compared, making it vague on how to apply this action.", "grounding_specificity_rationale": "The reviewer mentions 'other NLE interpretability tools' as the area to compare with. While they don't name specific tools, they clearly identify the *type* of tool (NLE interpretability tools) that should be considered. This provides some grounding, but it's not as precise as identifying a specific section or table in the paper.", "verifiability_rationale": "The reviewer's suggestion to 'compare with other NLE interpretability tools' is a prescription for improvement, not a claim that something is wrong. While the action is logical, there's no explicit verification or justification provided for why this comparison is necessary or beneficial.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement: 'They should compare with other NLE interpretability tools.' This is a direct and actionable piece of feedback that could help the authors enhance their evaluation methodology. While it lacks specific tool names, it points to a concrete area for further research and experimentation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue with Equation (5) and its relation to Equations (1), (2), and (3). While the reviewer's comment implies a lack of clarity or direct actionability regarding the equations themselves, the core of the criticism is about the *potential incompleteness* of the search space in Equation (5). The reviewer suggests that while the equations (1), (2), and (3) define the criteria for data points, Equation (5) might not be exhaustive in testing the diversity of all data points that satisfy (1) and (2). This implies a lack of explicit action or direct guidance on how to implement the suggested changes or reevaluation. The reviewer's point is about the *potential* issue, not a direct instruction.", "grounding_specificity_rationale": "The reviewer refers to 'Eq. (5)' and the surrounding equations. While the *review of the equations* is specific, the *review point itself* doesn't explicitly name the equations or detail the variables. The criticism is about the *process* of checking diversity, not the specific section or table where the data points might be located. Therefore, the grounding is *weak*. The reviewer doesn't pinpoint the exact location of the data points being considered, nor does the review point explicitly state which part of the paper the equations relate to.", "verifiability_rationale": "The reviewer states a claim: 'Eq. (5) doesn\u2019t include the exhaustive test over the diversity of all these data points.' This claim is presented as a statement of concern. Without access to the paper's content, we cannot definitively verify whether Equation (5) is exhaustive or not. The reviewer's statement is a *suspicion* based on their understanding of the equations. The review point itself doesn't provide direct evidence to confirm or deny this claim. Therefore, the verifiability is *not explicitly stated* as verifiable or 1 based *only* on the review point itself.", "helpfulness_rationale": "The reviewer's point is about the *potential incompleteness* of the search space in Equation (5). While the review point itself doesn't directly instruct the authors on what to do, it highlights a potential area for improvement in the methodology. The reviewer's comment is intended to *improve* the work by suggesting a more thorough evaluation. Therefore, the feedback is intended to be helpful in improving the methodology. However, it doesn't provide a direct, actionable step for the authors to take. The helpfulness is limited to pointing out a potential flaw."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to investigate the impact of document augmentation on supervised retrievers, which is a clear and direct action. While they don't provide specific details on *how* to implement this, the intention itself is a concrete action point.", "grounding_specificity_rationale": "The reviewer identifies a potential area for future work related to document augmentation and supervised retrievers. This implicitly points to a specific part of the paper or methodology they are referring to. While not explicitly naming a section or table, the context strongly suggests a connection to the 'document augmentation' aspect of their proposed approach, which is likely detailed elsewhere in the paper. The reviewer also provides a rationale for this suggestion, indicating a clear understanding of the potential benefits.", "verifiability_rationale": "The reviewer makes a suggestion for future research and provides a rationale for why this is a valuable direction. This constitutes a claim that can be logically supported. The reviewer's reasoning is based on the potential benefits of exploring the impact of document augmentation on supervised retrievers.", "helpfulness_rationale": "The review point directly suggests a valuable and actionable next step for the research. The reviewer proposes an additional experiment to investigate the impact of document augmentation on supervised retrievers, which is a clear and constructive suggestion that could significantly enhance the paper's findings and contribute to the field. The suggestion is specific and provides a clear direction for future work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the authors should discuss the cache hierarchy and its application. This is a clear call for action. While the reviewer doesn't specify *how* the authors should discuss the application, the *what* (the cache hierarchy and its integration) is clear. The action is implied but lacks detail on the mechanics of the integration.", "grounding_specificity_rationale": "The reviewer points out a specific gap in the paper: the lack of discussion about the cache hierarchy. The authors have not explicitly addressed this particular aspect. The reviewer is implying that this omission is a weakness, but they are not pointing to a specific section or element within the paper as being missing. The grounding is implied rather than explicitly stated.", "verifiability_rationale": "The reviewer makes a claim about the paper's content: 'the cache hierarchy is not discussed.' This is a verifiable statement. The reviewer also suggests a potential fix: 'the individual levels are discussed and their details, but not how they are applied together.' While the claim is verifiable, the reviewer doesn't provide specific examples or references to support the claim or the suggested fix. The reasoning is present, but the common knowledge or external references are lacking.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors: 'the authors should discuss the cache hierarchy and its application.' This is a direct and helpful comment that guides the authors towards a specific improvement. The suggestion is specific enough to be actionable, even though the *how* of the discussion is not detailed."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question about how GPU memory was managed to prevent OOM issues. This is an explicit request for information related to the implementation. However, the reviewer does not specify the method or provide any guidance on how to apply this information. Therefore, while the request is clear, it lacks concrete actionability for the authors.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 2' and mentions a specific number of backpropagation steps (3) as context for their question about GPU memory management. This provides some grounding, as the authors can infer that the memory management strategy might be related to the backpropagation process depicted in Figure 2. However, the reviewer does not explicitly state which part of Figure 2 is relevant or how the 3 backpropagation steps directly relate to the memory management. The grounding is weak because the authors need to make an inference about the relevance of the figure and the connection to the memory management.", "verifiability_rationale": "The reviewer poses a question about how GPU memory was managed. This can be considered a claim that information is needed. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support their claim. The verifiability is low because there is no justification or evidence provided to back up the request for information.", "helpfulness_rationale": "The reviewer asks a question seeking information about implementation details to prevent OOM issues during pretraining. While this identifies a potential problem, it does not offer any solutions or guidance on how to address it. The feedback is primarily a request for clarification rather than a critique or suggestion that would be helpful for improving the draft. Therefore, the feedback is not particularly helpful in terms of providing actionable insights or guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the problem ('The Abstract is not well written...') and suggests an action ('rewrite and well present your contributions'). However, it does not specify how to achieve this action or what aspects of the abstract need improvement. The action is stated, making it explicit, but the lack of concrete details makes it only partially actionable.", "grounding_specificity_rationale": "The comment identifies the specific part of the paper being addressed ('the Abstract'). However, it does not specify which aspects of the abstract are problematic or what needs to be improved within it. The part of the paper is identified, making the grounding explicit, but the lack of specificity about the issues makes it only weakly specific.", "verifiability_rationale": "The comment makes a judgment ('The Abstract is not well written...') but does not provide any supporting evidence or reasoning to back this claim. It is a suggestion, not a claim requiring justification. Therefore, it does not fit the criteria for verifiability.", "helpfulness_rationale": "The comment identifies a clear area for improvement (the abstract) and suggests a general action (rewrite). While it lacks specific details, it points towards a concrete next step for the author (focus on improving the abstract). The suggestion to rewrite is a valuable direction, even without specifics."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests that the ADE dataset might be biased. While the suggestion is clear, the reviewer does not provide specific details on how this bias might manifest or what steps could be taken to address it. The action is implied but not explicitly stated, and the specifics are missing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the ADE dataset' by name, which clearly identifies the specific part of the paper being addressed. The comment also specifies the *potential* issue, which is the bias of the dataset. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer states a claim that 'the ADE dataset might be biased'. However, the reviewer does not provide any evidence, examples, or references to support this claim within the review point. The claim is presented without sufficient justification.", "helpfulness_rationale": "The reviewer raises a valid concern about the potential bias of the ADE dataset. While the suggestion is relevant and could be helpful for the authors, the review point lacks specific guidance on how to investigate or mitigate this bias. The feedback is present but lacks concrete steps, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that they do not understand the statement. This indicates an implicit action or an action that needs to be inferred. While the reviewer doesn't suggest a specific action, the fact that they identify a lack of understanding implies an action of seeking clarification. Therefore, it can be considered 3 as the author would likely infer the need for clarification.", "grounding_specificity_rationale": "The reviewer refers to 'Section 2' and the concepts of 'upsampled feature map' and 'original feature map' and 'semantics'. While they don't pinpoint a specific sentence or element, they clearly identify the area of confusion. This indicates a level of grounding as the reviewer is referring to a specific part of the paper and the concepts discussed within it. However, it's not as precise as 'fully grounded' where the exact sentence or element is mentioned. Therefore, it can be considered 3.", "verifiability_rationale": "The reviewer states that they 'do not understand what it means'. There is X being made in the review point itself. The reviewer is expressing a lack of understanding, which is a valid concern, but it doesn't contain a claim that can be verified or unverified. Therefore, it is not verifiable as it doesn't contain a claim that can be supported or not supported.", "helpfulness_rationale": "The reviewer points out a genuine gap in understanding, which is a valid issue for the authors. While the review point itself doesn't offer specific guidance on how to understand the statement, it highlights a specific area where the author is struggling. This can be considered 3 as it directs the author's attention to a specific problem. However, it lacks the actionable suggestions that would make it fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need to compare with other methods, which is an action. However, the reviewer does not provide specific details on how to perform this comparison or what aspects of the other method should be considered. The action is stated, but the implementation details are missing, making it less actionable.", "grounding_specificity_rationale": "The reviewer mentions a specific paper (1) as a point of comparison. This indicates that the reviewer can identify the specific part of the paper (the method for personality detection) being addressed. However, the reviewer does not specify what aspects of this paper need to be compared or what the expected outcome should be. The grounding is present, but the specificity is lacking.", "verifiability_rationale": "The reviewer makes a claim that it is necessary to clarify the differences between the proposed method and other methods. The reviewer implicitly suggests that the current method is lacking by proposing a comparison. However, the reviewer does not provide explicit reasoning, common knowledge, or external references to support this claim. The claim is stated, but it lacks sufficient justification.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: to compare the proposed method with other existing methods. This directly addresses a potential weakness (lack of comparison) and offers a concrete improvement. The suggestion is directly related to the authors' potential needs for improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies two potential weaknesses in the authors' work: the lack of clarity regarding the intuition behind constraining B in LoRA and the apparent contradiction between theoretical findings and experimental results. However, the reviewer does not explicitly state how these weaknesses should be addressed or what specific changes are needed in the authors' paper. The reviewer's comments are more about raising questions and pointing out areas for further consideration rather than directly instructing how to improve the work.", "grounding_specificity_rationale": "The reviewer points out two specific areas of confusion related to the LoRA method and convergence. However, the reviewer does not explicitly identify a specific section, table, or figure in the authors' paper that is directly related to these issues. The reviewer's comments are more about the general understanding of the method and the experimental setup rather than pinpointing a precise location in the paper.", "verifiability_rationale": "The reviewer presents questions and observations about the relationship between the constraint on B and convergence speed, and the discrepancy between theoretical and experimental step size requirements. While the reviewer offers potential explanations (intuitive connection, connection to optimization), they do not provide direct evidence or references within the review point itself to support these claims. The reviewer's statements are more like hypotheses or suggestions for further investigation rather than explicit claims that can be verified.", "helpfulness_rationale": "The reviewer's comments are primarily in the form of questions and observations about the authors' work. While these points are relevant and raise valid concerns, they do not offer direct, actionable advice or solutions to the identified weaknesses. The reviewer's feedback is more about prompting further analysis and discussion rather than providing clear guidance on how to improve the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a future direction for the research by proposing an ablation study on different problem types, which is a concrete action.", "grounding_specificity_rationale": "The review point explicitly mentions 'shortest path problem' and 'BellmanFord algorithm', clearly identifying the specific aspects of the paper being addressed.", "verifiability_rationale": "The review point makes a claim about the potential benefits of expanding the evaluation beyond shortest path problems, which could be supported by evidence.", "helpfulness_rationale": "The review point offers a constructive suggestion for improving the evaluation of the PathGNN architecture by exploring its performance on other problem types, indicating a helpful suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests including 'more recent models' for comparison. While it doesn't specify which models, the suggestion is a clear action that authors can take to improve their experimental setup. However, the lack of specificity makes the action somewhat vague.", "grounding_specificity_rationale": "The review point explicitly mentions 'ControlSpeech' as the model being compared to new models. It also specifies the focus on 'multilingual settings' and 'other languages beyond English'. This provides clear grounding of the relevant part of the paper and specifies the area of focus. However, the suggestion is about 'including' rather than 'replacing' or deeply analyzing the new models, and specific models are not mentioned.", "verifiability_rationale": "The review point suggests including 'more recent models' without providing any specific justification, logical reasoning, or external references. There is X being made about why these models are needed or beneficial, and no evidence is provided to support this suggestion.", "helpfulness_rationale": "The suggestion to include 'more recent models' is a relevant and actionable point for improving the experimental setup. It directly addresses the comparison methodology and provides a direction for future experiments. However, the lack of specificity might limit its immediate impact on the authors."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'lack of visualization of the learned context token' and 'limited novelty is unfortunately limited, and analysis for the insight of this approach is absent.' These are direct statements that authors can act upon.", "grounding_specificity_rationale": "While the reviewer implies the need for a visualization of context tokens, they don't specify *which* visualization they need. Similarly, they imply a need for analysis of the 'insight of this approach' without specifying *which* insight. Authors can infer, but the lack of explicit detail makes it somewhat weakly grounded.", "verifiability_rationale": "The reviewer states that the paper 'lacks visualization of the learned context token' and 'analysis for the insight of this approach is absent.' These are claims that the authors can reasonably infer are problems with the paper.", "helpfulness_rationale": "The reviewer provides clear and actionable suggestions. The first suggests a specific improvement (visualization), and the second suggests a specific analysis (insight of the approach). Both are concrete and directly address potential weaknesses."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem of 'very small benefits over the baseline model' and suggests a solution by 'reporting results for other models than MetaOptNet'. This is an explicit action with concrete details on how to implement it by suggesting a specific type of model to evaluate. The reviewer clearly identifies the weakness and proposes a direct method to address it.", "grounding_specificity_rationale": "The review point explicitly mentions the 'experimental section' and suggests evaluating 'other models than MetaOptNet'. This clearly identifies the specific part of the paper being addressed and provides a specific direction for improvement. The reviewer uses literal mentions to pinpoint the area and suggest a concrete change.", "verifiability_rationale": "The review point makes a claim about the current results ('very small benefits') and suggests a way to address this ('report results for other models'). While it doesn't provide the specific data to verify the 'small benefits' within the review itself, it points to a logical next step for the authors to take. The suggestion is actionable and verifiable by the authors if they decide to follow it. The reviewer provides a clear direction for the authors to gather more information to support or refute their claim.", "helpfulness_rationale": "The review point clearly identifies a weakness ('small benefits over the baseline model') and offers a concrete and actionable suggestion ('report results for other models'). This directly addresses the authors' need to understand the performance of their method and how it generalizes. The reviewer's suggestion is directly tied to improving the authors' work, making it 5 in guiding them towards further experimentation and analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action (improve comparison) and provides a concrete suggestion (include wellestablished methods). However, it lacks specific details on *how* to implement this action, such as identifying specific areas for comparison or the criteria for selecting additional baselines. The suggestion is present, but the action is somewhat vague.", "grounding_specificity_rationale": "The comment explicitly mentions specific methods (FTML and LFW) as examples of 'wellestablished methods' and suggests 'including wellestablished methods' to improve the comparison. This clearly identifies the specific part of the paper (the comparison section) and details the issue (lack of comprehensive evaluation). The comment also implies a broader understanding of the current comparisons.", "verifiability_rationale": "The comment contains a claim ('The paper could benefit from a more extensive comparison...') and provides supporting evidence by stating the benefit ('...for a more comprehensive evaluation of the proposed method's strengths and weaknesses') and providing examples ('...by including wellestablished methods such as FTML and LFW'). The claim is wellsupported by logical reasoning, common knowledge (evaluation is generally considered important), and external references (the examples themselves).", "helpfulness_rationale": "The review point directly addresses a stated weakness ('Limited Comparison') and offers a clear and relevant suggestion ('include wellestablished methods'). The suggestion is concrete and directly addresses the identified limitation. The examples provided make the suggestion actionable. The claim about improved evaluation is a logical consequence of the suggestion and directly benefits the authors by guiding them towards a more thorough assessment of their method."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states actions or suggestions that authors can directly identify modifications they should apply to their draft. The first point directly tells the authors to 'downgrade focus on CRF modeling' and the second point suggests 'exploring location embeddings'. These are clear and direct instructions.", "grounding_specificity_rationale": "The review point explicitly mentions the specific aspects of the paper being addressed. The first point refers to 'modeling this task using a CRF (local and global context)' and the second point refers to 'location embeddings'. This indicates a high level of grounding as the authors can directly identify the sections or concepts being discussed.", "verifiability_rationale": "The review point makes claims about the performance of CRF variants and location embeddings. While it doesn't provide explicit evidence within the review point itself, it *implies* that the observed performance differences are significant enough to warrant a change in focus. The claim is stated, and the implications are clear, making it 3 based on the information provided in the review point.", "helpfulness_rationale": "The review point provides clear and actionable feedback on weaknesses and areas for improvement. It directly tells the authors what to focus on and what features to consider. This is 5 as it guides the authors towards specific changes and improvements."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point 'It's not clear what's the impact of the trainingtesting inconsistency.' does not explicitly state the impact of the inconsistency. While it implies a concern, the specific nature of this impact is vague. Therefore, it is implicit and somewhat vague, making it 2.", "grounding_specificity_rationale": "The review point refers to 'trainingtesting inconsistency' generally and does not specify which part of the paper or dataset this refers to. Therefore, it is 1 at all.", "verifiability_rationale": "The review point contains a claim ('It's not clear what's the impact of the trainingtesting inconsistency.') but does not provide any evidence, reasoning, or references to support this claim. It simply states a lack of clarity.", "helpfulness_rationale": "The review point highlights a genuine lack of clarity regarding the impact of a trainingtesting inconsistency. This directly addresses a potential source of confusion for the authors and could guide them in their analysis. While it doesn't provide a solution, it points out a crucial area that needs further investigation, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a potential issue ('the condition for y membership is unclear') and points to a reason ('because the sets S are disjoint'). While it doesn't directly tell the author *how* to fix it, it identifies a concrete problem related to the definition. Therefore, it is 3 as it highlights a specific area needing clarification.", "grounding_specificity_rationale": "The comment refers to 'the condition for y membership' and 'sets S are disjoint'. While it uses mathematical notation, it doesn't explicitly name a specific section, table, or unique element of the paper. The grounding relies on the reader understanding the context. Therefore, it is weakly grounded. However, the specificity is good as it clearly identifies the *specific* mathematical relationship and the *specific property* of the sets.", "verifiability_rationale": "The comment identifies a claim ('Some of the claims are not backed up') and states that this claim is not supported by justification or evidence. The lack of backing up makes the claim 1.", "helpfulness_rationale": "The comment points out specific issues in the paper, such as an unclear condition and a lack of backing for a claim. This directly addresses potential problems the author might be facing and suggests areas for improvement. Therefore, it is 3 as it highlights actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that comparisons of key references are missing. While this implies an action (comparing), it doesn't explicitly state what needs to be compared or how the comparison should be conducted. The action is implied but not fully specified, making it somewhat vague.", "grounding_specificity_rationale": "The review point mentions 'key related references' but doesn't specify which ones or the exact nature of the missing comparison. The grounding is weak because the reviewer can't confidently identify the referenced part of the paper or the specific issue within it.", "verifiability_rationale": "The review point states that 'a few key refererences that are highly related are not compared and explained.' This is a claim that something is missing. However, the reviewer doesn't provide any logical reasoning, common knowledge, or external references to support why this is a problem or how it should be addressed. The claim is stated but not verified.", "helpfulness_rationale": "The review point identifies a potential area for improvement in the literature review (comparing related references). However, it doesn't offer any specific guidance or suggestions on how to go about this comparison. The suggestion is present but lacks actionable steps, making it less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the analysis of SCL in fewshot learning is 'not convincing' and points to specific results in Figure 7(c) and (d) as evidence. The reviewer then suggests a concrete improvement: investigating COCOLM for sentence retrieval tasks. This indicates a clear understanding of the weakness and a direct suggestion for action, making the criticism 5.", "grounding_specificity_rationale": "The reviewer mentions 'section 5.2' and refers to 'Figure 7(c) and (d)' as evidence. This indicates that the reviewer has identified a specific area in the paper where the analysis is lacking. However, the reviewer does not explicitly state which specific part within Section 5.2 is unclear or misinterpreted. The reviewer's focus is on the *results* rather than the *explanation* of a specific part. Therefore, while the reviewer has identified a section, they haven't pinpointed the exact unclear element within that section.", "verifiability_rationale": "The reviewer provides specific data points from Figure 7(c) and (d) as evidence for their claim that the results are 'not convincing'. While the reviewer doesn't explicitly *explain* *why* these results are concerning, the presence of the data points themselves makes it verifiable that the observed trend deviates from the expected one. The reviewer's statement 'results in Figure 7(c) and (d) do not meet our expectation' directly links the evidence to a claim that needs verification.", "helpfulness_rationale": "The reviewer provides a clear criticism regarding the analysis of SCL in fewshot learning and offers a specific suggestion for improvement: investigating COCOLM for sentence retrieval tasks. This is a direct and actionable feedback that empowers the authors to explore a potential application of their learned representations. The reviewer's suggestion is a concrete step they believe would be beneficial for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states \"It is better to conduct more experiments\" and \"which can demonstrate the generalization of the proposed framework.\" This directly tells the authors what to do. While it doesn't specify *how* to conduct more experiments, it clearly identifies the action of adding more experiments. This makes it 3 as it points to a concrete modification.", "grounding_specificity_rationale": "The comment mentions \"experiments\" and \"generalization of the proposed framework.\" While it doesn't explicitly name a specific section, table, or figure, it clearly refers to a specific area within the paper (the evaluation of the framework's generalization ability). This can be considered weak grounding as the authors can infer the need for more LLMrelated experiments. However, the concept of 'generalization' is also a general idea, making the grounding somewhat implicit.", "verifiability_rationale": "The comment contains a claim: \"It is better to conduct more experiments on other LLMs.\" This claim is 3 because the authors can infer that conducting more experiments on different LLMs is a logical way to demonstrate the generalization of the framework. While it doesn't provide specific examples or references, the suggestion is based on a reasonable understanding of how to assess generalization in the context of LLMs.", "helpfulness_rationale": "The review point is 5 as it directly addresses a potential limitation of the paper. It encourages the authors to broaden their evaluation by conducting more experiments on different LLMs. This is a constructive suggestion that can significantly improve the robustness and generalizability of their findings. It provides a clear direction for future work and helps the authors address a potential lack of generalizability if the framework performs well across different models."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1: Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a *potential limitation* related to the number of objects. While the observation is relevant, the review does not explicitly state what needs to be done to address this limitation or how to improve efficiency. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer mentions the *number of objects* as a factor affecting efficiency. However, they do not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The reference is general and lacks precision.", "verifiability_rationale": "The reviewer states that generating multiple objects takes longer, depending on the number of objects. This is a statement, not a claim that requires verification. There is no evidence, reasoning, or references provided to support this observation.", "helpfulness_rationale": "The reviewer identifies a potential inefficiency in generating multiple objects. While this is a valid observation, it does not provide specific, actionable feedback on how to improve the process or the draft. The feedback is general and lacks concrete suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a weakness ('weak technical contribution') and suggests improvements ('find additional applications', 'deeply evaluate the approach'). While the suggestions are general, they are still explicit actions the authors should take. However, the reviewer doesn't specify *how* to find applications or *how* to deeply evaluate the approach, making the action somewhat vague. The mention of 'Interpolative Decomposition' is implicit, as the reviewer knows it's a technique used but doesn't explicitly state it as part of the action. Therefore, the action is partially explicit and partially vague.", "grounding_specificity_rationale": "The reviewer makes a general statement about the 'technical contribution being thin' and suggests improvements related to 'the algorithm proposed' and 'the representation'. While the reviewer mentions these elements, they don't explicitly identify a specific section, table, figure, or unique aspect of the paper that needs improvement. The suggestions are broad and don't pinpoint the exact location of the issue. Therefore, the grounding is weak and not specific.", "verifiability_rationale": "The review point makes a claim by stating the 'technical contribution is thin' and recommending improvements. However, it does not provide any evidence or justification for why the contribution is considered thin. The suggestions for improvement are also general and lack specific references or examples. There is no logical reasoning, common knowledge, or external references provided to support the claim. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The review point identifies a potential weakness ('weak technical contribution') and offers general advice ('focus on finding additional applications', 'deeply evaluate the approach', 'emphasize properties'). While these suggestions are relevant and could be helpful for the authors to consider, they are general and lack specific details or references. The reviewer doesn't provide concrete examples of applications or a methodology for 'deeply evaluating the approach'. Therefore, while the review might prompt the authors to think about their work, the feedback is somewhat vague and lacks actionable steps with concrete examples."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the absence of implementation details, which is an actionable area for the authors. However, the comment doesn't explicitly state what the authors should do to improve the draft. It's a valid suggestion, but lacks the explicitness required for high actionability.", "grounding_specificity_rationale": "The reviewer's comment does not identify a specific part of the paper or the implementation process. They are broadly stating that details are missing. Therefore, the grounding is weak as the authors cannot pinpoint the exact area where information is lacking.", "verifiability_rationale": "The reviewer makes a claim: 'There is no details on the implementation.' This claim is not supported by any evidence or references within the review point itself. The verifiability is low because the claim is presented without justification.", "helpfulness_rationale": "The reviewer identifies a valid weakness in the provided information \u2013 the lack of implementation details. However, the comment is vague and doesn't offer specific suggestions or point to areas where the authors should look. Therefore, while the feedback is relevant, it's not presented in a helpful or actionable way."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issues: 'some math notations are undefined' and 'some details in Figure illustrations are missing.' This indicates an explicit action being pointed out. However, the reviewer doesn't specify *which* notations or *which* details are missing, making the action somewhat vague and not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions the areas of the paper that are unclear, such as 'math notations' and 'Figure illustrations.' This indicates weak grounding as the specific section, table, or figure being addressed is not explicitly identified. While the *types* of issues are pointed out, the *exact* location is missing. The reviewer also mentions their own questions, which could be seen as a general comment implying something is missing, but it's not explicitly stated as a problem with a specific part of the paper.", "verifiability_rationale": "The reviewer states that 'some descriptions are unclear' and provides examples like 'some math notations are undefined' and 'some details in Figure illustrations are missing.' This constitutes a claim. However, the reviewer does not provide any evidence, examples, or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the descriptions are unclear.", "helpfulness_rationale": "The reviewer points out specific areas where the paper lacks clarity and provides concrete examples, such as 'some math notations are undefined' and 'some details in Figure illustrations are missing.' They also ask questions, which can be interpreted as constructive feedback highlighting specific shortcomings. This suggests that the reviewer's comments are relevant and actionable for the authors, even though the exact specifics of the issues are not always clear."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that they found the notation in Algorithm 1, which is an explicit action. However, the reviewer does not specify *where* in Algorithm 1 the notation is located or how to interpret it. The action is identified, but the concrete steps for applying it are missing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Algorithm 1' as the location of the notation, which is a specific part of the paper. However, the reviewer does not explain what the notation means within Algorithm 1 or how it relates to the text. The grounding is specific to the location, but the meaning is not explained.", "verifiability_rationale": "The reviewer states that they *cannot* find the meaning of the notation in the text. This is a claim that needs justification. The reviewer provides *partial* support by pointing to Algorithm 1 where the notation is located, which can be considered a reference. However, the claim is not fully supported by external references or logical reasoning within the text itself.", "helpfulness_rationale": "The reviewer's point is clear and directly addresses a potential issue the authors might face: encountering notation in an algorithm description without an explanation in the main text. This is a constructive suggestion that encourages the authors to look in the algorithm description. The reviewer identifies a potential gap in the clarity of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the finding: 'From appendix A.4, using noise robust loss on pseudolabels performs lower than using positive learning from Eq 9.' They also pose a question: 'Is the model underfit caused by pseudolabels being very accurate that positive learning has better feedback than a toneddown robust loss?' This indicates an explicit action to identify a discrepancy and an attempt to explain it.", "grounding_specificity_rationale": "The reviewer refers to 'appendix A.4' and discusses 'noise robust loss,' 'positive learning from Eq 9,' and 'pseudolabels.' While they don't explicitly label *what* these terms refer to within the paper, the context strongly implies they understand the location and the methods being discussed. They also specify the *what* (the performance difference) and the *why* (the potential underfitting explanation).", "verifiability_rationale": "The reviewer makes a claim: 'From appendix A.4, using noise robust loss on pseudolabels performs lower than using positive learning from Eq 9.' They also make a claim about the *potential reason* for this: 'This finding is also interesting as the pseudolabel would also be assumed to have certain ambiguity to it that could benefit from the noise robust loss.' While the reviewer doesn't provide direct evidence *within the review point* to support these claims, the reasoning is based on logical understanding of pseudolabels and loss functions. The reviewer's question about underfitting is a speculative attempt to explain the finding.", "helpfulness_rationale": "The reviewer points out a clear discrepancy in performance between two loss functions. While the reviewer doesn't provide direct actionable steps for the authors to take based on this finding, they offer a potential explanation: 'Is the model underfit caused by pseudolabels being very accurate that positive learning has better feedback than a toneddown robust loss?' This suggests they are trying to guide the authors towards further investigation or understanding of the issue. The helpfulness is somewhat conditional on the validity of their proposed explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the consequence of adding an exponentiation (noticeable increase in runtime, consideration for attackers) as a concern. This provides a clear action for the authors to consider. However, the reviewer does not specify the exact location or type of exponentiation, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to a specific line number (L248) when making their point, indicating that they are identifying a specific part of the paper. However, the reviewer does not explain what is happening at that line or why it is important. The explanation is missing, making the grounding underspecific.", "verifiability_rationale": "The reviewer makes a claim about the runtime impact of an extra exponentiation without providing any logical reasoning, examples, or external references to support this claim within the review point itself. The claim is presented as an assertion without justification.", "helpfulness_rationale": "The reviewer is questioning the significance of pointing out a specific technical detail (the impact of exponentiation) and its relevance to the authors. While technically correct, the reviewer doubts whether this is a meaningful weakness or a clear improvement for the authors, making the feedback potentially unhelpful."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states the names of related works but doesn't explicitly detail how the proposed method improves upon them or provide concrete steps for comparison. While the intent is to highlight an improvement, the specifics are missing, making the action implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions the names of specific related works (e.g., \u201cRubi: Reducing unimodal biases in visual question answering\u201d, \u201cRemoving bias in multimodal classifiers: Regularization by maximizing functional entropies\u201d), indicating strong grounding. However, the reviewer also states that the paper doesn't explain *why* these methods are not compared, which is underspecific as it lacks detail on the limitations or differences.", "verifiability_rationale": "The reviewer makes claims about the improvements of the proposed method and the lack of comparison with SOTA methods but doesn't provide any evidence or reasoning to support these claims. There's no logical basis for these statements, making them 1.", "helpfulness_rationale": "The reviewer points out a valid concern regarding the lack of comparison with stateoftheart methods but doesn't offer any constructive feedback or actionable steps to address this issue. The comment is focused on identifying a problem rather than providing a solution, making it not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "4: Mostly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points out a potential reason for the observed performance improvement (the added temperature parameter) but does not specify any actionable steps or guidance on how to address this observation.", "grounding_specificity_rationale": "The review refers to 'the proposed method' and 'the temperature parameter' generally, without specifying a particular section, table, figure, or unique element of the paper. It doesn't pinpoint where the issue lies within the method.", "verifiability_rationale": "The review makes a claim that the performance improvement is due to the added learnable parameter (temperature). However, it does not provide any direct evidence or justification to support this claim, such as specific examples, references, or logical reasoning.", "helpfulness_rationale": "The review offers a potential explanation for the observed performance improvement but does not provide concrete steps or guidance on how the author should proceed. It's a valid observation but lacks actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests removing the neuroscience inspiration, but it doesn't explicitly state how to do so. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The review points to 'the inspiration from neuroscience research' and 'the main processing pipeline of the main work' but doesn't specify a particular section, table, figure, or unique element within the paper. The grounding is implied but not explicit.", "verifiability_rationale": "The review contains a claim about the nature and impact of the neuroscience inspiration but doesn't provide any evidence or reasoning to support this claim. The verifiability is based on the lack of supporting evidence.", "helpfulness_rationale": "The review offers a suggestion for improvement (making the main work less distracting) but lacks specific details on how to achieve this. The helpfulness is limited due to the lack of concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the caption is unclear regarding the source dataset. While they don't specify *how* to make it clearer, they imply that adding information about the dataset would make it actionable for the authors. This suggests an implicit suggestion for an action, making it 3.", "grounding_specificity_rationale": "The reviewer explicitly mentions the table caption as the location of the missing information ('what source dataset is used *in the caption*'). This clearly grounds the comment to a specific part of the paper, making it fully grounded. They also specify the missing information as 'the source dataset', making it specific about what is missing.", "verifiability_rationale": "The reviewer states that the caption is unclear, which implies a lack of verifiability. While they don't provide external references, they suggest adding information, which could be seen as a form of implicit justification for the missing information. However, the core issue is the lack of information, making it 3.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'Update: Please add some information about the source dataset in the caption.' This directly addresses the identified issue and provides a concrete next step for the authors, making the review 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'No explicit description of the specific architectures of value network, policy networks, uncertainty aware networks used in this paper.' This directly identifies a missing element and provides a clear action for the authors: seek out and understand the architecture details. The description is clear and points to a direct action.", "grounding_specificity_rationale": "The review point mentions 'value network,' 'policy networks,' and 'uncertainty aware networks.' While it doesn't specify the exact section or table, it clearly identifies the *type* of architecture being referred to. This allows the authors to infer the location of the relevant information, making the grounding 'Weak'. The comment also specifies what is missing \u2013 the *specific* architecture details, making the specificity 'UnderSpecific'.", "verifiability_rationale": "The review point contains a claim: 'This makes it difficult for the readers to replicate and evaluate the applicability of the approach used in this paper.' This claim is not explicitly supported by further details or references within the review point itself. The verifiability is based on the logical implication that missing architectural details would indeed hinder replication. Therefore, it is '1' based solely on the information provided in this review point.", "helpfulness_rationale": "The review point clearly identifies a lack of information (explicit descriptions of network architectures) and its consequence (difficulty in replicating and evaluating). This provides the authors with a clear direction for improving their understanding of the approach. While it doesn't directly solve the problem, it is a helpful comment because it highlights a crucial missing piece of information. The authors can now focus on finding and understanding these details."}
{"actionability_label": "3", "grounding_specificity_label": "4: Mostly Grounded and UnderSpecific", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review points out limitations and requirements of EMCTS, such as the assumption of a true transition model, the linearity of Qfunctions in Theorem 1, and the consistency of learned models. While it doesn't explicitly state 'You should check if your transition model is consistent,' it implies it. The limitations are clearly stated, making it concrete, but the action needs to be inferred, making it implicit.", "grounding_specificity_rationale": "The review mentions 'EMCTS' generally and refers to 'the transition model P,' 'Theorem 1,' and 'learned models.' While it identifies the *type* of assumption (limitations of the method) and points to specific theoretical aspects, it doesn't pinpoint a specific section, table, or figure within the paper. The specificity is in the *what* and *why* of the limitations rather than a specific instance.", "verifiability_rationale": "The review makes a claim: 'Some assumptions might make EMCTS inapplicable to real complex problems.' It then provides specific reasons and requirements related to EMCTS, such as the assumption of a true transition model, the linearity of Qfunctions in Theorem 1, and the consistency of learned models. These reasons support the claim and explain why the limitations might arise.", "helpfulness_rationale": "The review highlights limitations and requirements of EMCTS, which can help authors understand the scope and applicability of their work. It points out potential areas for improvement, such as considering nonlinear Qfunctions or methods for handling inconsistent models. While it doesn't provide a direct solution, it identifies problems that authors should be aware of."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises questions about the relationship between explicitness, size, and capacity requirements but does not provide explicit instructions or suggestions on how to improve the work based on these factors. It suggests that evaluation of disentanglement should provide enough capacity and training time, but this is a speculative statement without concrete actions or modifications. The connection to input modality differences is also mentioned but not addressed with specific actions. Therefore, the review point lacks explicit and actionable feedback.", "grounding_specificity_rationale": "The review point uses general terms like 'explicitness,' 'size,' and 'capacity requirements' without specifying which part of the paper or concept these terms refer to. While it mentions 'DCI evaluation,' it doesn't clearly identify where in the evaluation process or what aspect of the model this refers to. The connection to 'different capacity requirements' is also 1 in a specific section or table. Therefore, the review point does not clearly identify the specific issue being discussed, making the grounding weak.", "verifiability_rationale": "The review point makes a claim about the sufficiency of evaluation methods but does not provide logical reasoning, common knowledge, or external references to support this claim. It states that 'evaluation of disentanglement should provide enough capacity and training time' but doesn't explain *why* this is the case or provide evidence for it. The connection to 'DCI evaluation' is mentioned but not justified. Therefore, the claim is not wellsupported by the reasoning, common knowledge, or external references provided.", "helpfulness_rationale": "The review point raises questions and offers a speculative connection between different factors but does not provide concrete, actionable feedback that would empower the authors to significantly improve their draft. It doesn't offer specific steps or modifications based on the discussed factors. The discussion is more about understanding the relationships between these factors than providing direct improvement suggestions. Therefore, the review point does not strongly benefit the authors in improving their work."}
{"actionability_label": "3", "grounding_specificity_label": "2: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action: 'The paper title does not need to include abbreviations.' This is a direct instruction for the authors. However, it lacks specificity on *why* abbreviations are unnecessary or what specific aspects of the title are affected. Therefore, while actionable, it's not very concrete in its guidance.", "grounding_specificity_rationale": "The comment explicitly mentions the 'paper title' as the area of concern. This is a clear identification of the specific part of the paper being addressed. The comment is grounded because it directly refers to a specific element of the submission.", "verifiability_rationale": "The comment does not contain a claim in the sense of identifying a problem or error. It's a suggestion for improvement. Therefore, it doesn't have verifiability in the traditional sense of validating a weakness.", "helpfulness_rationale": "The comment provides a suggestion for improvement ('The paper title does not need to include abbreviations'). While it guides the authors, it doesn't identify a specific weakness or error in the paper. It's a preference rather than a critique. Therefore, it's not 5 as it doesn't directly address a flaw."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point discusses the discriminator's properties (transferability and trainability with limited data) but does not explicitly state an action the authors should take based on this information. While it implies actions like testing on new tasks or experimenting with training, the lack of explicit instructions makes it not fully actionable. The discriminator's size is mentioned as an insight, but no action is suggested on how to use this information. Therefore, it is 2.", "grounding_specificity_rationale": "The review point discusses the discriminator's properties (transferability and trainability with limited data) in a general manner. It does not specify which discriminator is being referred to, nor does it pinpoint where in the paper this discussion is relevant. There are no specific details about the tasks or domains involved. Therefore, it is 1 and not specific.", "verifiability_rationale": "The review point makes claims about the discriminator's properties (transferability and trainability with limited data) but provides no evidence, examples, or references to support these claims. It states these properties as facts without justification. Therefore, it is 1.", "helpfulness_rationale": "The review point provides information about the discriminator's properties, which could be relevant to the authors if they are working on similar tasks or trying to understand the limitations of their own discriminators. However, it does not offer concrete steps or guidance on how to improve their specific draft. The information is general and lacks direct applicability to the authors' immediate needs. Therefore, it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the need to 'add and compared' the baseline. This is a clear, direct action. It's not just a suggestion; it's a concrete action item. Therefore, it scores highly on actionability.", "grounding_specificity_rationale": "The reviewer mentions 'The current SOTA GNNQE is completely omitted.' While the general idea of adding a baseline is implied, the reviewer *specifically* points out the *lack* of the closest related work. They are grounding the suggestion in a concrete, related piece of research. The phrase 'completely omitted' also adds to the specificity. Therefore, it scores highly on grounding specificity.", "verifiability_rationale": "The reviewer states 'This baseline should be added and compared.' While they *mention* the baselines are 'the closest work in terms of components,' this is more of a *premise* for their suggestion rather than a direct justification for *why* adding this specific baseline is helpful. The *act* of adding and comparing is the more direct form of justification. Therefore, it scores moderately on verifiability.", "helpfulness_rationale": "The reviewer directly states the suggestion: 'Add and compared the baseline.' This is a clear and actionable piece of feedback. It directly addresses a gap in the current evaluation. Therefore, it scores highly on helpfulness."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the nature of the pretraining data used for GPT2 and its implications for understanding language. This is a query for information, not a direct instruction or request for action on the part of the reader. The reviewer is seeking clarification rather than proposing a solution.", "grounding_specificity_rationale": "The reviewer refers to 'GPT2' and 'pretraining data' when asking their question. This provides some grounding as the reader can infer the context. However, the specific type or location of the pretraining data within GPT2 is not explicitly mentioned, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer's statement about GPT2's understanding of language based on its pretraining is a claim that could potentially be supported by knowledge of GPT2's training data or established understanding of language models. However, the reviewer does not provide specific references, examples, or logical reasoning to definitively verify this claim. Therefore, it is not 5 with the information provided.", "helpfulness_rationale": "The reviewer raises a valid concern about the potential impact of GPT2's pretraining data on its understanding of language. This is a constructive point that could help the authors identify potential limitations or biases in their experimental setup and consider alternative approaches. While it's a question, it highlights a relevant issue for discussion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing details in equation (4) and the optimization algorithm, implying that these are necessary for the authors to understand and implement the proposed method. While the criticism points to a lack of information, it doesn't inherently prevent the authors from taking action to address it. The reviewer's implication is that the authors *should* be able to calculate $p(x_k|d)$ after reading the criticism, making it somewhat implied but not explicitly stated as an action. Therefore, it's not fully actionable, but the reviewer's point is clear enough that it could guide the authors to take action.", "grounding_specificity_rationale": "The reviewer directly refers to 'equation (4)' and specifically mentions the missing component '$p(x_k|d)$'. This clearly identifies the specific part of the paper where the explanation is lacking. The reviewer doesn't just say 'the method is unclear'; they pinpoint the exact location and the missing element. This demonstrates strong grounding specificity as the authors can precisely identify the section and the missing detail.", "verifiability_rationale": "The reviewer makes a clear claim about the lack of necessary information in the paper, specifically mentioning the missing details in equation (4) and the optimization algorithm. The reviewer doesn't provide any logical reasoning or external references to support this claim. The claim is based on the absence of information, making it 1 based on the provided text. The reviewer states what is missing, but doesn't explain *why* it's missing or provide justification.", "helpfulness_rationale": "The reviewer's comment is explicitly directed at improving the authors' understanding and ability to implement their proposed method. They point out specific missing information and a lack of explanation, which directly addresses potential weaknesses in the authors' work. The comment is not a general critique but a targeted suggestion for improvement. Therefore, it is 5 in guiding the authors to address the identified issues."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The reviewer states a fact about MoE's general use, not an actionable improvement suggestion.", "grounding_specificity_rationale": "The reviewer mentions general applications of MoE but doesn't pinpoint a specific section or aspect of the authors' paper where the issue lies.", "verifiability_rationale": "The reviewer makes a claim about the novelty of MoE in text detection and provides a supporting statement (its relative novelty in that specific application).", "helpfulness_rationale": "The reviewer identifies a lack of novelty in the core concept but doesn't offer concrete actionable feedback on the authors' specific method."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the claim that SpaceTGN 'achieves significant performance improvement ... than other baselines' and directly points out the absence of statistical analysis to support this claim. This provides a clear action for the authors: find and provide the missing statistical analysis.", "grounding_specificity_rationale": "The review point refers to 'SpaceTGN' and 'other baselines' generally, without specifying a particular section, table, figure, or unique element of the paper where this claim is made. While it identifies the subject of the claim, it doesn't pinpoint the exact part of the paper being discussed.", "verifiability_rationale": "The review point identifies a claim made by the authors regarding SpaceTGN's performance and explicitly states that this claim is not supported by statistical analysis. The claim is clearly stated and the lack of supporting evidence is provided, making it 1.", "helpfulness_rationale": "The review point highlights a factual error in the authors' claim about SpaceTGN's performance, specifically pointing out the absence of statistical analysis. This is a direct and actionable feedback that will likely lead the authors to reevaluate their results and correct the claim."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment does not state what needs to be done or how to do it. It describes a situation (unclear why scores are excerpted/reproduced) rather than an action.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper or the review process that is unclear. It is a general statement about the confusion in the review process.", "verifiability_rationale": "The comment does not contain a claim that needs verification. It is a statement of a problem (unclear why scores are excerpted/reproduced) rather than a proposition that requires justification.", "helpfulness_rationale": "The comment points out a valid issue in the review process (the confusion around excerpting/reproducing scores), but it does not offer a solution or actionable steps to address this issue. It is a symptom, not a remedy."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states \"there is limited novelty\" and suggests the authors \"comment more on how consistency model achieves something that previous generative models cannot.\" These are concrete actions the authors can take to improve their draft.", "grounding_specificity_rationale": "The reviewer mentions \"consistency models\" as a specific area of the paper. However, they do not pinpoint a specific section, table, figure, or unique element within that area where the lack of novelty is a concern. They imply it's related to the method description, but not specifics.", "verifiability_rationale": "The reviewer makes claims such as \"there is limited novelty\" and \"the method is somewhat simply applying consistency models in place of other generative models for learning target distributions.\" However, they do not provide specific evidence or references to support these claims. The reasoning is presented as a general observation rather than a wellsupported argument.", "helpfulness_rationale": "The reviewer provides a specific weakness in the method (\"limited novelty\") and suggests a concrete improvement for the authors (\"comment more on how consistency model achieves something that previous generative models cannot\"). While it doesn't offer a definitive solution to the lack of novelty, it points the authors towards a specific area of investigation. The fact that it's framed as a \"question for the authors\" suggests the reviewer is seeking clarification rather than a definitive critique of the method itself."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer states a fact ('MSE in Table 2') and identifies a limitation ('cannot reflect the accuracy of nowcasting'). While the reviewer points out a problem, they do not explicitly recommend an alternative or explain how to fix it. Therefore, it's not fully actionable. It's a critique of the evaluation metric.", "grounding_specificity_rationale": "The reviewer states a fact ('MSE in Table 2') and identifies a limitation ('cannot reflect the accuracy of nowcasting'). While the reviewer specifies what the metric *cannot* do, they do not explicitly identify *where* in the paper this information is located. The grounding is implicit rather than explicit.", "verifiability_rationale": "The reviewer makes a claim about the limitations of MSE for nowcasting. While the claim is made, there is no explicit justification or reference to external knowledge within the review point itself. The verifiability depends on the reader's understanding of 'nowcasting' and the limitations of 'MSE'.", "helpfulness_rationale": "The reviewer points out a potential issue with the evaluation process (the use of MSE in Table 2 for nowcasting). However, they do not offer a solution or suggest an alternative evaluation metric. They simply state the problem. Therefore, it is not particularly helpful in guiding the authors on how to improve their draft based on this specific point."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing components of the ablation study ('CapCapNEClipNEEA' and 'CapCapNEClipNENEEA') and suggests adding them. It also requests 'more detailed analysis,' which is a clear and actionable instruction for the authors. The reviewer directly points out what needs to be done and how.", "grounding_specificity_rationale": "The review point mentions 'ENGINE' and suggests adding specific model combinations. While it doesn't explicitly state the section or table where ENGINE is located, the context implies it's related to the model architecture. The suggestion to 'add' implies a specific location and action. The request for 'more detailed analysis' also points to a specific aspect of the model.", "verifiability_rationale": "The review point makes claims about the ablation study being 'incomplete' and suggests specific actions ('add CapCapNEClipNEEA' and 'CapCapNEClipNENEEA'). It also claims that the authors should 'give more detailed analysis.' These are clear statements that require justification. The reviewer provides reasons for the incompleteness and suggests specific types of analysis, making the claims verifiable.", "helpfulness_rationale": "The review point is highly specific about what is missing in the ablation study and what needs to be done. It directly guides the authors on which components to add and what kind of analysis is required. The request for 'more detailed analysis' is a concrete next step for the authors to improve their work. The reviewer provides clear and actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states a problem: 'why GAN optimization produces both poor mode coverage in GDIM and good mode coverage in DDGAN?' and then suggests a concrete action: 'It would be more convincing if the authors could provide results on more challenging highresolution datasets like LSUN and ImageNet.' This indicates an explicit identification of an issue and a clear, actionable suggestion.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify which part of the paper or methodology is being affected by the mode coverage issue. While they suggest experiments on 'highresolution datasets like LSUN and ImageNet', they don't specify which section or table in the paper these datasets are intended to address. The reference to 'GDIM' and 'DDGAN' suggests they are referring to specific methods or experiments described elsewhere, but without a direct link, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim: 'It would be more convincing if the authors could provide results on more challenging highresolution datasets like LSUN and ImageNet.' This is a statement that requires justification. While the reviewer implies a general understanding of the challenges GANs face with highresolution data, they do not provide specific references or examples to support this claim within the review point itself.", "helpfulness_rationale": "The reviewer's suggestion to provide results on 'more challenging highresolution datasets like LSUN and ImageNet' is a valuable suggestion for improving the paper. However, it doesn't directly address the current issues in the draft. It's a suggestion for future work rather than a direct improvement of the existing content. Therefore, while relevant, it doesn't immediately help the authors with their current submission."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states they do not understand the meaning of the statement 'Each attribute of the table feature represents a scene'. This indicates that the explanation of this statement in the original paper was not clear enough or direct enough. The reviewer is implicitly asking for clarification on how this statement should be interpreted, which is an implicit action. While the action of clarifying is present, the concrete steps or information needed for clarification are not explicitly stated, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer directly references 'Section 5.1' in their review point. This is a clear and explicit identification of the specific part of the paper being discussed. Furthermore, the reviewer asks 'what does this mean?' regarding the attributes of the table feature, which is a specific request to detail the meaning of a particular element within that section. Therefore, the grounding is fully specific.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. The reviewer is asking for clarification on a statement made in the paper. Verifiability applies to claims that are made, not requests for clarification. Therefore, this review point does not fall under the category of verifiable claims.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific point in the paper ('Section 5.1: Each attribute of the table feature represents a scene'). This is a relevant and direct feedback for the authors, as they are seeking to understand a detail that is central to the paper's content. While the request itself doesn't directly lead to a concrete change, it contributes to the authors' understanding and ability to improve their work. Therefore, it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a question about the methodology, which implies a desire for clarification and guidance on how to improve the work. While not a direct instruction on how to fix something, the act of asking a question about a specific aspect of the paper can be considered actionable in the sense that it prompts the authors to seek more information or clarification. The reviewer is seeking to understand the impact of different aggregation methods, which is a relevant question for improving the analysis.", "grounding_specificity_rationale": "The reviewer does not explicitly identify which part of their previous response (the ablation study) they are referring to. The request is general: 'Similarly, there is no ablation study provided for the impact of token reweighting vs the logsumexp aggregation scheme.' There is no specific section, table, figure, or unique element of the paper being addressed. The reviewer is asking about the existence and content of an ablation study in general, not pointing to a specific location within their own writing.", "verifiability_rationale": "The reviewer states that there is 'no ablation study' and asks 'How much better is logsumexp aggregation than direct addition...'. While the claim about the lack of an ablation study could be argued as verifiable by checking the paper, the *process* of comparing the methods and determining how much better one is than the other is not explicitly justified or supported by external references or logical reasoning within the review point itself. The request for clarification also suggests a lack of immediate understanding or justification. Therefore, it is not 5 as the reviewer is not providing the reasoning or evidence themselves.", "helpfulness_rationale": "The reviewer's request for comparisons and clarifications directly addresses the quality and usefulness of the paper's content for the authors. They are asking for information that would likely be beneficial for the authors to understand and potentially improve their work. The request for how much better logsumexp is than direct addition, and the request for clarification on the impact of token reweighting, are both requests for information that would likely be helpful. The reviewer is not simply stating a fact; they are actively seeking to understand and improve the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point does not explicitly state what the authors should do. While it implies the need for more data, the specific actions or modifications are not clearly defined. The suggestion to 'consider larger datasets' is a general direction rather than a concrete action.", "grounding_specificity_rationale": "The review point explicitly mentions 'Five datasets' and 'largescale datasets' and even provides references to specific papers (1 and 2). This clearly identifies the specific part of the research or methodology being discussed. The suggestion to 'improve the assortativity of graphs' is a specific detail related to the dataset characteristics.", "verifiability_rationale": "The review point contains claims, such as 'Limited datasets: Five datasets are insufficient to evaluate the effectiveness of ECGs' and 'The largescale datasets mentioned in 2 should be considered'. These claims are supported by references to existing literature, making the information verifiable.", "helpfulness_rationale": "The review point identifies a clear weakness in the current evaluation of ECGs, specifically the limited number of datasets. It offers a relevant suggestion by pointing towards the potential of largescale datasets as mentioned in recent research. While it doesn't provide specific implementation details, it offers a valuable direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a limitation in the type of ResNet analyzed (fully connected vs. typical with convolutions) but does not explicitly state how the authors should address this. The action is implied but not directly stated as 'improve the analysis to include convolutional layers' or similar. The reviewer points out the discrepancy but doesn't provide a concrete action for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'fully connected ResNets' generally, but doesn't explicitly identify the specific section, table, figure, or unique aspect of the paper where this limitation is relevant. The authors would need to infer the intended target based on the context of the paper, making the grounding weak.", "verifiability_rationale": "The reviewer makes a claim that 'ResNets typically use convolutional layers in practice' which is a generally accepted fact. This claim is supported by common knowledge, making it verifiable. The reviewer doesn't need to provide external references for this point.", "helpfulness_rationale": "The comment highlights a limitation that could affect the practical relevance of the work. It points out that the analysis might not reflect realworld ResNet implementations. While it doesn't tell the authors *how* to fix this, it identifies a meaningful issue, making it 3 in guiding the authors towards considering more practical architectures."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly mentions 'standard KD methods' and their performance, providing a clear action. While it could be more explicit about the *how* of applying these methods, it clearly identifies a potential improvement strategy.", "grounding_specificity_rationale": "The review point explicitly mentions 'a ResNet18' as the student model and 'improving its performance' as the goal. It also names specific KD methods, indicating a clear focus on a specific part of the paper and the issues within it.", "verifiability_rationale": "The review point contains the claim 'Standard KD methods... have surpassed the reported KD performance.' It provides evidence for this claim by referencing the performance levels on similar architectures (MNIST, SVHN, CIFAR10) and naming specific KD methods (Hinton et al., 2015; FitNets). However, it lacks a detailed explanation of *why* these methods surpass the reported performance.", "helpfulness_rationale": "The review point identifies a performance gap in KD and suggests exploring 'standard KD methods' as a potential solution. This directly addresses a common issue and offers a concrete direction for the authors to explore, making it 5 in guiding improvement efforts."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly asks a question about the limitations of the proposed framework's assumption regarding causal relationships in GNNs, specifically mentioning the coupled message passing in models like GeniePath and Gated GNNs. This constitutes an explicit action to identify a potential issue.", "grounding_specificity_rationale": "The reviewer mentions specific GNN variants (GeniePath and Gated GNNs) and a specific mechanism (LSTMlike coupled message passing) as evidence of how message passing and routing are learnt, providing a clear grounding of the criticism.", "verifiability_rationale": "The reviewer raises a concern about the assumptions of the proposed framework regarding causal graphs in GNNs, but does not explicitly state a claim that requires verification. It's a question about the validity of an assumption.", "helpfulness_rationale": "The reviewer's point is primarily a question seeking clarification about the limitations of the proposed framework's assumptions. While relevant, it doesn't offer a direct suggestion for improvement or critique of the paper's content itself."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that they only considered messagepassing layers and found it to be the most important part of GNNs. This is a direct criticism of the paper's framing. Furthermore, the reviewer suggests that this claim is not convincing because different tasks use different pre/postprocessing modules. The reviewer also proposes including the performance of SOTA algorithms in the discussion. These are concrete suggestions for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'messagepassing layers' and 'pre/postprocessing modules,' which are specific concepts within the GNN architecture. This demonstrates strong grounding. The reviewer also explains *why* messagepassing is important and *why* the paper's claim might be problematic, providing a clear explanation of the issue.", "verifiability_rationale": "The reviewer makes a claim that including the performance of SOTA algorithms would be beneficial. However, the reviewer does not provide any evidence or justification to support the claim that stating messagepassing is the most important part is unconvincing. The suggestion is a potential improvement, but it lacks verification.", "helpfulness_rationale": "The reviewer identifies a potential issue with the paper's framing regarding the importance of messagepassing layers. The reviewer's suggestion to include the performance of SOTA algorithms is a concrete and actionable improvement that could help the authors better understand their model's strengths and weaknesses. While the suggestion itself isn't proven, it provides a clear direction for improvement."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The review point identifies a weakness in the paper but does not explicitly state how the authors should address it. While it points out the *lack of evidence* and the *need for comparison*, it doesn't provide concrete steps on how to demonstrate this or how to make the comparison. The weakness is implicitly stated, but the action is missing.", "grounding_specificity_rationale": "The review point clearly identifies the *area* where the paper lacks evidence and the need for a direct comparison. It doesn't point to a specific section or table but rather to a conceptual gap in the methodology. The grounding is present as the weakness is welldefined, even if the specific implementation details are not.", "verifiability_rationale": "The review point makes a claim that 'I find there is little evidence in the paper for why learning it directly with your method is important compared to the methods.' This claim is not fully supported by the reasoning, common knowledge, or external references provided in the review point itself. While it identifies a potential area for improvement, it doesn't provide evidence or justification for *why* this is a critical issue.", "helpfulness_rationale": "The review point is 3 because it identifies a specific area for improvement in the paper \u2013 the lack of evidence and the need for a direct comparison. It highlights a potential weakness in the methodology. However, it doesn't provide concrete suggestions or guidance on how to address this weakness, making it less helpful than a point that offers specific solutions."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the issue: 'Some explanations about the meaning of the variable symbols such as \u03c2 ,r_i ,\u03b1_i and so on in the appended algorithms could be added.' This directly points to a need for clarification and action.", "grounding_specificity_rationale": "The comment explicitly mentions 'appended algorithms' and specifies the type of explanation needed 'about the meaning of the variable symbols'. This allows the authors to identify the specific section and the nature of the required information.", "verifiability_rationale": "While the reviewer is suggesting an improvement, the *implication* is that understanding these symbols is crucial for using or interpreting the algorithms. However, the reviewer doesn't explicitly state that *this lack of explanation is a flaw that needs to be pointed out*. Therefore, it's 2. The reasoning for the suggestion is implicit.", "helpfulness_rationale": "The reviewer is suggesting a specific and actionable improvement: adding explanations for the variable symbols. This directly addresses a potential usability issue and is beneficial for the authors. While it could be more specific, it's a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies the *lack of innovation* and *limited performance gains* as issues. This is an explicit statement of a problem. However, the reviewer does not specify *how* the method lacks innovation or what specific aspects need improvement, making it implicit and vague.", "grounding_specificity_rationale": "The reviewer's comment is about the *entire method* lacking innovation and the *performance gains* being limited. The reviewer does not pinpoint a *specific* section, table, figure, or unique aspect of the paper. The comment is broad and lacks specific references.", "verifiability_rationale": "The reviewer states that the *method lacks innovation* and that this *further suggests* incremental changes. This is a claim. The reviewer provides the *limited performance gains* as supporting evidence, which is logical reasoning. However, the reviewer does not provide specific examples or citations to back up their claims.", "helpfulness_rationale": "The reviewer criticizes the method's lack of innovation and suggests it's merely incremental. While this points out a potential issue, the reviewer does not offer concrete *solutions* or *specific steps* to address this problem. The feedback is focused on the *problem* rather than providing clear guidance on how to solve it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out that the prediction performance of PHGDN_C on the real dataset does not outperform existing methods. While this identifies a weakness, the reviewer does not explicitly state the *action* the authors should take. They could infer that the authors should investigate the reasons for this gap, but the specific steps are not provided. Therefore, the action is implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'PHGDN_C' and 'prediction performance on the real dataset (longrange graph benchmark)'. This clearly identifies the specific part of the paper being addressed, making the grounding fully grounded. The issue is also clearly stated within this context, making it specific.", "verifiability_rationale": "The reviewer states that 'the prediction performance on the real dataset (longrange graph benchmark) does not outperform existing methods'. This is a claim made by the reviewer. However, the reviewer does not provide any supporting evidence, logical reasoning, or external references to back up this claim. The statement is presented as a fact without justification.", "helpfulness_rationale": "The reviewer identifies a performance gap for PHGDN_C on a specific dataset. While this points out a potential limitation, the reviewer does not offer any suggestions or insights on how to address this issue. The review stops at identifying the problem without providing any constructive feedback to the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the comparison is 'unfair' and provides a clear explanation for why it is unfair, identifying the different targets of the algorithms (equilibrium for multiagent online RL vs. policy optimization for singleagent offline RL). This constitutes an explicit action with concrete details.", "grounding_specificity_rationale": "The reviewer mentions 'offline RL algorithms' and 'single agent' when identifying the target of the algorithms being compared. This demonstrates some level of grounding, but the reviewer does not explicitly state the *difference* in the target (equilibrium vs. policy optimization) or provide specific examples of what needs to be addressed in the comparison.", "verifiability_rationale": "The reviewer makes a claim: 'It is unfair to compare the proposed algorithm with the offline RL algorithms for single agent...'. This claim is supported by the reasoning that 'the target of those algorithms is not to find an equilibrium'. This reasoning is logical and based on the fundamental goals of these algorithm types.", "helpfulness_rationale": "The reviewer points out a potential misunderstanding or flaw in the comparison being made, which could be valuable feedback for the authors. While they don't offer a specific alternative comparison, they highlight a problem with the current comparison, making it helpful in identifying an issue."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the overlap is 'general' and 'not specific,' implying that while the connection between the three tasks and prior work exists, it's not explicitly defined or clearly articulated. The reviewer suggests that the authors could identify the overlap, but the action isn't directly stated. The lack of explicit instructions makes it difficult to pinpoint the exact action the authors should take to address the overlap.", "grounding_specificity_rationale": "The reviewer's statement that the comment is '1' is supported by the fact that the overlap is described generally as 'partial coverage' and 'partially covered.' The paper doesn't explicitly mention the three tasks or the specific prior benchmarks being referred to. While the tasks themselves are specific, the connection to the prior work is implied rather than explicitly stated, making the grounding weak. The comment also lacks specific examples of how the overlap manifests in existing benchmarks.", "verifiability_rationale": "The reviewer claims the claim is '1' because the paper lacks 'detailed comparisons' to similar works. The comment identifies a potential issue (overlap) but doesn't provide concrete evidence or reasoning to support this claim. The lack of specific examples or references makes it difficult to verify the extent of the overlap and the paper's unique contributions.", "helpfulness_rationale": "The reviewer suggests the comment could be helpful by clarifying the paper's unique contributions. While the comment points out a potential area for improvement, it doesn't offer concrete, actionable steps or specific examples to guide the authors. The helpfulness is limited to a general suggestion of clarification, rather than specific, detailed improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that 'Section 1, \"human perception is usually invariant to the texture resampling\u2026\" lacks support materials.' This clearly identifies an action the author should take: investigating the claim in Section 1 for supporting evidence. However, the comment doesn't specify *what kind* of support is missing (e.g., citations, experimental data, theoretical justification). Therefore, while the action is identified, the specifics are vague.", "grounding_specificity_rationale": "The comment explicitly refers to 'Section 1' and the specific claim within that section, 'human perception is usually invariant to the texture resampling\u2026'. This allows for precise identification of the part of the paper being addressed. However, while the section is identified, the *specific type* of information lacking (support materials) is not specified. The claim within the section is also not detailed beyond the general statement of a lack of support.", "verifiability_rationale": "The comment states that 'Section 1, \"human perception is usually invariant to the texture resampling\u2026\" lacks support materials.' This is a claim that needs to be verified. However, the review point itself does not provide any evidence, reasoning, or references to support this claim. It simply states the absence of support. Therefore, the claim is not verifiable based on the information within the review point.", "helpfulness_rationale": "The comment points out a valid weakness in the author's work: the lack of support for a claim in Section 1. This highlights an area where the author could improve their manuscript by either providing the missing support or acknowledging this limitation. While the comment identifies a problem, it doesn't offer a specific solution or guidance on how to find the missing support. Therefore, it is helpful in identifying an issue but lacks the actionable steps that would make it 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that MiPKD is 'not specially designed for the SR task' and suggests 'additional experiments on a broader range of tasks'. This provides a clear action for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'MiPKD\u2019s performance in SR tasks' and then clearly states 'MiPKD is not specially designed for the SR task'. This directly identifies the specific part of the paper and the issue within it.", "verifiability_rationale": "The reviewer makes a claim about MiPKD's design and suggests additional experiments. While the claim is not fully supported by explicit citations, the suggestion to show applicability to other tasks implies a logical connection between the observed focus on SR tasks and the potential lack of special design for that task. The suggestion itself is a form of implicit justification.", "helpfulness_rationale": "The reviewer directly points out a potential limitation in the paper's scope and provides a clear suggestion for improvement by conducting additional experiments. This is a constructive and actionable piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests removing Equations 21 and 22. This is an explicit statement of a proposed change. While the reviewer doesn't provide specific details on how these equations are problematic or how their removal would benefit the authors, the act of suggesting their removal is a clear action. The vagueness of the action makes it less concrete.", "grounding_specificity_rationale": "The reviewer refers to 'Equations 21 and 22' specifically. This is a clear and explicit reference to a specific part of the paper. The reviewer also provides a specific detail about these equations: they describe an alternative scheme that is not used. This specificity allows the authors to understand exactly what the reviewer is pointing out.", "verifiability_rationale": "The reviewer makes a judgment that 'Equations 21 and 22 describe an alternative scheme which is not actually used... and I believe they may be omitted without hampering the flow of that section.' This statement contains a claim (the belief about the alternative scheme and its nonuse). While the claim is based on the reviewer's interpretation of the equations, it is supported by the description of the equations and the assertion of nonuse. The reviewer provides specific details about the nature of the alternative scheme, making the claim verifiable.", "helpfulness_rationale": "The reviewer's suggestion to omit Equations 21 and 22 is a direct and actionable comment aimed at improving the clarity and flow of the paper. By suggesting the removal of what they perceive as an unnecessary alternative scheme, the reviewer is providing a concrete piece of feedback that could directly benefit the authors by reducing potential confusion or redundancy. The suggestion is specific to a particular part of the paper, making it a targeted and helpful comment."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point mentions 'a simple iteration strategy' which is an explicit statement. However, it does not specify what this strategy is or how it should be improved. The reviewer implies a lack of sophistication but doesn't provide concrete actions or suggestions for the authors to take. Therefore, while the action is mentioned, the lack of detail makes it 1.", "grounding_specificity_rationale": "The reviewer refers to 'the optimization module,' which grounds the comment to a specific part of the paper. However, they do not specify *which* aspect of the module or *why* it is considered 'simple' or 'incremental.' The reference to the module is general, and the implications are vague. Thus, while a part is identified, the specifics are lacking, making it 2.", "verifiability_rationale": "The reviewer makes claims such as 'the optimization module applies a simple iteration strategy' and 'the overall model stands on the shoulder of some traditional approaches and seems a bit incremental.' These are claims that could potentially be supported by evidence. However, the review point itself does not provide the *verifiable* justification for these claims. The reasoning is stated but not backed up with details or references within the provided text. Therefore, the claims are stated but not 5 within the review point.", "helpfulness_rationale": "The reviewer points out a potential lack of sophistication in the optimization strategy and compares the model to 'traditional approaches,' suggesting a lack of novelty. While this highlights a potential weakness, the review point does not offer specific, actionable suggestions for improvement. The feedback is present but lacks concrete guidance, making it 3 but not highly so."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a lack of understanding regarding a specific technical detail (the choice of F(X) for the E(d) case). This is an explicit action the reviewer is requesting. The reviewer also suggests a concrete solution (elaborating on an example), making it actionable.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific technical detail (F(X) for the E(d) case) they are struggling with. They are not referring to a general area of confusion, but a very specific mathematical object. They are asking for clarification on how this specific object is defined. This indicates strong grounding as the authors can easily identify the referenced part.", "verifiability_rationale": "The reviewer does not explicitly state a claim about the quality or correctness of the paper. Instead, they are pointing out a potential area of confusion for themselves regarding a specific technical detail. Therefore, this review does not contain a claim that needs verification. The category is 'X'.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential area of confusion for them. By clarifying this, they are likely to improve their understanding of the paper. The reviewer's suggestion to elaborate on an example is a concrete way to address this confusion, making the review potentially very helpful."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about implicit assumptions, which implies an action of trying to understand or identify these assumptions. However, the question is quite general and doesn't specify which fewshot learning method or detail the author is referring to, making it difficult to pinpoint an exact action. Therefore, it's 2.", "grounding_specificity_rationale": "The reviewer mentions 'metadistribution assumption' and 'distributioncloseness assumption,' which are general concepts in the field of fewshot learning. While they are relevant to the topic, they don't specifically point to a particular section, table, figure, or unique element within the submitted paper. The grounding is weak because the reviewer is referring to general knowledge rather than specific details of the work. Therefore, it's 2.", "verifiability_rationale": "The reviewer is making a claim by asking about 'implicit assumptions this paper adopts.' This is a factual question about the underlying principles of the submitted work. While the information might not be explicitly stated in the paper, the claim itself is verifiable based on the general understanding of fewshot learning and potentially by looking for similar papers or metalearning frameworks. Therefore, it's 3 as the claim is factual, even if the supporting evidence isn't directly in the paper. It's not 5 because the specific assumptions are unknown without further investigation.", "helpfulness_rationale": "The review point is relevant to the author as it touches upon the fundamental assumptions underlying fewshot learning, which can influence their approach to the task. However, the question is quite broad and doesn't provide specific guidance or actionable steps for the author. While it's helpful in pointing out a potential area of concern, it lacks the specificity needed for direct implementation. Therefore, it's 3 as it raises a relevant question, but it doesn't offer concrete solutions or directions. It's not fully helpful because it doesn't directly address the author's specific needs or provide actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the comparison to prior work can be 'more thorough' but does not specify how this should be achieved. The action is implied (improving the comparison), but the method is not concrete, making it vague and less actionable.", "grounding_specificity_rationale": "The reviewer mentions 'comparison to prior work,' 'other tasks,' and 'largescale models' as areas for improvement. This provides a basis for grounding the suggestion, but the reviewer does not specify which prior work, tasks, or models are relevant. The grounding is present but lacks specificity.", "verifiability_rationale": "The review point does not contain a claim or suggestion. It is a statement of desire for more detail rather than a claim that needs verification.", "helpfulness_rationale": "The reviewer suggests comparing to 'more standard benchmarks' and considering 'other tasks and the largescale models' as ways to improve the comparison. This provides potential actionable feedback, making it 3. However, the suggestions are broad and lack specific details, making it less fully helpful."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states a similarity to a 'traditional removal method' but doesn't explicitly identify an action or suggest how to improve the method. While they express a belief, the action is not clearly defined or actionable. The reviewer points out a potential weakness but doesn't offer concrete steps to address it.", "grounding_specificity_rationale": "The reviewer refers to the 'manuscript' and 'traditional removal method' generally, without specifying which part of the paper or method they are referring to. They don't mention specific sections, tables, figures, or unique elements. The criticism is broad and lacks specificity.", "verifiability_rationale": "The reviewer makes a claim that the 'contribution of the manuscript still has room for improvement' but provides no evidence or reasoning to support this claim. They express a belief but don't back it up with specific examples or analysis. The claim is presented without sufficient justification.", "helpfulness_rationale": "The reviewer's comment is primarily a critique of the manuscript's contribution, expressed as a negative opinion. They don't offer any specific suggestions or actionable steps for the authors to improve their work. The feedback is general and doesn't provide direction for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state what the author should do to improve their understanding of the benefits. It identifies the difficulty in grasping the benefits but does not provide concrete steps or actions for the author to take. The reviewer is stating a problem, not offering a solution or actionable advice.", "grounding_specificity_rationale": "The review point does not specify which part of the paper or concept the author should focus on. It discusses the general difficulty in understanding the benefits without pinpointing a specific area of the paper that is causing this difficulty. The mention of 'benefits of the learning process' is general and does not identify a specific section or element.", "verifiability_rationale": "The review point does not make a claim that requires verification. It describes the difficulty in understanding the benefits rather than making a statement that needs to be supported by evidence or reasoning. There is no assertion of a problem that needs to be justified.", "helpfulness_rationale": "The review point is not helpful because it does not provide any actionable feedback or suggestions for the author. It identifies a problem (the abstract nature of the benefits) but does not offer any concrete steps or guidance on how to address this problem. The suggestions made in the review point are the same as the issues identified."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer is asking a question about the paper's categorization, which is an implicit action suggesting the need to understand the connection between the paper and Fairness/Accountability/Transparency. However, the question is broad and doesn't provide specific details on how to apply this understanding. The action is present, but it's not very concrete.", "grounding_specificity_rationale": "The reviewer is asking a question about the paper's categorization, which doesn't directly identify a specific part of the paper. The reference is to the *category* itself, not a specific section or element within the paper. Therefore, the grounding is weak as the authors can only make an educated guess about the referenced part (the paper's relevance to the category). The specificity is low as the question is about classification, not a specific detail within the paper.", "verifiability_rationale": "The reviewer is making a claim that the paper is categorized under Fairness/Accountability/Transparency. However, they are asking *why* this is the case, which requires justification or evidence. The review point doesn't provide any logical reasoning, common knowledge, or external references to support this categorization. It's a question prompting for further explanation, not a verifiable statement.", "helpfulness_rationale": "The reviewer is asking a question about the paper's categorization. While this prompts the authors to consider the ethical implications of their work, it doesn't directly point out a specific weakness or improvement area. The comment is a metacomment about the paper's classification, not a direct critique or suggestion for change. Therefore, it's not particularly helpful in guiding the authors' revision process."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly asks for a 'machine learning 2step baselines' and an 'explanation' for the performance difference. This indicates a desire for specific, actionable feedback.", "grounding_specificity_rationale": "The review point requests a 'machine learning 2step baselines' but does not specify which part of the paper this comparison should relate to. The grounding is in the type of baseline, not a specific section or element.", "verifiability_rationale": "The review point contains a claim ('It would have been useful to include a machine learning 2step baselines') but does not provide any supporting evidence or justification for this claim. The verifiability is low as there is no logical reasoning or references provided.", "helpfulness_rationale": "The review point is a critique and a suggestion for improvement, rather than a direct request for feedback on the current draft's weaknesses. While it points to a potential flaw in the comparison, it doesn't actively guide the authors towards a solution within the current review context."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the results seem better than other methods but doesn't explicitly say *how* the better image generative model contributes to this improvement. While they suggest an experiment, the action itself of comparing with other models is not explicitly stated within the review point itself. The reviewer implies the cause but doesn't explicitly state the action to be taken or the expected outcome.", "grounding_specificity_rationale": "The reviewer mentions 'image generative model' and suggests a comparison using 'other image generative models'. This indicates a clear identification of the specific aspect of the paper being addressed (the model) and a specific suggestion for improvement (comparing with other models). The mention of 'other' models also implies a clear specification of what needs to be addressed.", "verifiability_rationale": "The reviewer claims the better results are due to the image generative model but doesn't provide any evidence or justification for this claim within the review point. While they suggest an experiment, the reasoning behind why this experiment would confirm their hypothesis is missing. The suggestion itself is a form of verification, but the lack of supporting evidence makes it 2.", "helpfulness_rationale": "The reviewer points out a potential confounding factor (the image generative model) and suggests an experiment to address it. While this is a relevant critique and a constructive suggestion for improvement, the review point itself doesn't directly propose a concrete change to the draft. It identifies a limitation or a missing piece in the current evaluation, but doesn't actively help the authors improve their current draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the weakness: 'the comparative study should include the SOTA methods' and 'Given this lack of comparison, I believe that the claim of the authors \u201c...which lead to the information of the modalitymissing data not being well exploited to\u201d was not justified as well.' While it doesn't explicitly name what is missing, the intent is clear. Therefore, it is considered **partially actionable** as the authors can infer that they should add these comparisons. However, the action is vague as the authors don't know which specific SOTA methods are missing or how to implement the comparison.", "grounding_specificity_rationale": "The comment explicitly mentions 'SOTA methods' by name (Ma et al (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), Suo et al., (2019)) and also refers to a specific claim made by the authors regarding the exploitation of modalitymissing data. This provides strong grounding as the authors can accurately pinpoint the referenced part of the paper and the issue being addressed.", "verifiability_rationale": "The comment makes a claim about the authors' justification for a specific claim being weak ('I believe that the claim of the authors \u201c...which lead to the information of the modalitymissing data not being well exploited to\u201d was not justified as well'). It then provides a reason for this belief ('Given this lack of comparison'). This reasoning is logical and directly supports the claim, making it **5**.", "helpfulness_rationale": "The comment clearly identifies a weakness in the authors' justification: the lack of comparison with stateoftheart methods. It provides a reason for this weakness ('Given this lack of comparison...') and suggests a potential flaw in the authors' claim ('...the claim of the authors \u201c...which lead to the information of the modalitymissing data not being well exploited to\u201d was not justified as well'). This is a valuable critique that points to a potential issue in the authors' reasoning and highlights the importance of comparing with SOTA. The reviewer provides a clear reason for why the authors' claim might be flawed, making it a 5 comment."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer raises a valid point about the clarity of the task description. While the paper defines the task as 'plain polarity classification,' the mention of 'opinion holder' and 'opinion targets' could be interpreted as suggesting a more complex task involving opinion mining. The reviewer's question is explicit about whether these terms are relevant to the actual experiments. If the experiments are solely based on 'plain polarity classification' and these terms are just additional information, the reviewer's confusion is understandable. The reviewer is essentially asking for clarification on how the mentioned concepts relate to the experimental methodology. This is a direct request for more specific details about the authors' approach.", "grounding_specificity_rationale": "The reviewer's comment is 1 in the paper. The comment is a question about the relevance of specific terminology ('opinion holder' and 'opinion targets') to the experiments described in the paper. There is no explicit mention of sections, tables, figures, or unique elements of the paper that would allow the authors to identify where this question is being directed. The comment is general about the content of the paper (the task definition) and then asks about related concepts.", "verifiability_rationale": "The verifiability of the reviewer's comment is unclear. The comment is a question about the relevance of specific terminology to the experiments. There is X being made in the review point itself. The comment is not presenting a statement that requires justification or evidence. It's a direct inquiry about the connection between the defined task and potential related concepts.", "helpfulness_rationale": "The helpfulness of this review point is low. The comment is a question about the relevance of specific terminology to the experiments. It does not directly point to a flaw in the authors' methodology or suggest a concrete improvement. The comment is more of a clarification request than a constructive feedback point. The authors would need to explicitly state the connection between the defined task and the mentioned concepts to make this review point helpful."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states 'we cannot judge how much enforcing the equivariance strictly is beneficial' and then provides a reason 'because the original CapNet does capture some variations in the data.' While the reviewer identifies a specific area of concern, the lack of a direct action or suggestion on how to address this is the key factor. The reviewer is pointing out a limitation in the experimental setup rather than proposing a concrete improvement.", "grounding_specificity_rationale": "The reviewer refers to 'the capsule networks' and specifically compares 'group CapNet' and 'simple CapNet'. This demonstrates an attempt to ground the comment in the paper. However, the reviewer does not provide a specific section, table, or figure number where these networks are discussed. The mention is general, and the reviewer doesn't point to a unique aspect. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim: 'unfortunately, in the experiments the group CapNet is deeper than the simple CapNet and the authors do not provide the number of parameters in the group CapNet. So, we cannot judge how much enforcing the equivariance strictly is beneficial.' This claim is not supported by any logical reasoning, common knowledge, or external references within the provided text. The reviewer states the observation about the group CapNet's depth and the missing parameter count but doesn't explain *why* this makes the judgment impossible or provide any evidence to support this assertion.", "helpfulness_rationale": "The reviewer's comment raises a concern about the experimental setup and asks a question. While the reviewer identifies a potential issue ('unnecessarily restricting'), they do not provide a concrete solution or actionable steps for the authors to address this. The lack of information about the number of parameters in the group CapNet prevents the authors from making an informed decision about the impact of equivariance. Therefore, the reviewer's comment is more of a question and a statement of uncertainty rather than a direct and helpful suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly names 'FastDiME' and 'He et al.(https://openreview.net/forum?id=o3BxOLoxm1)' and suggests a 'more efficient implementation' of the 'Tweedie approach'. This provides a clear direction for improvement and is a concrete action the authors can take. The reviewer also points out that 'DiME' has been used in a similar context, which is a direct link to existing work. The suggestion to explore 'more efficient implementations' is a specific action the authors can undertake.", "grounding_specificity_rationale": "The reviewer refers to 'various approaches such as DiME' and then provides specific examples like 'FastDiME and He et al.(https://openreview.net/forum?id=o3BxOLoxm1)'. The core concept being discussed is 'efficient implementations of the Tweedie approach'. While the exact section or page isn't explicitly mentioned, the context of discussing 'noisy (intermediate) images' and 'gradients' strongly implies a specific part of the paper. The reviewer clearly identifies the problem ('obtaining meaningful gradients with respect to noisy (intermediate) images') and suggests a solution ('more efficient implementations'). The mention of 'DiME' and the 'Tweedie approach' provides the basis for this claim within the specific context.", "verifiability_rationale": "The reviewer makes a claim: 'Both FastDiME and He et al.(https://openreview.net/forum?id=o3BxOLoxm1) have (more?) efficient implementations of the Tweedie approach'. This claim is supported by the information provided in the review point. The reviewer names specific related works and suggests a direction for improvement, providing a basis for verification. The mention of 'DiME' and the 'Tweedie approach' provides the context for this claim.", "helpfulness_rationale": "The review point is highly specific and actionable. The reviewer identifies a relevant problem in the existing literature (inefficient implementations of Tweedie methods) and offers a concrete suggestion (exploring more efficient implementations of the Tweedie approach). The reviewer also points to specific related works ('DiME', 'FastDiME', 'He et al.(https://openreview.net/forum?id=o3BxOLoxm1)'). This provides valuable information and a clear direction for the authors to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the benefit of including an evaluation of inference speed on the hardware, which is a direct action the authors should take.", "grounding_specificity_rationale": "The comment implies the authors are referring to the evaluation of the model's performance on the hardware it was trained on/tested on, and specifically asks for 'inference speed on the hardware', which is a very specific request.", "verifiability_rationale": "The comment itself is not a claim that needs to be verified. It's a suggestion for improvement.", "helpfulness_rationale": "The comment directly addresses a potential weakness (lack of hardware evaluation) and proposes a concrete solution (including such an evaluation), making it 5 for the authors to consider and potentially implement."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer implicitly points out a potential weakness: the lack of detail regarding the SDP formulation. While they don't explicitly state 'You should add an SDP formulation,' the mention of convexity and SDP suggests that the current draft might be missing this crucial detail. The action is implicit, as the reviewer identifies a missing element but doesn't directly instruct the author on how to add it. The vagueness comes from not specifying the exact nature of the SDP formulation or where it would be located in the paper.", "grounding_specificity_rationale": "The reviewer mentions 'this modified problem' but doesn't specify where the SDP formulation is located or what aspect of it they are referring to. They imply it exists because the problem is convex and can be solved via an SDP, but they don't provide a concrete reference (e.g., 'in Section 3.2'). This lack of specificity means the reviewer can only make an educated guess about the location and content of the SDP formulation. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim: 'This modified problem is convex and can be solved via an SDP.' However, they do not provide any justification or evidence for this claim within the review point itself. There is no logical reasoning, common knowledge, or external references to support this statement. The claim is presented without any backing, making it 1 based solely on the information provided in this review point.", "helpfulness_rationale": "The reviewer's point is about identifying a potential improvement area: the lack of detail regarding the SDP formulation. While this is a valid concern and could be helpful for the author in the long term, the reviewer doesn't directly instruct the author *what* to do. They point out a missing piece of information but don't provide a concrete action for the author to take. Therefore, while it offers a suggestion for improvement, it doesn't directly help the author address a specific weakness in their current draft."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded", "verifiability_label": "UnderSpecific", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out two key areas of concern: the lack of detail regarding the number of task combinations used and the limited size of the test set. While the reviewer doesn't explicitly state what action should be taken, they imply a need for more information and a larger evaluation set. The reviewer's point is not about a missing action itself, but about the need for the authors to take a specific action. Therefore, it's not entirely explicit. The reviewer also doesn't specify how the task combinations were created or if there are any potential biases. This lack of detail makes the reviewer's point somewhat vague and implicit. The reviewer's point is about the *content* of the paper (the evaluation methodology) rather than a direct instruction on what to do. Therefore, it's not fully grounded.", "grounding_specificity_rationale": "The reviewer refers to 'line 558' and 'Table 7' as specific parts of the paper. However, they don't explicitly state which section or table within those locations is lacking information. The criticism is about the *content* of those locations (lack of detail on task combinations and test set size) rather than a direct reference to a specific element within them. The reviewer is implicitly pointing to a lack of grounding in the specific details of the evaluation process.", "verifiability_rationale": "The reviewer states a problem (lack of detail) and a finding (limited test set). This is a statement of judgment and requires justification. The reviewer is highlighting a potential limitation of the evaluation methodology. While the reviewer points out a valid concern, they don't provide a direct solution or cite external references to support their claim about the limited test set size. The claim is presented as a problem without a clear justification within the review point itself.", "helpfulness_rationale": "The reviewer raises concerns about the completeness and robustness of the evaluation methodology. While their point is valid, it doesn't directly provide a solution or actionable advice for the authors. The reviewer is highlighting a potential issue that the authors should consider, but they haven't offered any concrete steps or suggestions to address it. The reviewer's point is about identifying a problem, not providing a solution."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement explicitly mentions the 'figures' and criticizes their 'layout', which are concrete actions and specifics. The reviewer is suggesting a change to how the figures are presented.", "grounding_specificity_rationale": "The reviewer mentions 'the figures' generally, without specifying a particular section, table, or unique element within the figures. The reference is broad and lacks precision.", "verifiability_rationale": "The statement is a claim about the quality of the figures' layout. However, there is no supporting evidence or justification provided to back up this claim. The verifiability relies on the reviewer's subjective assessment of the layout.", "helpfulness_rationale": "The review points out a potential issue (poor figure layout) but does not offer any suggestions or actionable steps for improvement. It is a negative statement without a constructive counterpoint."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the paper's contributions may be perceived as incremental or lacking substantial novelty. This is an explicit action suggesting a potential issue. However, the reviewer does not specify *how* or *where* the paper falls short of existing works, making the action implicit. The request for a 'detailed comparison' is vague and does not point to specific sections or issues.", "grounding_specificity_rationale": "The reviewer makes a general statement about the paper's lack of differentiation from existing works and the need for a 'detailed comparison'. They do not specify which 'existing works' are similar or where the lack of differentiation is most prominent. The comment does not identify a specific part of the paper being addressed, only a general area of concern.", "verifiability_rationale": "The reviewer states that the paper's contributions may be perceived as incremental or lacking substantial novelty. This is a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no justification for why the contributions would be perceived in this way.", "helpfulness_rationale": "The reviewer criticizes the paper's perceived novelty. This is a relevant concern for the authors, as it directly relates to the perceived value and contribution of their work. While the criticism is about a potential issue, it is still a meaningful feedback point that could guide improvements in the paper. The reviewer does not provide specific solutions, but identifying a potential lack of novelty is a helpful starting point for discussion."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The request is a request for information (explaining a discrepancy) rather than a direct action or suggestion. While the request implies a desire for clarity, it doesn't actively prompt the authors to take a specific action. The reviewer is asking *why* something is different, not *how* to improve the baseline.", "grounding_specificity_rationale": "The request is about explaining a discrepancy between two tables. While it implies a desire for clarity, it doesn't explicitly identify the specific section, table, figure, or unique aspect of the paper being addressed. The request is about the *results* rather than a specific part of the paper. Therefore, it's not fully grounded in the paper's content.", "verifiability_rationale": "The request itself doesn't contain a claim that needs verification. It's a request for information about a discrepancy. There's no logical reasoning, common knowledge, or external references being presented within the review point itself.", "helpfulness_rationale": "The request is not inherently helpful as it doesn't provide any actionable feedback or insights. It's a request for information, not a suggestion for improvement. Without actively prompting the authors to take a specific action, it doesn't directly empower them to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer's criticism, while valid, primarily focuses on the *definition* and *verifiability* of 'execution feedback' rather than directly providing actionable feedback on how to improve the draft itself. The criticism points out that the paper uses the term 'execution feedback' (EF) but doesn't actually utilize it in the way it's described. Instead, the method appears to approximate EF based on structural perturbations in the Abstract Syntax Tree (AST). The reviewer argues that the paper assumes any structural perturbation results in a failure, which is not necessarily true. This criticism highlights a lack of clarity and a potential misunderstanding of the method's actual implementation. While the reviewer doesn't propose a specific action, they identify a crucial point of confusion that the authors should address to ensure their understanding is aligned with the paper's claims. The lack of a clear definition and the potential misinterpretation of EF make it difficult for the authors to implement the method correctly.", "grounding_specificity_rationale": "The reviewer provides strong evidence for *grounding specificity*. They explicitly state that the criticism is based on specific evidence from the paper (Lines 233238 and Equation 1), where they point out that the method doesn't actually use execution feedback as described. They also suggest an alternative interpretation of EF based on test suite pass/fail, which further demonstrates a clear understanding of where the paper's description and implementation diverge. The reviewer's analysis is grounded in the paper's content and offers a specific alternative interpretation, making the grounding quite clear.", "verifiability_rationale": "The reviewer's criticism is **1**. They argue that the definition of 'execution feedback' (EF) in the paper is misleading and not supported by evidence. The paper defines EF in terms of whether tests pass or fail, but the reviewer correctly points out that structural perturbations in the AST do not necessarily lead to failing tests. The paper seems to assume that any such perturbation results in a failure, which is a simplification and lacks verifiable support. The reviewer's alternative interpretation of EF based on test outcomes provides a verifiable alternative, but the original definition in the paper lacks this supporting evidence. Therefore, the claim about EF is not justified by the provided information.", "helpfulness_rationale": "The reviewer's criticism is **5**. It clarifies a potential misunderstanding of the method and corrects a misleading terminology ('execution feedback'). By pointing out the discrepancy between the paper's description of EF and the actual implementation based on AST perturbations, the reviewer provides valuable information for the authors to understand and potentially implement the method correctly. The criticism is actionable in the sense that it highlights a key point of confusion that the authors should address. It also provides an alternative, more accurate interpretation of EF, which is beneficial for the authors' understanding of the method's actual implementation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The reviewer states 'Similar' and 'sequence of dots' without explicitly stating what they are similar to or what the implications are. While the reviewer points out a potential issue, they don't provide clear, actionable steps the authors should take. They are pointing out a *similarity* and a *potential bias*, but not *how* to address it. The action is implied but not explicitly stated, and the consequences are not detailed.", "grounding_specificity_rationale": "The reviewer mentions 'target words' and 'a sequence of dots' without specifying *which* target words or *how* the sequence of dots is used. This is a weak grounding because the authors cannot confidently determine which part the comment addresses. The specificity is also low as the reviewer doesn't provide concrete examples or details about the 'target words' or 'sequence of dots' in their context.", "verifiability_rationale": "The reviewer claims that there is no information in terms of what '40 target words' are used, and how 'a sequence of dots' are used to remove bias in the model. The reviewer provides a claim that there is a lack of information and a potential bias. The claim is supported by the reviewer's observation that the information is missing and the concern about the potential bias introduced by the 'sequence of dots'.", "helpfulness_rationale": "The reviewer's comment is not directly helpful to the authors. While they identify a potential issue with the methodology used to evaluate bias, they do not offer any suggestions or solutions. The comment critiques the methodology rather than providing actionable feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The review point identifies limitations in the experimental setup (simple datasets, uniform random missingness) but does not explicitly instruct the authors on how to improve their experiments. While it points out what is lacking, it doesn't provide concrete steps or actions for the authors to take to address these issues.", "grounding_specificity_rationale": "The review point describes the type of experiments conducted (simple datasets) and a characteristic of the missing data (uniform random). However, it does not explicitly identify a specific part of the paper (e.g., a section, table, figure, or unique element) being addressed. The reference is more general to the nature of the experiments and missingness.", "verifiability_rationale": "The review point contains a claim that the experiments are conducted on 'some simple datasets' and that 'the uniformly random missing is also unrealistic in practice.' These are statements that can be verified by examining the paper's content. The reviewer provides specific examples of limitations that could be addressed.", "helpfulness_rationale": "The review point identifies limitations in the experimental setup, which is helpful for the authors to be aware of. However, it does not provide specific, actionable suggestions for how the authors should improve their experiments. The feedback is more about identifying problems than offering direct solutions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the missing element (legends) and the consequence (hard to interpret). It also suggests a specific solution (including explanations of data points). The authors know exactly what is missing and what they need to add.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 4', which is a precise reference to a specific part of the paper. The comment also specifies what is missing ('legends for the plots') and what should be included ('explanation of data points').", "verifiability_rationale": "The comment implicitly suggests an improvement is needed for Figure 4. It provides a clear action (including legends and explanations) to achieve this. While not a strong claim, the suggestion is directly actionable and guides the authors.", "helpfulness_rationale": "The comment is direct, specific, and actionable. It clearly identifies a weakness in the figure and provides a concrete suggestion for improvement. The authors are immediately guided on what to do to make the figure clearer."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question about the paper's focus on sequencetosequence models and the benefits of the proposed method for this specific model type. This directly points to an actionable suggestion for the authors to clarify this aspect. The question is clear and directly addresses a potential area for improvement in the paper's presentation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'sequencetosequence models' in their question. This demonstrates a clear grounding of the comment in the specific aspect of the paper being discussed. The comment is not vague or general but directly refers to seq2seq models.", "verifiability_rationale": "The reviewer makes a claim about the paper's focus on seq2seq models and the benefits of the proposed method. This claim is not explicitly supported by the paper's content within the provided text. While the paper's content isn't shown here, the reviewer's statement itself is a claim that needs evidence to be considered 5. The lack of explicit support makes it somewhat borderline.", "helpfulness_rationale": "The reviewer's comment is a valid question and a request for clarification. While it doesn't directly improve the paper's content, it highlights a potential area for improvement in the paper's presentation and clarity regarding its focus on seq2seq models. It is helpful in identifying a potential gap in the paper's communication."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their desire for 'more ablation on how the algorithm's behavior and how the accuracy of its Q estimates change as lambda changes'. This is a clear and direct request for information, indicating an explicit action the authors should take. The reviewer is not inferring this action, but rather stating it clearly.", "grounding_specificity_rationale": "The reviewer explicitly states 'a hyperparameter (lambda in algorithm 2) is used to balance how much auxiliary loss to use' and then asks for 'more ablation on how the algorithm's behavior and how the accuracy of its Q estimates change as lambda changes'. The reviewer is not only identifying a specific part of the paper (algorithm 2), but also specifying the exact parameter of interest (lambda) and the type of analysis requested (ablation studies on algorithm behavior and Q estimate accuracy). This demonstrates a high level of grounding specificity.", "verifiability_rationale": "The reviewer states a need for 'more ablation on how the algorithm's behavior and how the accuracy of its Q estimates change as lambda changes'. While the reviewer identifies the need for ablation studies, they do not provide any justification or reasoning for why this ablation is necessary or how it would be conducted. The claim is stated, but the supporting evidence is missing. The reviewer is making a claim about the need for this analysis, but it lacks verifiable reasoning or references.", "helpfulness_rationale": "The reviewer explicitly asks for 'more ablation on how the algorithm's behavior and how the accuracy of its Q estimates change as lambda changes'. This is a direct and clear request for information that is likely to be helpful for the authors in understanding and improving their implementation of the algorithm. The reviewer is identifying a potential gap in their understanding and suggesting a concrete way to address it. While the request itself isn't providing the information, it is a valuable suggestion that could lead to improved understanding and performance."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point directly asks a question about a specific implementation detail of the model, which can be directly addressed by the authors. The question is explicit about the base encoder and whether the model was trained from scratch.", "grounding_specificity_rationale": "The review point explicitly mentions the 'base encoder' and the 'training from scratch' aspect, directly pointing to specific parts of the paper. This can be achieved through literal mention or clear implication.", "verifiability_rationale": "While the review point is a question and not a direct claim, it requests information that can be verified by checking the model description. The answer to the question would be verifiable by examining the paper's implementation details.", "helpfulness_rationale": "The review point is a direct question about a crucial implementation detail of the model. This information is helpful for the authors to understand and potentially verify their model setup."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of 'extending the ethical statement' and provides a concrete direction for this action by mentioning 'more concrete discussion of challenges not addressed in the dataset' and giving examples like 'gender beyond the binary' and 'races other than Black'. This clearly indicates what the author should do and how to do it.", "grounding_specificity_rationale": "The review point explicitly refers to 'the Ethical Statement' and provides concrete examples of what is missing, such as 'challenges not addressed in the dataset', 'gender beyond the binary', and 'races other than Black'. This clearly identifies the specific part of the paper being addressed and provides specific details about the issues.", "verifiability_rationale": "The review point makes a claim about the ethical statement being 'well written, but should be extended...' and suggests 'more concrete discussion'. While it doesn't provide external references, it logically suggests that the current discussion is lacking detail and proposes a specific way to improve it. The suggestion is a form of justification for the identified weakness.", "helpfulness_rationale": "The review point is 5 as it directly addresses a specific aspect of the paper (the ethical statement) and provides concrete suggestions for improvement. It tells the author *what* to do and *how* to do it by suggesting a more detailed discussion of specific social bias issues."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states a potential issue regarding the noninteger nature of minibatch lengths and its implications for the analysis. This constitutes an explicit action or suggestion, as the reviewer directly points out a problem and its potential consequences.", "grounding_specificity_rationale": "The reviewer refers to 'minibatch lengths' and the potential issue of them being nonintegers. While they don't explicitly name a section or table, the grounding is to a specific concept within the method description. The reviewer also specifies the potential problem ($\tau_t << 1$) and its impact on the analysis.", "verifiability_rationale": "The reviewer makes a claim about the potential noninteger nature of minibatch lengths and its impact on the analysis. However, they do not provide any evidence, logical reasoning, or external references to support this claim. The statement is presented as a concern rather than a welljustified assertion.", "helpfulness_rationale": "The reviewer points out a potential issue with the method's implementation. While this is a valid observation, it doesn't directly provide actionable advice or solutions to the authors. It highlights a potential problem rather than offering a concrete improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their intention to examine the computational cost, which is a direct action. While the action is broad (examine), it is a clear direction for the authors to understand the efficiency of the model.", "grounding_specificity_rationale": "The reviewer specifically mentions 'STM decoding', 'LLM decoding', and the 'SCALE model'. These are explicit references to specific components and the system being analyzed, allowing for precise identification of the area of interest.", "verifiability_rationale": "The review point itself does not contain a claim or assertion. It is a request for information rather than a statement that can be verified or falsified.", "helpfulness_rationale": "The request for information about computational cost is relevant to understanding and potentially optimizing the SCALE model. While it doesn't immediately provide actionable steps, it points towards a valuable area of inquiry that could lead to improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states 'lacks performance comparisons' and 'unsupervised result outperforming the supervised result in the 5th row of Table 2'. While it identifies areas for improvement, it doesn't provide concrete steps on how to make the comparisons or explain the results. The reviewer suggests improvements but doesn't detail the actions to be taken.", "grounding_specificity_rationale": "The comment mentions 'performance comparisons with stateoftheart models' and 'unsupervised result outperforming the supervised result in the 5th row of Table 2'. While it points to specific aspects of the work, it doesn't explicitly identify a specific section, table, figure, or unique element of the paper. The mention is general.", "verifiability_rationale": "The comment presents claims such as 'This article only uses a subset of the complete dataset' and 'lacks performance comparisons with stateoftheart models', stating positions that require further explanation or justification. However, the review point itself doesn't provide evidence or reasoning to support these claims.", "helpfulness_rationale": "The reviewer clearly identifies significant shortcomings in the work ('lacks performance comparisons', 'peculiar experimental results') and suggests concrete improvements ('make comparisons', 'explain the results'). The suggestions are direct and actionable for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a problem ('lacks inherent semantic meaning') but does not provide explicit or concrete actions for the author to take. It only states the issue without suggesting how to address it.", "grounding_specificity_rationale": "The comment does not specify which part of the paper is affected by the lack of semantic meaning. It is a general statement about the entire text, making the grounding weak.", "verifiability_rationale": "The comment is a statement of observation ('The phrase... is used but not further elaborated upon') and does not contain a claim that requires verification. It is a factual statement, not a proposition needing support.", "helpfulness_rationale": "The comment identifies a weakness in the text ('lacks inherent semantic meaning') but does not offer any suggestions or guidance on how to improve it. It is a diagnosis without a prescription."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out two distinct issues: the use of 'hidden units' and 'elementwise function' and the treatment of unobserved ratings as zeros. While the reviewer implies these are problems, the review lacks explicit statements detailing *which* hidden units or *how* the elementwise function is applied. The action to take is vague, requiring the authors to infer the necessary changes.", "grounding_specificity_rationale": "The reviewer mentions 'a large number of hidden units' and 'an additional elementwise function,' indicating they are referring to specific components within the model description. This suggests a degree of grounding. However, the reviewer does not specify *which* hidden units or *how* the elementwise function is applied, making the grounding underspecific.", "verifiability_rationale": "The reviewer states that the authors 'do not provide sufficient details or justification' and that treating unobserved ratings as zeros 'may introduce bias, which is also not justified.' This statement clearly identifies a claim requiring support. However, the reviewer does not provide any evidence or reasoning to back up these claims, making the verifiability 1.", "helpfulness_rationale": "The reviewer raises concerns about the model's components and the handling of unobserved ratings. While these are valid points, the review does not offer any specific suggestions or explanations of *why* these are problems or how they should be addressed. The feedback is presented as a statement of concern without actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states \"The claim regarding motivation is not robust.\" This is an explicit statement of a weakness in the motivation. The reviewer also identifies a specific issue: \"these calculations can be done with 100% accuracy using other tools.\" This provides a concrete example of a problem. Therefore, the reviewer is providing a clear action for the authors to take: they should consider the limitations of their motivation given the availability of more accurate tools. The information is directly applicable to improving the draft.", "grounding_specificity_rationale": "The reviewer mentions \"the claim regarding motivation.\" This is a general reference to the motivation section of the paper. They do not specify which part of the motivation (e.g., a particular algorithm, a specific dataset, a particular justification) they are referring to. While they identify a weakness, they don't pinpoint the exact location or aspect within the motivation that needs improvement. The grounding is weak because the authors have to infer the specific part being criticized from the context.", "verifiability_rationale": "The reviewer states \"The claim regarding motivation is not robust.\" This is a claim. However, the reviewer does not provide any evidence or justification for why they believe the motivation is not robust. They offer a potential reason: \"these calculations can be done with 100% accuracy using other tools.\" While this is a relevant point, it is not presented as a direct verification of the claim. The claim is presented without sufficient supporting evidence or justification.", "helpfulness_rationale": "The reviewer points out a weakness in the motivation: \"The claim regarding motivation is not robust.\" This is a clear statement identifying a problem. While the reviewer does not provide specific suggestions for improvement, they have identified a concrete area that needs attention. The feedback is directly related to the authors' work and helps them understand a flaw in their approach. The reviewer's comment is actionable in the sense that it highlights a specific issue that the authors should consider."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the authors' reliance on synthetic datasets and realworld evaluation for eventbased optical flow in the context of eventbased dense tracking. While it identifies a limitation, the specific action the authors should take is not explicitly stated. The reviewer points out the mismatch but doesn't provide a direct instruction on how to address it.", "grounding_specificity_rationale": "The review point explicitly mentions 'eventbased dense tracking' and correctly identifies the authors' reliance on 'synthetic datasets and evaluate eventbased optical flow in realworld settings' as the current evaluation approach. This clearly pinpoints the specific area of concern and the method used, making it wellgrounded and specific.", "verifiability_rationale": "The review point makes a claim that 'this is a significant weakness.' It provides a justification by stating 'Since there\u2019s no dedicated eventbased dense tracking dataset, the authors rely on synthetic datasets and evaluate eventbased optical flow in realworld settings. However, this does not truly reflect eventbased dense tracking, which is a significant weakness.' This justification is logical and based on the described evaluation process, making the claim verifiable.", "helpfulness_rationale": "The review point identifies a valid limitation in the evaluation methodology by pointing out the mismatch between the goal of eventbased dense tracking and the actual evaluation approach (synthetic data/realworld optical flow). While it doesn't offer a constructive solution, it highlights a gap that the authors should consider. The reviewer's statement is a critique of the current evaluation process, suggesting it doesn't directly address the intended task."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states \"The motivation of this paper is unclear.\" and \"However, this paper seems to oppose this common understanding without strong justification.\" This directly points to a specific, actionable issue: the lack of clarity in the paper's motivation and the absence of strong justification for their claims. The reviewer identifies a problem that needs to be addressed.", "grounding_specificity_rationale": "The reviewer mentions \"the motivation of this paper is unclear.\" While this is a general statement, the subsequent part \"However, this paper seems to oppose this common understanding without strong justification.\" narrows it down to a specific aspect of the motivation lacking support. The reviewer identifies a lack of justification as the specific issue. However, the grounding is weak as the reviewer refers to the paper in general rather than a specific section or element within it.", "verifiability_rationale": "The reviewer states \"However, this paper seems to oppose this common understanding without strong justification.\" This is a claim made by the reviewer. However, this claim is not supported by any evidence or logical reasoning within the review point itself. There are no external references or examples provided to back up this assertion. The justification is missing and not derived from any verifiable source.", "helpfulness_rationale": "The reviewer identifies a problem with the paper's motivation but does not provide specific, actionable advice on how to improve the authors' draft. While the reviewer points out a lack of clarity and suggests a potential issue with the paper's interpretation of existing work, they do not offer concrete steps or guidance on how the authors should address these issues. The feedback is limited to identifying a problem without providing a solution or direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question that prompts the authors to provide an explanation. While not explicitly stating an action, the request clearly indicates a desire for clarification on why confidence intervals are missing. This can be interpreted as an implicit action: 'Please explain why confidence intervals are not provided for the substitution ASR in Table 3.' The reviewer is not asking for a specific action to be taken, but rather for information or justification to be provided.", "grounding_specificity_rationale": "The reviewer's question explicitly refers to 'Table 3' and 'substitution ASR', which are specific elements within the paper. The authors can directly identify the section and the metric being discussed. This allows for full grounding of the issue being addressed.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question about a missing element. There is no assertion of correctness, improvement needed, or request for justification. The comment is a request for information.", "helpfulness_rationale": "The reviewer is asking for a reason why something is missing. While this might prompt the authors to investigate their calculations or documentation, it does not directly point out a specific weakness or area for improvement in their work. The request is more about seeking clarification than addressing a concrete issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a lack of clarity regarding a specific technical detail: the estimation of mu_g in different kernel spaces. This constitutes an explicit actionability, as the authors can directly identify the missing information and understand the reviewer's concern. The reviewer clearly indicates what needs to be addressed.", "grounding_specificity_rationale": "The review point directly addresses the estimation of mu_g in different kernel spaces. The authors can directly identify the specific aspect of the paper being discussed. This constitutes full grounding, as the reviewer explicitly mentions the 'mean element mu_g for different kernel spaces' without needing to infer the location. The reference to 'different kernel spaces' also helps in pinpointing the exact area.", "verifiability_rationale": "The review point raises a concern about the clarity of a specific technical detail. While the reviewer doesn't provide a solution or a reference, the point itself is a claim that needs to be addressed. The lack of a solution or reference makes it 3, as the reviewer points out a deficiency that needs justification or explanation. The reviewer's statement itself is a claim that requires attention.", "helpfulness_rationale": "The review point identifies a specific technical detail (the estimation of mu_g in different kernel spaces) that is likely to be unclear to the author. While the reviewer points out a gap in understanding, they do not offer any specific guidance or suggestions on how to address this issue. The information is presented as a statement of lack of clarity rather than a constructive suggestion. Therefore, it is not 5 as it does not directly empower the author to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests considering \"datasets with a larger number of clusters, e.g. imagenet with reduced number of samples and feature dimensions.\" This is a clear and explicit action that provides a specific direction for improvement. The reviewer directly states the action and provides concrete details about the suggested dataset modifications.", "grounding_specificity_rationale": "The reviewer mentions \"clusters\" as a potential area for improvement. While the concept of exploring datasets with more clusters is relevant, the reviewer does not explicitly identify a specific part of the paper (e.g., a section, table, or unique element) that this suggestion directly addresses. The suggestion is more about a general experimental setup rather than a specific aspect of the paper.", "verifiability_rationale": "The reviewer presents the suggestion to consider \"datasets with a larger number of clusters, e.g. imagenet with reduced number of samples and feature dimensions.\" as a helpful addition. However, the reviewer does not provide any justification or reasoning for why this suggestion is beneficial or how it would help the paper. There are no logical connections, examples, or references to external works that support this claim.", "helpfulness_rationale": "The reviewer suggests considering \"datasets with a larger number of clusters, e.g. imagenet with reduced number of samples and feature dimensions.\" as a helpful addition to the discussion. This suggestion is relevant to the potential limitations of baselines on larger datasets and could provide valuable insights for authors. However, the suggestion is brief and lacks specific details about the expected outcomes or the methodology for conducting these experiments."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question and does not explicitly state what action the author should take. It asks about the suitability of a specific distance metric for a particular task, but doesn't provide a direct instruction or suggestion on how to proceed with their current method or explore alternatives.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or method. It is a general question about distance metrics in biometrics, lacking any grounding within the context of the author's work.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It is a question posed to the author, not a statement that needs to be proven or justified.", "helpfulness_rationale": "The review point is a question that is relevant to the author's work, as it asks about a methodological choice (distance metric) that could impact the results. However, it does not provide a direct answer or suggestion, making it less helpful than a critique or recommendation. It is more of a request for clarification or further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the 'weakness' of the experiments and the 'lack of comparison' with other methods. This indicates an intention to guide the authors towards improving these aspects. However, the actions are not fully concrete. While it implies the need for more complex experiments and comparisons, it doesn't specify *how* to achieve this, such as suggesting specific datasets, evaluation metrics, or alternative methods to compare against. The lack of specific action makes it less actionable than a comment that provides more detailed guidance.", "grounding_specificity_rationale": "The comment identifies the 'weakness' of the experiments and the 'lack of comparison' with other methods. However, it does not explicitly point to a specific section, table, figure, or unique aspect of the paper where these issues are most evident. The reviewer uses general terms like 'experiments' and 'other counterpart methods' without providing a precise reference within the paper. This lack of a specific reference makes the comment less grounded.", "verifiability_rationale": "The comment contains claims about the 'weakness' of the experiments and the 'lack of comparison' with other methods. It provides some reasoning, such as 'the paper only conducts a toy experiment and an experiment on a realworld dataset' and 'the proposed method does not compare with other counterpart methods.' However, these reasons are general and lack specific examples or references to external work. While the claims are present, the lack of concrete evidence or references makes them less verifiable than a comment that provides specific examples or external citations to support the claims.", "helpfulness_rationale": "The review points out valid weaknesses in the experimental section, specifically the lack of comparison to other methods and the use of a 'toy experiment' and a realworld dataset. This is a relevant and constructive criticism that can help the authors improve their work. However, the review lacks specific suggestions for improvement. It doesn't offer concrete steps the authors could take, such as suggesting specific alternative methods to compare against, designing more complex experiments, or including additional datasets. The absence of concrete suggestions makes the review less helpful than one that provides more actionable advice."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. This is a clear indication of an actionable point. The reviewer is directly pointing out a missing step that the authors should take to improve their draft.", "grounding_specificity_rationale": "The comment explicitly mentions 'figures related to completion errors' and 'analysis sections of the appendix'. This demonstrates strong grounding as the authors can directly identify the specific part of the paper being addressed. The reviewer is not just saying 'there's something wrong with the figures', but 'these specific figures in the appendix are not being discussed'.", "verifiability_rationale": "The comment itself doesn't contain a claim in the sense of presenting an opinion. However, the implication is that the lack of referencing is a problem. While not a direct claim, the reviewer is implicitly suggesting that referencing is important. The grounding specificity is high because the comment clearly identifies the specific figures and analysis sections being referred to.", "helpfulness_rationale": "The comment clearly identifies a potential issue (lack of referencing) and points the authors to a specific area of the paper (figures and appendix analysis). This provides a clear direction for improvement. While it doesn't *guarantee* that the figures are wrong or that the appendix analysis is missing them, it highlights a actionable area for the authors to check and potentially address."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a problem (unclear consistency) and suggests a concrete solution (consistent validation sets). This is a clear indication of an actionable point.", "grounding_specificity_rationale": "The reviewer mentions validation sets but doesn't explicitly state which specific validation sets are being used (e.g., train, dev, a separate heldout set). While the general idea is clear, the exact grounding is missing, making it less specific.", "verifiability_rationale": "The reviewer raises a concern about a lack of clarity regarding the consistency of perplexity measurement across levels. This is a claim that could be verified if the authors provide more detail on their validation sets and methodology. It's borderline because the potential for confusion exists without further information.", "helpfulness_rationale": "The reviewer raises a concern that could hinder the authors' understanding of their model's performance and potentially impede improvement efforts. This is a helpful point because it addresses a potential implementation detail that is important for understanding results."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point begins with \"To my opinion,\" which indicates a subjective assessment rather than a direct instruction for improvement. While the reviewer identifies a potential weakness in the originality of the work and draws a parallel to existing methods, they do not explicitly state what the authors should do to address this. The contrast between the perceived lack of originality and the actual strengths of the algorithm is implied but not a direct action. Therefore, the review point lacks explicit and concrete instructions for the authors to follow, making it 1.", "grounding_specificity_rationale": "The review point is very general and does not specify which part of the paper or algorithm it is referring to. It discusses \"the setting,\" \"the algorithm,\" and mentions concepts like \"graph labelings prediction\" and \"online learning in a switching environment\" without pinpointing a specific issue or component within the authors' work. The reviewer's opinion about the originality and connection to existing methods is broad and lacks specificity. Therefore, the review point does not identify a specific part of the paper being addressed, making it 1.", "verifiability_rationale": "The review point is an opinion expressed by the reviewer. It states that the setting and algorithm \"lack a bit of originality and might seem as incremental combinations of methods of graph labelings prediction and online learning in a switching environment.\" This is a subjective statement without any supporting evidence or justification. The reviewer then praises the algorithm for being \"efficient, new and seem different from the existing ones,\" which is a positive comment but does not constitute a claim that needs verification. Verifiability requires a claim to be supported by logical reasoning, common knowledge, or external references, which is not present in this review point. Therefore, the review point does not contain a claim that can be verified, making it 1.", "helpfulness_rationale": "The review point is primarily opinionbased and does not offer concrete, actionable advice on how to improve the paper. While the reviewer acknowledges a potential weakness in the originality of the work, they do not provide specific steps or suggestions for the authors to take to address this weakness. The contrast between the perceived lack of originality and the actual strengths of the algorithm is implied but not a direct suggestion for improvement. The positive comment about the algorithm's efficiency is 3 but does not directly address the core concern about originality. A helpful review point would explicitly identify weaknesses and provide clear, actionable feedback on how to improve the work. Therefore, the review point is opinionbased and lacks specific, actionable feedback, making it 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue with a specific regularization technique (using the state action of the current policy in the target environment as regularization) and suggests that this could harm learning because a suboptimal policy would result in a suboptimal stateaction distribution used for regularization. This is an explicit statement of a potential problem and an explicit description of the mechanism involved. The authors can directly identify the potential issue (harmful regularization) and the method (suboptimal policy's stateaction distribution).", "grounding_specificity_rationale": "The reviewer refers to 'a suboptimal policy' and 'stateaction distribution used for regularization'. While they don't explicitly name a specific section or table, they clearly identify the parts of the paper being addressed. The reviewer then explains that the regularization uses the stateaction distribution of this suboptimal policy. This provides a clear, albeit implicit, reference to the relevant parts of the paper. The grounding is present, although it could be more explicit.", "verifiability_rationale": "The reviewer makes a claim that 'using state action of the current policy in the target environment as regularization can harm learning, since a suboptimal policy would result in suboptimal state action distribution used for regularization.' This is a claim that can be verified. The reviewer provides a logical reasoning for this claim by stating that a suboptimal policy would lead to a suboptimal stateaction distribution, which could negatively impact the regularization process. While they don't provide specific citations, the reasoning is based on logical connections between policy performance and data distribution. The claim is verifiable through logical reasoning and common knowledge about policy learning.", "helpfulness_rationale": "The reviewer's point is clear and identifies a potential issue with a specific regularization technique. They explain that using the stateaction distribution of the current policy as regularization could be harmful because it might be based on a suboptimal policy, leading to a suboptimal distribution. This provides the authors with a specific area to investigate and understand the behavior of their algorithm and environment interaction. While it doesn't offer a solution, it points to a concrete problem that could be explored further. The feedback is directly relevant to the authors' work and guides them towards a potential flaw."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the concern: \"it is unclear whether this operation could negatively impact the model\u2019s performance on the base classes.\" This is a direct identification of a potential issue. Furthermore, the reviewer provides context by stating the objective of the feature compactness loss and sharpnessaware minimization: \"The objective of the feature compactness loss and sharpnessaware minimization is to reduce the distances among base classes.\" This explicit statement of the training objective makes the reviewer's concern more concrete, as the authors can now understand the context of the potential problem. The reviewer is asking for clarification on a specific aspect of the training procedure.", "grounding_specificity_rationale": "The reviewer refers to \"feature compactness loss and sharpnessaware minimization.\" While they don't explicitly state the section where these are discussed, mentioning these specific terms strongly implies they are referring to a particular part of the paper. The reviewer also mentions the \"purpose\" of these objectives: \"reduce the distances among base classes.\" This provides context and suggests they are specifically interested in how these objectives relate to the base classes. While the grounding isn't perfect, the mention of the specific terms indicates an attempt to identify a relevant section, and the mention of the objective provides some specificity.", "verifiability_rationale": "The reviewer states a potential issue: \"it is unclear whether this operation could negatively impact the model\u2019s performance on the base classes.\" This statement is a claim that requires verification. However, the reviewer does not provide any evidence, citations, or logical reasoning to support this claim. They are raising a question without attempting to answer it. The statement is presented as a point of uncertainty rather than a definitive assertion with supporting evidence.", "helpfulness_rationale": "The reviewer raises a concern about a specific training objective (feature compactness loss and sharpnessaware minimization) and its potential impact on base class performance. This is a clear and actionable point for the authors. By highlighting a potential issue with a specific aspect of their training procedure, the reviewer is guiding the authors to pay attention to this area and potentially investigate it further. This could be helpful in identifying and addressing a potential flaw in their approach. While it doesn't directly provide a solution, it identifies a potential area for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The questions are explicit in asking for insights and potential solutions, but they lack specific details on how to prevent attention collapse. The reviewer is prompting for information rather than providing a clear action to be taken on the authors' draft.", "grounding_specificity_rationale": "The review point asks general questions about the work's insights and a broad problem (attention collapse) without specifying which part of the paper or method is being referred to. There is no mention of a specific section, table, figure, or unique element of the paper.", "verifiability_rationale": "The review point contains claims about the value of the work and the importance of addressing attention collapse. However, it does not provide any specific evidence or references within the review point itself to support these claims or suggest concrete ways to prevent attention collapse. The reviewer is asking questions rather than making verifiable statements.", "helpfulness_rationale": "The review point asks questions that are relevant to the paper's context and a broader issue in the field. However, it does not provide specific, actionable feedback directly related to the authors' draft. The feedback is more about understanding the work and prompting for information rather than directly guiding improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'one point still remains unclear to me: how does the CHC model affect the capabilities of MLLMs? In other words, what specific attributes or behaviors would a powerful MLLM, grounded in CHC theory, exhibit?' This is a clear and actionable question that the authors can directly address by elaborating on the connection and providing examples. The reviewer identifies a specific area of the paper where clarification is needed and proposes concrete ways to improve it.", "grounding_specificity_rationale": "The reviewer explicitly identifies the gap: 'how does the CHC model affect the capabilities of MLLMs?' and specifies the type of information needed: 'what specific attributes or behaviors would a powerful MLLM, grounded in CHC theory, exhibit? Are there any case studies or pilot experiments that illustrate the significance of this influence?' This demonstrates strong grounding as the reviewer not only recognizes the missing information but also clearly defines the nature of the gap and the type of evidence that would be beneficial.", "verifiability_rationale": "The reviewer's point is primarily a suggestion for improvement rather than a claim that can be verified. While they are asking for clarification, they are not presenting a statement that can be supported by logical reasoning, common knowledge, or external references within the review itself. The request for 'case studies or pilot experiments' is a request for evidence, not a statement that *requires* evidence to be understood.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement: 'elaborate on the impact and provide examples.' This directly addresses the identified weakness in the paper and empowers the authors to enhance their work. The reviewer is not merely pointing out a problem but also offering a concrete way to solve it, making their feedback 5."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "1 (1)", "verifiability_label": "X (X)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point suggests using \"more recent related works\" and names two specific papers. This is a suggestion for improvement, but it doesn't explicitly state how to apply this suggestion. The reviewer doesn't provide concrete steps on how to integrate these models or what experiments to run.", "grounding_specificity_rationale": "The review point mentions \"more recent related works\" and names two specific papers. It doesn't explicitly state which part of the *pretraining model* (PreGNN) it addresses. The suggestion is general.", "verifiability_rationale": "The review point is a suggestion for improvement based on current research trends. It doesn't contain a claim that *something is wrong* or *something needs to be changed*. It's a forwardlooking suggestion.", "helpfulness_rationale": "The review point suggests using more recent models, which is relevant to the field of molecular pretraining. It points out a potential limitation of using an older model (PreGNN) in the context of current research. While it doesn't provide specific actionable steps, it highlights a potential area for improvement and encourages the authors to stay updated. The suggestion is clear in identifying a relevant area for improvement, even if it lacks specific actionable steps."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "4", "verifiability_label": "Partially Verifiable", "helpfulness_label": "None", "actionability_rationale": "The statement is explicit about the engineering challenge and the difficulty of object segmentation and pose tracking. However, it doesn't explicitly state what action the authors should take to address this challenge. The mention of Sec. A.3 suggests the authors have addressed this in the appendix, indicating a lack of immediate actionable steps within the main text.", "grounding_specificity_rationale": "The reviewer mentions 'object pose' and 'input' as specific aspects of the model. They also point out the difficulty of these inputs in the real world and explicitly state they documented their approach in Sec. A.3. This clearly identifies the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim about the engineering challenge being significant due to the difficulty of segmentation and tracking. They provide a general justification by referencing the realworld challenges. However, they don't provide specific examples of where this difficulty manifests in their model or cite external references to support this claim.", "helpfulness_rationale": "The reviewer identifies a potential limitation of the model's input. While they highlight the difficulty of the input, they don't offer a specific alternative or a constructive suggestion for improvement. It's a critique of the input rather than a direct proposal for a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's point is somewhat explicit in stating they want 'more downstream performance' and suggesting 'style transfer' as a starting point. However, the action is somewhat vague as 'more' is not clearly defined. The suggestion of 'style transfer' is concrete, but the 'advantage' of the model is still openended. Therefore, while the intent is clear, the specifics of the action are not fully detailed.", "grounding_specificity_rationale": "The reviewer mentions 'downstream applications' and 'style transfer,' which are specific concepts. However, they do not explicitly identify which specific part of the paper or model they are referring to. While 'style transfer' is a concrete suggestion, the connection to the controllable text generation model and how it would be implemented is not clearly established. The grounding is present but not precise enough to pinpoint the exact area of concern.", "verifiability_rationale": "The reviewer makes a claim by stating 'I would like to see more downstream performance...'. However, this claim is not supported by any evidence, reasoning, or references within the review point itself. There is no logical reasoning provided to justify why more downstream performance is needed or how it would be demonstrated. There are no external references or examples given to back up this claim. Therefore, the claim is not verifiable based on the information provided in this review point.", "helpfulness_rationale": "The reviewer's point is clear and directly addresses a potential area for improvement in the paper \u2013 the lack of demonstrated downstream performance. The request is relevant to the paper's goals, which likely involve controllable text generation and their practical applications. However, the reviewer does not provide specific suggestions or a clear path for how to demonstrate this improved performance. The request is more of a desire than a concrete improvement plan. Therefore, while the point is relevant, it lacks the specific details needed to be 5."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states they are 'a little confused' about the labels of the test set. This indicates a lack of explicit information or guidance on how to interpret these labels. While the information about the labels exists (e.g., they are used for evaluation), the reviewer isn't being told *how* to access or understand them. The actionable information is implicit but not clearly stated.", "grounding_specificity_rationale": "The reviewer can infer that the labels are used for evaluation, but they cannot confidently determine which part of the paper the comment addresses. The grounding is at the dataset level, but the specific location of the labels within the test set files is not explicitly identified. The information is implied but not precisely pinpointed.", "verifiability_rationale": "The reviewer states they are 'confused' about the labels. This is a subjective statement and lacks external references or logical reasoning to verify the confusion. The information about labels is generally common knowledge, but the specific point of confusion is not substantiated. The claim is not supported by evidence.", "helpfulness_rationale": "The reviewer's comment identifies a lack of clarity regarding the labels of the test set. While the information about labels is generally available (they are used for evaluation), the reviewer is not being told *how* to interpret or use them. The helpfulness is limited because the information is not presented in a way that directly addresses the reviewer's confusion. The feedback is about the *meaning* of labels, not a direct solution to a specific problem."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'Section 3.2 may be shortened'. It also provides a reason: 'many equations are NOT proposed by this work, but are wellknown in the community already'. This makes the action clear and the reasoning apparent.", "grounding_specificity_rationale": "The comment explicitly mentions 'Section 3.2', which is a specific part of the paper. It also identifies the issue as 'many equations are NOT proposed by this work, but are wellknown in the community already', which is a specific detail within that section. The comment is grounded in a specific section and provides a specific detail about the equations within it.", "verifiability_rationale": "The comment contains a claim: 'Section 3.2 may be shortened'. The reasoning provided is that 'many equations are NOT proposed by this work, but are wellknown in the community already'. While the claim itself is a suggestion, the reasoning provided is based on a general understanding of the field rather than specific citations or examples within the review point itself. The claim is presented as a suggestion rather than a verifiable statement within the review point.", "helpfulness_rationale": "The comment suggests a concrete action: shortening Section 3.2. This action is directly related to improving the organization and potentially highlighting the authors' contributions by removing standard background information. The suggestion is specific to a particular section and addresses a potential redundancy. While the reviewer doesn't provide specific examples of missing details, the suggestion implies a desire to make the paper more concise and focused."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point is a question, not a statement of what the author should do. It doesn't provide explicit or implicit instructions on how to address the evaluation method. Therefore, it is not actionable.", "grounding_specificity_rationale": "The review point refers to specific elements of the paper (Figures and Tables), indicating some level of grounding. However, it does not specify which particular aspect of those figures/tables is being evaluated by the automatic/human method. The grounding is weak because the authors cannot confidently determine the exact part being addressed. The specificity is low because it doesn't detail what needs to be addressed in those parts.", "verifiability_rationale": "The review point is a question, not a statement containing a claim that needs verification. Therefore, it does not have verifiability in the sense of supporting a claim.", "helpfulness_rationale": "The review point is a question seeking information about the evaluation method. While this might lead the author to investigate their evaluation process, it does not directly provide actionable feedback on how to improve the draft itself. It is not a suggestion for improvement, making it not helpful."}
{"actionability_label": "5", "grounding_specificity_label": "Highly Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point directly identifies a potential issue with the statistical test when the time index t is odd. It also poses a question about the implications of this issue, specifically regarding the coverage rate. This is a clear and actionable point, as it points out a specific area where the method might fail and asks a relevant question about the consequences. The reviewer is not just stating a problem but also asking about its potential impact.", "grounding_specificity_rationale": "The review point explicitly mentions the 'statistical test' and the specific issue related to the time index t being odd. It also discusses the implications of this issue for the coverage rate. The reviewer clearly identifies the specific part of the paper (the statistical test and its application to time series with odd indices) and explains what needs to be addressed (the behavior of the test at odd t and its impact on the coverage rate). This is a 5 point, as it accurately pinpoints the location of the problem and its consequences.", "verifiability_rationale": "The review point makes a claim about the average coverage rate being 0.5, which is supposed to be a bound according to a theorem. The reviewer observes that at odd time steps, the coverage rate is higher than this bound, based on the identified issue with the statistical test. While the core of the claim is based on an observation (the error at odd t), it lacks specific details about the theorem or the exact calculation of the coverage rate. The reviewer doesn't provide a logical reasoning or examples to support the claim, making it 3. More information about the theorem and the coverage rate calculation would be needed to fully verify this claim.", "helpfulness_rationale": "The review point clearly identifies a potential flaw in the statistical method's application to time series data with odd time indices. It also asks a relevant question about the implications of this flaw for the coverage rate. This is a helpful point because it directly points out a limitation of the method and encourages the authors to consider its potential impact on the reliability of their results. The reviewer is not just pointing out a problem but also asking a question that could lead to a better understanding of the method's behavior and limitations."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer raises a concern about the variability in translation choices among translators and suggests that relying on a single annotator's output might be insufficient. While the reviewer identifies a potential issue, the suggestion to use multiple translators is not explicitly stated as an action to be taken based on this review point. The reviewer points out a problem and encourages a more thorough approach, but the specific action of implementing this suggestion is not directly implied.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the variability in translation choices among translators' and 'the concern about using a single translator's annotations'. This clearly identifies the specific part of the paper (or the concept of annotation consistency) being addressed, making the grounding highly specific.", "verifiability_rationale": "The reviewer expresses an opinion about the potential inadequacy of relying on a single annotator's annotations. This constitutes a claim. While the reviewer suggests this is a valid concern, they do not provide specific examples or references to external work to support this claim. The reasoning is present but lacks concrete evidence.", "helpfulness_rationale": "The reviewer points out a practical consideration for annotation consistency and encourages a more thorough approach to handling translation variations. This provides valuable information for the authors, directly addressing a potential issue in their annotation process. The reviewer's suggestion is actionable and relevant to their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about a specific statement in the paper, but it doesn't explicitly state an action to be taken. It encourages the author to provide reasoning, which is an implicit action but lacks concrete details.", "grounding_specificity_rationale": "The review point directly refers to the statement \"people wear a hat and play guitar not viceversa;\" in the paper, clearly identifying the specific part being discussed. The reviewer is asking about this specific relationship, making the grounding explicit and specific.", "verifiability_rationale": "The review point itself is not a claim that requires verification. It's a question prompting the author to explain a statement. Therefore, it doesn't fit the criteria for a verifiable claim.", "helpfulness_rationale": "The review point asks a question that directly relates to a specific statement in the paper. By asking \"why not?\", the reviewer is prompting the author to clarify their reasoning. This can be very helpful for the author to identify potential misunderstandings or areas where the paper could be improved. It encourages the author to engage more deeply with the content."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states \"2000 examples may be insufficient for the model to learn this transformation correctly.\" This is an explicit statement identifying a potential limitation. However, it lacks specific details on how to address this issue or what needs to be done to make the examples sufficient. The reviewer suggests a potential problem but doesn't provide concrete steps for improvement.", "grounding_specificity_rationale": "The comment \"2000 examples may be insufficient for the model to learn this transformation correctly.\" does not explicitly refer to a specific part of the paper or the model. It is a general statement about the dataset size and its potential impact on learning. Therefore, it is 1 as it does not identify a specific section, table, figure, or unique aspect of the paper being addressed.", "verifiability_rationale": "The comment \"2000 examples may be insufficient for the model to learn this transformation correctly.\" expresses a potential issue with the dataset size. However, it does not provide any evidence, reasoning, or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that 2000 examples are insufficient.", "helpfulness_rationale": "The comment \"2000 examples may be insufficient for the model to learn this transformation correctly.\" raises a concern about the dataset size. While it identifies a potential weakness, it does not offer any concrete suggestions or actionable steps to address this concern. The feedback is primarily a concern about the data rather than a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks questions seeking clarification on how the algorithm differs from variational inference and what its advantages are. While these questions are relevant to understanding the algorithm, they do not directly instruct the author on specific actions to take or improve their draft. The reviewer is seeking information rather than proposing concrete changes.", "grounding_specificity_rationale": "The reviewer asks about the difference from variational inference and the advantages of the algorithm. The prompt mentions 'Gaussian distribution to approximate the target distribution.' However, the reviewer does not specify which part of the algorithm they are referring to or how it relates to the target distribution. The description is too highlevel to pinpoint a specific area of the paper being addressed. The reviewer is asking a general question about the method without specifying the exact component or issue.", "verifiability_rationale": "The reviewer asks 'How is it different from variational inference?' and 'What are the advantages?'. These are questions that require explanation and do not present a claim that needs verification. There is no statement that the reviewer is claiming something is a specific way based on evidence. The questions are about seeking information, not making assertions.", "helpfulness_rationale": "The reviewer asks questions seeking clarification on how the algorithm differs from variational inference and what its advantages are. These are relevant questions that could help the author understand their algorithm better. While the questions are not directly proposing actions, they are seeking information that could lead to improvements in the author's understanding and potentially their work. The feedback is informative, even if not fully actionable."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the entailment exercise lacks 'some basic details' and suggests two concrete actions: 'removing empirical and analyzed information' or 'removing the exercise from the paper'. This indicates a clear understanding of the problem and provides direct instructions for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'the entailment exercise' without specifying which particular section, table, figure, or unique aspect of the paper they are addressing. They are making a general comment about an 'entailment exercise' without pinpointing its location or content.", "verifiability_rationale": "The comment makes a claim: 'Only based on the information provided in the paper, it is hard to assess the efficacy of this technique.' However, it does not provide any specific examples, references, or logical reasoning to support this claim. It is presented as an opinion without justification.", "helpfulness_rationale": "The review point is relevant to the authors as it points out a potential issue with their entailment exercise. It offers two suggestions for improvement: removing the exercise or adding more empirical and analyzed information. While the suggestions are actionable, they are highlevel and lack specific details about what should be added or how the analysis should be conducted. The comment is not vague or lacking guidance, but it also doesn't provide concrete, actionable steps with specific implementation details."}
{"actionability_label": "3", "grounding_specificity_label": "2: 4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that the mathematical expression of the Gaussian distribution is 'ambiguous'. While the reviewer identifies a potential area for improvement, they do not explicitly state what action the authors should take to resolve this ambiguity. The reviewer points out a problem but doesn't provide a clear path forward. The ambiguity could be due to a lack of specific parameters, a typo, or a lack of context in the expression. Without further clarification from the authors or the paper, the action remains vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'line 225 and line 227' as the location of the issue. This clearly indicates that the reviewer can identify the specific part of the paper being addressed. The grounding is explicit.", "verifiability_rationale": "The reviewer states that the expression is 'ambiguous'. While the reviewer identifies a problem, they do not provide any evidence, references, or logical reasoning to support this claim. The statement is a declaration of a problem without further justification. There is no external reference or explanation provided to verify the ambiguity. The reviewer only points out the issue without providing any basis for belief in its existence.", "helpfulness_rationale": "The reviewer points out a problem ('ambiguous') without offering any suggestions or solutions. The comment identifies an issue but doesn't help the author improve their work. The reviewer only states that the expression is unclear without proposing any changes or providing any guidance on how to make it clear."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue ('not sufficient testing') and provides a clear action ('additional types of responses'). This is a direct and actionable suggestion.", "grounding_specificity_rationale": "The reviewer refers to 'tokens' in the paper, which is a specific part. While they don't explicitly name the *type* of token, the context strongly implies they are referring to specific data elements or features. The reviewer also explains *why* these tokens are insufficient ('not finding this to be sufficient testing').", "verifiability_rationale": "The reviewer makes a claim ('I do not find this to be sufficient testing') but does not provide any evidence or reasoning to support this claim. While the reviewer suggests an alternative approach ('additional types of responses'), this is a suggestion, not a verification of the initial claim. The lack of justification makes it only 'UnderSpecific' as the suggestion doesn't fully address the 1 nature of the initial statement.", "helpfulness_rationale": "The reviewer identifies a limitation in the testing and suggests an improvement. This is valuable feedback for the authors, especially if the 'tokens' refer to a specific, actionable aspect of the testing process. The suggestion to use 'additional types of responses' is concrete and actionable, making the review helpful for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a problem ('privacy protection capability is not sufficient') and suggests a potential solution ('chatGPT for text paraphrasing'). While it points towards a specific area ('text privacy protection'), the exact method of achieving sanitization using temperature is not detailed, making it only partially actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'chatGPT' and 'text privacy protection capability'. These terms are specific enough to likely identify the relevant section or aspect of the paper being discussed, thus being 5.", "verifiability_rationale": "The review point contains a claim ('privacy protection capability is not sufficient') and provides a justification ('chatGPT for text paraphrasing does not guarantee the removal of privacy information'). While the reasoning is logical, it lacks specific examples or references to external works, making it 4.", "helpfulness_rationale": "The review point directly addresses a potential weakness ('insufficient privacy protection') and suggests a concrete (though potentially incomplete) solution ('chatGPT for text paraphrasing'). This directly helps the authors improve their draft by highlighting a practical concern and offering a relevant technique, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a lack of significant novelty. While this *could* be actionable, it's quite broad. It doesn't specify *how* the authors should address the lack of novelty.", "grounding_specificity_rationale": "The reviewer mentions \"a relatively new method of using word embeddings,\" which grounds the comment on the *method*. However, the broader point about \"novelty\" is less specific and doesn't pinpoint a particular aspect of the method.", "verifiability_rationale": "The reviewer states \"the novelty is not significant enough.\" This is a claim, but the reviewer does not provide any evidence or reasoning to support or refute this claim. There is no logical reasoning, common knowledge, or external references provided to back up this assertion.", "helpfulness_rationale": "The review points out a potential weakness in the *method* (using word embeddings) but doesn't offer specific advice on how the authors can address it. They highlight the *lack* of novelty without suggesting concrete steps to achieve it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'The paper could benefit from comparing its method to nonNeRF methods on the mentioned tasks.' It also provides a concrete reason for this action: 'This comparison could help readers better understand how the proposed method stands in relation to conventional methods and the extent of its advantages.' The action is direct and the authors know exactly what needs to be done.", "grounding_specificity_rationale": "The comment explicitly mentions 'comparing its method to nonNeRF methods' and 'help readers better understand how the proposed method stands in relation to conventional methods'. This clearly identifies the specific part of the paper (or concept) being addressed, thus achieving full grounding. The comment also specifies what is needed: a comparison and an explanation of advantages, making it specific.", "verifiability_rationale": "The comment contains a claim: 'The paper could benefit from comparing its method to nonNeRF methods on the mentioned tasks. This comparison could help readers better understand how the proposed method stands in relation to conventional methods and the extent of its advantages.' This claim is supported by logical reasoning, as the comparison would indeed help readers understand the method's relation to conventional approaches. While it doesn't provide specific examples of nonNeRF methods, it clearly states the *purpose* of the comparison, making it 3. However, it doesn't provide specific references, making it not 5.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the authors: include a comparison to nonNeRF methods. This directly addresses a potential gap in the reader's understanding and helps the authors contextualize their contribution. While the suggestion is specific, it doesn't provide concrete examples of nonNeRF methods or a detailed methodology for the comparison. Therefore, while helpful, it might not be '4' as it could be expanded. The 'X' option is not applicable as the comment is not a claim but a suggestion for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly suggests that discussing related work on longterm motion trajectories would be beneficial for the authors. This is a clear action they are proposing, and it is concrete as they specify the type of related work they are suggesting. While the reviewer doesn't provide a detailed explanation of *why* this is important, the act of suggesting it is actionable for the authors in terms of improving their draft by adding context. The reviewer also criticizes the novelty of the idea, which can be seen as an implicit suggestion for improvement by providing more context.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'using longterm motion trajectories' as the specific aspect they are criticizing and provides a specific paper as context. This clearly grounds the feedback in the paper's content. The reviewer also specifies the *type* of related work they suggest discussing, further enhancing the specificity. The reviewer's comment is highly focused and directly addresses a specific part of the paper.", "verifiability_rationale": "The reviewer makes a claim that using longterm motion trajectories is a traditional idea. While they provide a citation, they don't explicitly *prove* or *disprove* the claim's veracity within the review itself. They also suggest discussing related work, which is a recommendation rather than a claim requiring verification. The reviewer's point is that this lack of discussion is a weakness, but the claim itself isn't definitively supported or unsupported by the review.", "helpfulness_rationale": "The reviewer's comment is relevant to the authors, pointing out a potential gap in the paper's discussion of related work. The suggestion to discuss related work is a constructive piece of feedback that could help the authors improve their draft. While the reviewer doesn't provide a detailed explanation of *why* this is important, the suggestion itself is valuable for the authors. The reviewer's comment is not entirely void of value, but it could be more impactful with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of a 'clear description of the specific task types addressed on graph data' and contrasts this with the section's focus on 'formalizing the challenges faced'. The reviewer also suggests an improvement by stating 'This feedback could be improved by providing a clearer description of the specific task types addressed on graph data.' This indicates a direct identification of a weakness and a suggestion for how to address it, making it explicit and actionable. While the action itself (identifying missing task descriptions) is implicit, the reviewer clearly states what is missing, making it somewhat explicit. The reviewer also provides a concrete suggestion for improvement, making it 3.", "grounding_specificity_rationale": "The reviewer explicitly names the 'problem formalization section' as the part of the paper lacking information. They further specify the missing information as 'the specific task types addressed on graph data'. This direct naming and specific mention of the missing information demonstrates strong grounding. The reviewer doesn't just say 'it's unclear'; they pinpoint the section and the specific aspect within it that is lacking.", "verifiability_rationale": "The reviewer makes a claim that the 'problem formalization section lacks a clear description of the specific task types addressed on graph data'. This claim can be verified by examining the section itself. While the reviewer doesn't provide specific examples of the missing task types, the claim itself is verifiable based on the content of the section. The reviewer also offers a suggestion for improvement by stating 'This feedback could be improved by providing a clearer description of the specific task types addressed on graph data.' This suggests a logical next step to address the identified issue.", "helpfulness_rationale": "The reviewer provides a clear criticism of the 'problem formalization section' and offers a direct suggestion for improvement: 'This feedback could be improved by providing a clearer description of the specific task types addressed on graph data.' This actionable suggestion directly addresses the identified weakness and provides a concrete path for the authors to follow. The reviewer's statement clearly identifies a problem and offers a specific solution, making the feedback 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the 'lack of the ablation study on training techniques' and provides specific examples of the techniques (IPI and vprediction). This directly identifies an actionable area for improvement by the authors.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. While it mentions 'training techniques,' it doesn't point to a particular section, table, or figure. The grounding is implied but not fully specified.", "verifiability_rationale": "The review point makes a claim about the 'lack of the ablation study on training techniques' and its implications for assessing the impact of these techniques and comparing YOSO with other models. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The claim is based on the absence of information.", "helpfulness_rationale": "The review point highlights a potential missing element (ablation study) that could be useful for understanding and improving the model. However, since the ablation study is missing, it doesn't directly tell the authors what to do or how to improve their draft. It points out a gap in the information rather than providing a direct solution."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"I suggest that since the author has mentioned the lack of domain knowledge in LLMs for specific tasks, it would be helpful to present a smallscale validation experiment...\". This directly indicates a concrete action the authors should take, making the review point 5. The reviewer proposes a specific type of experiment, providing a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer points out \"the two paragraphs from line 229 to line 272 redundantly describe the motivation and work approach already covered in the introduction.\" While the reviewer identifies a specific issue (redundancy), they do not explicitly state which *part* of the paper (e.g., a specific section, table, or figure) is redundant. The reviewer identifies the *what* but not the *where*. Therefore, the grounding is specific regarding the *content* being redundant, but not specific regarding the *location* within the paper.", "verifiability_rationale": "The reviewer makes a claim: \"I suggest that since the author has mentioned the lack of domain knowledge in LLMs for specific tasks, it would be helpful to present a smallscale validation experiment...\". This is a statement of opinion or judgment. The reviewer also provides a suggestion (a validation experiment) that logically addresses the identified problem (lack of domain knowledge). While the suggestion itself doesn't provide specific details, the reasoning behind it is clear and verifiable.", "helpfulness_rationale": "The reviewer's comment is a clear and actionable suggestion for the authors. They propose a specific type of experiment (validation experiment) to address a clear issue (lack of domain knowledge in LLMs). This provides the authors with a concrete next step and a standard method to evaluate their work, making the review point 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "Not Helpful", "actionability_rationale": "The comment identifies a weakness in the paper (theoretical contributions seem too abstract) and suggests an improvement (rewrite the section). However, it does not explicitly state how the authors should rewrite the section or provide concrete steps for making the connection between the theory and the method clearer. The action is implied but not directly stated.", "grounding_specificity_rationale": "The comment does not explicitly point to a specific part of the paper or methodology. It is a general statement about the theoretical contributions. Therefore, it is 1 in the paper's content.", "verifiability_rationale": "The comment is a suggestion for improvement, not a claim that requires verification. Therefore, it does not fall under the definition of verifiable.", "helpfulness_rationale": "The comment is a suggestion for improvement and a request for clarification. While it points in a helpful direction, it does not directly identify a weakness in the paper or suggest a concrete change to the authors' work. It is more of a request for the authors to improve their paper rather than a direct critique that would be considered helpful."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state what the author should do. It raises a question about the reproducibility of the GCN implementation. While the reviewer mentions the supplement, this is not a concrete action the author should take now. The reviewer is asking a question, not giving a direct instruction.", "grounding_specificity_rationale": "The reviewer refers to 'the GCN implementation' and mentions the 'supplement' as a source of more information. This indicates an attempt to identify a specific part of the paper. While the exact section isn't always pinpointed, the reviewer does refer to a specific implementation, and the supplement is a relevant part of the paper. Therefore, the grounding can be considered somewhat specific.", "verifiability_rationale": "The reviewer claims that the GCN implementation might be hard to reproduce based on their description and the information in the supplement. This is a claim that requires some level of justification. The reviewer states their descriptions are 'fairly detailed' and points to the supplement, which provides some basis for this claim. However, it's not a definitive statement or a citation to external work. Therefore, the claim is somewhat supported by evidence within the review itself.", "helpfulness_rationale": "The review point does not provide any actionable feedback for the author. It's a question about a future decision regarding code release and reproducibility. While the reviewer identifies a potential issue (difficulty in reproducing GCN), they don't offer any concrete steps the author should take to address it or improve their current draft. The review point is essentially a question posed to the author, not a suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the method used (Taylor expansions) and what it replaced (differential functions). The 'why' is also clearly stated, making it actionable for the authors to consider the implications of this choice.", "grounding_specificity_rationale": "The reviewer references specific equations (9) and (10), providing strong grounding. They also ask a very specific question about the choice of method, indicating a clear focus on the relevant part of the paper.", "verifiability_rationale": "The reviewer suggests an alternative approach (using differential functions), which is a claim. However, they don't provide any reasons or evidence to support why this alternative might be better, making it only 3.", "helpfulness_rationale": "The reviewer's point is about understanding a specific methodological choice. While it can be helpful to understand, it doesn't directly identify a weakness or suggest a concrete improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the location (Table 3), the method (BPE to character), and the specific missing metric (recall on lemmas/forms seen in training). This indicates a clear and direct action the authors should take: locate Table 3 and ensure the recall metric for lemmas/forms is included or calculated.", "grounding_specificity_rationale": "The review point explicitly mentions Table 3, the method (BPE to character), and the specific metric (recall on lemmas/forms seen in training). This strong grounding allows the authors to precisely identify where and what is missing. The mention of 'seen in training' further specifies the context.", "verifiability_rationale": "The review point makes a clear claim about a missing metric in a specific table and method. While the citations provided are relevant, they don't definitively prove the *absence* of the metric in Table 3. The claim is somewhat supported by the relevance of the cited works, but lacks direct evidence of the missing data itself.", "helpfulness_rationale": "The review point clearly identifies a specific issue (missing recall metric) in a specific section of the paper (Table 3). This is a direct and actionable feedback for the authors, making it 5 in guiding their attention to a concrete problem."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out an implicit action (the lack of impact on MLSC) but doesn't explicitly ask for the calculation or a detailed explanation of why the proposed method has no impact. The action is present, but the request for implementation details is missing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 4' and 'Table 3', indicating a clear attempt to ground the comment in specific parts of the paper. However, they do not specify *what* is missing or what needs to be addressed in those parts beyond the observation of 'no impact'.", "verifiability_rationale": "The reviewer identifies a gap in the paper's analysis by pointing out the discrepancy between the claim about wordalignment and the results in Table 3. They do not provide any external references or logical reasoning to support the claim that the proposed method has no impact on MLSC. The claim is present, but the lack of justification is a significant issue.", "helpfulness_rationale": "The reviewer informs the authors about a potential gap in the paper's analysis by highlighting the discrepancy between the claim about wordalignment and the results in Table 3. This could be helpful for the authors to investigate further and potentially improve their method. However, the reviewer does not explicitly ask for a detailed explanation or justification for this discrepancy."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action for the authors to take: 'evaluate the learned representation on other downstream tasks.' This is a clear and direct instruction.", "grounding_specificity_rationale": "The review point refers to 'the learned representation' generally, without specifying a particular aspect or section of the paper. While it implies the authors should evaluate the representation learned in their main experiments, the specific part being addressed isn't clearly identified. The authors would need to infer that it refers to the representation learned in the main experiments.", "verifiability_rationale": "The review point contains a claim: 'The quality of the learned representation was only evaluated on the linear evaluation setting, which is a bit insufficient...'. This claim is supported by the information provided in the review point itself ('only evaluated on the linear evaluation setting'). The reviewer is pointing out a factual observation about the current evaluation.", "helpfulness_rationale": "The review point is 5 as it directly addresses a potential limitation in the evaluation of the learned representation and suggests a standard improvement. By highlighting the insufficiency of the linear evaluation setting and recommending the use of other downstream tasks, the reviewer provides a clear and actionable direction for the authors to enhance their evaluation strategy. This is a constructive suggestion that empowers the authors to gain a more comprehensive understanding of their learned representation."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a lack of novelty in the approach, which is an actionable statement. However, it lacks specific details about what makes the approach nonnovel, making it difficult for the authors to take concrete action.", "grounding_specificity_rationale": "The comment criticizes the novelty of the approach but does not specify which part of the paper or method this refers to, thus failing to ground the criticism in a specific location.", "verifiability_rationale": "The comment contains a claim ('The novelty is very low') which is supported by logical reasoning and examples of the widespread use of stagewise and progressive training. This makes the claim 5.", "helpfulness_rationale": "The reviewer identifies a valid weakness in the novelty of the approach. While this is a helpful point, it lacks specific actionable steps for the authors, making it '4' rather than '5' or '1'."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the applicability of the analysis to more general cases. While the question itself doesn't explicitly state an action to be taken, it implies a desire for clarification or expansion, which can be considered an actionable request for the authors to consider broader scenarios. The action is implied rather than explicitly stated.", "grounding_specificity_rationale": "The reviewer's question is very general and doesn't specify a particular part of the paper or analysis that needs to be extended. It broadly asks about the applicability to more general Markov chains and those with FFN and nonlinearity. The reviewer is asking about the scope of the analysis, not a specific detail within it.", "verifiability_rationale": "The reviewer is not making a definitive claim that requires verification. They are suggesting an improvement to the analysis by considering more general cases. The suggestion is a proposal for future work rather than a statement that needs to be proven. It's a suggestion, not a claim.", "helpfulness_rationale": "The reviewer's question is relevant and points out a potential limitation or area for improvement in the analysis. It's likely to be helpful for the authors to consider these broader cases. The question highlights a specific area where the analysis could be extended, making it 3 in guiding future work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to clarify a specific aspect of their work (Fine state automaton) and its relationship to a cited work. This is a direct and actionable request.", "grounding_specificity_rationale": "The review point directly references section 3.1 and line 57 of the paper, providing precise locations for the authors to examine. It also asks for clarification on a specific technical detail (Fine state automaton) and a comparison to another work, making it highly specific.", "verifiability_rationale": "The review point contains a claim that the use of Fine state automaton in 19 is not obvious and asks for clarification. While the reviewer doesn't provide external references to support this claim, the implication is that the connection isn't clear within the paper itself, making it 3.", "helpfulness_rationale": "The review point identifies a potential area of confusion for the authors (the use of Fine state automaton and the comparison to 19) and provides a clear direction for them to seek clarification. This is a constructive and helpful suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests an optimization to the auto_weight scheme by avoiding the requirement for intermediate gradients for each domain. This is a clear and direct suggestion for improvement. The reviewer explicitly states the problem (memory requirements) and proposes a solution (referencing existing methods). This action is welldefined and actionable for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'Algorithm 1' and 'intermediate gradients for each domain' in the context of the auto_weight scheme. While the general area is pointed out, the specific part of Algorithm 1 being addressed and the nature of the intermediate gradients are not explicitly identified. The reviewer refers to the scheme generally rather than a specific line or section within Algorithm 1.", "verifiability_rationale": "The reviewer claims that the auto_weight scheme requires intermediate gradients for each domain. However, this claim is presented without any supporting evidence or justification. There are no logical reasons, external references, or common knowledge cited to support this assertion. The reviewer simply states it as a fact.", "helpfulness_rationale": "The reviewer suggests an optimization to the auto_weight scheme by avoiding the requirement for intermediate gradients for each domain. This is a relevant and potentially helpful suggestion for authors looking to reduce memory usage. The reviewer also provides relevant citations, which adds value to the feedback. However, the suggestion lacks context within Algorithm 1, making it slightly less helpful as the reader needs to infer the specific location of the issue."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the limitation of the backbone architecture, identifying it as being constrained to a double LSTM. It also explicitly mentions that the limitations are discussed in Section 6 but finds them insufficient. This provides a clear and direct identification of the missing aspect (transformers) and its impact on the method. The action is to acknowledge this limitation and consider alternative architectures.", "grounding_specificity_rationale": "The comment identifies the limitation regarding the backbone architecture and broader model structures but does not explicitly point to a specific section or element within the paper that needs improvement. While it implies the issue lies in the current architecture, it lacks the specificity of mentioning a particular table, figure, or unique aspect. The grounding is present in identifying the general area of concern (backbone) but is underspecific in pinpointing the exact location.", "verifiability_rationale": "The comment presents a concern or limitation about the method's applicability to more extensive model structures and pretrained language models. However, it does not provide any specific evidence, reasoning, or references to support this claim. It is presented as a potential concern without justification. The claim is the existence of this limitation, and the lack of supporting evidence makes it 1.", "helpfulness_rationale": "The comment is relevant to researchers working with transformerbased models and highlights a potential gap in the current methodology's applicability. It provides a clear identification of a relevant area for improvement and suggests considering alternative architectures. The feedback is actionable and directly addresses a potential limitation for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the contribution and novelty of the paper are limited and that the model combines existing techniques. While the reviewer identifies a potential weakness, the exact nature of the combination and its limitations are not explicitly stated, making it somewhat vague on how to improve the model.", "grounding_specificity_rationale": "The reviewer mentions specific techniques like structure learning regularization (NOTEARS) and missing value imputation. This grounds the comment to some extent as it identifies the methods involved. However, the comment does not specify how these techniques are combined or applied in the paper, making it underspecific regarding the implementation details.", "verifiability_rationale": "The reviewer claims that the contribution and novelty are limited and provides a potential reason: the model combines existing techniques. This claim is verifiable as the reviewer offers a plausible explanation for the limited contribution. While it doesn't provide definitive proof, it points to a specific area for the authors to investigate.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the paper's contribution and suggests a possible cause (combination of existing techniques). While this is a helpful starting point for the authors to consider, it doesn't provide specific, actionable steps on how to improve the contribution or address the identified issue."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests an alternative experimental setup (latefusion model with separate LR for each modality) as a comparison to the existing unimodal approach (MSLR). The suggestion is clear and provides a concrete direction for experimentation. The reviewer explicitly states the alternative method, making the action clear.", "grounding_specificity_rationale": "The reviewer points out a specific limitation of MSLR: the need to know the unimodal optimal learning rates in advance. While the target isn't explicitly named, the context strongly implies MSLR due to the mention of 'unimodal optimal learning rates'. The reviewer then clearly specifies the *specific* issue: 'which means we have to spend resources to tune unimodal models and discard them in the end. It would be interesting to see how this compares to directly tuning a latefusion model with separate LR for each modality...'. This clearly identifies the specific aspect of MSLR and the problem with its approach.", "verifiability_rationale": "The reviewer proposes an alternative experimental setup (latefusion model with separate LR for each modality) as a comparison to the existing unimodal approach (MSLR). While this constitutes a claim in the sense of suggesting a different approach, the reviewer does not provide any specific evidence, reasoning, or references to support why this alternative might be beneficial or how it would compare. The claim is presented without detailed justification or examples.", "helpfulness_rationale": "The reviewer suggests an alternative experimental setup (latefusion model with separate LR for each modality) as a comparison to the existing unimodal approach (MSLR). This suggestion is relevant to the limitations of MSLR, specifically the requirement of knowing unimodal optimal learning rates in advance. The reviewer encourages further exploration and potentially different insights by proposing this alternative. While the suggestion itself is not explicitly labeled a 'claim' in the verifiability framework, it does propose a concrete direction for future experimentation and could lead to valuable findings, making it a helpful suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly suggests specific notations (L_flow(F) or L_flow(F,S)) to clarify the inputs of a function, which directly addresses the ambiguity in the current notation (L_flow(X)). This is an explicit statement of what the notation should be, making it actionable. The reviewer is proposing concrete changes to how the inputs are represented.", "grounding_specificity_rationale": "The reviewer provides specific alternatives to the notation (L_flow(F) or L_flow(F,S)), indicating a clear understanding of the potential ambiguity in L_flow(X). This suggests the reviewer can confidently identify the specific part of the paper being addressed (the notation for the loss function) and how it should be implemented. This makes the comment highly grounded.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement in the notation of a loss function. While the comment itself doesn't contain a claim in the sense of criticizing an experimental choice or recommending a change to the paper's content, it does propose a specific alternative. The verifiability of this suggestion depends on whether the authors can independently understand the potential benefits of the proposed notation and whether it aligns with best practices. However, the *review of the notation itself* is a verifiable statement. The reviewer is pointing out a potential problem.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential ambiguity in the notation of a loss function. This is likely to be helpful for the authors if their suggestion is adopted, as it could improve the clarity and precision of the description. The impact is positive if the notation is indeed ambiguous and needs clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that '8bit batch norm has been proposed before in literature' and provides a citation. While the reviewer identifies a potential issue (lack of novelty), they do not explicitly state what the authors should do about it. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer mentions 'batch norm' generally and then specifies '8bit batch norm'. While the specific implementation is mentioned, the broader context of batch normalization is implied. The grounding is not entirely explicit, but the specific aspect is addressed.", "verifiability_rationale": "The reviewer makes a claim that '8bit batch norm has been proposed before in literature' and provides a citation. This claim is supported by logical reasoning (reference to existing literature) and external references.", "helpfulness_rationale": "The reviewer points out that '8bit batch norm has been proposed before in literature (e.g., https://arxiv.org/pdf/1805.11046.pdf), which undermines the novelty of this work.' While the reviewer provides evidence and a link, they do not offer specific, actionable steps for the authors to take. The comment is more of a critique of the authors' choice rather than a direct improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states: \"Given the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain, the practical relevance of the proposed framework may be limited.\" This is a statement of concern about the framework's applicability. While it points to a potential issue, it doesn't directly instruct the authors *what* to change or *how* to address it.", "grounding_specificity_rationale": "The review point mentions \"the graph representation learning domain\" and \"the practical relevance of the proposed framework.\" It doesn't explicitly refer to a specific section, table, figure, or unique element within the paper. The reviewer makes an *educated guess* about the areas being discussed (based on the terms used). While they are relevant areas, they aren't a precise reference.", "verifiability_rationale": "The review contains the claim \"the practical relevance of the proposed framework may be limited.\" However, it does not provide any evidence or justification to support this claim. It simply states a concern without backing it up.", "helpfulness_rationale": "The review point identifies a potential weakness regarding the framework's practical relevance. However, it does not offer any concrete suggestions or guidance on how to address this concern. It points out a problem but doesn't provide any solutions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a specific experiment the authors should perform: 'If M_t is calculated only using C without X, how about the results?'. The request is clear and directly addresses a potential limitation or area for improvement identified by the authors. The action is to conduct this experiment, and the method is clearly defined as calculating M_t without X. This is a direct and actionable request.", "grounding_specificity_rationale": "The comment refers to specific elements: 'M_t', 'C', and 'X'. While it doesn't explicitly name a section or table, it clearly identifies the variables involved in the calculation. The request is specific to the impact of removing 'X' on 'M_t'. This demonstrates a degree of grounding as the reviewer is referring to specific variables or components of a model. The specificity is in the request to perform an experiment related to these variables.", "verifiability_rationale": "The comment itself does not contain a claim that can be directly verified within the review point. The reviewer is making a judgment about the value and potential results of the experiment they suggest. There is no logical reasoning, common knowledge, or external references provided within the review point itself to support this judgment. The statement 'This experiment should be added' is a suggestion, not a claim that can be verified based on the information provided in the review point.", "helpfulness_rationale": "The comment directly addresses a request for clarification and a specific experiment. The reviewer is asking for a new experiment to understand the role of 'X' in the calculation of 'M_t'. This is a clear and actionable request that is likely to be helpful for the authors in improving their draft. The suggestion is directly related to a point raised by the authors, making it highly relevant and likely to be helpful."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states a fact ('It's not surprising...') but does not provide explicit or concrete actions for the authors to take. It describes the observed complexity difference but lacks specific guidance on how to address it.", "grounding_specificity_rationale": "The comment mentions specific types of problems (MLPs, FBDDs, perceptrons) but does not explicitly identify a specific section, table, or figure in the paper being addressed. The grounding is weak because the connection to the paper's content is not explicitly stated.", "verifiability_rationale": "The comment is a statement of fact and does not contain a claim that requires verification or justification. It's a descriptive statement, not a proposition that needs supporting evidence.", "helpfulness_rationale": "The comment is a statement of an observed fact but does not provide actionable feedback or point to specific areas for improvement in the paper. It's a descriptive observation, not a prescriptive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests considering the impact of various hyperparameters on the generalizability of the observations. While it doesn't explicitly state an action, the reviewer implicitly suggests a direction for the authors to explore. The suggestion to think about other training setups implies a potential action, but it's not a direct, concrete action like 'change the learning rate'.", "grounding_specificity_rationale": "The reviewer mentions 'Figure 4' and lists specific hyperparameters (optimization algorithms, weight initialization, batch size, learning rate, scheduling). This demonstrates a degree of grounding as the reviewer is pointing to specific aspects of the work and suggesting a direction to explore related parameters. However, the reviewer doesn't explicitly state which hyperparameters are the most relevant or how they might specifically affect the observed metrics in Figure 4.", "verifiability_rationale": "The reviewer doesn't explicitly claim that their findings are likely influenced by these hyperparameters. They are suggesting a consideration rather than making a definitive statement. While the suggestion implies a potential area of investigation, it doesn't provide a clear path to verification or a specific claim supported by evidence. The reviewer is prompting the authors to think about other possibilities, not verifying an existing claim.", "helpfulness_rationale": "The review point encourages the authors to think about the generalizability of their findings and considers various hyperparameters as potential factors. While this is a valuable suggestion for improving the robustness of the work, it doesn't provide a specific, actionable improvement or insight. The reviewer is prompting a broader consideration rather than offering a concrete solution or a specific direction to take. The helpfulness is limited to encouraging a more comprehensive analysis."}
{"actionability_label": "3", "grounding_specificity_label": "2: 4", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The comment explicitly states an action: 'use standard terminology' and points to a specific section (4) where the error is located. However, it doesn't provide specific guidance on *how* to implement this action, leaving the authors with a general direction but lacking concrete steps.", "grounding_specificity_rationale": "The comment explicitly mentions 'section 4', which is a clear and specific identification of the part of the paper being addressed. The reviewer is not making an inference but directly pointing to a location.", "verifiability_rationale": "The comment contains a claim: 'the paper is not wellorganized and using nonstandard terminology'. The claim is supported by the presence of the typo 'semihonst' and the general observation about organization. While it doesn't provide external references, the issue is verifiable within the paper itself.", "helpfulness_rationale": "The comment identifies a clear weakness ('not wellorganized' and 'nonstandard terminology') and provides a suggestion for improvement ('use standard terminology'). However, it doesn't offer specific guidance on *how* to reorganize the paper or *how* to use the standard terminology, making it 3 but lacking detailed actionable steps."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for the optimizer, initialization, and PPOzero. These are specific implementation details that, if known, could potentially help the authors improve their draft. The reviewer is not stating that something is missing, but rather asking for information that would be beneficial.", "grounding_specificity_rationale": "The reviewer is not explicitly pointing to a specific section, table, figure, or unique element of the paper. They are broadly stating that experimental details are missing. While the questions are about specific parameters, they don't directly identify a particular part of the paper being addressed. The grounding is in the general area of 'experimental details' rather than a precise section or element.", "verifiability_rationale": "The review point does not contain a claim in the sense of a statement that needs verification or justification. The reviewer is asking for information, not making a judgment about the paper. Therefore, it falls under the 'X' category of X.", "helpfulness_rationale": "The review point asks for specific information that could potentially help the authors improve their draft. The questions are about optimizer, initialization, and PPOzero, which are concrete implementation details. However, the questions are quite general and do not specify *where* in the paper these details are missing or what specific problems exist. While the information is likely to be helpful, the generality of the request makes it 3 rather than 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the use of two image encoders (LaVIT and EvaCLIP) and a detector in the decoding process. They also clearly point out that other existing works do not require these additional components. The reviewer further suggests a detailed comparison in terms of efficiency analysis (total model parameter, FLOPs, memory) with and without these components. This provides clear and actionable feedback on weaknesses and areas for improvement, though it could be expanded or refined to be fully comprehensive and impactful.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed method' and specifically mentions 'LaVIT for discrete token generation,' 'EvaCLIP for continuous token,' and 'a detector to provide prior in the Region Sampler.' This demonstrates strong grounding as the reviewer clearly identifies the specific part of the paper being addressed and specifies the issue with this part.", "verifiability_rationale": "The reviewer makes a claim that the proposed method requires additional components and that other existing works don't. They also suggest a comparison based on 'total model parameter, FLOPs, memory'. While the reviewer suggests the comparison, they do not provide specific examples or references to external works to support this claim. Therefore, the claim is somewhat justified but lacks key elements (e.g., examples, references).", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by highlighting a potential practical limitation of the proposed method (inefficiency due to additional components) and recommending a detailed performance analysis. This feedback is valuable for the authors to consider and can guide their future work. While the suggestion is concrete, it could be expanded to include more specific aspects of the analysis or potential solutions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the claim about extrapolation error and the nature of the proposed techniques. They also provide a concrete explanation of why the techniques are likely ineffective against extrapolation error. This provides clear guidance for the authors on how to improve their draft.", "grounding_specificity_rationale": "The reviewer mentions 'extrapolation error' and the 'proposed techniques' by name, making the grounding explicit. They also provide a specific explanation of why the techniques are likely ineffective against extrapolation error.", "verifiability_rationale": "The reviewer makes a claim about the lack of evidence for the extrapolation error claim and the nature of the proposed techniques. They provide a logical reasoning based on the concepts of bias/variance reduction and extrapolation to support their claim, although they do not provide external references.", "helpfulness_rationale": "The reviewer provides a clear diagnosis of a potential issue with the paper's framing and the proposed methods. They highlight the lack of evidence for the extrapolation error claim and the disconnect between the proposed techniques and the stated problem. This is a valuable piece of feedback for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the concern about the name 'LongShortTerm Strategy' being misleading due to its resemblance to LSTM. This directly points to a suggestion for improvement, making it actionable. While the suggestion is to 'reconsider' the name, it doesn't offer specific steps on how to implement this reconsideration, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly names the strategy as 'LongShortTerm Strategy' and then explains the potential confusion with 'Long Short Term Memory' (LSTM). This demonstrates a clear identification of the specific part of the paper being addressed, and the explanation of the issue is also specific to this strategy. Therefore, the grounding is fully grounded, and the specificity is also high.", "verifiability_rationale": "The reviewer makes a claim that the name 'LongShortTerm Strategy' might be misleading due to its similarity to LSTM. However, within the provided review point, there is no further evidence, examples, or references to support this claim. The reviewer presents a hypothesis but doesn't provide concrete evidence to back it up within this specific point. Therefore, the claim is present but lacks sufficient justification within the review point itself, making it 3.", "helpfulness_rationale": "The reviewer suggests reconsidering the name 'LongShortTerm Strategy' because it might be confusing with LSTM. This is a direct suggestion for improvement that directly addresses a potential ambiguity for the authors. While the suggestion is clear, it doesn't provide specific steps on how to implement this reconsideration or what the alternative name should be, making it 3 as it points towards a concrete action."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a weakness ('the proposed method is not the best performer') and suggests further investigation ('both sidesrobustness and fidelity'). While this points towards an actionable area for improvement, it doesn't explicitly state the *specific* action or how to implement it. The reviewer suggests exploring these aspects further, but doesn't provide concrete steps on how to do so.", "grounding_specificity_rationale": "The review point refers to 'the proposed method' and 'both sidesrobustness and fidelity' without specifying *which* method or experiment. While the reviewer identifies a potential issue, they don't pinpoint the exact section, table, figure, or unique aspect being addressed. The reference to 'both sides' is vague and doesn't clearly identify the problematic element.", "verifiability_rationale": "The review point is a statement of fact: 'the experiments results shows that the proposed method is not the best performer'. There is X or suggestion being made. It's an observation based on the results, not a claim that needs verification.", "helpfulness_rationale": "The review point identifies a weakness ('the proposed method is not the best performer') and suggests further investigation ('both sidesrobustness and fidelity'). While this points towards an area for improvement, it doesn't offer concrete *howto* advice. The reviewer suggests exploring these aspects further, but doesn't provide specific steps on how to do so or what changes should be made."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the motivation and logical connection is unclear. They point out the three key concepts: isometry, OT, and disentanglement, and state that the connection between isometry and disentanglement, and the role of OT in this connection, is not wellexplained. This indicates a lack of explicit and concrete information on how these concepts are linked, making the reviewer's suggestions not immediately actionable.", "grounding_specificity_rationale": "The reviewer clearly identifies the problematic concepts: isometry, OT, and disentanglement. They explicitly state that the connection between isometry and disentanglement is unclear and that this lack of clarity makes it difficult to understand the role of OT. The reviewer names the specific gap in the paper, indicating a strong grounding in the relevant sections and a clear understanding of what needs to be addressed.", "verifiability_rationale": "The reviewer makes a claim that the connection between isometry, OT, and disentanglement is not clear. However, the reviewer does not provide any evidence or reasoning to support this claim. While the reviewer suggests improvements (clarifying the connections and the role of OT), they do not logically explain *why* these connections are unclear or provide references to back up their assertion. Therefore, the claim is not welljustified.", "helpfulness_rationale": "The reviewer clearly identifies a significant issue in the paper's explanation: the lack of clarity in the connection between isometry, OT, and disentanglement. They pinpoint the specific gap in the paper and suggest concrete improvements (clarifying the connections and the role of OT). This provides the authors with a clear direction for improvement, making the feedback 5 and helpful."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the relevance of results to realworld language models. It doesn't explicitly state what the author should do next. Therefore, it's not 5. It might be implicitly actionable if the reviewer expects the author to reflect on the limitations of their work, but that's not stated.", "grounding_specificity_rationale": "The review point asks a question about the *realworld implications* of the results. The author isn't explicitly told *where* the discussion about realworld implications can be found in the paper. While the topic is relevant to the paper's introduction and conclusion, the *section* isn't specified. Therefore, it's weakly grounded. The question itself is general and doesn't specify *what* needs to be discussed about realworld implications.", "verifiability_rationale": "The review point contains a clear statement of a question/observation: \"how are they helpful for explaining how and why realworld language models work?\". This is a claim that the results are relevant to realworld language models. While it doesn't provide specific evidence or citations, it's a valid point that could be supported by referencing the introduction or conclusion of the paper. Therefore, it's 3.", "helpfulness_rationale": "The review point raises a valid concern about the practical relevance of the research. It encourages the author to think critically about the limitations of their work and consider realworld applications. While it doesn't directly tell the author *what* to do, it prompts a valuable reflection and discussion. Therefore, it's 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification on the novelty of their work in relation to the 'Venom' paper and the differences between 'Venom 1' and 'V:N:M'. This is an implicit request for information. While the reviewer implies an action \u2013 understanding the relationship between these concepts \u2013 the specific action is not clearly defined. The reviewer is not directly instructing the author on what to do, but rather asking them to explore a specific area of their work in relation to another. The lack of explicit action makes it less actionable than a direct suggestion. The reviewer is prompting for a comparison, which is not inherently actionable without further details.", "grounding_specificity_rationale": "The reviewer mentions 'the Venom paper,' 'V:N:M,' and 'Venom 1'. While they identify the general area of discussion, they do not explicitly pinpoint a specific section, table, figure, or unique aspect of the paper they are referring to. The grounding is weak because the reviewer cannot confidently determine which part of the paper they are addressing. The request is for a comparison, which requires understanding specific elements, but the specific elements are not clearly identified.", "verifiability_rationale": "The reviewer is not making a claim. They are asking a question seeking information about the relationship between 'V:N:M' and 'Venom 1'. There is no assertion of superiority, inferiority, or a definitive answer. The request is for clarification, not a statement that needs verification. Therefore, there is no evidence to verify, and the category 'X' applies.", "helpfulness_rationale": "The reviewer is asking for clarification on the novelty of their work in relation to another paper. While this can be helpful for the author to understand their contribution better, it does not directly instruct them on what specific changes or improvements to make. The review points to a need for information and understanding, which can lead to improvement, but it doesn't provide a concrete action or solution. Therefore, it is 3 as it encourages clarification, but it doesn't immediately provide actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that the attribution maps 'don\u00e2\u0080\u0099t seem to be related to the actual task' and provides specific examples like '3D worth pixels don't seem to be attended' and 'some clusters of attended pixels without a clear semantic meaning behind them'. While these observations point to potential issues with the maps, they don't explicitly state an action or a clear next step. The reviewer implies a need for improvement but doesn't specify *how* to achieve it. Therefore, while the reviewer identifies a potential problem, the lack of explicit action or solution makes the actionability somewhat implicit and potentially vague.", "grounding_specificity_rationale": "The reviewer's comment doesn't explicitly mention a specific part of the paper (e.g., 'Section 3.2', 'Figure 2') where attribution maps are discussed. They refer to them generally as 'attribution maps' and point to issues like 'attended areas of the image don\u00e2\u0080\u0099t seem to be related to the actual task'. This lack of a direct reference makes it difficult to pinpoint the exact location of the problem. However, the reviewer does identify specific *issues* with the maps (3D worth pixels, clusters), which suggests a degree of specificity in the *nature* of the problem, even if the *location* isn't explicitly stated.", "verifiability_rationale": "The reviewer states a claim: 'I didn\u00e2\u0080\u0099t quite find the attribution maps qualitatively intuitive'. However, they do not provide any evidence or reasoning to support this claim. They describe their *perception* but don't explain *why* they think the maps are unintuitive or how this impacts the work. There is no logical reasoning, common knowledge, or external references provided to back up their statement. Therefore, the verifiability of this claim is 1.", "helpfulness_rationale": "The reviewer's comment is a statement of opinion about the attribution maps. While they identify a potential issue ('not quite find the attribution maps qualitatively intuitive'), they do not provide any specific suggestions or actionable feedback on how to improve the maps or address the perceived lack of qualitative intuitiveness. The comment ends with 'However, the resulting analysis using the attribution maps seem to work (sec 4.2), so quantitative value seem to exist. But as this state I fail to spot a qualitative value'. This highlights the lack of a clear path forward and the reviewer's inability to articulate a solution. The comment is primarily a statement of a problem without offering a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states concerns about the title overclaiming and the limited model evaluation, which are direct and clear suggestions for improvement. However, the reviewer does not specify *how* the title is overclaiming or *how* the method might need to be adapted for larger LLMs. The action is implied but not fully defined.", "grounding_specificity_rationale": "The reviewer identifies the specific areas of concern: the title and the limited model evaluation (BERT and RoBERTa). While the reviewer doesn't explicitly state *which* part of the paper is being criticized (e.g., the title itself, the abstract, the introduction), the focus is clear. The reviewer also specifies *what* is missing (lack of results on LLMs). This indicates a degree of grounding as the issues are related to the paper's presentation and evaluation scope. However, the grounding is not fully explicit, as the reviewer doesn't point to a specific section or element of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim about the title potentially overclaiming the contribution and points out the lack of results on LLMs. This constitutes a claim that needs to be supported. The reviewer *does not* provide external references or logical reasoning to back up these claims. The information is presented as a question and a request for justification, indicating a lack of verifiable support within the review point itself.", "helpfulness_rationale": "The reviewer provides a clear and actionable question about the scalability of the method to LLMs and requests empirical justification. This directly addresses a potential weakness in the paper (the lack of LLM evaluation) and offers a concrete direction for improvement. The reviewer's request for justification is a valuable contribution to the paper's content."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for a reason for the choice of variables, which is an implicit request for justification. However, the request is general and doesn't specify what information would be helpful or how the authors might have arrived at that choice. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer refers to 'date and country' as variables and 'gender' as a target variable, which grounds the discussion somewhat. However, the reviewer does not specify *which* section or table this discussion might have occurred in, nor does the motivation ('speculating') provide specific examples or references.", "verifiability_rationale": "The reviewer makes a claim ('the paper does not provide any particular motivation...') and attempts to support it with 'speculating that they could show spurious correlations.' However, this support is weak and lacks concrete evidence or logical reasoning to verify the claim fully.", "helpfulness_rationale": "The review point is relevant as it seeks to understand the authors' reasoning behind their choice of variables. However, the request is not 5, as it doesn't directly suggest alternative choices or provide a clear path for the authors to improve their methodology. The information is more about seeking clarification than offering concrete advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue: 'authors make a point about exchanging channel \u2014 but exchanging channel is only achieved using BN.' This directly points to an action the authors should take: clarify the connection between channel exchange and the use of BN. While the reviewer doesn't provide specific steps, the action itself is clear.", "grounding_specificity_rationale": "The reviewer mentions '38' and the 'rationale of Theorem 1' but doesn't specify which part of the paper these refer to. They state 'mostly based on 38' without further explanation. This indicates a lack of precise grounding. While the concept of a theorem's rationale might be generally understood, the reviewer doesn't clearly identify the specific element being referenced or explain its relevance.", "verifiability_rationale": "The reviewer makes a claim: 'In my opinion, the rationale of Theorem 1 are mostly based on 38, and Theorem 1 seems like a simple fact.' However, they do not provide any evidence or reasoning to support this claim. They state an opinion without logical justification or references. The claim is presented without sufficient backing.", "helpfulness_rationale": "The reviewer raises valid concerns about the paper's novelty and clarity. They point out a potential lack of actionability for the authors and a lack of verifiability for the reviewers. While they identify an area where the authors could improve their explanation (channel exchange and BN), they don't offer specific solutions or constructive feedback on how to address the perceived lack of novelty. The feedback is more about identifying weaknesses than providing clear directions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'much more indepth studies are needed' which indicates an action. However, it does not specify how these studies should be conducted, making the action vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'secondorder methods' and asks about the meaning of 'K', which appears in section 4.1. This demonstrates strong grounding as the specific part of the paper is identified. The comment also poses a question about 'K', indicating an attempt to clarify a specific detail within that section.", "verifiability_rationale": "The comment contains claims such as 'then much more indepth studies are needed' and 'What does K denote exactly...'. While the need for more studies is implied, the claim about 'K' is specific and requires clarification. The suggestion of 'Is K=NC?' is a request for justification, indicating a lack of sufficient evidence or verification for the claim about 'K'.", "helpfulness_rationale": "The comment directly addresses a potential weakness in the paper (the lack of clarity on 'K') and suggests a direction for improvement (more studies on secondorder methods). While it doesn't provide specific steps, it points to areas where the authors need more information and guidance."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests 'an indepth analysis of the parameters k and N in the ablation study' and 'more analysis of the running time or the complexity, for example, the impact of the parameters k and N on the running time.' These are clear instructions on what the authors should do next. The reviewer explicitly mentions the parameters k and N and the running time/complexity, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'the parameters k and N in the ablation study' and 'the running time or the complexity'. This clearly identifies the specific aspects of the algorithm being discussed, demonstrating strong grounding. The reviewer is specific about the parameters and the analysis being performed.", "verifiability_rationale": "The reviewer states 'I believe more analysis of the running time or the complexity would be helpful, for example, the impact of the parameters k and N on the running time.' This statement proposes an analysis but does not make a claim that something is flawed or incorrect. Therefore, it does not contain a claim that requires verification. The reviewer is suggesting an improvement, not critiquing the current state.", "helpfulness_rationale": "The reviewer provides concrete suggestions for what analysis to perform (parameters k and N, running time/complexity) and why it would be beneficial (understanding the algorithm, impact on performance). These suggestions are directly relevant to improving the draft. Additionally, the reviewer points out a potential ambiguity in the description of Figure 2, which adds value by highlighting a minor issue that needs clarification. The suggestions are actionable and directly address potential areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer is prompting the authors to calculate the standard deviation and clarify the nature of the 10 runs. While not explicitly stating an action, the request implies a desired action to be taken by the authors.", "grounding_specificity_rationale": "The reviewer explicitly states 'Details in Appendix B', indicating they can identify the specific part of the paper where the information is located, even if the exact section or detail is not specified.", "verifiability_rationale": "The reviewer questions the claim that 'Details are averaged over 10 runs' and asks for justification. The lack of standard deviation and the ambiguity about the hyperparameter setup are presented as missing justifications for this claim.", "helpfulness_rationale": "The reviewer's desire for more clarity and detail in the appendix makes the comment less helpful as it stands. They are not providing concrete feedback but rather pointing out areas where the authors need to do more work to understand the results."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests adding more details about the task generation process. This is an explicit action, meaning the authors can directly identify the area needing improvement and apply the suggestion. However, the suggestion itself is somewhat vague, as it doesn't specify *what* details are missing or how to find them in the appendix.", "grounding_specificity_rationale": "The review point explicitly mentions 'the task generation process' and suggests including details 'in the main text.' This clearly identifies the specific part of the paper being addressed and what needs to be added, making it fully grounded. Furthermore, it specifies the location where the details should be included, making it specific.", "verifiability_rationale": "The review point itself doesn't contain a direct claim. However, the suggestion to include more details implies a judgment about the current level of detail being insufficient. This could be considered an implicitly stated claim. The verifiability of this claim relies on the reader's interpretation of the criticism ('This would give readers a better understanding...') as a signal that the current description is lacking in clarity or detail.", "helpfulness_rationale": "The review point is clear and directly addresses a potential weakness in the paper, which is the lack of detail in the task generation process description. By suggesting the inclusion of more details in the main text, the reviewer is providing a concrete and actionable piece of feedback that could significantly improve the paper's clarity and understanding. The suggestion empowers the authors to address a potential gap in the presentation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the lack of clarity regarding the entropy notation and provides a concrete suggestion to improve it by adding the datapoint dependency. This makes the action clear and actionable for the authors.", "grounding_specificity_rationale": "The comment explicitly mentions 'Individuallevel entropy' and 'Grouplevel entropy', clearly identifying the specific part of the paper where the confusion lies. It also specifies what needs to be clarified: making the entropy notation dependent on a datapoint. This is full grounding and specific identification of the issue.", "verifiability_rationale": "The comment suggests adding the datapoint dependency to the entropy notation and implies that this would make the formulas clearer. While it doesn't provide a formal proof, the implication and the logical connection between the suggestion and the goal of clarity make it verifiable. The benefit is inferred but implied.", "helpfulness_rationale": "The comment directly addresses a potential source of confusion for the authors regarding the notation used for entropy. It provides a specific suggestion for improvement, making it 5 for the authors to understand and implement the change. The suggestion is actionable and likely to improve the clarity of the formulas."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the action of connecting tokens beyond local windows and provides a concrete detail on how to implement this action by forming new groups across previous local windows. This clearly indicates an explicit and concrete action that the authors can readily apply.", "grounding_specificity_rationale": "The review point refers to 'tokens' and 'local windows,' which are general concepts within the context of sequence models and attention mechanisms. It does not specify a particular section, table, figure, or unique aspect of the paper being addressed. Therefore, the grounding is weak.", "verifiability_rationale": "The review point makes a claim about a potential issue with connecting tokens beyond local windows. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no verification of the statement's validity or how to address it.", "helpfulness_rationale": "The review point identifies a potential problem with the model's token processing. While this is generally helpful for the authors who are likely using sequence models, the review lacks specific details about the paper and does not offer concrete solutions or guidance on how to fix this issue. Therefore, its helpfulness is limited."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question, which is an explicit action. They are also asking for an explanation ('Why...?'), indicating a desire for actionable feedback. The question directly addresses a potential weakness in the paper's discussion of related work.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Distributionally Robust Optimization' and 'entropy' as the relevant areas. They also ask for a 'comprehensive illustration', which suggests they want the information grounded in detail. The paper's content discusses DRO and different distance metrics, making the grounding clear.", "verifiability_rationale": "The reviewer is making a claim about the advantages of the proposed distance metric (entropy) in the context of DRO, specifically comparing it to other metrics. This claim can be supported by knowledge of the DRO literature and the properties of entropy. While a full explanation might require more detail, the claim itself is verifiable.", "helpfulness_rationale": "The reviewer's question is directly relevant to the paper's contribution, as they are asking about the relationship between the proposed metric and existing DRO concepts. However, the question itself is primarily a query for information rather than a direct suggestion for improvement within the paper. It highlights a potential gap in the paper's discussion."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "None", "actionability_rationale": "The reviewer asks a question about TREx, which is an implicit action pointing towards addressing the lack of human labels. However, the review point itself doesn't explicitly state the implications or how to address this limitation. The action is present but not clearly articulated within the review point itself.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'TREx' and asks about its labels, directly pinpointing the specific dataset being discussed. This demonstrates strong grounding specificity as the section, table, figure, or unique aspect being addressed is clearly identified.", "verifiability_rationale": "The reviewer makes a claim about TREx being a distantly supervised dataset with no human labels. This claim is verifiable as it is a factual statement about the dataset. However, the reviewer does not provide specific examples or references to support this claim within the review point itself.", "helpfulness_rationale": "The reviewer points out a limitation of TREx (lack of human labels) and suggests alternatives (annotated datasets). This directly helps the authors understand the dataset's drawbacks and provides a path for improvement, making the review point helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests proofreading the appendix, which implies checking for errors. This is an actionable suggestion. However, the suggestion is quite general and doesn't specify the exact issues or how to proofread effectively. The reviewer points to specific typos in the appendix content (e.g., 'poster mean', 'peicewiselinear'), which suggests they have identified potential problems, but the action remains at a high level.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the appendix' as the location of the issue. This provides a clear grounding point. However, the reviewer does not specify which *part* of the appendix is problematic or what specific *details* within the appendix are lacking. The grounding is present but not fully specific.", "verifiability_rationale": "The reviewer claims the appendix is not using NeurIPS 2021 style files and points to specific instances within the appendix content ('poster mean', 'peicewiselinear', 'sugggest') as evidence. This constitutes a claim that can be verified. However, the reviewer does not provide external references or logical reasoning to *why* these specific instances are problematic in the context of the style file or writing quality. The verifiability is present but relies on internal evidence rather than external support.", "helpfulness_rationale": "The reviewer provides actionable suggestions, such as proofreading the appendix, and points out specific writing issues ('poster mean', 'peicewiselinear', 'sugggest'). These suggestions directly address potential problems in the draft. The reviewer also acknowledges the limitation discussion but suggests expanding on societal impacts, which, while less concrete, still contributes to a better understanding of the work's context. The overall feedback directly points towards areas for improvement in the authors' draft."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment implicitly suggests an action: investigating the training and validation curves of the losses. However, it doesn't explicitly state which losses are being referred to or provide concrete steps on how to interpret the curves or adjust loss weights. The lack of explicitness makes it less actionable.", "grounding_specificity_rationale": "The comment doesn't explicitly name the 'three losses' or specify which part of the paper they relate to. While the context implies they are related to a model being trained, the grounding is weak because the exact section or table isn't mentioned. The suggestion to weigh the losses is a general idea without specific examples.", "verifiability_rationale": "The comment makes a claim that these curves and loss weighting are useful. While this is generally true in the context of model training, the comment doesn't provide any specific justification or references to support this claim. The verifiability relies on the reviewer's general knowledge of machine learning practices.", "helpfulness_rationale": "The comment points to specific areas for investigation (training curves) and offers a practical suggestion (loss weighting). While it doesn't provide a definitive answer, it guides the author towards examining their training process and considering how to optimize their loss function. This points to a concrete direction for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer's assessment of the NPhardness claim is explicit, directly criticizing the paper's assertion and providing specific reasons for its lack of rigor. The reviewer states: 'This is not generally true for assignment problems' and 'Although NPhardness is claimed, the paper later assumes access to the optimal assignment matrix, which would limit the applicability.' This indicates a clear and actionable critique of the paper's claim.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly pointing to a specific section or table of the paper. While they are commenting on the overall claim about NPhardness and a later assumption about the optimal assignment matrix, they are doing so at a higher level rather than pinpointing a specific element within the paper. Therefore, while the comment is relevant, it lacks the explicit grounding of '5'.", "verifiability_rationale": "The reviewer makes a claim by stating that the paper's justification for the NPhardness of computing the GOSPA metric is not generally true for assignment problems and that the assumption of access to the optimal assignment matrix contradicts the NPhardness claim. This is a clear claim that needs to be supported. However, the reviewer does not provide specific citations or detailed explanations to back up these claims within the review point itself.", "helpfulness_rationale": "The reviewer's comment is 5 as it directly points out a significant weakness in the paper's NPhardness claim. They highlight the lack of rigor in the justification and the potential contradiction with the later assumption. This feedback is actionable and would likely guide the authors to improve their theoretical analysis or clarify their assumptions."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an *algorithmic* approach to explaining the pricing problem. This is a specific type of action, making it partially actionable. However, it doesn't explicitly state *how* the algorithm should be implemented or what specific aspects of the pricing problem it addresses. The reviewer is pointing towards a concrete way of presenting the solution, which is more specific than a vague suggestion.", "grounding_specificity_rationale": "The review point is a general suggestion about the *form* of the writeup. It doesn't specify which part of the paper the authors are referring to or what specific issue within the pricing problem they are addressing. The reviewer is offering a preference for an algorithmic explanation, not a correction or clarification of a specific detail.", "verifiability_rationale": "The review point itself does not contain a claim that needs verification. It's a suggestion for improvement in the *presentation* of the work, not a statement that requires evidence. Therefore, it doesn't fit into the categories of claim verification.", "helpfulness_rationale": "The review point suggests an algorithmic writeup as a potentially helpful way for the authors to present their solution to the pricing problem. This is a constructive suggestion that could benefit authors who prefer or need a more structured, stepbystep explanation. While it doesn't provide specific details, it offers a clear direction for improvement, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states their desire for clarification on how model averaging balances KL divergence and reward. They are asking for an explanation of the mechanism and its benefits, which is an implicit request for information rather than a direct instruction on what to do. The action is vague and lacks a clear next step.", "grounding_specificity_rationale": "The reviewer is asking about a general concept (model averaging and its benefits) rather than referencing a specific section, table, or figure in the paper. They are also asking *how* it works, which is a highlevel question. There are no explicit references to specific parts of the paper being addressed.", "verifiability_rationale": "The reviewer is not presenting a claim that requires justification or verification. They are asking for clarification and explanation, not making a statement that needs to be supported by evidence or logical reasoning. There is X being made.", "helpfulness_rationale": "The review point is valuable for the authors as it seeks to understand a complex technique. However, it lacks a clear next action or specific request for information. The reviewer is asking for clarification rather than providing a critique or suggesting a concrete improvement. While it provides some insight, it doesn't directly guide the authors to a specific step."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "1", "verifiability_label": "Not Verifiable", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point suggests a potential future research direction but does not provide specific, actionable steps for the author to implement or improve their current draft. The reviewer is proposing a generalization without specifying how this generalization relates to a particular part of the paper or how it should be addressed.", "grounding_specificity_rationale": "The review point is too vague and lacks specificity. It does not clearly identify which part of the paper the potential generalization is related to, making it difficult for the author to understand the context and potential implications.", "verifiability_rationale": "The review point is a suggestion for future discussion and does not present a claim that needs to be verified or supported by evidence.", "helpfulness_rationale": "The review point is a forwardlooking suggestion and does not offer specific, actionable feedback or identify problems in the author's current draft, making it unhelpful for immediate improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states a fact ('the analysis only considers...') and expresses uncertainty ('it is not clear...'). It does not provide explicit instructions or actions for the authors to take. The reviewer is pointing out a limitation in the analysis, not a call to action.", "grounding_specificity_rationale": "The reviewer refers to 'the analysis' generally and 'the effective initialization scale' as a concept. While 'the effective initialization scale' could be a target of investigation, the reviewer does not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The reference is vague.", "verifiability_rationale": "The review point states a fact ('the analysis only considers...') and expresses uncertainty ('it is not clear...'). It does not make a claim that requires verification or justification. The reviewer is stating an observation about the analysis's scope, not a statement that needs to be proven or explained.", "helpfulness_rationale": "The review point identifies a limitation in the paper's analysis but does not offer any suggestions or directions for the authors to improve their work. It is a critique of the analysis's scope, not a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the observation that more data leads to lower results on the ImageNet linear evaluation and asks for an explanation. This is an explicit statement of an action (identifying the issue) that needs to be addressed. While the action is clear, the reviewer does not explicitly state how to investigate this further, making it 3.", "grounding_specificity_rationale": "The reviewer specifically mentions 'Figure 7' and asks about the difference between '50% sampling' and '100% sampling'. This clearly identifies the specific part of the paper and the issue within it, providing strong grounding. The request for an explanation about the discrepancy is also very specific.", "verifiability_rationale": "The reviewer observes a discrepancy in the results presented in Figure 7 and asks for an explanation. This constitutes a claim that needs to be supported. While the reviewer does not provide external references or detailed reasoning within the review point itself, the act of identifying this discrepancy and asking for an explanation implies a need for justification. Therefore, it is 3 as the justification is implicit and requires the reviewer to formulate it.", "helpfulness_rationale": "The reviewer directly points out a discrepancy in their results and asks for an explanation. This is a highly relevant and actionable feedback for the authors. By highlighting a potential issue, the reviewer guides the authors to investigate further and understand the behavior of their model with different data sampling rates. This is a very helpful piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The reviewer criticizes the lack of quantitative results on mainstream metrics like FVD. While this could be interpreted as an implicit suggestion that the authors should include FVD, the review point itself doesn't explicitly state the action the authors should take or how to implement it. The criticism is more about the absence of a specific type of evaluation rather than a direct instruction. Therefore, the actionability is not explicitly stated, making it borderline.", "grounding_specificity_rationale": "The reviewer criticizes the lack of quantitative results on mainstream metrics like FVD. This criticism is not directly tied to the paper's content or methodology. It's a critique of the *outcome* or the *lack thereof*. The reviewer is not pointing to a specific section or table within the paper that they believe is 1. Therefore, the grounding is not explicitly identified in the paper itself.", "verifiability_rationale": "The reviewer states, 'While the authors have adopted the newly proposed VBench as the primary evaluation benchmark, they do not provide quantitative results on mainstream metrics such as FVD, which is widely recognized and robust for evaluating temporal video prediction.' This is a claim made by the reviewer about the paper's content. The reviewer's belief is based on their general knowledge of the field and the importance of FVD. While the paper might *mention* VBench, the lack of FVD results is a factual observation about the presented work. The reviewer's justification for the lack of FVD results is external to the paper itself. Therefore, the claim is partially justified by external knowledge but lacks explicit support within the paper's content.", "helpfulness_rationale": "The reviewer states, 'In sum, while the work offers a technically sound implementation, the limited novelty, insufficient methodological depth, and lack of comprehensive evaluation on standard metrics detract from its overall impact as a research paper.' This is a negative overall assessment of the paper's impact. The reviewer's statement is a critique of the paper's *outcome* and its potential *influence*. The lack of FVD results, as mentioned earlier, contributes to this negative perception. The reviewer's overall sentiment is that the paper is not as impactful as it could be due to these factors. Therefore, the review point is not directly helpful in improving the paper's content or methodology, but rather its perceived impact."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment implies an action but doesn't explicitly state it. The reviewer suggests the technical details are hard to follow, which is an implicit action. The comment is vague as it doesn't specify *what* is hard to follow.", "grounding_specificity_rationale": "The comment explicitly mentions 'section 2.2', which is a literal mention. However, it doesn't specify *what* is unclear within that section. The grounding is explicit but the specificity is lacking.", "verifiability_rationale": "The comment states a problem ('the technical details are hard to follow') but doesn't provide any evidence or reasoning to support this claim. It's a statement of a problem without verifiable backing.", "helpfulness_rationale": "The comment identifies a weakness (technical details are hard to follow) but doesn't offer any specific suggestions or actions for improvement. It points to a general area of concern without providing concrete guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states 'identical sentences,' which is a concrete action. However, it doesn't provide specific guidance on how to identify or address these sentences. Therefore, while it points to an actionable issue, the lack of concrete steps makes it partially actionable.", "grounding_specificity_rationale": "The comment explicitly mentions the locations of the identical sentences (Abstract, Introduction, Conclusion). This is a clear and accurate identification of the specific parts of the paper being addressed. The comment also specifies what is wrong (identical sentences). Therefore, it is 5.", "verifiability_rationale": "The comment contains a claim ('identical sentences') and, while it doesn't provide a specific *reason* for their existence, it clearly identifies the *problem*. This makes it 3 as the claim is stated, but lacks the supporting evidence to be 5. The comment identifies the *what* but not the *why* or *how*.", "helpfulness_rationale": "The comment identifies a problem (too many identical sentences) but does not offer any suggestions or guidance on how to address it. It points out the issue but doesn't provide a solution. Therefore, it is 2 as it doesn't empower the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly asks a question about a specific detail (the reward function in the ablation studies). This makes it 3 as it points the authors to investigate a specific aspect. However, it doesn't tell them *how* to apply this knowledge or what the implications are.", "grounding_specificity_rationale": "The comment refers to 'ablation studies' and asks about a 'reward function.' While it doesn't explicitly name a section or table, it points to a specific *type* of experiment. Authors can infer the relevance of the reward function within the context of ablation studies, but the specific detail (reward function) is implied rather than explicitly pointed out within a specific section.", "verifiability_rationale": "The review point itself is not a claim or a suggestion. It is a question seeking information. Therefore, it does not have verifiability in the context of this framework.", "helpfulness_rationale": "The question directly asks for information relevant to the authors (the reward function in ablation studies). This is a relevant piece of information for understanding and potentially improving their work. While it doesn't directly tell them *how* to improve, it directs their attention to a specific area that is likely important. It provides context."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem: 'For example, precise mathematical definitions of the how the quantum states in Eq (4) are missing from the main text, which makes it hard to follow.' This directly identifies the action the reviewer suggests: 'to include precise mathematical definitions of the quantum states in Eq (4)'. The reviewer also states the consequence: 'this makes it hard to follow', which is a direct action the reviewer identifies as a result of the missing definitions. The use of 'For example' further emphasizes the explicit nature of the problem and the suggested solution. Therefore, the action is clearly identified and directly related to the problem, making it actionable.", "grounding_specificity_rationale": "The reviewer mentions 'Sections 3 and 4' and uses the specific example of 'Eq (4)' to highlight the issue. While the reviewer doesn't explicitly state which *part* of Section 3 or 4 is problematic, the focus on 'Eq (4)' strongly implies a specific location within those sections. Furthermore, the reviewer specifies the *type* of missing information: 'precise mathematical definitions of the how the quantum states in Eq (4) are missing'. This clearly identifies the specific aspect of Eq (4) that is lacking. Therefore, while the reviewer doesn't point to a precise subsection, the specificity of the example and the type of missing information make this comment somewhat grounded and specific.", "verifiability_rationale": "The reviewer makes a claim: 'Sections 3 and 4 feel like they should be the main contributions of the paper, but they squeezed into about a single page. For example, precise mathematical definitions of the how the quantum states in Eq (4) are missing from the main text, which makes it hard to follow.' This claim is supported by logical reasoning. The reviewer explains why the lack of definitions makes it hard to follow, which is a logical explanation. While no external references are explicitly provided, the reviewer's statement is based on common knowledge about the importance of mathematical rigor in scientific writing, particularly in the context of quantum states. Therefore, the claim is supported by logical reasoning and common knowledge.", "helpfulness_rationale": "The reviewer provides a clear suggestion: 'include precise mathematical definitions of the quantum states in Eq (4)'. This suggestion is directly related to the identified problem of the lack of clarity due to missing definitions. The reviewer's suggestion is specific and actionable, directly addressing the identified issue. Therefore, the review point provides clear and actionable feedback to the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "Actionability is about providing clear instructions on what to do. The review point asks a question about fairness, which is valuable for identifying potential issues. However, it does not specify *how* to address this fairness concern. It lacks the explicit or implicit instructions needed for actionable feedback.", "grounding_specificity_rationale": "Grounding specificity is about linking the review point to a specific part of the paper and clearly explaining the issue. The review point raises a general concern about fairness and bias in LLM recommendations. It does not point to a particular section, table, figure, or unique aspect of the paper where this issue might be present. The concern is too broad to be considered grounded.", "verifiability_rationale": "Verifiability is about whether the review point makes a claim and if that claim is supported. The review point suggests investigating fairness. While this implies a need for evidence, it doesn't make a definitive claim about what is unfair or what should be done. It's more of a request for investigation rather than a verifiable statement.", "helpfulness_rationale": "Helpfulness is about the overall value of the review point. The review point raises a valid concern about fairness, which is important for improving the paper. However, it does not provide concrete steps or suggestions on how to address this concern. It's a good starting point for discussion but lacks the constructive elements needed for significant improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point provides explicit suggestions for improvement, such as shortening a paragraph and increasing the space for tables and figures. These are direct actions the authors can take to enhance their draft. However, the suggestion to increase space is somewhat vague and doesn't specify *how* the space should be used. The suggestion to shorten a paragraph is concrete but doesn't specify *which* paragraph or *how* shortening it would improve legibility.", "grounding_specificity_rationale": "The review point does not explicitly refer to any specific part of the paper or dataset. The suggestions are general and apply to the entire Section 1, the generation of longtailed datasets in general, and the presentation of experimental results in general. There is no mention of a specific table, figure, or unique element of the paper that the authors should focus on.", "verifiability_rationale": "The review point makes claims about the legibility of the paper, the need for more details in dataset generation, and the importance of more space for tables and figures. However, it does not provide any evidence or justification for these claims. For example, it doesn't explain *why* the paragraph is long or *why* the dataset generation process is limited to two illustrations.", "helpfulness_rationale": "The review point makes three suggestions: shortening a paragraph, providing more details on longtailed dataset generation, and increasing the space for tables and figures. The first two suggestions are directly related to improving the current draft and are actionable. The third suggestion, while potentially helpful, is more about formatting and doesn't directly critique the content or methodology of the paper. Therefore, two out of the three points are directly helpful for improving the current draft."}
{"actionability_label": "1", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question prompting for information rather than a directive with explicit actions to be taken.", "grounding_specificity_rationale": "The review point is a general question about the applicability of ECDiffusers to realworld data, lacking specificity to a particular part of the paper or issue.", "verifiability_rationale": "The review point is a question, not a claim, and therefore lacks verifiability.", "helpfulness_rationale": "The review point is a diagnostic question that highlights a potential issue but doesn't provide specific, actionable advice for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not directly instruct or suggest any specific actions the authors should take. It's a question about the evaluation process itself.", "grounding_specificity_rationale": "The review point does not explicitly or implicitly identify a specific part of the paper or protocol that is being questioned about its reliability. It's a general concern about the evaluation.", "verifiability_rationale": "The review point is a question, not a claim or assertion that needs verification. It doesn't present a statement that requires supporting evidence.", "helpfulness_rationale": "While the review point itself doesn't provide direct feedback on improving the draft, it raises a crucial question about the reliability of the evaluation process. This highlights a potential weakness in the review process and prompts the authors to consider the validity of the feedback they are receiving. It's a metacomment about the review process rather than a direct improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer states their concern about the novelty of the work and compares it to prior work, stating it's 'somewhat incremental'. This is an explicit statement of a weakness, but it doesn't directly tell the authors what to do about it. The reviewer is questioning the contribution, not proposing a specific action to address it.", "grounding_specificity_rationale": "The reviewer mentions specific prior work (von Kugelgen et al. 2021; Daunhawer et al. 2023) but doesn't explicitly point to a specific section, table, figure, or unique aspect of their paper that is problematic or needs improvement based on these prior works. The focus is on the *contribution* itself rather than a specific element of their work.", "verifiability_rationale": "The reviewer makes a claim about the novelty of the work and compares it to prior work. However, they do not provide any evidence, justification, or references to support this claim. The statement 'somewhat incremental' is presented without any backing.", "helpfulness_rationale": "The reviewer raises a valid concern about the novelty of the work and provides context by referencing prior work. However, they do not offer any suggestions or guidance on how the authors can address this concern or improve their work based on this feedback. The comment identifies a weakness but doesn't provide a path forward."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the need to 'improve' the LLM quality and suggests analyzing 'parameters, training data, and evaluation methods'. These are concrete actions or suggestions that are direct or apparent. However, the specific actions within these areas are not detailed.", "grounding_specificity_rationale": "The review point clearly identifies the 'area' of improvement: 'the quality of questions / answers generated by the LLM.' This can be considered 'grounded' as it specifies a part of the LLM. However, the 'specificity' of the suggestions ('parameters, training data, and evaluation methods') is not fully detailed. While the area is specific, the exact nature of the improvement within that area is not clearly defined.", "verifiability_rationale": "The review point contains a claim: 'An analysis on that would be nice i.e. which opensource LLMs would work with this approach ? or maybe find a LLM parameter count cutoff (say 7B) lower than that performance of PromptMix would start degrading ?' This claim suggests specific analyses and proposes a potential cutoff point, which could be considered verifiable.", "helpfulness_rationale": "The review point identifies a problem ('performance of PromptMix') and offers suggestions for improvement ('parameters, training data, and evaluation methods'). While the suggestions are broad, they provide clear directions for the authors to take action. The reviewer also asks for specific analyses, which can be seen as a request for clarification or further information, making it helpful in understanding the issue better."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly asks a question about the submodularity approach, which is an explicit and concrete request for information. They specify the SATURATE algorithm and its claimed N^5 scaling, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions the SATURATE algorithm and its claimed scaling with N^5 in the appendix. They also ask about the runtimes for large models, directly pointing to a specific part of the paper and the issue within that part. This demonstrates strong grounding as the reviewer can accurately pinpoint the referenced part and the specific problem.", "verifiability_rationale": "The reviewer questions the feasibility of the submodularity approach, which implies a need for justification or at least a statement of intent. While they don't provide explicit evidence or citations, the question itself serves as a form of justification for why they are questioning the approach. The request for runtime information also indicates an attempt to verify the claims made about the algorithm's scalability.", "helpfulness_rationale": "The reviewer's question directly addresses a potential weakness in the paper (the feasibility of the submodularity approach) and asks for crucial information (runtimes for large models). This question is directly helpful to the authors as it seeks to clarify and potentially improve the approach. The reviewer is actively engaging with the paper's content and seeking actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that 'inference at test time is briefly explained,' indicating the reviewer knows something is missing. However, the action of improving the explanation is not fully specified, making it 3.", "grounding_specificity_rationale": "The review point mentions 'inference at test time' without specifying which part of the paper or unique aspect it refers to. This lack of specificity makes the grounding weak. Furthermore, the point does not detail what is unclear, making it underspecific.", "verifiability_rationale": "The review point is a factual statement ('inference at test time is briefly explained') and does not contain a claim that requires verification.", "helpfulness_rationale": "The review point directly identifies a lack of detail in the explanation of 'inference at test time.' This is a clear and actionable suggestion for the authors, making it 5."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Partially Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out potential weaknesses in the evaluation process and the selfrevision prompting but does not explicitly state how these weaknesses should be addressed or what concrete changes are needed. The reviewer identifies areas like 'modality,' 'reusability,' 'submodule generation,' and 'selfrevision prompting' as potential issues, but lacks specific guidance on how to improve them.", "grounding_specificity_rationale": "The reviewer mentions specific terms and concepts like 'CodeChain,' 'GPT4 prompt,' 'submodule generation,' and 'selfrevision prompting,' indicating that the reviewer can identify the relevant parts of the paper or methodology being discussed. However, the reviewer does not explicitly state which specific section, table, or unique aspect of the paper is being addressed. The connection between the mentioned terms and the broader paper is implied but not clearly established.", "verifiability_rationale": "The reviewer states potential weaknesses in the evaluation process and the selfrevision prompting without providing any external references, logical reasoning, or examples to support these claims. The statements are presented as potential issues without justification. For example, the reviewer states 'It is unclear how this evaluation align with human preference' without providing any evidence or reasoning to support this claim.", "helpfulness_rationale": "The reviewer identifies potential problems with the evaluation process and the selfrevision prompting strategies. While the reviewer points out areas for improvement, they do not offer any concrete suggestions or solutions for addressing these issues. The feedback is diagnostic in nature, identifying potential weaknesses but lacking prescriptive elements that would guide the authors on how to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "6", "helpfulness_label": "5", "actionability_rationale": "The reviewer asks a question about the interpretation of a statement regarding classifier accuracy. While they don't explicitly state what is unclear, the act of asking a question implies an attempt to understand the meaning of 'higher overall accuracy at a given minimum subgroup accuracy'. This can be considered implicit actionability as the reviewer is trying to identify a point of confusion or lack of clarity. However, the reviewer doesn't provide a concrete explanation or suggest a specific step the authors should take to understand the statement, making it less explicit than a direct critique or suggestion. Therefore, it is 3 but lacks detailed guidance.", "grounding_specificity_rationale": "The reviewer's point is about a *conceptual* interpretation of accuracy tradeoffs in classifiers, specifically regarding the distribution of errors across subgroups. They are asking for clarification on the meaning of a statement, rather than explicitly pointing to a specific section or table in the paper. The comment is about understanding a relationship between different performance metrics, not about identifying a specific element within the paper that needs addressing. Therefore, the grounding specificity is low as the authors cannot confidently determine which part of the paper or concept the reviewer is addressing. It is classified as '1'.", "verifiability_rationale": "The reviewer's point is a question about the interpretation of a statement regarding classifier accuracy. It does not contain a claim that requires verification or support. It's a request for clarification, not a critique of existing work or a suggestion for a new experiment. Therefore, it does not fall under the verifiability aspect. It is classified as 'X'.", "helpfulness_rationale": "The reviewer's question directly addresses a potential point of confusion for the authors regarding the interpretation of classifier accuracy and its implications for fairness. They are asking for clarification on how a specific statement about accuracy tradeoffs should be understood. This is a valuable piece of feedback as it encourages the authors to think critically about the performance of their model across different subgroups. The reviewer is seeking to improve the authors' understanding of a key concept, which is directly helpful for their work. Therefore, the helpfulness is high as it directly addresses a potential area of confusion and encourages further analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that 'L107 claims that the relational embedding module significantly improves object classification, but we never see any results to back up this claim.' This is an explicit statement of an action the authors should take (verify the claim) and how to do it (look for results). The reviewer also suggests a concrete action: 'report the improvement on object classification directly in addition to the overall scene graph results.' This makes the point 5.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'L107' and the specific claim about the 'relational embedding module's impact on object classification'. This clearly identifies the specific part of the paper being addressed, indicating full grounding. The reviewer also specifies the nature of the missing information ('we never see any results to back up this claim') and the desired outcome ('report the improvement on object classification directly in addition to the overall scene graph results'), demonstrating high specificity.", "verifiability_rationale": "The reviewer makes a claim: 'L107 claims that the relational embedding module significantly improves object classification, but we never see any results to back up this claim.' This is a statement that can be verified by checking the results section. The reviewer also provides a reason for their claim: 'we never see any results to back up this claim.' While they don't provide external references, the absence of results is a verifiable fact. Therefore, the claim is somewhat supported by the lack of evidence.", "helpfulness_rationale": "The reviewer's point is clear and directly addresses a potential weakness in the paper's claims. They identify a specific area (L107) where evidence is lacking and suggest a concrete, actionable improvement ('report the improvement on object classification directly in addition to the overall scene graph results'). This directly empowers the authors to improve their draft by addressing the missing evidence and clarifying the claims."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that the novelty is 'relatively small'. This suggests that the reviewer does not perceive a clear, significant contribution or actionable feedback beyond a general observation. While the combination of selfsupervised learning and hypergraph attention networks is mentioned, the novelty is presented as an incremental addition rather than a groundbreaking concept. Therefore, the actionability is not explicitly stated, and the lack of clear guidance on how to improve the draft based on this observation makes it 1.", "grounding_specificity_rationale": "The reviewer mentions 'the idea is interesting' and 'narrow scope' without specifying a particular section or table. This indicates a lack of precise identification of the area being discussed. However, the reviewer does mention 'hypergraph attention network for multimodal learning' and even names a specific paper, providing a degree of grounding. The specificity is limited because the connection to the prior work and the exact relevance to the manuscript's novelty are not fully elaborated. Therefore, the grounding is weakly specific.", "verifiability_rationale": "The reviewer states that the novelty is 'relatively small' and that the connection to the prior work is also 'relatively small'. This implies that the reviewer does not see a strong, wellsupported claim. The statement about novelty lacks sufficient justification or evidence. Therefore, the claim is 1.", "helpfulness_rationale": "The reviewer concludes that the novelty is 'relatively small'. This directly translates to a lack of significant and actionable feedback for the authors. The comment does not provide clear guidance on how to improve the draft based on the identified limitations or the proposed addition. Therefore, the review point is not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue with the clarity of attention examples in Figure 4. While they don't explicitly state what is missing, they imply a lack of 'intuitive' examples. This suggests an implicit actionability, as the reviewer is highlighting a gap in the clarity of the examples. However, the action is not fully concrete, as the reviewer doesn't specify *how* the examples should be intuitive or *what* should be added to make them so.", "grounding_specificity_rationale": "The reviewer refers to 'intuitive attention examples' in 'Figure 4'. The reference to 'Figure 4' is explicit and grounded. However, the concept of 'intuitive attention examples' is vague and lacks specific criteria. The reviewer doesn't define what makes an example 'intuitive', making the grounding specific but the specificity of the request unclear.", "verifiability_rationale": "The reviewer states that it is 'hard' to find intuitive attention examples in Figure 4. This is a claim that requires verification. However, the reviewer does not provide any evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that finding these examples is difficult. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer points out a potential weakness in the paper's presentation regarding the clarity of attention examples in Figure 4. While this identifies an area for improvement, it does not offer a concrete suggestion or prescription for how to address this weakness. The review is more of a critique than a constructive suggestion. Therefore, the helpfulness is limited."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The action is implied but not explicitly stated. The reviewer asks the authors to understand the difference, implying they need to know how to interpret the labels in Figure 1. The action of 'understanding' is vague and needs to be explicitly stated as 'determine the meaning of 01 and 10 in Figure 1'. The comparison itself is explicit, but the action is implicit.", "grounding_specificity_rationale": "The authors can confidently identify the specific part of the paper being addressed, which is Figure 1. The comment clearly specifies what needs to be addressed in this part, which is the difference between the labeled elements 01 and 10.", "verifiability_rationale": "The review point itself does not contain a claim. However, the expected answer to this question would be a claim (e.g., '01 represents the initial state'). The expected answer would be verifiable based on the content of Figure 1 and potentially the surrounding text in the paper. The question is welldefined and points to a specific detail within the paper, making it 3 in the context of what the authors are expected to do.", "helpfulness_rationale": "The review point is very clear and directly points to a specific area of confusion for the authors. It encourages the authors to pay attention to a specific detail in their own figure. The request is very specific and targets a particular comparison."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desired action: 'move ... to the Related work section.' This action is clear and directly addresses the identified issue. The reviewer also specifies the content to be moved ('Traditional AES', 'Deep Neural AES', 'Pretraining AES'), making the action concrete and actionable. The reviewer is not just saying 'improve the Related Work section,' but they are pointing to specific content and location.", "grounding_specificity_rationale": "The reviewer explicitly identifies the section where the related work points are currently located ('Introduction') and the section where they want them moved ('Related Work'). They also name the specific related work points ('Traditional AES', 'Deep Neural AES', 'Pretraining AES'). This level of specificity clearly indicates which part of the paper is being addressed and what content is being proposed for that section.", "verifiability_rationale": "The reviewer is making a claim about the current structure of the paper being confusing and suggesting a specific change. This claim can be verified by examining the paper's content. The reviewer is pointing to a factual observation about the current structure (the presence of the bullet points in the introduction). While the claim is likely verifiable, the reviewer could strengthen it by providing more specific examples of why the structure is confusing to the authors.", "helpfulness_rationale": "The reviewer's suggestion to reorganize the paper by separating the related work section is a standard practice in academic writing. It addresses a potential hindrance for the authors (confusing structure) and proposes a solution that is likely to improve their experience. The reviewer is directly addressing a practical issue that could hinder the authors' ability to effectively present their work and its context."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential issue with the paper's organization but does not provide explicit or concrete steps for the authors to take. It criticizes the 'overall process and rationale for construction' without specifying what needs to be changed or how to improve it.", "grounding_specificity_rationale": "The comment criticizes the 'overall process and rationale for construction' without specifying which part of the paper or section this refers to. It lacks a clear reference point within the paper.", "verifiability_rationale": "The comment makes a judgment about the clarity of the 'overall process and rationale for construction' but does not provide any evidence or references to support this claim. It is a subjective assessment without logical reasoning or external references.", "helpfulness_rationale": "The comment identifies a potential area for improvement in the paper's organization but does not offer specific, actionable feedback or suggestions to the authors. It lacks the necessary level of detail to be truly helpful."}
{"actionability_label": "actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the missing literature review, the specific methods (Bayesian Coreset, uncertaintybased Coreset), and the missing comparisons to related works. This provides clear and actionable feedback for the authors to improve their draft by including these elements.", "grounding_specificity_rationale": "The reviewer does not explicitly state which specific part of the paper is missing information about. While they mention the lack of a literature review and the absence of discussion of specific works, they do not pinpoint the exact section or table where this information should be added. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim about the missing literature review and the lack of discussion of specific related works. They provide reasoning for this claim, such as the relevance of Bayesian Coreset and the existence of similar approaches. However, they do not provide specific examples or references to support these claims within the paper being reviewed. The reasoning is present, but the evidence is missing, making it 3.", "helpfulness_rationale": "The reviewer provides a clear criticism about the lack of a comprehensive literature review and the absence of discussion of relevant related works. They also offer suggestions for improvement, such as expanding the literature review and discussing specific studies. While the criticism is valid and the suggestions are actionable, the reviewer does not specify *where* in the paper these improvements should be made. Therefore, the feedback is 3 but lacks specific implementation details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out issues with Figure 2 but does not explicitly state what changes the authors should make. While they identify the 'onetomany relationship' and 'considerable amount of noise' as problems, they don't provide specific, actionable steps on how to address these.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Fig 2' and identifies issues within that specific figure. This demonstrates strong grounding as the authors can directly locate the referenced part. However, the reviewer does not specify *what* is wrong with the 'onetomany relationship' or the 'noise' within that figure.", "verifiability_rationale": "The reviewer makes a claim about the characteristics of Figure 2 ('hard to understand' and 'considerable noise'). However, they do not provide any external references or logical reasoning to support these claims. The verifiability relies on the authors' own visual assessment of the plot.", "helpfulness_rationale": "The reviewer identifies specific problems with Figure 2, which directly relates to the authors' work. While they don't provide concrete solutions, pointing out these issues can help authors diagnose problems and potentially make improvements. The feedback is directly relevant to the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks four questions and makes a request for information. The questions directly target specific aspects of the work, such as the source of speedup, the optimization level of compared algorithms, the fairness of comparisons, the training methodology discussed in the introduction, and the support for training from scratch. The request for information is also clear and directly points to areas needing clarification. The reviewer provides clear instructions on how to answer the questions, making the action explicit and concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'DFSSATTEN', 'Performer', 'Reformer', and 'training from scratch' within the text. These are clear and specific references to the relevant concepts and aspects of the paper being discussed. The reviewer's questions directly relate to these specific elements, indicating strong grounding. The concepts are explicitly mentioned, and the reviewer's questions are directly related to these mentioned concepts.", "verifiability_rationale": "The reviewer does not make a claim in the review point. Instead, they present questions and requests for information. There is no statement of opinion, judgment, or suggestion. The reviewer is asking for clarification and details, not making a claim that needs verification. Therefore, it falls under 'X'.", "helpfulness_rationale": "The review point asks clarifying questions and seeks information relevant to understanding and potentially improving the work. While it doesn't directly propose solutions, it identifies areas where the authors might be unclear or need more detail. By addressing these points, the authors can gain a better understanding of the method's strengths and weaknesses and potentially identify areas for improvement. The feedback is in the form of requests for specific information, which is generally helpful for understanding the work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a single sentence that describes an evaluation of a method. It does not explicitly state any action the authors should take or provide details on how to improve the evaluation. The comment is at a high level and lacks specificity regarding the next steps. Therefore, it is 1.", "grounding_specificity_rationale": "The review point mentions 'VMISITIDIFDSM' and 'blackbox setting' but does not explicitly identify a specific part of the authors' work or paper that this evaluation relates to. The connection is implied but 1. While the components mentioned are specific, the *section* or * aspect* of the authors' work being evaluated is not clearly pinpointed. Therefore, the grounding is 2.", "verifiability_rationale": "The review point states that 'VMISITIDIFDSM was examined on a blackbox setting when their method was evaluated on defended model.' This is a factual statement about what was done. However, it lacks any justification or reasoning for why this examination was conducted in this manner. There is no explanation of the implications, the limitations, or why this particular evaluation setup is relevant or insightful. Therefore, the claim is 1.", "helpfulness_rationale": "The review point is a brief statement describing an evaluation. It does not provide any specific feedback, critiques, or suggestions for improvement. It lacks the necessary context, detail, and actionable steps to be helpful for the authors. The comment is more of a report than a constructive critique. Therefore, it is not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point states, \"The clarity of the proposed method's description could be improved; please refer to the questions section for details.\"\" This comment identifies a problem (lack of clarity) but does not explicitly state what needs to be done to improve it. While the authors might infer that they should revisit the method description, the specific steps or changes are not outlined. Therefore, it lacks explicit actionability.", "grounding_specificity_rationale": "The review point states, \"The clarity of the proposed method's description could be improved; please refer to the questions section for details.\"\" This comment identifies a potential area for improvement (the method description) but does not specify which part of the description is unclear. The authors cannot confidently determine which section or element of the method description needs improvement. Therefore, the grounding is weak.", "verifiability_rationale": "The review point is a statement of opinion or a suggestion for improvement: \"The clarity of the proposed method's description could be improved; please refer to the questions section for details.\" This is a suggestion, not a claim that requires verification. There is no assertion that something is wrong, and no indication that it needs to be supported by evidence. Therefore, it does not contain a claim.", "helpfulness_rationale": "The review point identifies a genuine issue \u2013 the lack of clarity in the method description. This is likely to be helpful for the authors as it highlights an area they might need to revisit. However, the comment does not specify *how* to improve the clarity. While it points out a weakness, it lacks the specific actionable steps needed for maximum helpfulness. Therefore, it is 3 but not fully so."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a question rather than making a direct suggestion for improvement. While the question implies a desire for clarification, it doesn't explicitly state an action the authors should take. Therefore, it is 2.", "grounding_specificity_rationale": "The reviewer mentions 'GNN pruning' and 'different layers,' which are concepts present in a typical paper. However, they don't explicitly identify a specific part of the paper they are referring to. The question is about the relationship between pruning in different layers, which requires inferring the intended meaning. Therefore, it is weakly grounded.", "verifiability_rationale": "The reviewer is posing a question about the independence of pruning strategies across layers. This is a claim that could be verified by examining the paper's description of the pruning strategy. The question itself is a statement that requires justification or explanation. Therefore, it is a verifiable claim.", "helpfulness_rationale": "The reviewer is asking a question about a potential issue with the GNN pruning strategy. While this is relevant to the paper's topic, it is a question and does not directly suggest an improvement or action for the authors. Therefore, it is not 5 in terms of providing direct guidance. It is 3 in highlighting a potential area for clarification."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer does not explicitly state what they believe is lacking in the generalizability of the experimental results. They pose a question about whether the conclusions would generalize, but do not identify a specific action or improvement the authors should take based on this question. The comment is about identifying a potential issue, not suggesting a concrete step to address it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'other indistribution datasets' as the area of concern. They are pointing to a specific part of the paper (the experimental setup and results) and asking about its applicability to a broader category of datasets. This clearly identifies the specific section being addressed.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are raising a question about the limitations of the experimental validation. While the question could be addressed by the authors, the review point itself does not contain a verifiable statement or assertion. It's a question about the scope of their findings, not a critique of a flaw that needs justification.", "helpfulness_rationale": "The reviewer raises a valid point about the potential limitations of the experimental validation to only CIFAR10/100. This is a relevant question for the authors to consider when interpreting their results and potentially extending their work. While the question itself isn't a direct solution, it prompts the authors to think critically about the generalizability of their findings, making it a helpful point for discussion and future research directions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the observation that 'AlphaNets trained with alphadivergence doesn\u2019t benefit from your method' based on Table 8. They also suggest a specific analysis ('Maybe you should show the gradient conflicts ratio...') as a potential insight. This constitutes an explicit action with a concrete next step.", "grounding_specificity_rationale": "The reviewer refers to 'Table 8' and specifically mentions 'AlphaNets trained with alphadivergence'. They also point to the specific finding within that table ('doesn\u2019t benefit from your method') and suggest a specific analysis ('gradient conflicts ratio'). This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer presents a claim based on their observation from Table 8. They suggest a specific analysis ('Maybe you should show the gradient conflicts ratio...') as a way to understand the lack of benefit. This claim is supported by a suggestion for further investigation, making it 3.", "helpfulness_rationale": "The reviewer points out a specific limitation of the proposed method for a particular type of model (AlphaNets with alphadivergence) and suggests a concrete next step to investigate this limitation. This directly provides actionable feedback for the authors, making it 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
