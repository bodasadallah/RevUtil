{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the description of HIERENC is unclear and provides a specific alternative (averaging all instantiations). This indicates a lack of explicit or implicit action for the authors to take based on this review point. The reviewer is pointing out a missing definition of how HIERENC works, rather than suggesting a direct modification to their code or implementation.", "grounding_specificity_rationale": "The reviewer's description of HIERENC is general and does not pinpoint a specific part of the paper or the exact issue. The description is highlevel and does not clearly identify the section, table, figure, or unique aspect being addressed. The reviewer is describing the *process* of how HIERENC is calculated, but not the specific *component* or *section* where this calculation is relevant.", "verifiability_rationale": "The reviewer's point is a statement of what they *think* is wrong (potential noise in the input) rather than a claim supported by evidence. There is no logical reasoning, common knowledge, or external references provided to support the claim about noise. The reviewer is making a deduction or inferred observation that goes beyond merely stating facts.", "helpfulness_rationale": "The reviewer's point is valuable in identifying a potential issue with HIERENC's input calculation. However, they do not offer any specific suggestions or actions for the authors to take to address this potential problem. The reviewer is pointing out a lack of clarity, but does not provide a constructive solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that using integrated gradients to measure attribution has been studied in existing papers. This is a clear and direct action. Furthermore, the reviewer identifies the specific action of the paper proposing postprocessing steps to filter out 'falsepositive' neurons. The reviewer also explicitly states that the paper does not show how important these postprocessing steps are, which is a concrete action to identify a missing element in the paper's evaluation.", "grounding_specificity_rationale": "The reviewer mentions 'postprocessing steps' and 'falsepositive neurons' without specifying the exact section or table where these are described. While the general area of postprocessing is implied, the specific details are not linked to a precise location in the paper. However, the reviewer clearly specifies the *nature* of the postprocessing steps as 'filtering out the 'falsepositive' neurons'. This level of detail makes the grounding somewhat specific.", "verifiability_rationale": "The reviewer claims that the paper proposes postprocessing steps but does not show how important these steps are. This is a claim that can be verified by examining the paper's methodology and experiments. The reviewer identifies a gap in the paper's evaluation and suggests an ablation study to address this gap. The reasoning for the importance of these steps is implied but not explicitly justified with examples or references.", "helpfulness_rationale": "The reviewer's point is that the paper lacks an ablation study to demonstrate the importance of the proposed postprocessing steps. This is a constructive criticism aimed at improving the paper's evaluation methodology. While the criticism doesn't directly improve a specific methodological aspect, it highlights a potential weakness in the paper's empirical validation and suggests a concrete improvement. The reviewer's suggestion for an ablation study is a clear and actionable recommendation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the method (matching noun phrase heads) and identifies a specific limitation (when the head is not a pronoun). This provides a clear action for the authors to take to improve their method. The suggestion to match the head of the noun phrase is concrete and directly addresses the identified issue.", "grounding_specificity_rationale": "The reviewer mentions the 'noun phrase head matching' method and points out a limitation related to pronouns. While they don't explicitly name a specific section, table, or figure, they are referring to a specific aspect of their proposed method. This can be considered 'weak grounding' as the authors might need to infer which part of their method description they are referring to.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the proposed method (not working when the head isn't a pronoun) and suggests a potential improvement (matching the head of the noun phrase). The suggestion is logical and provides a concrete next step. While the reasoning is clear, it doesn't provide specific examples or external references, making it somewhat underspecified in terms of verifiable evidence.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improving the proposed method. They identify a specific limitation and offer a concrete solution. This is a very helpful comment as it directly guides the authors on how to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states a fact ('fairly straightforward extension') and suggests a potential improvement ('additional baselines') but does not explicitly tell the authors what to do or how to implement this suggestion. The action is implied but not directly stated.", "grounding_specificity_rationale": "The review point explicitly mentions 'character embeddings' as a potential baseline, which is a specific technical term. It also implies the need for additional baselines in the context of retrofitting work.", "verifiability_rationale": "The review point identifies a potential weakness ('fairly straightforward extension') and suggests a possible improvement ('additional baselines'). However, it does not provide any specific justification or evidence for why this is a weakness or how character embeddings would address it. The claim is that character embeddings are a good suggestion, but there's no logical reasoning or external references provided to support this claim.", "helpfulness_rationale": "The review point identifies a potential area for improvement (lack of baselines) and suggests a possible solution (character embeddings). While it points out a potential gap in the evaluation, it doesn't offer concrete, actionable steps for the authors on how to implement this suggestion or verify its effectiveness. The suggestion is quite broad and lacks specific implementation details."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states an action: 'understand why attention fails and change the attention mechanism'. This action is clear and directly addresses a potential issue in seq2seq MTL models. The reviewer also implies an action by suggesting focusing on the 'why' and 'how' aspects.", "grounding_specificity_rationale": "The reviewer makes a general statement about the difficulty of proving attention works in seq2seq MTL. While they mention 'attention mechanism' generally, they don't specify a particular section, table, figure, or unique aspect of a model where this problem might manifest. The reviewer is referring to a broader concept rather than a specific part of the paper. The reviewer also mentions 'why it fails' and 'how to change the attention mechanism' but doesn't provide concrete examples of how attention might fail or specific modifications to the mechanism.", "verifiability_rationale": "The reviewer makes a claim: 'it is always easier to show something (i.e. attention in seq2seq MTL) is not working'. However, the reviewer does not provide any evidence, logical reasoning, common knowledge, or external references to support this claim. The statement is presented as an observation without any backing.", "helpfulness_rationale": "The reviewer raises a valid concern in the field of seq2seq MTL, highlighting the importance of understanding failure points. By suggesting a focus on 'why it fails' and 'how to change the attention mechanism', the reviewer provides a direction for future research and problemsolving. This suggests a valuable and actionable insight for the community."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'The main weaknesses of the paper are the experiments' and 'the proposed augmentation method has potential to be used on more NLP tasks, which was unfortunately not shown'. These are direct statements of actions the authors should take. While the reviewer doesn't provide specific details on *how* to improve the experiments or demonstrate the method on other tasks, they clearly identify the areas for improvement. The implications are clear, guiding the authors towards specific next steps.", "grounding_specificity_rationale": "The review point mentions 'experiments' generally but then specifies 'sentence classification' when discussing the difficulty of the task. It explicitly states 'the lowresource setting' and 'NLP tasks' generally. While the setting and task are more grounded, the initial mention of 'experiments' and the final suggestion of 'NLP tasks' are less specific. The reviewer could have been more precise about which experiments are weak and which specific NLP tasks are missing.", "verifiability_rationale": "The review point states 'The main weaknesses of the paper are the experiments' and 'the proposed augmentation method has potential to be used on more NLP tasks'. These are claims that require justification. The reviewer doesn't provide specific examples, references, or logical reasoning to support these claims within the review point itself. While it's implied that the reviewer has identified these issues, the lack of explicit evidence within the review point makes the claims somewhat underjustified. The 'easier task' comment is a judgment without supporting evidence. The 'unfortunately not shown' comment is a statement of fact but lacks specific examples or references.", "helpfulness_rationale": "The review point identifies specific areas for improvement in the experiments and the application of the augmentation method. By pointing out the limitations in the lowresource setting and the sentence classification task, and suggesting the method's potential in other NLP tasks, the reviewer provides valuable insights that can guide the authors in enhancing their work. While the suggestions are general, they are still actionable and point towards concrete directions for the authors to explore. The reviewer's comments highlight potential weaknesses and suggest future research directions, making them helpful in a broader sense."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that 'A number of claims from this paper would benefit from more indepth analysis.' This clearly identifies an action that needs to be taken: 'more indepth analysis' of the claims. However, the comment does not specify *how* this analysis should be conducted. The action is stated, but the method remains vague.", "grounding_specificity_rationale": "The comment refers to 'claims from this paper' in general, without specifying which particular claims are being addressed. It does not identify a specific section, table, figure, or any unique element of the paper. The reference to 'claims' is broad and lacks precision. Therefore, the comment is 1 in a specific part of the paper.", "verifiability_rationale": "The comment itself does not contain a claim that requires verification. It is a suggestion for the authors to engage in a process of more indepth analysis. While the suggestion might be verifiable in practice, the comment itself doesn't make a statement that needs to be supported by evidence or references. The comment is a request for a process improvement, not a statement of fact requiring verification.", "helpfulness_rationale": "The comment identifies a valid area for improvement by suggesting that the authors should conduct more indepth analysis of the claims in their paper. This points towards a valuable direction for the authors to explore and refine their work. While the comment doesn't *do* the analysis for the authors, it encourages them to think critically and potentially take further steps, which can be helpful in the overall process of improving their draft. The suggestion is relevant and encourages further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their opinion about the substructure representation and the appropriateness of the term \"knowledge.\" They suggest that the substructure should be a sequence of words and offer constituent parsing as a potential alternative. While the reviewer doesn't explicitly state how to implement this change, the suggestion itself is a clear action. However, the reviewer's comment is somewhat vague, lacking specific details on how the constituent parse would be used or why the current representation is problematic beyond a general feeling.", "grounding_specificity_rationale": "The reviewer mentions \"the substructure has to be represented as a sequence of words\" and \"constituent parse,\" which implicitly points to a specific aspect of the model or processing. However, the reviewer does not explicitly name a specific section, table, or unique element of the paper. The criticism about the term \"knowledge\" is also general and doesn't target a specific part of the paper. The reviewer's suggestion is not very specific about how the constituent parse would be used or how it relates to the \"knowledge\" aspect.", "verifiability_rationale": "The reviewer makes a claim by stating \"The paper claims the model generalizes to different knowledge but I think the substructure has to be represented as a sequence of words...\" This is a statement of opinion. However, the reviewer does not provide any external references or logical reasoning to support their claim that the substructure *must* be a sequence of words. They offer a potential alternative but don't explain *why* the current approach is problematic beyond a general feeling.", "helpfulness_rationale": "The reviewer identifies a potential flaw in the methodology by suggesting that the substructure should be a sequence of words instead of relying on constituent parse. This is a valuable point that could guide the authors in improving their model. However, the reviewer's criticism of the term \"knowledge\" is more of a clarification than a direct suggestion for improvement. The helpfulness is moderate because the reviewer points out a potential issue and offers a solution, even if the connection to the \"knowledge\" claim isn't perfectly clear."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'The relatively poor performance on nouns makes me uneasy' and then focuses on 'the PPDBClus dataset' and the 'oracle GAP for PPDBClus'. This indicates a clear action point: investigate the performance discrepancy on nouns within the PPDBClus dataset. The action is directly derived from the reviewer's observation and is concrete, as the reviewer knows they should investigate this specific issue.", "grounding_specificity_rationale": "The reviewer mentions 'nouns' and 'PPDBClus dataset' as the specific parts of the paper being addressed. This is strong grounding. Furthermore, the reviewer specifies 'the oracle GAP for PPDBClus is higher than most clustering approaches', which adds significant specificity to the issue being pointed out.", "verifiability_rationale": "The reviewer presents a claim: 'This also directly contradicts the claim that the clustering approach is generalizable to all parts of speech (124126), since the performance clearly isn't uniform.' While the reviewer states a contradiction exists, the *reasoning* behind this claim isn't explicitly detailed within the review point itself. The reviewer requests further explanation, which can be seen as a form of justification, but lacks direct citations or logical reasoning within the provided text.", "helpfulness_rationale": "The reviewer clearly expresses unease about the performance on nouns and requests further explanation. This is a direct and actionable feedback for the authors. The reviewer's point is highly relevant to the authors, as it highlights a specific weakness in the model's performance and suggests a direction for improvement (further investigation). The request for clarification makes the feedback constructive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a claim: 'However, there is no corresponding set of tools for the reinforcement learning setting.' This is a direct statement of a missing element. While it doesn't provide a concrete *how* to implement this, it clearly identifies an action the authors should take: look for tools for the RL setting. Therefore, it is 3 in identifying a missing component.", "grounding_specificity_rationale": "The reviewer refers to 'the reinforcement learning setting' in the paper. This is a specific part of the paper, and the reviewer clearly identifies the issue within this specific area. This demonstrates strong grounding as the reviewer accurately pinpoints the relevant section.", "verifiability_rationale": "The reviewer makes a claim about the absence of tools in the 'reinforcement learning setting'. This claim is not supported by any evidence or references within the review point itself. The reviewer is stating their observation based on their own knowledge or previous experience. Therefore, it is not verifiable based on information within this specific review point.", "helpfulness_rationale": "The review point points out a potential inconsistency: the paper claims there are no tools for RL, but the reviewer is suggesting there might be. This could be helpful for the authors to doublecheck their understanding or consider alternative approaches. While it doesn't directly tell them *where* to find the tools, it highlights a potential gap. Therefore, it is 3 in identifying a potential issue that needs further investigation."}
{"actionability_label": "2", "grounding_specificity_label": "4: Mostly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer raises two main points: the fairness of comparing with other methods and the potential of the proposed technique to promote existing class incremental semantic segmentation methods. While these are relevant observations, they do not explicitly state what actions or improvements the authors should take based on these observations. The reviewer asks questions but doesn't provide clear directions for the authors.", "grounding_specificity_rationale": "The reviewer's comments lack specific grounding in the paper. While they mention 'comparison with other methods' and 'promoting existing class incremental semantic segmentation methods,' they do not identify the specific section, table, figure, or unique aspect of the paper being addressed. The reviewer's questions are general and do not point to a particular part of the paper or provide concrete examples.", "verifiability_rationale": "The reviewer's claims about the fairness of comparison and the potential for promotion lack sufficient verifiability. For the comparison, the reviewer states a concern but doesn't provide any logical reasoning, common knowledge, or external references to support why the comparison might be unfair. Similarly, for the potential promotion, the reviewer proposes a possibility without any basis or evidence. The claims are presented as possibilities rather than verifiable statements.", "helpfulness_rationale": "The reviewer's comments raise valid concerns and suggest future directions. However, they do not provide specific, actionable feedback that would directly help the authors improve their draft. The questions are about broader implications and potential extensions rather than concrete suggestions for improvement within the current work. The reviewer does not offer any constructive advice or guidance based on their observations."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a problem (tersely written section) but does not offer a specific action or suggestion on how to improve it. The suggestion is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 4' and states it is 'tersely written'. This allows the reader to identify the specific section being addressed, making it fully grounded. However, the comment does not specify what needs to be addressed in this section, making it underspecific.", "verifiability_rationale": "The comment states a claim ('Section 4 is very tersely written') but does not provide any evidence or reasoning to support this claim. It lacks logical reasoning, common knowledge, or external references to back up the statement.", "helpfulness_rationale": "The review points out a valid issue (tersely written section) but does not offer a concrete suggestion or direction for improvement. It lacks actionable feedback, making it less helpful for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the 'lack of method comparison' as a problem and suggests comparing with a specific method 1 and its techniques ('intertask ensemble' and 'intratask ensemble'). This is an explicit action, and the suggestion is concrete as it names a specific method and its components.", "grounding_specificity_rationale": "The reviewer explicitly mentions a 'highly relevant method' 1 and even specifies the techniques involved ('intertask ensemble' and 'intratask ensemble'). This clearly grounds the suggestion in a specific aspect of the paper.", "verifiability_rationale": "The reviewer identifies a 'lack of comparison' as a weakness, which can be considered a claim. However, the reviewer does not provide any justification or reasoning for why this lack of comparison is a problem. The claim is stated but not supported by evidence or logical reasoning.", "helpfulness_rationale": "The reviewer points out a 'lack of comparison' and suggests 'including the method comparison or performance comparison'. This is a helpful suggestion as it directly addresses the identified weakness. However, the reviewer does not elaborate on why this comparison is necessary or how it would benefit the authors. The suggestion is present but lacks further explanation or justification."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the 'pipeline style method' and its performance on 'XVNLI and MaRVL' by stating 'does not give better average results for both XVNLI and MaRVL'. While it suggests comparing to 'baseline models', it does not explicitly state what specific changes or improvements the authors should implement to address this performance gap. The suggestion is a potential action, but the initial statement is a critique without a direct instruction on how to act. Therefore, it is not explicitly stating an action or a clear path to improvement, making it 1.", "grounding_specificity_rationale": "The review point mentions 'a pipeline style method' and 'two models' in the context of its performance on 'XVNLI and MaRVL'. While it identifies the *type* of method and the *datasets* involved, it does not pinpoint a specific part of the paper, a component of the model, or a unique aspect of the pipeline that is problematic. The criticism is about the method's overall performance rather than a specific detail. Therefore, the grounding is weak as it identifies the *general* area of concern (the method's performance) but not the specific element being criticized.", "verifiability_rationale": "The review point makes a claim: 'This pipeline style method including two models does not give better average results for both XVNLI and MaRVL'. However, it does not provide any evidence, data, or logical reasoning to support this claim. There is no reference to external works, common knowledge, or examples to back up the assertion that the method performs worse than baselines. The claim is presented as a statement without sufficient justification. Therefore, the claim is not supported by any verifiable information, making it 1.", "helpfulness_rationale": "The review point is a critique of a 'pipeline style method' and its performance. While it suggests comparing this method to 'baseline models', which could be considered a helpful suggestion, the initial statement itself is not constructive. It simply states a negative observation without offering concrete steps or guidance on how to improve the method based on this observation. The suggestion is a potential action, but the initial negative statement is just a statement, not a helpful suggestion. Therefore, the review point is not particularly helpful in itself, making it 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the observation about political bias and the methodology used ('coarse' approach). This provides a clear direction for the authors to consider and potentially address.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'political bias in ChatGPT and in LLMs in general,' which grounds the comment to a specific part of the paper. They also mention the 'coarse' methodology, further specifying the aspect being addressed. This demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the lack of novelty in the observation and provides some justification by stating that the phenomenon has been observed at each step of language model evolution. This claim is supported by logical reasoning and common knowledge within the field.", "helpfulness_rationale": "The reviewer's point is relevant and constructive, highlighting a potential limitation of the authors' methodology and raising a valid concern about the novelty of the observation. While it doesn't directly tell the authors what to do, it provides valuable context and encourages further consideration of their approach."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to understand *how* the method achieves degree bias, which is a direct request for an explanation of the mechanism. This constitutes an explicit action request.", "grounding_specificity_rationale": "The reviewer wants to understand *how* the method achieves degree bias, specifically linking it to intracommunity concentration and intercommunity scatter. While the paper mentions these concepts, the reviewer is asking for a more detailed explanation of their connection to degree bias, indicating a desire for the explanation to be grounded in the specific mechanisms of the method.", "verifiability_rationale": "The reviewer questions the intuitiveness of the connection between the theoretical framework (intracommunity concentration and intercommunity scatter) and the resulting degree bias. While the paper proves the connection, the reviewer finds it not immediately clear, suggesting a need for better justification and explanation of why these mechanisms lead to degree bias.", "helpfulness_rationale": "The reviewer's request for a clearer explanation of how the method achieves degree bias directly addresses a potential weakness in the paper for the authors. This request is 5 and directly aims to improve the authors' understanding and potential implementation of the method, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the confusion regarding the variables 'S' and 'Xt' and provides a specific example of where this confusion arises. This directly identifies an actionable step the authors should take to clarify these variables. While the underlying issue of lack of clarity could be considered vague initially, the reviewer *now* specifies the exact missing information, making the action itself concrete.", "grounding_specificity_rationale": "The reviewer not only identifies the specific area of confusion (static vs. temporal features) but also explicitly points out the missing definitions of 'S' and 'Xt'. This demonstrates a strong grounding as the authors can easily identify the referenced part of the paper (the section discussing feature types and the variables used) and the specific issue within that part (the lack of definition for the variables).", "verifiability_rationale": "The reviewer states that the notation and the split between static and temporal features are confusing. This is a claim that the paper lacks clarity. While the reviewer's statement is based on their reading experience, it's a logical deduction based on their interpretation of the paper's content. There isn't a lack of external evidence to support this claim, but it's not purely subjective either. Therefore, it's 3.", "helpfulness_rationale": "The reviewer explicitly states that the point is helpful in identifying an area for improvement. They pinpoint the specific issue (confusion about variables) and suggest a concrete action (asking for clarification). This directly addresses a need for the authors to improve their understanding of the concepts presented."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement is explicit about the perdatainstance nature of INRs, but the reviewer's subsequent comment 'but I don't think it is an advantage' does not provide a concrete action or suggestion. The reviewer is expressing an opinion about the lack of advantage, not proposing a specific action to address it.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify which part of the paper they are referring to (e.g., 'Section 2'). The reference is general, stating a broadly applicable observation about INRs.", "verifiability_rationale": "The reviewer makes a claim: 'This claim is true but I don't think it is an advantage.' This claim is subjective and lacks supporting evidence or justification within the review point itself. The reviewer is expressing an opinion about the value of the statement, not providing a verifiable fact or argument.", "helpfulness_rationale": "The reviewer finds the statement factual but not particularly insightful or actionable for the reader. While the statement is true, the reviewer doesn't provide any concrete suggestions or improvements based on this observation. The feedback is more about informing the reader than guiding the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "None", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their opinion about the required condition for the learning rate, stating it is not scalable and unrealistic. This is a direct criticism of a specific aspect of the authors' work. The reviewer also provides a concrete example of a practical issue (learning rates becoming unreasonably large) and a specific scenario (largescale datasets) to support their claim. This makes the criticism quite explicit and actionable for the authors.", "grounding_specificity_rationale": "The reviewer's comment does not identify a specific part of the paper or method that requires attention. They are making a general critique about a condition that the authors seem to have overlooked or misunderstood. While the comment points to a potential issue, it doesn't pinpoint the exact location or nature of the problem within the paper. Therefore, the grounding is weak as the authors cannot confidently determine where the issue lies.", "verifiability_rationale": "The reviewer's comment is a statement of opinion and criticism, not a claim that requires verification or evidence. They are questioning the authors' understanding of learning rate scaling and its practical implications. Since there is X being made that needs to be supported by evidence, the verifiability is not applicable or, as a default, it can be considered 1 as there is no assertion to validate.", "helpfulness_rationale": "The reviewer's comment raises a valid point about the practical implications of the authors' required learning rate condition. They highlight a potential issue with the scalability and practicality of the proposed method. While the comment is relevant to the authors' work, it doesn't directly instruct them on how to improve their method. It's a critique that challenges their assumptions rather than providing a direct solution. Therefore, it is 3 in identifying a potential flaw but doesn't offer a concrete improvement strategy."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action: 'Since we cannot control the label distribution of unlabeled data during training, the author should also use a more convinced setting as did in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018, which directly samples unlabeled data from millions of reviews.' This action is to suggest using a more realistic data setting. While the comment doesn't provide specific details on how to implement this, it clearly identifies a potential improvement. The action is implicit in the suggestion to use a more 'convincing' setting and a specific method from a cited paper.", "grounding_specificity_rationale": "The comment explicitly mentions 'unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version)' and 'perfectly balanced'. These are specific parts of the paper and the data used. The comment also mentions 'imbalanced data in millions of reviews' as a more 'convincing setting', which implies a specific area of interest. The grounding is strong as the comment directly refers to the data used by the authors and suggests an alternative approach.", "verifiability_rationale": "The comment contains a claim: 'Since we cannot control the label distribution of unlabeled data during training, the author should also use a more convinced setting as did in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018, which directly samples unlabeled data from millions of reviews.' This claim is supported by the statement that using a more 'convincing setting' is beneficial and by citing a relevant paper that uses a specific method for handling unlabeled data. The reasoning is that realworld data is often imbalanced, and using such data can lead to more robust models. The evidence is the established practice in the field of using imbalanced data in semisupervised learning.", "helpfulness_rationale": "The review point directly addresses a potential limitation of the authors' experimental setup by highlighting the impracticality of using a perfectly balanced dataset for unlabeled data. It suggests a more realistic and commonly used approach in the field, which can help the authors understand how their method performs under more realistic conditions. The suggestion to use a method from a cited paper also provides a concrete direction for the authors to explore. This information is directly applicable and valuable for improving the authors' work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the difficulty of sampling from the DPP when eigenfunctions are inaccessible (line 130) and directly compares this to the challenges of sampling from the leverage score in 3. This provides a clear action for the author to take: investigate the implications of inaccessible eigenfunctions for their DPP sampling process. The reviewer also frames this as a question about whether DPP sampling is *easier* than leverage score sampling, which is a concrete action with a specific implication.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the DPP if the eigenfunctions e_n's are inaccessible (Eq (10) line 130)' and then directly connects this to the problem of 'sampling from the leverage score in 3'. This clearly identifies the specific part of the paper being addressed. The reviewer also poses a question about the ease of DPP sampling compared to leverage score sampling, which directly implies a comparison of these two methods. This strong explicit identification and connection makes the grounding very specific.", "verifiability_rationale": "The reviewer makes a claim: 'It's not clear how to sample from the DPP if the eigenfunctions e_n's are inaccessible (Eq (10) line 130). This seems to be the same problem with sampling from the leverage score in 3, so I'm not sure how sampling from the DPP is easier than sampling from the leverage score.' The reviewer provides a justification by stating that the inaccessible eigenfunctions make the sampling process unclear and draws a parallel to the leverage score problem. While the reviewer doesn't provide external references, the reasoning is based on the understanding of DPPs and leverage scores. The claim is supported by the logical connection between the two sampling problems.", "helpfulness_rationale": "The reviewer identifies a specific technical issue: the difficulty of sampling from the DPP when eigenfunctions are inaccessible and draws a direct comparison to the challenges of sampling from leverage scores. This highlights a potential area of confusion for the author. While the reviewer doesn't offer a solution, they point out a potential problem and its similarity to another known issue. This is helpful in that it directs the author to investigate the implications of inaccessible eigenfunctions for their DPP sampling process and consider the challenges associated with leverage score sampling. However, it doesn't provide a concrete solution, making it 3 rather than 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their doubt and criticism of the experimental results. They identify specific examples of POMDP problems with nonconvex value functions as the motivation for their solution. This clearly indicates an explicit action or suggestion, albeit one that is negative and points to a lack of something.", "grounding_specificity_rationale": "The reviewer identifies specific POMDP examples (surveillance in museums with thresholded rewards; privacy preserving data collection) as the context for their solution. This demonstrates a degree of grounding as the reviewer can accurately pinpoint the sections, tables, figures, or unique aspect being addressed. However, the reviewer does not explicitly state *why* these specific examples are particularly challenging or why existing methods would struggle with them. The grounding is present, but the specificity of the explanation is lacking.", "verifiability_rationale": "The reviewer's comment does not contain a claim that requires verification. They express a general doubt about the experimental results and provide examples to motivate their case. There are no external references or logical reasoning provided to support their claim.", "helpfulness_rationale": "The reviewer provides a clear criticism of the experimental section, highlighting the lack of experiments related to the specific examples they provided as motivation. While the criticism is valid and points to a weakness, it does not offer any suggestions or actionable feedback on how to improve the experiments. The feedback is about the *absence* of something, not about *how* to create it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a limitation of sequential ensembling: 'For sequential ensembling, it is important to study the effect of noise accumulation in the context of homomorphic encryption. This limitations prevents the use of even single deep neural networks on homomorphically encrypted data.' The action is to study the effect of noise accumulation, and the method is to consider homomorphic encryption. The action is clear.", "grounding_specificity_rationale": "The comment explicitly mentions 'sequential ensembling' and 'homomorphic encryption'. The unique aspect being addressed is the 'effect of noise accumulation' within the context of 'homomorphic encryption'. The authors can accurately pinpoint the section, table, figure, or unique aspect being addressed. This can be achieved through:  Literal mentions of sections, tables, figures, etc.  Mentions of unique elements of the paper.  General comments that clearly imply the relevant parts without explicitly naming them. In this case, the specific techniques are mentioned directly.", "verifiability_rationale": "The comment contains a claim: 'For sequential ensembling, it is important to study the effect of noise accumulation in the context of homomorphic encryption. This limitations prevents the use of even single deep neural networks on homomorphically encrypted data.' The claim is that 'noise accumulation in the context of homomorphic encryption' is a limitation for 'sequential ensembling' and that this 'limitations prevents the use of even single deep neural networks on homomorphically encrypted data'. The reasoning is that homomorphic encryption has limitations, and noise accumulation is a key factor. The evidence is that homomorphic encryption involves computations on encrypted data, which inherently introduces noise that can accumulate with multiple operations, making it difficult to perform complex computations or train deep neural networks without decryption. This is a generally accepted limitation in the field. The claim is thoroughly supported by common knowledge and logical reasoning.", "helpfulness_rationale": "The review point identifies a significant limitation of sequential ensembling in the context of homomorphic encryption. It highlights that the accumulation of noise during the sequential application of homomorphic operations can severely restrict the ability to effectively use deep neural networks on encrypted data. This is a valuable piece of feedback for authors working in this area, as it directly points out a practical challenge and a potential area for further research or development. The suggestion, while not explicitly stated, is implicit: authors should consider alternative approaches or methods to mitigate the noise accumulation issue."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a recommendation: \"it should be used standard regularization trick.\" This indicates a direct action to be taken. However, the specific type of regularization trick is not mentioned, making the action somewhat vague in terms of implementation details.", "grounding_specificity_rationale": "The comment explicitly mentions 'stronglyconvex concave case,\" which is a specific property of the optimization problem being considered. This clearly identifies the part of the paper being addressed. The comment also specifies what the suggestion is: to use a 'standard regularization trick.\" This provides some detail on what needs to be addressed in this part.", "verifiability_rationale": "The comment contains a claim: suggesting using a 'standard regularization trick\" for comparison. However, it does not provide any justification or reasoning for why this is beneficial or how it should be implemented. There is no logical reasoning, common knowledge, or external references provided to support this suggestion.", "helpfulness_rationale": "The comment provides a suggestion for improvement: using a 'standard regularization trick\" to compare complexity. While this is a valid area for the authors to consider, the comment lacks specific details about which regularization trick to use and how it applies to their method. The suggestion is clear and actionable in terms of identifying an area for improvement, but it lacks the necessary specifics to be fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests discussing different input types, but it lacks specific, actionable steps for the authors. It doesn't explicitly state what the authors should do next.", "grounding_specificity_rationale": "The review point is very general and doesn't specify any particular section, table, figure, or unique element of the paper. The vague pronoun 'it' makes it difficult to pinpoint the area of discussion.", "verifiability_rationale": "The review point is a suggestion for improvement, not a claim that needs verification. It doesn't contain any assertions about what is wrong or needs changing.", "helpfulness_rationale": "The review point is relevant to many papers but lacks specific guidance on how to implement the suggestions. It doesn't provide concrete steps or examples for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a problem (drop in accuracy) caused by a change (ICLHAR) and suggests a discussion. While it implies the authors should consider alternative approaches, it doesn't explicitly state an action to be taken. The action is implicit: 'You changed X, it caused Y, maybe try Z.'", "grounding_specificity_rationale": "The review point explicitly mentions 'ICLHAR' and 'accuracy scores' and their respective changes. It also specifies the metrics (TRIP, accuracy scores) and the direction of change (dropping). This clearly identifies the specific parts of the paper being addressed.", "verifiability_rationale": "The review point states a fact: 'a drop in consistency and verifiability' and 'accuracy scores (dropping from 70.4 to 55.6 on TRIP)'. This is a verifiable observation. While it doesn't provide external references or detailed reasoning for *why* ICLHAR impedes accuracy, the statement itself is verifiable.", "helpfulness_rationale": "The review point directly addresses a problem (drop in accuracy) caused by a change (ICLHAR) and suggests a discussion. This is a clear and actionable feedback that helps the authors understand the impact of their change and consider alternative approaches. The suggestion to 'discuss or at least acknowledge' is a concrete action the authors can take."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies the presence of writing issues but does not explicitly state how the author should address them. While it mentions 'grammatical errors' and 'abuses of mathematical symbols,' these are symptoms rather than explicit actions. The reviewer does not provide concrete steps or guidance on how to improve the writing or correct the mathematical notation. Therefore, the action is implicit rather than explicit.", "grounding_specificity_rationale": "The review point makes a general statement about the paper containing 'severe writing issues' without specifying which part of the paper or which type of issue is being referred to. It does not mention a specific section, table, figure, or unique aspect of the paper. The reviewer does not provide any information that would allow the author to pinpoint the location or nature of the problem. Therefore, the grounding is weak as the author cannot confidently determine the referenced part.", "verifiability_rationale": "The review point makes a claim about the paper's writing quality ('The paper contains severe writing issues...') but does not provide any evidence or reasoning to support this claim. It does not cite specific examples, external references, or logical arguments to back up the assertion. The reviewer simply states the existence of problems without providing any context or justification. Therefore, the claim is not supported by any verifiable evidence.", "helpfulness_rationale": "The review point identifies a problem with the paper's writing quality but does not offer any specific advice or suggestions on how to improve it. While it highlights the need for editing and review, it does not provide concrete steps or guidance on how the author should go about addressing the identified issues. The reviewer does not suggest any specific actions, tools, or resources that the author could use. Therefore, the review point does not provide actionable feedback to the author."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the weakness in the introduction: 'The statement in the introduction regarding the biological plausibility of backpropagation may be too weak...'. This directly points to a specific area and suggests a concrete improvement by making the statement more impactful. The reviewer implies the action of strengthening the statement.", "grounding_specificity_rationale": "The reviewer not only identifies the weakness but also explicitly points to the relevant section in the introduction: 'It is widely accepted that backpropagation is biologically implausible.' This clearly grounds the comment to a specific part of the paper and provides context for the weakness. The reviewer identifies the area that needs improvement.", "verifiability_rationale": "The reviewer makes a claim: 'The statement in the introduction regarding the biological plausibility of backpropagation may be too weak.' This claim is supported by external knowledge: 'It is widely accepted that backpropagation is biologically implausible.' This provides a logical reasoning and a commonsense argument to support the claim.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'It is widely accepted that backpropagation is biologically implausible.' This directly informs the authors on how to improve their draft by making the statement in the introduction more precise and informative. The reviewer's comment is directly relevant and provides a concrete direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review states a limitation but does not provide explicit or concrete suggestions for how the authors should address it. The action is implied but not stated.", "grounding_specificity_rationale": "The reviewer refers to \"their proposed method\" and \"other NLP tasks\" without explicitly naming a specific section, table, figure, or unique aspect of the paper. The grounding is implied but not precise.", "verifiability_rationale": "The review does not present a claim that requires verification. It is a statement of a limitation.", "helpfulness_rationale": "The review identifies a limitation of the paper's scope but does not offer specific, actionable advice on how to address it. The feedback is about the scope and generalizability, which is valuable context but not a direct prescription for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the action of 'clarify the meaning of \"certificate\"'. However, the reviewer does not specify *how* to clarify or what aspects of the meaning need to be addressed. This makes the action somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"line 267\" as the relevant part of the paper. This is a clear and precise identification of the section being addressed. The reviewer also suggests clarifying the meaning of \"certificate\", which is a specific issue related to this part. This demonstrates strong grounding. The reviewer also suggests a *specific* action (clarification), which further enhances grounding.", "verifiability_rationale": "The reviewer identifies a potential issue: the ambiguity of \"certificate\" in the context of complexity theory. However, the reviewer does not provide any specific evidence or references to support this claim. The reviewer also does not explain *why* this ambiguity is a problem or how clarifying the meaning will resolve it. Therefore, the claim is not welljustified.", "helpfulness_rationale": "The reviewer suggests a discussion about the potential misinterpretation of \"certificate\". While this is a relevant point for the authors, the reviewer does not provide any concrete suggestions or actions for the authors to take. The suggestion is more of a request for clarification rather than a direct improvement. Therefore, it is not 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points out a limitation (limited to toy data) and suggests a direction for improvement (real data). While it identifies an area for improvement, it doesn't explicitly state how to implement this improvement or what specific changes are needed. The suggestion is general and lacks concrete details.", "grounding_specificity_rationale": "The review mentions 'toy data' and 'real data' generally. It doesn't pinpoint a specific section, table, figure, or unique aspect of the paper where the limitation or suggestion applies. The grounding is weak as the target of the feedback is not clearly defined.", "verifiability_rationale": "The review points out a limitation of the experiments and suggests a potential area for future work. This is a judgment about the current work's scope and potential. While it could be *verifiable* by showing results on real data, the review itself doesn't *prove* or *disprove* anything. It's a suggestion, not a factual claim requiring evidence.", "helpfulness_rationale": "The review identifies a limitation of the experiments (limited to toy data) and suggests a relevant direction for future work (performance on real data). This is a valuable point for discussion and provides a direction for further research. However, the suggestion is general and lacks specific details, making it less directly actionable for improving the current draft."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their belief that the proxlinear subproblem can be reformulated using the conjugate function and claims this reformulation makes the motivation of Algorithm 1 unclear. This indicates a clear action: to explore this alternative approach and its implications for Algorithm 1.", "grounding_specificity_rationale": "The reviewer directly addresses the proxlinear subproblem mentioned in Algorithm 1, indicating a reasonable level of grounding. They propose a specific alternative method and explain how it potentially simplifies Algorithm 1, connecting their suggestion directly to the existing method.", "verifiability_rationale": "The reviewer makes a claim about a potential reformulation of the proxlinear subproblem and provides a reason (simplification and unclear motivation of Algorithm 1) for this claim. This constitutes a claim that is supported by reasoning, making it 3.", "helpfulness_rationale": "The reviewer proposes a specific alternative method for solving the proxlinear subproblem. While the suggestion is clear, the reviewer does not provide concrete steps on how to implement this reformulation or how it would directly improve Algorithm 1. The potential impact is that it could simplify Algorithm 1, but the lack of detailed steps makes it less immediately helpful."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the connection between Knowledge Distillation (KD) and Label Smoothing (LS) and provides specific conditions (uniformly distributed teacher network and temperature of 1) under which they can be viewed as equivalent. This makes the suggestion both explicit and concrete, as the conditions are clearly defined. The reviewer is indicating a potential conceptual link that could guide the author's understanding or implementation.", "grounding_specificity_rationale": "The reviewer explicitly mentions the conditions under which KD can be viewed as a special form of LS (uniformly distributed teacher network and temperature of 1). This allows the reader to precisely identify the specific aspect of the paper being addressed, making the grounding fully grounded. Furthermore, the reviewer explains what is meant by 'special form,' providing clear specificity about the relationship between the two techniques under these conditions.", "verifiability_rationale": "The reviewer presents a claim about the relationship between KD and LS under specific conditions. However, within the review point itself, there is no explicit justification, reference, or logical reasoning provided to support this claim. While the reviewer states the conditions, they do not demonstrate how these conditions lead to the equivalence or provide any evidence to back this up within the review point. Therefore, it is underverifiable as the claim is made without sufficient support within the provided text.", "helpfulness_rationale": "The reviewer points out a potential conceptual connection between Knowledge Distillation (KD) and Label Smoothing (LS). While this might not directly identify a flaw in the author's current work, it could be helpful for the author to understand the relationship between these two techniques and potentially explore ways to leverage or combine them. The helpfulness is somewhat limited to this conceptual understanding rather than a direct improvement suggestion. The reviewer is providing context and potentially opening up avenues for further exploration for the author."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states actions to be taken, such as 'make the captions more descriptive' and 'explain the scramble network better...'. However, the specific actions are not clearly defined, making it vague how to implement these changes. For example, 'make the captions more descriptive' could mean adding more details, using better wording, or explaining the data presented in the captions. Similarly, 'explain the scramble network better...' lacks specific guidance on how to elaborate on the network's function or its components.", "grounding_specificity_rationale": "The reviewer refers to 'the figures' and 'the scramble network' generally, without specifying a particular section, table, or unique element within the paper. While the intent is clear, the lack of precise identification makes the grounding weak. For instance, when saying 'make the captions more descriptive,' the reviewer doesn't specify which caption or part of the figure they are referring to. Similarly, 'explain the scramble network better...' lacks a specific reference point.", "verifiability_rationale": "The reviewer states a desire for improvement in the captions and the explanation of the scramble network. However, the review point does not contain a claim that can be verified. The reviewer is making a suggestion or request for change, but there is no logical reasoning, common knowledge, or external references provided to support this suggestion. The statement 'make the captions more descriptive' is a judgment about the current captions, but without evidence of their current state or why they need improvement, it cannot be considered verifiable.", "helpfulness_rationale": "The review point identifies areas for improvement, specifically the captions and the explanation of the scramble network. However, the lack of specificity in the suggestions makes it difficult for the authors to understand exactly what needs to be changed and how. The reviewer is making suggestions, but these suggestions are vague and open to interpretation. For example, 'make the captions more descriptive' could mean many different things, and 'explain the scramble network better...' lacks concrete examples or guidance on what aspects of the network need clarification. This vagueness limits the helpfulness of the feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their opinion that the motivation for using randomly sampled CIFAR images as backgrounds is 'not well motivated' and 'uninteresting'. This indicates an implicit action or suggestion that the authors should consider alternative background choices or justify this specific design decision more thoroughly. While the reviewer doesn't state the *exact* action, the sentiment suggests a need for more justification. The 'concrete vs. vague' aspect is less clear here, as the reviewer's overall assessment is more of a critique than a specific, actionable suggestion.", "grounding_specificity_rationale": "The reviewer mentions 'CIFAR images as backgrounds' as the specific aspect of the paper being questioned. This demonstrates a degree of grounding as the reviewer is referring to a specific part of the paper. However, the reviewer also mentions the 'dimension of difficulty' as being uninteresting, which is a more general concept and not a specific part of the paper. This lack of precise identification of the 'dimension of difficulty' weakens the grounding aspect.", "verifiability_rationale": "The reviewer poses a question: 'Why is this particular dimension of difficulty interesting?' This constitutes a claim that needs to be supported. However, the reviewer does not provide any evidence, reasoning, or references to support their opinion that this dimension of difficulty is not interesting. The claim is presented without any backing, making it difficult to verify.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the motivation behind a specific design choice (background selection). By questioning the 'interestingness' of this dimension of difficulty, the reviewer is implicitly suggesting that the authors should consider the implications of this choice and potentially explore alternative approaches. While the reviewer doesn't offer a direct solution, their question points to a potential area for improvement in the experimental design, making the comment 3 in guiding the authors' thinking."}
{"actionability_label": "4", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a question about the model's ability to capture periodicity versus compositionality. This directly addresses an action or suggestion related to the model's capabilities. While not providing a direct action, the question implicitly encourages the authors to consider the limitations of their model in capturing a broader concept (compositionality) when only a specific instance (periodicity) is explicitly modeled. The reviewer's question is clear and directly related to the model's behavior.", "grounding_specificity_rationale": "The reviewer mentions specific experiments (Experiment 1b, all experiments except Experiment 1b) and the types of relationships learned (periodic). This demonstrates strong grounding as the reviewer can accurately pinpoint the experimental context and the specific properties of the relationships being learned. The language used is precise and directly refers to the experimental setup and the nature of the data.", "verifiability_rationale": "The reviewer poses a question about the model's capabilities, which can be considered a claim. While the reviewer doesn't provide a definitive answer or proof, the question is based on generally accepted knowledge within the field of machine learning and model interpretability. The question is logical and relates to the common understanding of how models learn different types of relationships. The reviewer's question is verifiable through common knowledge and logical reasoning.", "helpfulness_rationale": "The reviewer's question is directly relevant to the field of machine learning and model interpretability, particularly in the context of compositional generalization. The question encourages the authors to reflect on the limitations of their model in capturing a broader concept (compositionality) when only a specific instance (periodicity) is explicitly modeled. While the review point does not offer a concrete solution, it prompts the authors to consider a specific aspect of their model and experimental setup, making it 3 in guiding further investigation and reflection."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the missing comparisons to existing DAS earthquake detection models and suggests clarifying the claim about the foundation model and demonstrating future applications. These are direct actions the authors can take to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'DAS earthquake detectors' and names 'PhaseNetDas' as an example. This is strong grounding as the authors can directly identify the specific area being addressed. The suggestion to show or justify a future useful application further grounds the comment in practical implications.", "verifiability_rationale": "The reviewer provides concrete suggestions for improvement, such as 'show or justify a future useful application'. These suggestions are actionable and provide a clear path for the authors to follow, making the claim verifiable. The reviewer is not just stating a problem but also offering a solution or a direction for investigation.", "helpfulness_rationale": "The reviewer identifies a clear gap in the evaluation by pointing out the existence of related work (DAS earthquake detectors) and the lack of comparison. They also suggest clarifying the claim about the foundation model and demonstrating future applications, which are actionable and constructive suggestions. While the paper might already address the benefit against PhaseNetDAS (as the reviewer acknowledges), the reviewer's point about *not making a comparison* is a valid concern that needs attention. The suggestions are specific and aim to improve the paper's positioning and impact."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a limitation of the approach, which constitutes an action (identifying a weakness). However, the suggestion is not concrete, lacking a proposed alternative or solution.", "grounding_specificity_rationale": "The reviewer's question is general to the triplet approach and does not point to a specific part of the paper or methodology. Therefore, the grounding is weak. The specificity is also low as the question is about a potential extension rather than a specific detail.", "verifiability_rationale": "The reviewer is not making a claim but rather posing a question about the limitations of a specific method (using triplets). Therefore, it does not fit the criteria for verifiability.", "helpfulness_rationale": "The reviewer's question prompts a discussion and consideration of the limitations of the triplet approach. While it doesn't directly tell the authors what to do, it encourages them to think critically about their methodology, which can be helpful for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment asks a question ('What is a 'sqeuence of episodes\" here?') and points to a potential gap in the explanation (\"Missing related work...\") but does not explicitly state an action the authors should take. While it identifies a potential area for clarification, it doesn't directly instruct the authors on how to address it.", "grounding_specificity_rationale": "The comment refers to \"practice and evaluation\" without explicitly naming a section, table, figure, or unique element of the paper. It also does not specify what needs to be addressed in this part. While it implies these concepts relate to parts of the paper, it doesn't pinpoint them.", "verifiability_rationale": "The comment contains a claim ('Missing related work...') but does not provide sufficient justification or evidence for its existence. It suggests related work but doesn't explain why this work is missing or how it would be relevant.", "helpfulness_rationale": "The comment raises a valid concern about missing related work but does not offer concrete, actionable steps for the authors to take. It points to a potential area of improvement but doesn't guide them on how to address the identified weakness."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review suggests a distinction between two concepts. While it points to a potential area for clarification, it doesn't directly instruct the authors on *what to do*. Therefore, it's not fully actionable.", "grounding_specificity_rationale": "The review *mentions* the 'allornothing or cutoff phenomenon' and 'machine learning and NeurIPS community'. It doesn't explicitly state *which part* of the paper this relates to.", "verifiability_rationale": "The review states a difference between two concepts. This constitutes a claim. However, it doesn't provide *evidence* or *explanation* for why this distinction is important or how it relates to the NeurIPS community. It's a statement of opinion without supporting justification.", "helpfulness_rationale": "The review suggests a potential area for improvement in the authors' understanding of statistical concepts. It highlights a gap in their knowledge. While the suggestion is valid, it's a *general* point about distinguishing concepts. It doesn't provide a *specific, actionable fix*."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "6: X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the reliance on Theorem 8, making the action clear: 'Understand the details of Theorem 8 and its proof.' However, the reviewer does not provide specific guidance on how to do this, such as pointing to a specific section or suggesting a method for verification. The action is identified but not fully elaborated, making it less concrete.", "grounding_specificity_rationale": "The reviewer does not specify where Theorem 8 is located within the paper or provide any details about its content or implications. The comment is a general statement about the theorem's location in the appendix without identifying the specific section, table, figure, or unique aspect being addressed. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer expresses concern about the clarity of the proof but does not provide any specific examples or references to external works to support this claim. The statement is a subjective opinion about the proof's clarity, lacking any verifiable evidence. There is X being made, so verifiability is not applicable.", "helpfulness_rationale": "The reviewer identifies a potential issue (clarity of Theorem 8's proof) but does not offer any suggestions or solutions. While identifying a problem can be helpful, the lack of concrete guidance makes the review less actionable and ultimately less helpful. The reviewer does not provide any alternative approaches or steps the authors can take to address the issue."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "Both review point 1 and 2 are actionable. Review point 1 explicitly states a correction to a statement about Walkman and ADMM, and review point 2 points out a lack of clarity in a specific sentence, indicating a desire for improvement. These are direct and clear suggestions for the authors.", "grounding_specificity_rationale": "Review point 1 explicitly mentions the 'Walkman algorithm (Mao et al., 2020)' and details its relation to ADMM, providing strong grounding. It also clearly criticizes 'SGD'. Review point 2 refers to 'the SGDbased Algorithm 1' within the context of the unclear sentence, providing partial grounding. While the reference to 'Algorithm 1' is implicit, the surrounding text makes it reasonably clear.", "verifiability_rationale": "Review point 1 provides specific information about the relation of Walkman to ADMM and critiques the SGDbased Algorithm 1, making the claim verifiable. Review point 2 points out a lack of clarity in a specific sentence, which can be considered verifiable by highlighting the unclarity itself, although it doesn't provide a specific justification for the lack of clarity.", "helpfulness_rationale": "Review point 1 is 5 as it provides concrete information about Walkman and directly critiques a generalization about SGD, likely guiding the authors in their work. Review point 2 is 4 as it points out a lack of clarity, which is a valuable feedback point, though it might be a smaller priority compared to the more specific point about Walkman."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'it only compares against 3 basic alternatives and ignores some other NAS (e.g. supernet/oneshot approaches, etc...)' which is a direct and clear action to point out a missing element in the analysis. The suggestion to include 'supernet/oneshot approaches' is also concrete, indicating a specific area for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'some other NAS (e.g. supernet/oneshot approaches, etc...)' which provides some specificity by naming the types of NAS methods being referred to. However, the reviewer does not explicitly state which specific part of the paper is being addressed (e.g., a particular section, table, or figure). The mention of 'examples' partially addresses the need for specificity, but the lack of a direct reference to a specific element in the paper makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer makes a claim about the BRPNAS analysis: 'it only compares against 3 basic alternatives and ignores some other NAS (e.g. supernet/oneshot approaches, etc...)' This claim is based on the reviewer's understanding of the paper's related work section (implied by 'BRPNAS analysis'). While the claim itself is verifiable based on the paper's content, the lack of explicit citations within this review point makes the verifiability somewhat lacking in depth.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'it only compares against 3 basic alternatives and ignores some other NAS (e.g. supernet/oneshot approaches, etc...)' This suggests a valuable improvement for the authors by pointing out a missing element in their analysis. While the grounding is not perfect, the suggestion itself is helpful in guiding the authors to expand their comparisons. The reviewer's intent is to inform the authors of a limitation in their current evaluation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states two distinct areas for improvement: the lack of 'attacks with different strength' and the lack of exploration of how 'different thresholds influence detection performance'. These are clear actions the authors should take.", "grounding_specificity_rationale": "The reviewer mentions 'attacks with different strength' and 'different thresholds'. While they identify the *type* of attacks and the *parameter* lacking detail, they do not specify *which* strengths or *how* the thresholds are varied. This makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer makes a claim that the experiment results lack these specific elements. While they state what is missing, they do not provide logical reasoning, common knowledge, or external references to support this claim. The justification is present, but it lacks depth and evidence.", "helpfulness_rationale": "The reviewer clearly identifies specific areas for improvement related to the experimental setup and analysis. They point out concrete shortcomings that the authors can directly address. This provides valuable guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states that the proposed method 'seems only works for digit or text images' and does not apply to 'natural images, such as CIFAR10'. This indicates an implicit action: the reviewer is pointing out a limitation of the method. The action is clear, but it is not stated directly. The reviewer provides specific examples of image types the method can and cannot handle, making the implied action quite concrete.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify a specific part of the paper or experiment where the limitation applies. They are discussing the general applicability of the method to different types of images. Therefore, the grounding is weak. While the reviewer mentions 'digit or text images' and 'natural images, such as CIFAR10', this specificity is about the *type of data* and not a specific section, table, or figure within the paper.", "verifiability_rationale": "The reviewer states that the method 'seems only works for digit or text images' without providing any evidence, reasoning, or references to support this claim. There is X being made; instead, a limitation is being pointed out. Therefore, the claim extraction would be 'X'. The lack of justification makes the statement 1.", "helpfulness_rationale": "The reviewer's comment is a criticism of the proposed method's limited applicability. They are not suggesting any improvements or providing any information to address the limitation. This type of comment, which identifies a weakness without offering a solution, is generally not helpful for authors trying to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem ('prompts are not wellorganized') and identifies the location ('Table 6, 7'). However, the reviewer does not specify how to fix the issue, making it partially actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 6, 7' and 'prompts', which are specific parts of the paper. However, the reviewer does not specify *what* is wrong with the organization of the prompts or the nature of the 'squeezing together'.", "verifiability_rationale": "The reviewer makes claims about the prompts ('not wellorganized', 'sentences squeeze together') but does not provide any evidence, references, or logical reasoning to support these claims within this review point.", "helpfulness_rationale": "The reviewer identifies potential issues with the organization of prompts and the squeezing of sentences. However, the feedback is general and lacks specific details on what is wrong or how to improve the situation, making it 3 but lacking concrete guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the issue with the figures ('figures are not clear') and provides specific examples of what is unclear ('in figure 2, it\u2019s confused for the relation of 3 subfigures') and what is missing ('Some modules are not labeled in figure, such as CMAF, L_BT, VoLTA'). The reviewer directly identifies areas for improvement, suggesting increased clarity and labeling. The actions to be taken are clear: improve the clarity of figure 2 and label the missing modules. The information provided is sufficient for the authors to understand the problem and how to address it.", "grounding_specificity_rationale": "The comment explicitly mentions 'figure 2' and the specific subfigures involved ('it\u2019s confused for the relation of 3 subfigures'). It also names specific modules that are not labeled ('Some modules are not labeled in figure, such as CMAF, L_BT, VoLTA'). The grounding is strong as the specific figure and the missing elements within it are clearly identified. The specificity extends to detailing the nature of the confusion (the relation of subfigures) and the exact missing labels.", "verifiability_rationale": "The review point does not contain a claim or suggestion that requires verification. It is a statement of observation about the figures' clarity. Therefore, it does not fall under the 'Verifiability' category, and the appropriate label is 'X' for X.", "helpfulness_rationale": "The review point directly identifies a clear weakness in the paper (unclear figures) and provides specific suggestions for improvement (increased clarity and labeling of modules). This feedback is directly relevant to the authors and provides actionable steps they can take to enhance their work. The reviewer's input is valuable in guiding the authors towards specific areas of improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states 'Some questionable design choices' and then lists specific concepts ('perplexity,' 'catastrophic forgetting,' 'domain drift'). This is an explicit statement of issues. However, the reviewer doesn't pinpoint *which* design choice is questionable. They also don't specify *how* perplexity relates to the design choices or what aspects of domain drift are relevant. Therefore, it's not very concrete.", "grounding_specificity_rationale": "The reviewer mentions 'perplexity,' 'catastrophic forgetting,' and 'domain drift' generally. While they don't point to a *specific* section or table, they do mention specific concepts within the paper's domain. This could be considered weak grounding as they don't pinpoint the exact location of the issue. The reviewer clearly specifies what needs to be addressed (perplexity, catastrophic forgetting, domain drift) in the referenced parts.", "verifiability_rationale": "The reviewer presents a statement about perplexity and its relation to semantic information retention and domain drift as a potential issue. This constitutes a claim that perplexity might not be a reliable indicator. However, the reviewer doesn't provide any specific examples, citations, or logical reasoning to *support* their claim about the relationship between perplexity and domain drift. They raise a concern but don't explain *why* they think this is the case or provide evidence.", "helpfulness_rationale": "The reviewer points out a potential flaw in the methodology (using perplexity without considering domain drift) and suggests that this could lead to misinterpretations. While the reviewer identifies a potential issue, they don't offer concrete suggestions or guidance on how to address this. They raise a concern but don't provide a solution or alternative approach."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the concern: 'I'm unsure if 44k dialogues is sufficient...' This is an explicit statement of a need for more data. Furthermore, the reviewer suggests a concrete action: 'how to expand the training data'. This suggests a clear understanding of the problem and a direct path to improvement. The reviewer is not just pointing out a problem but also offering a potential solution.", "grounding_specificity_rationale": "The reviewer mentions the dataset size (44k dialogues) and implies a lack of coverage. While they don't pinpoint a specific dialogue or section as the issue, their criticism of the dataset's scale and diversity contributes to weak grounding. The reviewer's suggestion to 'expand the training data' is vague and doesn't specify *how* to expand it, further indicating a lack of specific grounding.", "verifiability_rationale": "The reviewer states a fact: 'LLMs are typically trained on trillions of tokens'. This is verifiable. The reviewer then makes a logical inference: 'I do not see how 44k dialogues can capture the combinations of personalities and topics'. This inference is based on the stated fact and the reviewer's intuition about the vastness of LLM training data. While the inference is logical, the reviewer doesn't provide specific external references to support this claim within the review point itself. The final statement: 'In theory, this dataset also needs to be massive to cover varied domains' is another logical inference, building on the previous points. The reviewer is making a general point about the scale of LLM training data rather than referencing specific examples or external sources within this review point.", "helpfulness_rationale": "The reviewer clearly identifies a problem: the potential inadequacy of the dataset. They offer a solution: 'how to expand the training data'. The reviewer's overall message is constructive, suggesting a desire for improvement and a potential path towards it. The reviewer's statement about the dataset needing to be 'massive to cover varied domains' indicates a clear understanding of the limitations and a desire for a solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement explicitly states that the method's applicability is unclear for real and categorical features. This is an explicit action or suggestion that the authors should investigate or clarify. While the action itself is not fully specified, the target (real and categorical features) is clearly identified.", "grounding_specificity_rationale": "The comment refers to the 'applicability of the method' generally, without specifying a particular section, table, figure, or unique element of the paper. While the content is about features, it doesn't point to a specific part of the paper being addressed.", "verifiability_rationale": "The comment presents a question ('It is not clear...') which can be considered a claim that requires clarification or justification. However, the review point does not provide any logical reasoning, common knowledge, or external references to support this claim. It simply states the uncertainty.", "helpfulness_rationale": "The review point identifies a specific area for improvement (the applicability of the method to different feature types) and encourages the authors to clarify this point. While it doesn't offer a solution, it points to a gap in the information and suggests a direction for further investigation, which is helpful for guiding the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment does not specify how the writing should be improved or what specific points are unclear. It is vague and lacks concrete instructions.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper that is unclear. It is general and does not pinpoint the location of the issue.", "verifiability_rationale": "The comment does not make a claim about the writing. It is a suggestion and lacks any supporting evidence or logical reasoning.", "helpfulness_rationale": "The comment is vague and does not provide specific suggestions or identify areas that need improvement. It lacks actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an improvement to the evaluation method but does not explicitly state how the authors should implement this change. The action is implied but not directly stated, making it less actionable.", "grounding_specificity_rationale": "The review point does not specify which part of the paper is being addressed or what the issue is with the current evaluation method. The grounding is absent.", "verifiability_rationale": "The review point is a suggestion, not a claim or assertion about the paper. It does not make any statements that require verification or justification.", "helpfulness_rationale": "The suggestion to use other metrics is relevant and could be helpful for the authors. However, it lacks specific details on which metrics to use or how to apply the suggestion. The helpfulness is moderate as it points towards improvement but doesn't provide concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the weakness: 'Limited Discussion of Scalability Bounds' and further clarifies: 'No clear discussion of memory requirements or computational complexity.' This directly points to a lack of actionable information for the authors regarding these aspects. While it doesn't implicitly suggest where to look, the weakness is clearly defined, making it somewhat explicit. The action it implies is to investigate these missing discussions.", "grounding_specificity_rationale": "The review point mentions 'scalability bounds' and then specifically names 'memory requirements' and 'computational complexity' as areas lacking discussion. This demonstrates strong grounding as the authors can precisely identify the section, table, figure, or unique aspect being addressed (in this case, the discussion of these specific scalability aspects). Furthermore, the comment specifies what needs to be addressed in this part (the lack of discussion on memory requirements and computational complexity).", "verifiability_rationale": "The review point makes a claim: 'The paper doesn't thoroughly explore the upper limits of FedDES's scalability.' While this is a valid point, the review doesn't provide any logical reasoning, common knowledge, or external references to support this claim. It simply states the lack of exploration. Therefore, it is not 5. The claim is present, but the supporting evidence is missing.", "helpfulness_rationale": "The review point identifies a specific weakness ('limited discussion of scalability bounds') and suggests a direction for improvement ('no clear discussion of memory requirements or computational complexity'). This directly informs the authors where to look and what information is missing. The suggestion is clear and actionable, making the review point helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'differentially sorts nodes depending on the base node.' This indicates an action taken regarding the base node's influence on the sorting process. However, the reviewer does not detail *how* the base node affects the ordering, the key nodes for attention, or the model performance. The action is identified, but the specifics of the action are missing.", "grounding_specificity_rationale": "The reviewer directly mentions 'NodeSort' and 'base node' in the context of differential sorting. This demonstrates an attempt to identify the specific part of the paper being addressed. The reviewer is asking about the relationship between these two concepts, indicating a clear grounding of the issue.", "verifiability_rationale": "The reviewer is asking a question about the mechanism and impact of the differential sorting. This can be interpreted as a claim that the mechanism is not wellunderstood or that the impact on ordering, key nodes for attention, and model performance is unclear. However, the review point itself does not provide any evidence or reasoning to support this claim. The claim is implied but not explicitly stated or verified within the review point.", "helpfulness_rationale": "The reviewer is asking a very specific question about a potential implementation detail and its consequences. This is a 5 and constructive question that could lead to a better understanding of the model and potentially improvements. The question directly addresses a potential area for clarification or improvement in the original paper."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the diagram, which implies an implicit understanding that the arrow's direction is important. However, the reviewer doesn't explicitly state what the incorrect direction implies or how it should be corrected. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer explicitly points to the arrow in Figure 2 and asks about its connection to the Gaussian space and the latent space and its influence on n^(i). This demonstrates strong grounding specificity as the reviewer can accurately pinpoint the referenced part of the paper and clearly identify the issue with that part.", "verifiability_rationale": "The reviewer is making a claim about the purpose of the arrow in Figure 2 and its relationship to n^(i). The verifiability depends on whether the paper adequately explains the diagram's intended function. The reviewer's question implies a lack of clarity, making it 3 but lacking key elements like examples or references.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific detail in the paper. While it doesn't directly point out a flaw, it's highly likely the lack of clarity hinders understanding and potentially the implementation of the method. Therefore, it's 3 as it points to a potential problem that needs addressing."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that 'AR' stands for 'domain adaptation tasks and algorithms'. This provides a clear action for the authors to take, which is to understand the meaning of the abbreviation. The reviewer also provides the full phrase as the meaning, making the action concrete.", "grounding_specificity_rationale": "The reviewer explicitly states 'In Table 5', which clearly identifies the location where the undefined abbreviation 'AR' appears. This provides strong grounding for the authors to locate the relevant part of the paper. The reviewer also provides the full phrase 'domain adaptation tasks and algorithms' as the meaning of 'AR', which is a concrete specification of the issue.", "verifiability_rationale": "The reviewer makes a claim that 'Many abbreviations lack definition and cause confusion'. This claim is verifiable because the reviewer provides a specific example, 'AR' in Table 5, and explains its dual meaning. The reviewer also provides the full phrase 'domain adaptation tasks and algorithms' as the meaning of 'AR', which serves as the verification for the claim.", "helpfulness_rationale": "The review point is 5 because it directly identifies a clear weakness (undefined abbreviations) and provides a concrete solution (the full meaning of 'AR'). This actionable feedback empowers the authors to understand and improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential improvement in the analysis by suggesting using 'q value' instead of 'advantage'. While the reviewer doesn't explicitly state what action they are suggesting, the implication is that 'advantage' might be less common or have drawbacks. The action is implied but not directly stated, making it somewhat implicit. The action itself, switching to 'q value', is quite concrete once the suggestion is made.", "grounding_specificity_rationale": "The reviewer mentions 'advantage' and 'q value' in the context of analysis. While they are pointing out a potential improvement, they don't specify which part of the paper or figure is affected by this change. The reference is more general to the analysis process itself. Therefore, the grounding is weak as the specific location of the issue is not clearly identified.", "verifiability_rationale": "The reviewer poses a question about the technical consideration for using 'advantage' instead of 'q value'. There is no explicit claim or statement being made. It's a question posed for clarification, not a statement of what needs to be done. Therefore, it doesn't contain a claim that can be verified.", "helpfulness_rationale": "The reviewer is asking a question about a potential improvement in the analysis. While related to the paper, it's a question rather than a direct suggestion for change. It doesn't inherently improve the paper unless it leads to a concrete suggestion. It's more about guiding the authors' own investigation. Therefore, it's not a constructive critique that directly helps improve the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential ambiguity in the term 'Unsupervised Online Adaptation'. While the method might not be purely unsupervised due to the presence of labels in the training set, the criticism itself is a direct question about the definition and not an implicit instruction for the authors to modify their draft. The reviewer is asking for clarification on a concept, not providing a direct action or suggestion on how to improve the draft.", "grounding_specificity_rationale": "The reviewer explicitly names the method 'Unsupervised Online Adaptation' and highlights the specific components of the training set, including 'documents, quires and labels'. This clearly identifies the section of the paper and the unique elements being addressed, demonstrating strong grounding specificity.", "verifiability_rationale": "The reviewer states a fact about the training set requirements of the 'Unsupervised Online Adaptation' method. They correctly identify the need for 'documents, quires and labels'. This statement is verifiable as it is a factual claim about the method's requirements. There are no claims requiring justification, so it doesn't fall under the 'X' category. The information is present and logical.", "helpfulness_rationale": "The reviewer raises a valid point about the potential mislabeling of the adaptation method. While it might not be purely unsupervised, the presence of labels suggests a supervised aspect. This clarification, while not directly teaching the authors how to improve their draft, helps them understand the nature of the method and its requirements, making it more helpful in the long run by avoiding potential misunderstandings. The reviewer is not making a suggestion for improvement, but rather clarifying a concept."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that VINS uses different sample weights (W u i) in the training process, while most compared baselines like DNS, AOBPR, SA, and PRIS use a weight of 1. This is an explicit statement of a difference in implementation, which is a concrete action the authors should consider.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. It is a general comment about the experimental setup in Table 1. The authors cannot confidently determine which aspect of the comparison the reviewer is referring to.", "verifiability_rationale": "The claim is that the comparison in Table 1 is unfair due to different sample weights. While the claim is stated, there is no justification provided for why this difference makes the comparison unfair. There are no references to external knowledge or literature to support this assertion. The reasoning is based on the reviewer's interpretation of the experimental setup.", "helpfulness_rationale": "The review point identifies a potential flaw in the experimental setup (Table 1) regarding the use of different sample weights for VINS compared to other baselines. While this points out a problem, it does not offer a specific, actionable suggestion or propose a solution to make the comparison fair. It is a critique of the experimental design, not a constructive suggestion for improvement."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "3 (Somewhat Grounded and Specific)", "verifiability_label": "3 (3)", "helpfulness_label": "2 (2)", "actionability_rationale": "The reviewer states that the results are presented in a convoluted way, which implies an intention to point out a lack of clarity. While the reviewer identifies a specific issue (disregard of safety violations), they do not explicitly state how the presentation is convoluted or what specific changes should be made. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer mentions 'safety violations of the agent in the first 1000 episodes,' which is a specific part of the paper. However, the reviewer does not explain why these safety violations were disregarded or what the implications of this omission are for the results. The grounding is present, but the specific issue and its consequences are not fully elaborated.", "verifiability_rationale": "The reviewer makes claims about the presentation being convoluted and the disregard of safety violations. However, they do not provide explicit evidence or logical reasoning to support these claims. The claims are stated but not thoroughly justified or verified.", "helpfulness_rationale": "The reviewer points out a potential issue (lack of attention to safety violations) but does not provide specific recommendations or explain the consequences of this oversight. The impact on the authors is minimal, as they are not given actionable steps to improve their work based on this feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a *specific* issue ( allocation of Figure 1) and suggests an *improvement* (edits the main paper space more wisely). This suggests it *could* be actionable. However, the phrasing \"edits the main paper space more wisely\" is vague and doesn't explicitly state what needs to be done. While the reviewer implies a concrete action, the lack of explicitness makes it 2.", "grounding_specificity_rationale": "The review explicitly mentions \"Figure 1\" when stating \" allocation of Figure 1 is too naive.\" This indicates a degree of grounding as the specific part of the paper is identified. However, the broader comment \"Overall, you could have edited the space of main paper more wisely\" does not explicitly identify a *unique* element of the paper being addressed and could be interpreted as a general suggestion. Therefore, while a specific part is mentioned, the overall context lacks complete precision, making it weakly grounded and not fully specific.", "verifiability_rationale": "The review states \" allocation of Figure 1 is too naive\" as a claim. However, it does not provide any justification or reasoning for why the allocation is considered naive. There is no logical reasoning, common knowledge, or external references provided to support this claim. Therefore, the claim is made without sufficient backing, making it 1.", "helpfulness_rationale": "The review identifies a potential weakness ( allocation of Figure 1) and suggests an improvement (edits the main paper space more wisely). This indicates a potential value in the feedback. However, the suggestion is vague and lacks specific details on how the edits should be made. The lack of concrete guidance reduces the helpfulness of the review point. While it points to an issue, the lack of specific steps makes it less helpful than it could be."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer criticizes the planbased method because it requires manual design based on 'ground truth' in advance. While the reviewer identifies a limitation, they do not explicitly state an action or suggestion that the authors should take based on this observation. The criticism is about the *process* rather than a direct instruction on how to improve the plan. Therefore, the action is implicit, making it not fully actionable.", "grounding_specificity_rationale": "The reviewer criticizes the planbased method because it requires manual design based on 'ground truth' in advance. While they don't explicitly name the section, table, or figure containing the ground truth, they clearly imply it's related to the 'ground truth'. This suggests a lack of precise identification of the part being addressed, making the grounding weak. However, the reviewer does specify the *issue* \u2013 the difficulty in generalizing \u2013 which adds some specificity to the criticism.", "verifiability_rationale": "The reviewer makes a statement about the limitations of the proposed method regarding generalizability. This statement constitutes a claim. However, the reviewer does not provide any evidence, reasoning, or references to support this claim within the review point itself. The statement is presented as a critique without justification, making it 1.", "helpfulness_rationale": "The reviewer points out a limitation of the proposed method \u2013 its difficulty in generalizing to new datasets without ground truth. While this highlights a potential weakness, the reviewer does not offer any suggestions or actions for the authors to take to address this limitation. The review is primarily critical, identifying a problem without providing a constructive solution. Therefore, the review is not particularly helpful in guiding the authors towards improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitations of the paper's conclusion and provides specific examples of missing information, such as the exploration of combination methods and the discussion of featurereplay methods. They even suggest potential solutions, indicating a clear action the authors should take. The reviewer's point is not just a general critique but points to concrete areas for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'some conclusions' generally and doesn't pinpoint a specific section, table, figure, or unique aspect of the paper. They mention 'continuous learning with unlabeled data,' 'featurereplay methods,' and 'R3' but don't explicitly link these to specific parts of the submitted paper. While the reviewer identifies a potential area for improvement, they don't clearly specify *where* in the paper this improvement should be applied.", "verifiability_rationale": "The reviewer presents a claim: 'The results might come from the limited exploration of combination methods.' This is a statement of opinion or potential reason for a limitation. They then mention specific related works (R1 in continual learning and R2 (FRoST) in CCD, and R3 in continual category discovery) that are relevant. However, they don't explicitly explain *why* these methods are relevant or how they support their claim. The connection is implied but not fully elaborated. The reviewer provides examples of relevant literature, making the claim 3.", "helpfulness_rationale": "The reviewer provides a clear critique of the paper's conclusions and offers suggestions for improvement, such as exploring combination methods and discussing featurereplay methods. While the suggestions are somewhat general and lack detailed guidance on *how* to implement these suggestions, they are concrete and directly related to the identified weaknesses. The reviewer's point is actionable and provides a direction for the authors to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer's question is a valid point for discussion, but it lacks explicit actionability. While the question implies a desire to understand the significance of the ablation study's results, it doesn't directly instruct the authors on how to proceed or what changes to make based on this observation. The reviewer is asking a question, which is an implicit action, but the lack of a clear direction makes it 2.", "grounding_specificity_rationale": "The reviewer's question about the significance of the ablation study's results lacks grounding specificity. While the question is relevant to the paper's findings, it doesn't explicitly identify a specific part of the paper or table where the ablation study is discussed. The reviewer is asking about the *meaning* of the results, which is a general question rather than a question about a specific element of the paper. The reference to 'Tab.' suggests an attempt to ground the question, but the content of the question itself doesn't specify which table or section is being referred to.", "verifiability_rationale": "The reviewer's question about the significance of the ablation study's results lacks verifiability. The claim that a small difference is noticeable is presented without any logical reasoning, external references, or examples. The reviewer is asking a question about the *meaning* of the results, but there's no justification provided to support the claim that this difference is meaningful. The question is posed as a statement of observation rather than a wellsupported claim.", "helpfulness_rationale": "The reviewer's question about the significance of the ablation study's results is not helpful because it lacks justification and specific direction. The question is general and doesn't provide actionable feedback to the authors. The reviewer is asking *what* the difference means, but not *how* that understanding can be used to improve the paper. The lack of a clear request for clarification or a suggestion for further analysis makes the review point unhelpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies an issue ('wording is overly exaggerated') and points to a specific section ('conclusion'). This constitutes explicit identification. However, it does not specify *how* to make the wording less exaggerated, making it only partially actionable.", "grounding_specificity_rationale": "The comment explicitly mentions the 'conclusion' as the area of concern and identifies a specific phrase ('... our pioneering contributions herald a new era in robotic adaptability ...') as being overly exaggerated. This provides clear grounding. Furthermore, the comment identifies a specific *quality* ('overly exaggerated') as being an issue, making it specific.", "verifiability_rationale": "The comment contains a claim ('wording is overly exaggerated') but does not provide any evidence, reasoning, or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the wording is overly exaggerated. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The comment identifies a stylistic preference ('wording is overly exaggerated') but does not offer any concrete suggestions for improvement or explain *why* this wording is problematic. It is a subjective observation without actionable guidance, making it less helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point contains multiple parts. '11 is wonderful, how about other bit operations?' suggests an extension, which is an implicit action. 'Fig. 5 a seems strange' indicates a need for clarification, which is an implicit action. 'When the input is aer format, how did you deal with DVS input?' is a question seeking more details, implying an implicit action. 'If you can analyze the energy consumption as reference15 did, this paper would be more solid' is a suggestion for improvement, which is an implicit action. While the actions are implied, they lack concrete steps on how to implement them. The lack of explicit instructions makes the actionability somewhat lower.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper. 'Fig. 5 a seems strange' is a general observation about a figure, not a precise reference. The question about 'how did you deal with DVS input' is vague and doesn't point to a specific section or table. The suggestion to 'analyze the energy consumption as reference15 did' is a goaloriented statement but doesn't specify how to achieve it. The lack of explicit references to specific sections, tables, or figures makes the grounding specificity low.", "verifiability_rationale": "The review point contains a claim: 'Fig. 5 a seems strange'. This is an observation or judgment about the paper. The suggestion to 'please give more explanations' implies a lack of clarity and requires justification. The suggestion to 'If you can analyze the energy consumption as reference15 did, this paper would be more solid' is a request for a specific type of analysis, indicating a need for verification. The lack of explicit justification or references makes the verifiability somewhat lower.", "helpfulness_rationale": "The review point raises valid concerns about the scope of the paper, the clarity of Figure 5, the explanation of input handling, and the potential for more rigorous analysis (energy consumption). The suggestions, while not explicitly stated as 'do this', point towards actionable improvements. The reviewer is indicating areas where the authors could enhance their work. However, the lack of explicit instructions and specific requests might make the helpfulness somewhat lower."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that applying multigranularity and multiscale approaches from convolutional networks to MLMs is not an innovative contribution. They further specify that similar information enhancement techniques are already used in object detection, suggesting a lack of novelty. The reviewer identifies the core issue as the lack of a unique or significant advancement in the field of MLMs. This is a clear and direct criticism of the proposed approach, making it 5 for the authors to consider the limitations of their method.", "grounding_specificity_rationale": "The reviewer attempts to ground the criticism by mentioning 'multigranularity and multiscale' and 'convolutional networks' as aspects of the proposed approach. They also mention 'object detection algorithms' as a point of comparison. While the grounding is not perfect, it points to the key features of the approach being criticized. The reviewer also specifies the *nature* of the criticism: the lack of innovation and the similarity to existing techniques in a related field. This adds a degree of specificity to the criticism, indicating a clear understanding of the potential issue.", "verifiability_rationale": "The reviewer presents a claim that migrating multigranularity and multiscale approaches from CNNs to MLMs is not an innovative contribution. This claim is supported by the reviewer's reasoning that similar information enhancement techniques are already used in object detection, and that MLMs can perform object detection tasks. The reviewer uses logical reasoning to connect the capabilities of both approaches. While the reviewer does not provide specific citations, the basis for their claim is grounded in the existing body of work in computer vision. The evidence is present, making the claim verifiable.", "helpfulness_rationale": "The reviewer's point is 5 for the authors as it directly addresses the perceived lack of novelty in their approach. By highlighting the similarity to existing techniques in object detection, the reviewer provides a valuable context for the authors to understand the limitations of their method. This can help the authors focus their efforts on identifying unique contributions or areas where their approach offers specific advantages, even if it's not a fundamentally new concept. The reviewer's suggestion to consider the inherent capabilities of MLMs in object detection also offers a potential direction for improvement."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue (oversmoothing) and offers a suggestion (using perturbed noise for positive samples). However, they don't explicitly state how to investigate or implement the suggestion.", "grounding_specificity_rationale": "The reviewer raises concerns about the method's behavior and its impact on generalization but doesn't specify which part of the model or method is being affected.", "verifiability_rationale": "The reviewer expresses a concern without stating a specific claim or suggestion.", "helpfulness_rationale": "The reviewer raises valid points about the methodology but doesn't offer concrete suggestions or experiments for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a lack of clarity in the main paper but does not explicitly state an action or suggestion for the authors to take. While the issue is stated, the specific steps to address it are missing.", "grounding_specificity_rationale": "The review point refers to 'the main paper' generally and does not specify a particular section, table, figure, or unique element. The issue is broad and not tied to a specific part of the paper.", "verifiability_rationale": "The review point states a fact about the current state of the paper ('The types of situations/social norms... are not clear') but does not provide any external references or logical reasoning to support why this lack of clarity is a problem. It presents a statement without further justification.", "helpfulness_rationale": "The review point identifies a valid issue (lack of clarity) but does not offer any concrete suggestions or explanations for why this lack of clarity is problematic for the reader. It points out a deficiency without providing actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests improvements by adding more baselines and more domains. While these are actionable suggestions, the reviewer does not specify *which* baselines or *how many* domains are needed, making the action somewhat vague. The criticism regarding the weighting and density functions is also general and lacks specific details, further contributing to the vagueness of the action. Therefore, while the reviewer points out areas for improvement, the lack of concrete steps makes the suggestions somewhat vague and general.", "grounding_specificity_rationale": "The reviewer mentions the need for 'more baselines' and 'more domains' but does not specify which particular baselines or domains are lacking. They also criticize the 'weighting' and 'way of learning density functions' without pinpointing the exact issues. The grounding is weak because the reviewer cannot confidently determine which part of their methodology or approach needs improvement. While the suggestions are relevant, the lack of specificity makes it difficult to know exactly what needs to be addressed.", "verifiability_rationale": "The reviewer states, 'As I mentioned, the choices of the weighting and the way of learning density functions are not strongly motivated.' This statement can be considered a claim that requires justification. However, the reviewer does not provide any evidence, examples, or references to support this claim. The reasoning is vague and lacks concrete backing. Therefore, the claim is not wellsupported, making it 1.", "helpfulness_rationale": "The reviewer's comment primarily focuses on the shortcomings of the current work, specifically the lack of strong motivation for the weighting and density functions, and the need for more baselines and domains. While these are valid points, the reviewer does not offer any concrete suggestions or actionable steps to address these issues. The comment is more of a critique than a suggestion for improvement. Therefore, the comment is not particularly helpful in guiding the authors towards better solutions."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the issue with Figure 2 ('the Figure 2 is a little ambiguous...') and points to specific elements within the figure ('some symbols are not explained clearly'). This directly identifies a need for the author to clarify or improve the figure. The reviewer is asking a direct question about the symbols, implying they are unclear. While the reviewer doesn't explicitly state what needs to be done with the symbols, the ambiguity itself is a clear action the author should take. The reviewer is prompting for a solution, making it actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 2' and specifically identifies 'some symbols' as unexplained. This allows the author to directly locate the relevant part of the paper and understand the specific issue. The grounding is strong because the reviewer doesn't need to make any inferences to identify the section or the specific elements.", "verifiability_rationale": "The review point makes a claim about the clarity of Figure 2 ('the Figure 2 is a little ambiguous...') and identifies specific elements within the figure ('some symbols are not explained clearly'). However, the reviewer does not provide any evidence or reasoning to support this claim. They are stating an observation but not providing a logical explanation or reference for it. The claim is present, but the verifiability is low as there's no justification provided.", "helpfulness_rationale": "The review point raises a valid concern about the clarity of Figure 2 and asks a pertinent question about the unexplained symbols. This directly prompts the author to investigate and potentially improve the figure. The reviewer is asking a question that is relevant to the author's work, making it helpful in identifying an area for improvement. However, the review point is primarily a question rather than a direct instruction on how to address the issue, making it less helpful than a directive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation regarding the assumption of a subgaussian kernel spectrum and provides a specific example (Matern kernels) and explains why this assumption is important. This makes the comment actionable for the authors to consider the implications of using Matern kernels or broaden their analysis.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the assumption of a subgaussian kernel spectrum' and then names 'Matern kernels' as an example of a spectrum that does not fit this assumption. This is a clear identification of the specific part of the paper being addressed. Furthermore, the reviewer explains 'this is OK, as the popular Gaussian kernels are in this class' and 'However, another popular class of kernels such as Matern kernels are not included, since their spectrum only decay polynomially'. This clearly specifies what needs to be addressed in this part.", "verifiability_rationale": "The comment contains a claim: 'the authors assume that the spectrum of a kernel is subgaussian'. This claim is supported by logical reasoning: 'This is OK, as the popular Gaussian kernels are in this class'. The reviewer also provides external references (implied by mentioning 'another popular class of kernels such as Matern kernels') and logical arguments ('since their spectrum only decay polynomially'). The connection to the results ('In this sense, the results of the paper could be restrictive') further supports the claim.", "helpfulness_rationale": "The review point identifies a valid limitation in the methodology by pointing out the assumption of a subgaussian kernel spectrum and its implications for the inclusion of other popular kernels like Matern kernels. The reviewer provides a specific example and explains why this assumption is relevant to the results. This information is directly actionable for the authors to consider the limitations of their approach and potentially extend their analysis."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment suggests making the writing easier to follow by simplifying, but it does not specify what needs to be simplified or how. The action is implied but not explicit.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper where the writing is difficult to follow. It is a general statement about the writing quality without pinpointing the location of the issue.", "verifiability_rationale": "The comment does not contain a claim or assertion that requires verification. It is a suggestion for improvement rather than a statement of fact or opinion.", "helpfulness_rationale": "The comment suggests simplifying the writing, which is a valid goal. However, the comment is vague and lacks specific details about what needs simplification, where it needs to happen, or how to do it. This lack of specificity makes it less helpful for the authors to implement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "None", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'The method is only tested on two datasets.' This is a clear statement of a fact, making it partially actionable in the sense that the consequence (limited testing) is stated. However, it doesn't provide concrete steps on how to improve the performance or what specific actions the authors should take. Therefore, it is partially actionable but lacks concrete guidance.", "grounding_specificity_rationale": "The comment states 'The method is only tested on two datasets.' This statement is general and does not explicitly refer to a specific part of the paper or method. While it implies a limitation, the authors cannot confidently determine which specific aspect of the method or experiments is being referred to. Therefore, it is 1.", "verifiability_rationale": "The comment contains a claim: 'The method is only tested on two datasets.' This is a statement of a fact about the experimental setup. However, the comment does not provide any evidence or reasoning to support this claim. It doesn't cite any specific external references or logical reasoning to explain why only two datasets were used. Therefore, the claim is 1.", "helpfulness_rationale": "The comment identifies a potential limitation in the experimental setup (limited testing on two datasets) and asks a relevant question ('Have the authors tried more datasets to get a better idea of the performance?'). This suggests that the reviewer has observed a potential area for improvement and is asking a pertinent question. While it doesn't directly suggest specific improvements, it points towards a direction for the authors to consider. Therefore, it is 3 in highlighting a potential area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly states a problem with Batch Normalization (gradient bias due to minibatch estimation) and contrasts it with Online Normalization (no dependency on batch size). However, it doesn't clearly explain *why* Online Normalization is unbiased while Batch Normalization is biased. The action is implicit \u2013 the reviewer is inferring the difference in bias based on the descriptions.", "grounding_specificity_rationale": "The comment directly references a specific sentence in the paper: \"Batch Normalization has the problem of gradient bias because it uses minibatch to estimate the real gradient distribution. In contrast, Online Normalization can be implemented locally within individual neurons without the dependency on batch size.\" While it targets a concrete part of the paper, it doesn't specify *which* equations or algorithms are affected by the bias.", "verifiability_rationale": "The comment identifies a claim in the paper: \"Online Normalization is unbiased and Batch Normalization is biased.\" However, the reviewer expresses confusion and questions the validity of this claim based on their understanding of the underlying mechanisms. The paper does not provide a detailed explanation or cite external references to support this specific claim about the difference in bias.", "helpfulness_rationale": "The reviewer explicitly states they will 'stay with my original score' and does not provide any additional information or insights based on the comment. The comment itself does not offer a clear explanation or justification for why Online Normalization is unbiased and Batch Normalization is biased."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point directly criticizes a statement about overparametrization and offers a counterargument by suggesting its benefits in supervised learning of deep neural networks. While the criticism is valid in the context of general overfitting, the reviewer provides a specific alternative viewpoint and references theoretical work, indicating an attempt to guide the authors towards a more nuanced understanding. However, the reviewer does not explicitly state what specific changes the authors should make based on this counterargument. The criticism is present, but the explicit action is missing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'overparametrization' and its potential benefits in 'supervised learning of deep neural networks' when critiquing the general statement about overparametrization. This demonstrates a clear identification of the specific area where the original statement might not hold and provides a concrete example, making the grounding very strong. The reviewer does not mention 'external work' in this specific part of the review point.", "verifiability_rationale": "The reviewer provides specific examples, such as 'practical experience' and 'theoretical work', to support their counterargument about the benefits of overparametrization. This demonstrates an attempt to provide evidence and reasoning to support their claim. The evidence is present, but it is not as robust as it could be, lacking specific citations or detailed explanations of the theoretical work.", "helpfulness_rationale": "The review point is highly constructive. It identifies a potential misunderstanding or misapplication of the concept of overparametrization and offers a counterargument with supporting evidence (practical experience and theoretical work). This is very helpful for the authors as it guides them towards a more comprehensive understanding and potential improvements to their models. The reviewer's point is actionable and provides valuable information."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a problem ('experiments are only done on one game environment') but does not specify how to address it. It lacks concrete actions or suggestions for improvement.", "grounding_specificity_rationale": "The comment is too general and does not specify which game environment or aspect of the experimental setup is limited. It lacks a clear reference to a specific part of the paper.", "verifiability_rationale": "The comment points out a valid limitation ('experiments are only done on one game environment') but does not provide any specific evidence, reasoning, or references to support potential solutions or improvements.", "helpfulness_rationale": "The comment identifies a valid weakness ('experiments are only done on one game environment') but does not offer specific, actionable, or wellsupported suggestions for improvement. It lacks constructive guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer clearly states a problem with the assumption that recognition lists are based on justseen items and proposes an alternative scenario involving all items in memory. This suggests a potential action: investigating the implications of the 'old vs. new' distinction on recognition list formation. While the reviewer doesn't explicitly detail the exact action to be taken, the suggestion of testing the alternative model indicates a clear direction for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'recognition lists' and 'old vs. new judgments,' which are relevant concepts. However, they do not explicitly point to a specific section, table, or figure in the paper that discusses these concepts. While the concepts are generally known in the field, the reviewer doesn't provide a precise reference, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer raises a concern about the applicability of a specific model to a common scenario. However, they do not provide any external references or logical reasoning to support their claim that the model is not applicable or that the 'exhaustive list' approach is problematic. The statement is presented as a question and a potential alternative, but without further justification, it lacks verifiable support.", "helpfulness_rationale": "The review points out a potential issue with a commonly used model in a specific context. It highlights a nuance that practitioners might need to consider when applying recognition models. While it doesn't offer a definitive solution, it raises a valid point that can help authors understand the limitations of certain approaches and consider alternative interpretations. It provides a direction for further investigation but doesn't directly solve the problem."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue with the experimental comparison, stating 'As the proposed method was pretrained before the finetuning stage, it is unclear if the compared methods were also initialised with the same (or similar scale) pretrained model.' This suggests an implicit understanding of the proposed method's training process and a question about the compared methods' training details. While the reviewer doesn't explicitly state how to improve the comparison, they imply it's a relevant factor. The reviewer's statement about the performance difference without SSL is also an observation, not an actionable suggestion.", "grounding_specificity_rationale": "The reviewer mentions 'experimental comparison with other methods' and then focuses on 'pretrained model' as the key aspect of the compared methods. While 'experimental comparison' is a general area, 'pretrained model' is a specific element. However, the reviewer doesn't pinpoint *exactly* which pretrained model or its specific details. The focus shifts to the *concept* of pretraining and its potential impact on the comparison's fairness.", "verifiability_rationale": "The reviewer states a potential issue with the experimental comparison and provides a potential reason: 'it is unclear if the compared methods were also initialised with the same (or similar scale) pretrained model.' This constitutes a claim that the comparison might be unfair. The reviewer also observes a performance difference without SSL, which could be seen as supporting evidence for their concern. However, the reviewer doesn't provide direct evidence or citations to support their claim about the pretraining details of the compared methods.", "helpfulness_rationale": "The reviewer raises a valid concern about the fairness of the experimental comparison. By pointing out the potential difference in pretraining, they highlight a potential flaw in the evaluation. While they don't provide a direct solution or specific steps to improve the comparison, their observation is relevant and could prompt further investigation by the authors. The reviewer's mention of the performance difference without SSL adds another layer of concern, suggesting a potential issue with the proposed method's generalizability. This makes the review point 3 in identifying a potential problem."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the metadata used is 'attribute' and suggests exploring 'better metadata embeddings' from a specific paper. This clearly indicates an action  to investigate the impact of using alternative embeddings. The reviewer provides concrete details about the current metadata and the proposed improvement, making the action explicit and concrete.", "grounding_specificity_rationale": "The reviewer refers to 'zeroshot learning on CUB dataset' and specifically mentions 'better metadata embeddings' from a cited paper. This clearly identifies the specific part of the paper and the issue being addressed, making the grounding fully grounded. The reviewer also specifies the type of metadata used ('attribute') and the type of alternative metadata embeddings they suggest, making the grounding highly specific.", "verifiability_rationale": "The reviewer makes a claim about the limitations of using 'attribute' metadata for zeroshot learning and suggests exploring 'better metadata embeddings' based on a reference. This constitutes a claim that needs verification. The reviewer provides a reference to support the suggestion of better embeddings, making the claim verifiable by providing a basis for further investigation.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by suggesting the use of 'better metadata embeddings' and references a paper containing such options. This actionable suggestion directly addresses a potential limitation and is likely to be helpful for the authors. The reviewer also acknowledges the authors' response, indicating a positive reception of the feedback."}
{"actionability_label": "2", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out that the paper does not explicitly state how the number of bins for ECE_sweep is determined, implying it is datadependent. While the reviewer's point is valid and could lead to a concrete action for the authors, the paper does not explicitly state this as a key differentiator or action for the authors. The action is implied but not explicitly stated as a key contribution or actionable step.", "grounding_specificity_rationale": "The reviewer states, 'The nature of the contribution with respect to ECE_sweep is not clearly described in the text.' While the reviewer can infer that the binning method is important, they cannot pinpoint exactly what is being done. The paper mentions the estimator but not the specific binning procedure. The reviewer can make an educated guess but cannot precisely identify the referenced part.", "verifiability_rationale": "The reviewer's point is a claim that the binning method is not fundamentally different. This claim is not supported by any evidence or reasoning within the review itself. The reviewer is making a statement about the method without providing justification or examples.", "helpfulness_rationale": "The reviewer raises a valid concern about the paper's description of the binning process for ECE_sweep. This concern is about the method and could potentially help the authors improve their understanding. However, the reviewer does not provide a concrete solution or a strong argument for why this is not a significant contribution. The reviewer is asking a question that could be answered, making it 3 in terms of prompting clarification."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly suggests an improvement by asking about the variability of results with different random projection matrices. This is a clear and actionable point, directly addressing a potential limitation of the method.", "grounding_specificity_rationale": "The reviewer mentions 'pathological projection matrices' and 'resilience of the metric,' which are specific aspects of the method. They also suggest an experiment ('see resilience') to verify their claim, indicating a clear understanding of what they are referring to.", "verifiability_rationale": "The reviewer makes a claim about the potential lack of resilience of the MFTMA scores to random projection matrices. They propose a concrete experiment ('I might have missed this in the appendix, though') to verify this, demonstrating a logical approach to evaluating the method. The claim is supported by the suggestion of a specific experiment to test the claim.", "helpfulness_rationale": "The reviewer's point is directly relevant to users of the MFTMA method. By asking about the robustness of the scores, they are highlighting a potential limitation and suggesting a way to address it. This provides valuable guidance for ensuring the reliability of the method."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the purpose of the ablation study and the role of FGT evaluation within it. It clearly identifies the action of 'evaluating the method performance in the ablation study' and the tool used 'FGT'. This is an explicit action with no need for inference. The comment is also concrete as it specifies the action and the tool used.", "grounding_specificity_rationale": "The reviewer is commenting on the *purpose* of the FGT evaluation within the ablation study. While the *content* of the FGT evaluation might be grounded (it's a specific metric), the reviewer is criticizing the *motivation* for its inclusion. The reviewer is pointing out that the FGT evaluation is only used for internal validation and not for comparing against other methods. The authors can infer the purpose of the ablation study, but the grounding is in the *motivation* of the ablation study rather than the *content* of the FGT evaluation itself.", "verifiability_rationale": "The reviewer makes a claim about the purpose of the FGT evaluation in the ablation study. The claim is that it is 'only leveraged to evaluate the method performance in the ablation study, which should be used to evaluate the performance of the proposed method and the comparative methods.' The reviewer provides a clear reasoning for this claim, stating that this purpose is 'not used to evaluate the performance of the proposed method and the comparative methods.' This reasoning is logical and directly supports the claim.", "helpfulness_rationale": "The reviewer's comment is critical of the ablation study design. While the criticism is valid, it doesn't directly help the authors improve their *own* draft. The authors are likely looking for feedback on how their method compares to existing methods, not just on the internal validation of FGT. The reviewer is pointing out a potential flaw in the experimental design. While the criticism is valid, it doesn't directly provide actionable feedback for improving the current draft. Therefore, it is not 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the 'winnertakeall property has been widely used in previous works' and that the paper's contribution is 'unclear'. This is an explicit statement of an action: to identify the lack of novelty. The reviewer also mentions specific examples (1 and Sec 5) where similar findings have been reported, which provides concrete details on how to apply the action of identifying the lack of novelty. The reviewer's statement is clear and directly points to a specific area for improvement.", "grounding_specificity_rationale": "The reviewer states that the winnertakeall property has been 'widely used in previous works' and that the paper's contribution is 'unclear'. This statement is not specific to any particular part of the paper. The reviewer does not mention any specific section, table, figure, or unique element of the paper when making this claim. The comment is a general statement about the novelty of the work.", "verifiability_rationale": "The reviewer claims that the winnertakeall property has been 'widely used in previous works' and that the paper's contribution is 'unclear'. This is a claim that requires verification. The reviewer attempts to support this claim by mentioning specific examples (1 and Sec 5) where similar findings have been reported. However, the reviewer does not explicitly state how these prior works relate to the current paper's findings or how the current paper differs. The evidence provided is somewhat vague and lacks a clear connection to the paper's specific claims. Therefore, while the claim is verifiable, the reasoning provided is not entirely clear or robust.", "helpfulness_rationale": "The reviewer states that the winnertakeall property has been 'widely used in previous works' and that the paper's contribution is 'unclear'. This is a claim that the paper does not provide a clear and actionable contribution. The reviewer's point about the lack of novelty makes the feedback less helpful for the authors in terms of guiding them towards a better understanding or method. The paper does not offer a novel perspective or a significant advancement in the field based on the reviewer's assessment."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer is not proposing a new action or suggesting how to implement something. They are asking for clarification or a different perspective on the authors' existing approach. While they imply a desire for improvement, the comment itself doesn't explicitly state a new action to be taken.", "grounding_specificity_rationale": "The reviewer mentions specific terms like 'Witness oracle,' 'polynomial time,' and 'tabular case.' This indicates some level of grounding as they are referencing specific aspects of the authors' work. However, the *purpose* of mentioning these specifics isn't entirely clear. The reviewer is pointing out that the current approach might be overly complex or indirect, but the connection between these terms and the need for clarification isn't explicitly stated.", "verifiability_rationale": "The reviewer is not making a claim that *something is wrong* with the authors' approach. They are asking for clarification or suggesting an alternative. Therefore, this doesn't fit the definition of a claim that requires verification.", "helpfulness_rationale": "The reviewer is directly asking for something \u2013 clarification or a different approach. This provides a benefit to the authors by addressing their confusion and potentially guiding them towards a more efficient or direct solution. The request itself is a form of helpful feedback, indicating a desire for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the 'description of experimental details' needs improvement and suggests making it 'clearer'. This directly tells the authors what to do and how to do it, making it 5. The 'see questions' part further implies the need for clarification, but the core is explicit.", "grounding_specificity_rationale": "The comment refers to 'experimental details' generally, which could be interpreted as implying the lack of clarity relates to the entire experimental section. However, it doesn't explicitly identify a specific part of the paper, table, figure, or unique aspect being addressed. Therefore, it can be considered weakly grounded as it implies the issue but doesn't pinpoint it. It is also somewhat specific in that it points to the clarity of the experimental description, which is a specific area.", "verifiability_rationale": "The comment doesn't make a claim that something is wrong. Instead, it suggests improving clarity. While this is a valid suggestion, the comment itself doesn't present a claim that requires verification. It's more of a constructive suggestion than a definitive statement about a problem.", "helpfulness_rationale": "The comment clearly identifies a weakness ('lacking detail') and provides a concrete suggestion ('increase clarity'). While the suggestion is general, it is a valuable piece of feedback that the authors can readily understand and implement. The 'see questions' part adds a bit of vagueness, but the core is still helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The reviewer states they are 'confused' about the statement in Theorem 5.1. While they identify the theorem as a point of confusion, they don't explicitly state what action they would take based on this confusion. They could potentially ask for clarification, but the comment itself doesn't directly lead to a concrete action.", "grounding_specificity_rationale": "The reviewer mentions 'Theorem 5.1' and compares it to a 'variance regularized problem'. This indicates they have attempted to ground the comment by referencing a specific part of the paper and making a comparison. However, they do not provide specific details about the statement in Theorem 5.1 or the nature of the 'disadvantage' they perceive. The grounding is present but lacks precision.", "verifiability_rationale": "The reviewer's confusion about Theorem 5.1 and its implications for MMD DRO's conservativeness is presented as a deduction or inference. They are inferring a potential disadvantage based on the theorem's statement. While they have attempted to connect the comment to a claim (the potential disadvantage), they haven't provided sufficient evidence or justification for this inference. The verifiability is limited as the connection is based on their interpretation rather than explicit statements within the comment itself.", "helpfulness_rationale": "The reviewer's comment is primarily focused on expressing confusion and interpreting the implications of a theorem. While they identify a relevant aspect (the comparison between MMD DRO and variance regularized problems), they do not provide a clear, actionable suggestion or insight to help the authors understand or address this confusion. The comment is more about interpretation than providing direct assistance, making it less helpful in resolving the reviewer's specific issue."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question about the invariance of morphologic segmentation across domains, which can be interpreted as a request for clarification on a potential limitation or assumption in the paper. While not a direct instruction on how to modify the draft, it points to a specific area needing further explanation. The action is implicit in asking for clarification, and the reviewer does not provide a concrete action on how to address this.", "grounding_specificity_rationale": "This review point does not explicitly mention a specific part of the paper being addressed. The reviewer is making a general point about a methodological choice (morphologic segmentation) and its applicability across domains. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are asking a question about a methodological choice, not making a statement that needs to be supported by evidence or reasoning. Therefore, there is X to evaluate for verifiability.", "helpfulness_rationale": "The reviewer's question directly addresses a potential point of confusion for the authors regarding the paper's methodology. It seeks clarification on a specific aspect of morphologic segmentation and its relevance to domain adaptation. This question is relevant and seeks to improve the authors' understanding, making it 3 in guiding their work. While it doesn't offer a direct solution, it identifies a gap in the authors' understanding, which the authors can then pursue."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the *lack* of discussion about a specific related work (Set Transformer) and a category of related works (other works using summary tokens). While it doesn't provide explicit instructions on *how* to address this, the action is implied: 'Go back to the related work section and discuss Set Transformer and similar methods.'", "grounding_specificity_rationale": "The comment explicitly mentions 'Set Transformer' by name, which is a specific section or category within the paper. It also identifies 'other related works that also uses summary tokens' as a specific type of missing work. This strong identification of specific parts and issues demonstrates full grounding.", "verifiability_rationale": "The comment presents a claim that 'the paper should discuss Set Transformer... and other related works that also uses summary tokens' as a necessary improvement. However, it does not provide explicit justification or reasoning for why this discussion is needed or what specific aspects should be covered. It lacks concrete examples or references to support the claim beyond stating the absence of the discussion.", "helpfulness_rationale": "The comment identifies a specific gap in the related work section, which is a relevant and actionable piece of feedback for the authors. It guides them towards discussing a specific type of related work. While it doesn't provide detailed suggestions on *how* to discuss these works, it clearly points to an area for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks 'did you do any statistical significance test?' which is a direct question about a methodological choice. This makes the action somewhat explicit  the reviewer is asking about a specific action (performing a statistical significance test). However, the action itself is vague because the reviewer doesn't specify which test was used, how it was implemented, or if any was actually performed. The lack of detail makes the action only 3.", "grounding_specificity_rationale": "The review point is a general question about statistical significance testing in the context of comparing proposed methods with baselines. The reviewer is not pointing to a specific section, table, or figure in the paper where this issue arises. While the topic is relevant to the paper's content, the question is not specifically addressing a unique element or a particular part of the paper. Therefore, it is not strongly grounded. However, the topic of statistical significance is somewhat specific to research in this domain.", "verifiability_rationale": "The review point is a question, not a statement of a claim or opinion. Questions, by their nature, do not contain verifiable information in the same way a statement of critique or a request for justification would. The reviewer is asking for information (whether a statistical significance test was done), not making a claim that needs verification. Therefore, it is 1.", "helpfulness_rationale": "The review point is a question about a standard practice in research. While it might be helpful to remind the authors about the importance of statistical significance testing, the review itself does not provide specific, actionable feedback on how to improve the draft. It's more of a reminder or a point for discussion rather than a constructive critique that directly guides the authors towards a better version of their work. Therefore, it is 3 in prompting awareness but lacks the direct critique or actionable suggestion that would be 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment suggests using a paired test because the data comes from the same input, implying a dependency between the samples. While it points out a potential improvement, it doesn't explicitly state how to implement this change or what specific actions need to be taken in the code or analysis. The suggestion is clear and actionable in identifying a potential issue with the current approach (independent samples ttest).", "grounding_specificity_rationale": "The comment explicitly mentions 'two samples generated from the same input' when suggesting a paired test. This directly identifies the specific part of the analysis where the issue lies and provides a clear context for the recommendation. The grounding is strong as the comment accurately pinpoints the relevant comparison.", "verifiability_rationale": "The comment suggests a paired test because the data comes from the same input, implying a dependency between the samples. This is a generally accepted statistical principle. While it doesn't provide a specific reference or example, the reasoning is based on established knowledge. The comment doesn't present a claim that requires external verification but rather points out a potential improvement based on statistical principles.", "helpfulness_rationale": "The comment highlights a potential issue in the presentation of the statistical analysis (using an independent samples ttest when a paired test might be more appropriate given the data structure). It encourages the authors to reconsider their analysis approach. While it doesn't provide a definitive solution, it points out a potential area for improvement that the authors could consider. The suggestion is 3 in prompting them to think critically about their statistical methods."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer's statement is explicit and concrete. They directly state the result of replacing procedure steps with a random mechanism, and specify which procedure steps were replaced.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'XAIFOOLER' and the specific change being tested: 'replacing any of the procedure steps'. This is a clear reference to a specific part of the paper. They also specify 'a random mechanism' as the alternative.", "verifiability_rationale": "The reviewer makes a claim: 'I'm unsure that 'better than random' is a strong demonstration of capability.' However, they do not provide any specific evidence or reasoning to support this claim. There are no logical arguments, references to external work, or examples provided to back up their assertion.", "helpfulness_rationale": "The reviewer's review point primarily raises a concern about the methodology. While they identify a potential issue, they do not offer specific suggestions or actionable steps for the authors to improve their algorithm. The point is more about questioning the significance of the result rather than providing a constructive solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the desired actions: 'give more background knowledge' and 'bring the description of the relate literatures forward'. However, the reviewer does not specify how these actions should be implemented.", "grounding_specificity_rationale": "The reviewer mentions 'background knowledge' and 'related literatures,' indicating they understand the need for this information. However, they do not specify which particular background knowledge or which specific related literature they are referring to.", "verifiability_rationale": "The reviewer states a potential improvement ('The organization of this paper could be further improved') and suggests actions ('such as give more background knowledge of the proposed method and bring the description of the relate literatures forward'). However, the reviewer does not provide any justification or reasoning for why the current organization is problematic or why the suggested actions will solve the issues.", "helpfulness_rationale": "The reviewer identifies a weakness ('the organization of this paper could be further improved') and suggests improvements ('such as give more background knowledge of the proposed method and bring the description of the relate literatures forward'). While the suggestions are present, the reviewer does not explain the specific problems with the current organization or how the proposed changes will address those problems."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment suggests adding comparisons with specific models, which can be interpreted as an implicit suggestion to improve the experimental evaluation. However, the action of adding these comparisons is not explicitly stated, making it somewhat vague. The reviewer is pointing towards a potential improvement but doesn't directly tell the authors *how* to add these comparisons or where to add them.", "grounding_specificity_rationale": "The comment suggests comparing with 'other representative panoptic segmentation models' and mentions specific examples like 'PanopticFPN' and 'Mask2Former'. This grounds the suggestion to a specific area within the field of segmentation models. The comment also implies a potential weakness in the experimental evaluation by suggesting these comparisons. The specificity is good as it points to concrete models, but the *where* of the comparison within the paper is not explicitly stated.", "verifiability_rationale": "The comment presents a suggestion to include more comparisons, which can be considered a claim that the current evaluation is incomplete. The suggestion itself is a form of justification or reasoning for why more comparisons are needed. The evidence for verifiability is moderate. The suggestion is logical and based on common practices in experimental evaluation, but it doesn't provide specific references or examples of where these comparisons should be made within the paper.", "helpfulness_rationale": "The review point directly addresses a potential weakness in the experimental evaluation \u2013 the lack of comparison with specific stateoftheart panoptic segmentation models. By suggesting these comparisons, the reviewer provides a clear direction for the authors to improve their work. The suggestion is actionable, prompting the authors to expand their experimental evaluation. The reviewer is implying that the current set of comparisons is insufficient for a thorough analysis of the proposed method."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states \"I was all excited to see how the authors managed to get the diversity term into their model and got disappointed when I learned that there is no diversity.\" This clearly indicates an implicitly stated action: the reviewer expects explicit diversity enforcement and points out the absence of it. The action is to implement diversity enforcement.", "grounding_specificity_rationale": "The reviewer mentions \"the diversity term in the title\" and \"the model does not enforce diversity explicitly.\" This directly refers to a specific aspect of the paper and model, indicating full grounding. The reviewer is not making a general comment about the paper's motivation but rather a specific observation about the model's implementation.", "verifiability_rationale": "The reviewer states a claim: \"the model does not enforce diversity explicitly.\" While this is a factual observation, the reviewer infers this lack of explicit diversity based on their experience or understanding of the model's components. There is no direct evidence or citation provided to support this claim, making it somewhat inferable.", "helpfulness_rationale": "The reviewer's comment directly points to a significant discrepancy between the paper's stated motivation (extensive motivation of diversity) and the actual implementation (lack of explicit diversity enforcement). This is a concrete and actionable feedback that directly addresses a core aspect of the work, making it 5 for the authors to understand and improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3: 2", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment identifies a weakness ('some experiments are missing') but does not specify *how* to address it. It lacks concrete instructions or actions for the authors. The examples provided are suggestions for improvement rather than explicit actions to take.", "grounding_specificity_rationale": "The comment mentions 'experiments' generally and then provides examples of missing experiments (contrastive and adversarial learning). While it hints at the *type* of experiment missing, it doesn't pinpoint a *specific* missing element within the paper's current experimental section. It's more about the *category* of experiments missing rather than a precise reference to a specific part of the paper.", "verifiability_rationale": "The comment makes a claim ('some experiments are missing') and provides examples as justification. The examples act as evidence supporting the suggestion to include these types of experiments. The claim is supported by logical reasoning and examples.", "helpfulness_rationale": "The comment identifies a valid weakness ('some experiments are missing') and provides a clear suggestion for improvement (including these types of experiments). It doesn't criticize the style or content of other sections, which could be helpful in a different context. The suggestion is direct and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the alternative (inverse triples) and the reason for considering it (CP besides CP). However, the reviewer does not specify how this alternative would be implemented or what specific steps would be taken to test it. The action is present, but the details are lacking.", "grounding_specificity_rationale": "The reviewer mentions 'inverse triples' as a specific concept and 'CP' as a general category. While 'inverse triples' is relatively specific, 'CP' is vague. The reviewer could have been more specific about the type of CP they were referring to. However, the reviewer does identify a specific area of the paper (CP) that is being discussed in relation to the alternative.", "verifiability_rationale": "The reviewer poses a question about why the authors didn't test the alternative (inverse triples). This constitutes a claim. However, the reviewer does not provide any logical reasoning, examples, or external references to support why the authors might have overlooked this. The claim is present, but it lacks justification.", "helpfulness_rationale": "The reviewer asks a question about why the authors didn't test the alternative. While this is a valid point for prompting further investigation, it does not directly instruct the authors on how to improve their draft. The reviewer is not providing actionable advice, but rather a diagnostic question."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'I agree the efficiency could be improved since the FLOP is quadratic on activation side length. But in terms of parameters, more details are expected'. This is a direct and actionable suggestion for the authors to clarify the parameter behavior in the S2D structure. The reviewer identifies a specific area of concern and proposes a concrete step to address it by seeking more details.", "grounding_specificity_rationale": "The reviewer refers to 'S2D structure' and 'number of parameters' as the specific area of concern. While they don't provide a specific section number, the concept is quite localized. The reviewer clearly identifies the issue and the specific aspect within that area that needs clarification. The reviewer is confident in the specific part they are addressing.", "verifiability_rationale": "The reviewer makes a claim: 'the number of parameters does not change' in the context of the S2D structure. They then provide a logical reasoning: 'If the kernel height/width stay the same, then its depth will increase, resulting in more parameters.' This reasoning is sound and provides a clear justification for why the reviewer expects a change in the number of parameters. They also suggest a solution ('more details are expected') which implies a verification gap. The claim is wellsupported by logical reasoning.", "helpfulness_rationale": "The reviewer raises a valid point about a potential inconsistency in the description of the S2D structure. They are likely experiencing confusion or uncertainty about how parameters behave. By pointing out this potential issue and requesting more details, the reviewer is directly addressing a likely area of uncertainty for the authors and encouraging them to seek clarification. This is a helpful comment that prompts further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation in the experimental setup (single game, single baseline) and its impact on interpretability. While they identify the *what* (limitation, interpretability issue), they don't explicitly state the *how* to address this. The action is implied but not directly stated, making it less actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 7.2 (Atari game result)' as the area being discussed, which constitutes 'Full Grounding'. They also specify the limitations as 'a single game' and 'a single baseline', providing further detail within that section, indicating 'Specificity'.", "verifiability_rationale": "The reviewer states that the 'Atari game result is limited to a single game and a single baseline. It is very hard to interpret this.' This constitutes a 'Claim' as it expresses an opinion or judgment about the interpretability of the results. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The verifiability is based on the reviewer's assertion without further justification.", "helpfulness_rationale": "The reviewer identifies a clear weakness in the experimental design (limited scope) and points out its negative consequence ( difficulty in interpretation). While they highlight a problem, they do not offer any suggestions or guidance on how to improve the experiment. The feedback is diagnostic but lacks constructive solutions, making it less helpful for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests 'I might be helpful to quantify and clarify the claim' as a potential improvement. While this suggests an actionable step (quantifying), the initial statement 'ReLU does not work very well in very deep or in convolutional networks' is not explicitly stated as an action to be taken. The reviewer is pointing out a potential area for improvement, but the action itself is not clearly defined. Therefore, it is not fully actionable.", "grounding_specificity_rationale": "The reviewer states 'ReLU does not work very well in very deep or in convolutional networks.' This statement identifies a potential issue but does not explicitly point to a specific section, table, figure, or unique aspect of the paper. While the connection to the AlexNet paper is implied, it is not explicitly mentioned as the basis for this statement. Therefore, the grounding is weak. The claim 'ReLU was used in the AlexNet paper which, at the time, was considered deep and makes use of convolution (with pooling rather than ReLUs for the convolutional layers)' attempts to ground the statement but is not clearly linked to the specific part being addressed.", "verifiability_rationale": "The reviewer makes the claim 'ReLU does not work very well in very deep or in convolutional networks.' This is a statement of opinion or judgment about ReLU's performance. The reviewer attempts to verify this claim by stating 'ReLU was used in the AlexNet paper which, at the time, was considered deep and makes use of convolution (with pooling rather than ReLUs for the convolutional layers).' While this provides a counterexample and attempts to support the claim, the explanation is somewhat vague (distinguishing between ReLU and pooling could be clearer). The claim is presented and some evidence is given, but the reasoning could be more robust. Therefore, it is partially verifiable.", "helpfulness_rationale": "The reviewer's point is relevant to understanding the limitations of ReLU and potentially improving network design. They suggest 'quantify and clarify the claim' as a potential improvement. This is a helpful suggestion as it provides a direction for further investigation and analysis. However, the suggestion itself is somewhat vague and does not provide specific steps on how to quantify or clarify the claim. Therefore, the helpfulness is somewhat limited."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the hyperparameters k and \u03b7 require finetuning. This directly implies an action the authors should take, making it at least 3. However, the comment does not specify how to perform this finetuning, making it vague on the 'how'.", "grounding_specificity_rationale": "The comment does not specify which environment or which good OPE method is required for the finetuning of k and \u03b7. It is a general statement about a dependency without identifying a specific part of the paper or providing details about the finetuning process. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The comment contains a claim that introducing k and \u03b7 introduces a dependency on environment availability or a good OPE method. However, the comment does not provide any evidence, justification, or references to support this claim. It is presented as a statement of a practical limitation without any logical reasoning or external references.", "helpfulness_rationale": "The comment identifies a practical limitation of the method, specifically the dependency on environment availability or a good OPE method for finetuning the hyperparameters. While this highlights a problem, it does not offer any suggestions or guidance on how to overcome this limitation. Therefore, it is helpful in pointing out a problem but does not provide actionable improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'I don't understand Figure 5' and 'labels are wrong'. This indicates a clear and actionable suggestion for the authors to improve their understanding of the figure. The action is concrete as the authors can directly identify the issue  the labels are incorrect.", "grounding_specificity_rationale": "The reviewer states 'I don't understand Figure 5' which is a general statement and does not identify a specific part of the paper being addressed. While the reviewer later mentions 'labels are wrong', this is an inference on their part, as the reviewer doesn't specify *which* label is incorrect or *what* aspect of the figure is unclear. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer states a fact: 'either I don't understand Figure 5 or the labels are wrong'. There is X being made or supported by evidence. The statement is a description of a potential issue.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'fix the labels'. This directly helps the authors improve their understanding of the figure and is a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states that 'Performance differences between methods are minimal' and offers a potential explanation 'less than 1 percentage point'. While this points to a *difference* in performance, it doesn't explicitly recommend a specific action or provide a concrete next step for the authors. The reviewer suggests 'reconsidering the benchmarks', which is an implicit action, but it's not a detailed, actionable suggestion. Therefore, while the point identifies a potential issue, it lacks a clear, direct recommendation for improvement.", "grounding_specificity_rationale": "The review point refers to 'Performance differences between methods' and 'benchmarks selected'. While it mentions these aspects, it does not explicitly identify a specific part of the paper being addressed. The reviewer is commenting on the *results* of the methods and the *benchmarks used*, but they are not pinpointing a specific table, figure, or section within the paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point makes a claim about the 'Performance differences between methods are minimal'. It also provides a potential explanation, 'less than 1 percentage point', and suggests that the 'benchmarks selected are outdated and likely saturated'. While the claim is stated, the verifiability is limited. The explanation and suggestions are general and do not provide specific references, examples, or external evidence to support the claim. Therefore, the claim is 3 but lacks key elements like examples or references.", "helpfulness_rationale": "The review point raises a valid concern about the minimal performance differences and suggests considering 'outdated and likely saturated benchmarks'. While it doesn't offer a direct solution to the problem, it points to a potential limitation in the evaluation and provides a direction for further investigation. It highlights a potential area for the authors to reconsider their evaluation setup. Therefore, the review point is 3 in guiding the authors to consider the limitations of their evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the lack of interpretive insights and the lack of comparison with stateoftheart methods not based on gyrostructures. This directly points to actionable improvements for the authors. However, it doesn't specify *how* to interpret the results or *how* to expand the comparisons, making it somewhat vague in its implementation.", "grounding_specificity_rationale": "The review mentions 'the experiments part,' 'related discussion,' 'SPDbased models,' 'gyrostructurebased approaches,' and 'stateoftheart methods.' While it doesn't pinpoint a specific table or figure, it clearly refers to different types of experiments and discussions, indicating weak grounding. It also points out missing comparisons but doesn't specify what those comparisons should be, making it underspecific.", "verifiability_rationale": "The review states that the related discussion lacks interpretive insights and that there's a lack of comparison with other stateoftheart methods. This constitutes a claim that needs to be supported. However, the review doesn't provide any logical reasoning, examples, or external references to back up these claims. It simply states the absence of these elements without explaining *why* or providing *evidence*.", "helpfulness_rationale": "The review identifies specific areas for improvement in the paper, such as adding interpretive insights to the discussion and including comparisons with a broader range of stateoftheart methods. This directly suggests concrete actions the authors can take to enhance their work. While it doesn't provide detailed instructions on *how* to perform these actions, it clearly points out shortcomings and encourages improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the concern about regularization and the lack of ablation studies. This is an *explicit* action. However, the reviewer doesn't specify *how* to perform ablation studies or other regularization techniques, making the action *vague*. Therefore, the comment is explicitly stated but lacks concrete details on how to apply the suggested actions.", "grounding_specificity_rationale": "The reviewer refers to concepts like 'distillation,' 'regularization,' 'finetuning,' 'epochs,' and 'earlystopping.' While not a direct reference to a specific section, table, or figure, the reviewer clearly implies the relevance of these concepts to the experimental setup and methodology. This indicates a lack of precise identification of the *part* of the paper being addressed. However, the reviewer *clearly specifies* the potential issue: 'the lack of ablation studies.' This specificity points to a clear weakness in the experimental design. Therefore, the comment is not *fully grounded* but clearly *specific* about the identified weakness.", "verifiability_rationale": "The reviewer makes a claim: 'The finetuning on GLUE without validation earlystopping usually has very high variances, proper ablation studies are needed to verify.' This claim is supported by logical reasoning ('GLUE finetuning without validation usually has high variances') and provides a clear suggestion ('proper ablation studies are needed'). Therefore, the claim is wellsupported and verifiable.", "helpfulness_rationale": "The reviewer identifies a potential flaw in the methodology (the possibility of regularization effects due to the finetuning setup) and provides a concrete suggestion (conducting ablation studies). This actionable feedback directly addresses a potential weakness in the experimental design and guides the authors on how to improve their work. The reviewer's comment is highly specific and directly relevant to the described methodology and experimental setup. Therefore, the review point is 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the absence of 'little insights' regarding the necessity of selfsupervised learning on this specific data. While it identifies a gap, it doesn't provide a concrete action or suggestion on how to address this lack of understanding. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The review point mentions 'selfsupervised learning on 360 video data which have spatial audio'. This provides a specific context, thus grounding the comment. However, the comment focuses on the *lack of insights* rather than specifying what needs to be improved or addressed within this context. The grounding is present, but the specificity of the suggestion is lacking.", "verifiability_rationale": "The review point contains a claim: 'little insights are given about why do we need to do selfsupervised learning on this kind of data.' This is a statement of what the paper lacks. However, the review point does not provide any logical reasoning, common knowledge, or external references to support this claim. It simply states the absence of information.", "helpfulness_rationale": "The review point identifies a weakness in the paper: the lack of justification for applying selfsupervised learning to this specific type of data. While it highlights a problem, it does not offer any concrete suggestions or actions for the authors to take to address this weakness. It points out a gap in the reasoning rather than providing a solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'there is no analysis on a seemingly important (see SimCLRv2 and other recent papers that show that) part of that approach, ie the projection head.' This clearly identifies an action the authors should take: analyze the projection head. The phrasing 'ie the projection head' indicates a direct action to be taken. The reviewer also provides a reason for why this is important ('given recent work suggesting its importance'), which further clarifies the action.", "grounding_specificity_rationale": "The reviewer explicitly names 'the projection head' as the missing part of the SimCLR analysis. This is a clear and specific reference to a component of the method. The reviewer also explains *why* this is important by referencing 'recent papers' and the general understanding of its role in representation learning. This provides a clear indication of what needs to be addressed.", "verifiability_rationale": "The reviewer makes a claim: 'only the SimCLR case is covered and yet, there is no analysis on a seemingly important (see SimCLRv2 and other recent papers that show that) part of that approach, ie the projection head.' This is a clear statement of a deficiency. The reviewer provides a justification for this claim by stating 'given recent work suggesting its importance.' While the specific papers are not named, the general idea of their importance provides some level of support. The reviewer is making a logical argument based on common knowledge in the field.", "helpfulness_rationale": "The reviewer clearly identifies a gap in the analysis of a specific component of the SimCLR method and provides a reason for its importance. This directly informs the authors to investigate the projection head, which is a concrete and actionable step for them. The reviewer's statement is a clear and specific piece of feedback that the authors can directly use to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the *lack* of *necessary* experiments, implying an action: the authors should conduct these experiments. However, the specific *action* of *how* to conduct them is not detailed, making it somewhat vague. The *types* of experiments (comparison, ablation, hyperparameter) are mentioned, making the explicit part concrete. The implicit part is the action of conducting these experiments.", "grounding_specificity_rationale": "The comment states the *lack* of *additional necessary experiments* but does not specify *which* part of the paper needs these experiments. It does not mention any specific sections, tables, figures, or unique aspects of the paper where these experiments are needed. The comment focuses on the *type* of experiments needed, not the location within the paper. The comment also does not detail *what* is missing in these experiments (e.g., specific datasets, baselines, hyperparameter ranges).", "verifiability_rationale": "The comment contains a claim: 'The paper lacks additional necessary experiments...'. However, it does not provide any specific examples, references, or logical reasoning to support this claim. It states a problem without providing evidence or justification.", "helpfulness_rationale": "The comment identifies a significant omission in the experimental evaluation, specifically the lack of comparison, ablation, and hyperparameter analysis. This is a clear indication of a weakness in the current work and provides a concrete direction for improvement. While it doesn't explicitly tell the authors *how* to conduct these experiments, it highlights a necessary step they should take. This makes it a valuable piece of feedback for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point clearly identifies a weakness in the regularization term (lack of theoretical support) and suggests alternatives (median). It also proposes improvements (using other statistics). This provides explicit and actionable feedback for the authors.", "grounding_specificity_rationale": "The reviewer refers to 'the regularization term' generally, which is a weak grounding. While they mention 'mean and standard derivation', they don't specify which part of the regularization or the method they are referring to. The grounding is not precise enough to pinpoint the exact issue.", "verifiability_rationale": "The reviewer claims a lack of theoretical support for the regularization term and provides an intuitive explanation. While this is a valid concern, the verifiability is somewhat limited as the reviewer doesn't provide specific references or logical reasoning to support their claim within the review itself. The intuitive explanation is not a strong form of justification.", "helpfulness_rationale": "The review points out a significant weakness in the methodology (lack of theoretical grounding) and offers concrete suggestions for improvement (using alternatives like the median). This directly helps the authors identify areas for enhancement in their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'add a discussion of the iteration cost (computational budget) of the proposed method'. However, it does not provide concrete details on *how* to implement this discussion. The action is stated, but the execution is vague.", "grounding_specificity_rationale": "The comment explicitly mentions 'the proposed method' and 'related methods including baseline methods'. This clearly identifies the specific parts of the paper being addressed, demonstrating strong grounding specificity.", "verifiability_rationale": "The comment presents a suggestion: 'It will be great if the authors discuss the iteration cost of all related methods including baseline methods.' This is a suggestion, not a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support this suggestion.", "helpfulness_rationale": "The review point identifies a relevant area for improvement by highlighting the importance of discussing iteration costs. It encourages the authors to include this analysis, which is a standard practice in computational methods. While it doesn't provide specific guidance on *how* to analyze the cost, it points to a missing element and suggests a direction for improvement. Therefore, it is helpful in guiding the authors towards a more complete analysis."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the paper's method of VAD implementation: 'what is stated in the paper simply discards any TF bins that have a magnitude of less than epsilon'. This directly identifies an action the paper takes. The reviewer then contrasts this with the expected behavior of a VAD, which should look for speech presence over time and handle zeromagnitude bins differently. This provides a clear action for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly names the paper they are referring to: 'Your VAD description is puzzling. What is stated in the paper simply discards any TF bins that have a magnitude of less than epsilon'. This is strong grounding. Furthermore, the reviewer describes *how* the VAD is implemented in the paper (discarding TF bins), which is highly specific.", "verifiability_rationale": "The reviewer makes a claim: 'what is stated in the paper simply discards any TF bins that have a magnitude of less than epsilon'. This is a claim that needs verification. The reviewer then provides a detailed explanation of what the paper *should* do for a proper VAD (look for speech presence over time and handle zeromagnitude bins differently). This logical reasoning and explanation support the claim that the paper's method is not a true VAD. The reviewer also points out common issues with VAD, further supporting their critique. Therefore, the claim is wellsupported.", "helpfulness_rationale": "The reviewer provides a direct critique of the paper's VAD implementation. They explain *why* the paper's method is problematic (simply discarding bins vs. looking for speech presence). They also offer alternative approaches (looking for the presence of speech, not just energy, over time). This critique is actionable and provides valuable guidance for the authors to improve their draft. The reviewer is not just pointing out a problem; they are also providing context and potential solutions."}
{"actionability_label": "5", "grounding_specificity_label": "1 and Specific", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests a concrete action: \"run experiments on ImageNet\". This is a clear instruction for the authors to take. Therefore, it is 5.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or table it is referring to. It simply suggests using \"ImageNet\" generally. While it points to a *general* area of improvement, it doesn't specify *which* section, table, or figure is lacking. Therefore, it is 1.", "verifiability_rationale": "The review point is a suggestion or recommendation, not a claim that something is wrong or needs to be improved. It doesn't make a judgment about the current results being \"unconvincing\". Therefore, it doesn't contain a claim that can be verified.", "helpfulness_rationale": "The review point suggests a concrete and actionable improvement: \"run experiments on ImageNet\". This is a valuable suggestion for the authors to consider and could significantly strengthen their paper. While it doesn't directly address a specific flaw, it provides a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point primarily criticizes the novelty and significance of the findings rather than providing explicit instructions on how to improve the model. The reviewer states, 'In general, the authors studied the connection between the complementary and the model robustness but without further studies on how to leverage such characteristics to improve model robustness.' This indicates a lack of actionable insights. While the reviewer identifies a potential area for improvement, they do not offer concrete steps or methodologies for achieving this. The focus is on the *what* (the connection exists) and the *why* (it's intuitively obvious), but not on the *how* to leverage it. Therefore, the comment lacks explicit and detailed guidance on how to apply the findings.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly tied to a specific section, table, figure, or unique aspect of the paper. While the comment generally refers to the 'connection between the complementary and the model robustness,' it does not pinpoint where this connection is discussed within the paper. The reviewer's statement is a general critique of the findings rather than a specific suggestion related to a particular part of the work. Therefore, the grounding is weak as the comment does not clearly identify the referenced part.", "verifiability_rationale": "The reviewer makes a claim by stating, 'Even though this paper could be the first work to study this connection, the conclusion could be easily and intuitively obtained, i.e., when multimodal complementary is higher, the robustness is more delicate when one of the modalities is corrupted.' This claim is supported by logical reasoning and common knowledge, although the reviewer also expresses a belief that the conclusion is 'easily and intuitively obtained.' While the reviewer provides a logical explanation, the lack of specific examples or references weakens the verifiability. The claim is based on a logical deduction rather than a rigorous verification.", "helpfulness_rationale": "The reviewer's concern about the lack of actionable insights makes the comment 3 in identifying a potential area for improvement. However, the comment does not provide concrete steps or methodologies for achieving this. The reviewer expresses a concern about the lack of actionable insights, suggesting the feedback is somewhat limited. While the comment points out a potential weakness in the paper's analysis, it does not offer a clear path forward for the authors to address this weakness. The comment is more of a critique of the findings than a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of a strong connection between the theoretical analysis (PACBayesian bounds) and the proposed method (selfattention mechanism). They also explicitly point out that the proposed method seems to simply adopt the idea of selfattention from transformers and apply it to graphs, without clearly explaining how it enhances generalization for distant nodes. While the reviewer identifies a gap, the action of pointing this out is somewhat implicit rather than directly suggesting a solution or providing a concrete stepbystep improvement.", "grounding_specificity_rationale": "The reviewer's comment does not identify a specific part of the paper being addressed. They are making a general criticism about the connection between the theoretical analysis and the proposed method, as well as the effectiveness of the method for distant nodes. There is no specific section, table, figure, or unique element of the paper that the reviewer is referring to.", "verifiability_rationale": "The reviewer's comment contains a claim (the criticism of the connection and the lack of clarity on distant node generalization). However, the reasoning provided is a general assessment of the method's effectiveness without specific examples or references to external works. The claim is not fully supported by explicit, sufficient, and robust evidence.", "helpfulness_rationale": "The reviewer's comment is clear and identifies a significant gap in the paper's explanation. They highlight a lack of connection between theory and method and the unclear mechanism for enhancing generalization for distant nodes. While the criticism is valuable in pointing out a weakness, it doesn't directly propose a solution or offer actionable steps for improvement within the review point itself."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly identifies a factual error in the authors' description of the IOI circuit. They state that the Induction, Duplicate Token, and Previous Token heads do not *primarily* attend to the S2 token, contradicting the authors' claim. Furthermore, the reviewer provides a clear alternative explanation based on external knowledge (Wang et al., 2023), stating that these heads are *active* at the S2 token. This allows the authors to directly address the error and update their description. The reviewer's statement is a clear and direct action for the authors to take: revise their description of the IOI circuit with the correct understanding.", "grounding_specificity_rationale": "The reviewer explicitly names the 'IOI circuit' and the specific components 'Induction, Duplicate Token, and Previous Token heads' as being related to the 'S2 token'. They also point to 'Section 3 of Wang et al., 2023' as a source of information to clarify the misunderstanding. This demonstrates high grounding specificity as the reviewer not only identifies the relevant part of the paper but also provides a specific reference to support their claim.", "verifiability_rationale": "The reviewer provides a clear explanation of why the authors' understanding of the IOI circuit is incorrect. They state that the heads are 'active' at the S2 token, not 'primarily' attending to it. This explanation is supported by external knowledge (Wang et al., 2023), making the claim 5. The reviewer's reasoning is logical and provides a concrete alternative understanding.", "helpfulness_rationale": "This review point is 5. The reviewer explicitly identifies a factual error in the authors' description of the IOI circuit and provides a clear alternative explanation based on external knowledge. The reviewer not only points out the discrepancy but also guides the authors towards the correct understanding by mentioning the concept of 'activity' at the S2 token. This information empowers the authors to directly address the error and improve their draft. The reviewer's comment is specific, actionable, and wellsupported."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states their uncertainty about why eta_ri is a noncentral chisquared distribution, indicating an implicit action. While they don't demand a specific fix, they want the paper to clarify this point, which is a concrete action once the explanation is provided.", "grounding_specificity_rationale": "The reviewer directly addresses a specific element of the paper, the eta_ri term, and asks a question directly related to it. This indicates strong grounding as the reviewer can accurately pinpoint the referenced part. The comment specifies what needs to be addressed in this part (the distribution).", "verifiability_rationale": "The reviewer points out a lack of explanation within the paper regarding the distribution of eta_ri. They are not claiming the paper is incorrect, but rather that it lacks sufficient justification for a stated fact. This makes the claim somewhat underspecific as the paper doesn't provide the reasoning. The comment requires the reader to infer the reason.", "helpfulness_rationale": "The reviewer's request for clarification is a common and generally helpful type of feedback. It highlights a potential area where the paper could be improved for better understanding."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the lack of speed analysis and provides a concrete suggestion to compare FLOPs, which is a direct and actionable improvement for the authors.", "grounding_specificity_rationale": "The comment explicitly mentions 'lack of speed analysis' and suggests comparing 'FLOPs of different segmentation networks,' which directly identifies the specific part of the paper and the issue within it.", "verifiability_rationale": "The comment contains a claim (lack of speed analysis) and provides a logical reasoning (FLOPs comparison is more interesting) to support it, making it verifiable.", "helpfulness_rationale": "The comment is 5, clearly identifies a missing element, and provides a concrete suggestion for improvement, making it 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the proposed method is not wellpositioned in literature and points to specific mathematical concepts (expectation of scores conditioned on inputs) that are known from existing works like denoising score matching and scoreinterpolation. This directly identifies an area for improvement and provides a concrete direction for the authors to explore. The reviewer's suggestion to point out these connections is a clear action to be taken.", "grounding_specificity_rationale": "The reviewer suggests pointing out the connection between the proposed method and existing objectives like denoising score matching and scoreinterpolation. While the reviewer doesn't explicitly state which section or part of the paper this refers to, the implication is clear that this connection is relevant to the overall work. The reviewer also specifies the mathematical formulation and the existing concepts it relates to, making the grounding somewhat specific. However, the exact location isn't pinpointed, making it 'Weakly Grounded'.", "verifiability_rationale": "The reviewer makes a claim that the key idea of representing the marginal score as the expectation of scores conditioned on inputs is wellknown and provides specific examples (denoising score matching, scoreinterpolation). This claim is supported by the reviewer's knowledge and the logical connection between the described mathematical formulation and existing literature. The reviewer also suggests a specific action (thorough literature review), which provides further justification for the claim.", "helpfulness_rationale": "The reviewer provides specific suggestions for the authors to improve their work, such as pointing out the connection to existing objectives like denoising score matching and scoreinterpolation, and suggesting a thorough literature review. These suggestions are concrete and directly address potential areas for improvement in the authors' work. The reviewer's guidance helps the authors understand how their method relates to existing knowledge and how they can further develop their approach."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "None", "helpfulness_label": "3", "actionability_rationale": "The suggestion to explore the combination of SOTA and an adaptive metric is explicit, indicating a desire to try something. However, it lacks specific details on how to combine them or what kind of adaptive metric to use. This makes it 3 in terms of identifying a direction for improvement, but less so in terms of providing concrete steps.", "grounding_specificity_rationale": "The reviewer mentions 'SOTA method' and 'adaptive metric' without explicitly naming a specific method or providing a clear reference point within the paper. This suggests a weak grounding as the authors cannot confidently determine which part the comment addresses. The specificity is also low as the suggestion is general and doesn't specify the exact nature of the combination or the adaptive metric.", "verifiability_rationale": "X", "helpfulness_rationale": "The review point is concise and relevant to the paper's goal. It suggests a direction for future work (performance evaluation of the combination). However, it lacks specific details on how to implement this suggestion, which might limit its immediate helpfulness for the authors in quickly understanding the next steps."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X (X)", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests expanding the experiments to 'other architecture' and 'other classification tasks'. While this implies a desire for more comprehensive experimentation, it lacks specific details about which architectures or tasks are intended. The action is implied but not explicitly stated, and the method of implementation is not detailed. Therefore, it is not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions 'other architecture' and 'other classification tasks' as potential areas for future experiments. While this indicates a general direction, it doesn't explicitly identify a specific section, table, or figure within the paper. The reviewer's intent is clear, but the connection to a specific part of the paper is not perfectly explicit. The issue is more about the scope of the *current* work rather than pinpointing a specific problem within a defined area. Therefore, it is weakly grounded in terms of identifying the *specific* part being addressed, but the intent is clear.", "verifiability_rationale": "The reviewer's point is more of a suggestion or a critique of the current scope rather than a claim that requires verification. They are suggesting that the experiments are limited to 'neural networks and image classification tasks' and are interested in seeing performance on 'other architecture and classification tasks'. This is a statement of intent or a limitation, not a claim that needs to be supported by evidence within the review itself. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The reviewer's comment is more of a suggestion for future work rather than a direct critique or actionable feedback on the current paper. While it points out a potential limitation (the narrow scope of experiments), it doesn't offer concrete suggestions for improvement within the context of the current submission. It lacks the specific details needed to be immediately helpful for addressing the current work. Therefore, it is not 5 in its current form."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "Not Helpful", "actionability_rationale": "The statement identifies a potential issue with the algorithm's output, which can be interpreted as an implicit action: 'I'm concerned about the algorithm's output and think it might depend on the order of the data.' However, the reviewer does not provide specific steps or examples of how this dependency might manifest or how to address it, making the action implicit and vague.", "grounding_specificity_rationale": "The reviewer makes a general statement about the algorithm's output depending on data order. They do not specify which part of the paper or data this refers to. The comment is about a potential issue with the process, not a specific element within the paper being addressed. Therefore, it is 1 in a specific part of the paper.", "verifiability_rationale": "The reviewer states a claim: 'the output from the algorithm depends on the order in which the data are processed.' This claim is 3 because the reviewer *suggests* clarifying this. However, the suggestion itself is vague and doesn't provide a clear justification or evidence for why this dependency exists or how to clarify it. The reasoning is present but lacks depth and specific examples.", "helpfulness_rationale": "The reviewer points out a potential source of confusion for the authors. While it highlights a potential issue with the review process, it doesn't directly provide actionable feedback on the paper itself. It's a metacomment about the algorithm's behavior, not a direct critique or suggestion for improvement of the paper's content. Therefore, it doesn't directly help the authors improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "Mostly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the aim of the mitigation strategies ('aim to reduce memorization') and raises a question about their impact ('what impact they might have on the overall performance'). However, it does not provide specific actions or concrete details on how to investigate this further.", "grounding_specificity_rationale": "The review point refers to 'mitigation strategies' and 'overall performance of the model.' While it mentions these terms, it does not explicitly point to a specific section, table, figure, or unique aspect of the paper. The context implies it's related to the 'mitigation strategies' discussed in the paper, but the exact location isn't pinpointed.", "verifiability_rationale": "The review point contains a claim ('it's unclear what impact they might have on the overall performance of the model') but does not provide any supporting evidence or reasoning within the review itself. It relies on the authors' own experience or understanding of typical model behavior.", "helpfulness_rationale": "The review point raises a valid concern about the potential impact of mitigation strategies on performance, which is a relevant issue for researchers. However, it does not offer any concrete suggestions or guidance to the authors on how to investigate this further or what steps they might take. It identifies a problem but doesn't offer a solution or a clear path forward for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The reviewer identifies an implicitly stated action: the fact that a reason for crossvalidation is missing. However, the action itself is vague and lacks detail on how to apply it. The reviewer states 'the reason for crossvalidation is not understood' which is a clear indication of an implicit action. The action is to understand *why* 6fold crossvalidation is used, but the reviewer doesn't specify what constitutes a 'good' reason or how this understanding should be derived.", "grounding_specificity_rationale": "The reviewer's comment is 1 at all. They do not identify a specific part of the paper or methodology where the use of 6fold crossvalidation is unclear. The comment is highly unspecific, simply stating a general concern about the justification of a methodological choice. The comment does not specify what needs to be addressed in this general area.", "verifiability_rationale": "The reviewer's comment is not verifiable because they are making a claim (that 6fold crossvalidation is needed) without providing any supporting evidence or justification within the review point itself. The comment relies on the assumption that other papers *didn't* use it, but doesn't explain *why* that was the case or what the specific requirements of this problem necessitate it.", "helpfulness_rationale": "The review point is not helpful because it does not provide a clear justification for the use of 6fold crossvalidation. The reviewer raises a valid concern but fails to explain why this specific crossvalidation method is necessary for their particular problem. Without a justification, the reviewer cannot confidently understand the implications of the results obtained through this method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point mentions the lack of clear improvement and suggests the presented method doesn't outperform ODA. While it implies an action (improving performance and speed), it doesn't explicitly state the action or how the presented method achieves it. The action is implicit and vague.", "grounding_specificity_rationale": "The review point mentions 'ODA' and 'MOIP problem', which grounds the discussion in the paper's context. It also mentions 'performance and computation speed', indicating a focus on specific aspects. However, it doesn't explicitly detail how the presented method addresses these aspects compared to ODA, making the grounding somewhat specific but incomplete.", "verifiability_rationale": "The review point makes a claim that the presented method doesn't clearly show improvement over ODA. However, it doesn't provide any logical reasoning, common knowledge, or external references to support this claim. The verifiability is low as there's no evidence provided to back up the statement.", "helpfulness_rationale": "The review point raises a valid concern about the comparison to ODA and the lack of demonstrated improvement in performance and speed. This is a meaningful feedback point for the authors, as it highlights a potential weakness in the presented method's justification and empirical validation. However, the lack of explicit suggestions on how to improve or clarify the comparison makes the helpfulness somewhat limited."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point identifies the importance of the sampling method for convergence but does not explicitly state how the authors should change or improve their sampling strategy. While it suggests comparing to uniform sampling, it doesn't provide concrete steps for the authors to take. The reviewer points to a potential area for improvement but lacks a direct action.", "grounding_specificity_rationale": "The review point refers to 'the sampling method' generally and 'the proposed benchmarks' broadly. It does not specify which particular sampling method or which specific aspect of the benchmarks is problematic. The comparison to 'uniform distribution' is a general example rather than a specific issue with the proposed benchmarks themselves. The authors are not told where to look or what specific problem to address.", "verifiability_rationale": "The review point makes a statement about the importance of the sampling method for convergence. While it implies that the choice of sampling method *could* impact convergence, it does not explicitly claim that a specific sampling method *will* cause problems or *requires* a specific type of analysis compared to uniform sampling. The reference to the supplementary material suggests an *observation* rather than a definitive claim within the review itself. There is no clear statement of a claim that is supported by logical reasoning, common knowledge, or external references within the review point itself.", "helpfulness_rationale": "The review point identifies a potential area for improvement (sampling) and suggests a comparison. However, it does not provide concrete steps for the authors to take. It's more of a *suggestion* for further work than a direct, actionable improvement for the authors. The reviewer highlights a potential issue but doesn't offer a clear path to resolution or a specific recommendation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests an interesting possibility but does not explicitly state an action or provide concrete steps for the authors to take. While it implies a potential application of multimodal data, it doesn't detail how to implement or explore this further. The suggestion is openended and lacks specific instructions on what the authors should do with this information.", "grounding_specificity_rationale": "The review point is a general suggestion about multimodal data and does not identify a specific part of the paper, table, figure, or element that it addresses. It offers a broad idea rather than focusing on a particular aspect of the authors' work. There is no mention of a specific section or element that would require revision based on this suggestion.", "verifiability_rationale": "The review point is a suggestion or an observation about the potential of multimodal data for tabular data. It does not present a claim that requires verification or justification. There is no explicit statement about what is wrong with the current approach or what needs improvement based on this suggestion.", "helpfulness_rationale": "The review point is a suggestion for exploring multimodal approaches with tabular data. While this is a relevant topic, it does not directly address any specific weaknesses or areas for improvement in the authors' current draft. It is a broad idea rather than a concrete, actionable suggestion that would help the authors make specific changes to their work. The suggestion is interesting but lacks direct applicability to the authors' immediate needs."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment suggests adding details about attention, which is an actionable step. However, it doesn't specify how to add these details, making it somewhat implicit.", "grounding_specificity_rationale": "The comment doesn't explicitly refer to a specific section, table, figure, or unique aspect of the paper where additional details about attention should be added. The location is implied but not explicitly stated.", "verifiability_rationale": "The comment is a suggestion for improvement, not a claim that needs verification. There's no assertion about the current level of detail or correctness.", "helpfulness_rationale": "The comment identifies a potential area for improvement (adding details) but lacks specific guidance on how to achieve this. This makes it 3 but less actionable for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The statement 'why the explicit methods perform better than implicit methods on the locomotion tasks' is an implicit statement. The reviewer is making a claim (explicit methods are better) but is not directly telling the author how to verify or improve their methods. The action is implied but not explicitly stated, and the direction of improvement is not specified.", "grounding_specificity_rationale": "The reviewer states 'The pseudocode of the proposed method is missing.' This statement does not explicitly identify a specific part of the paper being addressed. While the context implies the 'proposed method,' the reviewer does not point to a specific section, table, figure, or unique aspect of the paper. The grounding is weak as the reviewer cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The statement 'The pseudocode of the proposed method is missing' is a factual statement, not a claim requiring verification. A claim would involve an opinion, judgment, or suggestion. This statement simply states a fact about the absence of a specific element.", "helpfulness_rationale": "The statement 'why the explicit methods perform better than implicit methods on the locomotion tasks' is unhelpful as it is a general observation without any specific direction or actionable steps for the author. The statement 'The pseudocode of the proposed method is missing' points out a concrete deficiency, but it does not explicitly tell the author how to fix it or what to do about it."}
{"actionability_label": "3", "grounding_specificity_label": "4: Mostly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The suggestions are present but could be more specific. The reviewer offers a general idea and a vague suggestion about differences in figures.", "grounding_specificity_rationale": "The reviewer refers to \"result description\" and \"figures\" which is broad. However, they also suggest specific visualizations and a specific interpretation of the results.", "verifiability_rationale": "The reviewer makes a claim about the convoluted nature of the description and suggests investigating specific visualizations and referencing prior work. While not explicitly citing a figure, the suggestions provide a basis for verification.", "helpfulness_rationale": "The review has potential but lacks some clarity and specificity. The reviewer connects the convoluted description to a potential communication issue and suggests a specific area of prior work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions 'optimization strategy, including the grid search strategy for hyperparameters selection' as a missing detail. This directly points to an actionable improvement the authors should implement. The reviewer also suggests 'considering deeper networks' which is a clear action. While the reviewer doesn't explicitly state 'how' to implement these actions, they are concrete and directly related to the mentioned issues. The reviewer's suggestion to 'provide details on the optimization strategy' is a clear action.", "grounding_specificity_rationale": "The review point mentions 'experimental validation are not convincing' and 'only shallow networks are considered (2 or 3 layers)'. While it identifies a general area of concern, it doesn't specify *which* experiments or *which* part of the network is lacking detail. The reviewer also mentions 'optimization strategy, including the grid search strategy for hyperparameters selection' without specifying *which* part of the model or experiment this applies to. The positioning point about layer redundancy is also not explicitly linked to a specific section or table.", "verifiability_rationale": "The review point makes the claim 'Experimental validation are not convincing' and 'only shallow networks are considered (2 or 3 layers)'. It also mentions 'optimization strategy, including the grid search strategy for hyperparameters selection'. The claim about optimization strategy is 3 as it points to a specific detail (grid search). However, the claim about 'not convincing' is subjective and not directly verifiable. The lack of detail about optimization strategy makes it partially verifiable, but the claim about 'not convincing' is not supported by specific evidence within the review point itself.", "helpfulness_rationale": "The review point provides specific suggestions for improvement, such as 'considering deeper networks' and 'providing details on the optimization strategy'. These suggestions are concrete and actionable for the authors. The reviewer also points out a 'minor issue' regarding the 'positioning with respect to related works' and suggests considering a specific paper. While the suggestion is specific, it doesn't explicitly state *how* the authors should position their work in relation to the cited paper. The reviewer's overall assessment of the positioning as 'limited' is a valid concern, but it lacks a clear recommendation for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the limitation to Task 1 of the bAbI dataset. However, it does not provide concrete guidance on how this limitation affects the model's performance or suggest specific actions the authors should take to address it. The action is present (identifying the limitation), but it is vague on how to apply it.", "grounding_specificity_rationale": "The comment explicitly mentions 'bAbI' and 'Task 1 of bAbI'. This is a clear identification of the specific aspect being addressed. The grounding is strong as the comment names the specific task and dataset. However, the comment does not specify what is wrong with testing only on this specific task or what needs to be improved. The grounding is present, but the specificity is lacking.", "verifiability_rationale": "The comment raises a concern about the limited scope of the evaluation (only Task 1). While it identifies the weakness, it does not provide any external references or logical reasoning to support why this limited scope is a problem. The claim is that the evaluation is too narrow, but the verifiability is weak because there's no evidence provided to back this claim up. The claim is present, but the verification is lacking.", "helpfulness_rationale": "The comment points out a potential limitation in the evaluation of the bAbI task. It is helpful in identifying that the evaluation might not be comprehensive. However, it does not offer specific suggestions or evidence to help the authors address this limitation. The comment is 3 in identifying a potential issue, but it lacks the actionable steps or verifiable evidence to fully address the reviewer's concern."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests improving Sec. 3.2, which implies an action. However, the suggested action is vague, stating 'give more illustrations and examples' without specifying what kind or how many. This makes the action somewhat explicit but not fully concrete.", "grounding_specificity_rationale": "The review point explicitly mentions 'Sec. 3.2', which is a specific section of the paper. It also identifies a problem within this section ('It is hard to follow Sec. 3.2'). This clearly grounds the comment in a specific part of the paper and the issue within it.", "verifiability_rationale": "The review point contains a claim: 'It is hard to follow Sec. 3.2'. The suggestion to 'give more illustrations and examples' provides a method for addressing this claim, making it verifiable. While it doesn't provide specific examples or cite external references, it offers a clear direction for improvement.", "helpfulness_rationale": "The review point directly identifies a difficulty ('It is hard to follow Sec. 3.2') and offers a constructive suggestion ('give more illustrations and examples') to address it. This directly points to a potential weakness and provides a clear path for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests a specific experiment: 'Thus, GCG could craft adversarial prompts and transfer them to other LLMs. It would be good if such a comparison could be included.' This clearly indicates a direct action the authors could take. The reviewer also provides a minor point: 'A minor point: The jailbreaking percentage is low for certain LLMs.' This suggests a concrete improvement related to the results section.", "grounding_specificity_rationale": "The reviewer refers to 'GCG' and 'other LLMs' as a context for their suggestion. While they mention the concept of transferability, they do not explicitly point to a specific section, table, or figure in the paper where this discussion already exists. The reviewer is suggesting a new experiment rather than pointing to a specific area that needs improvement.", "verifiability_rationale": "The reviewer's claim that 'GCG could craft adversarial prompts and transfer them to other LLMs' is based on the established understanding of GCG and the concept of transferability in machine learning. While the reviewer doesn't provide specific references in this review point, the reasoning for the claim's validity is based on existing knowledge. The claim specifies what needs to be done (craft adversarial prompts and transfer them) and identifies the context (GCG and other LLMs).", "helpfulness_rationale": "The reviewer's suggestion to include a comparison of GCG's transferability across LLMs is a concrete and actionable suggestion. It directly addresses a potential area for improvement in the paper by exploring the generalizability of the findings. The reviewer provides a clear direction for the authors to take, making this a 5 suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point states \"How to set the parameter S remains a problem.\" While it identifies a problem with the parameter S, it does not explicitly state how to set it or provide any suggestions for improvement. The action is implied but not directly stated, making it 2.", "grounding_specificity_rationale": "The review point refers to \"parameter S\" without explicitly naming the section, table, figure, or unique aspect of the paper where this parameter is located. The reference to parameter S is implicit, indicating a lack of precise grounding.", "verifiability_rationale": "The review point does not contain a claim or make any assertions. It is a question about how to set a parameter, not a statement that requires verification. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The review point identifies a valid issue (the lack of guidance on setting parameter S) but fails to offer any concrete solutions or suggestions. It points out a weakness but does not provide actionable improvement, making it 2."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'This can be seen as a hyperparameter that needs to be chosen or tuned.' It identifies the *choice* of constraint type as something that requires a decision, which is a form of action. However, it doesn't provide specific guidance on *how* to implement this action or what the implications are.", "grounding_specificity_rationale": "The review point refers to 'constraint choices' which are likely specific parts of the paper. The reviewer implies these choices are important and need consideration. However, the point doesn't explicitly state which specific part of the paper is being addressed (e.g., the 'Methods' section or a specific table). The grounding is implied but not explicitly stated.", "verifiability_rationale": "The review point doesn't present a claim that requires verification. It's a statement of observation and a suggestion for improvement, not a claim that needs to be supported by evidence or references.", "helpfulness_rationale": "The review point is helpful because it points out a nuance in the authors' description. It encourages the authors to consider the implications of their constraint choices and to refine their language. It provides a valuable insight into a potential point of confusion or a subtle limitation in their current phrasing. It guides the authors towards a more precise and technically accurate description of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states what is missing (limited datasets, models, bias benchmarks) but does not provide concrete steps on how to address these limitations. While they identify areas for improvement, they don't offer specific actions or solutions.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific biases measured (gender, race, religion) and the models missing (stateoftheart generative models). This clearly identifies the specific parts of the paper or evaluation framework that are lacking.", "verifiability_rationale": "The reviewer makes a judgment about the limited scope of the bias benchmarks and models. While they state a fact, they do not provide any logical reasoning, common knowledge, or external references to support this claim within the review point itself.", "helpfulness_rationale": "The reviewer points out limitations in the evaluation framework. This can be helpful for authors by guiding their focus and potentially highlighting areas where their work might be evaluated. While it doesn't directly instruct how to improve, it provides a direction for authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that Figure 3 is 'challenging to understand' and 'unclear'. This implies that the authors need to make changes to the figure. While the reviewer doesn't explicitly state what needs to be changed, the lack of understanding points to an actionable issue. The authors can infer that the figure needs improvement, and the specific unclear elements (workflow, captions, communication modes) provide some guidance on where to focus their attention.", "grounding_specificity_rationale": "The reviewer explicitly names 'Figure 3' and then specifies the unclear elements within it: 'workflow,' 'captions,' and 'representation of communication modes.' This precise identification of the section and the specific aspects within that section demonstrates strong grounding specificity. The authors can directly locate the problematic area and understand what needs to be addressed.", "verifiability_rationale": "The review point states that Figure 3 is 'challenging to understand' and 'unclear'. These are statements of observation, not claims that require verification. There is no suggestion, recommendation, or judgment being made. Therefore, there is X to be supported or verified.", "helpfulness_rationale": "The reviewer points out that Figure 3 is 'challenging to understand' and 'unclear'. This directly identifies a specific area within the paper that needs improvement. While the review doesn't offer a solution, it clearly highlights a weakness that the authors should address. By pointing to a specific part of the paper, the reviewer provides a starting point for the authors to focus their attention and potentially make necessary changes."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point directly asks for a definition of 'learned MASK embedding', which is a clear and explicit request for action. Once the authors understand what this term refers to, they can apply this knowledge to improve their understanding of the SSL pretraining stage. The request is also concrete as it specifically asks for a definition of a particular term.", "grounding_specificity_rationale": "The reviewer uses the term 'learned MASK embedding' generally, without specifying the exact section or table where this term is likely to be found. This indicates weak grounding as the authors cannot confidently determine the referenced part. However, once the authors locate the relevant section, the request to define the term becomes specific and clear.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a request for clarification. Therefore, it does not fit into the categories of 'Claim Extraction' or 'Verifiability Verification'. The score 'X' indicates that the comment is not a claim.", "helpfulness_rationale": "The review point is helpful as it seeks to clarify a potentially confusing term in the authors' understanding of the SSL pretraining stage. This clarification can help the authors better grasp the method. However, the lack of specificity in the request (e.g., 'where is this used and why is it important?') makes the feedback somewhat vague and less actionable for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the desire for error analysis and specifies \"under different scenarios,\" indicating a clear and actionable request.", "grounding_specificity_rationale": "The reviewer mentions \"model performance\" generally, lacking specific details about the model, the evaluation metrics, or the datasets used. While the *topic* is clear, the *specifics* are missing, making it weakly grounded. It's somewhat specific in that it points to a general improvement area but lacks concrete details.", "verifiability_rationale": "The reviewer states the importance of error analysis and detailed explanations but doesn't provide any evidence or reasoning to support this claim. It's a statement of importance, not a verifiable claim.", "helpfulness_rationale": "The suggestion to conduct error analysis is valuable and points to a potential improvement, but it lacks specific, actionable steps for the authors. The authors still need to conduct the error analysis themselves. The review points out a potential improvement but doesn't detail *how* to implement it."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer directly challenges the authors' claim about the paper being NLPspecific by stating they don't see anything NLPrelated. While this points to a potential issue with the authors' categorization, the reviewer doesn't explicitly state a concrete action the authors should take based on this finding. The reviewer's statement is more of a question or a request for clarification than a direct instruction for improvement.", "grounding_specificity_rationale": "The reviewer's statement is a general challenge to the authors' claim, not a specific criticism of a particular section, table, figure, or unique aspect of the paper. They are questioning the general applicability of LLP to NLP, not a specific element within the paper. Therefore, the grounding is weak as the reviewer cannot confidently identify the referenced part.", "verifiability_rationale": "The reviewer makes a clear claim: 'I don't see anything NLPspecific in their approach.' They also provide a reason for this claim ('I don't see anything NLPspecific in their approach'). This provides sufficient justification for the claim, making it verifiable.", "helpfulness_rationale": "The reviewer's point is a direct challenge to the authors' categorization of their work. It forces the authors to reconsider their framing and potentially identify where their work might overlap with NLP. While it doesn't offer a specific, actionable improvement, it is a clear and actionable point that guides the authors to reevaluate their claims."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential issue (unfair comparison due to dataset size) but doesn't explicitly state an action or provide details on how to address it. The reviewer suggests using the same dataset, which is a potential action, but the comment itself doesn't clearly outline the steps or methods to achieve this.", "grounding_specificity_rationale": "The comment mentions the 'comparison with the SOTA methods' and the 'newly collected 209M dataset' and the 'smaller datasets' used by 'existing methods'. This grounds the comment to specific parts of the paper. The comment also clearly specifies what it is questioning \u2013 the fairness of the comparison due to the dataset size difference. Therefore, the grounding and specificity are both high as the comment accurately identifies the relevant parts and the issue within them.", "verifiability_rationale": "The comment states a potential problem (unfair comparison) but does not provide any evidence or justification to support this claim. The reviewer suggests using the same dataset as a potential improvement, but this is a suggestion, not a verified issue within the paper. The claim is presented as a possibility, not a proven fact.", "helpfulness_rationale": "The comment raises a valid concern about the fairness of the comparison. However, it lacks the necessary details and evidence to be considered a helpful critique. The reviewer suggests a potential improvement (using the same dataset) but doesn't explain how this improvement could be implemented or what specific changes would be required. The comment is a suggestion for improvement but lacks the concrete steps and justification to be truly helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The suggestion to add references is a valid point, as it highlights the importance of citing existing studies. However, it lacks specific details on which studies to include or how they relate to the current work. The reviewer identifies the need for references but doesn't provide concrete steps on what to do with them.", "grounding_specificity_rationale": "The reviewer mentions 'some claims may be inspired from existing studies' and lists 'four critical factors' that require references. While the factors are named, the reviewer does not explicitly state the specific section, table, or figure within the paper where these factors are discussed. The grounding is present in the identification of the factors, but the location is not explicitly mentioned.", "verifiability_rationale": "The review point does not contain a claim or assertion about the paper's quality or the authors' work. It is a statement about the importance of referencing existing studies and the need to understand the context of the identified factors. Therefore, it does not require verification in the sense of logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point is relevant and addresses a common practice in academic writing, which is citing existing studies. However, it is a general suggestion and does not provide specific guidance on which studies to cite or how to integrate them into the current work. It lacks concrete steps to improve the draft based on the suggested action."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review suggests that the current prompting technique is 'basic' and that 'carefully curated prompts' could be better. While the reviewer identifies a potential area for improvement, the specific action to be taken is not explicitly stated. The reviewer implies the need for better prompts but does not detail how to achieve this or what constitutes a better prompt. Therefore, the action is implicit and lacks concrete details, making it 2.", "grounding_specificity_rationale": "The review points out that the prompting technique used is 'very basic' and that 'carefully curated prompts' could gain better results. However, it does not specify which particular aspect of the paper or the prompt is lacking. The reviewer is broadly commenting on the prompting technique's potential impact on the systematic review process but lacks the specificity needed to ground the feedback to a particular part of the paper or the prompt itself. Therefore, the feedback is 1 to a specific section or detail.", "verifiability_rationale": "The review states that the 'prompting technique used in this study is very basic and fail to leverage the full potentials of LLMs'. This statement presents a claim about the current technique's limitations. However, the reviewer does not provide any specific examples, references, or logical reasoning to support this claim. There is no evidence provided to verify the claim about the 'failing to leverage the full potentials of LLMs'. Therefore, the claim is not supported by any evidence, making it 1.", "helpfulness_rationale": "The review suggests that the prompting technique is 'very basic' and that 'carefully curated prompts' could gain better results. While the reviewer identifies a potential area for improvement, the comment lacks specific details on how to curate better prompts or what constitutes a better prompt. The suggestion is general and lacks actionable advice for the authors. Therefore, the feedback is not specific enough to be 5 for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential limitation in the experimental setup and raises a question about the scalability of the method to larger backbones. While the reviewer identifies a trend (small gains) and a potential explanation (small receptive field), they do not explicitly state what specific part of the paper or experiment needs to be changed or improved. The reviewer suggests an experiment with larger backbones but does not provide a clear, actionable step on how to conduct this experiment or analyze the results. The reviewer's comment is more of a question and an observation rather than a direct instruction on how to improve the current draft.", "grounding_specificity_rationale": "The reviewer's comment is not strongly grounded. While they connect the observed results (small gains) to a specific architectural detail (global pooling in ResNet50), they do not explicitly identify the exact section, table, or figure where these results are presented. The reviewer's suspicion about larger backbones (SwinB or SwinL) is a generalization and lacks a clear reference point within the paper. The grounding is present but not precise enough to pinpoint the exact location of the issue.", "verifiability_rationale": "The reviewer makes a claim about the relative gains being 'not very strong' and suspects the method might not work well on 'large backbone models like SwinB or SwinL.' However, the reviewer does not provide any evidence, justification, or references to support these claims. The statement is presented as an observation and a hypothesis, but there is no logical reasoning, common knowledge, or external references to back it up. The claim is stated, but the lack of supporting evidence makes it 1.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the experimental results and suggests a potential area for future work. While the comment is relevant to the paper's findings, it does not directly suggest specific, actionable improvements to the current draft. The reviewer points out a limitation in the current experimental setup and proposes an experiment with larger backbones, but they do not provide a clear roadmap on how to conduct this experiment or what specific changes should be made to the current draft based on this observation. The comment is more of a critique of the current experimental scope rather than a direct suggestion for improvement."}
{"actionability_label": "None", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out 'some confusing mistake' and 'lacks a detailed discussion and comparison with the previous work'. While these point towards actionable feedback, the lack of specific details makes the actionable elements implicit rather than explicit. The reviewer doesn't explicitly state *where* the mistake is or *how* the discussion or comparison should be done. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer states 'this paper seemed not to give any new insight on this field' and 'lacks a detailed discussion and comparison with the previous work'. These statements are general and do not pinpoint a specific section, table, figure, or unique aspect of the paper that is lacking detail or insight. The grounding is in the general assessment of the paper's content rather than a specific element.", "verifiability_rationale": "The reviewer makes claims about the paper lacking 'detailed discussion' and 'no new insight'. However, these claims are not supported by any evidence or references. The reviewer does not provide logical reasoning, common knowledge, or external references to back up their assertions. The claims are presented without sufficient justification.", "helpfulness_rationale": "The review point is somewhat vague and general. While the reviewer identifies areas for improvement ('confusing mistake', 'lack of detailed discussion', 'lack of new insight'), they do not provide specific, actionable suggestions for the authors to address these issues. The feedback is about what's missing but not how to fix it. The helpfulness is limited as the authors are left without clear guidance on what to do next."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out the unfair comparison and the larger model size as issues, but doesn't explicitly ask the authors to address these or provide specific, actionable steps within the paper itself. While these are valid observations, the reviewer doesn't directly instruct the authors on how to improve their draft based on these points.", "grounding_specificity_rationale": "The reviewer mentions 'motivation,' 'experimental results,' 'CAT and GAN,' and 'pretrained model' generally, without specifying the exact section, table, figure, or unique aspect of the paper being addressed. The references are broad and lack precision.", "verifiability_rationale": "The reviewer states that the motivation is unclear, the comparison is unfair, and the model is larger. While these are valid points, the reviewer doesn't provide specific evidence or reasoning *within the paper* to support these claims. The lack of specific references makes it difficult to verify these statements based on the paper alone.", "helpfulness_rationale": "The reviewer raises concerns about the motivation, experimental setup, and model size. While these are valid points that could potentially help the authors improve their work, the review point itself is general and lacks specific suggestions or requests for clarification within the paper. The reviewer doesn't directly instruct the authors on how to improve their draft based on these observations."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a discrepancy in the results (MSE < MAE) and links it to the reliability of the experimental results. While it identifies the *area* (experimental results) and the *issue* (MSE < MAE in Table 1), it doesn't explicitly state *what* needs to be changed or how to address this discrepancy. The reviewer suggests the results are 'unreliable' but doesn't provide specific steps for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 1' and then specifies the metrics 'MSE' and 'MAE' within that table. This clearly identifies the specific part of the paper being addressed, indicating full grounding. The reviewer also specifies the * issue they are raising ('MSE is significantly smaller than the MAE'), which adds to the specificity.", "verifiability_rationale": "The review states 'The experimental results are unreliable, especially in Table 1, where the MSE is significantly smaller than the MAE, which raises concerns about their validity.' This is a claim that the experimental results are unreliable and that the MSE < MAE is a cause of this. However, the review does not provide any specific justification or evidence for why the MSE being smaller than the MAE is *specifically* a sign of unreliability. There are no references to external works or logical reasoning provided within the review point itself to support this claim.", "helpfulness_rationale": "The review identifies a potential issue with the experimental results and points to a specific table and metric comparison. This is a valuable piece of feedback for the authors. It highlights a concrete area where something might be going wrong. However, it doesn't provide specific guidance on how to fix the issue. The reviewer suggests the results are 'unreliable' but doesn't offer concrete steps for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment states a fact about the loss function but doesn't provide actionable steps for the author of the reviewed paper. It's a declarative statement, not a directive. Therefore, it's 1.", "grounding_specificity_rationale": "The comment doesn't specify which part of the paper it's referring to. It's a general statement about adversarial loss. Therefore, it's 1.", "verifiability_rationale": "The comment is a statement of fact about the intended behavior of an adversarial loss function, not a claim that needs verification. Therefore, it's X.", "helpfulness_rationale": "The comment provides information about a desirable property of an adversarial loss function. While it doesn't directly improve the paper being reviewed, it offers context and understanding of a relevant concept. Therefore, it's 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the 'verylongterm forecasting task is of limited practical significance' and provides concrete suggestions such as 'conducing experiments on more datasets' and 'training the baseline models with the \"correct\" forecast horizon'. These suggestions are direct and specify how to implement the changes.", "grounding_specificity_rationale": "The reviewer refers to the 'verylongterm forecasting task' but does not explicitly identify a specific part of the paper or methodology within that task. While the reviewer implies the importance of the discussion section, they do not specify which aspect of the longterm forecasting is lacking. The reviewer focuses on the *what* (improving the task) but not the *where* within the task.", "verifiability_rationale": "The reviewer makes a claim that the 'verylongterm forecasting task is of limited practical significance'. This claim is supported by the suggestions to 'conducing experiments on more datasets' and 'training the baseline models with the \"correct\" forecast horizon', which implicitly justify the significance of the task. While the reasoning is not fully explicit, it is present.", "helpfulness_rationale": "The review identifies a limitation ('limited practical significance') and offers concrete suggestions for improvement ('conducing experiments on more datasets' and 'training the baseline models with the \"correct\" forecast horizon'). These suggestions are actionable and directly address the identified limitation, making the review helpful for guiding improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'analyze the security...of the proposed framework.' This clearly indicates an action the authors should take. However, it lacks specific details on *how* to analyze the security, making it somewhat vague on the implementation level.", "grounding_specificity_rationale": "The comment refers to 'the proposed framework' without specifying a particular part, section, table, or figure. This means the authors have to infer which framework is being discussed. Furthermore, while it mentions 'privacy,' it doesn't specify which aspect of privacy or which part of the framework is lacking. This makes it weakly grounded and somewhat specific.", "verifiability_rationale": "The comment contains a claim: 'the authors do not analyze the security (i.e., protection of the privacy) of the proposed framework.' However, the comment does not provide any evidence or justification to support this claim. It's an assertion by the reviewer, not a statement backed by logical reasoning, common knowledge, or external references. Therefore, it is 1.", "helpfulness_rationale": "The comment clearly identifies a weakness in the authors' work: the lack of security analysis, specifically regarding privacy protection. It also suggests a concrete improvement: conducting such an analysis. This is a helpful comment as it points the authors directly to an area for improvement and provides a clear direction for them to follow. While it doesn't provide specific *howto* details, it does highlight a clear need."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states \"Memb is apparently the previous stateoftheart, but there is no mention to any reference.\" This points to an implicit action: the authors should verify if 'Memb' is indeed the stateoftheart and ensure they are referencing the correct work. However, it doesn't explicitly tell them how to do this, such as suggesting a specific paper or method. The action is implied but not clearly stated, making it 2.", "grounding_specificity_rationale": "The review point mentions \"Memb\" without specifying what 'Memb' refers to or which part of the paper is being discussed. It doesn't point to a specific section, table, or figure. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point makes a claim: \"there is no mention to any reference.\" While it points out a factual deficiency, it doesn't provide any logical reasoning, common knowledge, or external references to support this claim. The claim is stated, but there's no justification for why this absence is a significant issue or how it impacts the work. Therefore, it is 1.", "helpfulness_rationale": "The review point identifies a factual error: the absence of a reference for 'Memb'. However, it doesn't offer any actionable advice or suggestions to the authors on how to address this issue. It simply states a problem without providing any guidance on how to fix it. Therefore, it is 2."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states the problem (examples are hard to find) but doesn't explicitly *say* what the authors should do to find them. Therefore, the review is 3 in identifying a need, but it lacks direct guidance on how to address it.", "grounding_specificity_rationale": "The reviewer is asking for *specific* examples, likely implying the examples are in the 'Illustration of Loss Principles' section, but this isn't explicitly mentioned. The weakness is about the *lack of specific examples* within that section.", "verifiability_rationale": "The reviewer makes claims about the difficulty of finding examples and the unclear nature of the FSR metric's examples. However, they do not provide any evidence or reasoning to support these claims. The review points out a weakness but doesn't offer any justification or references.", "helpfulness_rationale": "The reviewer directly asks for *helpful* information about finding examples and clarifying the FSR metric. This indicates a genuine need for improvement, but the review itself doesn't provide any specific solutions or further details to address this need."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the impact of the paraphrase difference on subsequent steps, which can be considered an action the authors should take into account. However, the reviewer does not specify *how* different the paraphrases are, making the action implicit rather than explicit. The lack of concrete details about the paraphrase difference makes it difficult to fully understand the action.", "grounding_specificity_rationale": "The reviewer refers to 'the difference between the paraphrases and the original sentence' generally, without explicitly naming a specific part of the paper or a unique element. While they are referring to a specific concept within the training data generation process, the grounding is weak because they are not pointing to a specific section, table, figure, or unique aspect. However, the reviewer *does* specify the *impact* of this difference, which adds a layer of specificity to the comment.", "verifiability_rationale": "The reviewer makes a claim about the impact of paraphrase quality on subsequent steps and training data quality. This claim is supported by logical reasoning, stating that the model relies on the quality of these paraphrases. While the reviewer doesn't provide specific examples of *how* the difference impacts subsequent steps, the logical reasoning provides a basis for verification. The claim is not based on external references, making it 3 but lacking strong external support.", "helpfulness_rationale": "The reviewer clearly identifies a crucial issue (the lack of clarity on paraphrase differences) and its potential negative consequences (impact on subsequent steps and training data quality). The reviewer also suggests a direct action the authors should take \u2013 consider the impact of paraphrase quality. This makes the comment 5 as it directly addresses a practical concern and provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The question points to a potential issue with text input, but it doesn't explicitly state what needs to be done. It's an implicit suggestion that the author check their input for concatenation. Therefore, it's 2 as it requires the reader to infer the action.", "grounding_specificity_rationale": "The question is about text input in general, not a specific part of the paper or the review process. It lacks grounding in a particular section, table, figure, or unique aspect of the paper. Therefore, it's 1.", "verifiability_rationale": "The question is not a claim that requires verification. It's a question about the validity of a text input operation. Therefore, it has no verifiability.", "helpfulness_rationale": "The question identifies a potential issue with text input, which is a valid concern for the author. It encourages the author to doublecheck their input. While it doesn't provide specific steps to fix the issue, it points to a potential problem, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the weakness: 'the paper could do better to first motivate the \"Why\" (why do we care about what we are going to be presented)'. This indicates an action the authors should take: add a strong motivation or introduction. However, the comment does not specify *how* to do this, leaving the authors without concrete guidance on the implementation.", "grounding_specificity_rationale": "The comment refers to the 'paper' as a whole, stating it 'could do better to first motivate the \"Why\"'. There is no specific section, table, figure, or unique element of the paper being identified. The reviewer is making a general comment about the paper's structure or flow. Therefore, the grounding is weak as the authors cannot confidently pinpoint where the issue lies.", "verifiability_rationale": "The comment contains a claim: 'the paper could do better to first motivate the \"Why\" (why do we care about what we are going to be presented)'. This is a statement of opinion or suggestion. The 'support' provided is logical reasoning \u2013 the reviewer is stating a preference for a wellmotivated introduction. However, the reviewer does not provide specific examples, references, or external sources to back up this claim. The verifiability relies on the commonsense understanding that a strong introduction is generally beneficial for engaging readers.", "helpfulness_rationale": "The comment provides a general suggestion: 'the paper could do better to first motivate the \"Why\" (why do we care about what we are going to be presented)'. While this is a relevant piece of feedback, it lacks specific details or examples. The authors would need to interpret what constitutes a 'better' introduction and how to achieve it. The feedback is not actionable enough to immediately guide the authors' revisions."}
{"actionability_label": "1", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review points out a discrepancy in the experimental setup (Pix3D training and testing) and compares it to zeroshot methods. This doesn't directly tell the authors *what to do*. It highlights a potential flaw in their evaluation.", "grounding_specificity_rationale": "The reviewer mentions \"Pix3D training and testing\" and \"zeroshot singleimage 3D reconstruction models.\" While they name the models, they don't explicitly point to a specific part of the paper being addressed. The connection to the *author's specific method or result* is missing.", "verifiability_rationale": "The reviewer states a fact: \"The domainspecific model is trained on Pix3D. And the experiments are conducted on Pix3D.\" This is a factual statement, not an claim requiring evidence. There's no explicit claim being made about the comparison to zeroshot models being unfair.", "helpfulness_rationale": "The review points out a potential flaw in the experimental design. While it's a valid point for discussion, it doesn't directly instruct the authors on *how to improve their draft*. It's more of a critique of the experimental setup than a direct suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The review point suggests *what* to do (additional experiments) but doesn't specify *how* to do it or what specific results are needed. The phrase \"more support\" is vague.", "grounding_specificity_rationale": "The review point explicitly mentions \"WebVision\" as the dataset and \"C2D\" as the task, allowing the authors to directly identify the relevant information.", "verifiability_rationale": "The review point contains a suggestion (\"additional experiments\") that implies a logical next step to support the claim about C2D. While not a direct citation, it's a reasonable suggestion based on common research practices.", "helpfulness_rationale": "The review point clearly identifies a potential weakness (lack of support for C2D) and suggests a concrete way to address it (additional experiments on WebVision). This directly points to an area for improvement and offers a clear next action. While it doesn't provide specific details on *how* to conduct the experiments, it guides the authors in the right direction. It's more than just a negative comment; it offers a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point poses a question about a specific procedure (grid search location). While it doesn't explicitly state what to do, it points to a potential area for clarification or improvement. The reviewer is implicitly suggesting that the grid search might not be done correctly on the validation set, which is a actionable suggestion for the authors to check their implementation.", "grounding_specificity_rationale": "The reviewer explicitly asks about 'the validation set'. This clearly identifies the specific part of the paper or the intended behavior being referred to. The reference is literal and unambiguous.", "verifiability_rationale": "The review point primarily asks a question. While the phrase 'Minor problems:' at the end could be interpreted as a claim about the nature of the problems, there's no direct evidence or reasoning provided to support this claim within the review point itself. Therefore, it's borderline in terms of verifiability. However, if we consider the 'Minor problems:' as a claim about the issues in the paper, it lacks specific examples or justification, making it underverifiable. Given the direct question, the primary focus is on the validation set, which is verifiable. The 'Minor problems:' makes it somewhat borderline overall.", "helpfulness_rationale": "The review point directly asks a question about a specific implementation detail (grid search location). This is a clear and actionable question that the authors can investigate. It helps them understand and potentially correct a procedural issue. However, the phrase 'Minor problems:' is vague and doesn't provide specific guidance, making the overall helpfulness somewhat limited."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly asks a question about a specific aspect of the data (racial/economic diversity) and its implications for generalizability. While the request is clear, the exact action the authors should take is not fully specified, making it 3.", "grounding_specificity_rationale": "The reviewer refers to 'the sample' in general and asks about racial/economic diversity within it. The comment does not identify a specific part of the paper or analysis where this lack of diversity is evident, making it underspecific and weakly grounded.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the sample and its generalizability but does not provide any evidence, examples, or references to support this claim, making it 1.", "helpfulness_rationale": "The reviewer's comment is relevant as it points out a potential limitation of the study. However, it does not provide explicit, actionable steps for the authors to take, making it only 2. It prompts the authors to investigate further but doesn't directly guide them in making changes."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a potential issue (nonconvexity) and suggests a possible solution (good properties of the loss function Z). This is an explicit action that the authors can take to investigate or address the issue. While the exact nature of the 'good properties' isn't specified, the reviewer indicates they are relevant, making the action actionable.", "grounding_specificity_rationale": "The comment explicitly refers to 'ln. 182184' and mentions 'loss function Z'. This directly points to a specific part of the paper and a specific element within it, indicating strong grounding. The authors can easily identify the section and the function being discussed.", "verifiability_rationale": "The comment contains a claim that 'nonconvexity may not be an issue for the SGD to converge if the function Z has some good properties'. This claim is 3 as the reviewer suggests a potential relationship, but it doesn't provide concrete evidence or examples within this review point. The connection to 'good properties' implies that further investigation or specific characteristics of Z could be explored.", "helpfulness_rationale": "The comment raises a valid point about the potential impact of nonconvexity on SGD convergence and offers a potential mitigating factor ('good properties' of the loss function Z). This is a relevant and helpful suggestion for the authors to consider, as it points to a potential area for further investigation or clarification in their work. It provides a direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points to a clear issue (lack of proper experimental settings) but lacks specific details on *what* is missing and *how* to address it. While it identifies the *area* of concern, it doesn't provide concrete steps or information for the author to follow.", "grounding_specificity_rationale": "The review mentions 'experimental settings' generally, not pointing to a specific section or table. However, it does specify the *nature* of the missing information ('not mentioned properly').", "verifiability_rationale": "The review makes a clear claim about the missing code. The connection to the lack of proper experimental settings is implied but not explicitly demonstrated with examples or references. The claim is that the lack of code is the reason for the reproducibility issue.", "helpfulness_rationale": "The review highlights a critical issue (reproducibility) and points to a potential cause (lacking experimental details). However, it stops short of providing concrete steps for the author to take. It identifies a problem but doesn't fully guide the author towards a solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment states 'the motivation behind applying CMD in federated learning seems a bit unclear'. While it identifies a potential issue, it doesn't explicitly state what the authors should do to address this lack of clarity. The action is implied (understanding the motivation), but not explicitly stated.", "grounding_specificity_rationale": "The comment mentions 'CMD in federated learning' generally. It doesn't specify a particular section, table, figure, or a unique aspect of the paper related to CMD and FL. The reference is broad.", "verifiability_rationale": "The comment states 'the motivation behind applying CMD in federated learning seems a bit unclear'. This is a statement of opinion or a perceived weakness. It doesn't present a claim that requires verification or justification based on external knowledge or logical reasoning within the paper itself. It's a suggestion for improvement.", "helpfulness_rationale": "The review points out a potential lack of clarity in the motivation for using CMD in FL. While it identifies a problem, it doesn't offer a specific solution or actionable step for the authors to take. The suggestion is present but lacks concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer's point implicitly suggests that the UNet part might be the source of the claimed performance boost. While not explicitly stated as 'what to do', the question implies a need to investigate the contribution of the UNet. The lack of clarity on whether the boost comes from the fractional transform or the UNet operation makes the action somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'the UNet part in the proposed CoNO model' and asks about the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain. This clearly identifies the specific part of the paper being addressed and what is being questioned, making it highly specific.", "verifiability_rationale": "The reviewer is not making a claim that can be verified. They are suggesting a complementary experiment (comparison to UNets) to further investigate the model's performance. This is a suggestion for future work, not a statement that can be proven or disproven based on the existing paper. Therefore, it lacks verifiability in the sense of the provided definition.", "helpfulness_rationale": "The reviewer's suggestion to compare the CoNO model to standard UNets is highly relevant and directly addresses a potential ambiguity in the model's design. It provides a clear direction for further investigation and could significantly improve the understanding of the CoNO model's effectiveness. This is a valuable suggestion that directly tackles a potential weakness in the paper's analysis."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that W1 and W2 are not defined. While they point out a specific issue, they don't explicitly state what these variables represent or how they should be defined. The reviewer implies a need for clarification on these variables' roles in the model.", "grounding_specificity_rationale": "The reviewer explicitly states that W1 and W2 are not defined. They also specify that these variables are part of the Encoder and Decoder network. This clearly identifies the specific part of the paper being addressed, making the grounding strong. The reviewer also makes a judgment about the paper's clarity, which is a specific point about the paper's content.", "verifiability_rationale": "The reviewer makes a claim about the missing definitions of W1 and W2. They suggest that the authors should define these variables. This claim is verifiable by pointing to the lack of information in the paper. The reviewer's suggestion, while not a direct reference to external evidence, is a logical step based on the identified lack of information.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by pointing out the missing definitions of W1 and W2. This is a specific and actionable piece of feedback that could help the authors improve their draft. While it might not be the most comprehensive feedback, it is certainly helpful in addressing a specific technical detail."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential limitation in the model's assumption about data aggregation, suggesting that the model assumes averaging while realworld data might use other methods like summation or populationweighted averages. While this points to a potential issue, the reviewer does not explicitly state the action the authors should take. The authors would need to consider whether their data aggregation method aligns with the model's assumption and potentially adjust their model or interpretation accordingly. The action is implied rather than directly stated.", "grounding_specificity_rationale": "The reviewer provides specific terminology and details related to the model, such as 'bag observation model,' 'spatial aggregation process,' 'averaging,' 'summation,' 'population weighted average,' and 'rate per the number of residents.' These terms directly refer to specific parts of the paper or concepts. The reviewer also mentions that the formulation assumes averaging, which is a specific detail within the model description. This indicates a high level of grounding specificity as the reviewer clearly identifies the relevant aspects of the paper or methodology being discussed. The reviewer is not just making a general comment but is referencing specific technical details.", "verifiability_rationale": "The reviewer makes a claim about a potential discrepancy between the model's assumption of averaging and the actual data aggregation methods used in practice for disease incident data (e.g., counts, rates). This is a claim that needs verification. The reviewer does not provide explicit logical reasoning or external references to support this claim. While the reviewer suggests alternative aggregation methods, they do not explain *why* they believe the averaging assumption is problematic or provide evidence to back this up. Therefore, the verifiability is somewhat lacking as the claim is presented without strong supporting arguments or references.", "helpfulness_rationale": "The reviewer's comment raises a valid point about the assumptions made in the model and suggests that these assumptions might not align with realworld data aggregation practices. This is a valuable observation that could encourage the authors to critically examine their model and consider alternative approaches or interpretations. However, the reviewer does not provide specific suggestions or guidance on how the authors should proceed. While the comment is relevant and prompts critical thinking, it does not directly instruct the authors on what to do next. Therefore, the helpfulness is somewhat limited as the reviewer raises a point but does not provide concrete actions or solutions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential limitation of a fixed policy in reinforcement learning. While the action itself (identifying a potential limitation) is explicit, the reviewer doesn't specify *which* policy is fixed, making the action somewhat vague on how to apply it to a specific part of the paper. The reviewer suggests that in more complex RL scenarios, the policy might not be fixed, implying a lack of actionable detail on how to modify the policy itself.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly tied to a specific section, table, figure, or unique aspect of the paper. The comment is more general, referring to the *nature* of RL policies and the potential for more complex tasks. While the concepts are relevant to the paper's topic, the lack of a direct link to a specific part of the work makes the grounding weak. The comment is also somewhat specific in its suggestion to compare with a reinforcement learning algorithm baseline, but this specificity is within the broader context of RL rather than a precise reference to a paper element.", "verifiability_rationale": "The reviewer's comment presents a claim about the potential limitations of a fixed policy in RL, particularly in complex scenarios. However, the claim lacks specific examples or references to external works to support the assertion. While the reasoning is logical (that a fixed policy might not be sufficient for evolving policies in complex RL tasks), the lack of concrete evidence or references makes the claim somewhat underjustified.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the limitations of a fixed policy in RL, particularly in complex scenarios. This could be helpful for the authors to consider when designing their own RL systems. However, the comment primarily highlights a potential issue without offering concrete solutions or specific steps to address it. The suggestion to compare with a reinforcement learning algorithm baseline is a potential action, but the comment itself doesn't provide a clear, actionable plan for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a weakness ('Incomplete study') but does not explicitly state the action to be taken. While it implies the need for further investigation, the specific steps are not outlined.", "grounding_specificity_rationale": "The comment refers to 'the top selected patches' and 'the disease', which implicitly points to specific parts of the paper. While it doesn't explicitly name a section or table, the context suggests a specific area of the study. The issue ('the relationship between the top selected patches and the disease is not yet established') is also clearly stated.", "verifiability_rationale": "The comment contains a claim ('the relationship between the top selected patches and the disease is not yet established') but does not provide any supporting evidence or logical reasoning to back it up. It's a statement of observation rather than a claim that is verified.", "helpfulness_rationale": "The comment identifies a significant gap in the study by pointing out the missing relationship between the identified patches and the disease. This is likely to prompt the authors to reevaluate their analysis and potentially expand their study, indicating a helpful direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out specific weaknesses in the evaluation methodology, such as the use of synthetic data and the comparison with method 5. While these points are valid criticisms of the evaluation, they don't inherently make the *review point itself* 1. The reviewer clearly identifies areas for improvement in the evaluation, which can guide authors on how to strengthen their own evaluation methods. The suggestions provided by the reviewer, such as using realworld data or considering the limitations of 5's approach, are concrete actions authors can take.", "grounding_specificity_rationale": "The reviewer mentions 'synthetic data' as a limitation of the evaluation. This directly relates to grounding specificity. While the reviewer doesn't explicitly state they cannot confidently determine which part of the evaluation is being addressed, the mention of 'synthetic data' suggests a lack of clear grounding in the *context of the review itself*. The criticism is about the *data used for evaluation*, not necessarily a lack of grounding in the *review process*.", "verifiability_rationale": "The reviewer states that the numerical evaluation is 'not fully convincing' and that the comparison with 5 is 'not completely fair'. This directly relates to verifiability. The reviewer is expressing an opinion about the limitations of the evaluation's conclusions, and the reasons provided (synthetic data and different problem complexity) do not provide strong evidence or justification for the evaluation's claims. The comparison highlights a difference in assumptions or problem complexity, making the direct comparison less convincing.", "helpfulness_rationale": "The reviewer's statement directly addresses the helpfulness of the review point. They explicitly state that the evaluation is 'not fully convincing' and that the comparison with 5 is 'not completely fair'. This indicates a lack of meaningful feedback or justification for the evaluation methodology. The reviewer is essentially criticizing the value of the information provided in the review point."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "X", "actionability_rationale": "The reviewer explicitly states their lack of understanding regarding the relaxed sampling and the differences in the algorithms. This is explicit in identifying areas of confusion. The reviewer points to specific algorithmic components (\u03b2, QRS, RS) as the source of their confusion, making the actions clear but the lack of explanation for those actions also makes it somewhat vague on how to apply them.", "grounding_specificity_rationale": "The reviewer mentions 'Algorithm 1' and specific components within it (\u03b2, QRS, RS). This indicates some level of grounding as they are pointing to a specific part of the paper. However, they do not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The reviewer also does not specify what needs to be addressed in this part. The issues are not clearly defined, making it underspecific.", "verifiability_rationale": "The reviewer makes claims about the authors' lack of understanding and the absence of a difference between QRS and RS. However, the reviewer does not provide any evidence or reasoning to support these claims. There is X being evaluated for verifiability in the sense of a statement needing justification. The claims are presented as observations of the authors' perceived shortcomings.", "helpfulness_rationale": "The reviewer's comments are framed as questions and requests for clarification, not as actionable suggestions for improvement. They are asking *why* something was done (or shouldn't have been done) rather than offering solutions or further guidance to the authors. The review points out weaknesses but doesn't offer concrete solutions or improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests a comparison in terms of computation cost and running time. This is an explicit action, as the reviewer directly states what they want to compare. However, the action is vague. The reviewer does not specify which comparison to make (e.g., between different algorithms, different hardware configurations, or different implementation approaches). Furthermore, the reviewer does not provide any concrete details on how this comparison should be conducted. The lack of specificity makes it difficult for the authors to understand the exact nature of the suggested comparison and how to address it.", "grounding_specificity_rationale": "The reviewer's comment is 1 as it does not explicitly refer to a specific part of the paper or a unique element. The comment is a general suggestion about comparisons. The comment is also underspecific as it does not specify what kind of comparison to make or how to approach it. The reviewer is making a suggestion about a general aspect of efficiency without pinpointing a specific detail within the paper that needs improvement.", "verifiability_rationale": "The reviewer's comment does not contain a claim that requires verification. The comment is a suggestion for improvement, not a statement that needs to be proven or justified. While the suggestion is relevant to the paper's efficiency, it is presented as a suggestion rather than a claim that needs supporting evidence. There is no logical reasoning, common knowledge, or external reference provided to support the suggestion itself.", "helpfulness_rationale": "The reviewer's comment is 3 as it points out a relevant aspect of the paper (computation cost and running time) that could impact its efficiency. The suggestion encourages the authors to consider these factors, which could lead to improvements. However, the comment lacks the specifics needed to be fully helpful. The authors would not know exactly what kind of comparison to make or how to implement the suggested considerations. The vagueness limits the actionable insights provided by the review point."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'no comparison against baselines' and provides a clear action: 'The reviewer suggests comparing against established methods in binary analysis and similarity comparison.' The reviewer also explains *why* this is important: 'This is a widelyunderstood binary analysis application and many papers have developed architectureagnostic similarity comparison (or often reported as codesearch, which is a similar task).'", "grounding_specificity_rationale": "The reviewer clearly identifies the area of comparison: 'binary analysis and similarity comparison'. This can be inferred from the context of the paper, and the reviewer even provides more specific subareas: 'architectureagnostic similarity comparison' and 'codesearch'. While the exact papers are not mentioned, the *field* of comparison is welldefined.", "verifiability_rationale": "The reviewer provides a claim: 'The functionality similarity comparison study reports only accuracy across optimization levels of binaries, but no baselines are considered.' The reviewer also provides verification by stating: 'This is a widelyunderstood binary analysis application and many papers have developed architectureagnostic similarity comparison (or often reported as codesearch, which is a similar task).'", "helpfulness_rationale": "The reviewer's point is highly relevant to the field of binary analysis and directly addresses a gap in the paper's evaluation. By highlighting the lack of comparison to existing similarity comparison methods, the reviewer provides a clear direction for future work and helps the authors understand the context of their findings."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue: 'In the abstract the authors require the proposal distribution to upper bound the target everywhere which is not true as the authors themselves clarify in the text.' This is a direct and clear identification of a flaw in the abstract. The reviewer identifies the specific claim in the abstract that needs correction.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'the abstract' of the paper. This is a strong form of grounding, as the reviewer directly identifies the specific section or part of the paper being addressed. The reviewer also clearly specifies the *nature* of the issue: 'require the proposal distribution to upper bound the target everywhere which is not true'. This specificity indicates a clear understanding of what is wrong in that abstract section.", "verifiability_rationale": "The reviewer makes a claim about the abstract's content: 'the abstract the authors require the proposal distribution to upper bound the target everywhere which is not true'. This claim is verifiable based on the reviewer's statement and their subsequent clarification in the text. However, the verifiability is limited to the reviewer's interpretation and the subsequent clarification. There is no external reference or detailed explanation within the review point itself to support this claim. The verifiability relies on the assumption that the reviewer's clarification is accurate.", "helpfulness_rationale": "The reviewer identifies a specific issue in the abstract: the incorrect claim about the proposal distribution. This identification of a flaw makes the review 3 as it points out a concrete problem that needs addressing. However, the review does not offer any suggestions for improvement or correction. The helpfulness is limited to highlighting the error without providing actionable steps for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, which doesn't directly state an action or suggestion. However, the reviewer implicitly suggests that the section's intent needs clarification, implying a desire for the author to understand or improve the section. This makes the action implicit. The lack of specific details makes it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Section 5.2', which clearly grounds the comment to a specific part of the paper. The comment identifies the section, indicating full grounding. However, the comment doesn't specify *what* is wrong with the section's intent, making it underspecific.", "verifiability_rationale": "The review point is a question, not a statement making a claim or suggesting a change. Therefore, it doesn't contain a claim that can be verified. It's classified as 'X'.", "helpfulness_rationale": "The review point is a question, which provides information but doesn't directly tell the author what to change or why something is problematic. It lacks concrete feedback and actionable suggestions, making it not very helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies two key issues: (1) the need for clarification on how the approach handles the interaction between knowledge about objects and verbs, and (2) the paper's rapid transition to technical details without adequately explaining the overall approach and its benefits. While the reviewer points to specific areas needing clarification, the action taken by the authors to address this could be more explicit. For instance, the authors could have provided a more detailed explanation of the interaction mechanism or a concrete example illustrating how the approach overcomes reporting bias. The reviewer's suggestion to slow down the technical introduction is also a concrete action the authors could take. However, the reviewer's point does not explicitly state what action they are suggesting, making it somewhat vague in terms of implementation.", "grounding_specificity_rationale": "The reviewer's comment refers to the 'overall approach' and 'why it is a good idea' without specifying a particular section, table, or figure of the paper. They mention the interaction between object knowledge and verb knowledge, which could be considered a specific aspect, but they don't explicitly identify the section where this interaction is discussed or defined. The reviewer's comment is a general statement about the paper's structure and content, lacking precise grounding within the document. The lack of a clear reference point makes it difficult to determine exactly what aspect the reviewer is referring to.", "verifiability_rationale": "The reviewer makes a claim that the paper 'gets very quickly into highly technical details, without clearly explaining the overall approach and why it is a good idea.' This is a verifiable claim as the reviewer provides a specific observation about the paper's structure and content. The claim is supported by the reviewer's statement about the rapid introduction of technical details and the lack of explanation of the overall approach. While the reviewer doesn't provide specific examples or references to support this claim, the statement itself is a logical deduction based on the described scenario.", "helpfulness_rationale": "The reviewer's comment raises concerns about the clarity and structure of the paper, specifically regarding the interaction between object and verb knowledge and the transition to technical details. This is a helpful comment as it directly points to areas where the authors can improve their work. The reviewer's feedback is actionable in the sense that it highlights specific aspects of the paper that need attention. However, the comment is somewhat general and doesn't provide specific suggestions for improvement. The authors would need to interpret the reviewer's feedback and then formulate specific actions based on this general feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the ChatGPT baseline is 'rudimentary' and suggests that 'including the discourse relation information in the prompts (probably in a ChainofThought style approach) might yield good results.' These statements directly point to areas where the authors could improve their draft. The suggestions, while not fully detailed, are clear and actionable, indicating a desire for specific changes. The 'extraneous' claim, however, reduces the overall actionable potential.", "grounding_specificity_rationale": "The comment states that the ChatGPT baseline is 'rudimentary' and that 'including the discourse relation information in the prompts (probably in a ChainofThought style approach) might yield good results.' The first part, 'rudimentary,' is a general assessment and could be interpreted in various ways, making it weakly grounded. The second part, suggesting ChainofThought, is a general prompting strategy and doesn't specify the exact implementation, also making it weakly grounded. The claim that it is 'extraneous to their line of evaluation' is 1 at all, as it doesn't relate to the paper's specific goals.", "verifiability_rationale": "The review point makes claims about the rudimentary nature of the ChatGPT baseline and the potential benefits of different prompting strategies (specifically mentioning discourse relations and ChainofThought). These claims are opinions or suggestions, not verifiable facts. There is no logical reasoning or external references provided to support these claims. The 'extraneous' claim is also not verifiable.", "helpfulness_rationale": "The review point offers suggestions for improvement, such as recommending a more sophisticated baseline and exploring different prompting strategies like incorporating discourse relations and ChainofThought. These suggestions are generally helpful and point towards concrete changes the authors could make. However, the claim that this is 'extraneous to their line of evaluation' is not helpful, as it undermines the value of the other suggestions. The mixed nature of the points makes the overall helpfulness somewhat limited."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that they are 'not clear' on the numbers of parameters. This directly indicates an explicit action that needs to be taken \u2013 to clarify the numbers of parameters. The reviewer is directly identifying a missing piece of information and how to obtain it. Therefore, this is a concrete action that can be taken.", "grounding_specificity_rationale": "The reviewer refers to 'numbers of parameters used in each approach' and specifically asks for clarification on this information. This directly points to a specific part of the paper (Section B.3) and asks for details about a specific implementation aspect. The reviewer is not making an assumption or inferring the information; they are directly referencing a section and asking for a specific numerical detail. Therefore, the grounding is fully specific.", "verifiability_rationale": "The reviewer is stating their lack of clarity, which is a statement of opinion or judgment about the paper. They are not making a claim that requires verification. Therefore, this falls under the 'X' category.", "helpfulness_rationale": "The reviewer explicitly states they are 'not clear' on the numbers of parameters. While this points to a specific area needing clarification, it doesn't identify a flaw or suggest a concrete improvement. The feedback is specific but doesn't directly address a weakness or propose a solution. Therefore, it is 3 in identifying a need for clarification, but not in providing actionable feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what is wrong with the evaluation or suggest a specific action to take. It only criticizes the small number of trials and the interpretation of the deviations. Therefore, the actionability is low as the authors are not given a clear direction on how to improve their work based on this review.", "grounding_specificity_rationale": "The reviewer mentions 'evaluation results' and 'statistical significance' but does not pinpoint a specific part of the paper or methodology that needs improvement. The grounding is weak because the authors cannot confidently determine which aspect of the evaluation is flawed. The specificity is also low as the reviewer does not detail what needs to be addressed in this general area.", "verifiability_rationale": "The reviewer makes a claim that the evaluation results are not statistically significant based on only three trials. This claim can be verified by understanding the statistical principles of small sample sizes and the interpretation of deviations from expected results. While the reasoning is general, it provides a basis for understanding the issue.", "helpfulness_rationale": "The review point is critical and points out a flaw in the experimental design and interpretation. While it is helpful to identify issues, the lack of specific guidance on how to address the problem makes it less helpful. The reviewer does not offer concrete suggestions or propose alternative approaches."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the architecture is 'not clearly explained' and 'refers to Jiang et al. (2019) for details'. This indicates an implicit action, as the reviewer desires a clearer explanation. The action is also somewhat vague, as the reviewer doesn't specify what part of the architecture needs clarification. While the reviewer doesn't explicitly state they want a stepbystep breakdown, the criticism implies a lack of sufficient detail, which is a form of vagueness in action implementation.", "grounding_specificity_rationale": "The reviewer states the architecture is 'not clearly explained' and 'refers to Jiang et al. (2019) for details'. This means the authors cannot confidently determine which part of the paper is being addressed by the reviewer's comment. The comment does not specify what needs to be addressed in this part, making it 'not specific'.", "verifiability_rationale": "The reviewer makes a claim that the architecture is 'not clearly explained' and 'refers to Jiang et al. (2019) for details'. This claim is not supported by any evidence or reasoning within the review point itself. The reviewer is stating a problem without providing any logical justification or external references to back it up. The reference to Jiang et al. (2019) is presented as a solution to the reviewer's problem, not as evidence to support the claim that the current explanation is lacking.", "helpfulness_rationale": "The reviewer directly criticizes the lack of explanation of the architecture and calls for a reference to Jiang et al. (2019). This is a clear and actionable feedback for the authors, highlighting a specific area where the paper falls short. The reviewer's statement is a direct assessment of the paper's clarity and completeness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer provides specific examples of presentation issues, such as 'Figs 1&2', 'tables with a \"\"', and the 'Management of Fig 3 and Table 2'. These examples indicate that the authors should specifically look at these figures and tables and address the identified problems. While the reviewer doesn't explicitly state 'improve the figures', the concrete examples make the action somewhat clear.", "grounding_specificity_rationale": "The reviewer explicitly names specific parts of the paper being criticized, such as 'Figs 1&2', 'tables with a \"\"', and the 'Management of Fig 3 and Table 2'. This clear identification of the specific elements allows the authors to directly address the issues. The 'Dataset' column in tables is also a specific area of concern. The use of quotes around the hyphen indicates the reviewer is aware of the specific formatting issue, further grounding the feedback.", "verifiability_rationale": "The reviewer states that 'Some aspects in the presentation quality of this paper are a weakness for a high quality publication' and provides specific examples. However, the reviewer does not provide any evidence or reasoning to support these claims. They are stating their belief that these are weaknesses, but without pointing to specific instances of poor presentation or citing external references, the claim is not verifiable.", "helpfulness_rationale": "The reviewer clearly identifies areas where the presentation could be improved. While they don't explicitly ask for specific changes or modifications, the criticism is very actionable and directly points to concrete areas the authors can examine. The examples provided, like 'Figs 1&2' and 'tables with a \"\"', directly indicate what the authors should focus on. This provides a clear direction for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states: 'Therefore, the results simply appear to indicate that 'better NMT systems are also better at idiomatic translations'. This is a clear and direct statement of what the authors should do with the results. The reviewer provides a specific interpretation and suggests an alternative explanation. This is an explicit statement that guides the authors on how to interpret their findings.", "grounding_specificity_rationale": "The review point focuses on the *results* of the experiments (similar impact on idiomatic vs. random data) and draws a conclusion about the MT modeling methods. While it doesn't directly pinpoint a specific section or table in the paper, it's based on the *findings* of the experiments. The reviewer is implicitly referring to the *results* as the specific part being addressed. The reviewer clearly states the observation about the similar impact on idiomatic vs. random data and draws a conclusion about the MT methods. This suggests a clear understanding of the issue being addressed, even if not a perfectly explicit section reference.", "verifiability_rationale": "The review point makes a claim: 'Therefore, the results simply appear to indicate that 'better NMT systems are also better at idiomatic translations'. This claim is based on the interpretation of the existing experimental results presented in Figure 3. While the claim itself isn't explicitly supported by new evidence or references within the review point, it's a logical deduction based on the presented data. The reviewer doesn't provide external references to support this claim, making it rely on the interpretation of the authors' own results.", "helpfulness_rationale": "The review point clearly identifies a potential issue with the proposed upweighing and KNN methods. The reviewer states that the results suggest these methods are not idiomspecific and that the observed impact on idiomatic vs. random data is similar. This directly points out a weakness in the proposed approach and offers an alternative interpretation of the findings. This is a valuable piece of feedback that directly addresses a potential area for improvement in the authors' work. The reviewer provides a specific criticism and a potential alternative explanation, which is valuable information for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an action (cite and discuss) but doesn't specify how to apply it or what references are needed. The action is implied but not explicitly stated in detail.", "grounding_specificity_rationale": "The review refers to 'important references for domain adaptation' without specifying which part of the paper or unique element they are addressing. The references are mentioned generally.", "verifiability_rationale": "The review contains a claim ('This paper lacks some very important references for domain adaptation') and provides a suggestion ('The authors should cite and discuss in the revised manuscript') to address it. However, the suggestion lacks specific references or examples of how to discuss them.", "helpfulness_rationale": "The review identifies a weakness (lack of important references) and suggests an improvement (cite and discuss). While the suggestion is helpful, it lacks specific details about which references are needed and how they should be integrated. The feedback is relevant but lacks concrete implementation details."}
{"actionability_label": "2", "grounding_specificity_label": "1 and UnderSpecific", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a claim about PACE being a 'diagnostictype prediction' but doesn't explicitly state what is being diagnostic or how this differs from existing diagnostic approaches. The reviewer also doesn't provide concrete steps for the authors to take.", "grounding_specificity_rationale": "The reviewer states a claim about PACE being a 'diagnostictype prediction' without explicitly referring to any specific part of the paper being addressed. The reviewer's statement is general and doesn't pinpoint where the diagnostic aspect is being discussed in the paper.", "verifiability_rationale": "The claim extraction step identifies a claim in the review point: 'the claim that 'To address this gap, we propose PACE, which treats climate emulation as a diagnostictype prediction' is misleading without making clear that prior work (e.g. ClimateBench or ClimateSet) does exactly this.' This claim is verifiable through the provided references to ClimateBench and ClimateSet, which are external sources that support the claim.", "helpfulness_rationale": "The review point identifies a potential misrepresentation of PACE's novelty compared to existing diagnostic methods. However, it stops short of providing a clear explanation of PACE's specific diagnostic capabilities or how it differs from ClimateBench/ClimateSet. The reviewer's point is relevant to the authors' understanding of PACE's contribution, but the lack of detailed explanation limits its helpfulness in guiding the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer states that using 'r' for both minimization problems and primal risk for minimax problems is confusing. This is an explicit statement of a lack of clarity, indicating that the notation is not welldefined or easily distinguishable. While the reviewer doesn't provide specific suggestions for improvement, they clearly identify a problem that needs addressing. Therefore, the actionability is 3 as the authors can infer the need for clarification on the notation.", "grounding_specificity_rationale": "The reviewer specifically mentions 'r' for minimization problems and 'primal risk' for minimax problems. This directly points to specific elements within the paper and how they are being discussed. The reviewer is not making a general comment about a section but rather referring to specific notation and concepts. Therefore, the grounding is fully grounded as the reviewer can accurately pinpoint the referenced part of the paper. The specificity is also high as the reviewer clearly identifies the issue with the notation.", "verifiability_rationale": "The reviewer makes a claim about a specific issue in the paper: 'using r to denote the risk for minimization problems and primal risk for minimax problem at the same time is confusing.' This claim can be verified by examining the notation used in the paper. The reviewer provides a specific example of a potential ambiguity, making it verifiable. The claim is directly about the paper's content and is based on a clear observation. Therefore, the verifiability is 5 as the claim is directly supported by the paper's content and is a clear observation.", "helpfulness_rationale": "The reviewer states that the point is 'confusing.' This directly points to a potential source of error or ambiguity for the author. The reviewer's point is clear and directly addresses a potential issue in the paper's presentation. Authors would likely appreciate clarification on notation. The point is specific enough that the author can focus their attention. Therefore, the helpfulness is 5 as the reviewer clearly identifies a potential problem that needs addressing."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states \"making the factors in a table does not help convey more messages than pure text.\" While this is a suggestion for improvement, it is not explicitly stated. The reviewer implies that the table is not effective, but does not specify what needs to be done. Therefore, it is implicitly suggesting an action, but the action is vague. This makes it **3**.", "grounding_specificity_rationale": "The reviewer makes a general statement about tables not being effective in conveying more messages than text. They do not identify a specific part of the paper (like a table number or a section) where this issue is occurring. The statement is about the table's overall effectiveness, not a specific element within it. Therefore, the comment is 1 in a specific part of the paper. This makes it **1**.", "verifiability_rationale": "The reviewer states \"making the factors in a table does not help convey more messages than pure text.\" This is a claim that something is not the case. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. They simply state it as a fact. Therefore, the claim is not wellsupported. This makes it **1**.", "helpfulness_rationale": "The reviewer's comment identifies a potential issue with tables \u2013 that they don't convey more messages than text. While this points out a weakness, the reviewer does not offer any suggestions or actionable steps to improve the table's effectiveness. The comment is a critique without a constructive solution. Therefore, it is not very helpful for the author. This makes it **2**."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the authors 'do not mention anything about potential necessity to find global top Q values of the metric over the average of gradients.' This is a clear and direct criticism of the authors' lack of attention to a specific detail. The reviewer also implies that this omission is actionable, suggesting that the authors should investigate this further. The statement is precise and directly points to a missing element, making it 5.", "grounding_specificity_rationale": "The reviewer explicitly states 'authors do not mention anything about potential necessity to find global top Q values of the metric over the average of gradients.' This directly identifies the specific part of the paper the authors should be referring to. The reviewer provides a concrete example of what is missing, making the grounding specific. The authors can easily identify the missing detail by looking for where they discuss distributed training or optimization metrics. The information is directly stated, indicating strong grounding.", "verifiability_rationale": "The reviewer makes a claim: 'This will potentially break big portion of acceleration techniques, such as quantization and sparsification.' This claim is supported by the reasoning that a lack of consideration for global metrics over average gradients could lead to issues when applying these techniques. While the reasoning isn't fully explicit, the consequence (breaking acceleration techniques) is clear and directly related to the missing information. The reviewer provides a logical connection between the missing detail and the potential problem, making the claim 3.", "helpfulness_rationale": "The reviewer provides a specific point for the authors to investigate, which is the necessity of finding global top Q values. This is a valuable piece of information that could guide the authors' implementation of distributed training. The reviewer also highlights a potential negative consequence (breaking acceleration techniques), which is a helpful warning for the authors. While the review doesn't offer a complete solution, it points the authors towards a specific area of investigation and highlights a potential problem, making it 5 in identifying areas for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment directly points out a factual error in the reviewer's understanding of relation classification. It states, 'Lines 2627: Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.' This clearly identifies an actionable issue.", "grounding_specificity_rationale": "The comment explicitly states, 'Lines 2627: Multiple entities typically exist in both sentences and documents and this is the case even for relation classification...'. This directly identifies the problem and the area of concern, making it fully grounded. The reviewer is also implicitly informed about the typical structure of relation classification.", "verifiability_rationale": "The comment is a factual statement. While it doesn't provide external references, the logic is clear and aligns with common knowledge in NLP. The reviewer can understand that a relation needs a subject and an object, not just a single entity. The comment is logically sound and doesn't require external verification to be understood.", "helpfulness_rationale": "The comment is concise, directly addresses a likely misunderstanding, and empowers the reviewer to provide more comprehensive explanations. The reviewer is given a clear example of relation classification (subject, object, relation). This feedback is actionable and directly addresses a potential point of confusion for the reviewer."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests removing RQ1 and proposes an alternative analysis. While the reviewer indicates a preference for the alternative analysis, the suggestion to remove RQ1 is an implicit action. However, the reviewer does not specify *how* RQ1 should be moved or *what* it should be replaced with. The action is present, but lacks concrete details, making it 2.", "grounding_specificity_rationale": "The reviewer mentions 'RQ1' but does not specify which part of the paper or section it refers to. They also do not detail the specific issue with RQ1's redundancy. The alternative analysis idea is general and lacks a clear connection to a specific part of the paper. Therefore, the comment does not identify a specific area in the paper being addressed.", "verifiability_rationale": "The reviewer states their opinion about RQ1's redundancy but does not provide any evidence or justification for their claim. They also do not explain how the provided reference link supports their assertion. The claim is presented without supporting reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer clearly states their opinion that RQ1 is redundant and suggests an alternative analysis. This provides some direction for improvement and offers a potential solution. However, the reviewer does not elaborate on the specific issues with RQ1 or provide concrete suggestions for its removal or replacement. The feedback is present but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests a potential simplification in the LSTM architecture for both pretraining and finetuning. While the suggestion is concrete in terms of adding an output head for value functions, the *specific* implementation details are not provided. The reviewer implies a *possible* action rather than a clearly defined one. Therefore, while the suggestion points towards a concrete change, the lack of specific details makes it 2.", "grounding_specificity_rationale": "The reviewer mentions 'standard RL practices' and 'adding another head to the network computing the value functions.' While the general idea is understandable, the reviewer does not explicitly point to a specific section of the paper where this change would be applied. The suggestion to add a 'value function head' to an LSTM is somewhat vague and lacks precise location or implementation details. Therefore, the grounding is weak, and the specificity of the suggestion is limited.", "verifiability_rationale": "The reviewer suggests a potential simplification based on the understanding of standard RL practices. The *reasoning* behind this suggestion is based on the goal of simplifying the LSTM architecture. However, there is no explicit citation of external works to support this specific suggestion. While the general idea of simplifying RL algorithms is common knowledge, the lack of specific references makes it difficult to assess the verifiability definitively. The reviewer's suggestion is plausible, but the lack of strong external support makes it 3.", "helpfulness_rationale": "The reviewer suggests a potential simplification in the LSTM architecture, which could be beneficial for reducing complexity and improving efficiency in RL implementations. This is a valuable suggestion for authors looking to implement RL. However, the *rationale* for why this is helpful is brief and doesn't delve into the potential benefits (e.g., faster training, easier debugging, reduced computational cost). While the suggestion points towards a positive outcome, the lack of a detailed explanation of the benefits makes it 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests 'it would be good to acknowledge some of the older works too.' While this implies an action (acknowledging older works), it lacks specific guidance on *how* to achieve this. The reviewer doesn't provide concrete steps or examples of how to incorporate these older works. Therefore, the action is explicit but lacks detail on implementation.", "grounding_specificity_rationale": "The reviewer mentions 'related works' generally, without specifying a particular section, table, figure, or unique aspect of the paper. The suggestion is broad and doesn't pinpoint the exact location or nature of the missing information. The reviewer doesn't provide any specific examples or references within the 'related works' section. Therefore, the grounding is weak as the specific part isn't identified.", "verifiability_rationale": "The reviewer states 'it would be good to acknowledge some of the older works too.' This is a suggestion or a desire for improvement, not a claim that something is missing, flawed, or requires verification. There is no assertion that the current related work section is lacking in any specific way that needs to be proven. Therefore, there is X being made.", "helpfulness_rationale": "The reviewer suggests 'it would be good to acknowledge some of the older works too.' This points towards a concrete improvement in the related work section, specifically suggesting better organization. While the suggestion is vague on the *method* of acknowledgment, it clearly indicates a desired change and provides a direction for the author to take. The reviewer is not criticizing the current state but offering a constructive suggestion for improvement. Therefore, the review provides a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer's confusion is implicit. While the reviewer states their confusion, the actionability of identifying the discrepancy between the expected and observed performance of the sampling methods is not explicitly stated. The reviewer is asking *why* uniform sampling isn't clearly superior, not just *that* it isn't. The actionability could be improved by explicitly stating the expected outcome and how the results deviate from it.", "grounding_specificity_rationale": "The reviewer's confusion is not about *identifying* the specific part of the paper being addressed (the experimental setup). However, the confusion is about *interpreting* the results and the expected outcome. The grounding is implicit in the discussion of the results, but it's not explicitly pinpointing the relevant section or table. The reviewer is asking for a clearer explanation of *why* the results are surprising.", "verifiability_rationale": "The reviewer questions the authors' claim that the decaying methods should be better if the predictor is accurate in the highperforming region. This suggests a lack of clear justification for the authors' interpretation of the results. The verifiability is limited because the reasoning behind the expected superiority of decaying methods is not explicitly and robustly presented. The authors could strengthen their claim by providing a more detailed explanation of the expected outcome and the supporting evidence.", "helpfulness_rationale": "The reviewer's confusion is a valuable feedback point for the authors. It highlights a gap in the authors' explanation of the experimental results and their interpretation of them. This feedback is helpful because it directly points to an area where the authors' communication could be improved to better guide the reader (and potentially the authors themselves) in understanding the results."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states their intention to clarify how the SE framework can help but does not specify the exact improvement or action to be taken. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer does not identify a specific part of the paper or aspect of their work that the SE framework is intended to improve. The reference is general.", "verifiability_rationale": "The review point is a request for information, not a claim that something is true or false. Therefore, it is not verifiable as a statement.", "helpfulness_rationale": "The review point does not provide any actionable feedback or suggestions to the authors. It is a request for clarification, not a helpful comment."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states the criticism of the chosen metrics and the suitability of these metrics for datasets with known task boundaries. It also points out the unsuitability of these metrics for datasets without clear task boundaries. The action is clear: criticizing the metrics. The information is directly provided in the comment.", "grounding_specificity_rationale": "The comment attempts to ground the criticism in the specific metrics mentioned (continual learning, loss after switch, recovery time after switch) and the characteristic of the dataset (lack of clear task boundaries). However, it does not explicitly point to a specific section of the paper where this issue is discussed. The grounding is implied rather than literal. The specificity is evident as it clearly identifies the metrics and the dataset characteristic as the basis of the criticism.", "verifiability_rationale": "The comment makes a claim that the chosen metrics are not suitable for datasets without clear task boundaries. However, it does not provide explicit reasoning or references to support this claim within the provided text. The claim is asserted without immediate justification.", "helpfulness_rationale": "The comment identifies a potential issue with the evaluation methodology by pointing out the limitations of the chosen metrics for certain types of datasets. While it highlights a problem, it doesn't actively propose alternative metrics or suggest concrete improvements to the current approach. Therefore, it's more of a critique than a constructive suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the concern about the calculation of d_lambda and its potential impact on the sketching approach. They also point out that this issue is not discussed in the paper. The reviewer identifies a specific area of the method (the calculation of d_lambda) and a potential problem (bias in sketching). This is an explicit and concrete concern.", "grounding_specificity_rationale": "The reviewer mentions 'd_lambda' but doesn't explicitly point to a specific section, table, figure, or unique aspect of the paper where this parameter is discussed. While they identify a potential problem (bias in sketching due to inaccurate d_lambda), they don't specify *where* in the paper this issue is relevant. The reviewer implies the issue is with the *method* of calculating d_lambda rather than a specific element within a section.", "verifiability_rationale": "The reviewer makes a claim: 'I couldn't find this issue discussed in the paper.' This is a clear statement of a deficiency in the paper's explanation or analysis. However, the reviewer doesn't provide any evidence or reasoning to support their claim. They identify a gap but don't explain *why* it's not discussed or what the implications might be. The claim is stated but not verified.", "helpfulness_rationale": "The reviewer raises a valid concern about the practicality and potential bias of the proposed sketching approach. They highlight a specific parameter (d_lambda) that needs to be computed and point out that this crucial step is not adequately addressed in the paper. While the reviewer identifies a potential problem, they don't offer any concrete solutions or suggestions. The impact of this missing information on the authors' ability to implement the method is a valid concern, making the review potentially helpful in identifying a gap in the paper's explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'the error analysis on the movie dataset is missing' and 'what are the cases that such model fails.' These are direct statements about a deficiency, making the action clear. The reviewer implies the authors should perform this analysis, indicating a concrete action to be taken. Therefore, the review point is actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'the movie dataset' and asks about 'the cases that such model fails.' This directly identifies the specific part of the paper being addressed, making the grounding very clear. The language is precise and directly refers to the dataset and the nature of the deficiency. Therefore, the grounding is fully specific.", "verifiability_rationale": "The review point makes a claim about the missing error analysis and the need to know the failing cases. While it doesn't provide specific examples of errors, it clearly states what is missing and what information is required. This makes the claim 3 as it points to a specific area that needs further investigation. The reviewer is not asking for a solution, but rather for the identification of the problem, which can be verified by examining the model's performance on the movie dataset. Therefore, the claim is 3.", "helpfulness_rationale": "The review point clearly identifies a deficiency ('the error analysis on the movie dataset is missing') and provides a direct suggestion ('In order for other researchers to continue on this task, they need to know what are the cases that such model fails'). This directly points to a concrete action the authors should take. The language is clear and directly addresses the need for further investigation. Therefore, the review point is 5 as it guides the authors on what to do and why."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "1 (1)", "verifiability_label": "X (X)", "helpfulness_label": "2 (2)", "actionability_rationale": "The review point is not actionable because it lacks specific details on how the authors should address the limitations. While it suggests a 'more detailed plan,' this is vague and doesn't provide concrete steps or specifics.", "grounding_specificity_rationale": "The review point is 1 because it does not specify which limitations or parts of the paper are being addressed. It also lacks specificity in its suggestion of a 'detailed plan.'", "verifiability_rationale": "The review point is not verifiable because it does not contain a claim or assertion that anything is incorrect or needs verification.", "helpfulness_rationale": "The review point is not 5 because it only suggests a future action (a detailed plan) without directly addressing any current weaknesses or issues in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the computational cost of FedMITR, which implies an action of comparing costs. However, the question lacks specific details on how to perform this comparison or what benchmarks to use, making the action somewhat vague and not fully explicit.", "grounding_specificity_rationale": "The comment does not specify a particular part of the paper being addressed. It's a general question about the computational cost of a method.", "verifiability_rationale": "The comment itself doesn't contain a claim that requires verification. It's a question about a potential implementation detail.", "helpfulness_rationale": "The comment raises a valid point about the potential lack of comparison of computational costs for FedMITR. This could be helpful for the author to understand the practical implications of using the method, but the suggestion is vague and lacks specific direction."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what action the authors should take. While it suggests an alternative approach, it doesn't specify how to implement it or what exactly needs to be changed. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being criticized. It is a general comment about the writing style. While it implies a potential issue, it doesn't pinpoint the exact location or nature of the problem.", "verifiability_rationale": "The review point contains a claim: 'the writing is too confusing I cannot be sure if that is the case or not.' However, the support for this claim is weak. The suggestion to use a 'generic external knowledge base' is a possible solution, but it is not verified within the paper. The reasoning is vague and lacks specific examples or references.", "helpfulness_rationale": "The review point offers a potential improvement and suggests an alternative approach. However, the specific aspects of the writing that are confusing are not identified. The suggestion is too broad and lacks concrete details on how the authors should implement the change. The feedback is general and lacks actionable steps."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer provides two explicit statements: 'Perplexity is the probability that the model generates the current sentence' and 'Eq1  This does not look like perplexity either, this looks like crossentropy'. Both statements are direct and identify specific areas for improvement. The reviewer clearly states what they believe is incorrect about the paper's content.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'L259' and 'Eq1' in their review point. This demonstrates a clear understanding of the specific location and content being referenced in the paper. The reviewer is not making an inference about what should be discussed, but rather directly points to a specific section and equation.", "verifiability_rationale": "The reviewer presents two claims: 'Perplexity is the probability that the model generates the current sentence' and 'Eq1 does not look like perplexity either, this looks like crossentropy'. While these are valid claims, the reviewer does *not* provide any supporting evidence or justification for these claims within the provided review point. The claims are presented as factual statements without any logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer's review point identifies potential inaccuracies in the paper's description of perplexity and its relation to Eq1. While this points out a problem, it does not explicitly instruct the authors on what changes should be made. The reviewer is highlighting discrepancies without providing clear directions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states 'the model has many components whose hyper parameters are not fully provided.' This directly points to an actionable issue for the authors. While the reviewer doesn't specify *how* to obtain this information, they clearly identify a deficiency that needs addressing. The statement is explicit about the problem and suggests a specific area for improvement (providing hyperparameter details).", "grounding_specificity_rationale": "The reviewer states 'the model has many components whose hyper parameters are not fully provided.' While they mention 'components' and 'hyper parameters,' they don't explicitly identify the *specific section* or *type* of component where this information is lacking. The grounding is present in mentioning components and hyperparameters, but it's not as precise as '3.' The specificity is in mentioning hyperparameters, but the lack of a clear section reference makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer states 'the model has many components whose hyper parameters are not fully provided.' This statement acts as a claim about the state of the model's components. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. It's an observation based on their experience, but without further explanation or evidence, the verifiability is low.", "helpfulness_rationale": "The reviewer's point, while factual, doesn't directly guide the authors on how to improve their draft. They are informing the authors of a potential issue (lack of hyperparameter information) but don't provide specific suggestions or actions for the authors to take. The helpfulness is limited to pointing out a gap, but it lacks concrete guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the authors' claim and identifies the specific errors in it. The phrase 'According to the Central Limit Theorem (CLT), a normally distributed random variable can be produced through a finite linear combination of any random variables' directly quotes the authors' statement. The reviewer then elaborates on the inaccuracies, explaining that the CLT applies to the *sum* of independent and identically distributed random variables as the sample size approaches infinity, not to a finite linear combination of *any* random variables. This provides a clear and actionable point for the authors to improve their understanding of the CLT. While the reviewer doesn't *immediately* suggest a fix, the identification of the error and the explanation of why it's an error make the actionable aspect quite clear.", "grounding_specificity_rationale": "The reviewer provides strong grounding specificity by directly referencing 'line 238' in the authors' paper. This indicates a precise understanding of where the problematic statement is located. Furthermore, the reviewer not only points to the location but also explains the specific flaw in the authors' claim in that context. They explain that the CLT, as typically understood, deals with the convergence of the *sample mean* to a normal distribution under certain conditions (like independence and identical distribution), and the authors' statement misrepresents this by equating Gaussianity with a finite linear combination of arbitrary variables, without mentioning the asymptotic requirement or the independence assumption. This detailed explanation goes beyond simply pointing to a location and delves into the specifics of the error.", "verifiability_rationale": "The reviewer clearly identifies a claim made by the authors: 'According to the Central Limit Theorem (CLT), a normally distributed random variable can be produced through a finite linear combination of any random variables'. The reviewer then provides a logical reasoning to verify this claim. They explain that the CLT, in its standard form, states that the *sample mean* of a large number of independent and identically distributed random variables will be approximately normally distributed. The reviewer correctly points out that the CLT doesn't guarantee Gaussianity in a nonasymptotic regime and that the linear combination needs to be of *independent* and *identically distributed* random variables, not just *any* random variables. This explanation provides a clear justification for why the authors' claim is incorrect, using logical reasoning and common knowledge about the CLT. While the reviewer doesn't cite a specific external reference in this review point, the reasoning itself serves as the verification.", "helpfulness_rationale": "The reviewer's comment is 5 because it directly identifies a specific and important error in the authors' understanding of the Central Limit Theorem. By pinpointing the inaccuracies in the authors' statement, the reviewer provides a clear and actionable feedback. The reviewer explains that the CLT applies to the *sum* of independent and identically distributed random variables as the sample size approaches infinity, not to a finite linear combination of *any* random variables. This explanation helps the authors understand the limitations of the CLT and how to correctly apply it. While the review doesn't explicitly suggest a complete overhaul of the introduction, it provides enough information for the authors to understand what needs to be corrected and how to approach it. The specificity of the feedback, combined with the clear explanation of the error, makes it 5."}
{"actionability_label": "1", "grounding_specificity_label": "X", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer criticizes the proposed method for being less relevant to the authors' motivations in the abstract section, stating that automatic scores are not effective and human evaluation scores are not affordable. This suggests a lack of actionable insights or specific guidance that the reviewer believes is missing from the proposed method. The reviewer's point is not about a specific flaw in the author's work that the review should address, but rather a critique of the evaluation *process itself*.", "grounding_specificity_rationale": "The reviewer's criticism of the proposed method focuses on its overall effectiveness and applicability to single dialogue systems, rather than pinpointing specific sections or aspects of the paper it should address. The reviewer does not provide any information about specific parts of the paper that the review comment should have identified or explained. The criticism is directed at the *evaluation system* and its general utility.", "verifiability_rationale": "The reviewer's critique of the proposed method does not involve making any claims or judgments about the paper itself. The reviewer is expressing a general sentiment about the method's limitations, rather than evaluating the verifiability of specific statements within the paper. There are no explicit claims, opinions, or suggestions about the paper's content or quality.", "helpfulness_rationale": "The reviewer explicitly states that the comment is '1' and provides reasons for this assessment, including the lack of actionable feedback and the critique of the evaluation system. This indicates a strong negative evaluation of the review point's ability to assist the authors in improving their draft. The reviewer is not providing specific suggestions or feedback on the paper itself, but rather criticizing the *evaluation process*."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks a question ('Improvement still be observed...') and suggests a specific alternative to the current encoder (BERT vs. RoBERTabase). This is a clear and direct suggestion, making it explicit. Furthermore, the suggestion is concrete, specifying a different encoder to consider. Therefore, it is 5.", "grounding_specificity_rationale": "The review point directly asks about a specific encoder (BERT vs. RoBERTabase). The authors can easily identify the specific part of the paper being addressed \u2013 the choice of encoder. The comment also clearly specifies what is being asked \u2013 whether improvement can be observed with a better encoder. This is a clear and precise identification of the issue, making it 5.", "verifiability_rationale": "The review point contains a claim (implying that a better encoder could lead to improvement). However, it does not provide any evidence or reasoning to support this claim within the review point itself. The suggestion is based on general knowledge in the field but lacks specific justification or references within the provided text. Therefore, it is 3 as it makes a claim but lacks strong supporting evidence within the review point.", "helpfulness_rationale": "The review point is a valid question that encourages authors to consider alternative model architectures. It directly relates to potential improvements in their current work. While it doesn't provide a definitive answer, it prompts further investigation and exploration of different options. Therefore, it is 3 in guiding the authors towards potential improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a concern regarding the potential 'severe damage to the performance of predictive model' when focusing on 'fair policy learning'. They then suggest showing how to achieve fairness 'without' this negative impact. This is a clear and direct action that the authors can readily identify and apply to their work.", "grounding_specificity_rationale": "The reviewer refers to 'fair policy learning' and the 'performance of predictive model' when identifying the issue. This clearly pinpoints the specific aspect of the paper being addressed, making the grounding explicit and complete. The mention of 'without' further specifies the desired outcome.", "verifiability_rationale": "The reviewer makes a claim about a tradeoff between fairness and predictive performance. While they don't provide a detailed explanation of *how* to show this, the claim itself is a statement that can be supported by evidence or reasoning. The concept of 'severe damage' is a generally understandable and verifiable idea in the context of model performance.", "helpfulness_rationale": "The reviewer clearly identifies a problem (the potential negative impact on predictive performance) and offers a potential solution (demonstrating how to achieve fairness without severely damaging performance). This directly addresses a likely need for authors working on this type of problem, making the review point 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out the phrase \"a response candidate can meet each utterace\" as being unclear. While the reviewer identifies a weakness, the specific action they should take (e.g., to rephrase the phrase) is not explicitly stated. The reviewer infers the need for clarification, making the action implicit. The reviewer identifies the need for improvement, but the exact nature of the problem is not specified, making the action vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions the phrase \"a response candidate can meet each utterace\" on line 280. This clearly identifies the specific part of the paper being addressed, indicating full grounding. The phrase itself is also clearly specified, making the specificity high.", "verifiability_rationale": "The reviewer makes a claim that the phrase \"a response candidate can meet each utterace\" is \"difficult to understand\". This is a clear statement of a problem. The reviewer also provides a suggestion for improvement by stating that it should be rephrased. This provides logical reasoning and a concrete suggestion, making the claim verifiable.", "helpfulness_rationale": "The reviewer provides a specific example of a grammatical phrasing issue in the paper. They directly point out the problematic phrase and suggest a rephrasing. This actionable feedback is directly aimed at improving the clarity of the paper, making it 5 for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This clearly indicates an intended action: to correct the connections in the figure. The reviewer provides a clear explanation of *why* these specific connections are incorrect, implying a desire for greater accuracy and clarity in the figure. The action is also concrete, as the reviewer specifies *which* images should be connected and *why* the alternative connections are incorrect.", "grounding_specificity_rationale": "The reviewer directly refers to 'Figure 2,' 'Second Inpainted Images,' 'Inpainted Image,' and 'Images Masked by Second Masks.' This demonstrates a high level of specificity. The reviewer not only identifies the relevant parts of the figure but also explains the *purpose* of the connections, making it clear what needs to be fixed. The grounding is literal, as the reviewer points to specific elements within the figure.", "verifiability_rationale": "The reviewer makes a claim about the figure's accuracy, suggesting that the current connections are misleading or incorrect. While they do not provide external references, the claim is based on a logical understanding of how such figures typically represent data or relationships. The implication is that incorrect connections would lead to misinterpretation of the Perceptual Metric. The reasoning, though not explicitly detailed, is present and based on standard practices for presenting such information.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for improvement: correcting the connections in Figure 2. This is directly actionable for the authors, as they would likely need to adjust their interpretation or the figure itself. The reviewer specifies *which* connections are likely incorrect and *why* they are problematic. This level of detail makes the feedback highly valuable and directly applicable to improving the clarity and accuracy of the paper. The reviewer is not just pointing out a problem but also suggesting a concrete solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the inconsistency between Fig 1 and Fig 2 regarding the number of encoderdecoder models. It implies a need to clarify this discrepancy, which can be considered an explicit action. However, the specific details of *how* to resolve this discrepancy are not provided, making it somewhat vague in its actionable nature.", "grounding_specificity_rationale": "The comment explicitly refers to 'Fig 1' and 'Fig 2', clearly identifying the specific parts of the paper being addressed. This strong grounding allows the authors to locate the relevant information. The comment also specifies the *number* of encoderdecoders as the difference, providing specific details about the discrepancy.", "verifiability_rationale": "The comment contains a claim ('Fig 1 is not consistent with Fig 2'). However, it does not provide any justification or evidence for this claim. There is no logical reasoning, common knowledge, or external references provided to support the inconsistency. Therefore, the claim is not verifiable based solely on the information within this review point.", "helpfulness_rationale": "The comment identifies a potential issue with the figure descriptions. It is clear and points to a specific discrepancy. However, it does not provide concrete suggestions or actions for the authors to take. It lacks the constructive and actionable elements that would make it 5. It is more of a diagnostic observation than a prescriptive improvement suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "Weakly Grounded and Partially Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issues: \"unclear main contribution\", \"overstated novelty claims\", \"not clear about the main idea of how the proposed method copes with dynamic largescale multitasking\", and \"unclear automation is achieved\". These are direct statements of what needs to be addressed, making the comment explicit. Furthermore, the reviewer points to specific areas of the paper (novelty, multitasking, automation) and specific aspects within those areas (main contribution, properties, idea, automation), making the action concrete. The reviewer is not inferring these actions but directly pointing out the weaknesses.", "grounding_specificity_rationale": "The reviewer mentions specific areas of the paper (novelty, multitasking, automation) but does not explicitly state the section number, table, figure, or unique element being addressed. The reviewer mentions \"main contribution,\" \"novel properties,\" \"dynamic largescale multitasking,\" and \"automation,\" which are specific aspects within those areas. However, without a clear reference to a specific section or element, the grounding is weak. The comment specifies *what* needs to be addressed but not *where* in the paper.", "verifiability_rationale": "The reviewer states a claim about the paper's contributions and clarity: \"the main contribution of this paper is unclear. Although it claimed that the proposed method possesses 8 novel properties, they either somewhat overstated the ability or applicability of the proposed method or were not wellsupported. The main idea of how the proposed method copes with dynamic largescale multitasking is not clear. How the automation is achieved is also unclear.\" This is a claim that requires verification. However, the reviewer does not provide any specific evidence, examples, or references to support this claim. The reasoning is vague, and there are no external references provided. Therefore, the claim is not welljustified.", "helpfulness_rationale": "The reviewer identifies areas where the paper falls short, specifically mentioning the unclear main contribution, overstated novelty, lack of clarity in the multitasking approach, and unclear automation. This indicates a desire for improvement. However, the reviewer does not provide specific, actionable steps or suggestions for how to address these issues. They point out the *need* for clarification but do not offer concrete solutions. Therefore, while the reviewer identifies problems, they do not provide sufficient detail to make the feedback immediately helpful for implementation."}
{"actionability_label": "3. 3", "grounding_specificity_label": "3. 3", "verifiability_label": "1. 1", "helpfulness_label": "3. 3", "actionability_rationale": "The review point presents an alternative approach to dealing with churn, suggesting using unlabeled data and constraints. While this points towards a potential improvement, it doesn't explicitly state what needs to be done to implement this approach or how it would differ from the current method of training 3040 models. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The review point discusses the idea of using unlabeled target data and constraints to improve model stability. However, it does not specify which part of the paper or the draft it is referring to. There is no mention of a specific section, table, figure, or unique element of the paper that would be addressed. The grounding is implied but not explicit.", "verifiability_rationale": "The review point suggests an alternative approach to dealing with churn but does not provide any evidence, reasoning, or references to support why this approach is beneficial or how it would be implemented. There is no logical reasoning, common knowledge, or external references provided to back up the suggestion. The claim is made without sufficient justification.", "helpfulness_rationale": "The review point offers an alternative idea for dealing with churn, suggesting the use of unlabeled data and constraints. This is a relevant and potentially valuable suggestion for improving model stability. It points towards a different approach and highlights a potential area for further research. While it doesn't provide a definitive solution, it offers a direction for improvement and is directly related to the challenges of churn management."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "4 (4)", "verifiability_label": "2 (2)", "helpfulness_label": "3 (3)", "actionability_rationale": "The statement 'The experiments are not sufficient enough' is somewhat implicit. While it implies a lack of thoroughness, it doesn't explicitly name the specific limitations. However, the reviewer later elaborates with '21) There are limited types of teacher architectures' and '22) Most compared methods are proposed before 2019 (see Tab.)', which are concrete aspects. The initial phrasing lacks direct actionability, but the subsequent points provide specific directions for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions '21) There are limited types of teacher architectures' and '22) Most compared methods are proposed before 2019 (see Tab.)'. This clearly identifies the specific aspects of the work that are being criticized. The reviewer pinpoints the areas where the experiments might be lacking, making the grounding specific to these aspects.", "verifiability_rationale": "The reviewer states 'The experiments are not sufficient enough' which is a claim. However, the reviewer does not provide any specific evidence or reasoning to support this claim within the provided text. While they suggest potential reasons ('21) There are limited types of teacher architectures' and '22) Most compared methods are proposed before 2019 (see Tab.)'), they don't explain *why* these factors contribute to the insufficiency of the experiments. The verifiability is limited as the claim is presented without sufficient justification or references.", "helpfulness_rationale": "The reviewer's point about the insufficiency of the experiments is generally helpful for the authors as it highlights potential weaknesses in their experimental design or baseline comparisons. However, the criticism is somewhat vague. While it points to areas for improvement, it doesn't offer specific, actionable suggestions *beyond* what was already mentioned in the grounding specificity evaluation. The reference to 'see Tab.' suggests a table that's not included, making it harder to fully assess the impact and the specific areas needing improvement. The helpfulness is limited by the lack of concrete guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the potential issue with comparing experiments using different amounts of data and suggests a solution by ensuring equal data. This is a clear and actionable point for the authors, directly addressing a potential flaw in their experimental design. The reviewer identifies the *problem* and proposes a *specific solution*, making it 5.", "grounding_specificity_rationale": "The reviewer identifies the *importance* of using the same amount of data for comparisons, which is a relevant point for the authors. However, the reviewer does not explicitly point to a *specific section or table* in the paper where this issue is discussed. While the *content* of the review point is specific to the experimental setup, the *target* (a general principle about data comparison) is not explicitly linked to a specific part of the paper being addressed. The reviewer mentions 'comparing apples to apples' and the importance of 'the same amount of data', but doesn't directly reference a specific section, table, or unique aspect of the paper where this principle is discussed.", "verifiability_rationale": "The reviewer makes a clear claim about the potential issue with comparing experiments using different amounts of data. This claim is supported by providing *examples* of the experiments being compared (H>N and H>N+B, and H>N>H and H>N>H). The reviewer logically explains why using different amounts of data can be a problem and provides concrete examples to support their claim. The reasoning is clear and the examples are relevant to the claim.", "helpfulness_rationale": "The reviewer's point is directly relevant to the experimental methodology and could help the authors improve their draft. By highlighting the potential issue with comparing experiments using different amounts of data, the reviewer is providing actionable feedback that could lead to improvements in the experimental design. The reviewer's suggestion to ensure equal data is a constructive and helpful suggestion for the authors to consider. The feedback is directly applicable to the authors' work and addresses a potential flaw in their methodology."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a concern about the practicality of using prior knowledge, which implies a desire for the authors to consider alternative approaches. While the reviewer doesn't explicitly state what to do, the concern itself is an actionable item for the authors to address. The reviewer is pointing out a limitation, which can guide the authors in refining their method or acknowledging its limitations.", "grounding_specificity_rationale": "The reviewer's comment is quite specific, mentioning 'prior knowledge is not always available' and 'might be inaccurate to a specific subpopulation.' This clearly identifies the potential issue related to the accuracy of prior knowledge within a specific context. The reviewer is not just stating a general concern but pinpointing a specific aspect of the method that could be problematic.", "verifiability_rationale": "The reviewer states a concern based on their experience or understanding within the field, specifically mentioning 'most researchers focus on mining causal relationship from the data automatically.' This is a statement of fact based on common practices in the field. The reviewer is not making a subjective judgment but rather pointing out a widely accepted alternative approach.", "helpfulness_rationale": "The reviewer raises a valid concern about the limitations of relying on potentially flawed prior knowledge, which directly impacts the practical application of the proposed method. This concern is actionable for the authors, prompting them to consider alternative methods or acknowledge the limitations of their approach. The reviewer's statement is a concrete point that can guide the authors' work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states suggestions for improvement, such as 'polishing of figures,' 'missing axis labels,' 'randomly masked out portions of curves,' 'single seed experiments,' and 'two small scale datasets and a single architecture type.' These are direct actions the authors can take to address the identified weaknesses. The reviewer clearly indicates what needs to be done.", "grounding_specificity_rationale": "While the review point refers to 'figures' generally, it also specifies *what is wrong* with them (e.g., 'missing axis labels,' 'randomly masked out portions of curves'). Furthermore, it points to specific aspects of the empirical results, such as 'core findings in section one' and mentions the 'datasets and architecture type.' This indicates a level of specificity beyond just stating the area of improvement. The reviewer doesn't just say 'figures are bad,' but rather pinpoints specific issues within the figures and the experimental setup.", "verifiability_rationale": "The review point makes a claim about the state of the empirical findings, stating 'there is a lack of polishing of figures and of empirical results which impedes clarity and well as confidence in empirical results.' This is a claim that can be supported by logical reasoning (e.g., 'lack of polishing hinders clarity') and by referencing the specific issues mentioned (e.g., 'missing axis labels,' 'randomly masked out portions of curves'). The reviewer provides examples that serve as evidence for their claim.", "helpfulness_rationale": "The review point provides a clear list of suggestions for improving the figures and the experimental setup. The suggestions are specific, actionable, and directly address the identified weaknesses. For example, instead of just saying 'the figures need work,' the reviewer suggests concrete steps like 'add axis labels,' 'unmask portions of the curves,' and 'conduct experiments with multiple random seeds.' These suggestions are likely to be directly beneficial for the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the 'lack of comparative experiments' in Section 4.3, which is a direct and clear indication of an action the authors should take. The suggestion to include 'bottleneck blocks in ResNet or linear bottleneck in MobileNetV2' provides a concrete direction for the authors to improve their experiments.", "grounding_specificity_rationale": "The comment explicitly mentions 'nonlinear blocks' and then specifies 'bottleneck in ResNet' and 'linear bottleneck in MobileNetV2'. This clearly identifies the type of nonlinear block the authors should consider, providing a specific area for improvement. While it doesn't pinpoint a specific experiment within Section 4.3, it does specify the *type* of block to compare. Therefore, it can be considered 'fully grounded' in terms of the *type* of block, but 'underspecific' in terms of a specific experiment within Section 4.3.", "verifiability_rationale": "The comment contains a claim: 'there lack of comparative experiments with other nonlinear blocks...'. This claim is supported by the suggestion to include 'bottleneck blocks in ResNet or linear bottleneck in MobileNetV2'. While the claim itself is factual, the *support* provided is a suggestion for improvement rather than a detailed justification or citation of external references. Therefore, it can be considered '3' as it is supported but lacks some depth in justification.", "helpfulness_rationale": "The comment is 5 as it directly points out a missing element in the experimental section (comparative experiments with specific nonlinear block architectures). It provides a clear and actionable suggestion for the authors to improve their work by including these comparisons. The suggestion is specific enough to guide the authors in their experiments."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point says \"The discussion around equation (10) is very terse, and not very clearly explained.\" This statement identifies a problem (terse and unclear) but doesn't directly tell the author what to do or how to improve the discussion. The author still needs to figure out how to make the discussion more detailed and clear.", "grounding_specificity_rationale": "The review point mentions \"equation (10)\". This is a specific part of the paper. The authors can identify the section, table, figure, or unique aspect being addressed.", "verifiability_rationale": "The review point states a problem (\"terse\" and \"not very clearly explained\") without making a claim that requires verification. It's a statement of observation, not a claim that needs supporting evidence.", "helpfulness_rationale": "The review point identifies an area for improvement (discussion around equation 10). While it doesn't specify *how*, it clearly points to a actionable area for the author to focus their revision efforts. Knowing that the discussion is terse and unclear provides the author with a target for improvement."}
