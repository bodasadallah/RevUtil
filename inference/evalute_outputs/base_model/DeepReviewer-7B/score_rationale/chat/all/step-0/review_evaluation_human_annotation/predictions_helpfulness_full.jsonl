{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The reviewer points out a potential issue (noise in the dataset). This is an observation, not a direct action. It suggests an action: 'Check the dataset for noise.' However, the review itself doesn't explicitly state this action or provide details on how to do it. Therefore, while it *could* be actionable, the review point itself is not explicit or concrete enough to be considered actionable.", "grounding_specificity_rationale": "The reviewer mentions 'artificially created,' 'noise,' 'misinformation,' and 'outofcontext images.' These are specific aspects of the dataset. However, the reviewer does not explicitly state which part of the dataset (e.g., specific tweets, images, metadata) these issues relate to. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer states the 'possibility' of noise but does not provide any evidence, reasoning, or references to support this claim. There is X extracted from this review point. Therefore, it is 1.", "helpfulness_rationale": "The reviewer expresses a desire to understand the dataset's quality. While this is a valid concern for the authors, the review point itself does not directly instruct or request improvements to the draft. It's a desire for information, not a direct request for actionable feedback on the draft itself. Therefore, it is not helpful in terms of directly improving the authors' current draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the lack of 'dig into the theory' and 'show the convergence properties' of the proposed algorithm. These are direct and clear actions or suggestions that authors can directly identify modifications they should apply to their draft. The language is direct and doesn't require inference.", "grounding_specificity_rationale": "The review point mentions 'theory profs' and 'convergence properties' of the algorithm. This provides a specific area within the paper where the lack of detail is being pointed out. While it doesn't pinpoint a specific section or table, it clearly identifies the *nature* of the missing information. Therefore, it can be considered weakly grounded in terms of identifying the *section* but specific in identifying the *type* of information missing.", "verifiability_rationale": "The review point makes a claim about the paper's lack of theoretical analysis and convergence demonstration. While it states a fact, it doesn't provide any logical reasoning, common knowledge, or external references to support this claim. It's a statement of opinion or judgment about the paper, requiring further justification to be considered verifiable.", "helpfulness_rationale": "The review point identifies a significant area for improvement by pointing out the lack of theoretical analysis and convergence demonstration. This is generally helpful for authors as it highlights a key deficiency. However, it lacks specific suggestions on *how* to address this deficiency, making it less impactful than a more detailed comment."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the methodology used to calculate the overall score in the results section. This directly points to a lack of clarity in the description of the calculation method. While the reviewer doesn't explicitly state what is unclear, the question itself indicates a potential ambiguity or lack of detail in the explanation of how the scores were aggregated. Therefore, the review point is considered actionable as it identifies a specific area of the paper (the results calculation) where further clarification is needed.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper being addressed. The reviewer is asking a question about the methodology used elsewhere in the paper, not about a specific element within that methodology. While the method is used in the 'results' section, the review point itself doesn't pinpoint a specific element within that section that needs clarification. Therefore, the grounding is weak, as the authors cannot confidently determine which part of the paper the comment addresses.", "verifiability_rationale": "The reviewer states a claim ('why you did not consider...') without providing explicit evidence or justification within this review point. They are asking a question, which implies a belief that the current method is better, but they do not provide any logical reasoning, common knowledge, or external references to support this claim within the review itself. Therefore, the verifiability is low, as the claim is made without sufficient supporting evidence within the review point.", "helpfulness_rationale": "The reviewer's question directly relates to the clarity and usefulness of the feedback for the authors. They are asking for a justification of a methodological choice, which directly impacts the authors' ability to understand and act upon the feedback. While the review point itself doesn't provide the justification, the question directly prompts for it, making it 3 in identifying a potential area where the feedback could be improved for the authors. Therefore, the helpfulness is considered 3 as the question directly relates to the authors' ability to understand and act upon the feedback."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential issue with the description of HIERENC's input calculation but doesn't explicitly recommend a solution or provide a concrete alternative. While they point out a potential problem (averaging all entity instantiations), they don't offer a clear improvement or a different approach. The reviewer's point focuses on the *what* (the averaging) and *why it might be a problem* (noise), but lacks a direct suggestion of what should be done instead.", "grounding_specificity_rationale": "The reviewer mentions 'HIERENC' and describes the process of calculating its input. They state that each input (h_i) is the average of representations of all instantiations of context filled by every possible entity in the vocabulary. This demonstrates an attempt to ground the discussion by referencing a specific component (HIERENC) and describing its input. However, the reviewer doesn't explicitly state which part of the paper they are addressing (e.g., the description of HIERENC itself, or the overall method). The grounding is present, but the clarity of the referenced part could be improved.", "verifiability_rationale": "The reviewer states that the description of HIERENC's input calculation introduces 'a lot of noise' due to averaging all possible entity instantiations. While the reviewer provides a claim (the averaging introduces noise), they don't explicitly provide external references or logical reasoning to *verify* this claim. The reviewer's statement is an inference based on their understanding of the potential issues with the averaging process, but lacks direct evidence or citations to support the claim of noise.", "helpfulness_rationale": "The reviewer's point directly addresses a technical detail of the method (the description of HIERENC's input calculation) and raises a potential issue (the introduction of noise). This point is relevant to the authors who are trying to understand or implement the method. By highlighting a potential flaw in the description, the reviewer provides a suggestion for improvement, which could be helpful for the authors."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "1", "verifiability_label": "Not Verifiable", "helpfulness_label": "4", "actionability_rationale": "The review point is a question, not a statement that explicitly calls for an action. While the reviewer is expressing a desire for clarification, the point itself doesn't dictate what needs to be done with it. Therefore, it doesn't directly provide actionable feedback.", "grounding_specificity_rationale": "The review point is about the methodology of selecting answers, not about a specific part of the paper being criticized. Therefore, it doesn't identify a specific section, table, figure, or unique element of the paper. It's about the evaluation process itself.", "verifiability_rationale": "The review point is a question about the evaluation process, not a claim that needs verification. While it implies a process exists, it doesn't explicitly state a claim that requires justification. Therefore, it doesn't fit the 'X' category (X). The verifiability of the process itself is unclear due to the lack of detail in the question.", "helpfulness_rationale": "The review point directly questions the evaluation process and its potential impact on performance estimation. This is a clear indication of a helpful review point, as it points out a potential issue with the methodology. It asks for clarification and justification of a process, which is valuable information for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests a change in how the data is described, implying an action to make the description clearer. While the current comment could be interpreted as actionable (the authors could try to understand the description as contradictory), the reviewer's suggestion for improvement adds a layer of explicitness. Therefore, it's 3 as the authors can act upon the suggestion to improve clarity.", "grounding_specificity_rationale": "The reviewer points out that the description of the data used is not precise and lacks explicit mention of Li et al. (2019a) earlier. The authors can infer the data source but cannot confidently determine the specific part of the paper being addressed without the explicit mention. This aligns with the definition of '2'.", "verifiability_rationale": "The reviewer identifies a potential contradiction in the description of the data and suggests citing Li et al. (2019a) to verify the syntactic information. The comment itself identifies a weakness (the potential contradiction) and suggests a way to verify it. While not 5 within the comment itself, the reviewer's point about verification points towards '3'.", "helpfulness_rationale": "The reviewer's comment is informative about a potential issue with the data description and suggests a way to improve it. While the comment provides some information, the reviewer's point about clarity makes it '3' as the authors can improve the feedback's impact."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a lack of explanation regarding the purpose of the average duration in Table 1. While the reviewer doesn't explicitly state an action, the question about understanding the table's content implies an action on the part of the authors. The lack of explicitness makes it 3, as the authors would need to infer the meaning.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 1' and asks a specific question about the 'average duration'. This demonstrates a clear grounding of the reference. The request for clarification about whether waiting time is included further specifies the area of concern.", "verifiability_rationale": "The reviewer makes a claim about the lack of supporting explanation for the table and asks for clarification. This claim is verifiable by checking the table's caption or surrounding text. The request for clarification is also a verifiable action for the authors.", "helpfulness_rationale": "The reviewer's question directly addresses a lack of clarity and understanding, which is a significant point for the authors. The request for clarification is a direct and actionable improvement. This feedback is 5 as it guides the authors on how to better understand and potentially improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to clarify Table 4, which is an action. The request is also concrete, asking for the specific splits used, meaning the authors know exactly what needs to be done (obtain the splits and understand how they relate to the ATIS numbers).", "grounding_specificity_rationale": "The reviewer's comment directly refers to 'Table 4' and 'ATIS numbers,' indicating a clear identification of the specific part of the paper being addressed. This is a strong form of grounding as the comment pinpoints the exact location of the issue.", "verifiability_rationale": "The reviewer is asking a question about the methodology used to generate the results in Table 4. There is no explicit claim being made, nor is there any suggestion or judgment being offered. The request is a question that should ideally be answerable by referring to the paper's methodology section. The lack of justification makes it 1 in the sense that the authors cannot independently confirm the validity of the information presented without further information from the reviewer.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential weakness in the paper (lack of clarity on Table 4). By asking for clarification on the splits used, they are providing a concrete suggestion for improvement. This directly helps the authors understand and reproduce the results. The request for clarification is a valuable contribution to the paper's clarity and reproducibility."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests a specific way to phrase the results, implying an action to improve clarity. However, the exact action or change is not explicitly stated, making it somewhat vague. The reviewer's suggestion is a general improvement rather than a concrete, actionable step like 'rewrite section X to be clearer'.", "grounding_specificity_rationale": "The reviewer makes a general comment about the results being 'on par or better' and suggests a specific interpretation. They do not explicitly identify a specific part of the paper or result that needs improvement. The comment is about the overall interpretation of the results, not a specific detail within the paper.", "verifiability_rationale": "The reviewer's comment is a subjective opinion about the interpretation of the results. They do not provide any evidence, reasoning, or references to support their claim. The statement is purely an interpretation and lacks any verifiable basis.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by recommending a specific way to phrase the results. They explain their reasoning, stating that this wording would make the results clearer and easier to understand. This actionable feedback directly addresses a potential weakness in the presentation of the results."}
{"actionability_label": "2 (2)", "grounding_specificity_label": "4 (4)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer asks a question about interpreting results in Table 3, which implicitly suggests an action (understanding the implications). However, the reviewer does not explicitly state how to interpret the overlapping 95% confidence intervals or provide concrete guidance on what these results mean for the models.", "grounding_specificity_rationale": "The reviewer refers to specific results in Table 3, specifically mentioning 'Chinese MOSQ', 'Chinese MOSV', and 'English MOSV'. This demonstrates a clear identification of the specific part of the paper being addressed. The reviewer also explicitly states 'For results shown in Table 3', which indicates a strong grounding of the comment.", "verifiability_rationale": "The reviewer states the findings about the comparability of models in Table 3 without providing any justification, reasoning, or external references. The statement is purely descriptive and lacks any supporting evidence.", "helpfulness_rationale": "The reviewer's question about interpreting results in Table 3 is relevant to understanding the findings. However, the review point does not offer any solutions or guidance on how to proceed based on this interpretation. It simply asks a question."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a flaw in the presentation of results but does not provide a specific action or suggestion on how to improve the spacing. It points out a problem but doesn't tell the authors what to do about it.", "grounding_specificity_rationale": "The comment explicitly mentions 'Table 2 and Table 3', which are specific sections of the paper. This allows the authors to identify the relevant part of the paper being addressed.", "verifiability_rationale": "The comment makes a judgment about the presentation of results being inconsistent, which can be considered a deduction or observation. However, it doesn't provide specific examples or references to support this claim.", "helpfulness_rationale": "The comment points out a valid issue regarding the formatting of tables. It highlights a potential problem for the authors' work, which is a form of constructive feedback. However, it doesn't offer a solution or a broader discussion on the implications of this formatting issue."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "2 (2)", "verifiability_label": "X (X)", "helpfulness_label": "3 (3)", "actionability_rationale": "The comment explicitly states 'antecedent missing', which indicates a problem with something preceding 'both tasks'. This is an explicit action, but it lacks specific details on what is missing.", "grounding_specificity_rationale": "The comment refers to 'both tasks' without explicitly identifying the specific part of the paper being addressed. It does not name a section, table, figure, or unique element. Therefore, the grounding is weak. While it points out a potential issue, it doesn't specify what is missing within 'both tasks'.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It points out a potential issue ('antecedent missing') but does not formulate a statement that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The comment identifies a potential issue ('antecedent missing'), which is valuable feedback. However, it does not offer a solution or suggest how to address the problem. It is diagnostic but lacks prescriptive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point states a lack of novelty and points out prior work on adversarial attacks. While it identifies a *related* area (videotext models), it doesn't explicitly *recommend* an action or suggest a *specific* improvement. It's more of a statement of fact.", "grounding_specificity_rationale": "The review point mentions \"many NLP models and imagetext models\" and \"prior work on adversarial attacks.\" The reviewer also mentions \"videotext models\" as the target area. While it names the *types* of models and the *area* of application, it doesn't pinpoint a *specific* model, paper, or aspect within these categories. The grounding is implied but not explicit.", "verifiability_rationale": "The review point contains a claim: \"Lack of novelty\". This is a statement of opinion or judgment about the work. The reviewer *summarizes* related work in the related work section of the paper. This provides some justification for their claim. However, they don't provide *new* evidence or *specific* examples of how these attacks are applied to NLP or imagetext models to demonstrate the lack of novelty in the *videotext* context.", "helpfulness_rationale": "The review point is more of a statement of the authors' perception of the novelty of their work. While it identifies a relevant area of research, it doesn't directly guide the authors on *how* to improve their work. It's more of a negative comment rather than a constructive suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem ('confusing') and provides a clear action ('more separate paragraphs'). The suggestion is concrete, indicating a direct understanding of what needs to be improved. The reviewer knows what they want to achieve (clarify Section 3.2) and how to do it (reorganize the content).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3.2' and then specifies the content to be separated ('lexical features' and 'sentencelevel features'). This demonstrates a clear understanding of the location and the specific elements within that section that require clarification. The reviewer provides a precise target for their feedback.", "verifiability_rationale": "The reviewer is making a suggestion for improvement rather than stating a claim that requires verification. The suggestion is about the organization and clarity of information, which is a constructive feedback but doesn't inherently require external references or logical reasoning to be considered valid. The reviewer is proposing a change based on their interpretation of the confusion.", "helpfulness_rationale": "The reviewer directly addresses a potential issue authors might face with Section 3.2 and provides a clear and actionable suggestion to resolve it. This is highly likely to be helpful for the authors who might be struggling with the same confusion. The suggestion is specific and directly targets the identified problem."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses an opinion about the space allocation but does not propose a concrete action or improvement. The reviewer states, 'I find that dedicating a whole section of the paper plus experimental results is a lot of space,' which is a subjective assessment, not a directive for the authors to make changes.", "grounding_specificity_rationale": "The reviewer refers to 'a whole section of the paper' and 'experimental results' generally, without pinpointing a specific part of the paper or detailing what is problematic within that section or results. The reference is vague and lacks precision.", "verifiability_rationale": "The review point is an opinion and does not contain a claim that requires verification. The reviewer states, 'I find that...,' which is a subjective statement, not a claim that can be supported or unsupported. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point is primarily a critique of the space allocation and lacks specific guidance on how to improve the paper based on this critique. While it highlights a potential inefficiency, it doesn't offer concrete suggestions for the authors to follow. The reviewer's statement is more of an observation than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that using integrated gradients has been studied and that the paper proposes postprocessing steps. These are direct statements of what the paper contains, making the action clear and explicit. The reviewer also mentions 'falsepositive neurons' and 'ablation study' without specifying which postprocessing steps or how the ablation study would be conducted, making the action somewhat vague on how to implement it.", "grounding_specificity_rationale": "The reviewer refers to 'postprocessing steps' and 'ablation study' generally. While they imply the existence of these steps, they don't specify which section, table, or unique aspect of the paper they address. The reviewer also doesn't clearly detail what is wrong with the postprocessing or how the ablation study would be performed, making the grounding weak. However, the reviewer does identify the specific area of the paper being questioned (the method section and its postprocessing steps), which can be inferred from the context of the review.", "verifiability_rationale": "The reviewer states that the paper 'lacks an ablation study to demonstrate the importance of these postprocessing steps.' This is a claim that the paper is missing supporting evidence. The reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. While the reviewer suggests an ablation study might be needed, this is a suggestion, not a claim that is being verified or unverified by the paper itself.", "helpfulness_rationale": "The reviewer points out a potential weakness in the paper (the lack of an ablation study) and suggests a potential improvement (an ablation study). This is a constructive comment that identifies a missing element and proposes a solution. While the reviewer doesn't explicitly recommend performing the ablation study, their comment is directly aimed at improving the paper's rigor and providing more comprehensive evidence. This makes the review helpful for the authors in understanding the limitations and potential improvements of their work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer proposes a method and then identifies a specific limitation: 'It\u2019s not clear how to handle the situation when the head word is not a pronoun.' While the reviewer suggests *matching the head of noun phrases* as a solution, they don't specify how this would work in practice for nonpronoun heads. This is an implicit action that requires further clarification.", "grounding_specificity_rationale": "The reviewer proposes a specific method (matching the head of noun phrases) to identify the antecedent. This demonstrates strong grounding as the specific part of the paper being addressed is clearly identified.", "verifiability_rationale": "The reviewer states a concern about the proposed method's clarity when the head is not a pronoun. However, they do not provide any justification or evidence to support this claim. The statement itself is a claim that requires verification.", "helpfulness_rationale": "The reviewer raises a valid concern about the proposed method's limitations. While they suggest a potential solution, they do not elaborate on it or provide a clear path forward. The comment primarily expresses a concern about the method's clarity."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer's point is somewhat implicit. While they clearly state the comparison is 'unclear' and suggest including 'more baselines,' the exact action the authors should take is not explicitly stated. The suggestion is more of a call for clarification and addition rather than a direct instruction on how to perform a specific action. The action is vague, as it doesn't specify *how* the comparison should be made or what criteria should be used to select the additional baselines.", "grounding_specificity_rationale": "The reviewer refers to 'models that only consider different senses but not sememes' and suggests the MST baseline as an example. However, they do not explicitly state where in the paper this baseline is located or how it is described. The reviewer's suggestion to include 'more baselines based on related work' is a general suggestion and not a specific reference to a particular part of the paper. While the reviewer points to a potential gap in the comparison, the grounding is in the *review itself* pointing out a potential issue, not in the specific sections or tables of the paper being reviewed.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity regarding the comparison to models considering only senses and suggests baselines based on related work. This claim could be considered 3. The reviewer points to the emphasis on 'soft vs. hard word sense disambiguation' as the current discussion's focus, potentially supporting their claim about the lack of clarity regarding sememes. However, the reviewer does not provide specific references or examples to support this claim within the review point itself.", "helpfulness_rationale": "The reviewer's suggestions for including more baselines based on related work are relevant and directly address potential weaknesses in the comparison. This provides useful information to the authors. However, the initial part of the review, stating the comparison is 'unclear,' is somewhat vague and could be expanded with more specific suggestions or questions. The helpfulness is moderate as the suggestions are relevant but could be more concrete and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point contains two claims. The first, 'The abstract is written well and invokes intriguing early', is a positive statement and does not provide explicit or concrete actions for the author. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', explicitly states an action and provides a concrete suggestion for improvement. Therefore, the review point is partially actionable.", "grounding_specificity_rationale": "The review point contains two claims. The first, 'The abstract is written well and invokes intriguing early', does not explicitly identify a specific part of the paper being addressed, making it weakly grounded. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', explicitly refers to the inconsistency between gold and human evaluations and provides a specific example, making this part 5. Therefore, the review point has somewhat specific grounding.", "verifiability_rationale": "The review point contains two claims. The first, 'The abstract is written well and invokes intriguing early', is a subjective statement and does not provide any evidence or justification, making it 1. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', points to a wellknown issue in the field (the inconsistency between gold and human evaluations) and provides a specific example, making this claim 5. Therefore, the review point has 3 claims.", "helpfulness_rationale": "The review point contains two claims. The first, 'The abstract is written well and invokes intriguing early', is a positive comment and does not offer specific actionable feedback, making it not very helpful. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', identifies a specific area for improvement (the abstract) and provides a concrete suggestion for improvement, making this part 5. Therefore, the review point is 3 as it contains both not helpful and 5 elements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states that the selection process for 'frame similarity factors' and 'attributes similarity factors' is unclear. This directly points to an actionable area for the authors to seek clarification or further explanation.", "grounding_specificity_rationale": "The review point explicitly mentions 'frame similarity factors' and 'attributes similarity factors', which are specific components of the model. This demonstrates strong grounding as the authors can identify the specific part of their work being addressed. The comment also states that the selection of these factors is unclear, which is a specific issue within the methodology.", "verifiability_rationale": "The review point does not contain a claim. It is a statement of a deficiency in the clarity of the methodology. Therefore, verifiability is not the primary aspect to evaluate here.", "helpfulness_rationale": "The review point identifies a lack of clarity in the methodology. While it points to a potential area for improvement, it doesn't directly suggest *how* to improve the clarity. It's a diagnostic statement rather than a prescriptive one."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need for a discussion on the convergence of the joint learning process and its connection to obtaining stable points in probabilistic metric space. This implies an action: to explain or elaborate on this mechanism. The reviewer identifies a missing element (discussion of convergence and stable points) and specifies what needs to be discussed (convergence, stable points, probabilistic metric space). This makes the comment explicit and concrete, providing a clear action for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'convergence of the proposed joint learning process' and then further specifies the 'stable points in probabilistic metric space' as the context for this convergence. This direct identification of the specific part of the paper being addressed demonstrates strong grounding. The reviewer also clearly states what is missing: a 'discussion' or 'explanation' of this process. This makes the comment 5 about the missing information.", "verifiability_rationale": "The reviewer is not presenting a claim that needs verification. They are requesting information or an explanation about a specific technical aspect of the method. This falls under the 'normal statements' category, where the purpose is to provide information rather than assert an opinion or require justification. There is no logical reasoning, common knowledge, or external references being introduced to support a claim.", "helpfulness_rationale": "The reviewer is asking for clarification on a core technical aspect of the method, specifically the convergence of the joint learning process and its relation to stable points in probabilistic metric space. This is directly relevant to the authors' understanding and ability to reproduce their work. While it might not provide a *new* insight, it addresses a fundamental point for clarity and correctness, making it a valuable piece of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states actions to be taken. It says '681 as mentioned above, you should discuss the results for the task of inferring knowledge on objects, and also include results for model (B)' and '778 \"latent in verbs\": why don't you mention objects here?'. These sentences directly tell the authors what needs to be done and how to do it. The first part clearly indicates the action of discussing and including results, while the second part asks for a correction regarding the mention of objects. The actions are also quite concrete, specifying the tasks to be performed.", "grounding_specificity_rationale": "The review point refers to specific elements of the paper. It mentions 'the results for the task of inferring knowledge on objects' and 'results for model (B)'. This indicates that the authors are expected to have identified these results and are pointing out a need for discussion and inclusion. While it doesn't explicitly point to a specific section or table, it refers to specific *outputs* of the model. The second part of the review, '778 \"latent in verbs\": why don't you mention objects here?', directly refers to a specific term ('latent in verbs') within the paper's methodology or explanation. This makes the grounding quite specific, as it identifies a particular element that needs attention.", "verifiability_rationale": "The review point makes claims about the paper's content and methodology. It states that there's a need to discuss the results for the task of inferring knowledge on objects and include results for model (B), which is a claim that requires these actions. It also points out an inconsistency in terminology ('latent in verbs' and 'objects'). While it doesn't provide external references to support these claims, the reasoning is logical and based on the observed inconsistencies. The claim about the missing mention of objects is directly inferred from the observation of the term 'latent in verbs' being used without the corresponding 'objects'.", "helpfulness_rationale": "The review point provides clear and actionable feedback to the authors. It directly points out potential weaknesses in the paper's analysis and methodology, specifically the need to discuss and include results for model (B) and the inconsistency in terminology. The suggestions are concrete and directly address potential areas for improvement. The reviewer is asking the authors to take specific actions, which is 5 in refining their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out the incorrect sentence in line 212 and provides a clear alternative description based on their interpretation of Figure 2. The reviewer states, 'The correct way would be to say that you do a bidirectional encoder that encodes the source sentence into a set of vectors... at least, that's what's seen in Figure 2.' This is an explicit statement of an error and a suggestion for improvement, making it actionable.", "grounding_specificity_rationale": "The reviewer explicitly references 'line 212' in the paper, providing a very specific point of reference. They also explain what is *incorrect* in that line and what the *correct* interpretation should be based on Figure 2. This strong grounding makes it clear to the authors where the issue lies and what needs to be addressed.", "verifiability_rationale": "The reviewer points out a factual discrepancy between the text in line 212 and their interpretation based on Figure 2. If the paper *accurately* describes a bidirectional encoder producing a set of vectors, then the reviewer's correction is verifiable. The reviewer is not making a subjective judgment but rather highlighting a difference between the text and the visual representation. This makes the feedback actionable and verifiable.", "helpfulness_rationale": "The reviewer provides a clear and specific correction to a potential point of confusion for the authors. By highlighting the difference between a single vector and a set of vectors, the reviewer is directly addressing a specific implementation detail that could lead to misunderstandings. This is a 5 and constructive suggestion that empowers the authors to improve their draft."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the nature of the work ('fairly straightforward extension of existing retrofitting work') and implies an improvement ('would be nice to see some additional baselines'). However, it does not specify *how* to implement this improvement or what specific aspects of the extension are lacking. The action is implied but not explicitly stated in a concrete manner.", "grounding_specificity_rationale": "The comment explicitly mentions 'existing retrofitting work,' which grounds the feedback to a specific area of the paper. However, the suggestion to 'see some additional baselines' is general and lacks specificity. The reviewer does not identify a particular section, table, figure, or unique element within the 'existing retrofitting work' that requires improvement.", "verifiability_rationale": "The comment contains a claim ('would be nice to see some additional baselines') that suggests a potential improvement. However, it does not provide any justification or evidence for why these additional baselines would be beneficial, how they should be implemented, or provide any references to support this suggestion. The claim is stated but not wellverified.", "helpfulness_rationale": "The comment identifies a potential area for improvement (testing with additional baselines) but does not provide specific details on what these baselines should be, how they should be compared, or what specific aspects of the current draft would be improved by this. The suggestion is general and lacks actionable steps, making it less helpful for the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states weaknesses in the baseline models and suggests improvements, although it doesn't specify *how* to address these weaknesses. The suggestions are general and could be interpreted in multiple ways. For example, 'Weak Baseline Models' could mean adding more comparisons, but it doesn't detail which models to compare or how to justify their weakness. The suggestion to 'Rephrase Sentence' is vague and doesn't provide specific guidance on which sentence or how to rephrase it. The suggestion to 'Add Citation' is also vague and doesn't specify *where* in the paper this citation should go. The suggestion to 'Compare to Domain Adaptation Methods' is a general direction but lacks specific examples or criteria for comparison.", "grounding_specificity_rationale": "The review point identifies general areas for improvement, such as 'Weak Baseline Models' and 'Missing Domain Adaptation Comparisons,' but it does not explicitly point to a specific section, table, figure, or unique aspect of the paper where these weaknesses are located. The suggestions are broad and could apply to various parts of the paper. For instance, when suggesting 'Rephrase Sentence,' the review doesn't specify *which* sentence. Similarly, when suggesting 'Add Citation,' it doesn't indicate *where* in the paper this citation should be added. While the concepts are clear, the specific application is not welldefined.", "verifiability_rationale": "The review point makes claims about the weakness of baseline models and the lack of comparison to domain adaptation methods. However, it lacks specific evidence or references to support these claims. For example, when stating 'Weak Baseline Models,' the review doesn't provide any examples of how these models are weak or cite any specific performance metrics that demonstrate this weakness. Similarly, when suggesting 'Compare to Domain Adaptation Methods,' it doesn't provide any criteria for comparison or cite relevant works in this area. The claim 'The may be attributed...' is a hypothesis but lacks sufficient justification or evidence.", "helpfulness_rationale": "The review point identifies areas where the author's work could be improved, specifically regarding the choice of baseline models and the comparison to domain adaptation methods. The suggestions to 'Rephrase Sentence' and 'Add Citation' are directly actionable and address specific formatting and clarity issues. However, the criticism of 'Weak Baseline Models' and 'Missing Domain Adaptation Comparisons' is more of a general observation than a specific, actionable suggestion. While it points to areas for improvement, it doesn't provide concrete steps for the author to take. The lack of specific examples or criteria for comparison makes it less helpful than suggestions like rephrasing or adding a citation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action: 'may use'. This indicates a suggestion for improvement. The action is to replace the label on the yaxis of figure 5. This action is clear and directly addresses a potential issue with the figure. The reviewer is directly pointing out a potential improvement.", "grounding_specificity_rationale": "The comment explicitly mentions 'figure 5' when suggesting a change to the yaxis label. This clearly identifies the specific part of the paper being addressed. The comment is specific about the suggestion, which is to change the label. The grounding is literal and precise.", "verifiability_rationale": "The comment contains a claim: 'may use'. This claim suggests that the current label might not be the most appropriate or accurate. While the comment doesn't provide explicit justification or evidence for this claim, it implies a potential issue with the current label. The suggestion to use a different label implies a belief in the exact match ratio as a more suitable metric, although this isn't explicitly stated or verified within the review point itself. The claim is not fully supported by explicit reasoning or references within the review point.", "helpfulness_rationale": "The comment provides a clear and actionable suggestion: to replace the label on the yaxis of figure 5 with 'Exact Match ratio'. This is a direct and specific improvement that the authors can easily implement. The suggestion is welldefined and directly addresses a potential issue with the figure's clarity. The reviewer is empowering the authors to make a concrete change."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer points out a relevant concern (societal biases) and suggests a general approach (reasoning chains). However, the lack of specific implementation details makes it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions broad terms like 'societal biases\" and \"knowledge bases\" without specifying a particular aspect or component.", "verifiability_rationale": "The reviewer states a concern about the effectiveness of reasoning chains and points to a figure as evidence of their lack of conviction. However, this is a subjective statement and lacks any logical or factual basis within the review point itself.", "helpfulness_rationale": "The reviewer raises a valid concern about societal biases in knowledge bases, which is a relevant issue for authors to be aware of. Suggesting the use of reasoning chains is a relevant suggestion. However, the lack of specific guidance on how to implement this makes it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the difficulty of proving attention works and suggests changing the attention mechanism. This is a clear indication of an actionable point, as it directly points towards a potential improvement. However, the suggestion lacks specific details on *how* to change the attention mechanism, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer discusses the general difficulty of proving attention works in seq2seq MTL and suggests focusing on understanding *why* it fails. While this is a relevant point, the comment does not explicitly identify a specific part of the paper, model, or data where this issue manifests. The discussion is general and doesn't pinpoint a concrete area for investigation.", "verifiability_rationale": "The reviewer makes a claim about the difficulty of proving attention works in seq2seq MTL and suggests focusing on understanding *why* it fails. While this is a valid observation, the comment does not provide any specific evidence, examples, or references to support this claim. It is presented as a general statement without any backing.", "helpfulness_rationale": "The reviewer raises a pertinent point about the common practice of focusing on negative results (showing something is not working) in research. They suggest exploring the reasons *why* attention fails in this context. While the suggestion is broad and lacks specific details, it offers a potentially valuable direction for future research and could guide the authors in improving their draft. This makes the comment 3 as it points towards a potentially fruitful area of investigation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly states the missing strong baselines and asks for justification. The action is to identify the missing baselines, which is clear and direct.", "grounding_specificity_rationale": "The comment explicitly mentions 'Table 3' and 'MCNC', which are specific parts of the paper. The grounding is strong as the section and concept are clearly identified.", "verifiability_rationale": "The comment contains a claim ('MCNC should have many strong baselines...') but does not provide any evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the statement about the missing baselines.", "helpfulness_rationale": "The comment identifies a weakness in the paper (missing strong baselines and lack of justification) but does not offer any suggestions or reasoning to address this weakness. It simply states the problem without providing any actionable steps for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a problem (paper dependence on supplementary material) but doesn't explicitly recommend a specific action to address it. While the problem is clear, the lack of a direct solution makes it 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific sections/figures (S3.1, Sup. Fig. 6) within the paper, demonstrating strong grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the paper's independence and provides evidence (mention of supplementary references) to support it. While the evidence is present, it could be more robust with direct examples or citations, making it 3.", "helpfulness_rationale": "The reviewer raises a valid and important point about the paper's structure and reliance on supplementary material, which directly impacts the paper's selfsufficiency. This is a 5 critique for improving clarity and rigor."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two suggestions. The first suggests adding word embeddings to the BiLSTMCRF model, which is an explicit action. The second suggests clarifying the meaning of 'KNs' in Figure 3, which requires the authors to take an action (clarify) but lacks specific guidance on how to do so. Therefore, the reviewer's point is partially actionable.", "grounding_specificity_rationale": "The reviewer's first suggestion explicitly mentions 'section 2.3', providing strong grounding. The second suggestion mentions 'Figure 3', which is also a specific part of the paper. However, the second suggestion is more about identifying a lack of clarity rather than explicitly pointing to a specific element within the figure. Thus, the grounding is good but not perfect.", "verifiability_rationale": "Neither of the reviewer's suggestions contain explicit claims that require verification. The first suggestion is a recommendation, and the second is a critique leading to a request for clarification. Therefore, the reviewer's point is not verifiable.", "helpfulness_rationale": "The first suggestion is directly actionable and provides a concrete improvement. The second suggestion is a constructive critique that encourages the authors to clarify a point. Both suggestions are helpful in guiding the authors. Therefore, the reviewer's point is 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The review point does not explicitly state an action or suggestion for the authors. It raises a question about the necessity of a separate task and offers a potential reason based on the scalability of concept maps. While the underlying implications could lead to actions, the point itself lacks direct instructions on how to improve the draft.", "grounding_specificity_rationale": "The claim is somewhat general. It refers to 'concept map extraction' and 'node number' without specifying *which* concept maps or *how* the node numbers are increasing. It's also a bit vague in terms of the 'node number' \u2013 is it the number of nodes in the graph, or some other measure? The claim implies a general issue with concept maps and their scalability, but doesn't pinpoint a specific part of the paper being addressed.", "verifiability_rationale": "The claim 'Is it necessary to treat concept map extraction as a separate task?' is supported by the reasoning that 'many generic summarization systems build a similar knowledge graph and then generate summaries accordingly' and 'with the increase of the node number, the concept map becomes growing hard to distinguish.' These statements provide logical reasoning and a potential explanation for why a separate task might be needed. While it doesn't cite specific papers, the arguments are presented clearly and logically.", "helpfulness_rationale": "The review point raises a valid concern about the necessity of a separate concept map extraction task and provides a potential reason related to scalability. However, it primarily critiques the approach and doesn't offer concrete, actionable suggestions for the authors on how to address this issue or what alternative approaches they could consider. It raises a question but doesn't provide a clear path forward for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks for 'more about the traits of the experts' and 'justify why annotation must be carried out by the experts.' While not explicitly stating an action, the request directly points to an area where the authors need to take action (provide more detail and justification). The action isn't fully defined yet, making it 3.", "grounding_specificity_rationale": "The reviewer asks very specific questions about the experts' qualifications ('were the linguistic experts or domain experts?') and the annotation process ('did it introduce any linguistic challenges?'). This directly addresses the 'where' and 'how' of the information, indicating strong grounding. The questions are precise and target specific details.", "verifiability_rationale": "The reviewer states that annotation 'must be carried out by the experts, outside its commercial values.' This is a claim that needs justification. While the reviewer doesn't provide external references, the request itself is a logical step towards verifiability. The claim is supported by a logical reasoning (commercial values) but lacks specific examples or references, making it 3.", "helpfulness_rationale": "The reviewer's request for more detail about the experts and justification for expert annotation is generally helpful for the authors. It clarifies a process and its rationale, which can improve the quality and understanding of the annotation. While it doesn't directly fix a problem, it provides valuable information that can enhance the authors' understanding and potentially the validity of the annotation process."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point points to a specific location in the paper (lines 102106) and criticizes the writing style ('misleading'). While the reviewer identifies the area of concern, they do not specify what is misleading or how to address it. The criticism is general to the writing style in that area, lacking specific details on how to improve the clarity or precision.", "grounding_specificity_rationale": "The authors can identify the specific part of the paper being addressed (lines 102106). However, the reviewer does not explicitly detail what is misleading about the discussion in that specific part. The criticism is general to the writing style in that area, lacking specific details on what needs to be addressed within that section.", "verifiability_rationale": "The reviewer states 'such distribution' cannot refer to the discussion in the above. This is a claim that there is a disconnect between the concept of 'distribution' and the preceding discussion. The reviewer does not provide any evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up this assertion.", "helpfulness_rationale": "The reviewer points out a potential issue with the writing style ('misleading'). While they identify a problem, they do not offer any suggestions or propose a solution. The comment is diagnostic rather than prescriptive, failing to provide actionable feedback that would empower the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests including examples but doesn't specify how to create them or where to find information about this feature. It lacks concrete actions or methods.", "grounding_specificity_rationale": "The comment refers to 'the system' and 'actual texts' generally, without specifying which part of the paper or where these texts are located. The reference is broad and lacks specificity.", "verifiability_rationale": "The review point is a suggestion for improvement, not a declarative statement that makes a claim about the system or the paper. It doesn't present a judgment or assertion about the current state of the system or the need for examples.", "helpfulness_rationale": "The review point suggests a valuable improvement (including examples), but it's very general and lacks specific details. It doesn't pinpoint where these examples should come from or how the comparison to 'other components & models' would be done. This makes it less helpful than it could be."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that 'A number of claims from this paper would benefit from more indepth analysis.' This clearly indicates an intended action: to analyze the claims more thoroughly. However, the comment does not provide specific guidance on *how* to perform this analysis. The reviewer suggests a direction for improvement but leaves the implementation details open. Therefore, while the action is explicit, the lack of concrete steps makes it 3.", "grounding_specificity_rationale": "The comment states 'A number of claims from this paper would benefit from more indepth analysis.' While it identifies the *type* of analysis (more indepth analysis), it does not specify *which* claims are benefiting from this analysis. The reviewer is referring to 'claims' in general, not a specific section, table, figure, or unique element of the paper. Therefore, the grounding is weak as it does not pinpoint the exact location of the claims being analyzed. It is underspecific because it does not identify the nature of the problem with the claims or suggest a specific way to address them.", "verifiability_rationale": "The review point does not contain a claim in the sense of an opinion or judgment that requires verification. It is a suggestion for improvement: 'A number of claims from this paper would benefit from more indepth analysis.' There are no explicit references to external knowledge, logical reasoning, or specific examples provided within this statement. The reviewer is making a recommendation, not stating a verifiable fact. Therefore, according to the provided definitions, this comment does not contain a claim that needs to be supported.", "helpfulness_rationale": "The review point identifies a valid area for improvement: suggesting more indepth analysis of claims. However, it lacks specific guidance on *how* to achieve this. The reviewer suggests a direction for improvement but does not provide concrete steps or criteria for what constitutes 'more indepth analysis.' This vagueness limits the potential impact of the suggestion on the author. While the point points out a need, the lack of actionable steps makes it less helpful than a more specific suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer raises two distinct questions: (1) about the pooling method for embedding features and (2) about the definition and role of E_i in equation (7). Both questions directly point to specific areas where the authors could benefit from clarification and improvement. The reviewer explicitly states the desire for improvement in the presentation of the model, indicating a clear action the authors should take. The questions are direct and require the authors to identify and address specific issues or areas of confusion.", "grounding_specificity_rationale": "The reviewer explicitly asks about the pooling method for embedding features (line 397) and the definition of E_i in equation (7) (line 472). These are specific requests that directly target particular aspects of the paper. The mention of 'line 397' and 'equation (7) in line 472' indicates a clear understanding of the location of the relevant information within the paper. The reviewer is asking the authors to identify specific areas that need clarification or improvement.", "verifiability_rationale": "The reviewer asks for clarification on the pooling method for embedding features and the definition of E_i in equation (7). These are requests for information that, if provided, would directly address the authors' needs. While the reviewer doesn't explicitly state that the pooling method is incorrect or that E_i is not welldefined, the questions themselves act as implicit verifications: 'Is the pooling method correct?' and 'What does E_i represent?' These are questions that require the authors to engage with the paper and identify potential areas for improvement.", "helpfulness_rationale": "The reviewer's questions directly address areas where the authors could benefit from clarification and improvement. The request for information about the pooling method and the definition of E_i are both actionable and would directly impact the authors' understanding and implementation of the model. The reviewer's desire for improvement in the presentation of the model makes these requests highly valuable and helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper 'does not really study these hypotheses' (lines 078086). This is a clear and direct statement of a gap in the paper's content. The reviewer identifies the *area* of the hypotheses as the issue, which is an explicit action the authors should take. While the reviewer doesn't specify *how* to study them, the act of identifying the missing study is actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions the hypotheses in lines 078086, providing a clear grounding of the issue. While the reviewer doesn't pinpoint a specific *part* of those hypotheses that needs more study, the reference to the section where the hypotheses are stated demonstrates a degree of grounding. The reviewer identifies the *area* of the hypotheses as the problem, which is a specific enough reference to guide the authors.", "verifiability_rationale": "The reviewer makes a clear claim: 'the paper actually does not really study these hypotheses (nor are they even mentioned/discussed again).' This claim is directly supported by the paper's structure and content. The hypotheses are stated in lines 078086, and there's no further discussion or analysis of them. The reviewer provides a logical reasoning to support their claim, making it 5.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors: 'I would have also liked the paper to go deeper into the respective topics, at least to some extent.' This is a helpful suggestion because it directly points to a specific area for improvement. The reviewer doesn't criticize the *methodology* of studying the hypotheses but rather encourages *more* study. This actionable feedback is 5 to the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3 (3)", "grounding_specificity_label": "3 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer desires an action (learning how the CS is used), but the comment doesn't provide it.", "grounding_specificity_rationale": "The comment doesn't explicitly identify the *specific* part being addressed (the data split).", "verifiability_rationale": "The paper doesn't explicitly state the data split used for the CS, making the reviewer's question unanswerable based on the provided information.", "helpfulness_rationale": "The reviewer expresses uncertainty about the explanation, indicating the comment isn't entirely clear or helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states their opinion about the substructure representation and the appropriateness of the term \"knowledge.\" They also provide a specific alternative ('sequence of words,\" \"constituent parse\"). This clearly indicates an actionable suggestion for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"the substructure has to be represented as a sequence of words\" and provides an example (\"constituent parse\"). This clearly identifies the specific part of the paper being addressed and offers a concrete alternative, demonstrating strong grounding specificity.", "verifiability_rationale": "The reviewer states a claim about the paper's terminology (\"knowledge\") and provides a logical argument against using it, suggesting a sequence of words or constituent parse. While they don't provide external references, their reasoning is clear and logical, making it 3.", "helpfulness_rationale": "The reviewer's comment directly challenges a key claim of the paper (\"the model claims the model generalizes to different knowledge\"). They propose an alternative interpretation and suggest a more precise term. This is likely to be helpful for the authors in refining their terminology and understanding the scope of their model's generalization capabilities. The suggestion to consider 'syntax\" or 'semantics\" (if AMR is used) is also a valuable point for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'The relatively poor performance on nouns makes me uneasy' and 'the fact that the oracle GAP for PPDBClus is higher than most clustering approaches is disconcerting'. These statements directly identify an issue and indicate the reviewer's intention to investigate it. The reviewer also asks a question ('I would like to understand the gap better'), which further encourages the authors to take action. The reviewer points to a specific part of the paper (nouns) and a specific dataset (PPDBClus) as the area of concern, making the action quite explicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'nouns' as the area of concern and 'PPDBClus' as the dataset where the performance is particularly high. This direct identification of the specific part of the paper and the specific result makes the grounding very clear and precise. The reviewer also asks a question ('I would like to understand the gap better') which directly relates to the identified issue, further emphasizing the grounding of the comment.", "verifiability_rationale": "The reviewer states a concern: 'the fact that the oracle GAP for PPDBClus is higher than most clustering approaches is disconcerting'. This is a claim that needs to be verified. However, the reviewer does not provide any specific evidence or justification for why this is a significant issue or how it relates to the general claim about clustering approaches being generalizable to all parts of speech. The statement is presented as a question ('I would like to understand the gap better') rather than a definitive claim requiring evidence. While the concern is valid, the lack of supporting evidence makes the verifiability somewhat limited.", "helpfulness_rationale": "The reviewer's comment directly points out a specific weakness ('poor performance on nouns') and asks a question ('I would like to understand the gap better') that encourages the authors to investigate this issue. This is a valuable piece of feedback that directly addresses a specific problem. The reviewer's comment is clear, concise, and directly actionable for the authors. The authors are explicitly told where to look and what to investigate. The comment is not vague or general, making it 5 in guiding the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they need 'examples of spurious structures' to understand the discussion in section 5.2. This is a direct and specific request for action, indicating a clear need for concrete guidance. The request is not vague or inferred, making it 5.", "grounding_specificity_rationale": "The reviewer asks for 'examples of spurious structures' without explicitly stating which part of their paper this relates to. While they mention section 5.2, the core request is about clarifying the concept of spurious structures through examples. They are not pointing to a specific section *within their own paper* and then asking for an example of something within that section. Therefore, it's not fully grounded. However, the request is quite specific about the type of example needed.", "verifiability_rationale": "The reviewer states that the discussion in section 5.2 is 'so abstract that I don't get the insights why the new model is better than MH'. This is a claim about the lack of clarity and the need for examples. While the reviewer might have *read* the section, they are stating that it was not helpful for them. They are not providing external references to support their claim about the abstractness of the discussion within their own paper. Therefore, it is not 5. However, the claim is clear and directly related to the lack of information, making it 3.", "helpfulness_rationale": "The reviewer directly suggests improving the discussion in section 5.2 by providing 'examples of spurious structures'. This is a very specific and actionable suggestion that directly addresses a stated weakness. The reviewer is not just pointing out a problem; they are offering a concrete solution. This makes the suggestion 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a clear and explicit description of the baseline they are proposing. They state the goal is to add a baseline smaller PCFG and detail the method of creating it by parameterizing matrices of specific dimensions. The use of 'under this setting' indicates a clear understanding of the context and the purpose of the suggestion. The reviewer explicitly states the potential impact on parsing F1 and perplexity, making the action quite direct.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'parsing F1' and 'perplexity' as the metrics affected by the proposed baseline. They also explain how the smaller PCFGs can be used to evaluate the 'impact of PCFG size on parsing performance'. The mention of 'parameterized as learned matrices' provides specific details about the construction of the smaller PCFGs. The reviewer's statement that 'parsing F1 might not be directly comparable, but perplexity can still be compared' shows a clear grounding in the relevant metrics and the goal of the suggestion.", "verifiability_rationale": "The reviewer makes a claim about the proposed baseline 'can help evaluate the impact of PCFG size on parsing performance'. They provide a rationale for this claim by explaining that the smaller PCFGs can be used to observe the impact on parsing metrics like F1 and perplexity. The reviewer also specifies the type of PCFGs being created ('smaller PCFG with state size being r, but where H, I, J, K, L are directly parameterized as learned matrices of specific dimensions'). This provides the necessary information to understand and verify the claim.", "helpfulness_rationale": "The reviewer's suggestion is clear, relevant, and directly addresses the problem of comparing parsing performance across different PCFG sizes. The suggestion is specific about the type of baseline to create and the metrics to consider. The reviewer explicitly states the potential impact on parsing F1 and perplexity, making the suggestion constructive and actionable. The reviewer's statement that 'this baseline can help evaluate the impact of PCFG size on parsing performance' is a clear and verifiable claim based on the proposed method."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the suggestion and provides concrete details on what needs to be added (maximum number) and where it should be added (in the table). The action is directly identifiable and the method of implementation is clear.", "grounding_specificity_rationale": "The reviewer implies the table being referred to, as they are suggesting an improvement *to* the table. However, they do not explicitly name the table, section, or figure. The information provided is sufficient to infer the relevant part of the paper.", "verifiability_rationale": "The reviewer makes a claim by suggesting an improvement to the table. This claim is 3 because the reviewer can check the table themselves to see if this information is already present. While the reviewer doesn't provide external references, the suggestion is based on their own understanding of the table's content.", "helpfulness_rationale": "The reviewer provides a specific and actionable suggestion for improving the table. This directly addresses a potential area of weakness (if the table is missing this information) and provides a clear direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that they found it difficult to understand the 'whole picture' and how the 'different pieces of the puzzle' fit together. They suggest that the authors should clarify the connection between the experiments and the research question/hypothesis. This is an explicit action that is also concrete, as the reviewer clearly identifies the missing link.", "grounding_specificity_rationale": "The reviewer identifies a specific area of confusion for the authors: the connection between the experiments and the research question/hypothesis. They ask about the 'overall picture' and how the 'different pieces of the puzzle' fit together. This directly points to a specific section or aspect of the paper, making the grounding explicit. Furthermore, the reviewer specifies *what* is unclear, making the specificity high.", "verifiability_rationale": "The reviewer states that it was 'difficult to get the whole picture' which is a claim that needs to be addressed. While the reviewer doesn't provide specific evidence *why* it's difficult, their suggestion to clarify the connection between experiments and the research question is a direct suggestion for improvement. The lack of clarity itself is a verifiable issue that the reviewer is pointing out.", "helpfulness_rationale": "The reviewer's comment directly addresses a need for the authors to better understand the connection between their experiments and their research question. Their suggestion to clarify this connection is a clear and actionable piece of feedback. This directly helps the authors improve their paper by making the research question and experimental results more cohesive and understandable."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests a concrete action: including a 'hard prompt baseline' in Table 1. However, it does not provide specific details on *how* to implement this baseline or what specific aspects of the methods this baseline is intended to highlight. The action is implied but not explicitly stated with sufficient detail.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper being addressed. It is a general suggestion about improving Table 1. Therefore, the grounding is weak as the authors cannot pinpoint the exact location or aspect of the paper the comment refers to.", "verifiability_rationale": "The comment suggests including a 'hard prompt baseline' but does not provide any justification or reasoning for why this would be beneficial or how it would be implemented. There are no references to external works or logical reasoning provided.", "helpfulness_rationale": "The comment suggests a potential improvement to Table 1 by including a 'hard prompt baseline'. While this could be helpful for authors to understand performance gains, the suggestion lacks specificity and lacks a clear explanation of *why* this baseline is important or how it would be implemented. The lack of detail makes it less helpful as a concrete piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the 'lack of numerical results' as a problem, which is a direct identification of an issue. However, the reviewer does not explicitly state how to apply the work to popular algorithms or compare their performance with existing DP algorithms. The suggestion is implied but not explicitly stated as an action to be taken.", "grounding_specificity_rationale": "The reviewer mentions 'numerical results' and 'algorithms' as areas where more information is needed. However, the reviewer does not specify the *nature* of the numerical results (e.g., specific metrics, datasets) or the *specific* popular algorithms to be considered. The suggestion to compare with existing DP algorithms is also a general direction.", "verifiability_rationale": "The reviewer identifies a 'lack of numerical results' as a problem and suggests 'applying it to some popular algorithms and their performance compared with existing DP algorithms' as a way to address it. This is a clear claim with a suggested method, making it 3.", "helpfulness_rationale": "The reviewer points out a significant omission ('lack of numerical results') and provides a concrete suggestion ('apply it to some popular algorithms and their performance compared with existing DP algorithms') to improve the work. This is a clear and actionable feedback that directly addresses a practical concern."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer states \"I don't think the probabilistic connection is drawn very well.\" This is a statement of opinion about the quality of the connection, not a specific action the authors should take. The comment lacks explicit instructions or suggestions for improvement. It's a critique of the connection itself, not a call to action regarding it.", "grounding_specificity_rationale": "The reviewer refers to \"the probabilistic connection,\" which is a specific part of the paper. However, the comment itself is a general statement about the connection being 'drawn very well' and lacks specific details about what is wrong with it or how it should be improved. The grounding is present in identifying the section, but the specificity is limited to the critique of the connection without concrete suggestions.", "verifiability_rationale": "The review point is a statement of opinion: \"I don't think the probabilistic connection is drawn very well.\" This is not a claim that requires verification or justification. It's an expression of concern, not a proposition that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer's comment is a critique of the probabilistic connection. While it points out a potential issue, it does not offer any specific actions or suggestions for improvement. The helpfulness is limited because the comment identifies a problem but doesn't provide a solution or direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'It would be good to show some empirical evidence...'. This is an explicit action suggesting the authors should add empirical evidence. However, the specifics of *where* to find this evidence or *what* kind of evidence is not detailed, making it somewhat vague.", "grounding_specificity_rationale": "The review point mentions 'the third contribution of the paper' and 'the Column Subset Selection problem'. This indicates the reviewer can identify the specific part of the paper being addressed, making it fully grounded. Furthermore, the suggestion is specific to the 'Column Subset Selection problem', adding to the specificity.", "verifiability_rationale": "The review point is a suggestion for *new* empirical evidence, not a claim that the paper is flawed or needs correction. There is no logical reasoning, common knowledge, or external references provided to *support* the suggestion itself. It's a request for future work, not a critique that needs verification.", "helpfulness_rationale": "The review point identifies a gap in the paper (lack of empirical evidence for a contribution) and suggests a concrete way to address it (adding empirical evidence). While it doesn't *do* the empirical work, it points towards a logical next step for improvement. It's a constructive suggestion aimed at improving the paper."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment implies an action (the applicability of the robust training scheme might not scale) but doesn't explicitly state what needs to be done or how to implement it.", "grounding_specificity_rationale": "The comment explicitly mentions 'practical datasets' and 'highdimensional domains', which are specific parts of a potential experimental setup or discussion. However, it doesn't specify *why* the accuracy would scale unfavorably in these areas.", "verifiability_rationale": "The comment contains a claim ('the applicability of the robust training scheme seems unlikely to scale') and provides a logical reasoning ('it seems like the accuracy would scale unfavorably unless the size of V scales exponentially with the dimension'). However, it lacks specific examples or external references to support this claim.", "helpfulness_rationale": "The review point is critical, highlighting a potential limitation of the proposed method. It prompts the authors to consider the scalability of their approach and the potential impact on practical datasets and highdimensional domains. This raises concerns and encourages further investigation, which is valuable feedback."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a gap in the study of style shifts but doesn't explicitly recommend a specific action or provide a concrete next step for the authors. They raise a question, which could be seen as an implicit action, but it's not very actionable.", "grounding_specificity_rationale": "The reviewer *identifies* a lack of clarity regarding the *nature* of style shifts within a 4year timeframe. They point to a missing element in the authors' analysis. This can be considered weak grounding as the authors cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part (the lack of clarity on style shifts).", "verifiability_rationale": "The reviewer makes a claim about the *insufficiency* of a 4year timeframe and the *lack of understanding* of style shifts. This claim could potentially be supported by examples or references, making it potentially verifiable. However, within the scope of *this* review point, there is no explicit verification provided.", "helpfulness_rationale": "The reviewer raises a crucial question about the validity of the authors' dataset analysis, which directly impacts the model's training and performance. This is a valuable point for the authors to consider. While it doesn't provide a direct solution, it prompts the authors to critically examine their methodology and potentially reevaluate their dataset or analysis approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the incorrect table (Table 3) and the issue with Figure 6's callout (it's not directing properly). This provides a clear target for the author and a concrete action to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific tables (Table 3 and Table 5) and the figure (Figure 6) and its callout. This indicates a high level of grounding as the author can directly identify the referenced parts. The comment specifies what needs to be addressed in these parts (the correct table for the callout and the issue with the figure callout).", "verifiability_rationale": "The reviewer makes a claim about the incorrect table and the issue with Figure 6's callout. While they don't provide explicit evidence or reasoning to *verify* these claims, they present a factual observation that the author can investigate. The lack of explicit verification makes it less than 5.", "helpfulness_rationale": "The reviewer points out specific errors in the tables and the figure callout. This directly informs the author's revisions and provides actionable feedback, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'comparisons with SketchRNN' as a suggestion for improvement, which is a concrete action. It directly tells the authors what they should do to enhance their draft.", "grounding_specificity_rationale": "The review point refers to 'the experiments' as the area needing improvement. While it doesn't pinpoint a specific subsection or table within the experiments, it clearly identifies the *type* of comparison (SketchRNN) that should be made. Therefore, it is '3' in identifying the *method* of comparison, but the 'grounding' is at the broader level of 'the experiments'. However, if we interpret 'grounding' as the specific element within the paper being referenced, it's not specific. If we interpret it as the *type* of comparison being suggested, it is specific. Given the prompt's focus on the paper being reviewed, it's more about the specificity of the *comparison* being suggested. Therefore, it's '3' in the *method* of comparison, but the prompt asks for 'grounding specificity' of the paper, which is broader. Let's consider 'grounding' as the specific element within the paper being referenced. In that case, it's '1' as the specific element isn't identified. However, if 'grounding' refers to the *type* of comparison, it's 'Specific'. Given the ambiguity, and considering the prompt's intent, it leans towards '3' as it specifies the *method* of comparison, even if the *specific element* within the experiments isn't pinpointed.", "verifiability_rationale": "The review point makes a claim by stating 'The paper reports only self comparisons' and 'In a generative setting comparisons with SketchRNN could be performed'. It provides a justification for the claim by suggesting a relevant baseline (SketchRNN) for comparison.", "helpfulness_rationale": "The review point is 5 as it directly addresses a clear weakness in the paper (lack of external comparisons) and provides a concrete suggestion for improvement (comparisons with SketchRNN). It guides the authors on what specific aspect to focus on and what baseline to use for comparison."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a disagreement with the authors' conclusion about the performance trends of ViTs and CNNs in Figure 3. It provides specific observations about the performance of different DeiT models on various datasets, indicating a clear intention to analyze and compare the results. The reviewer directly addresses a point made in the original paper, making the action clear and actionable.", "grounding_specificity_rationale": "The review point explicitly refers to 'Figure 3' and discusses the performance of 'DeiTB', 'DeiTT', 'DeiTS', and 'CNNs' on specific datasets ('APTS2019', 'ISIC2019', 'CheXpert'). This direct reference to a specific part of the paper and the discussion of performance on these datasets clearly identifies the issue being addressed and specifies what is being analyzed. The mention of 'almost consistent model improvements' further clarifies the nature of the observed differences.", "verifiability_rationale": "The review point contains a claim: 'I disagree with authors' viewpoint that 'Both CNNs and ViTs seem to benefit similarly from increased model capacity'. The reviewer then provides specific observations from Figure 3, such as 'DeiTB does not outperform DeiTT in APTOS2019' and 'DeiT models do not consistently outperform smaller DeiT models across all datasets'. These observations serve as evidence to support the claim that the performance gains are not similar for CNNs and ViTs. While the reasoning behind these observations could be more explicit, the claim is stated, and supporting data points are provided.", "helpfulness_rationale": "The review point provides specific observations about the performance of different models in Figure 3 and explicitly disagrees with the authors' interpretation. This suggests that the reviewer has identified a potential issue or area for further investigation in the original paper's analysis. While the point doesn't offer concrete suggestions for improvement, it highlights a discrepancy and provides data to support the reviewer's claim, making it a relevant and helpful feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a general issue ('several places may cause confusion') but does not specify which parts of the paper are problematic or how to address them. It lacks explicitness and concreteness, requiring the authors to infer the areas needing improvement.", "grounding_specificity_rationale": "The comment does not identify specific parts of the paper that are causing confusion. It uses the vague phrase 'several places,' indicating a lack of precision in pinpointing the problematic areas. Therefore, the grounding is weak as the authors cannot confidently determine the scope of the issue.", "verifiability_rationale": "The comment does not contain a claim that needs verification. It is a statement of observation about the clarity of the paper. Therefore, verifiability is not applicable, and the label is 'X'.", "helpfulness_rationale": "The comment identifies a valid issue ('several places may cause confusion') that authors would likely find helpful. While it doesn't specify the exact nature of the confusion or provide concrete solutions, it points to an area for improvement, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a fact, 'However, there is no corresponding set of tools for the reinforcement learning setting.' This is an explicit statement but lacks an implied action. The authors are not told what to do based on this statement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'tools for the reinforcement learning setting' as the specific area being addressed. This is a strong indication of good grounding.", "verifiability_rationale": "The reviewer makes a claim: 'However, there is no corresponding set of tools for the reinforcement learning setting.' This is a claim that could be supported by external references or by checking the paper's own description of tools. The *review point itself* doesn't contain supporting evidence within it.", "helpfulness_rationale": "The reviewer identifies a potential inconsistency in the paper by pointing out the absence of tools for the reinforcement learning setting, despite claiming this is false. This highlights a potential gap in the paper's description of available tools or a need for clarification. This information could be valuable for the authors to understand the state of the field and potentially identify relevant tools or areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states: \"The results, while mostly based on 'standard\" techniques, are not obvious a priori, and require a fair degree of technical competency (i.e., the techniques are really only 'standard\" to a small group of experts).\" While the reviewer points out a potential area for improvement (comparing the authors' work to 'standard\" techniques and noting the expert audience), they don't *specifically* suggest *how* to do this comparison or what aspects to focus on. The comparison itself is vague.", "grounding_specificity_rationale": "The review point discusses the general nature of the results and the level of technical competency required. It doesn't explicitly refer to any specific section, table, figure, or unique aspect of the paper. The comment is about the overall interpretation and audience for the results, not a specific flaw within a particular section.", "verifiability_rationale": "The review point contains a claim: \"The results, while mostly based on 'standard\" techniques, are not obvious a priori, and require a fair degree of technical competency (i.e., the techniques are really only 'standard\" to a small group of experts)\". The reviewer provides a definition of this claim: \"require a fair degree of technical competency (i.e., the techniques are really only 'standard\" to a small group of experts)\". This provides a reason *why* the results might not be immediately obvious. While it doesn't cite specific external references, it offers a logical explanation.", "helpfulness_rationale": "The review point identifies a potential weakness in the authors' work (that it relies heavily on techniques understood by a limited audience). It clearly states this potential issue. While it doesn't offer concrete *suggestions* on how to improve the work to broaden the audience, it highlights a *problem* that the authors might face. This can be helpful in prompting them to consider alternative approaches or clearer explanations."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need to distinguish between hard prompt updates and model updates, which is a clear and direct action. They also suggest citing specific papers as a way to clarify this distinction, further specifying the action.", "grounding_specificity_rationale": "The reviewer explicitly names the areas of confusion: 'hard prompt work updates the frozen model' and 'the frozen model'. This demonstrates strong grounding as the specific parts of the paper are identified. While the reviewer doesn't explain *why* these areas are confusing, they clearly pinpoint the relevant sections.", "verifiability_rationale": "The reviewer provides a claim by suggesting citing specific papers to clarify the distinction between hard prompt updates and model updates. This claim is 5 as the suggestion directly points to a concrete method for providing additional information and context.", "helpfulness_rationale": "The reviewer offers a clear and actionable suggestion for improving clarity by citing specific papers. This directly addresses a potential point of confusion for the authors and provides a concrete path for them to gain more information."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a potential issue with the experimental setup, specifically the difference in training data between the two systems. While it concludes that the direct model might be better despite this difference, it doesn't explicitly state what specific changes or improvements the authors should implement based on this finding. The actionable aspect lies in considering the impact of training data, but the exact steps are not prescribed.", "grounding_specificity_rationale": "The comment explicitly mentions 'the text disambiguation model' and 'the endtoend system', identifying the specific parts of the paper being discussed. It also refers to the 'difference between the two proposed systems', which points to a specific comparison within these systems. This demonstrates a clear identification of the relevant parts and their characteristics.", "verifiability_rationale": "The comment presents a claim that the direct model might be better despite the smaller training data difference. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a possibility based on intuition rather than verifiable evidence.", "helpfulness_rationale": "The comment raises a valid concern about the experimental setup and its potential impact on the conclusions. It highlights a potential flaw in the direct model's performance due to the data difference. While it doesn't directly tell the authors what to do, it points out a potential area for improvement and a factor to consider in future experiments, making it 3 in terms of guiding further research or discussion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the lack of motivation for GaRare and the need for a more detailed algorithmic presentation. However, it does not specify what the advantages of GaRare are over GaLore or how the algorithmic presentation will be improved. The action is implicit (the need for a more detailed presentation) but not explicitly stated in detail.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper being addressed regarding the motivation for GaRare. It makes a general statement about the lack of motivation. However, when discussing the algorithmic presentation, it mentions 'projected gradients,' which implicitly points to a specific concept. Therefore, the grounding is weak for the motivation but potentially stronger for the algorithmic part.", "verifiability_rationale": "The comment makes a claim about the lack of motivation for GaRare and the need for a more detailed algorithmic presentation. However, it does not provide any evidence or justification for these claims. The reasoning is purely based on the reviewer's observation, lacking external references or logical reasoning to support the criticism.", "helpfulness_rationale": "The comment identifies areas for improvement (lack of motivation and algorithmic detail) but does not offer any specific suggestions or guidance on how to address these issues. The feedback is present but lacks actionable steps, making it less helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the goal of conducting an ablation study on the VisDial dataset and specifically requests the performance of ATT(+H) without attention retrieval. This is a clear and direct action the authors should take. The request is also quite concrete, asking for a specific experiment to be performed.", "grounding_specificity_rationale": "The reviewer mentions 'visDial dataset' and 'ATT(+H)', which indicates they can identify the specific part of the paper being addressed. The request to conduct an ablation study and evaluate ATT(+H) without attention retrieval is also quite specific.", "verifiability_rationale": "The reviewer's underlying claim is that the paper lacks sufficient experimental validation, specifically regarding the contribution of attention retrieval. While the paper doesn't explicitly state this lack of validation, the reviewer's request implies a need for more evidence to support the importance of attention retrieval. The request itself provides a justification for the claim.", "helpfulness_rationale": "The reviewer provides a clear and specific request for an ablation study. They are asking for a concrete experiment to be performed to assess the impact of attention retrieval on the VisDial dataset. This directly addresses a potential weakness in the paper's experimental validation and provides a clear direction for the authors to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the names of the relevant works and highlights the key similarities between the proposed method and the Continuous Conditional Random Fields (CCRFs) and Continuous Conditional Neural Fields (CCNFs). The reviewer suggests that incorporating or discussing these related works would improve the paper's related work section and provide context. The action is explicit, and the details are concrete.", "grounding_specificity_rationale": "The review point explicitly mentions the names of the specific works, Ristovski 2013 and Baltrusaitis 2014, which directly correspond to the Continuous Conditional Random Fields and Continuous Conditional Neural Fields. This clearly identifies the specific part of the literature the reviewer is referring to, making the grounding fully grounded. The reviewer also specifies the relevance of these works based on their 'similar structure of the CRF' and 'ability to perform exact inference', adding specificity to the identified area.", "verifiability_rationale": "The review point contains a claim that the related work section should include a discussion of similar works on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. This claim is supported by the reviewer's statement that these works have a 'similar structure of the CRF' and an 'ability to perform exact inference', which are verifiable characteristics. While the review point itself doesn't cite external works to support these claims, the information provided is sufficient to verify the existence and relevance of these works.", "helpfulness_rationale": "The review point is 5 as it directly points out a specific area for improvement in the related work section of the paper being reviewed. The reviewer provides concrete examples of relevant works and their features, suggesting that incorporating or discussing these would enhance the paper's context and potentially enable exact inference. This is a clear and actionable suggestion for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides actionable information by asking specific questions about WPA's behavior and performance. It identifies the need to understand WPA's predictions with `np.ones` input, its ability to serve as a 'white paper' input, and why it performs better than Gaussian noise. These are concrete questions that the authors can directly address in their draft.", "grounding_specificity_rationale": "The review point is highly specific about the aspects of WPA being questioned. It directly asks about the input requirements (specifically `np.ones` and the concept of 'white paper' input) and the mechanism behind its performance compared to Gaussian noise. This strong focus on specific parts of the paper enhances grounding specificity.", "verifiability_rationale": "While the review point raises valid questions about the rationale behind certain choices (e.g., why `np.ones` is a good 'white paper' input and why Gaussian noise is a relevant comparison), it doesn't provide explicit justifications or references for these choices. The reviewer's questions highlight the need for clearer explanations and evidence within the paper to support these design decisions. The lack of explicit backing makes the claims somewhat underjustified.", "helpfulness_rationale": "The review point is highly relevant and addresses a gap in the paper. It asks insightful questions about the internal workings of WPA and its design choices, which are crucial for understanding its effectiveness and for inspiring future research. By highlighting this lack of insight, the review effectively points out an area where the paper could be significantly improved."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a similarity between the method and a specific related work. While this is an explicit statement, it lacks concrete details on how the method is similar to the cited work. The reviewer does not provide any suggestions or actions on how to address this similarity, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions a 'related work cited in the paper: Generating Adversarial Disturbances for Controller Verification'. This indicates a strong grounding as the reviewer can identify the specific part of the paper being addressed. However, the reviewer does not specify what aspects of the method are similar to this related work, making the specificity low.", "verifiability_rationale": "The reviewer states that 'It seems that the method part is very similar to the related work cited in the paper'. This is a claim that requires verification. However, the reviewer does not provide any logical reasoning, examples, or external references to support this claim. The statement is presented as an observation without further justification.", "helpfulness_rationale": "The reviewer's point about the similarity to related work is relevant and constructive for the authors. It highlights a potential area for improvement or a need for better differentiation. However, the reviewer does not offer any specific actions or suggestions to address this issue, making the overall impact on the authors' work somewhat limited."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer raises two main points: the fairness of comparing against other methods and the potential of the proposed technique to promote existing class incremental semantic segmentation methods. While these are valid concerns, the review point does not explicitly state what the authors should do based on these observations. The reviewer asks questions but doesn't provide concrete actions or suggestions for the authors.", "grounding_specificity_rationale": "The reviewer's comment is 1 in the specific aspects of the paper being discussed. While the comment raises concerns about the comparison and the potential impact, it does not explicitly identify which part of the paper is being referred to. The reviewer makes general statements about the comparison and the technique without pinpointing the exact section or table.", "verifiability_rationale": "The reviewer's comment is not verifiable as it does not contain a claim that can be supported by evidence. The reviewer raises concerns about the fairness of the comparison and the potential impact of the technique, but these are presented as questions and observations rather than statements that require justification. There is no logical reasoning, common knowledge, or external references provided to support these concerns.", "helpfulness_rationale": "The reviewer's comment is not helpful as it does not provide actionable feedback or insights for the authors. The reviewer raises concerns about the fairness of the comparison and the potential impact of the technique, but these are presented as questions and observations rather than specific suggestions or guidance on how to improve the paper. The reviewer's comments are more about potential negative societal impact and limitations of the work itself, rather than providing actionable feedback on how to improve the current submission."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies the missing information about the minimum cluster size and conductance threshold parameters and their impact on performance. While it points out a gap in the experimental section, it doesn't explicitly state how to set these parameters or provide concrete guidance on their adjustment. The suggestion is implicit, as it implies the need for this information but doesn't directly instruct the authors on how to obtain or use it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'minimum cluster size' and 'conductance threshold' by name, indicating a degree of grounding. However, the point only identifies the *existence* of these parameters and their *impact* on performance, lacking specific details on *how* they are set or *why* they are important. The grounding is present, but the specificity regarding the parameters themselves is limited.", "verifiability_rationale": "The reviewer states that the experimental section does not mention or discuss how the parameters are set and how sensitive the performance is with respect to these parameters. This is a factual statement about the missing information in the paper. The claim is that the paper lacks this information, and the verifiability is low because the reviewer is pointing out a factual gap without providing evidence or justification for why this is a problem.", "helpfulness_rationale": "The review point highlights a factual omission in the paper: the absence of information regarding the setting of key parameters and their impact on performance. While this omission could potentially lead to confusion or difficulties for the authors attempting to reproduce or understand the work, the review point itself does not offer any suggestions or guidance on how to address this gap. It points out a problem but doesn't provide a solution or direction for the authors."}
{"actionability_label": "borderline actionability", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential area for improvement (Section 4 being terse) but does not explicitly state the action to be taken. While it suggests 'slower development,' it lacks specific details on how to achieve this. Therefore, it is 2.", "grounding_specificity_rationale": "The review point explicitly names Section 4 and states that it is 'very tersely written.' This clearly identifies the specific part of the paper being addressed. Therefore, it is 5.", "verifiability_rationale": "The review point makes a claim about Section 4 being 'very tersely written' but does not provide specific evidence to support this claim. Therefore, it is 3.", "helpfulness_rationale": "The review point identifies a potential improvement area (Section 4) and suggests a way to improve it (slower development), making it a relevant suggestion. Therefore, it is 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states a potential weakness (reinforcement learning might be less dataefficient for static VQA) but does not specify how to address it or what part of the approach needs adjustment. The suggestion is vague and lacks concrete steps.", "grounding_specificity_rationale": "The reviewer criticizes the approach in general, not a specific section, table, figure, or detail within the paper. The connection to the paper's content is implied but not explicit.", "verifiability_rationale": "The reviewer states a potential weakness (reinforcement learning might be less dataefficient for static VQA) but does not provide any specific evidence or reasoning *within the review point itself*. They are making an assumption about the data efficiency of RL for static VQA tasks.", "helpfulness_rationale": "The reviewer raises a concern about the approach but does not offer any concrete suggestions or point to specific flaws in the paper's methodology. The feedback is speculative and lacks actionable steps for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential issue with the assessment of reasoning ability due to the missing information on video length distribution. While it doesn't explicitly state how to improve the draft, it points to a specific area that needs attention. The action is implicit  the reviewer suggests the authors should be aware of this potential issue and consider the video length distribution when evaluating reasoning. However, the reviewer doesn't provide specific steps on how to improve the draft based on this observation.", "grounding_specificity_rationale": "The review point explicitly mentions 'video length distribution within the benchmark' and '11 categories'. It accurately identifies the specific aspect of the paper being discussed. This can be considered fully grounded as the reviewer clearly pinpoints the relevant section and elements.", "verifiability_rationale": "The review point makes a claim that the distribution of video lengths is crucial for the assessment of reasoning ability and robustness. It provides a reason for this claim by stating that the paper does not provide relevant explanations. While it doesn't offer specific external references, the reasoning about the impact of video length on reasoning ability is generally accepted knowledge within the field of video understanding and reasoning. The claim is supported by logical reasoning and the implication of a lack of explanation in the paper.", "helpfulness_rationale": "The review point identifies a specific issue related to the dataset description and its potential impact on the assessment of reasoning ability. It points to a concrete area where the authors might need to make adjustments or considerations. While it doesn't directly instruct the authors on how to improve their draft, it highlights a potential weakness that could affect their work. The feedback is relevant and points to a specific area for the authors to investigate or adjust their evaluation process. The helpfulness is moderate as it doesn't provide direct actionable steps but highlights a potential problem."}
{"actionability_label": "3", "grounding_specificity_label": "2: Weakly Grounded and Explicit", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for a clarification on a specific implementation detail (the bilinear layer) and how it differs from other approaches. This is a direct request for information that could be considered an implicit action. The reviewer is not explicitly stating how to apply this information to improve the draft, but rather seeking understanding of an existing component.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'bilinear layer' and 'other approaches,' indicating a clear identification of the specific part of the paper being addressed. However, the reviewer does not specify *where* in the paper this is discussed or what specific issue is being addressed beyond the difference from other methods. The request is for clarification rather than a direct instruction on how to apply this knowledge.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking for clarification on how something was implemented. There is no assertion of correctness or improvement needed based on this review point.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific implementation detail. While this can be helpful for the authors, it is not a direct suggestion of how to improve the draft. It's a request for understanding an existing component rather than a critique or a proposed change."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states a fact (the dataset isn't available) but doesn't instruct the author on what to do. There is no explicit action or suggestion for improvement.", "grounding_specificity_rationale": "The comment refers to 'the promised dataset' which is vague and doesn't pinpoint a specific section, table, figure, or unique element of the paper. The author cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The comment is a factual statement about the dataset's availability, not a claim that requires verification or justification.", "helpfulness_rationale": "The comment identifies a relevant limitation (the dataset not being available) but doesn't provide concrete guidance on how the author should address this gap or make specific changes to their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out the similarity of the proposed method to existing attentional modules and the connection to ResNeSt. While this identifies a potential weakness, it doesn't explicitly state what the authors should do to address this. The reviewer suggests the paper should discuss these connections, but doesn't provide specific, actionable steps on how to implement or improve the method based on this insight. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer mentions specific prior works 1, 2, 3 and ResNeSt 4 by name, indicating a clear identification of the referenced part of the paper (the existing attentional modules and ResNeSt). They also point out the structural similarity, which specifies the issue. However, the reviewer doesn't explicitly state the *specific* aspects of the proposed method that need improvement based on this grounding. The grounding is present, but the specificity of the suggestion is missing.", "verifiability_rationale": "The reviewer makes a claim about the limited novelty and similarity of the proposed method to existing work. This is a verifiable statement. However, the reviewer does not provide specific evidence or justification to support this claim. There are no references to external works or logical reasoning to back up the assertion of similarity. The claim is present, but the verifiability is lacking.", "helpfulness_rationale": "The reviewer's comment primarily identifies a weakness in the paper (limited novelty) but does not offer concrete, actionable advice on how to improve the method. While it points out a potential area for discussion, it doesn't provide specific steps or suggestions for the authors to follow. The comment is diagnostic rather than prescriptive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a logical consequence of the preactivation values being the same and suggests an alternative visualization. While they don't explicitly state an action to take, the suggestion is direct and implies a change in how the results are presented. The reviewer identifies the implication of equal preactivations and proposes an alternative visualization strategy.", "grounding_specificity_rationale": "The reviewer specifically refers to 'Fig. 3 e.' and discusses the cosine similarity of 'two networks with the same membrane potentials.' This indicates a clear identification of the specific part of the paper and a specific property being discussed. The reviewer is not making a general comment but rather focusing on a particular aspect of the results.", "verifiability_rationale": "The reviewer provides a logical explanation for why the cosine similarity would be high (due to equal preactivations) and poses a question about an alternative visualization of the 'latter loss term of Eqn 13'. This demonstrates a clear understanding of the underlying concepts and suggests a constructive improvement. The reviewer is not just stating an observation but also proposing a potential improvement in how the results are presented.", "helpfulness_rationale": "The reviewer's suggestion to directly illustrate the results of the 'latter loss term of Eqn 13' is a concrete and actionable suggestion. It directly addresses the observation about the high cosine similarity and proposes a specific way to improve the presentation of the results. This feedback is directly aimed at enhancing the authors' understanding and the clarity of their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the missing comparison with testtime adaptation (TTA) methods and clearly outlines the difference in approach (model parameter adjustment vs. input data processing). This provides a concrete and actionable suggestion for the authors to consider. The reviewer also asks for experimental justification, which is a direct request for action.", "grounding_specificity_rationale": "The reviewer mentions 'testtime adaptation (TTA) methods' by name, which indicates a level of grounding. They also explain the general goal of TTA (adapting to outofdistribution data) and the difference in approach (model parameters vs. input data). However, the reviewer does not specify the exact section or table where these methods are discussed or provide specific examples of TTA methods within the paper, making the grounding somewhat implicit.", "verifiability_rationale": "The reviewer poses a question about how to prove the superiority of data processing over model parameter adjustment. This constitutes a claim that requires justification. However, the reviewer does not provide any specific evidence, reasoning, or references to support this claim. The request for 'experimental results' highlights the lack of verifiable support for their assertion.", "helpfulness_rationale": "The reviewer identifies a potential area for improvement by highlighting the absence of a comparison with TTA methods. While the suggestion is valid, it primarily points out a gap in the paper rather than offering a direct solution. The request for 'experimental results' is a request for action, but the suggestion itself is more about identifying a problem than providing a concrete remedy."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the incorrect expression for J(\u03b8) and provides the correct expression, Q(s<sup>t</sup><sub>0</sub>, \u03c0<sub>\u03b8</sub>(s<sub>t</sub><sub>0</sub>)). They also indicate that the current expression is an expected value and the correct one is an actionvalue. This provides a clear and direct action for the authors to take.", "grounding_specificity_rationale": "The reviewer not only identifies the section (Section 3.2.1) but also specifies the exact formula and explains why the current expression is incorrect. They provide the correct formula, Q(s<sup>t</sup><sub>0</sub>, \u03c0<sub>\u03b8</sub>(s<sub>t</sub><sub>0</sub>)), and explicitly state that it should replace the current one. This level of detail and precision makes the grounding very clear.", "verifiability_rationale": "The reviewer makes a claim that the first expression for J(\u03b8) is incorrect and provides the correct formula, Q(s<sup>t</sup><sub>0</sub>, \u03c0<sub>\u03b8</sub>(s<sub>t</sub><sub>0</sub>)). While they don't provide a detailed proof of the mathematical equivalence, they offer a replacement that is generally accepted in the field (actionvalue vs. expected value). This provides a basis for the authors to potentially verify the correctness.", "helpfulness_rationale": "The reviewer directly points out an error in a specific section and provides the correct formula. This is a clear and actionable feedback that directly helps the authors improve their draft by correcting a specific mathematical expression."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states actions such as 'improving the paper' and lists specific actions like 'correcting capitalization errors in references'. The actions are clear and directly address the identified issues. The reviewer also mentions 'various words in many of the references need capitalization' and lists specific examples like 'ai' in Amodei et al. (2016), 'bayesian' in many papers, and 'Advances in neural information processing systems' in several papers. These are concrete actions with clear targets.", "grounding_specificity_rationale": "The reviewer mentions 'references' generally and points to specific pages (p.8 and p. 13) where capitalization errors might be located. However, they do not explicitly state which *part* of the paper (e.g., section, table, figure) contains these errors. While the pages are mentioned, the *specificity* of the section or table within those pages where the capitalization issues occur is not clearly identified. The reviewer also lists the *words* that need capitalization but doesn't specify *why* these are problematic or how they affect the paper.", "verifiability_rationale": "The reviewer states a claim: 'This paper needs to be revised to correct capitalization errors in references'. However, they do not provide any logical reasoning, common knowledge, or external references to support this claim. They simply state the problem exists without explaining *why* these errors are problematic or how correcting them would benefit the paper. They also list the specific words that need capitalization but do not provide any justification or evidence for why these are indeed errors.", "helpfulness_rationale": "The reviewer provides a list of actions to take, such as 'correcting capitalization errors in references'. While these actions are clear and actionable, the reviewer does not explain *why* these corrections are necessary or how they will improve the paper. The feedback is presented as a list of actions without any justification or reasoning behind them. The reviewer does not explain the impact of these errors on the paper's clarity, professionalism, or scientific rigor."}
{"actionability_label": "High", "grounding_specificity_label": "Weakly Grounded", "verifiability_label": "X", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states what information is missing: 'I didn't find all parameter values' and 'What are the model parameters for task 1? What lambda was chosen for the Boltzmann policy.' This indicates a lack of specific details. However, the reviewer also implies an action: 'But more importantly: How were the parameters chosen?' This suggests the reviewer desires to understand the methodology behind the parameter selection. The criticism is not just about missing information, but also about the lack of justification for the absence of this information. The reviewer's request for clarification on parameter selection points to a potential area for improvement in the paper's transparency and reproducibility.", "grounding_specificity_rationale": "The reviewer does not explicitly state which part of the paper is being addressed with the question 'What are the model parameters for task 1?'. While the context might suggest the reviewer is referring to the model parameters discussed in the paper, the specific section or table is not mentioned. Therefore, the grounding is weak. The reviewer also does not specify *what* is wrong with the parameters or the parameter selection process, making the grounding less specific.", "verifiability_rationale": "The reviewer's criticism is primarily about the *lack* of information and the *lack of justification* for that lack of information. While the reviewer identifies specific *parameters* (model parameters, lambda for Boltzmann policy), the *process* of choosing them is not described or justified. There is X being made, only a question about where to find information and how it was obtained. Therefore, this criticism does not fit the definition of a claim requiring verifiability.", "helpfulness_rationale": "The reviewer provides specific examples of what information is missing and *why* it would be helpful for the authors. They are asking for details about model parameters and the selection process, which are directly relevant to understanding and potentially reproducing the work. The criticism is not about the truth of a statement, but about the *lack* of information and the *lack of justification* for that lack. While the *information* itself might be verifiable elsewhere, the *review itself* points out a concrete gap in the paper's clarity and completeness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points to a potential weakness in the authors' approach by suggesting the strong performance might stem from the first step. While it raises a valid concern, it doesn't explicitly state what the authors should do to address this. The reviewer implies a need to investigate the first step further but doesn't provide concrete, actionable steps. The suggestion is more of a question or a pointer to an area of concern rather than a direct instruction on how to improve the draft.", "grounding_specificity_rationale": "The reviewer refers to the authors' claim about 'stateoftheart results' and their 'first step'. While this points to a general aspect of their work, it doesn't specifically identify a particular section, table, figure, or unique element of the paper that needs improvement. The reference is more general and doesn't pinpoint a concrete location within the authors' submission.", "verifiability_rationale": "The review contains a claim: 'the authors claim to achieve stateoftheart results on challenging scene text recognition tasks, even outperforms the deeplearning based approaches, which is not convincing.' However, this claim is not supported by any evidence or logical reasoning within the review point. There are no references to external works, data, or specific examples to back up the authors' performance claims. The reviewer states the claim but doesn't provide any justification or supporting evidence.", "helpfulness_rationale": "The review raises a valid concern about the authors' claim of achieving stateoftheart results and suggests that the performance might be due to the first step. While it doesn't provide direct solutions, it points to a crucial area for further investigation and challenges the authors' confidence in their findings. By highlighting this potential issue, the review encourages the authors to be more critical of their results and potentially conduct additional experiments or analyses. Although it doesn't offer explicit instructions, it prompts a valuable reflection and potential improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a question about the performance of the model with a specific architectural change. While the reviewer points out the performance difference, they don't explicitly state what action the authors should take or how to address the issue. The authors would need to infer the potential problem and seek clarification or further investigation. Therefore, it is 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 2' and the specific layers (2, 3, and 4) when describing the experiment. This clearly identifies the specific part of the paper being addressed. However, the reviewer does not specify *why* the performance deteriorates. They are stating a fact (performance difference) but not explaining the underlying cause. Therefore, it is 2.", "verifiability_rationale": "The reviewer is making a claim about the performance of the model under a specific condition ('Table 2, applying Conditional Batch Norm to layer 2 in addition to layers 3 and 4 deteriorates performance for GuessWhat?! compared to when CBN is applied to layers 4 and 3 only'). However, the reviewer does not provide any reasoning, common knowledge, or external references to support this claim. The claim is presented as a statement without justification. Therefore, it is 1.", "helpfulness_rationale": "The reviewer is pointing out a performance issue with a specific architectural modification. This is a common type of feedback that can be helpful for authors, as it highlights a potential problem and encourages them to investigate further. While the review doesn't offer a solution, identifying a weakness is a valuable piece of information. Therefore, it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the 'lack of comparison with a highly relevant method' and suggests 'including the method comparison or its ensemble strategies'. This is an explicit action with concrete details about the method and its components (intertask ensemble, intratask ensemble).", "grounding_specificity_rationale": "The reviewer explicitly mentions a 'highly relevant method' and its specific components ('intertask ensemble', 'intratask ensemble'). This clearly grounds the suggestion to a specific part of the paper and a specific issue.", "verifiability_rationale": "The reviewer makes a claim that 'the lack of comparison with a highly relevant method is a problem' but does not provide any logical reasoning, common knowledge, or external references to support this claim. The justification is based on the *what* (lack of comparison) rather than the *why*.", "helpfulness_rationale": "The reviewer identifies a specific area for improvement ('lack of comparison') and suggests a concrete action ('include the method comparison or its ensemble strategies'). However, they do not provide any guidance on *how* to perform this comparison (e.g., which datasets, metrics, specific aspects to compare)."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point asks for clarification, which is an implicit action. However, it doesn't specify what needs clarification, making it vague and not fully actionable. To be actionable, it should explicitly state the action and provide details on how to apply it.", "grounding_specificity_rationale": "The review point mentions 'Witness oracle' without specifying which part of the paper it refers to. This lack of identification makes the comment weakly grounded. Additionally, it doesn't detail what is wrong with the Witness oracle, so it is not specific.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It is a request for clarification, which falls under the 'X' category.", "helpfulness_rationale": "The review point is a request for clarification, which, on its own, does not directly improve the draft. It lacks specificity and doesn't identify any potential weaknesses or suggest concrete actions. Therefore, it is not helpful in its current form."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a limitation of the proposed method (handling headpose) and suggests an alternative approach (conditioning headpose like Gafni et al.). They ask 'why' this is not possible. While the reviewer identifies a potential issue, the suggestion to condition headpose is presented as a possibility, not a direct criticism of what the method *should* do. The 'why' part of the question implies a desire for clarification rather than a direct actionable point.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed method' and 'headpose' when discussing the limitation. They also specify the *potential* solution (conditioning headpose like Gafni et al.). This indicates a clear identification of the specific aspect of the paper being addressed and the nature of the issue.", "verifiability_rationale": "The reviewer states that the proposed method cannot handle headpose and suggests a similar technique was used in another work. However, they do not provide any evidence or justification within this review point to support the claim that the proposed method *cannot* handle headpose. The suggestion is presented as a possibility, not a definitive limitation of the method itself.", "helpfulness_rationale": "The reviewer points out a limitation of the proposed method and asks a question about it. While this can be helpful in identifying areas for improvement, the lack of verifiable evidence within the review point makes it difficult for the authors to definitively understand the issue or how to address it. The question is somewhat openended, as it doesn't provide a clear path forward or a definitive answer."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue with the spurious features and suggests investigating their similarity to backdoor triggers. While the reviewer identifies a problem, they do not explicitly state the exact action the authors should take to address it. The suggestion is more of an observation and a direction for further analysis rather than a direct instruction on how to modify the model or data.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3.1 and 3.2,' which clearly identifies the specific part of the paper being addressed. This demonstrates strong grounding as the reviewer can accurately pinpoint the section being discussed.", "verifiability_rationale": "The reviewer makes a claim about the impact of spurious features on the model, stating that 'It is wellknown that a few training examples with such triggers (rare spurious examples in this paper) would have a large impact on the trained model.' This claim is supported by the reviewer's knowledge and the examples provided (Chen et al. (2017), Gu et al. (2019)). While not a direct citation in the review point, the context and the established knowledge in the field make this claim verifiable.", "helpfulness_rationale": "The reviewer provides a clear explanation of a potential issue and suggests a direction for investigation. By pointing out the similarity to known harmful patterns, the reviewer provides valuable context and encourages the authors to explore the impact of these spurious features. This feedback is helpful as it highlights a potential problem and guides the authors towards further analysis."}
{"actionability_label": "3", "grounding_specificity_label": "1: 2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the optimization algorithm is 'directly from some previous works'. This is a clear and direct statement of what they believe, making it explicit. However, the reviewer does not specify *which* previous works or *how* it's directly taken from them, making it less concrete.", "grounding_specificity_rationale": "The reviewer mentions 'optimization algorithm' in the context of the structural optimization component. However, they do not explicitly identify the specific part of the paper where this information is relevant. They do not mention a particular section, table, figure, or unique aspect of the paper where this information is pertinent. Therefore, the grounding is weak. While the reviewer identifies a potential issue, they do not specify *what* needs to be addressed in this part.", "verifiability_rationale": "The reviewer makes a claim that the optimization algorithm is 'directly from some previous works'. However, they do not provide any evidence, citations, or logical reasoning to support this claim. The statement is presented as a statement of belief rather than a wellsupported assertion. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer's point about the algorithm's origin impacting the contribution is a valid concern for the authors. It highlights a potential weakness in the work's novelty. While the reviewer's point is clear and directly addresses a potential issue, framing it as a question about contribution might be slightly less helpful than a direct suggestion for improvement. The reviewer identifies a problem, but the presentation could be more actionable."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the 'pipeline style method including two models' does not give better average results for both XVNLI and MaRVL. This directly points to a specific area of the method that needs improvement. The reviewer suggests that the authors should investigate the performance of this specific pipeline on these datasets.", "grounding_specificity_rationale": "The reviewer mentions 'pipeline style method including two models' as the basis for the criticism. While this identifies a general methodological aspect, it doesn't pinpoint the exact section, table, or unique element within the paper where this method is described. The reviewer can infer the relevant part but cannot precisely identify it.", "verifiability_rationale": "The reviewer states that the 'pipeline style method including two models' does not give better average results for both XVNLI and MaRVL. However, the reviewer does not provide any logical reasoning, examples, or references to support this claim. The statement is presented as an observation without further justification.", "helpfulness_rationale": "The review identifies a potential issue with a specific experimental setup ('pipeline style method including two models') and suggests investigating its performance on specific datasets (XVNLI and MaRVL). This provides a clear direction for the authors to take. However, the lack of grounding and verifiability means the authors do not know *why* this issue exists. The criticism of the baseline models' introduction is also vague and does not offer specific improvements, making the overall feedback less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests using a 'more sophisticated methodology' to address the issue of reproducing known results. While this indicates a desire for improvement, the review lacks specific details on how to implement this 'more sophisticated methodology'. Without concrete steps, the suggestion remains at a high level, making it somewhat general and lacking actionable details.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the 'coarse' (their description) methodology of passing a binary stance classifier over ChatGPT's output' as the problematic aspect. This clearly identifies a specific part of the methodology being criticized, making it grounded. However, the reviewer does not specify a particular section or table within the paper where this methodology is detailed, making it only weakly grounded as the exact location is not pinpointed.", "verifiability_rationale": "The reviewer states that the observation about bias reproduction has been made at each step of LLM evolution and criticizes the authors' 'coarse' methodology. This constitutes a claim that the authors' methodology is redundant given prior findings. The reviewer provides a logical reasoning (redundancy of finding) and a common knowledge aspect (the progression of bias observation in LLMs) to support this claim, making it verifiable.", "helpfulness_rationale": "The reviewer points out a valid concern regarding the authors' methodology and suggests a potential improvement by using a 'more sophisticated methodology'. While this is a relevant point, the suggestion is quite general and does not offer specific implementation details. Without concrete steps, it is difficult for the authors to directly apply this feedback, making it 3 but lacking the depth needed for significant improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that 'When discussing related work it is crucial to mention related work on modular networks for VQA such as A' and 'otherwise the introduction right now seems to paint a picture that no one does modular architectures for VQA.' This directly tells the authors what to do and why it's important. The action is explicit, and the details are concrete.", "grounding_specificity_rationale": "The review point explicitly mentions 'A' as a specific example of related work on modular networks for VQA and links this to the 'introduction' of the paper. This allows the authors to precisely identify the section and the specific type of related work being referred to.", "verifiability_rationale": "The review point makes a claim: 'When discussing related work it is crucial to mention related work on modular networks for VQA such as A'. It also provides a justification: 'otherwise the introduction right now seems to paint a picture that no one does modular architectures for VQA.' This justification is logical and points to a specific area for improvement in the introduction.", "helpfulness_rationale": "The review point is highly specific, telling the authors exactly what to do (mention related work on modular networks for VQA, specifically A) and where to do it (the introduction). It also explains why this is important (the introduction seems to misrepresent the use of modular architectures). This makes the feedback actionable and directly addresses a potential issue."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the authors' focus on SSC and suggests a comparison with other methods, indicating an implicit action: to contrast their method with TSC and greedy subspace clustering. While it doesn't explicitly say 'improve your introduction by including a discussion of TSC...', the implication is clear.", "grounding_specificity_rationale": "The comment explicitly mentions 'TSC' and 'greedy subspace clustering', which are specific methods. It also implies a comparison with these methods given the authors' focus on SSC. The authors can infer the need to discuss and compare their method with these specific techniques.", "verifiability_rationale": "The comment makes a claim about the authors' focus on SSC and provides information about the properties of TSC and greedy subspace clustering. It logically infers that a comparison with these methods would be beneficial. The properties of TSC and greedy subspace clustering serve as supporting evidence.", "helpfulness_rationale": "The comment points out a potential gap in the authors' discussion and suggests a relevant comparison. It highlights the relevance of TSC and greedy subspace clustering given the computational efficiency and similar guarantees. However, it doesn't explicitly tell the authors *how* to improve their method or where exactly in the paper they should make this comparison. The helpfulness is indirect, suggesting a direction for improvement rather than a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a specific area of confusion in the paper (the distinction between weak and semisupervised training) and proposes a concrete solution (clearer column names and structure in Table 1). While the reviewer doesn't explicitly state *how* to implement the solution, the suggestion is quite specific and actionable. The reviewer also points out that the current presentation in Table 1 is unclear, which is a concrete observation about the paper's content.", "grounding_specificity_rationale": "The reviewer explicitly states what information is missing (clarity on weak vs. semisupervised training) and how the authors can identify the missing part (by looking at Table 1 and the descriptions of the methods). The reviewer also suggests a specific way to ground the information (adding new columns to Table 1). This demonstrates a strong understanding of where the information should be and how to find it. The suggestion is quite specific and would likely make the information clear to the authors.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity in the paper regarding the training regimes. They then provide a method for verifying this claim (by examining Table 1 and the method descriptions). The reviewer also offers a solution (clearer column names and structure) which directly addresses the identified issue. The claim is verifiable through direct examination of the paper, and the proposed solution is also quite concrete.", "helpfulness_rationale": "The reviewer provides a clear and specific point of confusion for the authors. They directly address a potential ambiguity in the paper's description of the training process. The suggestions for improvement (clearer column names and structure) are actionable and would likely significantly enhance the authors' understanding of the proposed method. This makes the review point very helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states the perceived similarity to previous methods ('mostly good engineering') and the difficulty in differentiating the contribution ('seems hard to differentiate'). This constitutes an explicit action (identifying a weakness) but lacks specific details on how to address it, making it 3.", "grounding_specificity_rationale": "The reviewer names specific prior works (NCNet 6 and Sparse NCNet 21) and generally refers to the 'previous methods' and the 'contribution'. This grounds the comment by referencing specific parts of the paper. However, the reviewer also generally describes the weakness ('seems hard to differentiate') without pointing to a specific technical detail or experimental result where the similarity is evident, making it somewhat specific.", "verifiability_rationale": "The comment contains a claim ('Small contributions... mostly (good) engineering. And despite that it seems hard to differentiate it from its predecessors, as it performs very similarly in practice.') that the paper's contribution is small and lacks clear distinction from previous work. However, the reviewer does not provide any evidence or reasoning to support this claim. The statement is an opinion without backing, making it 1.", "helpfulness_rationale": "The reviewer expresses a negative sentiment about the paper's contribution, suggesting it's not a significant advancement. While they identify a potential weakness ('small contributions'), they don't offer any specific suggestions or analysis to address it. The comment is primarily a critique without actionable improvements, making it 2 in terms of providing concrete feedback for improvement. The lack of specific examples makes it difficult for the authors to act on this feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the characterization of semantic segmentation as a 'lowlevel cue' is incorrect and should be removed. This is a direct and actionable suggestion. The authors know exactly where in their paper (likely the section describing semantic segmentation) they need to make the change and what the correct characterization should be (likely 'highlevel' or 'pixelbased'). The action is clear: remove the incorrect statement and replace it with the correct one.", "grounding_specificity_rationale": "The review point directly refers to 'semantic segmentation' and its characterization as a 'lowlevel cue'. The terms are specific to the paper's content. The reviewer can confidently identify the section or concept being addressed. The grounding is explicit.", "verifiability_rationale": "The review point contains a claim: 'the statements about semantic segmentation being a lowlevel cue should be removed from the paper.' While the reviewer doesn't provide extensive justification *within the review point itself*, the statement itself implies a degree of verification. The reviewer understands the pixelbased nature of semantic segmentation categories and recognizes that 'lowlevel cue' is an inaccurate characterization. The evidence for this claim is implicit but present.", "helpfulness_rationale": "The review point is 5. It directly identifies a factual error in the paper (the characterization of semantic segmentation) and provides a clear, actionable suggestion for improvement (remove the incorrect statement). This directly guides the authors to a specific part of their paper and the exact change they need to make. The impact on the authors' work is clear and direct."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a discrepancy in the ablation experiment results and notes the absence of specific cases in the tables. While the reviewer identifies a problem, they do not explicitly suggest concrete actions or modifications the authors should make based on this observation. The action is implied but not stated directly.", "grounding_specificity_rationale": "The reviewer refers to 'the ablation experiment' and 'the two tables,' indicating that they are identifying a specific part of the paper where information is lacking. However, they do not specify *which* element within the tables is missing or what exactly is not listed. The grounding is present, but the specificity is limited to the general area.", "verifiability_rationale": "The reviewer makes a claim that 'the two tables do not list the cases where dependency tree and RL are not used.' This is a verifiable statement as it refers to the content of the tables. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support why this omission is problematic or what should be listed in those cases. The claim is stated, but the verification is missing.", "helpfulness_rationale": "The reviewer identifies a discrepancy in the ablation experiment results and points out the missing information in the tables. This observation highlights a potential issue for the authors. However, the reviewer does not offer any specific suggestions or guidance on how the authors should address this problem or update the tables. While the feedback identifies a need, it lacks concrete steps for improvement, making it 3 but lacking actionable value."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the 'experiments section' as the main weakness and provides concrete examples of missing information, such as the specific dataset 'CIFAR10' and mentions 'other datasets from Federated learning benchmarks (e.g., LEAF)'. They also name specific papers (FedProx and FedMAX) that highlight the importance of these benchmarks. This clearly indicates an explicit action and concrete details on how to implement it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the experiments section' and then further specifies the lack of evaluation on 'CIFAR10 dataset and other datasets from Federated learning benchmarks (e.g., LEAF)'. They also name specific papers (FedProx and FedMAX) that provide relevant context and examples. This indicates a strong grounding in the specific part of the paper and a high level of specificity about the missing information.", "verifiability_rationale": "The reviewer makes a claim about the 'main weakness of this paper being the experiments section' and then provides specific evidence to support this claim by stating that 'the results are presented only on CIFAR10 dataset and do not consider many other datasets from Federated learning benchmarks (e.g., LEAF)' and by naming specific papers (FedProx and FedMAX) that highlight the importance of these benchmarks. This provides clear verification of the claim.", "helpfulness_rationale": "The reviewer provides a clear and actionable feedback on the 'experiments section' by pointing out the limited dataset usage and suggesting the inclusion of more comprehensive evaluations on other federated learning benchmarks. They provide specific examples (CIFAR10, LEAF, FedProx, FedMAX) to support their suggestion, making the feedback very concrete and helpful for the authors to improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out that the authors consider a single vulnerability at a time, which is an implicit action. While the reviewer doesn't explicitly say 'You should consider multiple vulnerabilities,' they highlight a limitation in the methodology that could be actionable for the authors. However, the reviewer doesn't provide concrete steps on how the authors should address this limitation, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'vulnerability discovery methodology,' 'ingle vulnerability at a time,' 'ecological validity,' 'Previous work,' and 'interpretability.' These are all specific aspects of the paper being discussed. The reviewer clearly identifies the *specific* area of the paper and the limitations within that area. This indicates strong grounding specificity.", "verifiability_rationale": "The reviewer states facts about previous work and the challenges in interpreting the results. This is supported by common knowledge about research methodologies and the nature of interpretability. The reviewer provides logical reasoning and references (even if implicit) to support their claims. This is 5.", "helpfulness_rationale": "The reviewer provides a clear critique of the methodology and raises a specific question. While this points to a significant limitation, it doesn't offer a direct solution or actionable advice on how the authors should improve their draft based on this critique. The helpfulness is moderate as it highlights a weakness but doesn't provide a complete fix."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for an explanation of how the method achieves degree bias. While the paper claims this, it doesn't explicitly state the mechanism or provide a clear, stepbystep guide on how to implement it. The reviewer needs to understand the underlying process to apply this understanding. The paper focuses on the *outcome* (degree bias) and the *proven properties* (intracommunity concentration and intercommunity scatter) but doesn't explicitly explain the *how*. Therefore, the actionability is borderline as the reviewer needs to infer the action.", "grounding_specificity_rationale": "The reviewer is asking for a clear identification of the specific part of the paper where degree bias is achieved and a clear explanation of what is wrong or missing in that part. The paper mentions intracommunity concentration and intercommunity scatter, which are relevant, but it doesn't explicitly state *how* GCL achieves degree bias or *how* these properties relate to it. The grounding is weak because the authors can't confidently pinpoint the exact mechanism or the specific connection to degree bias. While the concepts are mentioned, the explicit link is missing, making it not fully grounded.", "verifiability_rationale": "The reviewer is asking for a clear justification of the claim that GCL conforms to a clearer community structure via intracommunity concentration and intercommunity scatter and its relationship with degree bias. While the paper provides logical reasoning and potentially external references (though not explicitly requested in this case, it's a good implicit check), the connection between these properties and degree bias is not intuitive enough. The reviewer needs a more detailed explanation of *why* these properties lead to degree bias and *how* GCL facilitates this. The explanation is somewhat vague, making it partially verifiable but not fully robust. The paper proves the properties but doesn't fully explain the intuitive link to degree bias.", "helpfulness_rationale": "The reviewer is asking for feedback that empowers them to improve their understanding of how GCL achieves degree bias. While the paper claims this and provides some justification, the explanation is not clear enough for the reviewer to fully grasp the mechanism and its implications. The feedback is 3 as it points towards a need for a clearer explanation, but it doesn't immediately provide actionable steps beyond understanding the mechanism. The reviewer needs more guidance on how to apply this understanding to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer's question is explicit about the missing information regarding the construction of 'clean exemplar manifolds' for ResNet50 and ATResNet50. While the action is explicit (asking for information), the lack of concrete details on how this 'action' is to be carried out makes it somewhat vague. The reviewer is asking for a specific clarification that is not immediately provided in the paper.", "grounding_specificity_rationale": "The reviewer explicitly points to lines 182183 as the source of their confusion. This demonstrates strong grounding as they are directly referencing a specific section of the paper. The reviewer also clearly states what they are asking for \u2013 the construction of clean manifolds and the calculation of the denominator in Figure 2c \u2013 making the specificity high within that referenced section.", "verifiability_rationale": "The reviewer is not making a claim about the paper itself. Instead, they are highlighting a potential inconsistency or lack of clarity in the description of how manifold capacity is measured. This could be considered 'underjustified' as the paper doesn't explicitly address how the 'clean' manifold is constructed or how the denominator in Figure 2c is calculated, especially for nonperturbed networks. Without this information, the reproducibility of the results could be hindered.", "helpfulness_rationale": "The reviewer's question is highly specific and directly addresses a potential source of confusion for the authors. By clarifying how 'clean' manifolds are constructed and how the denominator in Figure 2c is calculated, the authors would gain a crucial piece of information that could significantly improve their understanding and ability to replicate the experiments. This directly helps them interpret the results and potentially identify issues in their own models."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the confusion regarding the variables 'S' and 'Xt' and suggests adding more information. While the paper likely contains information about static and temporal features, it doesn't explicitly define 'S' and 'Xt' in the context of this split. The reviewer's suggestion to clarify this is an implicit action the authors should take, making it 3 but potentially vague as the paper might provide the necessary information elsewhere or in a more detailed form.", "grounding_specificity_rationale": "The reviewer identifies the issue as being related to the distinction between static and temporal features. While the paper likely discusses these concepts, the reviewer doesn't explicitly point to a specific section, table, or figure. However, they *mention* the variables 'S' and 'Xt' as the source of confusion, providing some level of specificity to the problematic area.", "verifiability_rationale": "The reviewer presents the confusion about 'S' and 'Xt' as a problem without explicitly stating why it's a problem or providing a claim. There's no logical reasoning, common knowledge, or external references provided to support the statement. Therefore, it can be considered a statement requiring justification or an opinion, but without any backing.", "helpfulness_rationale": "The reviewer's comment directly points to a potential improvement in the paper's clarity by explicitly defining the variables 'S' and 'Xt'. This is a clear and actionable suggestion that would benefit the authors by making the paper easier to understand. While the paper likely contains the information, the lack of explicit definition is a concrete weakness that the authors can address."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the paper should provide a rationale for the formula, indicating an implicit action (providing justification) that is not directly stated. The lack of a clear explanation makes it difficult for the authors to understand the basis for this specific choice.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific part of the paper (Theorem 3) where the formula appears and points out the lack of motivation. This demonstrates strong grounding specificity as the authors can easily locate the referenced part and the issue.", "verifiability_rationale": "The reviewer claims the paper lacks justification for the formula, forming a claim that needs verification. While the paper states the formula is empirical, it doesn't provide the reasoning behind this choice, making it difficult to verify the claim.", "helpfulness_rationale": "The reviewer finds the current explanation lacking and suggests it could improve the paper. This indicates that the feedback is not entirely missing but is incomplete or unclear, making it less helpful for the authors to understand and implement the suggested change."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the need for 'more details' and provides specific suggestions for 'definitions of the resistance distance' and 'more explanations on Alg. 1 with brief sentences defining A_t, Y_t,...'. These suggestions are direct and actionable, indicating the reviewer is directly pointing out areas where the authors should apply changes.", "grounding_specificity_rationale": "The review point mentions 'many graph notions' generally, which is a broad category. While it then specifies 'definitions of the resistance distance' and 'more explanations on Alg. 1 with brief sentences defining A_t, Y_t,...', it doesn't explicitly state the exact section, table, or unique aspect where these are addressed. The grounding is present but not as precise as it could be.", "verifiability_rationale": "The review point states 'the writing is generally good though more details could sometimes be provided'. This statement expresses a judgment about the paper's quality and the need for more information. While it implies a potential issue, the reviewer doesn't provide specific citations or references to external sources to support this claim about the writing being 'generally good'. The claim is present, but the justification is not strongly supported by verifiable evidence within the paper itself.", "helpfulness_rationale": "The review point directly identifies areas where the authors can improve their paper by providing more details and explanations. The suggestions are concrete and actionable, clearly indicating what the authors should do to enhance their work. The reviewer is directly aimed at helping the authors address specific weaknesses."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The statement is explicit about the limited originality, making it somewhat explicit. However, it lacks concrete details, making it somewhat vague. For example, it doesn't specify which aspects of variable splitting or the algorithm are not new.", "grounding_specificity_rationale": "The reviewer *mentions* the concepts of \"variable splitting\" and \"algorithm,\" which provides some grounding. However, they don't explicitly point to a specific section, table, figure, or unique aspect of the paper being addressed. The mention is general, like a literal mention of sections, tables, figures, etc., which can be considered weak grounding.", "verifiability_rationale": "The statement itself is not a direct criticism or suggestion for improvement. It's an observation about the originality. Therefore, there is no evidence of verifiability in this aspect.", "helpfulness_rationale": "The statement is helpful in informing the authors that their work might not be groundbreaking. It sets expectations and helps them focus their efforts. While it doesn't provide specific actionable steps, it is informative and empowers the authors to understand the context of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the limitation of using training image transformations to prove shape model invariance and clearly identifies the action of looking at quantitative results on testing images. This makes it a concrete and actionable point.", "grounding_specificity_rationale": "The comment explicitly refers to the 'shape model invariance study' and specifically asks about quantitative results on 'testing images'. This demonstrates strong grounding and specificity as the authors can easily identify the referenced part of the paper and the issue being addressed.", "verifiability_rationale": "While the comment itself doesn't contain a claim, it implicitly points to a need for further evidence on testing images. If the paper does not provide this, the reviewer's point is 1. However, if it does, the point is verifiable. Therefore, it can be considered 3 as it highlights a gap in the presented evidence.", "helpfulness_rationale": "The comment clearly identifies a potential limitation in the experimental setup and prompts the authors to consider results on testing images. This is a constructive and actionable suggestion, making the point helpful, although it doesn't explicitly propose a solution."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly names a specific paper (Ghoshdastidar and Dukkipati, AAAI 2015) and suggests a concrete action: 'discuss and compare against'. This directly points the authors to a relevant work and tells them what to do with it. The action is both explicit ( naming the paper) and concrete (suggesting comparison).", "grounding_specificity_rationale": "The review point explicitly names the paper (Ghoshdasticiarid and Dukkipati, AAAI 2015) and provides a brief explanation of its relevance by mentioning its focus on hypergraphs and tensors, which aligns with the reviewer's mention of tensors. This allows the authors to identify the specific paper being discussed and understand the context of the suggested comparison.", "verifiability_rationale": "The review point contains a claim: 'This AAAI 2015 paper deals with hypergraph data with tensors as well so it should be discussed and compared against to provide a better understanding of the stateoftheart.' While the reviewer doesn't provide a detailed proof within the review point, the statement itself is verifiable by examining the mentioned paper. The claim is supported by the stated relevance of the paper to hypergraphs and tensors.", "helpfulness_rationale": "The review point is 5 because it directly identifies a relevant piece of related work and provides a clear action for the authors: 'discuss and compare'. This is a specific and actionable suggestion that directly addresses the authors' need to understand the stateoftheart. The reviewer is not just pointing out a related work but also guiding the authors on how to engage with it."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point presents several questions and statements related to the computational cost and scalability of the optimal transport method. While the questions are direct and point to specific areas for improvement, they lack explicit instructions on how to address them. The reviewer asks about scalability on normal machines and the transition from the Sinkhorn output to the exact optimal transport matrix, but doesn't provide concrete steps or guidance on how to investigate these aspects. The statements about the expense of optimal transport are generally true but don't directly suggest improvements to the authors' draft.", "grounding_specificity_rationale": "The review point explicitly mentions 'normal machines with a couple of cores' and 'Sinkhorn method gives you a doubly stochastic matrix'. These phrases directly identify the specific aspect of the method being discussed (scalability and the nature of the Sinkhorn output). The reviewer is asking about the behavior of the method under specific conditions and about a specific technical detail of the algorithm. This provides a clear target for the authors to investigate and address.", "verifiability_rationale": "The review point contains claims that could be considered verifiable. The statement about optimal transport being expensive is generally verifiable through common knowledge in the field. The question about scalability on normal machines requires understanding the algorithm's complexity and how it scales with the number of cores, which can be verified through logical reasoning or by referencing relevant literature. The question about the Sinkhorn output to exact optimal transport also points to a verifiable aspect of the algorithm, although the exact method to achieve this might require external references.", "helpfulness_rationale": "The review point is 5. The questions directly address potential limitations of the method (scalability) and a specific technical detail (Sinkhorn output to exact transport). These questions empower the authors to investigate and potentially improve their draft by considering these aspects. The reviewer is actively engaging with the method and pointing out areas that need clarification or further investigation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'Some ablation study is missing...' and further specifies 'the hyperparameters in the RBF kernel' (\u03c3, \u03b7, \u03c4). This is a clear and actionable criticism.", "grounding_specificity_rationale": "The reviewer mentions 'the hyperparameters in the RBF kernel' and explicitly names them (\u03c3, \u03b7, \u03c4). This demonstrates both grounding (referring to a specific part of the paper) and specificity (identifying the exact elements).", "verifiability_rationale": "The reviewer makes a claim ('no analysis is given') about a specific area (the hyperparameters in the RBF kernel). This claim is verifiable by pointing to the existence of these hyperparameters and the potential impact they have on the model's performance. While the reviewer doesn't provide the analysis, the claim about the missing analysis is supported by the knowledge of machine learning and the context of the paper.", "helpfulness_rationale": "The reviewer's suggestion to analyze the hyperparameters in the RBF kernel is a relevant and likely beneficial piece of feedback for the authors. It points them towards a specific area of investigation that could improve their model. While it's not a direct fix, it's a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states that the paper was 'extremely hard to follow' and points to 'experimental procedures' and 'evaluations' as areas of difficulty. While it identifies a problem, it does not explicitly state what needs to be changed or how the issues should be addressed. The authors are left to infer the necessary steps, making the action implicit rather than explicit.", "grounding_specificity_rationale": "The comment mentions 'the paper' generally and then points to 'experimental procedures' and 'evaluations' as areas of difficulty. While it identifies broad categories, it doesn't specifically name sections, tables, figures, or any unique elements within those categories that are causing confusion. The grounding is present but not fully precise.", "verifiability_rationale": "The comment is a statement of opinion ('The paper was extremely hard to follow') rather than a claim that requires verification. There are no references to external works or logical reasoning to support this statement. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The comment identifies a significant issue ('extremely hard to follow') and points to specific areas within the paper ('experimental procedures' and 'evaluations') that need clarification. While it doesn't provide specific solutions, it clearly indicates where the authors should focus their attention and what information is lacking. This makes it 3 in guiding the authors to the relevant parts of their own document."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The statement 'Finally, INRs operate on a perdatainstance basis, meaning that one timeseries instance is required to train an INR' is explicit in identifying the mechanism of INR operation. However, the reviewer's suggestion to clarify that this applies to *each instance* within a batch is a specific, actionable improvement. While the initial statement is explicit, the reviewer's point highlights a potential lack of clarity for the reader, making it 3 if explicitly stated.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly point to a specific section, table, figure, or unique aspect of the paper being addressed. They are commenting on a general statement about how INRs operate. However, the reviewer does specify what they find unclear: 'A model that can only handle a single time series data is almost useless.' This provides some level of specificity in their feedback, making it somewhat grounded.", "verifiability_rationale": "The reviewer makes a factual claim: 'Finally, INRs operate on a perdatainstance basis, meaning that one timeseries instance is required to train an INR'. This claim is verifiable based on the definition of 'perdatainstance basis'. While the reviewer doesn't provide external references or complex reasoning, the statement itself is a clear assertion supported by the definition they provided. Therefore, it is **3** as it is verifiable but could benefit from more explicit justification.", "helpfulness_rationale": "The reviewer's point directly addresses a potential misunderstanding of INRs and their limitations. By highlighting that a model handling only single timeseries data is practically useless, the reviewer provides a clear and actionable piece of information for the reader. This directly helps them understand the practical implications of the model's capabilities and guides them to consider the limitations. Therefore, it is **5**."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the missing information: 'certain parameters are bounded on one side (acceleration and scaling parameters)'. This provides a clear target for the authors to address. The reviewer also suggests a concrete action: 'Consider introducing the aspects of the specific model that are specific to this example model'. This indicates a direct and actionable improvement the authors should consider.", "grounding_specificity_rationale": "The reviewer refers to 'the specific model' and mentions 'acceleration and scaling parameters'. This provides some grounding as the parameters are specific to the model. However, the review point does not explicitly point to a unique section, table, or figure within the paper, making the grounding less precise than fully grounded. The parameters are mentioned, but not in a way that clearly identifies a specific part of the paper.", "verifiability_rationale": "The review point makes a statement about the paper's content: 'it should be clear from the beginning that we are not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters)'. This is a claim based on the paper's description. However, the review point itself does not provide explicit evidence or justification within its own text to verify this claim about the bounded parameters. The reviewer's suggestion is more of a constructive improvement than a verifiable claim about the paper's current state.", "helpfulness_rationale": "The review point identifies a potential area for improvement by pointing out the lack of clarity regarding parameter bounds in the specific model. The reviewer suggests a concrete action: 'Consider introducing the aspects of the specific model that are specific to this example model'. This suggests a helpful and actionable improvement. However, the review point itself does not explicitly state *why* this boundedness is a problem or how it affects the model's behavior. It's more of a suggestion for clarification and improvement rather than a direct critique of a flaw."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'It is important to investigate whether the results can be generalized to differences in model size, objective function, and architecture (i.e., encoder, encoderdecoder, or decoder)'. It also provides a specific suggestion: 'In particular, it is worthwhile to include more analysis and discussion for GPT2. For example, I would like to see the results of Figure 2 for GPT2.'", "grounding_specificity_rationale": "The comment explicitly mentions 'other models adopting learnable APEs' and specifically suggests investigating 'GPT2' and 'differences in architecture (encoder, encoderdecoder, or decoder)'. This clearly identifies the specific parts of the paper being addressed.", "verifiability_rationale": "The comment makes a claim: 'Most of the experiments (excluding Section 4.1.1) are limited to RoBERTabase only, and it is unclear if the results can be generalized to other models adopting learnable APEs.' It does not provide any logical reasoning, common knowledge, or external references to support this claim.", "helpfulness_rationale": "The comment identifies a limitation in the experiments and suggests specific areas for improvement (testing on other models, analyzing different architectures). While it points in a productive direction, it doesn't provide specific instructions or expected results for the suggested experiments. For example, it doesn't specify how to analyze the results for GPT2 or how to compare encoder, encoderdecoder, and decoder models."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a limitation in the scope of the method (ViT and image data) and suggests exploring other areas (NLP) and simpler models. This is an implicit suggestion for improvement, indicating a lack of explicit actionability on the part of the authors. The reviewer doesn't directly tell the authors *what* to do, but rather points out a gap in their current approach.", "grounding_specificity_rationale": "The reviewer explicitly states the limitations of the method to ViT and image data. While they don't pinpoint a specific section or table, the mention of 'parameters in Table 1' and 'state of the art performance' suggests a general lack of applicability. The reviewer's suggestion to explore NLP and simpler models indicates a lack of specific grounding in the current work or alternative approaches. The weakness is in identifying a concrete area of the paper that needs improvement.", "verifiability_rationale": "The reviewer's comment is a question about the generalizability of the method. It doesn't contain a claim that requires verification. The reviewer is asking for clarification or a request for changes, which falls under the 'Normal Statements' category in the verifiability definition. There's no assertion that something is correct or incorrect, just a question about applicability.", "helpfulness_rationale": "The reviewer's comment is highly critical of the method's limited scope and suggests concrete ways to improve it by exploring other areas and simpler models. This demonstrates a desire for the method to be more broadly applicable and impactful. While the comment doesn't explicitly state a solution, it clearly identifies a significant limitation and proposes actionable steps for the authors to consider. The reviewer is not just pointing out a problem, but also suggesting a path towards a more general solution, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a problem (nonstandard benchmarks breaking TTA methods) but does not provide a specific action or suggestion on how to address it. It is a statement of observation rather than a directive for improvement.", "grounding_specificity_rationale": "The review point mentions 'TTA methods' and 'natural distribution shift, like WILDS 9'. While it mentions WILDS, it does not explicitly identify a specific part of the paper being addressed. The grounding is weak because the connection to the paper's specific content is not clear.", "verifiability_rationale": "The review point makes a claim ('This is an interesting observation...') but does not provide any evidence or reasoning to support it within the review itself. The claim is presented as an observation without justification.", "helpfulness_rationale": "The review point identifies a potential issue with the evaluation methodology (nonstandard benchmarks) and suggests an alternative (WILDS). While this points to a potential problem, it does not offer a concrete solution or actionable steps for the authors to address this. It is a suggestion for further investigation rather than a direct solution."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states their belief that the authors' understanding of the learning rate scaling condition is unrealistic and contradicts practical experience. While the reviewer clearly states their opinion, they do not explicitly identify a specific action or suggestion for the authors to take. They are critiquing the authors' assumptions rather than providing a direct path for improvement. Therefore, the comment is explicit in its statement but lacks a concrete action for the authors.", "grounding_specificity_rationale": "The reviewer refers to the 'required condition on the learning rate (scaling with the number of samples)' mentioned by the authors. While they do not provide a specific section number, the reviewer's criticism is directly related to a concept discussed in the paper. They are implicitly pointing to the discussion of learning rate scaling. However, the reviewer does not specify *what* aspect of the learning rate scaling is causing the issue or what specific part of the paper needs to be addressed. The grounding is weak because the authors cannot confidently pinpoint the exact location of the problem. The specificity is also lacking because the reviewer does not detail *what* is wrong with the scaling or how it should be adjusted. Therefore, the comment is 2.", "verifiability_rationale": "The reviewer makes a claim about the authors' understanding of the learning rate scaling condition being unrealistic and contradicting practical experience. This is a clear claim. However, the reviewer does not provide any evidence, reasoning, or external references to support this claim. They state their belief without backing it up. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer's comment is primarily critical of the authors' understanding and the practical implications of a stated condition. They do not offer any specific suggestions or actionable steps for the authors to take to improve their draft. The comment is more of a critique than a helpful suggestion. Therefore, the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the paper does not explain how the results are useful to machine learning algorithms or how they analyze the algorithms. This directly points to an implicit action that needs to be taken by the authors to understand the significance of their work. While the reviewer doesn't provide specific steps on how to improve this, they clearly identify a missing link in the explanation.", "grounding_specificity_rationale": "The reviewer mentions 'tensor networks,' 'PMF,' and 'machine learning algorithms' in their critique, which suggests they have identified a specific area in the paper that needs clarification. However, they do not explicitly state which part of the paper is unclear or what specific aspect of the connection between these concepts is missing. This indicates a weak grounding as the authors cannot confidently pinpoint the referenced part.", "verifiability_rationale": "The reviewer makes a claim that 'the significance of this paper is poor' based on the lack of clarity regarding the connection between tensor networks, PMFs, and machine learning algorithms. While they provide a reason for this claim, they do not offer specific examples or external references to support their assertion about the poor significance. Therefore, the claim is not fully justified by explicit reasoning or external evidence.", "helpfulness_rationale": "The reviewer's comment directly points to a significant issue in the paper \u2013 the lack of explanation regarding the significance of the results for machine learning. While they do not offer specific suggestions for improvement, their critique highlights a crucial gap that the authors need to address to make their work more impactful. The criticism is clear and identifies a problem, making it 3 in highlighting the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'The unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version) is perfectly balanced, which is impractical in realworld applications.' This is a clear and direct identification of a problem. The reviewer also suggests a solution: 'Since we cannot control the label distribution of unlabeled data during training, the author should also use a more convinced setting as did in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018, which directly samples unlabeled data from millions of reviews.' This suggests a concrete improvement. Both the problem and the solution are clearly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version)' and 'perfectly balanced'. This clearly identifies the specific part of the paper being addressed. The reviewer also names a specific paper, 'Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018', which further grounds the reference to a specific technique. The reviewer also suggests 'directly sampling unlabeled data from millions of reviews', which is a concrete alternative approach.", "verifiability_rationale": "The reviewer provides a clear explanation of why the statement about the perfectly balanced dataset is true: 'impractical in realworld applications' and suggests a more 'convincing setting' based on 'Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018'. While the reviewer doesn't provide a direct citation *in this specific point*, the reasoning is wellestablished in the field. The suggestion to use 'unlabeled data from millions of reviews' is a logical and verifiable alternative approach.", "helpfulness_rationale": "The reviewer directly points out a limitation of the authors' experimental setup: the use of a perfectly balanced unlabeled dataset, which is unrealistic. The reviewer then provides a concrete suggestion for improvement: 'the author should also use a more convinced setting as did in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018, which directly samples unlabeled data from millions of reviews.' This is a clear and actionable suggestion that can help the authors improve their work by making it more relevant to realworld scenarios."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a problem: 'It's not clear how to sample from the DPP if the eigenfunctions e_n's are inaccessible (Eq (10) line 130)' and draws a parallel to a similar problem with leverage score sampling: 'This seems to be the same problem with sampling from the leverage score in 3'. While it doesn't offer a direct solution, it clearly identifies a gap in understanding and highlights a potential area of confusion.", "grounding_specificity_rationale": "The review point explicitly mentions 'Determinantal Point Process (DPP)' and 'eigenfunctions e_n's and refers to a specific equation (Eq (10) line 130). This clearly identifies the technical concepts being discussed, demonstrating strong grounding.", "verifiability_rationale": "This review point is primarily a question asking for clarification. It doesn't present a claim that requires verification. The reviewer is seeking information about a specific technical detail, not making a statement that needs to be proven or supported.", "helpfulness_rationale": "The review point identifies a specific technical issue related to sampling from a DPP, which is likely relevant to the authors' work. The reviewer's explicit question about the connection to leverage score sampling indicates a desire for more information and a potential point of confusion. While it doesn't provide a direct solution, it highlights a potential area where the authors might need further guidance. The reviewer's engagement suggests it's at least 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point states a limitation of the study. While it points out a *potential* area for future work, it doesn't directly instruct the authors on *what* to do or *how* to address it. Therefore, it's not explicitly actionable in its current form.", "grounding_specificity_rationale": "The review point refers to \"fewshot learners beyond Prototypical Networks.\" This is a specific area, but it's a bit vague. While it mentions a specific term, it doesn't pinpoint a *specific section* or *unique aspect* within that field. The grounding is more general than fully specific.", "verifiability_rationale": "The review point is a statement of a limitation, not a claim requiring verification. It's a suggestion for future work, not a critique that needs evidence. Therefore, it doesn't contain a claim that can be verified.", "helpfulness_rationale": "The review point identifies a limitation and suggests a direction for future research. While it's constructive, it doesn't directly guide the authors on how to improve their current submission. It points to a gap in the understanding of episodic training, which is valuable for the field, but it doesn't provide concrete steps for the authors to take *now* with their current work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a potential solution (distinguishing strong vs. weak modal subsets) and provides a detailed procedure for implementing it. They suggest identifying instances where one modality performs significantly better than another and then creating separate subsets for these instances. This provides a clear action for the authors to take. The reviewer also mentions 'Equation 3' which, while not fully defined, suggests a connection to existing methods, adding further detail to the implementation.", "grounding_specificity_rationale": "The reviewer refers to 'different modalities,' 'instances,' and 'Equation 3' in their review. While they imply a connection to the original paper, they do not explicitly identify a specific section, table, figure, or unique aspect of the paper where this problem is occurring. They discuss the modalities and instances in a general way. The connection to 'Equation 3' is also not explicitly stated as referring to a specific equation in the paper. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer presents a claim: 'Equation 3 directly removes the modal subset of all instances, how to deal with the problem mentioned above.' They then propose a solution: 'We can distinguish the strong modality and weak modality subsets, and then create separate subsets for instances where one modality performs significantly better than another.' This claim is supported by suggesting a specific method (distinguishing and separating instances) to address the problem. While they don't provide a citation, the suggestion of creating subsets is a logical and verifiable approach.", "helpfulness_rationale": "The reviewer's point is very specific and directly addresses a potential issue with how modalities are handled in the paper. They propose a concrete solution (distinguishing strong and weak modal subsets) to ensure fair treatment of different modalities. This is a valuable and actionable suggestion that would likely improve the clarity and fairness of the analysis. The reviewer's feedback is clear and directly tackles a potential weakness."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states the abstract is good but lacks description of how the idea was evaluated and what was the outcome. This points out a missing element, but doesn't directly instruct the author on what to do. Therefore, it's not fully actionable. It identifies a gap, but doesn't fill it by providing explicit instructions on how to address it.", "grounding_specificity_rationale": "The review point talks about the abstract lacking evaluation and outcome. It doesn't explicitly mention a specific part of the paper (e.g., methodology section, results table) being lacking detail. Therefore, it's 1 at all. The comment is highly unspecific.", "verifiability_rationale": "The review point is a statement of observation (' The abstract does a good job explaining the proposed idea') followed by a criticism (' lacks description of how the idea was evaluated and what was the outcome'). The criticism is a claim that needs to be supported. However, the review point itself doesn't provide any evidence or reasoning to support why the abstract lacks this description. It's a statement of opinion, not a claim that is verifiable based on the provided text. Therefore, it's 1 as it stands.", "helpfulness_rationale": "The review point identifies a weakness in the abstract (lack of evaluation details) but doesn't offer any suggestions or actions for the author. It points out a gap, but doesn't provide any constructive feedback on how to address it. Therefore, it's 1. It identifies a problem but doesn't offer any solutions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer expresses a lack of confidence in the experimental results and provides specific examples of POMDP problems with nonconvex value functions. However, the reviewer does not explicitly state what specific action or improvement they would like the authors to take based on this feedback. The comment is more of a critique of the motivation and the lack of specific experimental instances rather than a direct instruction on how to improve the experiments. Therefore, while the feedback is relevant, it lacks the explicit actionability required to be 5.", "grounding_specificity_rationale": "The reviewer mentions specific POMDP examples (surveillance in museums with thresholded rewards; privacy preserving data collection) to motivate the experiments. However, they do not explicitly identify a specific part of the paper (e.g., a section, table, or figure) where these examples are discussed or where the lack of experiments is being pointed out. The reviewer's point is more general, criticizing the *type* of motivation used rather than pinpointing a specific location in the paper. Therefore, the grounding is weak because the reviewer cannot confidently determine which part of the paper they are addressing.", "verifiability_rationale": "The reviewer's comment is not a claim requiring verification. They are expressing a concern about the experimental setup and motivation, but they are not stating that something is wrong with the paper's results or providing external references to support their critique. The comment is more of an opinion or a suggestion for improvement rather than a verifiable claim. Therefore, the claim extraction would result in 'X' (X).", "helpfulness_rationale": "The reviewer's comment is clearly aimed at improving the paper. They identify a perceived weakness (lack of specific experiments) and suggest a potential improvement (including experiments on the mentioned POMDP settings). While the actionable aspect might be low, the reviewer provides a concrete suggestion for improvement, making the review quite helpful in terms of guiding the authors towards better experimental design. The reviewer is not stating something is wrong with the paper's results, but rather pointing out a lack of specific evidence to support their motivation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of clarity in the description of the MFDA setting, which implies an implicit action of identifying a problem. However, the action is vague, making it less concrete.", "grounding_specificity_rationale": "The reviewer highlights the unlabeled nature of the target domain notation (\tau) and questions the use of source domain data. This indicates a lack of full grounding as the specific part of the paper being addressed is unclear, and the reviewer doesn't specify what needs to be addressed in this part.", "verifiability_rationale": "The reviewer raises a concern about the consistency of the problem setting description with the original MFDA paper, questioning the accuracy and clarity of the description. This suggests the claim is somewhat supported by the reviewer's reasoning but lacks definitive verification or references.", "helpfulness_rationale": "The confusion about the method description likely makes the information less helpful for the authors to understand and potentially implement changes. The lack of clarity and grounding reduces the potential impact of the feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a *type* of analysis (epochwise) and *specific investigations* (batch size, sampling, deterministic/stochastic comparison). However, it does not explicitly state what specific part of the paper needs to be analyzed or what concrete action the author should take. The reviewer implies the usefulness of this analysis but doesn't provide explicit instructions on how to perform it.", "grounding_specificity_rationale": "The review point suggests a *general* approach to analysis (epochwise) but does not specify which particular section, table, figure, or unique element of the paper this analysis should focus on. The reviewer mentions *what* to investigate (batch size, sampling, deterministic/stochastic comparison) but not *where* in the paper this investigation should be conducted. Therefore, the grounding is weak as the target part of the paper is not clearly identified.", "verifiability_rationale": "The review point contains a claim: 'I think epochwise analysis, especially for finite sum settings, could help provide insights into behaviors of optimization algorithms.' It also provides reasoning and potential examples to support this claim, such as investigating the effect of batch size or different sampling strategies. The claim is logically reasoned and supported by potential examples.", "helpfulness_rationale": "The review point offers a suggestion for improvement by proposing a *specific type of analysis* (epochwise) that could enhance the understanding of optimization algorithm behavior. While it doesn't provide concrete implementation details, it clearly indicates a direction for the author to focus their work. The suggestion is not critical but rather a constructive idea for improvement, offering potential insights and comparisons. Therefore, it is helpful in guiding the author towards better analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies potential issues such as missing key baselines and missing citations. These are explicit statements about what is missing. However, the reviewer does not explicitly state how the authors should address these issues. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer mentions specific missing works (GraphRAG papers) and a potentially relevant area (MedRetriever). This grounds the feedback to specific parts of the field. However, the reviewer does not explicitly point to a specific section, table, or figure in the submitted paper that needs improvement. The issue is more general.", "verifiability_rationale": "The reviewer makes claims about the contribution being incremental and the potential GraphRAG connection. These claims lack strong justification within the review point itself. They point to what might be missing, not why it's missing or how it impacts the work. There is X being verified.", "helpfulness_rationale": "The reviewer points out potential issues with the authors' workload, the incremental nature of the contribution, and suggests missing key baselines and citations. While these are valuable observations, the review point does not directly instruct the authors on how to improve their draft. The feedback is more about what is missing from the work rather than how to address the identified weaknesses."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a problem (the difficulty in differentiating between types of extreme speech) and provides a specific example. While the reviewer doesn't explicitly state how to solve the problem, they prompt the authors to consider the distinction. This suggests a level of action, but it's not as explicit as a direct instruction on how to modify the draft. The reviewer is asking the authors to consider a specific instance, which implies an action, but it's not a clear, stepbystep guide.", "grounding_specificity_rationale": "The reviewer mentions the issue (difficulty in differentiating) and refers to the 'Paper Summary,' implying they've read it. They also provide a specific example to illustrate the ambiguity. However, they don't explicitly state which section, table, or unique aspect of the paper they are referring to. The reference to 'Paper Summary' is general, and they don't pinpoint the exact location of the definitions they are questioning.", "verifiability_rationale": "The reviewer makes a claim about the ambiguity of the distinction between the two types of extreme speech and provides a potential explanation (local regulations) for this ambiguity. They ask a question to elicit clarification. While the claim is present, the reviewer doesn't provide sufficient justification or evidence to support their claim about local regulations. The connection between the example and the regulation is implied but not explicitly stated or supported by external references.", "helpfulness_rationale": "The reviewer clearly identifies a problem (the lack of clarity in distinguishing between extreme speech types) and provides a concrete example to illustrate this point. They also ask a question, which is a helpful prompt for the authors. While the feedback is focused on a specific issue, it is clear and actionable in terms of highlighting a potential area for improvement. The reviewer is not providing a solution, but they are prompting the authors to consider a specific problem."}
{"actionability_label": "4", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states what the reviewer wants the authors to do: 'show a graph showing the plot of T vs number of images, and Expectation(T) over the imagenet test set.' This is a clear and direct instruction. While it doesn't specify *how* to create the graph, it identifies the key elements and the context. The reviewer is suggesting a specific analysis to understand the source of performance improvement.", "grounding_specificity_rationale": "The comment explicitly mentions 'T', 'number of images', and 'Imagenet test set'. These are specific parts of the paper and unique elements within them. The reviewer is referring to a general concept 'T' and a dataset 'Imagenet test set'. While it doesn't pinpoint a specific section *within* the 'network design' or 'Imagenet dataset', it clearly identifies the *types* of information needed for the analysis. The grounding is weak but not nonexistent.", "verifiability_rationale": "The comment is not making a claim or assertion. It is a request for a specific analysis and visualization. There is X that needs to be verified or supported with evidence.", "helpfulness_rationale": "The review point is highly specific and directly addresses a potential concern about the source of performance improvement. It tells the authors exactly what analysis they should perform and on what data. While it doesn't provide the exact methodology for creating the graph, it provides a clear direction for further investigation. This information is valuable for the authors to understand the factors contributing to their results."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states two areas for improvement: 'mathematical correctness' and 'notation clarity'. While the reviewer doesn't label them as 'explicit' or 'concrete', the suggestions are directly pointing to specific actions the authors should take. The reviewer also provides a preference, which can be interpreted as an implicit suggestion to improve clarity. However, the lack of a specific example for the preference makes it less actionable. Overall, the reviewer provides clear directions for improvement, making it 4.", "grounding_specificity_rationale": "The reviewer refers to 'L_l' and 'Fig.', which implies they are referring to a specific section or figure in the paper. While they don't explicitly name it, the use of 'Fig.' suggests they can identify the relevant part. The reviewer also points to a preference for better notation, which can be argued as implicitly referring to a specific aspect of the notation. Therefore, while not fully 'fully grounded', the reviewer can identify the specific area they are referring to, making it somewhat grounded.", "verifiability_rationale": "The reviewer is stating a preference for better notation and a desire for mathematical correctness. This is a statement of opinion rather than a claim that something is definitively wrong. Therefore, it doesn't fall under the 'X' category (X). While the reviewer provides suggestions, they are not supported by external references or logical reasoning within the review point itself. The reviewer is making a statement about what they believe is best practice, not a verifiable fact. Therefore, it is 1.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, including 'change to be mathematically correct' and 'why is it L_l instead of just L?'. These are actionable and directly address potential weaknesses in the paper. The reviewer also suggests that the notation should be introduced beforehand, which is a constructive suggestion. While the suggestion 'Fig.' is incomplete, the preceding statements clearly indicate a desire for clarification and improvement. The reviewer's comments are focused on providing concrete feedback to guide the authors' work, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitation of sequential ensembling in the context of homomorphic encryption, identifying 'noise accumulation' as the issue. This provides a clear direction for improvement by highlighting a specific problem with the method.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'sequential ensembling' and its relation to 'homomorphic encryption,' providing a clear reference to specific parts of the paper. They also explain the problem ('noise accumulation') within this context, making the grounding specific.", "verifiability_rationale": "The reviewer identifies a limitation ('It is important to study...') and provides a justification ('This limitations prevents the use...') based on the impact on the usability of the technique. While it doesn't provide a citation, the reasoning is logical and directly related to the mentioned issues.", "helpfulness_rationale": "The review points out a specific limitation of a particular technique ('sequential ensembling') in a specific context ('homomorphic encryption'). This is helpful as it guides the authors to consider the challenges and potential drawbacks of this approach, encouraging them to think critically about their methodological choices."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the observation about similar performance ('Figure 5 shows similar performance') and identifies the scenario ('when trained and evaluated with the same timestep'). While the reviewer also suggests a potential implication ('This makes the effectiveness of the proposed methods questionable') and a potential benefit ('maybe under some scenarios where the training timestep and evaluation timestep are different'), the core observation and the identified scenario are clearly stated. The reviewer does not provide concrete steps on how to improve the method based on this observation.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 5' and discusses 'timestep' as specific elements. While they don't explicitly state 'Section X of the paper discussing the experimental setup,' the reference to 'Figure 5' implies they are referring to a specific part of the paper. The concept of 'timestep' is also a specific concept within the context of the paper. However, the reviewer does not explicitly identify a specific element within Figure 5 or the 'timestep' concept itself.", "verifiability_rationale": "The reviewer presents an observation ('Figure 5 shows similar performance') and then offers an interpretation ('This makes the effectiveness of the proposed methods questionable'). While the observation itself could potentially be verifiable by examining Figure 5, the interpretation is not directly supported by evidence within the review point itself. The reviewer also suggests a potential alternative scenario ('maybe under some scenarios where the training timestep and evaluation timestep are different'), but this is a suggestion for future exploration rather than a direct verification of the current observation.", "helpfulness_rationale": "The reviewer points out a potential issue (similar performance) and raises a question about the method's effectiveness in that specific scenario. They also suggest a potential benefit in a different scenario. This highlights a limitation or a point of confusion regarding the method's current application. While it doesn't directly *improve* the paper, it does point out a relevant point that could guide further work or clarification. The reviewer does not offer concrete steps to improve the method based on this observation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the problem: 'it is not clear how disentanglement is guaranteed.' It then provides a suggestion: 'the authors want more detail on the mechanism or conditions that ensure disentanglement.' This is an explicit statement of a problem and a direct suggestion for improvement, making it 5. The reviewer clearly knows what action they want the authors to take.", "grounding_specificity_rationale": "The reviewer directly references 'disentanglement' and 'Broader Impacts and Limitations' sections. This is a clear and specific identification of the area being discussed. Furthermore, the reviewer asks a very specific question: 'how the disentanglement is realized and guaranteed without certain bias types.' This specificity points to a particular aspect within the mentioned section, making it highly specific.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification in the sense of logical reasoning, common knowledge, or external references. It's a request for more information. Therefore, it's not strictly 'verifiable' in the defined sense. While the request implies a need for verifiable information if the paper lacked it, the point itself doesn't make a claim that needs to be supported.", "helpfulness_rationale": "The reviewer has identified a genuine gap in their understanding \u2013 the mechanism behind disentanglement. They provide a clear suggestion for improvement: providing more detail in the 'Broader Impacts and Limitations' section. This is a valid and actionable feedback point that would likely help the authors improve their work by clarifying a crucial aspect of their methodology or findings."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states 'it should be used standard regularization trick.' This is a direct action. However, the specific type of regularization trick is not mentioned, making it less concrete. Therefore, it is an explicit but somewhat vague action.", "grounding_specificity_rationale": "The review point mentions 'stronglyconvex concave case.' This clearly identifies the specific aspect of the paper being addressed, making the grounding strong. However, the suggestion itself, 'standard regularization trick,' is not fully specific regarding the *implementation* of the regularization. Therefore, it is weakly grounded and somewhat specific.", "verifiability_rationale": "The review point suggests a 'standard regularization trick' for comparison. This is a suggestion or recommendation, which can be considered a claim that this method is appropriate. However, the review point does not provide any logical reasoning, common knowledge, or external references to support this claim. Therefore, it is a claim that is not verifiable.", "helpfulness_rationale": "The review point suggests using a 'standard regularization trick' for comparison in a 'stronglyconvex concave case.' While this points to a relevant method for comparison, it does not explain why this comparison would be beneficial or how it would be implemented. The suggestion is procedural but lacks a clear rationale or justification. Therefore, it is not 5."}
{"actionability_label": "4  4", "grounding_specificity_label": "5  5", "verifiability_label": "5  5", "helpfulness_label": "5  5", "actionability_rationale": "The comment explicitly states the action of 'including the learning curve for a model without any mean teacher or pi regularization for comparison' and implies the desired outcome is to understand the impact of mean teacher and pi regularization. While the action is clear, the level of detail on *how* to improve the graph is not explicitly stated.", "grounding_specificity_rationale": "The comment explicitly mentions 'fig 3' and specifies the purpose of the graph as 'learning curve for a model without any mean teacher or pi regularization'. This clearly identifies the specific part of the paper being addressed. The comment also clearly specifies what needs to be addressed in this part, which is the inclusion of a specific graph and a comparison.", "verifiability_rationale": "The comment contains a claim (a suggestion for improvement) and provides sufficient justification by stating the purpose of the graph and the model being considered. The suggestion is verifiable by showing the intended result (the learning curve). The claim is wellsupported by the reasoning and common knowledge about model training.", "helpfulness_rationale": "The comment provides a clear and actionable suggestion for the authors to improve their understanding of the impact of mean teacher and pi regularization. The suggestion is directly relevant to the authors' work and provides a concrete next step. The comment is not vague or lacking in detail."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points to a specific aspect of the method (Equation 2 and the optimization problem) and raises a question about the implications for the number of parameters compared to AlignFlow. While the reviewer doesn't explicitly state an action or a concrete step, the question directly relates to a specific implementation detail of the proposed method. The reviewer is essentially asking for clarification on how the optimization over both parameters is handled and how it differs from prior work in terms of parameter count. This falls under the category of 'Explicit' as the reviewer is directly addressing a specific part of the method (Equation 2). However, the action is not a direct instruction but a question about a specific aspect, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'AlignFlow (Grover et. al. 2019)' in the context of comparing the number of parameters. This directly grounds the criticism in existing literature. The reviewer is asking a question about a specific comparison, making the grounding quite clear. The criticism is focused on a specific aspect of the method (parameter count) and a specific prior work, making the grounding strong.", "verifiability_rationale": "The reviewer states that the effect on the number of parameters vs. prior work has not been discussed clearly. This constitutes a claim that there is a lack of sufficient justification or explanation regarding the parameter count comparison. The reviewer is making a statement about the absence of a specific type of evidence (clear discussion). While the reviewer doesn't provide evidence *why* it's unclear, they are stating that this is the case. This fits the definition of a 'Claim' as it identifies a specific aspect (parameter count) and its relation to prior work. The lack of explicit discussion makes the verifiability somewhat low.", "helpfulness_rationale": "The reviewer finds the point relevant to understanding the method's parameter handling and its relation to AlignFlow. The question directly addresses a potential concern or gap in the understanding of the proposed method compared to existing work. This makes the point potentially helpful for readers trying to understand the method's practical implications. The point raises a valid question that could inform implementation decisions or comparisons with other methods."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or provide concrete guidance on how to address the issue of different input types. While it suggests discussing and presenting solutions, it lacks a direct instruction for the author.", "grounding_specificity_rationale": "The review point explicitly mentions 'different types of inputs (e.g., biomedical signals or speech)' and suggests discussing and presenting solutions. This clearly identifies the specific aspect of the paper being addressed.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It presents a suggestion for future discussion rather than a definitive statement about what the author needs to do.", "helpfulness_rationale": "The review point raises a valid concern about the paper's scope and suggests a direction for improvement. However, it does not provide specific, actionable steps or concrete guidance on how to address the issue, making it less immediately helpful for the author."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer directly asks a question about the relationship between two equations (Eq. 4 and Eq. 3). This is an explicit request for clarification on how one equation implies the behavior of another. The reviewer is asking the authors to identify modifications they should apply to their draft based on the equations.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Eq. 4' and 'Eq. 3' and then mentions 'Table 5' and specifically the 'OfficeHome dataset'. This demonstrates a clear identification of the specific parts of the paper being addressed. The reviewer is not just stating a general weakness but pinpointing the equations and the numerical results in Table 5 as evidence of a lack of significant improvement.", "verifiability_rationale": "The reviewer makes a claim about the significance of the results in Table 5, stating that the improvement is 'not significant on some datasets'. This claim is verifiable by looking at the numerical data provided in Table 5. The reviewer then asks a question related to the equations, which is a logical followup to the claim, asking for an explanation of the implication of one equation on another based on the observed results. The claim is supported by the numerical data, making it '3'.", "helpfulness_rationale": "The reviewer points out a lack of significant improvement in the results presented in Table 5 for certain datasets. This is a valid observation that could be helpful for the authors to know. While the reviewer doesn't explicitly ask for a solution or a specific change, identifying this lack of significance is a constructive feedback point that can guide the authors in interpreting their results and potentially exploring further improvements. The feedback is directly related to the presented data and is therefore helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing reference 'Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" and compares the reported LFW accuracy (98.65%) to the result in Table 3 of the paper. This provides a concrete action for the authors to investigate the missing reference and potentially improve their results by adopting the betterperforming method. The action is clearly defined and the metric for comparison is provided.", "grounding_specificity_rationale": "The review point begins by explicitly mentioning 'the experiment of face recognition' and then specifically names the missing reference 'Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\". This demonstrates strong grounding as the authors can easily identify the specific part of the paper being addressed. The specificity is further enhanced by comparing the result to a metric (accuracy on LFW) reported in another paper, making it clear what needs to be investigated.", "verifiability_rationale": "The review point contains a claim that the missing reference represents a better stateoftheart with a higher accuracy on LFW. It provides external evidence (the cited paper and its reported accuracy) to support this claim. The reasoning is logical and the reference is specific, making the claim 5.", "helpfulness_rationale": "The review point is 5 as it identifies a clear weakness (missing references) and provides a concrete suggestion for improvement (investigating the betterperforming method from the cited paper). The specific comparison of accuracy makes the direction of improvement clear and actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential limitation of the method, suggesting it might not generalize well to questions that are not 'Whtypes'. While the reviewer doesn't propose a specific action, they are highlighting a potential consequence of the current action (transforming all questions). The actionability here is implicit \u2013 the reviewer is suggesting a potential flaw in the approach. The action being pointed out is 'transforming all questions into masked statements'. The reviewer is indicating that this might not be universally applicable. However, the reviewer doesn't explicitly state how to address this limitation, making the actionability somewhat implicit and not fully actionable.", "grounding_specificity_rationale": "The review point does not explicitly state which part of the paper it is addressing. The reviewer is making a general comment about the limitations of the question answering method. Therefore, the grounding specificity is low as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer states a concern about the method's potential limitations without providing any evidence or justification. They are expressing an opinion about the generalization issue. The verifiability here is low because the reviewer is not presenting a claim that can be supported by logical reasoning, common knowledge, or external references. The statement is a critique, not a claim requiring verification.", "helpfulness_rationale": "The reviewer's comment is a critique of the method and a suggestion for improvement (handling nonWhtype questions). While valuable feedback, it doesn't directly provide actionable steps for the authors to improve their draft. The helpfulness is limited as the reviewer is not proposing a concrete solution or guidance for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that using volumetric representations in the deformation field isn't a novel idea and names a specific prior work (VolumeDeform). This is a clear and direct statement, making it 5 for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'volumetric representation in the deformation field' but doesn't specify a particular section, table, or unique element. While the context strongly links it to the 'realtime dynamic reconstruction task' and 'VolumeDeform 1', the exact location isn't pinpointed, making the grounding weakly specific.", "verifiability_rationale": "The reviewer makes a claim about the lack of novelty and mentions VolumeDeform as a related work. However, they don't provide a detailed explanation of why it's not novel or cite specific aspects of VolumeDeform that make it relevant. The evidence is present but not fully developed, making the claim 3.", "helpfulness_rationale": "The reviewer informs the authors about a potential lack of novelty and points to a related work. While this information is relevant, it doesn't directly guide the authors on how to improve their current draft. It's an observation rather than a constructive suggestion, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a problem (ICLHAR hindering accuracy) and suggests a discussion. While the *cause* (ICLHAR) is mentioned, the *specific steps* or *how* to take action are not explicitly stated. The suggestion to discuss implies an action, but it's not a direct, actionable instruction.", "grounding_specificity_rationale": "The review point explicitly mentions 'ICLHAR' and 'accuracy scores,' clearly identifying the specific part of the paper and the issue. It also specifies what is wrong ('dropping from 70.4 to 55.6 on TRIP'). This indicates strong grounding as the specific element and the problem within it are welldefined.", "verifiability_rationale": "The review point states a fact ('dropping from 70.4 to 55.6 on TRIP') and offers a potential explanation ('has greatly impedes the accuracy scores'). However, it lacks explicit justification for *why* ICLHAR might cause this drop, nor does it provide specific examples or citations to support this claim. The explanation is present but lacks robust backing.", "helpfulness_rationale": "The review point directly points out a problem ('ICLHAR, while improving consistency and verifiability, has greatly impedes the accuracy scores') and suggests a discussion ('should be discussed or at least acknowledged in the main text in more detail'). This directly helps the authors understand an issue with their method and encourages them to investigate further. The suggestion to discuss is a clear and actionable step for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "Not Verifiable", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point states a fact ('The rockpaperscissors example is clearly inspired by an example that appeared in many previous work') but does not provide any instructions or suggestions on how to improve the paper based on this observation. There is no explicit action or concrete steps to be taken.", "grounding_specificity_rationale": "The review point explicitly mentions 'the rockpaperscissors example,' clearly identifying the specific part of the paper being criticized.", "verifiability_rationale": "The review point makes a claim ('The rockpaperscissors example is clearly inspired by an example that appeared in many previous work') but does not provide any evidence or justification within the review point itself to support this claim. It's a statement of opinion without backing.", "helpfulness_rationale": "The review point criticizes the use of a rockpaperscissors example without providing any specific feedback on how this is a problem or what the authors should do about it. It's a critique without actionable suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "2", "actionability_rationale": "The review points out a limitation and attributes it to the performance of the oracle expert. While this is a valid observation, it does not provide the author with explicit or concrete steps to improve their network architecture or constraint embedding.", "grounding_specificity_rationale": "The review explicitly mentions 'innovations of network architecture design' and 'constraint embedding,' which are specific areas within the paper. It also clearly states that 'performance is limited by the performance of the oracle expert,' providing a specific issue within these areas.", "verifiability_rationale": "The review contains claims such as 'The innovations of network architecture design and constraint embedding are rather limited' and 'The performance is limited by the performance of the oracle expert.' While the connection to the 'discussed' part of the original text implies these points, the reviewer does not provide external references or logical reasoning to support these claims within the review itself.", "helpfulness_rationale": "The review identifies a limitation and attributes it to the oracle expert. However, it does not offer any suggestions or actionable steps for the author to address this limitation or improve their work."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the limitation of the current evaluation setup (pretraining only on synthetic data) and proposes an alternative (pretraining on synthetic, finetuning on realworld with different losses). This directly addresses a potential weakness in the authors' current approach. The reviewer also clearly states the goal of the alternative evaluation: to demonstrate the importance of the proposed projection errors. The reviewer identifies a specific area for improvement and suggests a concrete method to achieve it. Therefore, the review point identifies a clear action for the authors to take, making it actionable.", "grounding_specificity_rationale": "The reviewer explicitly states the *why* of the suggestion \u2013 to demonstrate the importance of the proposed three projection errors. The reviewer also clearly identifies the alternative evaluation strategy (pretraining on synthetic data but finetuned on realworld datasets with different losses). This shows a clear understanding of what aspect of the model needs improvement. The reviewer grounds the suggestion in a specific area of the model (the projection errors) and proposes a specific method to evaluate them. Therefore, the reviewer provides a clear target for the authors to focus on, making the grounding specific.", "verifiability_rationale": "The reviewer proposes an alternative evaluation strategy (pretraining on synthetic data but finetuned on realworld datasets with different losses) to demonstrate the importance of the proposed three projection errors. While the reviewer doesn't provide specific examples of which losses to use, the suggestion is logically sound and points to a relevant area for further experimentation. The reviewer provides a clear *method* for investigation, making the claim 3. Without specific details, it's not 5, but the underlying logic is sound. Therefore, the reviewer provides a suggestion that can be followed, making it 3.", "helpfulness_rationale": "This review point is 5 for the authors in several ways. First, it critiques the authors' current evaluation setup (pretraining only on synthetic data), highlighting a potential flaw in their methodology. This provides valuable information for the authors to consider when revising their work. Second, the reviewer offers a concrete suggestion for an alternative evaluation strategy (pretraining on synthetic data but finetuned on realworld datasets with different losses). This provides a clear direction for the authors to take their work further and potentially gain a deeper understanding of the importance of the proposed projection errors. The suggestion is specific enough to guide the authors in their next steps, making it actionable and helpful. Therefore, the review point provides valuable insights and guidance, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the alternative method ('average over the subword representations') and provides a citation. This is a clear and direct suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions 'the embedding of the first subword token' and 'average over the subword representations,' clearly identifying the specific parts of the paper being addressed. It also specifies the alternative method, making it 5.", "verifiability_rationale": "The comment presents a suggestion ('It is also quite common...') but provides a clear justification by stating the difference from the proposed method ('...what is common in cases like that...') and cites a specific paper and footnote. This makes the suggestion wellsupported and verifiable.", "helpfulness_rationale": "The comment offers a concrete alternative implementation, which can be helpful for the authors to consider and potentially improve their method. While it might not be a major flaw, it provides a valuable point of comparison and suggests a different, common approach, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of using AUC for assessing the consistency between predicted scores and actual risk, which is a clear action. They then suggest conducting calibration curves as a solution, which is a concrete action with a clear goal. The reviewer also mentions proving the feasibility of the generated scoring system and discussing the difference between traditional and their method, further elaborating on the action.", "grounding_specificity_rationale": "The reviewer identifies the specific area for improvement as 'calibration' and specifies the issue as 'the consistency between predicted score and actual risk'. They also specify the type of scoring system as 'clinical scoring system' (differentiated from classification). Furthermore, the reviewer suggests conducting calibration curves and discussing the difference between traditional and their method, providing concrete actions and context. The reviewer even mentions 'proving the feasibility of the generated scoring system', which is a specific action related to demonstrating the practical value.", "verifiability_rationale": "The reviewer makes a claim that 'related studies are encouraged to conduct calibration curves to show the agreement' and further suggests that 'it would be better to prove the feasibility of the generated scoring system?'. The reviewer provides a justification for this claim by stating that 'consistency may be more crucial to the clinical scoring system'. The reviewer also suggests discussing the 'difference between the traditional method and our method', providing a specific action and a reason for it. The claim about conducting calibration curves is directly linked to the aspect of verifiability, as it aims to verify the claim about the importance of consistency.", "helpfulness_rationale": "The reviewer provides a clear suggestion to 'conducted calibration curves' and explains the 'importance of showing the agreement' and the 'consistency between predicted score and actual risk'. The reviewer also suggests 'proving the feasibility of the generated scoring system' and 'discussing the difference between the traditional method and our method', providing concrete actions and a clear rationale for why these actions are helpful. The reviewer's suggestion directly addresses the limitations of relying solely on AUC for evaluating scoring systems, particularly in clinical contexts."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific issue (no change in ID/OOD ranges/mean) and questions the implementation of conditions for DICE. This directly suggests a potential problem the authors should address. The implicit nature lies in the need for the authors to *check* if their sparsification method is correctly implemented and if their analysis of Lemma 2 is thorough. However, the reviewer doesn't explicitly state the action to take, making it somewhat implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 4,' 'ID,' 'OOD,' 'Lemma 2,' and 'DICE' when describing the issue. This clear identification of the specific part of the paper being addressed makes the grounding very explicit. The reviewer is not making an educated guess; they are directly referring to specific elements of their work.", "verifiability_rationale": "The reviewer makes a claim: 'From Figure 4, the range of ID and OOD seems not to be changed much by sparsification.' and 'Similarly, Lemma 2 requires approximately identical mean as the assumption. These conditions are crucial for DICE, but is not well discussed, eg., how to ensure DICE meet these conditions.' This claim is supported by the observation of Figure 4 and the statement about Lemma 2. While the reviewer doesn't provide *external* references, the *fact* that they are pointing out this discrepancy suggests it's a verifiable concern within their own work. The logical reasoning is that if the ranges didn't change and the conditions are crucial, this is a significant point that needs verification.", "helpfulness_rationale": "The reviewer's point is likely to be helpful for the authors. They are directly pointing out a potential issue in the implementation or analysis (lack of change in ranges/mean and missing discussion of conditions for DICE). This provides a clear direction for the authors to investigate and potentially improve their work. The implicit nature is that the authors need to *find* where the problem lies (check Figure 4, analyze Lemma 2, and verify the DICE conditions). However, the reviewer doesn't explicitly state the solution, making it somewhat implicit."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a clear and actionable list of suggestions. They explicitly state *what* is missing and *why* it's a problem. For example, they state 'besides, the experiments seem not too strong and fair to me' and 'I don't understand why all the baselines use the position kernels'. They also suggest *what* to do, such as 'use default settings of these baselines in the literature' and 'include missing baselines related to BO with discrete & categorial variables'. The reviewer's suggestions are not just general observations but specific, actionable steps for the authors to take.", "grounding_specificity_rationale": "While the reviewer points out several weaknesses in the experimental setup and the lack of certain baselines, the criticism remains somewhat general. The reviewer doesn't explicitly state which specific part of the paper (e.g., a particular section, table, or figure) is affected by these issues. For instance, while they mention 'position kernels', they don't specify *which* baseline uses them or *where* in the paper this is relevant. Similarly, they suggest 'missing baselines related to BO with discrete & categorial variables' but don't point to a specific area in the paper where these are supposed to be. The criticism is about the *type* of issue rather than pinpointing the exact location.", "verifiability_rationale": "The reviewer makes several claims in the review point. For example, they state 'Besides, the experiments seem not too strong and fair to me' and 'I don't understand why all the baselines use the position kernels'. These are statements that require justification and explanation. The reviewer also suggests improvements, such as 'use default settings of these baselines in the literature' and 'include missing baselines related to BO with discrete & categorial variables'. While the reviewer doesn't provide explicit citations for these claims, they offer logical reasoning and suggestions, indicating an attempt to verify the issues. The claims are not purely subjective opinions but are supported by the reviewer's analysis of the experimental setup and the suggested improvements.", "helpfulness_rationale": "The reviewer's review point is highly relevant to the paper's content. They clearly identify several weaknesses in the experimental methodology, the lack of certain baselines, and the absence of a discussion on limitations and societal impacts. The reviewer provides concrete suggestions for improvement, such as using default settings, including missing baselines, and addressing limitations and societal impacts. These suggestions are directly actionable and would significantly help the authors improve their draft. The reviewer's comments are not just a critique but also a roadmap for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point describes the observed trend of correlation after training but does not provide explicit or implicit instructions on how to *action* or improve the model based on this observation. It states what happened, not what to do next. Therefore, it lacks the explicit action or guidance needed for actionability.", "grounding_specificity_rationale": "The review point mentions 'training' and 'correlation' but does not specify *which part* of the paper or model this refers to. It lacks the precision needed to identify a specific section, table, figure, or unique element. While it identifies a general area of concern, it doesn't pinpoint the exact location of the issue.", "verifiability_rationale": "The review point describes an observed trend ('correlation after a short period of training, which goes up with more training iterations') but does not make a claim that requires verification. It's a descriptive statement about the training process, not a claim that needs supporting evidence or references. Therefore, it doesn't present a verifiable statement in the sense of the aspect definition.", "helpfulness_rationale": "The review point points out a potential issue (decreasing correlation initially) and a positive outcome (increasing correlation with more training). This could be helpful for the authors if they are tracking performance and see a similar trend. It highlights a potential area for concern and a positive development, which can guide further investigation. While it doesn't directly tell them *how* to fix it, it provides context and direction for their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a discrepancy or lack of insight, prompting the authors to seek more information. While the reviewer identifies a potential issue ('sparsity patterns do almost equally well'), they don't explicitly state what needs to be done next. The request for clarification ('Is this something unique to the sparsity detection problem or is this true for GNN in general?') indicates an intention to investigate, but not a specific action to take on their part. Therefore, while the reviewer identifies a problem, the lack of explicit instructions on how to address it makes the actionability borderline.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 4.3: presentation bits > representation bits.' This is a very specific reference within the paper, indicating that the reviewer has located the relevant section. Furthermore, the reviewer directly asks a question related to the content of this section ('presentation bits > representation bits'), specifying the area of concern. This demonstrates a clear understanding of the section and the specific aspect being discussed within it.", "verifiability_rationale": "The review point is a question, not a claim that requires verification. The reviewer is asking for clarification and context, not making a statement that needs to be supported by evidence. Therefore, verifiability is not applicable to this point.", "helpfulness_rationale": "The reviewer directly asks a question to improve the authors' understanding of a specific aspect of their work. The request for clarification and the focus on the relationship between 'presentation bits' and 'representation bits' are directly aimed at helping the authors improve their draft. The reviewer is providing context and asking a question that is directly relevant to the authors' work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4. This directly points out a specific, actionable omission in the mathematical steps. The reviewer clearly identifies what is missing and how it should be included, making this a concrete and actionable piece of feedback.", "grounding_specificity_rationale": "The reviewer refers to specific equations (Eqn. 3 and Eqn. 4) in their comment. This indicates that the authors can accurately pinpoint the section or part of the paper being addressed. While the *content* of the criticism (the missing \u03c4) is the primary focus, the explicit reference to equations provides a level of grounding.", "verifiability_rationale": "The reviewer makes a claim: 'The derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4'. This is a verifiable statement. If the authors were to check the derivation, they would likely find that the temperature parameter is indeed missing, supporting the reviewer's claim. While no external references are provided in this specific point, the claim itself is logically verifiable.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for improvement: '\u03c4 should be shown in a rigorous way or this paper mention it'. This actionable feedback directly addresses a potential weakness in the paper's presentation of the derivation. By pointing out the missing parameter and suggesting how it should be included, the reviewer provides valuable guidance for the authors, making this a 5 comment."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "1 (1 and Not Specific)", "verifiability_label": "X (X)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point explicitly states an action: 'add a citation' and provides a method: 'e.g. one of the standard works like 2'. While it doesn't specify the exact location, the phrasing strongly implies it relates to the current discussion on differential privacy, making it 3.", "grounding_specificity_rationale": "The review point mentions 'differential privacy' and suggests 'adding a citation'. However, it does not explicitly identify a specific section, table, figure, or unique aspect of the paper where this citation is needed. The reference is general and lacks precision on the paper's part.", "verifiability_rationale": "The review point is a suggestion to improve the paper by adding a citation. It does not make a claim about what is wrong with the current draft or provide a basis for verification. It is a suggestion, not a claim.", "helpfulness_rationale": "The review point suggests adding a citation to the topic of differential privacy. While it is a helpful suggestion that could improve the paper, it lacks specific details on how to implement this action. It does not provide guidance on where to add the citation, how to choose the citation, or how to integrate it into the text. Therefore, it is 3 but not highly detailed."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the *specific* additional assumption being referred to in the methodology section. This is explicit. The reviewer also points out the *wrong sign* in an inequality, which is a concrete action to take. Therefore, the reviewer provides clear guidance on how to improve the paper.", "grounding_specificity_rationale": "The reviewer doesn't explicitly *mention* a specific section or table in their criticism. They refer to \"the methodology section\" generally. While the *content* of the criticism is relevant to a specific part of the methodology, the reviewer doesn't pinpoint the exact location (section, table, line number) of where this assumption is clearly stated in the methodology. Therefore, it's not fully grounded. It's also not weakly grounded because the *content* of the criticism is relevant to a specific part of the methodology.", "verifiability_rationale": "The reviewer presents two distinct points as claims: \"this methodology requires significant additional assumptions\" and \"The only additional assumption is that the test set be drawn from the same distribution as the query set\". These are clear statements that could be argued as opinions or suggestions. The reviewer then provides specific evidence to support their claims: \"The only additional assumption is that the test set be drawn from the same distribution as the query set, which is natural for many machine learning settings where the train, validation, test sets are typically assumed to be from the same iid distribution.\" This provides justification.", "helpfulness_rationale": "The reviewer explicitly names the *section* they are referring to when making the assumption claim (\"the methodology section\"). This makes the criticism directly actionable. The reviewer clearly states the *specific* assumption they are referring to, making it easy for the author to understand the concern. The reviewer points out a potential issue with the assumptions, which could lead to a discussion or clarification in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a *lack of* something (experimental comparison and discussion) but doesn't directly instruct the authors on what to do or why they should do something. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer mentions specific methods and dimensionality reduction techniques (Shapely value explanations, CaCE, raw gradients, different dimensionality reduction techniques). However, the connection to the authors' specific work is not explicitly stated, and the reviewer doesn't clearly identify which part of their work is being addressed.", "verifiability_rationale": "The reviewer makes a claim about the paper lacking experimental comparison and discussion on dimensionality reduction. This claim needs to be verified by examining the paper. The reasoning for this claim is present, but the evidence (lack of comparison and discussion) is not explicitly stated within the review point itself.", "helpfulness_rationale": "The reviewer provides a clear critique of the paper, highlighting significant omissions. While the feedback is constructive, it doesn't directly provide concrete, actionable steps for the authors. The helpfulness lies in pointing out weaknesses rather than offering immediate solutions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the action of comparing Section 6 to prior work. While it doesn't specify the *how*, it clearly indicates the *what*. This makes it actionable as the authors know they need to perform a comparison.", "grounding_specificity_rationale": "The review point refers to 'Section 6' and 'prior efforts' without explicitly identifying specific parts or providing details. The authors have to infer the intended sections, making the grounding somewhat weak.", "verifiability_rationale": "The review point presents a claim that comparison is beneficial but lacks any supporting evidence or justification within this specific review. There are no logical arguments, references, or examples provided to back up the claim.", "helpfulness_rationale": "The review point is a clear suggestion to compare Section 6 to prior work. It identifies a potential improvement and guides the authors to take action. While it doesn't provide detailed steps on how to compare, it offers a clear direction."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states an assumption about the relationship between performance and the number of training scenarios and suggests an experiment to examine this relationship. This constitutes an explicit action with clear instructions on how to proceed. The action is also concrete, specifying the purpose of varying the number of scenarios.", "grounding_specificity_rationale": "The reviewer refers to 'scenarios used for training' and 'number of scenarios'. While not explicitly pointing to a specific section or table by number, the concept is reasonably clear within the context of the paper's description of the experimental setup. The reviewer implicitly refers to the fixed number (200) as the baseline for comparison. The suggestion to vary the number is also clear.", "verifiability_rationale": "The reviewer presents an assumption ('I would assume') about the relationship between performance and the number of scenarios. This can be considered a claim that needs to be supported. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to back up this assumption within the review point itself. The suggestion to examine the performance with different numbers is a potential verification method, but the claim itself lacks external justification.", "helpfulness_rationale": "The reviewer raises a relevant point about the potential impact of the number of training scenarios on performance. This is a valid concern for the authors and could guide their understanding and potential improvements. However, the review point lacks specific details on which scenarios to vary or how to analyze the performance changes. The suggestion is general and doesn't offer concrete steps for the authors to take, making it less immediately helpful."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what the authors should do. It raises a question about the impact of training data disturbances on the quality label, but it doesn't provide a direct action or suggestion on how to address this.", "grounding_specificity_rationale": "The review point mentions 'training data disturbances' and 'quality label' but does not specify the *nature* of the disturbances or the * aspect of the quality label that might be affected. It's a general statement rather than a precise identification of a specific part of the paper or a clear indication of what needs to be changed.", "verifiability_rationale": "The review point presents a question and a hypothesis but does not make a clear claim that can be verified. It's a speculative statement about potential issues rather than a definitive assertion supported by evidence or reasoning.", "helpfulness_rationale": "The review point raises a valid concern and asks a relevant question. It prompts the authors to consider the impact of potential disturbances on their model's performance. While it doesn't provide a direct solution, it is a relevant piece of feedback that can guide further investigation and experimentation."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point describes the experiments conducted but does not suggest specific actions or improvements the authors should take based on these experiments. It's a report of achievements, not constructive criticism.", "grounding_specificity_rationale": "The review point mentions the scope of the experiments (various settings, architectural mismatch, crossdomain imitation) but does not explicitly identify a specific part of the paper being addressed. It lacks the precision required for grounding.", "verifiability_rationale": "The review point is a factual statement about the authors' experiments and does not contain a claim that requires verification or justification.", "helpfulness_rationale": "The review point summarizes the authors' work but does not offer any constructive feedback, suggestions for improvement, or identify any weaknesses. It lacks the value needed to be considered helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential improvement area ('make the setting more fully strategic') but doesn't provide a specific, actionable step. While it implies the opponent isn't strategic, it's more of an observation than a direct instruction. The level of detail is missing, making it less actionable.", "grounding_specificity_rationale": "The review mentions 'strategic predictions' (l28) and 'opponent doesn't behave strategically,' indicating a specific concept and a critique of behavior. However, it doesn't explicitly pinpoint a specific part of the paper being addressed. The grounding is weak because it relies on implied understanding rather than direct references. The specificity is present in identifying the opponent's lack of strategic behavior, but the *specific aspect* of the model lacking this is unclear.", "verifiability_rationale": "The review point makes a judgment about the current state of the work ('this seems like only a very first step...') and the opponent's behavior ('...opponent doesn't behave strategically...'). However, it doesn't provide any evidence or reasoning to support these claims. It presents an opinion without backing, making it 1.", "helpfulness_rationale": "The review point identifies a potential improvement area ('make the setting more fully strategic') and points out a limitation in the current approach ('opponent doesn't behave strategically'). While it doesn't offer specific *howto* instructions, it does highlight a direction for improvement. It's not completely devoid of value, as it suggests a more comprehensive approach. The weakness is that it lacks concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential issue in Appendix A.2 but does not explicitly state what needs to be done or how to address it. It points to a lack of clarity, which is a vague and implicit action.", "grounding_specificity_rationale": "The comment specifies that Appendix A.2 does not illustrate the state space representation clearly. This identifies the specific part of the paper being addressed, making it fully grounded. It also specifies what is unclear (lack of illustration and clarity of state space representation), making it specific.", "verifiability_rationale": "The comment is a claim that Appendix A.2 does not illustrate the state space representation clearly. This claim is not supported by any evidence or reasoning within the review point itself. Therefore, it is 1.", "helpfulness_rationale": "The comment points out a potential area for improvement in the clarity of Appendix A.2. While it doesn't explicitly state how to improve it, it identifies a concrete issue that could hinder understanding. This suggests it could be helpful if the authors take action to improve the clarity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the authors' approach is limited to small or mediumscale problems and identifies the scalability issue as a key limitation. This is a clear and direct action the authors should take to address this problem, such as exploring decomposition techniques or alternative optimization methods. The action is also concrete in identifying the problem area (scalability of the approach).", "grounding_specificity_rationale": "The comment is a general statement about the limitations of the authors' approach regarding problem scale and solver performance. It does not specify a particular section, table, figure, or unique aspect of the paper where this limitation manifests. Therefore, the authors cannot confidently determine which part of the paper is being affected, making the grounding weak. However, the comment does specify what needs to be addressed (scalability issues), making it somewhat specific in that regard.", "verifiability_rationale": "The comment states a limitation of the authors' approach without providing any evidence, reasoning, or references to support this claim. It is a statement of observation, not a claim that requires verification. Therefore, it is not verifiable as it lacks supporting evidence or justification.", "helpfulness_rationale": "The comment identifies a practical limitation of the authors' approach, specifically its scalability issues. This is valuable information for the authors as it helps them understand the boundaries of their current method and plan for potential modifications. While it doesn't offer specific guidance on how to overcome the limitation, it does point to a relevant area for improvement, making it 3."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the bounded noise assumption and suggests broader alternatives but does not explicitly state an action or provide concrete steps for the author to take. The reviewer points out that the bounded noise assumption is somewhat restrictive and provides examples of alternative noise conditions, but the review does not directly instruct the author on how to modify their work based on this information.", "grounding_specificity_rationale": "The review point criticizes the bounded noise assumption in general and does not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. While it mentions stochastic optimization literature, noise conditions, and provides citations, it doesn't pinpoint where the bounded noise assumption is used in the author's work. The grounding is at a high level regarding the assumption itself, not a specific instance in the paper.", "verifiability_rationale": "The review point criticizes the bounded noise assumption and suggests broader alternatives. It does not make a claim that requires verification or justification. The reviewer is pointing out a limitation and offering a different perspective, but it doesn't present a statement that needs to be proven or supported with evidence within the context of the review itself. The comment is more of an observation and suggestion rather than a verifiable claim.", "helpfulness_rationale": "The review point identifies a potential limitation of the bounded noise assumption and offers broader alternatives. It provides citations, which can be helpful for the author to explore further. While it doesn't immediately tell the author how to address the bounded noise assumption, it points towards a relevant area of research and provides context. The feedback is relevant and points towards a direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue with the clarity of the motivation but does not explicitly state what action the authors should take to address this. While it points to a problem, it doesn't provide a clear, actionable step for the authors to improve their work.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or methodology. It is a general statement about the overall motivation, making the grounding specificity weak. The authors cannot pinpoint the exact location of the issue based on this review point.", "verifiability_rationale": "The review point expresses an opinion about the clarity of the motivation. While it could be supported by examples of unclear writing, the review point itself doesn't provide a logical reasoning or external reference to justify the claim. It's an assertion, not a claim that is 5.", "helpfulness_rationale": "The review point identifies a potential area for improvement (clarity of motivation) but does not offer specific suggestions or guidance on how to achieve this. It's a diagnostic statement rather than a prescriptive improvement suggestion, making it less helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the combination of existing techniques might be incremental. While this is a clear observation, it doesn't directly instruct the authors on what to do next. The reviewer identifies a potential area for improvement (combining techniques) but doesn't provide a specific action or method for achieving this. Therefore, while the observation is present, it lacks the explicit action required for high actionability.", "grounding_specificity_rationale": "The review point mentions specific techniques (Lykouris et al., 2018; weighted version of OFUL/Zhou et al., 2021; contextual linear bandits) and the concept of combining them. This provides some grounding as the authors can identify the specific parts of the paper being referenced. However, the reviewer doesn't pinpoint a specific section, table, or figure within the paper where this combination is being discussed or evaluated. The grounding is present but not fully precise, making it 3.", "verifiability_rationale": "The review point contains a claim: 'The fact that these results can be combined together is not surprising'. This is a statement of opinion. The reviewer provides specific references (Lykouris et al., 2018; Zhou et al., 2021; contextual linear bandits) to support the idea that these are existing techniques. These references serve as sufficient justification for the claim. Therefore, the claim is thoroughly supported by explicit and sufficient evidence, making it 5.", "helpfulness_rationale": "The review point offers a comment on the combination of existing techniques. While this is a relevant observation, it doesn't provide specific, actionable feedback on how the authors should improve their draft based on this combination. The reviewer points out a potential limitation but doesn't offer concrete steps or suggestions for the authors. The feedback is relevant but lacks the constructive nature needed for high helpfulness. Therefore, the feedback is 3 as it identifies a potential area for improvement, but it lacks specific guidance."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer identifies a potential area for improvement in the paper ('Multiscale modeling' and the 'aggregation operation after 'Integration') but does not provide specific details on how the authors should apply this feedback. The request is general and lacks concrete steps for the authors to take. The reviewer states 'The aggregation operation after \"Integration\" needs further clarification' without specifying what is unclear or how the authors should implement the aggregation. This makes the feedback less actionable.", "grounding_specificity_rationale": "The reviewer mentions the 'Integration' section within the 'Multiscale modeling' section, indicating some level of grounding. However, the reviewer does not specify the exact part of the 'Integration' section or table that needs clarification. The reference is somewhat vague, as the reviewer only mentions 'Integration' without pinpointing the specific element within it. The reviewer states 'The authors cannot confidently determine which part the comment addresses' which aligns with the definition of 'Weakly Grounded'.", "verifiability_rationale": "The reviewer makes a claim by stating that the aggregation operation after 'Integration' needs further clarification. However, the reviewer does not provide any evidence, examples, or logical reasoning to support this claim. The statement is presented as a suggestion for improvement without any backing. The reviewer states 'The comment contains a claim without any supporting evidence or justification', which aligns with the definition of '1'.", "helpfulness_rationale": "The reviewer identifies a potential issue in the paper ('Multiscale modeling' and the 'aggregation operation after 'Integration') which suggests a meaningful weakness. However, the feedback is presented as a general suggestion without providing specific details on how the authors should address the lack of clarity. While the feedback points to a relevant area for improvement, the lack of concrete suggestions limits its helpfulness. The reviewer states 'The comment fails to identify meaningful weaknesses or suggest improvements, leaving the authors with no actionable feedback' which aligns with the definition of 'Not Helpful'."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies the *type* of issues (writing, grammatical errors, mathematical symbol abuses) but does not provide explicit or concrete actions for the authors to take. It states the *problem* but lacks specific steps to address it. For example, it doesn't suggest rewriting a specific sentence or section, which would be necessary for actionability.", "grounding_specificity_rationale": "The review point broadly refers to the *entire paper* having writing issues and does not pinpoint a specific section, table, figure, or unique element of the paper where the problem lies. While it mentions 'grammatical errors' and 'abuses of mathematical symbols,' it doesn't specify *where* these occur within the paper. The grounding is weak because the authors can only *guess* where the issues are.", "verifiability_rationale": "The review point makes a claim about the paper containing 'severe writing issues such as grammatical errors, abuses of mathematical symbols, unclear sentences, etc.' This is a claim that requires verification. While the reviewer doesn't provide specific evidence *within the review point* to support this claim, the existence of grammatical errors and unclear sentences in a paper is generally verifiable through direct observation or feedback from others. The claim is 3 because it's based on observable characteristics of writing, even if the reviewer doesn't provide specific examples within their review.", "helpfulness_rationale": "The review point identifies a significant issue with the paper's writing quality but does not offer any specific guidance or suggestions for improvement. It points out the *problems* but doesn't provide actionable steps for the authors to take. For example, it doesn't suggest specific areas for clarification, potential revisions, or how to improve the flow of the text. While it highlights a need for change, it doesn't directly instruct the authors on how to make those changes, making it less directly helpful than a review with more specific suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification on the meaning of the dotted lines in the figures, which implies an implicit action: to understand how the untrained network results are represented. However, the reviewer does not provide concrete steps on how to interpret these lines or suggest concrete improvements to the figures themselves. The request for additional experiments (running untrained networks) is a concrete action, but the initial phrasing focuses on clarification.", "grounding_specificity_rationale": "The review point explicitly mentions 'Fig 3c' and 'Fig 3', indicating a clear grounding of the issue in specific parts of the paper. It also asks for clarification on whether the network was trained on random data and the normalization of the nonrandom data, which are specific aspects of the methodology. The phrasing 'Clarify: Random data (Fig 3c)' and 'Clarify: Random data (Fig 3)' clearly points to specific elements within the figures. The suggestion to show examples in the appendix is also a specific request for improvement.", "verifiability_rationale": "The review point contains claims about the interpretation of the figures and the methodology. For example, it claims that the dotted lines represent results for untrained networks. The 'verifiability' of this claim depends on whether the authors can provide evidence or justification. The request to run untrained networks and add the results to the figures and Table 1 is an attempt to verify this claim. However, the initial phrasing focuses on clarification rather than directly challenging or verifying the existing interpretation.", "helpfulness_rationale": "The review point is primarily focused on clarifying aspects of the figures and methodology. While the request to run untrained networks is a concrete suggestion, the initial phrasing emphasizes clarification rather than directly addressing a perceived weakness or providing actionable feedback on the presented results. The suggestions for clarification aim to improve understanding but don't directly resolve any identified issues with the current data or analysis. The request for examples in the appendix is a suggestion for improvement in presentation."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a lack of clarity regarding the meaning of '100 steps' in the context of the search model comparison. While the action is to clarify this ambiguity (an explicit action), the specific action of 'identifying the meaning of 100 steps' is not explicitly stated, making it somewhat vague. Therefore, it is not fully actionable as the action itself is not fully defined.", "grounding_specificity_rationale": "The review point asks a question about the meaning of '100 steps' without explicitly stating what part of the paper or what aspect of the search model comparison this '100 steps' refers to. The authors cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part, which is the clarification of the meaning of '100 steps'. Therefore, it is UnderSpecific.", "verifiability_rationale": "The review point itself does not present a claim that needs verification. It's a request for clarification. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point highlights a lack of clarity in the original text regarding the search model comparison. This lack of clarity makes it difficult for the authors to understand the experimental setup and potentially replicate or build upon the work. While the action is to clarify, the current phrasing doesn't explicitly state the conclusion (e.g., 'The 100 steps refer to 100 sampled strategies'). Therefore, it is 3 in identifying an issue but not fully resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the similarity to a prior VAE paper, indicating a weakness. However, the lack of specific details about the *how* makes it not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions \"motivation and goals\" and draws a parallel to a \"prior VAE paper.\" While they don't give a precise section number, the connection to a prior work is a strong indicator of some level of grounding. However, they don't specify a section, table, or unique element, making it weakly grounded.", "verifiability_rationale": "The reviewer makes a claim about the similarity to a prior VAE paper. However, they provide no evidence, reasoning, or references to support this claim, making it 1.", "helpfulness_rationale": "The reviewer raises a concern about the lack of novelty. While potentially helpful in highlighting limitations, the lack of specifics makes it 3 as it guides the authors to consider alternative approaches or focus areas."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the improvement is 'small' and suggests actions such as 'repeat the experiments' and 'conduct statistical significance analysis'. While the reviewer identifies an area for improvement and suggests actions, the lack of specific details on how to repeat the experiments or conduct the statistical analysis makes the action somewhat vague. The reviewer's suggestion to repeat experiments and conduct statistical analysis implies an action, but the current review point lacks the specifics needed to be fully actionable.", "grounding_specificity_rationale": "The reviewer mentions 'previous methods', 'Table 1 and Fig.5', and 'statistical significance'. While the reviewer identifies elements of the paper that are relevant to the criticism, they do not explicitly pinpoint a specific section, table, figure, or unique aspect. The reviewer's mention of 'Table 1 and Fig.5' and 'statistical significance' suggests they understand the context, but without explicitly naming the table or figure, the grounding is weak. The reviewer also claims the results are 'not reported' and the improvement is 'hard to know', which lacks specific details about the data and analysis.", "verifiability_rationale": "The reviewer makes a claim that the results are 'not reported' and the improvement is 'hard to know'. This constitutes a claim that needs verification. The reviewer suggests repeating experiments and conducting statistical significance analysis as ways to verify this claim, providing a path to verification. However, the claim itself, as stated in the review point, lacks immediate supporting evidence or justification within the review point itself.", "helpfulness_rationale": "The reviewer suggests repeating experiments and conducting statistical significance analysis as ways to improve the results. These suggestions are actionable and directly address the identified issue of limited statistical significance. While the suggestions are general, they provide a clear direction for improvement. The reviewer's suggestion to improve the paper's quality is constructive and aims to address a specific weakness. The reviewer's suggestions are directly related to improving the paper's quality and addressing the identified limitations."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"The method is evaluated only on the tasks from Meta World...\" This is an explicit statement about the evaluation scope and implies a clear action: to evaluate the method on Meta World. The reviewer also states \"I strongly recommend running experiments on a different benchmark such as Atari...\" This is a direct suggestion based on the identified limitation, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer mentions \"Meta World, a robotic manipulation domain.\" While this provides some grounding, it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper or method being evaluated. The reviewer argues that this lack of specificity makes it difficult to judge the generalizability of the results. The reviewer implies that the evaluation is *over* the entire Meta World benchmark, not a specific aspect of it.", "verifiability_rationale": "The reviewer makes the claim \"Hence, it is difficult to judge whether the results will generalize to other domains.\" The reviewer then provides a suggestion as evidence: \"I strongly recommend running experiments on a different benchmark such as Atari...\" This suggestion directly addresses the lack of generalizability and provides a concrete next step. The claim is supported by the reasoning provided.", "helpfulness_rationale": "The reviewer states \"The method is evaluated only on the tasks from Meta World...\" This is a clear statement of a limitation. The reviewer then suggests \"I strongly recommend running experiments on a different benchmark such as Atari...\" This is a direct and actionable recommendation based on the identified limitation. The reviewer's point is directly aimed at improving the method's robustness and generalizability."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a weakness ('a bit of analysis on what the model does is missing') and suggests a concrete action to take ('check the feedback/suggestions'). This directly tells the authors where to find the missing information, making it 5.", "grounding_specificity_rationale": "The review point mentions 'what the model does' and 'feedback/suggestions'. While it points to a general area, it doesn't specify a particular section, table, or unique element of the paper. The grounding is weak because the authors have to infer the specific part being referred to.", "verifiability_rationale": "The review point makes a claim by stating a weakness ('a bit of analysis on what the model does is missing') and provides a suggestion ('check the feedback/suggestions') as a form of justification. While not a direct citation, the suggestion points to a location where the information might be found, making it 3.", "helpfulness_rationale": "The review point is 5 because it directly identifies a potential weakness ('a bit of analysis on what the model does is missing') and provides a clear and actionable suggestion ('check the feedback/suggestions') for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a lack of clarity in the 'task setup'. It implies that the author needs to clarify how the EHR data is used and how far away the outcomes are from the input notes. This constitutes an explicit action, as the reviewer directly points out a missing element. However, the action is vague, as it doesn't specify the exact nature of the EHR data used (e.g., current admission, all previous admissions) or the timeframe for the outcomes.", "grounding_specificity_rationale": "The review point is 1 at all. It does not identify a specific part of the paper or methodology being addressed. The reviewer is broadly criticizing the 'task setup' without pointing to a particular section, table, or figure. Therefore, the grounding is weak as the authors cannot confidently determine which part of the paper is being discussed.", "verifiability_rationale": "The review point contains a claim in the form of a suggestion for improvement: 'The task setup is not described clearly.' However, this claim is not wellsupported. While the reviewer implies that the lack of clarity hinders understanding, there is no explicit justification or evidence provided to support this claim. The reasoning is implied but not explicitly stated, making it 3 but lacking strong supporting evidence.", "helpfulness_rationale": "The review point is 5. It directly points out a specific area where the author's work needs improvement \u2013 the clarity of the task setup. This is a concrete and actionable feedback that empowers the author to revisit their methodology description and ensure all necessary information is provided for others to understand and replicate their work. The feedback is directly linked to improving the quality of the draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the difference in convergence rates between the proposed algorithm (DMLCBO) and existing methods (SUSTAIN and MRBO). They then ask for an explanation of *why* DMLCBO does not achieve the same convergence rate. This is an implicit action, as the reviewer does not directly tell the authors to explain the theoretical difference. However, the request is very clear and actionable, prompting the authors to provide a justification for the observed discrepancy.", "grounding_specificity_rationale": "The reviewer points out a discrepancy in the convergence rate of the proposed algorithm. While they do not explicitly name a specific section, table, or figure in the paper, they are referring to a general issue with the algorithm's theoretical convergence rate. The connection to a specific part of the paper is implied but not clearly established. Therefore, the grounding is somewhat weak.", "verifiability_rationale": "The reviewer makes a claim: 'the authors are encouraged to discuss the reason why DMLCBO does not achieve it' (referring to the convergence rate). This claim requires justification. The reviewer is asking for an explanation, which is likely to be based on theoretical reasoning. This reasoning can be supported by citations to relevant literature, making the claim verifiable.", "helpfulness_rationale": "The reviewer's comment is focused on a specific theoretical aspect of the proposed algorithm and asks a direct question about it. They are suggesting that the authors should provide an explanation for the observed convergence rate. This is a focused and actionable suggestion that directly addresses a potential area for improvement or clarification in the authors' work. While not a broad critique, it is very helpful in guiding the authors to consider the theoretical underpinnings of their algorithm."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the 'approach section' is missing. While they don't specify what is missing within the section, the absence of a section dedicated to describing the methodology is a clear indication of an actionable omission. The reviewer implies the authors should look for this section in the main paper.", "grounding_specificity_rationale": "The reviewer points to the 'approach section' as the missing element. While they don't specify *what* is missing within this section, they clearly identify its location in the main paper. This implies a level of grounding as the authors can infer the section where the information should be. However, without specific details about the missing content, the specificity is limited.", "verifiability_rationale": "The reviewer's comment is a factual statement: 'The approach section is missing.' There is X being made or judgment being offered. The comment is a description of a factual absence, not a claim that requires verification.", "helpfulness_rationale": "The reviewer's comment highlights a significant omission in the main paper: the absence of a section detailing the approach. This omission is a valid concern for the authors trying to understand the paper. While the comment doesn't provide specific feedback *within* the missing section, it points to a crucial missing piece of information that could hinder the authors' understanding and ability to build upon the work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the weakness in the introduction and provides a clear suggestion for improvement. The action is to strengthen the statement about biological plausibility, and the implementation is to make the statement more impactful.", "grounding_specificity_rationale": "The reviewer accurately identifies the specific claim in the introduction regarding the biological plausibility of backpropagation and pinpoints the exact section where this claim is made. The grounding is 'Full Grounding' as the section is explicitly mentioned. The specificity is high as the reviewer clearly states that the statement is 'too weak' and lacks clarity.", "verifiability_rationale": "The reviewer makes a claim that the statement in the introduction is 'too weak' and lacks clarity. While the reviewer doesn't provide a direct citation in this review point, the context implies that the lack of clarity stems from the ongoing debate about biological plausibility, which is a generally accepted concept. Therefore, the claim is 3 as it points to a lack of clarity that can be supported by the existing understanding of the topic.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement in the introduction. They identify a specific weakness (the statement being too weak) and offer a constructive suggestion (make the statement more impactful). This directly helps the authors address the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement is explicit about the heuristic design of the modulator but does not provide concrete actions or guidance on how to improve it. It implies a potential issue with scalability and hyperparameter tuning but does not specify how to address these.", "grounding_specificity_rationale": "The review mentions 'modulator' and 'hyperparameter tuning' without explicitly identifying the specific part of the paper or model these relate to. It also does not specify what is wrong or missing in that part.", "verifiability_rationale": "The review contains claims about the modulator being 'heuristically designed' and a potential issue with 'scalability and hyperparameter tuning' but does not provide any logical reasoning, common knowledge, or external references to support these claims.", "helpfulness_rationale": "The review points out a potential issue with a 'modulator' and suggests it might be related to 'scalability and hyperparameter tuning' but does not offer any specific advice or guidance on how to address this."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The statement about 'practical amount of data' implies a limitation of directly using f_R/f_P, but it doesn't explicitly state an action or provide details on how to improve.", "grounding_specificity_rationale": "The review refers to 'f_R and f_P' generally and doesn't specify a particular section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer makes a claim about the limitations of less informed f_R/f_P, which could be supported by evidence, though the specific evidence isn't provided in the review point itself.", "helpfulness_rationale": "The review identifies a potential issue with f_R/f_P but doesn't offer concrete, actionable advice or insights on how to improve the draft based on this information."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the necessity of obtaining labeled data for imitation learning and mentions the lack of experiments on the difficulty of obtaining this data and the impact of its size. This provides a clear action for the authors to take, which is to conduct such experiments. While the reviewer doesn't provide specific details on *how* to obtain the data, the need for it is clear.", "grounding_specificity_rationale": "The review point mentions 'labeled data' and 'imitation learning' in general terms. It does not explicitly refer to a specific part, table, figure, or unique aspect of the paper being addressed. The reviewer is discussing a general gap in the application of imitation learning, not a specific issue within a particular section of the paper.", "verifiability_rationale": "The review point clearly identifies a claim: 'there are no experiments on whether there are any difficulties in obtaining the corresponding data, and how the performance changes depending on the size of the labeled data.' This claim is not explicitly supported by any examples or references. While the reviewer points out a gap in the experimental evaluation, they do not provide specific evidence to back up their assertion about the difficulties or the impact on performance.", "helpfulness_rationale": "The review point is specific about a missing experimental component related to the application of imitation learning. It highlights the lack of experiments on labeled data and its size, which is a concrete area for improvement. While the reviewer doesn't provide specific suggestions for the experiments, they clearly point out a gap in the current evaluation process, which is valuable information for the authors."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a gap in the paper's discussion by questioning the connection between overparameterization, memorization, and generalization, specifically regarding the implications for generalization bounds. While the reviewer identifies a problem in the paper's argument, they do not explicitly suggest a concrete action or modification to address this gap within the review itself. The reviewer is highlighting a missing piece in the paper's narrative.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'generalization bounds' and questions the connection between the paper's findings on overparameterized networks and robust memorization to robust generalization. They identify a specific area in the paper (the connection to generalization bounds) and highlight a lack of clarity regarding this connection. The reviewer can accurately pinpoint the area of discussion and clearly identifies the issue.", "verifiability_rationale": "The reviewer does not make a claim that can be verified. They are raising a question about the implications of existing knowledge (the connection between memorization and generalization) for the paper's theoretical framing. The reviewer is not presenting a claim that requires logical reasoning, common knowledge, or external references to be supported. The statement is a question about the interpretation of existing results.", "helpfulness_rationale": "The reviewer's point is highly relevant to the paper's theoretical framing. They question a potential weakness in the paper's argument regarding the connection between memorization and generalization, and they highlight the importance of considering generalization bounds. This raises a valuable point for the authors to consider and potentially address in future revisions or discussions about the paper's theoretical underpinnings. The reviewer's question is directly related to the paper's core arguments and could guide future research directions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states, \"it does not thoroughly explore the implications of their proposed method for other NLP tasks.\" This indicates a lack of clear action. The authors are informed about a limitation but not given a specific next step.", "grounding_specificity_rationale": "The comment refers to \"their proposed method\" generally, without pointing to a specific section, table, or figure. The issue is broad (\"thoroughly explore the implications...for other NLP tasks\") rather than pinpointing a specific element within the method's description.", "verifiability_rationale": "The review states, \"this somewhat limits the generalizability of the results.\" This is a statement of a problem or limitation, which can be considered a *judgment* about the paper. However, it doesn't *explain* *why* this limits generalizability or *suggest* *how* to address it. There's no external reference or logical reasoning provided.", "helpfulness_rationale": "The review points out a valid limitation: the narrow focus of the experiments. However, it doesn't suggest concrete improvements or alternative experimental setups. The impact is limited to informing the authors of a potential weakness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential ambiguity related to the term \"certificate\" and specifically mentions a location (line 267). This constitutes an explicit action or suggestion, as the reviewer identifies a potential issue that the authors should be aware of. However, the action itself is vague as it doesn't specify how to resolve the ambiguity or what changes are needed.", "grounding_specificity_rationale": "The reviewer explicitly mentions the term \"certificate\" and its location (line 267) within the paper. This demonstrates a clear identification of the specific part of the paper being addressed, which is a key aspect of grounding specificity. However, the comment does not specify what is wrong with the use of \"certificate\" or what alternative interpretations might exist, making it somewhat specific in identifying the *what* but less specific in explaining the *why* or *how*.", "verifiability_rationale": "The reviewer states that the use of \"certificate\" might be misinterpreted due to its meaning in complexity theory. This constitutes a claim that requires verification. The reviewer provides a logical reasoning by connecting the potential ambiguity to the established meaning of \"certificate\" in a specific field. While the reviewer doesn't provide external references, the logical connection to a wellknown concept makes the claim verifiable. The reasoning is present, making it 3.", "helpfulness_rationale": "The reviewer identifies a potential source of confusion related to the terminology \"certificate\" and its potential misinterpretation. This is a valuable piece of feedback as it highlights a fundamental aspect of clarity in academic writing. While the reviewer doesn't offer specific solutions, pointing out a potential ambiguity is helpful for the authors to ensure their message is understood correctly. The impact is significant as it addresses a core principle of effective communication."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the relevance of untrained networks and suggests a comparison, which is an explicit action. However, the reviewer does not specify *which* untrained networks to compare with or *how* to implement the comparison, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'untrained NNs (like deep image prior Ulyanov et al., CVPR 2018)' and 'inverse problems', providing specific examples and a general area of comparison. However, the reviewer does not explicitly point to a specific section, table, or unique aspect of the paper where this comparison should be made, making the grounding somewhat underspecific.", "verifiability_rationale": "The reviewer makes a judgment about the relevance of untrained networks for inverse problems and suggests a comparison, which constitutes a claim. The reviewer provides a citation for a relevant work ('deep image prior Ulyanov et al., CVPR 2018'), which supports the claim. However, the reviewer does not provide detailed reasoning or examples of how this comparison would be made or what the implications would be, making the verification somewhat incomplete.", "helpfulness_rationale": "The reviewer points out a relevant area (OOD generalization) and suggests a comparison with a class of methods (untrained networks) that could potentially improve the paper's contribution or address a potential weakness. While the suggestions are broad, they offer a valuable direction for improvement. The reviewer does not provide specific details on which untrained networks to compare or how to implement the comparison, which limits the immediate helpfulness for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point suggests *what* experiments to conduct (deeper networks and other network structures) but does not explicitly state *how* to conduct them. While it implies further experimentation, the specific steps or modifications needed are not detailed. The references provided are relevant but do not constitute a direct action for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions 'deeper networks' and 'other network structures' and provides specific examples like 'ResNet50' and 'MobileNet'. This clearly identifies the specific aspect of the paper being addressed and the nature of the suggested improvement. The authors can directly infer the need for experiments with these specific architectures.", "verifiability_rationale": "The review point contains a claim (a need for more experiments) and provides supporting references to justify the suggestion of exploring different network architectures. The reasoning is logical, and the references are relevant to the field, making the claim verifiable.", "helpfulness_rationale": "The review point directly addresses a common need for more comprehensive experimentation in machine learning papers. Suggesting specific architectures like ResNet50 and MobileNet provides concrete directions for improvement. While it doesn't offer *how* to implement the experiments, it clearly identifies a weakness and offers a clear improvement path, making it helpful for the authors to understand where their current experiments might be limited."}
{"actionability_label": "1", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point states a lack of clarity but does not provide any explicit or concrete actions for the authors to take. The reviewer is pointing out a problem, not suggesting a solution.", "grounding_specificity_rationale": "The review point refers to 'the proposed sample selection mechanism' and 'label distribution' without specifying which section or table of the paper these concepts relate to. The authors cannot identify the specific part of the paper being addressed.", "verifiability_rationale": "The review point states a lack of clarity regarding the proposed mechanism's effect on the label distribution. There is X made, let alone any supporting evidence or logical reasoning.", "helpfulness_rationale": "The review point identifies a problem (lack of clarity) but does not offer any suggestions or guidance on how to improve the draft. The authors are left with an unaddressed issue without any proposed solutions."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the limitation of evaluating only 'two relatively old and small models'. This clearly identifies a specific aspect of the evaluation that needs improvement. The reviewer directly points out a concrete issue that can be directly addressed by expanding the scope of the evaluation.", "grounding_specificity_rationale": "The comment refers to the 'results/analysis' in general, without specifying a particular section, table, or figure. While it identifies the *models* being evaluated, it doesn't pinpoint the exact part of the paper or analysis being limited. Therefore, the grounding is weak as the authors cannot confidently determine which specific aspect is being addressed beyond a general area.", "verifiability_rationale": "The comment identifies a limitation in the evaluation scope but doesn't provide a claim that requires verification or justification. It's more of a statement of fact about the current evaluation. There's no explicit claim being made that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The comment provides a clear direction for improvement by highlighting the limited scope of the evaluation. It suggests expanding the evaluation to include more models. This is helpful as it guides the authors on a specific area to focus on to enhance their work. While it doesn't offer a specific solution, it points towards a concrete action."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their belief that the proxlinear subproblem can be reformulated using the conjugate function. They also suggest that this reformulation makes the motivation of Algorithm 1 unclear. This indicates a direct identification of a potential improvement and its connection to Algorithm 1, making it explicit. While the reviewer doesn't provide the reformulation details, the suggestion itself is a concrete action.", "grounding_specificity_rationale": "The reviewer directly addresses the proxlinear subproblem mentioned in Algorithm 1, which is a specific part of the paper. They also mention 'Eq.(1)' to pinpoint the location of the problem being discussed. The reviewer further elaborates on the implications of the suggested reformulation for the motivation of Algorithm 1. This demonstrates a clear and precise identification of the relevant part and its implications, indicating high grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the relationship between the proxlinear subproblem and the conjugate function. They also provide a reasoning for why this reformulation might make the motivation of Algorithm 1 unclear. While the reviewer doesn't provide a detailed proof or external reference within the review point itself, the claim and the accompanying reasoning constitute a verifiable statement based on logical reasoning and the provided context. The suggestion of a reformulation implies a logical connection to the motivation of Algorithm 1.", "helpfulness_rationale": "The reviewer points out a potential simplification in the proxlinear subproblem using the conjugate function. They argue that this simplification could make the motivation of Algorithm 1 less clear. This directly addresses a potential weakness or area for improvement in Algorithm 1 and provides a clear rationale for why it might be helpful. The reviewer's comment is directly actionable and addresses a specific aspect of the algorithm's motivation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the relationship between Knowledge Distillation (KD) and Label Smoothing (LS) and provides specific conditions under which this relationship holds. While the connection is presented as a fact ('I believe'), the reviewer implies it's a relevant observation for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions 'Knowledge Distillation (KD)', 'Label Smoothing (LS)', and even the specific conditions 'uniformly distributed teacher network' and 'temperature is set at 1'. This provides clear grounding for the statement.", "verifiability_rationale": "The review point makes a claim ('KD can be viewed as a special form of LS'). However, it does not provide a detailed explanation, proof, or specific citation to support this claim. While the conditions are mentioned, the reviewer doesn't elaborate on how the equivalence holds under these conditions. The phrasing 'I believe' indicates uncertainty about the claim's validity.", "helpfulness_rationale": "The review point offers a conceptual insight into the relationship between KD and LS. While it's not a direct instruction on how to improve the authors' draft, understanding this relationship could potentially guide the authors in their own analysis and choices when applying these techniques. It provides a higherlevel understanding rather than a concrete, actionable step."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem (outofdate methods, small datasets) but does not explicitly state how the authors should address it. While the direction is implied (using more recent methods and larger datasets), the specific actions or modifications are not detailed. The reviewer suggests improvements but doesn't provide a clear path forward for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions 'dynamicpruning methods' and 'ImageNet', indicating a clear reference to specific parts of the paper. It also states the goal of 'further verify the effectiveness', which further grounds the comment. The reviewer accurately identifies the area of concern and the desired outcome.", "verifiability_rationale": "The review point contains a claim that 'No.3. 2021. Competing dynamicpruning methods are kind of outofdate. More recent works should be included. Only results on small scale datasets are provided. Results on large scale datasets including ImageNet should be included to further verify the effectiveness of the proposed method.' This claim requires justification. While the reviewer states the need for more recent work and larger datasets, they do not provide logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a suggestion for improvement rather than a claim that needs verification.", "helpfulness_rationale": "The review point raises a valid concern about the limitations of the current evaluation and suggests improvements. It points out the need for more recent methods and evaluation on larger datasets. This is a relevant point for the authors to consider and can guide their future work. However, the review point lacks specific suggestions on how to implement these changes or what specific experiments to conduct. It identifies a problem but doesn't provide concrete steps for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'can authors please throw light on why the performance degrades' and asks for an explanation of this phenomenon. This is a direct request for action, making it 5. The reviewer identifies the specific area of the results (FBN, table 5) and the characteristics of the data (missing/wrong/redundant) as the basis for the performance degradation, making the action explicit.", "grounding_specificity_rationale": "The reviewer refers to 'FBN results (table 5)' and specifically asks about 'missing/wrong/redundant' information. This direct reference to a specific part of the paper and the characteristics of the data demonstrates strong grounding. The reviewer can confidently identify the section and the relevant aspects being discussed.", "verifiability_rationale": "The reviewer states 'performance degrades' and asks for an explanation. This is a claim that requires verification. While the review point itself doesn't provide evidence, the request implies a logical connection and a need for justification. The reviewer is asking 'why' this happens, which requires reasoning and potentially references within the paper's methodology or experiments to understand the mechanism.", "helpfulness_rationale": "The reviewer is asking for an explanation of a phenomenon they observed (performance degradation) in the FBN results. This is a clear and direct request for improvement, making it 5. The reviewer is specifically asking about the impact of certain data characteristics on the model's performance, highlighting a potential area of confusion or lack of understanding."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'Make the captions more descriptive' which is a direct and clear action for the authors to take. They know exactly what needs to be improved.", "grounding_specificity_rationale": "The reviewer specifically mentions 'the captions' and states 'more descriptive', indicating a clear understanding of the part of the paper being addressed and the nature of the desired improvement.", "verifiability_rationale": "The reviewer does not make a claim about what is wrong with the captions or the paper. Instead, they suggest improvements. Therefore, it fits the 'X' category as defined in the provided guidelines.", "helpfulness_rationale": "The reviewer provides specific feedback on the figure captions, indicating a clear understanding of what needs improvement. While they don't explicitly claim the captions are wrong, the suggestion to make them more descriptive directly points to an area for authors to enhance their work. The location discrepancy and the need to explain the 'scramble network' also implicitly suggest areas for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their concern: \"Why is this particular dimension of difficulty interesting?\" This is a clear and direct identification of a lack of motivation for the chosen background images. The reviewer also points out that the choice is \"not well motivated,\" providing a specific reason for their dissatisfaction. This explicitness and the clear direction for improvement make the comment actionable.", "grounding_specificity_rationale": "The reviewer mentions \"CIFAR images\" and \"difficulties,\" which grounds the criticism somewhat in the paper's content. However, the reviewer does not explicitly state which part of the paper (e.g., a specific section or table) is being criticized for using these images as backgrounds. The criticism is more general, focusing on the *effect* of this choice rather than a specific instance. Therefore, while the topic is grounded, the specific element being addressed is not clearly identified.", "verifiability_rationale": "The reviewer states that the choice is \"not well motivated\" and asks \"Why is this particular dimension of difficulty interesting?\" This is a statement of opinion without providing any specific evidence or examples to support their claim. There is no logical reasoning, common knowledge, or external references provided to back up their assertion. The claim itself is that the motivation is lacking, but there's no verification of *why* it's lacking.", "helpfulness_rationale": "The reviewer's comment is relevant to the paper's goals as it points out a potential flaw in the experimental setup (using random CIFAR images as backgrounds). However, the comment is not particularly helpful because it does not offer a concrete suggestion or alternative for what *should* be used instead. The reviewer asks \"Why is this particular dimension of difficulty interesting?\" but does not propose a different dimension of difficulty that *would* be interesting or relevant. Without a specific direction for improvement, the comment is more of a critique than a constructive suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'minimizing the averaged loss across the noise injected models does not ensure the flatness of the minima.' This is a clear and direct criticism. The reviewer also provides a concrete suggestion: 'To claim that the minima found by minimizing the loss in Eq (3), the analysis on the losses of the noiseinjected models after training is required.' This indicates a clear next step for the authors. Therefore, the comment is 5 as it directly identifies a problem and suggests a solution.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the noiseinjected models' and refers to the loss function in Eq (3). This clearly identifies the specific part of the paper being addressed. The comment is fully grounded as it accurately pinpoints the section and equation being discussed. The reviewer also specifies 'the losses of the noiseinjected models after training' as the necessary analysis, making the grounding very specific.", "verifiability_rationale": "The reviewer makes a clear claim: 'minimizing the averaged loss across the noise injected models does not ensure the flatness of the minima.' This is a statement that can be verified. The reviewer provides a logical reasoning for this claim: 'The reviewer argues that minimizing the average loss might not guarantee flatness in the context of noiseinjected models.' While the reviewer doesn't provide external references, the reasoning is based on the understanding of flat minima and the described training process. The claim is thoroughly supported within the context of the paper. Therefore, the claim is 5.", "helpfulness_rationale": "The reviewer clearly identifies a gap in the analysis regarding flatness. They provide a specific suggestion: 'To claim that the minima found by minimizing the loss in Eq (3), the analysis on the losses of the noiseinjected models after training is required.' This is a valuable suggestion that directly addresses the identified issue. The reviewer's point is clear, concise, and directly actionable for the authors. It guides the authors to perform additional analysis that is directly relevant to the claim being made. Therefore, the comment is 5 as it directly points to a flaw in the methodology and offers a clear next step for the authors to take to validate their claims about flat minima."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'the text inside the figure and the labels are too small to read without zooming'. This is a direct and actionable statement. The reviewer also provides a concrete solution: 'This text should be roughly the same size as the manuscript text'. This clearly indicates an action the authors should take.", "grounding_specificity_rationale": "The reviewer directly references the 'text inside the figure and the labels'. This is a very specific reference, indicating strong grounding. They are not making an educated guess or referring to a general concept; they are pinpointing a specific part of the paper.", "verifiability_rationale": "The reviewer points out a factual issue: 'the text inside the figure and the labels are too small to read without zooming'. This is a verifiable observation. While the reviewer doesn't offer a solution or justification for *why* this is a problem, the statement itself is verifiable. The underlying issue is the lack of consistency in text size, which is a verifiable problem in the presentation.", "helpfulness_rationale": "The reviewer clearly identifies a significant issue: the readability of the text in the figure. They provide a direct and actionable suggestion to make it the same size as the manuscript text. This is a clear and constructive piece of feedback that directly empowers the authors to improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a potential weakness ('lack of clarity in motivation') but does not specify *how* the motivation should be improved or what specific aspects are unclear. It's a general statement about the introduction, lacking concrete action items for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'the motivation' in relation to the introduction, which can be interpreted as implicitly referring to a specific part. However, the comment does not explicitly state which specific section or element of the introduction is unclear. The grounding is weak because the authors cannot confidently determine the referenced part. The comment also does not specify what needs to be addressed in this part, making it not specific.", "verifiability_rationale": "The comment 'The motivation is not clear at all' is a statement of opinion or judgment about the paper's introduction. It does not contain a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support or justify this statement.", "helpfulness_rationale": "The comment identifies a potential area for improvement ('lack of clarity in motivation') but does not provide any specific suggestions or guidance on how to address this issue. The authors are left with a general observation rather than concrete feedback on how to revise the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a difference in feature positions but doesn't explicitly state what needs to be changed or how to implement the change. It's a statement of observation rather than a direct instruction.", "grounding_specificity_rationale": "The review discusses 'features' and 'categories' without specifying which part of the paper or element is being referred to. It lacks explicit identification of the specific area being addressed.", "verifiability_rationale": "The review states a claim about the inconsistency of feature positions but provides no evidence, logical reasoning, or references to support this observation.", "helpfulness_rationale": "The review identifies a potential issue with feature organization but offers a general observation without specific suggestions or actionable steps for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the problem (insufficient validation) and the goal (validate the alignment). However, it lacks specific details on how this validation should be performed, making it vague on the implementation.", "grounding_specificity_rationale": "The comment explicitly mentions 'relabelled reward data' and 'human annotator judgments', accurately pinpointing the specific parts of the paper being addressed. It also clearly identifies the issue as 'insufficiently validated'. This indicates strong grounding and specificity.", "verifiability_rationale": "The review point itself is a statement of a problem ('alignment of relabeled reward data with human annotator judgments remains insufficiently validated') and does not contain a claim that requires verification. Therefore, it is classified as 'X'.", "helpfulness_rationale": "The comment identifies a crucial issue (alignment validation) that is directly relevant to the authors. It highlights a potential weakness in their work and points towards an area that needs attention. While it doesn't offer a solution, it effectively highlights a problem that needs addressing."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states actions the authors should take, such as replacing natural language descriptions with notation and adding breakout diagrams showing attention mechanisms. These are direct and actionable suggestions for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'section 4' as the area needing improvement, which provides some grounding. However, they do not specify the exact part within section 4 (e.g., a particular table, figure, or unique element) that requires improvement. The suggestion to add 'breakout diagrams showing the attention mechanisms' is a general improvement suggestion rather than a specific fix for a known issue within that section.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement, framed as helpful feedback. It does not contain a claim that requires verification. There is no logical reasoning, common knowledge, or external references being offered. It is a constructive suggestion based on the reviewer's understanding of the paper's presentation.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as replacing natural language descriptions with notation and adding breakout diagrams showing attention mechanisms. These suggestions are directly actionable and likely to be beneficial for the authors. The reviewer's tone is constructive and suggests a desire to help the authors improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a limitation in the method's generalizability due to the limited number of molecules used for training. While it points out a potential issue, it doesn't explicitly state what action the author should take or how to address it. The reviewer mentions 'indistribution testing' as a limitation, which is a specific detail, but the suggested solution of 'training for each molecule individually' is not a concrete, actionable step that the author can directly implement. The reviewer identifies the *problem* but doesn't provide a clear, actionable path to solve it.", "grounding_specificity_rationale": "The review point explicitly mentions 'a very limited number of molecules' and 'indistribution testing' as specific aspects of the paper being addressed. These are clear references to specific sections, tables, or unique elements within the paper. The reviewer also explains *why* these are limitations, connecting them to the need for individualized training. This demonstrates a clear understanding of the specific part of the paper being discussed and the issues within it.", "verifiability_rationale": "The review point contains a claim: 'I think the value of this method would be limited if it needs to train for each molecule individually.' This is a statement of opinion. The reviewer then provides a logical reasoning to support this claim by connecting it to the 'limited number of molecules' and 'indistribution testing.' They explain *why* training individually would be a limitation, providing a clear justification for their claim.", "helpfulness_rationale": "The review point raises a valid concern about the method's value given the limited training data and indistribution testing. While it doesn't offer a solution or specific advice on how to improve the method, it highlights a potential limitation that the author should be aware of. Understanding these limitations is helpful for assessing the scope and potential biases of the method. The reviewer's point contributes to a critical evaluation of the method, but it doesn't directly guide the author on how to proceed. Therefore, it's 3 as it points out a potential issue without providing a complete solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly states that 'symbols are a little bit complicated'. This indicates an explicit action or suggestion that the authors should make the symbols easier to understand. However, the point is vague about *which* symbols are complicated and doesn't provide specific guidance on how to improve their clarity. Therefore, while it suggests an actionable step, the specifics are lacking.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or the symbols being discussed. It makes a general statement about the complexity of 'symbols' without pinpointing their location or nature. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part. The specificity is also weak because the point does not detail what is meant by 'complicated' or how the symbols are used. This aligns with the definition of '3' where the authors cannot confidently identify the referenced part and the issue is not clearly specified.", "verifiability_rationale": "The review point contains a claim: 'symbols are a little bit complicated'. However, it does not provide any evidence or reasoning to support this claim. There are no references to external works, logical arguments, or common knowledge to back up the assertion that symbols are complicated. Therefore, the claim is not verifiable based on the information provided.", "helpfulness_rationale": "The review point identifies a potential issue ('symbols are a little bit complicated') but does not offer any suggestions or actions to address it. It is a diagnosis without a cure. The authors are left wondering what the problem is and how to fix it, but the review point doesn't provide any concrete steps. Therefore, it does not help the authors improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer requests an explanation for a red line in Figure 3. This is an explicit request for action, as the reviewer wants to understand how to interpret or address the line. However, the review point itself does not contain the explanation or the action of identifying the source of the test data and the concept of ground truth.", "grounding_specificity_rationale": "The reviewer explicitly asks 'Where does the test data come from?' and 'Do you have a ground truth?'. These are very specific questions directly addressing the source and nature of the data being used. This indicates a high level of grounding specificity as the reviewer is asking about the concrete elements of the data used in the analysis or experiment represented by the red line.", "verifiability_rationale": "The reviewer is making a statement (a request for clarification) rather than making a claim that needs verification. While the request implies a need for information, the review point itself does not contain a verifiable claim. The *ability* to answer the question is what would make it verifiable, not the question itself in its current form.", "helpfulness_rationale": "The reviewer's request to understand the red line in Figure 3 is directly related to improving the draft. Understanding visual elements is crucial for a thorough review and constructive feedback. However, the review point itself does not contain the explanation or the action of identifying the source of the test data and the concept of ground truth, which are necessary for the reviewer to understand the figure."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about the role of periodicity, which is a direct and actionable request. They also suggest adding periodicity to the spectral kernel as a way to test this hypothesis, providing a concrete target for investigation. While the action of identifying the question is implicit, the question itself is clear and points towards a specific area of improvement.", "grounding_specificity_rationale": "The reviewer clearly identifies 'periodicity' and 'compositionality' as the key concepts being discussed. They explicitly compare the model's ability to capture periodic relationships with its ability to capture relationships more generally. This strong grounding makes it clear which specific aspects of the model they are referring to.", "verifiability_rationale": "The reviewer presents a question about the extent to which periodicity is sufficient, rather than requiring the full framework of compositionality. While the question itself doesn't provide a definitive answer, it is a clear and verifiable claim that the authors can investigate through experimentation. The reviewer is asking a question that can be directly addressed by further analysis of the model's performance on periodic tasks.", "helpfulness_rationale": "The reviewer's comment is 5. They directly ask a question that is relevant to the authors' work and provide a specific suggestion for an experiment (adding periodicity to the spectral kernel) to investigate this question. This is a clear direction for the authors to take their research forward and helps them focus their efforts on a specific aspect of their model's capabilities."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment is a general statement about the paper's writing quality and does not specify any particular aspect or section of the paper that needs improvement. While it identifies a problem, it lacks the explicit and concrete instructions necessary for actionability. The reviewer suggests the paper is 'not very wellwritten' and 'possibly hurriedly written,' but does not indicate what needs to be changed or how to achieve better writing quality.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper or element that needs improvement. It is a general statement about the overall writing quality. While the reviewer can infer that the issue lies in the writing, they cannot pinpoint the exact section, table, figure, or unique aspect being addressed. The comment lacks the specificity required to guide targeted changes.", "verifiability_rationale": "The comment contains a claim ('The paper is not very wellwritten...') but does not provide any supporting evidence, logical reasoning, or external references. The reviewer states a negative assessment of the paper's writing quality but does not explain *why* they believe this or provide any context or examples to support their claim. The verifiability is low because there is no justification for the statement.", "helpfulness_rationale": "The comment identifies a weakness in the paper ('not very wellwritten') but does not provide any specific suggestions or actions for improvement. While the reviewer points out a problem, they do not offer concrete steps or guidance on how to address it. The comment is vague and lacks actionable feedback, making it less helpful for the authors to improve their draft. It's better than nothing, but it doesn't provide the necessary direction for change."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests the introduction to orthogonality in Part 2 could be 'more detailed'. This is an implicit suggestion, as the reviewer does not explicitly state what should be added or changed. While the reviewer identifies a potential area for improvement, they do not provide specific actions or concrete steps for the authors to take. The suggestion is vague and lacks direction.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Part 2' when stating that the introduction to orthogonality 'could be more detailed'. This clearly identifies the specific section of the paper being addressed, indicating strong grounding. However, the reviewer does not specify *what* is missing or unclear in that introduction. The claim is about the introduction being 'could be more detailed', which is a general statement about the level of detail, not a specific problem or issue within that section.", "verifiability_rationale": "The reviewer states that the introduction to orthogonality in Part 2 'could be more detailed'. This is a claim made by the reviewer. However, the reviewer does not provide any evidence, reasoning, or external references to support this claim. The statement is presented as an observation or suggestion without justification.", "helpfulness_rationale": "The reviewer's suggestion that the introduction to orthogonality in Part 2 could be 'more detailed' is a constructive comment aimed at improving the clarity and completeness of the paper. This suggestion directly addresses a potential weakness and offers a positive direction for the authors to consider. While it doesn't provide specific details, it is a helpful suggestion that encourages the authors to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the paper's contribution as the removal of double descent under specific conditions *in relation* to prior work. This is an explicit action. Once the action is identified (identifying the paper's contribution), the authors can deduce how to apply this feedback by focusing on the anisotropic settings and optimal regularization. The reviewer also suggests a way to improve the paper's framing, which is a concrete action. Therefore, the review point is 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'samplewise multiple descent\" and \"optimal regularization can remove double descent even in certain anisotropic settings.\" These are specific technical terms and concepts. The reviewer also connects these specific concepts to existing theoretical work, indicating an understanding of the context. The reviewer's comment is grounded in existing knowledge and is specific about the type of double descent and the conditions being considered. Therefore, the review point is 5.", "verifiability_rationale": "The reviewer states that the paper's contribution is \"the result that optimal regularization can remove double descent even in certain anisotropic settings.\" This is a clear claim about the paper's novelty. The reviewer also provides a justification for their belief that the paper should highlight this novelty, stating they cannot verify the claims due to a lack of familiarity with the techniques. This justification, while based on a lack of expertise, is a logical reasoning process. Therefore, the review point is 4.", "helpfulness_rationale": "The reviewer clearly identifies a key contribution of the paper and provides a constructive suggestion for improving the paper's framing. The reviewer suggests that the paper should explicitly highlight the novelty of their result in relation to prior results. This is a clear and actionable suggestion for the authors. The reviewer's point is directly helpful for the authors in improving their paper. Therefore, the review point is 5."}
{"actionability_label": "1", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the two methods are independent. While this is a true statement, it does not provide any actionable advice or suggestions for the authors on how to connect or utilize these methods. The authors are not guided on how to modify their approach based on this observation.", "grounding_specificity_rationale": "The review point explicitly mentions 'contrastive training objective' and 'contrastive search' by name. This directly identifies the specific methods being discussed. It also specifies the relationship between these methods as 'little inner connection' on both 'intuition' and 'algorithm'. This provides a clear and specific reference point for the reviewer.", "verifiability_rationale": "The review point presents a claim that the two methods are independent. However, it does not provide any evidence, reasoning, or references to support this claim. There is no logical argument or citation to back up the assertion that these methods have little inner connection.", "helpfulness_rationale": "The review point is a critique pointing out a potential area for further exploration. It does not offer any suggestions, solutions, or actionable steps for the authors. It is a negative comment about the relationship between the methods without proposing any concrete improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a gap in the paper's comparison to existing DAS models but doesn't explicitly state how the authors should address this gap. While it points out the existence of PhaseNetDAS and similar models, it doesn't provide a clear action on how to compare or justify the proposed method against them. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The comment explicitly mentions the existence of DAS models and the lack of comparison, which grounds the feedback to a specific part of the paper. It identifies the area where the paper is lacking. The comment specifies what needs to be addressed: the benefit of the proposed method against existing methods. The action is implicit but the grounding and specificity are clear.", "verifiability_rationale": "The comment contains a claim about the existence of DAS models and the lack of justification for the proposed method. It is supported by the reviewer's knowledge and the potential content of the paper. However, it lacks specific examples or references to back up the claim about the lack of justification. The evidence is general and could be strengthened with specific instances of where the justification is missing. It is 3 but could be more robust with supporting evidence.", "helpfulness_rationale": "The comment identifies a valid criticism regarding the lack of comparison to existing DAS models and the need for clearer justification. It suggests that if the claim is about a foundation model, future applications should be highlighted. This provides some direction for the authors to consider. However, it doesn't explicitly state *how* the authors should make this comparison or *why* they should prioritize this justification. It points out a gap but doesn't provide a direct path to improvement. It is 3 in identifying an area for improvement but lacks concrete guidance on how to achieve it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a specific question about the discrepancy between Table 6 and Table 1, which implies an actionable request to understand why this difference exists. However, the reviewer does not explicitly state the action to be taken or the expected outcome, making it partially actionable.", "grounding_specificity_rationale": "The reviewer asks about the results of Table 6 in relation to Table 1, specifically for MCTpairs. This implies a clear identification of the specific aspect of the paper being addressed. The reviewer also asks about ablation studies of MCT without adaptive metrics, which clearly specifies the component being questioned. Therefore, the grounding is strong.", "verifiability_rationale": "The reviewer states a claim: 'Why the results of Table 6 is not aligned with Table 1 (MCTpair)'. This claim requires justification. The reviewer also asks for 'ablation studies of MCT without the adaptive metrics', which is a request for additional information, not a claim requiring verification. Therefore, the verifiability is partially verifiable.", "helpfulness_rationale": "The reviewer asks 'Why the results of Table 6 is not aligned with Table 1 (MCTpair)' and 'what about the ablation studies of MCT without the adaptive metrics'. These are both clear and actionable questions aimed at improving the understanding of the results and the methodology. The request for ablation studies is particularly direct and valuable for the authors. The 'why' question, while not immediately actionable, points to a potential area of confusion and encourages clarification."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point identifies a pattern in existing research but doesn't explicitly state how the authors should use this information to improve their model. The action is implied but not directly stated.", "grounding_specificity_rationale": "The review point is a general statement about the robustness of models and the existence of prior work, not a specific reference to a part of the authors' paper.", "verifiability_rationale": "The review point is an observation about the existence of prior work and findings, not a definitive claim that needs verification.", "helpfulness_rationale": "The review point is insightful and relevant, connecting the authors' work to existing research. However, it doesn't provide direct, actionable steps for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests 'more discussions' as a way to improve the paper. While this is a suggestion, it's not explicitly tied to a specific action on the part of the authors. The criticism of the subtasks' simplicity is vague. Therefore, it's '2'.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the 10 subtasks' and 'bAbi,' which are specific parts of the paper. This demonstrates good grounding.", "verifiability_rationale": "The reviewer makes a claim ('The 10 subtasks are rather simplistic for bAbi') but doesn't provide any evidence or justification within the review point itself. Therefore, it's '1'.", "helpfulness_rationale": "The reviewer criticizes the simplicity of the subtasks and suggests more discussion. While this has the potential to be helpful, the review point lacks a specific, verifiable claim about the subtasks' simplicity. The suggestion for more discussion is a general call for improvement rather than a concrete action item. Therefore, it's '2'."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about the limitation of the approach (the restriction to triplets) rather than providing a direct instruction on how to address it. While it identifies a problem, it doesn't offer a concrete action or suggestion on how to overcome this limitation. The action is implicit in the question itself, suggesting an exploration of longer subsequences, but without specific guidance on how to do so.", "grounding_specificity_rationale": "The review point is a general question about the restriction to triplets and does not specify which part of the paper or method this limitation refers to. It doesn't mention any specific section, table, figure, or unique aspect of the paper. Therefore, it doesn't ground the issue in a specific part of the work.", "verifiability_rationale": "The review point is a question, not a statement that requires verification. It doesn't present a claim that needs to be supported by evidence or reasoning. It's a diagnostic question about a limitation.", "helpfulness_rationale": "The review point identifies a limitation of the approach (the restriction to triplets) but doesn't offer any suggestions or insights on how to overcome this limitation. It's a diagnostic question rather than a constructive suggestion for improvement. While it highlights an area for potential extension, it doesn't provide concrete guidance on how to implement such an extension."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point primarily asks for clarification on a term and suggests a connection between two concepts. It does not explicitly state an action or provide concrete steps for the authors to take. While it implies an area for improvement, the action is not directly identified or detailed.", "grounding_specificity_rationale": "The reviewer uses specific terminology like 'sequence of episodes' and mentions 'practice' and 'evaluation' as types of this sequence. This suggests an attempt to pinpoint the area of concern. However, the exact section or part of the paper being addressed is not explicitly stated, making it only somewhat grounded.", "verifiability_rationale": "The review point is a question seeking clarification and does not contain a claim that requires verification. Therefore, it does not have verifiability in the sense of supporting a statement with evidence.", "helpfulness_rationale": "The review point is a question seeking clarification on a specific term and suggesting a missing related work. While this points to potential areas for improvement, it does not directly guide the authors on how to improve their draft. The feedback is more about understanding the current terminology rather than providing actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the issue: 'I don't think the study about different subdomain sizes is an \"ablation\" study since they aren't removing a component of the method.' This directly identifies a potential mischaracterization of the study. The reviewer is stating an opinion about the nature of the experiment. While it doesn't provide a concrete action to improve the draft, it points to a specific area where the authors might have misunderstood the experimental setup. The reviewer is stating a judgment about the paper (something is unclear, not wellwritten), as deduced or inferred observations that go beyond merely stating facts.", "grounding_specificity_rationale": "The comment explicitly mentions 'subdomain sizes' and 'ablation study' as the key elements being questioned. The reviewer uses precise terminology and clearly identifies the specific part of the paper or concept being referred to. The comment specifies what needs to be understood about the experiment. The authors can easily identify the referenced part (the description of the experiment with varying subdomain sizes) and the issue (the lack of component removal). This falls under the category of '5' as the reviewer can accurately pinpoint the section and identify the issue.", "verifiability_rationale": "The comment contains a claim: 'I don't think the study about different subdomain sizes is an \"ablation\" study since they aren't removing a component of the method.' This claim is supported by the reasoning that an ablation study typically involves removing a component, which is not the case here. The reviewer provides a logical explanation of why the study is not an ablation study. The reasoning is clear and directly supports the claim. The comment uses logical reasoning to explain why the study is not an ablation study. This falls under the category of '5' as the claim is thoroughly supported by explicit, sufficient, and robust evidence (the definition of an ablation study).", "helpfulness_rationale": "The comment is highly relevant and directly addresses a potential misunderstanding or mischaracterization of the study. It provides clear information for the authors to understand that the experiment is not a traditional ablation study. This information is actionable in the sense that it guides the authors to reevaluate their understanding of the experimental setup and potentially the related literature. The comment is clear and directly points out a specific area of confusion. The reviewer is stating a judgment about the paper (something is unclear, not wellwritten), as deduced or inferred observations that go beyond merely stating facts. The comment is not just a criticism but also a suggestion for clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests adding AccNet as part of a larger predictor and mentions the context of semantic segmentation and similar operators. This indicates a clear action or suggestion, making it actionable.", "grounding_specificity_rationale": "The review point mentions specific terms like 'AccNet,' 'larger predictor,' 'semantic segmentation,' and 'similar operators.' This demonstrates an attempt to identify the specific aspect of the paper being addressed, indicating grounding. While it doesn't explicitly state which part of the paper this refers to, the terms are directly related to the potential extension.", "verifiability_rationale": "The review point presents a suggestion for future work but doesn't provide concrete evidence or justification for why this would be a good idea or how it would be implemented. It lacks logical reasoning, common knowledge, or external references to support the suggestion. Therefore, it is not 5.", "helpfulness_rationale": "The review point offers a potential avenue for future research by suggesting the inclusion of AccNet in a larger predictor for semantic segmentation. While this is a valuable direction to explore, it doesn't directly address a specific weakness or improvement needed in the current work. It's more of a suggestion for future development than a direct critique or actionable improvement for the current draft. Therefore, it is 3, as it encourages the authors to think about their work in a broader context, but it doesn't immediately resolve any immediate issues."}
{"actionability_label": "4", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitation of the metric's testing and suggests improvement by testing on more datasets. This is an explicit action, and while the concreteness could be debated (it doesn't specify *how* to expand testing), the action itself is clear.", "grounding_specificity_rationale": "The reviewer refers to 'the new proposed metric' and 'a single dataset'. While not a direct section reference, it clearly identifies the scope of the metric and the dataset being discussed. This can be considered partially grounded as the topic is quite specific. However, it doesn't pinpoint a specific part of the metric or the dataset itself, only the general area.", "verifiability_rationale": "The reviewer states a fact about the metric's testing limitation. While the claim is verifiable (it's a factual statement), there is no further justification or reasoning provided for why this is a problem or what should be done about it. It's a statement, not a reasoned argument.", "helpfulness_rationale": "The reviewer points out a limitation of the metric's testing. While this is a valid observation and a helpful piece of feedback for the authors to know the metric's scope, it doesn't offer specific suggestions for improvement or how to address this limitation. It identifies a problem but doesn't provide a constructive solution beyond acknowledging it."}
{"actionability_label": "High", "grounding_specificity_label": "Low", "verifiability_label": "High", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states a desire to compare the base DA methods with and without AutoDial and AdaBN, which are direct competitors to TN. This clearly indicates an action the authors should take.", "grounding_specificity_rationale": "While the reviewer suggests comparing TN with AutoDial and AdaBN, they do not explicitly state where this comparison should be made in the paper or why these baselines are relevant. The reasoning is implied but not stated within the review point itself.", "verifiability_rationale": "The reviewer provides a clear justification for why the comparison with AutoDial and AdaBN is important, stating it would strengthen the evaluation. This demonstrates logical reasoning.", "helpfulness_rationale": "The reviewer's suggestion is directly aimed at improving the understanding of TN's performance relative to relevant baselines, which is a valuable contribution to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states actions the authors should take, such as 'move the definition to L73' and 'clarify the superscript in Eq 6'. While the reviewer doesn't explicitly state *how* to define 'NE' or clarify the superscript, the actions are clear and direct. The reviewer is prompting the authors to take specific actions to improve the paper.", "grounding_specificity_rationale": "The reviewer explicitly refers to specific locations in the paper, namely 'L73' and 'Eq 6', when pointing out the issues. This indicates a high level of grounding specificity as the reviewer is directly identifying the parts of the paper that need attention.", "verifiability_rationale": "The reviewer makes claims about the paper, specifically stating that 'Some abbreviations are not defined' and 'Superscript notation in Eq 6 is not defined until much later'. The reviewer also provides suggestions ('move the definition to L73' and 'clarify the superscript in Eq 6') as actions to be taken. The grounding (referring to L73 and Eq 6) makes it easier to verify the claims, and the suggestions provide a basis for verification.", "helpfulness_rationale": "The reviewer clearly identifies specific weaknesses in the paper (undefined abbreviations and undefined superscript) and provides concrete suggestions for improvement ('move the definition to L73' and 'clarify the superscript in Eq 6'). The suggestions are directly relevant to the identified issues and are actionable for the authors. The reviewer's comments are not just observations but also constructive recommendations."}
{"actionability_label": "3", "grounding_specificity_label": "1 and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement 'the evaluation is weak' is an explicit action, as it directly identifies a deficiency. However, it is somewhat vague as it doesn't specify what aspects of the evaluation are weak. The statement 'the baselines used in the paper are not even designed for fair classification' is also explicit, identifying a specific issue with the baselines. It is somewhat vague as it doesn't detail *why* the baselines are not designed for fair classification.", "grounding_specificity_rationale": "The comment 'the evaluation is weak' does not identify a specific part of the paper or methodology being evaluated. It is a general statement about the evaluation. The comment 'the baselines used in the paper are not even designed for fair classification' also does not identify a specific part of the paper or methodology. It is a general statement about the baselines.", "verifiability_rationale": "The statement 'the evaluation is weak' does not contain a claim that can be verified. It is a subjective assessment. The statement 'the baselines used in the paper are not even designed for fair classification' is a claim. However, the review point does not provide any evidence or justification for this claim. It is presented as a statement of opinion without supporting references or explanations.", "helpfulness_rationale": "The review point is a critique of the evaluation's quality and the baselines used. It does not provide specific, actionable feedback or suggestions for improvement. It is not a direct instruction on how to revise the work, but rather a metacomment on the evaluation process itself."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the action they want to see: 'spelling out the setting'. This action is both explicit (the reviewer names the action) and concrete (they specify what needs to be spelled out: the setting).", "grounding_specificity_rationale": "The reviewer identifies the specific part of the paper they are referring to: 'the first three paragraphs of section 2'. This is strong grounding as the authors can directly identify the referenced part. The reviewer also specifies what needs to be spelled out: 'the setting', which clearly identifies the issue.", "verifiability_rationale": "The reviewer makes a claim that the authors might be misinterpreting the generality of their work and that spelling out the setting would improve clarity. However, the reviewer does not provide any evidence or justification for why spelling out the setting would necessarily make the exposition clearer or address the perceived generality issue. The reasoning is presented as a suggestion rather than a verifiable claim.", "helpfulness_rationale": "The reviewer's comment suggests a potential improvement to the authors' work by clarifying the exposition. However, the comment itself does not provide any specific information or guidance on how to 'spell out the setting' or how this would lead to a clearer exposition. The comment is a suggestion, not a constructive critique that offers concrete help."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue with the baselines ('The experiments are not quite convincing') and suggests an alternative ('...or compared to these approaches, what is the advantage of the proposed method?'). While the reviewer doesn't provide a concrete stepbystep action, they clearly identify a problem and propose a solution. The explicitness of the suggestion could be debated, but it leans towards explicit.", "grounding_specificity_rationale": "The reviewer doesn't explicitly point to a specific section or table in the paper. They refer to the general 'experiments' and suggest improvements related to the choice of baselines. While the intent is clear (improving the experimental section), the lack of a precise reference point makes the grounding somewhat weak. It's not obvious which part of the paper needs improvement, but it's not so vague that it's 1 at all.", "verifiability_rationale": "The reviewer makes a claim ('The experiments are not quite convincing') and provides a justification ('The authors choose the old baseline like R3D and C3D. To reduce computation complexity, many papers have been proposed in 3D CNN (X3D, SlowFast, etc)') as evidence. While the claim itself is subjective ('not quite convincing'), the reviewer attempts to support it with reasons related to the choice of baselines and the existence of more advanced models. This suggests an attempt to provide logical reasoning, even if the claim is ultimately subjective. The lack of direct references makes the verifiability somewhat limited.", "helpfulness_rationale": "The reviewer raises valid concerns about the experimental setup and encourages further discussion. They point out a potential weakness in the baselines and suggest exploring more advanced models. This feedback is relevant to the authors and highlights areas for improvement. However, the reviewer doesn't provide specific, actionable steps *on how* to improve the method or the experiments. The feedback is more about suggesting alternatives than providing concrete implementation guidance. Therefore, it's helpful in identifying areas for improvement but lacks the detailed guidance of a '4' or '5' comment."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for specific details about the implementation of the attention module within the ResNet20 architecture. While the action of seeking clarification is explicit, the lack of concrete details makes it only partially actionable. The reviewer could infer that the attention module is integrated within the ResNet20 blocks, but this is not explicitly stated.", "grounding_specificity_rationale": "The reviewer is referring to the 'attention module' and the 'backbone ResNet20 architecture'. They are asking for details about their integration. The authors can infer that the attention module is part of the ResNet20 architecture, but they cannot confidently determine the exact part being addressed without further clarification.", "verifiability_rationale": "The reviewer is stating a fact: 'It is not very clear how exactly is the attention module attached to the backbone ResNet20 architecture when performing the search.' This statement is verifiable as it is a direct observation about the lack of clarity.", "helpfulness_rationale": "The reviewer is providing valuable information to the authors by clarifying the lack of clarity regarding the attention module's integration. This information is likely to be helpful for the authors in understanding the method better."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a performance difference between high and low bitrates, which is an explicit action. However, it lacks specific guidance on how to improve the low bitrate performance, making it somewhat vague on the action to be taken. The suggestion to discuss or compare with a related work is also an explicit action but lacks specific guidance on how to apply this suggestion.", "grounding_specificity_rationale": "The comment discusses performance at different bitrates but does not explicitly identify the specific bitrate range or the section of the paper where this comparison is made. The suggestion to discuss a related work is also 1 to a specific aspect of the proposed method.", "verifiability_rationale": "The comment makes a claim about the performance difference at different bitrates but does not provide any evidence or justification for this claim within the review point itself. Similarly, the suggestion to discuss a related work is a claim that lacks specific examples or references within the review point.", "helpfulness_rationale": "The comment points out a potential area for improvement (low bitrate performance) but does not offer concrete steps or guidance on how to address it. The question about the bitrate range is also not helpful as it does not provide any actionable feedback. The suggestion to discuss a related work is helpful as it points to a relevant area for further research or comparison, providing a concrete resource for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review suggests a distinction but doesn't provide explicit steps on how to achieve it.", "grounding_specificity_rationale": "The review refers to general concepts without explicitly naming the section or part of the paper where this distinction is discussed. It also doesn't specify what these bounds are.", "verifiability_rationale": "The review contains a claim about the lack of distinction but doesn't provide sufficient justification, examples, or references to support this claim.", "helpfulness_rationale": "The review points out a potential area for improvement in the authors' understanding or application of statistical concepts, encouraging them to think more critically."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'marginal' and 'further analysis,' which are direct actions the authors should take. The reviewer points to specific areas ('three tasks', 'previous works', 'baselines'), making the action more concrete than a vague general statement.", "grounding_specificity_rationale": "The comment explicitly mentions 'improvements on three tasks' and 'previous works and baselines,' which allows the authors to accurately pinpoint the referenced parts. However, the comment does not specify *why* these improvements are marginal or *what* aspects of the tasks, previous works, or baselines are lacking. The specificity is limited to identifying the areas of concern, not explaining the shortcomings or suggesting specific improvements.", "verifiability_rationale": "The comment contains a claim: 'improvements on three tasks over the previous works and selfimplemented baselines are marginal' and 'further analysis beyond the main experiments is not sufficient.' However, it does not provide any logical reasoning, common knowledge, or external references to support these claims. The reviewer states a problem but doesn't explain why it's a problem or how it should be addressed.", "helpfulness_rationale": "The comment identifies a valid concern (marginal improvements) and suggests an improvement (further analysis). However, it lacks specific details on what the improvements are marginal on, why they are marginal, and how further analysis should be conducted. The suggestions are very highlevel and lack concrete guidance, making the review less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that all linear convergence rates *rely* on Theorem 8. This indicates an explicit action the authors should take: identify the theorem and understand its role in their analysis. However, the reviewer does not provide specific guidance on *how* to use Theorem 8 or what aspects of their work it addresses, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'Theorem 8' but does not specify *where* in the paper this theorem is located or *what specific part* of their work it relates to. The comment is general and does not pinpoint a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer states that 'Theorem 8 which is burried at the end of the appendix and which proof is not clear enough'. This comment itself is a claim that requires justification. The reviewer provides some justification by stating the theorem is 'buried' and the 'proof is not clear enough', but they do not provide specific examples or references to external works to support this claim about the theorem's location or lack of clarity.", "helpfulness_rationale": "The reviewer points out a potential issue (clarity of Theorem 8) that could hinder the authors' understanding and implementation of their analysis. While the reviewer suggests moving Theorem 8 to the main body, this is a suggestion and not a concrete action the authors can take based on the current review point alone. The reviewer does not provide specific steps the authors can follow to address the lack of clarity or location information."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides specific details about the Walkman algorithm's relation to ADMM and critiques the paper's generalization about SGD. It also points out a lack of clarity in Section 3 regarding a comparison between SGDbased algorithms and ADMM. These are direct and actionable criticisms.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Walkman algorithm (Mao et al., 2020)' and details its relation to ADMM. In Section 3, while the pronoun 'it' makes the reference less explicit, the context strongly suggests 'SGDbased Algorithm 1'. The criticism of SGD is also tied to the mentioned algorithm. While the exact algorithm isn't named in the general statement, the context makes it clear.", "verifiability_rationale": "The first part of the review point provides specific information about Walkman's relation to ADMM and argues against a general statement about SGD. This information can be verified. The second part points out a lack of clarity in Section 3, which is a valid observation but doesn't present a claim that can be verified or falsified.", "helpfulness_rationale": "The review point directly identifies issues in the related work section (incorrect generalization about SGD) and highlights a lack of clarity in Section 3. These are actionable and provide valuable feedback to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the limitation of the theoretical result regarding the Gaussian assumption and provides a clear suggestion to not use this assumption. It also implies a comparison to existing rates, which can be inferred as a concrete action. The action is explicit and the comparison is implied, making it 5.", "grounding_specificity_rationale": "The review point explicitly refers to the 'main (and only) theoretical result' and mentions specific elements of that result, such as 'features and noise are Gaussian'. It also refers to 'previous algorithms' and 'rates achieved by their procedure'. This indicates a strong grounding as the reviewer can easily identify the specific part of the paper being addressed. The comparison to existing rates further specifies the area of concern within the result.", "verifiability_rationale": "The review point contains a claim about the limitations of the theoretical result regarding the Gaussian assumption. It also implicitly suggests that this is a strong requirement and implies a need to compare the rates. The claim about the Gaussian assumption can be verified by examining the stated assumptions of the theoretical result. The suggestion to compare rates can be verified by looking at the derived utility guarantees and the existing literature on similar problems. The claim is supported by logical reasoning and common knowledge about the importance of assumptions in theoretical analysis.", "helpfulness_rationale": "The review point is 5 as it directly points out a limitation of a key theoretical result and provides a concrete suggestion for improvement (not using the Gaussian assumption). It also highlights a gap in the comparison to existing work, which is a valuable piece of feedback. The suggestions are clear and actionable, providing the authors with a direction for future work and a comparison to related research."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment suggests a comparison with a prior work, which can be seen as an implicit action to help the authors understand the context of their extension. However, it doesn't explicitly state how to perform this comparison, making it somewhat vague on the action to be taken.", "grounding_specificity_rationale": "The comment explicitly mentions 'Schiratti et al. (2015)' and 'simulated data', which grounds the reference to a specific paper and the type of data to be used. It also implicitly suggests that this comparison is relevant, indicating an understanding of the context. While it doesn't explicitly state *how* to compare, it clearly identifies the target of the comparison.", "verifiability_rationale": "The comment identifies a potential improvement or area for validation by comparing with a prior work. While it doesn't provide explicit justification for *why* this comparison is important, the suggestion itself acts as a form of justification, indicating that the authors believe this comparison would be beneficial. It lacks external references or detailed reasoning about the specific aspects of the extension that need to be validated.", "helpfulness_rationale": "The comment suggests a comparison with a relevant prior work, which is generally a valuable piece of feedback for authors. It points towards a specific area for further analysis and validation, which could help the authors better understand their extension and its relationship to existing methods. While it doesn't provide explicit instructions on how to perform the comparison, it offers a clear direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of the experimental setup (only two baselines) and provides concrete suggestions for improvement (adding more baselines 1, 2, 3). This indicates both explicit and concrete aspects of the review.", "grounding_specificity_rationale": "The reviewer identifies the specific area of the paper needing improvement (the 'experimental section') and provides specific examples of what should be added (1, 2, 3). This demonstrates both grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the experimental setup and provides a logical argument for why adding more baselines is beneficial. While they don't provide specific references in this point, the underlying principle is generally accepted.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the experimental section and offers concrete suggestions to improve it. This is a valuable piece of feedback for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer's point is a critique of the evaluation methodology, specifically the use of the development set for both hyperparameter tuning and model selection. While this is a valid concern in machine learning, the reviewer does not propose a specific action or improvement within the paper itself. They are suggesting a change in the experimental setup, not an actionable item within the paper's content. Therefore, the point lacks explicit and concrete actions that the authors should take.", "grounding_specificity_rationale": "The reviewer criticizes the evaluation process, stating that the authors do not know what they should do after reading the comment. They are pointing out a lack of clarity in the evaluation methodology. While the criticism is valid, the reviewer does not specify *which* aspects of the evaluation are unclear. They are broadly criticizing the use of the development set for tuning and selection, but not pinpointing a specific section or detail within the paper that is missing. Therefore, the grounding is weak as the authors can infer the problem but not the specifics of the issue.", "verifiability_rationale": "The reviewer makes a claim: 'I strongly suggest that the paper should present the average results on the test set with clearly defined error bars under different random seeds.' This claim is based on a standard practice in machine learning. While the reviewer doesn't provide a detailed justification for *why* this is a problem in their specific case, the suggestion itself is a verifiable statement. The claim is supported by the common practice of using the test set for final evaluation and reporting performance with error bars. Therefore, the claim is verifiable, but the reviewer doesn't provide a detailed reasoning or examples to fully support it.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement: 'I strongly suggest that the paper should present the average results on the test set with clearly defined error bars under different random seeds.' This suggestion directly addresses a potential weakness in the current evaluation methodology. While the reviewer doesn't provide a detailed explanation of *why* this is necessary or *how* to implement it, the suggestion is a concrete and actionable piece of feedback for the authors. It points them towards a specific area for improvement in their experimental setup. Therefore, the point is helpful in guiding the authors towards a better evaluation process."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification on how topicword parameters were obtained and the size of the AG news dataset. While the paper mentions 'topicword parameters' and uses the 'AG News dataset', it does not explicitly state the method used to obtain the topicword parameters or the vocabulary size of the dataset. The questions are implicit, requiring the reader to infer the missing information. The action is present (identifying missing information), but it is not explicitly stated, making it implicit.", "grounding_specificity_rationale": "The review point asks for clarification on how topicword parameters were obtained and the size of the AG news dataset. The paper mentions 'topicword parameters' and uses the 'AG News dataset', which can be considered a form of grounding. However, it does not explicitly state the section of the paper where this information is located or provide the specific details requested (parameter estimation method and vocabulary size). The information is present but not explicitly identified, making the grounding somewhat weak.", "verifiability_rationale": "The review point does not contain a claim. It is a question seeking information. Therefore, verifiability does not apply to this review point.", "helpfulness_rationale": "The review point raises valid questions about the data generation process and dataset characteristics. While the information is not explicitly stated in the paper, it is not necessarily unhelpful. The reviewer is pointing out missing information that would be beneficial for the authors to understand the experimental setup and potentially reproduce the results. The lack of explicit information makes it less helpful than a review that directly criticizes a flaw in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states \"it only compares against 3 basic alternatives and ignores some other NAS (e.g. supernet/oneshot approaches, etc...).\" This is an explicit statement of a weakness, identifying the lack of comparison with specific NAS methods. While the reviewer doesn't specify *how* these alternatives should be included, the action is clear: the authors should compare against these other NAS approaches. The reviewer also mentions \"basic alternatives\", which, while not explicitly defined, implies a lack of depth or sophistication in the comparisons.", "grounding_specificity_rationale": "The reviewer mentions \"other NAS (e.g. supernet/oneshot approaches, etc...).\" This shows the reviewer is providing specific examples of NAS methods that are missing. However, the reviewer does not explicitly state which part of the BRPNAS analysis is lacking these comparisons. The grounding is weak because the reviewer is mentioning the *type* of alternative NAS methods but not pinpointing a specific aspect of the BRPNAS analysis that needs improvement.", "verifiability_rationale": "The reviewer states \"it only compares against 3 basic alternatives and ignores some other NAS (e.g. supernet/oneshot approaches, etc...).\" This is a claim that can be verified by examining the BRPNAS analysis. However, the reviewer does not provide any logical reasoning, external references, or examples to *justify* why these are \"basic alternatives\" or why they are \"ignored\". The claim is stated, but the verification is lacking.", "helpfulness_rationale": "The reviewer states \"it only compares against 3 basic alternatives and ignores some other NAS (e.g. supernet/oneshot approaches, etc...).\" This is a clear statement identifying a weakness in the BRPNAS analysis. The reviewer also implicitly suggests that the authors should include these missing comparisons, providing a direction for improvement. While the suggestion is somewhat general, it directly points towards a concrete action the authors can take."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X (X)", "helpfulness_label": "None", "actionability_rationale": "The reviewer's point is subjective and offers a general aesthetic critique of the paper's presentation, specifically mentioning the zeroshot version and connection to density estimation as potentially distracting. While they identify a *area* of concern (presentation), they do not explicitly state a concrete action the authors should take to address this. The criticism is about the *how* rather than the *what*.", "grounding_specificity_rationale": "The reviewer mentions 'the zeroshot version' and 'density estimation' but does not explicitly identify a specific part of the paper (e.g., a section, table, figure, or unique aspect) that is being criticized. The reference to these concepts is general and does not pinpoint a specific element of the paper being addressed. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment refers to.", "verifiability_rationale": "The review point is a subjective statement expressing an opinion about the paper's presentation. It does not present a claim that can be verified through logical reasoning, common knowledge, or external references. The reviewer is stating what they perceive is distracting, not a factual assertion about the paper's content. Therefore, there is no verifiable claim in this review point.", "helpfulness_rationale": "The review point is not actionable and is a subjective opinion about the paper's presentation. Since it does not provide specific, concrete feedback that the authors can use to improve their draft, it is not particularly helpful. The lack of a clear action for the authors to take diminishes its potential usefulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that 'details around the filtering process used to create the Arabic climate change QA dataset are lacking.' This indicates an explicit action that needs to be taken \u2013 to provide more information on the filtering process. However, the action itself is vague as it doesn't specify what exactly is missing or how it should be described. Therefore, while the reviewer points to a need for information, the specific action is not clearly defined.", "grounding_specificity_rationale": "The review point explicitly mentions 'filtering process' and 'Arabic climate change QA dataset.' This provides a clear grounding of the comment to specific aspects of the paper. However, it does not specify a unique section, table, figure, or element within the dataset that needs to be addressed. The grounding is present, but it is not fully explicit.", "verifiability_rationale": "The review point contains a claim: 'More information on the translation and filtering methodology is needed.' This claim is 3 because it points to a lack of detail. However, it lacks specific examples or references to make it 5. The reviewer states a need for more information, implying that the current information is insufficient to assess the dataset quality.", "helpfulness_rationale": "The review point clearly identifies a lack of detail regarding the filtering process and translation methodology as a barrier to assessing the dataset quality. This is a direct and actionable comment for the authors. The reviewer is asking for specific information that is currently missing, which is likely to be helpful for the authors in evaluating their work. The request for more information directly addresses a potential weakness."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states two specific shortcomings: 'lack of attacks with different strength' and 'lack of influence of different thresholds on detection performance.' These are direct actions the authors should take to improve their draft.", "grounding_specificity_rationale": "The reviewer mentions 'attacks with different strength' and 'different thresholds' as specific types of attacks and parameters. While they don't name the exact section or table, they clearly identify the *nature* of the deficiencies, indicating a degree of grounding.", "verifiability_rationale": "The reviewer states the problems ('lack of attacks with different strength' and 'lack of influence of different thresholds on detection performance') without providing any logical reasoning, common knowledge, or external references to support these claims. The verifiability is low as the reasoning is missing.", "helpfulness_rationale": "The reviewer points out specific areas where the experiment could be improved ('lack of attacks with different strength' and 'lack of influence of different thresholds on detection performance'). However, they do not offer concrete suggestions or explain the consequences of these deficiencies for the authors. The helpfulness is limited as the reviewer identifies problems without providing solutions."}
{"actionability_label": "4", "grounding_specificity_label": "Mostly Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need to 'train a discriminator on generations from the learned model' to confirm the model's ability to reduce exposure bias. This is a direct action. While the reviewer also mentions 'in a way similar to Figure 1' and the difference from 'Figure 4', these are clarifications of the *method* and a *potential issue*, rather than implicit actions that need to be inferred. The core action is clear: train a discriminator.", "grounding_specificity_rationale": "The reviewer explicitly states the need to 'train a discriminator on generations from the learned model'. This directly targets the output of the learned model, making it grounded. The reviewer also mentions 'Figure 1', which likely refers to a specific visualization or analysis of the generated text, further grounding the action in a specific aspect of the output. The comparison to 'Figure 4' highlights a specific aspect of the evaluation, indicating a focus on a particular detail of the generated text.", "verifiability_rationale": "The reviewer makes a claim that 'training a discriminator on generations from the learned model is needed to confirm if it is the case, in a way similar to Figure 1'. The reviewer also provides a justification by stating that 'it is different from Figure 4, since during training the discriminator is coadapting with the generator, and it might get stuck at a local optimum'. This justification provides a logical reasoning for the claim, making it verifiable.", "helpfulness_rationale": "The reviewer suggests a specific method ('training a discriminator') to validate the model's claim. This directly addresses the core claim of the paper. While the suggestion is present, the reviewer could have provided more specific details about the discriminator's architecture, the training process, and the evaluation metrics. The mention of 'Figure 4' highlights a potential issue, suggesting an awareness of a specific challenge, which adds some depth to the helpfulness."}
{"actionability_label": "Low", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point does not explicitly state what the authors should do. The reviewer is asking for information about the impact of specific experimental choices, which requires the authors to interpret and analyze the results themselves. There is an implicit suggestion that understanding this impact is important, but the point does not demand a specific action.", "grounding_specificity_rationale": "The reviewer mentions 'it' in relation to 'L170', suggesting they have located something in the paper. However, they do not explicitly identify the specific part of the paper being addressed (e.g., a section, table, or figure). The reference is weak and does not pinpoint the exact location. The comment also does not specify what is meant by 'performance difference'.", "verifiability_rationale": "The review point does not contain a claim or assertion that needs verification. It is a question seeking information, not a statement that requires logical reasoning, common knowledge, or external references to be considered valid.", "helpfulness_rationale": "The review point is not inherently harmful to the authors. However, it does not provide direct, actionable feedback on how to improve their draft. It asks for information that could be helpful for understanding the experimental setup, but it does not identify a weakness or suggest a concrete improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment states that the algorithm should be presented and described in detail. While this is an explicit instruction, it lacks specific guidance on *how* to achieve this. The reviewer doesn't specify which aspects of the algorithm need more detail or what the desired format should be. Therefore, it is partially actionable as it points out a need for more detail, but lacks concrete steps on how to implement it.", "grounding_specificity_rationale": "The comment 'The Algorithm should be presented and described in detail' is a general suggestion and does not specify which part of the paper the algorithm is located in. There is no mention of a specific section, table, figure, or unique element of the paper. Therefore, the comment does not ground the feedback in a specific part of the paper, making it 1.", "verifiability_rationale": "The review point 'The Algorithm should be presented and described in detail' is a suggestion or recommendation. It does not contain a claim that requires verification or justification. There are no explicit opinions, judgments, or suggestions about what is incorrect or missing. Therefore, it does not meet the criteria for verifiability, which focuses on supporting claims.", "helpfulness_rationale": "The review point suggests providing more detail about the algorithm. While this can be helpful for understanding, it is a general suggestion and does not directly address a specific weakness or issue in the authors' work. It lacks specific direction on how to improve the algorithm's description. Therefore, it is 3 as it points out a potential area for improvement, but lacks specific guidance on how to achieve it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'it would have been interesting to see a runtime comparison at test time.' This action is concrete, telling the authors exactly what they should do and where to perform the comparison.", "grounding_specificity_rationale": "The review point refers to 'the paper mentions the possibility to use Chebyshev polynomials to achieve a speedup.' While it doesn't explicitly name a section or table, the reference to a specific idea within the paper implies a degree of grounding. The authors can infer the relevant part of the paper where this speedup potential is discussed. The suggestion 'runtime comparison at test time' is also specific, indicating a clear area for improvement.", "verifiability_rationale": "The review point contains a claim: 'it would have been interesting to see a runtime comparison at test time.' This claim is 3 because the authors can infer the relevance of a runtime comparison based on the mention of Chebyshev polynomials as a potential speedup. While it doesn't provide a definitive proof of benefit, it points to a logical next step to explore that potential.", "helpfulness_rationale": "The review point is 5. It directly suggests a concrete and actionable improvement: conducting a runtime comparison at test time. This encourages the authors to perform a specific experiment and analyze the results, directly addressing the potential speedup mentioned in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The reviewer explicitly states that the proposed method 'seems only works for digit or text images'. This is an explicit statement of a limitation, indicating that the action the method can take is restricted to these specific types of images. The reviewer is directly identifying a constraint on the applicability of the method, making the review point actionable in identifying a limitation.", "grounding_specificity_rationale": "The reviewer's comment, 'The proposed method seems only works for digit or text images, such as MNIST and SVHN. Can it be used on natural images, such as CIFAR10...', does not explicitly and accurately identify a specific part of the paper (e.g., a section, table, or figure). While the reviewer implies a concern about the method's applicability to different types of images, they don't point to a specific element within the paper that the method is intended for. Therefore, while the reviewer is pointing out a limitation, they are not precisely identifying the 'where' of the issue. The specificity of the comment is about the *type* of data, not a specific element within the paper. Thus, it can be considered weakly grounded.", "verifiability_rationale": "The reviewer makes a clear claim: 'The proposed method seems only works for digit or text images...'. This claim is verifiable based on the information provided. The reviewer is stating their understanding or observation about the method's limitations. The reasoning is direct and doesn't require external references to be considered valid. The claim is about the scope of the method, which can be assessed by examining the method's description or implementation details (if available). Therefore, the claim is verifiable.", "helpfulness_rationale": "The reviewer's comment, 'The proposed method seems only works for digit or text images, such as MNIST and SVHN. Can it be used on natural images, such as CIFAR10...', is a question directed at the authors. While it identifies a limitation, it doesn't offer a constructive suggestion or actionable advice on how to adapt the method or address this limitation. The reviewer is pointing out a boundary rather than proposing a solution or improvement. Therefore, while the review points out a limitation, it doesn't actively help the authors improve their draft. It's more of a *detection* of a problem than a *helpful* suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer states the *problem* ('prompts are not wellorganized') and provides *specific references* ('Table 6, 7'). However, the reviewer does not explicitly state *how* the organization is lacking (e.g., lack of clear headings, separation of related prompts). The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 6, 7' by name, indicating a strong ability to identify the specific part of the paper being addressed. However, the reviewer does not specify *what* is wrong with the organization of these tables (e.g., lack of clear separation, unclear instructions). The issue is implied but not explicitly stated.", "verifiability_rationale": "The reviewer makes a claim ('prompts are not wellorganized') and provides supporting information by describing the issue ('all sentences squeeze together'). While they do not cite external references, the descriptions themselves serve as implicit support for the claim.", "helpfulness_rationale": "The reviewer identifies a potential issue ('prompts are not wellorganized') and points to the formatting of the text ('all sentences squeeze together'). However, the reviewer does not explicitly state the *consequences* of this disorganization for the authors or suggest *specific ways to improve* the organization. The feedback is present but lacks concrete action."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the figures are 'not clear' and provides a specific example of confusion with the subfigures in Figure 2. They also identify the missing modules (CMAF, L_BT, VoLTA). This indicates that the authors should be able to directly identify modifications they should apply to their draft by understanding the specific issues with the figures.", "grounding_specificity_rationale": "The reviewer specifically mentions 'figure 2' and the 'relation of 3 subfigures' and the 'modules CMAF, L_BT, VoLTA'. This demonstrates that the authors can identify the specific part of the paper being addressed, making the grounding fully grounded. The reviewer also specifies what needs to be addressed in this part (clarity of subfigures and labels), making the specificity high.", "verifiability_rationale": "The reviewer states that the figures are 'not clear' but does not provide any specific evidence or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the claim that the figures are unclear. The reviewer claims the figures are unclear, but doesn't explain *why* or provide *examples* of what makes them unclear.", "helpfulness_rationale": "The reviewer provides a clear description of the issue (figures are unclear) and points to specific elements within the figure that are missing or confusing (CMAF, L_BT, VoLTA). This directly helps the authors identify areas for improvement. The reviewer's statement is actionable and specific, providing concrete feedback that the authors can readily use."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'While FFNs are omitted because a linear decomposition cannot be obtained' and suggests a solution: 'maybe a line or two should be added that there exists no solution for this, and it is an open (hard) problem.' This provides a clear direction for the authors to improve their draft.", "grounding_specificity_rationale": "The reviewer refers to 'FFNs' and 'linear decomposition,' which are specific terms used in the paper. They also mention 'as mentioned in the paper,' indicating they have located this information. The reviewer also suggests a specific type of solution ('approximation'), making the grounding quite specific.", "verifiability_rationale": "The reviewer points out a factual omission ('FFNs are omitted') and provides a reason ('a linear decomposition cannot be obtained'). While they suggest further research ('is there existing work that offers a way around'), the core point about the omission and the reason for it are verifiable based on the paper's content. The suggestion for further research could be seen as a recommendation for the authors to explore, which isn't directly verifiable but is a consequence of the identified issue.", "helpfulness_rationale": "The reviewer directly addresses a specific issue related to the clarity of the paper's limitations regarding FFNs. They provide a concrete suggestion for improvement ('maybe a line or two should be added') which is directly actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies 'some questionable design choices' and mentions 'perplexity is used as a measure of the model retaining semantic information after finetuning'. While this points to a potential issue, the reviewer does not explicitly state what specific action needs to be taken or how the design choice should be altered. The implications are about 'catastrophic forgetting' and 'domain drift', but the reviewer doesn't provide concrete steps to address these. The action is implied but not explicitly stated, making it partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'perplexity' and its relation to 'semantic information retention', 'catastrophic forgetting', and 'domain drift'. However, they do not explicitly and precisely identify 'which specific aspect' of perplexity or the 'entire process' of finetuning is potentially flawed. The references are more conceptual than pointing to a specific, identifiable part of the model or process. The grounding is present but not fully precise, making it 3.", "verifiability_rationale": "The reviewer presents a claim: 'Some questionable design choices. Perplexity is used as a measure of the model retaining semantic information after finetuning, and while that does relate to the original task, there are also aspects of domain drift which are possible and separate from catastrophic forgetting. How are such factors controlled?'. The reviewer mentions perplexity and its connection to semantic information, and they mention domain drift as a separate issue. However, they do not provide specific evidence or references to support their assertion about the 'questionable design choice' or how these factors are controlled. The reasoning is more speculative than verifiable.", "helpfulness_rationale": "The reviewer raises a valid concern about the use of perplexity as a metric and points out the potential for 'domain drift' as a separate issue from 'catastrophic forgetting'. This highlights a potential limitation in the evaluation process. However, the reviewer does not offer specific, actionable suggestions or propose concrete solutions to address these issues. The point is relevant but lacks the depth and specificity needed to be fully helpful. The helpfulness is moderate as it identifies a problem but doesn't provide a clear path forward."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks two questions: 'How does the number of images impact the model performance?' and 'Do more training images make the performance worse or better?'. While the second question is phrased as a claim, the intent is to understand the relationship between data quantity and performance. The reviewer is seeking direct action, specifically how the number of images affects performance. The phrasing is direct and explicit about the desired outcome.", "grounding_specificity_rationale": "The reviewer mentions 'the cluster structure is defined by the identity' in the context of the BYOL model. This provides a clear and specific reference point for discussing the model's components. The grounding is explicit and literal, directly identifying a specific aspect of the model. The specificity is moderate as the reviewer doesn't delve into the details of how the identity is implemented or its impact, but the reference is clear.", "verifiability_rationale": "The review point poses a question: 'Do more training images make the performance worse or better?'. This is framed as a claim, but the review point itself does not provide any evidence, reasoning, or references to support this claim. The verifiability is based on the expectation that the reviewer has encountered this question in the context of BYOL and can infer or recall relevant information. Without external context or evidence within the review point itself, the verifiability is low.", "helpfulness_rationale": "The review point raises a relevant question about the impact of a key parameter (number of images) on the performance of a core component (BYOL). This is generally helpful for understanding the behavior and potential limitations of the model. However, the question is broad and lacks specific details about which performance metric is being considered. The helpfulness is moderate as it points to a relevant area for investigation but lacks specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the reasoning behind the method's effectiveness, particularly regarding the L_pixel component, is unclear. While this implies an implicit action (the authors should understand why it works), the lack of specific guidance on *how* it works makes it vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'L_pixel' component, indicating a clear identification of a specific part of the paper. They also ask about its effectiveness, specifying what needs to be addressed within that component. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer states that the reasoning behind the method's effectiveness, particularly regarding the L_pixel component, is unclear. This statement itself is a claim that requires justification. However, the reviewer does not provide any evidence or reasoning to support their claim about the unclarity of the reasoning. Therefore, it is 1 based on the information given.", "helpfulness_rationale": "The reviewer provides a clear and specific request for clarification regarding the effectiveness of the L_pixel component. This directly addresses a potential weakness in the paper and guides the authors to improve their understanding. While it doesn't offer a solution, it is 5 in identifying areas for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the 'lack of details' in the Related Work section and provides a list of specific methods (longcontext language models, sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods) and their 'limitations'. This is an explicit statement of a problem that needs to be addressed.", "grounding_specificity_rationale": "The reviewer mentions specific methods by name (1, 2, 3, 4, 5, 6, 7) when describing the shortcomings of the Related Work section. While it doesn't pinpoint a specific section, it clearly identifies the type of information that is lacking, grounding the feedback to a specific area of the Related Work.", "verifiability_rationale": "The reviewer makes a claim about the 'lack of details' in the Related Work section and provides specific examples of methods and their limitations. This claim is supported by the logical reasoning and the examples provided, making it verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable feedback on the Related Work section, pointing out its shortcomings and suggesting specific areas for improvement. This feedback is directly aimed at helping the authors enhance their draft."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "Medium", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states the concern about the sufficiency of 44k dialogues and suggests that datasets in the trillions of tokens are needed. This indicates a clear action the authors should take: acquire or create a larger and more diverse training dataset.", "grounding_specificity_rationale": "The reviewer mentions '44k dialogues' and discusses its ability to capture 'a wide range of user traits and personalities across different content topics'. This clearly identifies the specific part of the paper (training data) being addressed. The reviewer also provides specific details about the desired range of traits and personalities. This demonstrates strong grounding as the authors can identify the specific aspect they are concerned about.", "verifiability_rationale": "The reviewer presents a claim about the insufficiency of 44k dialogues, which requires some form of justification. While the reviewer doesn't provide a direct comparison or specific evidence within the review point itself, the subsequent suggestion about the trillions of tokens used for other LLMs provides implicit support. Therefore, it's not '1' or '1 and not specific'. The claim is somewhat supported by general knowledge about LLM training data size, making it 'underspecified' in terms of providing concrete evidence within the review point itself.", "helpfulness_rationale": "The reviewer's point directly addresses a practical limitation in the training data and offers a concrete suggestion for improvement: increasing the dataset size. This is a clear and actionable feedback that directly helps the authors understand their data limitations and what they need to do. The reviewer's statement is a direct criticism and a call for more data, which is actionable for the authors. Therefore, it's considered '5' because it directly addresses a practical limitation and offers a concrete solution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The binary classification label itself doesn't provide any specific action or guidance on how to improve the text. It simply states whether the classification is correct or incorrect, without explaining *why* it's wrong or what kind of error it is. Therefore, it's not actionable in the sense that a more detailed feedback would be.", "grounding_specificity_rationale": "The binary classification label does not specify *which* part of the text or which aspect of the text is being classified. It only indicates whether the classification is correct or incorrect. Therefore, it is 1 in a specific section or detail of the text.", "verifiability_rationale": "The binary classification label, while verifiable in the sense that it's a clear decision, does not provide any justification or explanation for why the classification is correct or incorrect. It lacks the reasoning or references needed to understand the basis of the classification. Therefore, it is 1 in terms of providing insights into the model's decisionmaking process.", "helpfulness_rationale": "The binary classification label is not helpful for authors because it does not provide any insights into *why* the classification is correct or incorrect, nor does it suggest any specific ways to improve the text. It's a simple correctness judgment without any deeper understanding or actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the method is 'not clear if the method is applicable to real and categorical features too.' This is an implicit suggestion that the method has limitations with these feature types. While the reviewer points out a potential area for improvement, they do not explicitly state what steps the authors should take to address this. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer mentions 'real and categorical features' without specifying which part of the paper or method they are referring to. They are not pointing to a specific section, table, or figure. The grounding is weak because the reviewer cannot confidently determine which part of the paper is being addressed. The comment is vague and does not clearly identify the issue.", "verifiability_rationale": "The reviewer states 'not clear if the method is applicable to real and categorical features too.' This is a statement of uncertainty, not a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support this statement. It's a question about the method's applicability, not a verifiable claim.", "helpfulness_rationale": "The reviewer points out a limitation of the method but does not offer any suggestions or ask clarifying questions. While they identify a potential area for improvement, they do not provide any actionable feedback to the authors. The feedback is a statement of a problem without any constructive elements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment is a general statement about the writing needing improvement. It doesn't specify *which* parts are unclear or *how* the writing should be changed. Therefore, it lacks actionable steps for the author.", "grounding_specificity_rationale": "The comment doesn't mention any specific section, table, figure, or unique element of the paper. The phrase 'some points' is vague and doesn't help the author pinpoint the issue. Thus, it's 1.", "verifiability_rationale": "There is X being made. The comment is a suggestion, not a statement of fact that requires verification. Therefore, it's 'X (X)'.", "helpfulness_rationale": "The comment is relevant in that it points out a general weakness (unclear writing). However, it lacks specificity, making it difficult for the author to know exactly what to do. It's more of a broad suggestion than a detailed critique that would be 5."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The suggestion to 'use other metrics' is an explicit instruction on what the authors should do. However, it lacks specific details on which metrics to use and how to apply them, making it somewhat vague.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. It is a general suggestion about evaluation metrics, making the grounding weak. Furthermore, it does not specify what is wrong with the current evaluation methods, making the specificity low.", "verifiability_rationale": "The review point is a suggestion, not a claim. It does not make any assertion or judgment about the paper or the suggested metrics. Therefore, there is X to verify.", "helpfulness_rationale": "The suggestion to use other metrics is relevant and could be helpful for the authors to improve their evaluation of the results. However, it is a general suggestion without specific guidance, making it 3 but not very informative. It does not actively harm the authors by providing misleading information."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests looking at 'LLM evaluation' and points to a specific paper 2. While the reviewer doesn't provide a direct action, they implicitly suggest that the comparison of SynTextBench with other metrics, like MMLU and Big Bench, is a relevant area for improvement. The suggestion to 'see what conditions should one use SynTextBench over other metrics' is a clear indication of a desired action. However, the lack of specific details about the comparison makes it difficult to pinpoint the exact action the authors should take, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'LLM evaluation' and a specific paper 2. While they don't explicitly state the section or table within the paper, the reference to a specific paper is a strong indicator of grounding. The reviewer is referring to a concrete piece of work. However, the reviewer does not specify *which* aspect of LLM evaluation they are referring to, nor does they specify *which* section of paper 2 they are referring to. The request to compare SynTextBench with other metrics is also general and lacks specificity.", "verifiability_rationale": "The reviewer states that 'there has been a large amount of work on LLM evaluation' and that 'it would still be good to see how SynTextBench metric compares to the other metrics proposed in the literature.' This statement is a claim. The reviewer mentions a specific paper 2 as an example of work on LLM evaluation, which provides some grounding and justification for the claim. However, the reviewer does not provide a clear explanation of *why* they think SynTextBench might be better or under what conditions they are considering the comparison. The request is vague and lacks specific reasoning.", "helpfulness_rationale": "The reviewer raises a relevant point about the lack of clarity on when to use SynTextBench over other metrics like MMLU and Big Bench, especially in the context of language generation. This is a valuable observation for researchers in the field. However, the reviewer's suggestion to 'see what conditions should one use SynTextBench over other metrics' is vague and lacks specific details. The lack of concrete suggestions or criteria makes the review less actionable and therefore less helpful."}
{"actionability_label": "High", "grounding_specificity_label": "Full Grounding and Specific", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that the algorithm for construction of coresets is not novel and points to the extension of existing coreset frameworks to the kernelized setting. This provides a clear action for the authors to consider, namely the potential lack of novelty of their algorithm.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'algorithm for construction of coresets' and 'existing coreset frameworks for classical kmeans and (k,z) clusterings'. This provides clear grounding as the reviewer accurately pinpoints the specific parts of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim about the lack of novelty of the algorithm. While the reviewer provides a reason for this claim (the extension of existing frameworks), they do not provide specific evidence or references to support this assertion. The reasoning is present, but lacks concrete backing.", "helpfulness_rationale": "The reviewer points out a potential weakness in the paper's contribution by suggesting that the algorithm for construction of coresets is not novel and that existing frameworks have been extended to the kernelized setting. While this raises a valid concern, the reviewer does not provide specific, actionable feedback on how this lack of novelty should be addressed or how the authors can improve their work based on this feedback. The comment is present but lacks concrete suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment 'Poor writing and annotations are a little hard to follow' identifies a problem but does not specify what needs to be done to improve the writing or annotations. It lacks explicit and concrete actions. The comment is vague and does not provide guidance on how to make the writing or annotations clearer. Therefore, it is 1.", "grounding_specificity_rationale": "The comment 'Poor writing and annotations are a little hard to follow' does not identify a specific part of the paper or annotation that is difficult to follow. It is a general statement about the overall writing and annotations. The comment lacks grounding specificity as it does not point to a particular section, table, figure, or unique element of the paper. Therefore, it is 1.", "verifiability_rationale": "The comment 'Poor writing and annotations are a little hard to follow' does not make a claim or assertion. It is a statement of observation about the writing and annotations. Since there is X, there is no verifiability to evaluate. Therefore, it is X (X).", "helpfulness_rationale": "The comment 'Poor writing and annotations are a little hard to follow' identifies a valid issue but does not provide any specific suggestions or guidance on how to improve the writing or annotations. It is a diagnosis without a prescription. Therefore, it is 1."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that only 8 out of 14 evaluation metrics achieve SOTA performances in Table 2. This is a clear and direct statement of a weakness. The reviewer also points out that under the setting of 'Twitter2017 > Twitter2015', the proposed method achieves the best overall F1, while not achieving the best F1 in all single types. This is an implicit action suggesting the authors should investigate why the overall performance is better despite the lack of improvement in singletype evaluations. While the action is not stated explicitly, the reviewer provides the necessary information to identify the action.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Table 2', '8 of the total 14 evaluation metrics', 'SOTA performances', 'Twitter2017 > Twitter2015', and mentions 'overall F1' and 'best F1 in all single types'. These are all specific references to the paper's content and the results being discussed. The reviewer clearly identifies the specific aspect of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim about the results in Table 2, stating that only 8 out of 14 metrics achieve SOTA. This is a claim that needs verification. The reviewer also makes a claim about the discrepancy in F1 scores, stating that the best overall F1 is achieved while not achieving the best in all single types. This claim also needs verification. The reviewer provides the necessary information to potentially find evidence to support or refute these claims, although they do not provide external references or detailed reasoning beyond the observed numbers.", "helpfulness_rationale": "The review point directly identifies a weakness in the reported results of the authors' work. By pointing out that only a portion of the evaluation metrics show SOTA performance, the reviewer highlights a potential issue with the authors' evaluation process or implementation. Furthermore, the reviewer points out a discrepancy in the F1 scores, suggesting that the authors need to investigate why the overall performance is better despite the lack of improvement in singletype evaluations. This encourages the authors to delve deeper into their results and potentially identify areas for improvement. The reviewer's questions also prompt the authors to consider the validity of their evaluation methodology and its impact on the reported metrics."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about a specific methodological choice, which can be interpreted as an implicit request for justification. While they don't explicitly state 'How do you decide to only consider ECG segments with one label assigned?', the implication is clear. Therefore, it's not entirely 1, but it's also not explicitly stated. The reviewer can infer the reason for this filtering, making it 3.", "grounding_specificity_rationale": "The reviewer directly asks a question about a specific aspect of the methodology: 'Why do you only consider ECG segments with one label assigned to them?'. They are referencing the 'one label assigned' criterion, indicating a clear grounding in the methodological details. The question is also specific about the *reason* behind this selection, making it highly specific. Therefore, it's 5.", "verifiability_rationale": "The reviewer expresses an expectation about the difficulty of including all reports compared to those with one label assigned. While this is a reasonable assumption, the paper itself doesn't explicitly state *why* including all reports would be harder. The reviewer is making an inference based on their understanding of the task. Therefore, it's not 1, but it's also not fully justified by evidence within the paper. The claim is based on a reasonable assumption but lacks direct evidence from the paper being reviewed, making it partially verifiable.", "helpfulness_rationale": "The reviewer is pointing out a potential issue with the methodology by questioning the filtering of ECG segments. While they are asking a question about a specific aspect, they are not actively proposing a solution or improvement to the authors. They are more of a critique of the methodological choice. Therefore, it's not unhelpful, but it doesn't actively guide the authors towards a better approach. The question highlights a potential problem, but doesn't offer a concrete next step for the authors, making it 3. It points to a potential flaw in the methodology, but doesn't actively propose a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The statement is somewhat explicit in identifying the proposed solution as an 'incremental step' considering Guzman's work and mentioning 'minor suggestions'. However, it lacks specific details on how the solution is incremental or what the suggestions entail. The actions are implied rather than explicitly stated and detailed.", "grounding_specificity_rationale": "The comment refers to 'the proposed solution' and 'Guzman et. al.' generally. It doesn't explicitly point to a specific section, table, figure, or unique aspect of Guzman's work. The specificity of the referenced element is unclear. The comment also doesn't specify what is meant by 'incremental step' or 'minor suggestions'.", "verifiability_rationale": "The comment is an evaluative statement about the nature of the proposed solution, stating it's an 'incremental step' and mentioning 'minor suggestions'. It doesn't present a claim that requires verification or support. There are no logical reasoning, common knowledge, or external references provided within the comment itself.", "helpfulness_rationale": "The comment is evaluative and doesn't provide specific actionable feedback or insights that would empower the authors to improve their draft. It's more of a comment on the *process* of proposing solutions than a direct critique or suggestion for improvement. There are no concrete steps or guidance provided for the authors to follow."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the absence of a 'thorough exploration' of 'scalability bounds,' 'memory requirements,' and 'computational complexity.' These are direct and specific criticisms of the paper's content, making the action clear. While the point doesn't suggest *how* to explore these aspects, it clearly identifies the need for such an exploration, making it actionable in terms of identifying a missing element and suggesting a direction for improvement.", "grounding_specificity_rationale": "The review point explicitly mentions 'scalability bounds' as the area lacking discussion. While it doesn't point to a specific section, table, or figure, the reference to 'scalability bounds' itself can be considered a clear indication of the paper section being addressed. Furthermore, the review point clearly specifies the issues within this area: 'memory requirements' and 'computational complexity.' This makes the grounding 'Full' and the specificity 'Highly Specific'.", "verifiability_rationale": "The review point implies that the lack of discussion on 'scalability bounds,' 'memory requirements,' and 'computational complexity' constitutes a weakness in the paper. While it doesn't provide a definitive statement of opinion, the conclusion drawn about the paper's state is generally accepted within the field of federated learning. The limitations of algorithms, especially concerning scalability and resource requirements, are common knowledge. Although the point doesn't provide specific citations, the general understanding is widely held, making it '3'.", "helpfulness_rationale": "The review point is helpful because it directly identifies a clear weakness in the paper \u2013 the limited discussion of scalability aspects. It provides a specific area for improvement by suggesting a 'thorough exploration' of 'scalability bounds,' 'memory requirements,' and 'computational complexity.' While it doesn't offer a solution, it clearly guides the authors on what needs to be addressed, making it '4'."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The statement explicitly states a limitation of LLMs in handling problems with more than 7 variables, which is a direct and clear action. The reviewer directly points out a specific issue with LLM capabilities.", "grounding_specificity_rationale": "The statement is about a general limitation of LLMs, not a specific part of a paper. There is no explicit mention of a section, table, figure, or unique element of the paper. The grounding is weak because the authors cannot confidently determine which part the comment addresses. The comment specifies what needs to be addressed (LLMs' limitations with variable count), but it doesn't pinpoint a specific part of the paper being discussed.", "verifiability_rationale": "The statement contains a claim about LLMs' limitations. It does not provide specific evidence or references to support this claim within the review itself. The reasoning is that it's a forwardlooking statement about LLM capabilities, and without external references, it's not 5 within the given context.", "helpfulness_rationale": "The statement identifies a potential issue with the types of problems LLMs can handle. While it highlights a limitation, it doesn't offer specific advice or actionable steps for the authors on how to address this limitation. It's a critique of the problem space rather than a direct solution or improvement suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point does not explicitly state an action or suggest a change to the paper. It is a critique of the presentation of results.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 2 and 3', clearly identifying the specific part of the paper being addressed.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a statement of observation and suggestion.", "helpfulness_rationale": "The suggestions in the review point directly address the clarity and representation of the results, which can be beneficial for the authors in understanding and interpreting their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a direct question about the mechanism of NodeSort and its impact. While they are asking for clarification, the underlying action is to understand how the base node affects the sorting, which is an explicit request for information about the implementation. The reviewer is also implicitly asking how this affects key nodes and performance, which can be inferred. Therefore, while not explicitly stating an action, the reviewer is prompting for information that would allow them to take action (understand and potentially improve the model).", "grounding_specificity_rationale": "The reviewer uses terms like 'NodeSort,' 'nodes,' 'base node,' and 'key nodes for attention,' suggesting they are familiar with these concepts. However, the *specific section* or *table* where this information is detailed is not explicitly mentioned in the review point. The reviewer is inferring the relevance of these terms based on their understanding of the model. Therefore, the grounding is weak, as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point is a question, not a claim that can be supported or unsupported. The reviewer is asking 'Does this mean...' which is a question about the interpretation of the paper's description. There is no explicit claim being made that requires verification. Therefore, it is not verifiable in the sense of supporting a claim. However, the underlying question is about understanding a mechanism, which *could* be verifiable if the paper provided the necessary details. Since there's X, the closest fit is '1'.", "helpfulness_rationale": "The reviewer is asking a specific question about a technical detail of the model. This is likely to be helpful for the authors who are trying to understand the implementation and potentially improve their own work based on this understanding. The question is about a specific aspect of the model's behavior and its potential impact, making it a relevant and potentially useful piece of feedback. While it's not a direct suggestion, it's a question that, if answered, could significantly improve the authors' understanding and potentially their model's performance."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the diagram, which implies a desire for clarification. While they don't explicitly state 'You should explain this arrow to me,' the act of asking a question about a specific part of the paper or diagram can be considered an implicit action. However, the action is vague, as the reviewer doesn't specify *how* the arrow is supposed to be interpreted or what problem it solves. The lack of explicitness makes it less actionable than a direct instruction.", "grounding_specificity_rationale": "The reviewer explicitly points to the Gaussian space and the latent space in Figure 2 and asks a question directly related to their relationship. They identify the specific parts of the diagram being discussed, demonstrating strong grounding specificity. They are not making an educated guess or leaving it ambiguous which parts they are referring to.", "verifiability_rationale": "The reviewer asks a question about the purpose of the arrow in Figure 2. This constitutes a claim that the diagram element has a specific function (influencing n^(i)). The verifiability of this claim depends on whether the paper adequately explains the diagram's construction and the role of the arrow. If the paper provides a clear and logical explanation of how the arrow represents a causal relationship or information flow, then the claim is verifiable. However, if the explanation is lacking or ambiguous, the claim remains 1 or 2.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific aspect of the paper. While they are not directly criticizing the methodology or suggesting a concrete improvement, their request can be helpful for the authors in understanding the diagram better. This understanding could potentially lead to improvements in future iterations of the work. Therefore, it is 3 in the sense that it addresses a potential area of confusion and promotes a deeper understanding of the method."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that 'AR' stands for 'domain adaptation tasks and algorithms'. This provides a clear and direct action for the authors to take: define 'AR' in the paper. The action is also concrete as the meaning is fully specified.", "grounding_specificity_rationale": "The reviewer explicitly states 'In Table 5', which clearly identifies the location of the undefined abbreviation. This provides strong grounding for the authors to locate the relevant information. The specificity is also high as the reviewer provides the exact meaning of 'AR' as 'domain adaptation tasks and algorithms'.", "verifiability_rationale": "The reviewer makes a claim that the lack of definition for 'AR' is a weakness. This is a verifiable claim as the meaning of 'AR' is generally understood within the field of domain adaptation. The reviewer provides a clear and logical explanation for why defining 'AR' is beneficial.", "helpfulness_rationale": "The reviewer identifies a clear weakness in the paper: the undefined abbreviation 'AR'. The reviewer's suggestion to define 'AR' is a direct and actionable improvement that will help the authors communicate their work more clearly and precisely."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states 'Although using advantage instead of q value is more common in practice,' which points to a specific technical aspect and asks a question about it. This constitutes an explicit action or suggestion, even if it's not a direct instruction on what to do. The reviewer is indicating an area needing further consideration.", "grounding_specificity_rationale": "The reviewer mentions 'advantage' and 'q value' but does not explicitly identify which part of the paper or concept they are referring to. The reference is weak, as the reviewer can only make an educated guess about what these terms relate to. The specificity of the comment is also limited as the connection between these terms and 'analysis' is not clearly explained.", "verifiability_rationale": "The reviewer poses a question: 'I'm wondering if there is other technical consideration for conducting the analysis with advantage instead of q value.' This statement implies a claim that there are other considerations, but it does not provide any evidence or references to support this claim. The claim is subtle and lacks verification.", "helpfulness_rationale": "The review point is a question posed without providing any actionable feedback or guidance. It does not identify a specific weakness or suggest a concrete improvement. The reviewer is simply asking for more information, which is not helpful in the context of providing feedback for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer is pointing out a potential discrepancy or a lack of clarity in the description of the 'Unsupervised Online Adaptation' setting. While the method might be intended to be unsupervised, the description implies the need for annotated data (documents, quires, and labels), which is a characteristic of supervised learning. This makes the action (identifying the issue) implicit rather than explicit. The reviewer is essentially stating an expectation that is not clearly articulated in the description.", "grounding_specificity_rationale": "The reviewer is highlighting a lack of clarity in the grounding of the comment. The terms 'documents,' 'quires,' and 'labels' are mentioned, which could be interpreted as providing some level of grounding. However, the reviewer's core point is about the *supervision* aspect. The paper's description might not clearly distinguish between the *terms* used and the *implied level of supervision*. The comment specifies what the adaptation process uses, but not necessarily the underlying supervision status in a clear and unambiguous way.", "verifiability_rationale": "The verifiability of the reviewer's claim depends on the clarity and completeness of the paper's description of the 'Unsupervised Online Adaptation' setting in Sec 3.1. If the paper explicitly states that this adaptation method does not require annotated data and the reviewer's interpretation of the terms 'documents,' 'quires,' and 'labels' as implying supervision is correct, then the claim is wellverified. However, if the paper's description is ambiguous or could be interpreted as requiring annotations, then the claim is only 2.", "helpfulness_rationale": "The helpfulness of this review point depends on the interpretation of the paper's Sec 3.1. If the paper's description of 'Unsupervised Online Adaptation' is indeed misleading or ambiguous regarding the requirement of annotated data, then this review point is 5 as it points out a crucial misunderstanding. However, if the paper is already clear and the reviewer has misunderstood the distinction between terminology and supervision, the helpfulness is lower. Given the directness of the criticism, it leans towards being helpful if the paper is indeed ambiguous."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that VINS uses different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights to 1. This is an explicit statement of a difference in implementation, which is a concrete action the authors should consider.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. It is a general comment about the experimental setup in Table 1. The authors cannot confidently determine which aspect of the comparison the reviewer is referring to.", "verifiability_rationale": "The claim is that the comparison in Table 1 is unfair due to different sample weights. However, the review point does not provide any justification or evidence for why this difference makes the comparison unfair. There is no logical reasoning, common knowledge, or external references provided to support this claim.", "helpfulness_rationale": "The review point identifies a potential flaw in the experimental setup of the comparison in Table 1. However, it does not offer any specific, actionable suggestions or propose alternative experimental designs to address this issue. It is a critique of the methodology rather than a constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point states: \"The time complexity will be too high if the reply buffer is too large.\" This is a statement of a potential problem, not an actionable suggestion. It identifies a *problem* related to a *component* (reply buffer) but doesn't tell the authors *how* to fix it.", "grounding_specificity_rationale": "The review point refers to \"reply buffer\" without specifying which part of the paper or context this relates to. It also doesn't pinpoint the specific algorithm or component within the PRMRL framework.", "verifiability_rationale": "The review point is a statement of a potential problem: \"The time complexity will be too high if the reply buffer is too large.\" It doesn't make a definitive claim about *why* this will happen or *how* to solve it. It's more of an observation.", "helpfulness_rationale": "The review point identifies a potential performance bottleneck (time complexity) related to the reply buffer. While it highlights a problem, it doesn't offer any specific solutions or directions for improvement. It's a symptom, not a cure."}
{"actionability_label": "5", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point suggests 'display the performance of accelerating SGMs by involving some other baselines'. This is an explicit action that the authors should take. The suggestion is also concrete, specifying 'some other baselines' and providing examples of what those baselines could be ('optimizing the discretization schedule or by modifying the original SGM formulation 16, 15, 23, 36, 31, 37, 20, 10, 25, 35, 45'). This provides clear guidance on how to improve the evaluation.", "grounding_specificity_rationale": "The review point does not explicitly refer to any specific part of the paper (e.g., a section, table, or figure) when making its suggestion. While it mentions 'performance of accelerating SGMs' and 'baselines', it does not specify *where* in the paper these should be evaluated or compared. The grounding is weak because the authors are not told to look at a specific element.", "verifiability_rationale": "The review point makes a claim that 'It is better for authors to display the performance of accelerating SGMs by involving some other baselines'. This is a claim that the authors should do. The suggestion provides specific examples of *how* to do this ('optimizing the discretization schedule or by modifying the original SGM formulation 16, 15, 23, 36, 31, 37, 20, 10, 25, 35, 45') and suggests a comparison against existing methods. This provides sufficient evidence and justification for the suggestion, making it verifiable.", "helpfulness_rationale": "The review point suggests 'display the performance of accelerating SGMs by involving some other baselines'. This is a helpful suggestion because it provides a concrete way for the authors to improve their evaluation. By comparing against other baselines, the authors can gain a more comprehensive understanding of the performance of their SGM and identify potential areas for improvement. While it doesn't pinpoint a specific weakness, it offers a valid direction for enhancing the evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests improvements but lacks specific instructions on how to implement them, making it 3 but not fully so. While it implies adding a conclusion and summary, it doesn't specify where, what format, or what to include.", "grounding_specificity_rationale": "The review point refers to the entire paper without specifying a particular section or element, making it 1. It doesn't identify a specific part of the paper being addressed.", "verifiability_rationale": "The review point is a suggestion, not a claim that requires verification. It doesn't present an opinion or judgment that needs supporting evidence.", "helpfulness_rationale": "The suggestion to add a conclusion and summary is relevant but lacks specific details, making it 3 but not fully so. It doesn't specify where the conclusion should be, what format it should have, or what aspects of the contributions to summarize."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks 'how to explain that the data distribution illustrated in Figure 1 is inseparable from the network model?'. This is a direct question, making it explicit. However, the reviewer does not provide a concrete action or suggestion on how to approach this explanation. The action is 'to understand the explanation,' which is somewhat vague. It's not concrete in the sense of 'what to do' but rather a request for clarification.", "grounding_specificity_rationale": "The reviewer refers to 'the data distribution illustrated in Figure 1' and 'the network model'. This clearly identifies specific parts of the paper being addressed. The references are literal and specific, indicating strong grounding. The comment also specifies what needs to be explained \u2013 the relationship between the data distribution and the model's ability to handle nonlinearity in the context of separability.", "verifiability_rationale": "The reviewer does not explicitly state a claim or assertion that requires verification. They are posing a question to seek clarification. Therefore, it falls under the 'X' category of 'X'. There is no evidence to evaluate for verifiability.", "helpfulness_rationale": "The reviewer is asking a question to clarify a point of confusion regarding the relationship between the data distribution, the model's nonlinearity, and the concept of nonseparability. While the question doesn't directly provide actionable steps or solutions, it aims to improve the authors' understanding of a potentially problematic aspect of the experiment. This can be considered helpful as it addresses a potential area of confusion, though it doesn't actively resolve the issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the suggestion: 'the authors can further compare the proposed framework with a method that is designed to defend against multiple attacks'. This is a clear indication of an actionable next step for the authors. The reviewer identifies a specific area for improvement in the evaluation.", "grounding_specificity_rationale": "The reviewer suggests 'a method that is designed to defend against multiple attacks' as a basis for comparison. While the *type* of defense is specific, the reviewer does not identify a *specific* paper or method within that category. Therefore, the grounding is weak as the authors cannot confidently determine the exact part of the paper being addressed. However, the issue (defending against multiple attacks) is clearly specified, making it somewhat specific.", "verifiability_rationale": "The reviewer makes a claim: 'the results would be more meaningful if the authors could present this comparison in their paper'. This is a clear claim. However, the reviewer does not provide specific evidence or reasoning to support why this comparison would be more meaningful. The claim is present, but the verification is lacking. The reasoning is present but lacks concrete examples or references.", "helpfulness_rationale": "The reviewer's suggestion to compare against a defense against multiple attacks is relevant to the paper's goal of defending against malicious perturbations. This suggestion directly addresses a potential limitation in the evaluation and provides a concrete direction for improvement. While it doesn't provide a complete solution, it is a valuable and actionable suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies the presentation of results as 'convoluted' and the 'disregard' of safety violations in the first 1000 episodes. While it points out specific information being missing, it doesn't explicitly state what the authors should do to improve the presentation or address the issue of disregarding safety violations. The actionable aspect is present, but the guidance on how to implement the suggested changes is lacking.", "grounding_specificity_rationale": "The comment criticizes the presentation of results and the handling of safety violations. However, it does not explicitly identify the specific part of the paper being addressed (e.g., the results section, a particular table or figure). The grounding is weak because the authors cannot confidently determine which part the comment refers to.", "verifiability_rationale": "The comment contains a claim that the results are 'convoluted' and that safety violations in the first 1000 episodes were 'disregarded.' However, the reviewer states that the reason for presenting the results in this way is 'unclear.' Without a clear justification or reference for this claim, it is difficult to verify the accuracy or significance of the criticism. The claim is present, but the supporting evidence is lacking.", "helpfulness_rationale": "The comment identifies potential issues with the clarity of the results and the handling of safety violations. While it points out a potential area for improvement, it does not provide specific, actionable steps for the authors to take. The feedback is present, but the guidance on how to address the identified issues is minimal. The comment is not vague or lacking clarity in identifying a problem, but it lacks concrete suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer is asking for a definition of a specific term (\tau_i^l) which is crucial for understanding the 'timewarp function'. This is a direct and explicit request for information. The reviewer clearly identifies the missing information and states their need for clarification. Therefore, this is a 5 request as the authors can directly use the definition to understand the function.", "grounding_specificity_rationale": "The reviewer is asking for a definition of a specific term (\tau_i^l) which is directly related to the 'timewarp function'. The authors can accurately pinpoint the section or concept being addressed by understanding the definition of this term. This request is fully grounded as the reviewer explicitly mentions the importance of this term for understanding the function. The authors can deduce the missing information and understand the specific aspect being addressed.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are simply asking for a definition, which is a statement of fact. There are no logical reasoning, common knowledge, or external references required to understand the need for defining \tau_i^l. Therefore, this comment does not contain a claim and is not verifiable.", "helpfulness_rationale": "The reviewer is asking for a definition of a term (\tau_i^l) that is crucial for understanding the 'timewarp function'. This is directly beneficial to the authors as it will help them grasp a key aspect of their work and potentially improve their understanding or implementation of the function. Therefore, this is a 5 comment for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies the specific instances of writing errors ('informative informative' and 'performance') and points to their locations on specific pages. While the reviewer explicitly states the *what* (the errors), they do not explicitly state the *how* to fix them. The authors would need to infer that 'informative' should be changed to something else and 'performance' needs a title. Therefore, the action is explicitly stated, but the implementation is not.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific pages where the errors are located ('on page 5' and 'on page 1'). This clearly identifies the specific part of the paper being addressed. Furthermore, the reviewer describes the *nature* of the errors ('writing errors,' 'repetitive word,' 'missing title') and provides specific examples of the problematic text ('informative informative,' 'performance'). This clearly specifies what needs to be addressed in that part.", "verifiability_rationale": "The review point makes a claim about the existence of writing errors in the paper. It provides specific examples of these errors ('informative informative' and 'performance'). While it doesn't explicitly recommend a fix, the presence of these errors and their locations serve as verification of the claim. The claim is supported by logical reasoning (the presence of the errors) and examples.", "helpfulness_rationale": "The review point identifies specific writing errors and suggests they are 'lacking in clarity and precision'. While it points out the *what* (the errors and their nature), it does not explicitly tell the authors *how* to fix them. The authors would still need to infer the necessary changes. Therefore, while the review provides valuable information, it lacks explicit guidance on the next steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the difference between the standard sigmoid and the sigmoid used in URNNs regarding the maximum slope. It also points out that Theorem 4.1 is relevant to this difference. While the reviewer doesn't explicitly state an action or how to implement it, the identification of a specific technical detail and its connection to a theorem can be considered an implicit action. However, without further clarification from the authors on how this information is useful, the actionability is somewhat limited.", "grounding_specificity_rationale": "The review point explicitly mentions 'standard sigmoid', 'URNN's sigmoid', 'Theorem 4.1', and the concept of 'maximum slope'. It also mentions the relevance of 'RNN convergence' and 'URNN convergence' to understanding Theorem 4.1. This strong grounding makes it clear which parts of the paper the reviewer is referring to.", "verifiability_rationale": "The review point presents a claim: 'Theorem 4.1: Would be useful to elaborate a bit more in the main text why this holds (intuitively, since the RNN unlike the URNN will converge to the nearest FP).' The reviewer provides a rationale for why this claim is valid: 'intuitively, since the RNN unlike the URNN will converge to the nearest FP)'. This provides a logical reasoning for supporting the claim.", "helpfulness_rationale": "The review point identifies a specific technical detail (the difference in sigmoid and its connection to Theorem 4.1) and suggests a concrete improvement: 'elaborate a bit more in the main text why this holds (intuitively, since the RNN unlike the URNN will converge to the nearest FP)'. This directly addresses a potential area where the authors might need more clarity and provides a suggestion for improvement. The reviewer is directly pointing out a specific point of potential confusion and offering a clear path for the authors to understand it better."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a weakness ('inefficiency') but doesn't specify *how* to improve pairwise matching or provide concrete steps for the authors to take. It suggests the area of improvement (practical application systems) but lacks specific actionable feedback.", "grounding_specificity_rationale": "The comment does not specify which pairwise matching methods are inefficient. It broadly refers to 'such pairwise matching' without identifying a specific part of the paper or method. Therefore, it is 1.", "verifiability_rationale": "The comment contains a claim ('the efficiency of such pairwise matching is very low') but does not provide any evidence, reasoning, or references to support this claim. It lacks logical reasoning, common knowledge, or external references to back up the assertion of low efficiency. Therefore, it is 1.", "helpfulness_rationale": "The comment identifies a clear weakness ('inefficiency') and suggests a broad area for improvement ('practical application systems'). While it points out a problem, it doesn't offer specific, actionable steps or concrete suggestions for how the authors can address this inefficiency. It is more of a reminder than a constructive suggestion to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment criticizes the 'allocation of Figure 1' and suggests making 'edits the main paper space more wisely'. While the comment identifies a specific part of the paper (Figure 1) and suggests an improvement, the action of 'edits the main paper space more wisely' is vague and lacks specific details on how to achieve this. The reviewer points out a weakness and offers a general direction for improvement, but doesn't provide concrete steps or criteria for what constitutes 'more wisely' or how to allocate the space differently. Therefore, while the comment identifies a specific area and suggests an improvement, the lack of concrete actionability makes it 2.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1' and refers to the 'allocation' of space for it. The reviewer uses specific terminology ('Figure 1') to point to a particular element of the paper. This indicates a clear identification of the specific part being addressed. The comment does not rely on general statements or inferences about the paper's layout. The reviewer directly names the element they are commenting on.", "verifiability_rationale": "The comment states 'Minor weaknesses The allocation of Figure 1 is too naive' and 'edits the main paper space more wisely'. The first part is a statement of judgment about the figure's allocation. The second part, 'edits the main paper space more wisely', is vague and lacks specific examples or references. There is X that this allocation is incorrect based on external knowledge or logical reasoning. The criticism is based on the reviewer's perception of the allocation's naivety, but it doesn't provide a clear justification or evidence for why it is naive or what constitutes 'more wisely'. Therefore, the claim is not fully supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review points out a weakness (' allocation of Figure 1 is too naive') and suggests an improvement ('edits the main paper space more wisely'). While the reviewer identifies an area for potential improvement, the suggestion lacks specific details on how to achieve this. The comment is somewhat critical ('naive') but offers a general direction rather than concrete steps. Without specific actionable steps, the feedback is not particularly helpful in guiding the authors on how to make the necessary changes. The reviewer's intent is there, but the lack of clarity and specificity limits its helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states that the planbased method requires manually designing a plan based on the ground truth in advance. This implies an explicit action (designing a plan) that needs to be taken. However, the reviewer also points out that the learned plan methods are not comparable to the methods with predefined plans based on Table 2, suggesting that the proposed method may be difficult to generalize to a new dataset without the ground truth summary. This implies a vague outcome or a lack of concrete guidance on how to handle new datasets without ground truth. Therefore, while an action is mentioned, the specifics of how to implement it are not clear, making it 3 but also somewhat vague.", "grounding_specificity_rationale": "The review point mentions 'ground truth in advance' and 'without the ground truth summary'. This indicates that the reviewer is not explicitly identifying the specific part of the paper being addressed (the 'ground'). The comment focuses on the *need* for ground truth information but doesn't pinpoint where in the paper this information is relevant or how it should be used. The comment also clearly specifies what needs to be addressed (the manual design of the plan), making it somewhat specific within that context, but the lack of clear grounding makes it not fully grounded. Therefore, the grounding is not explicitly stated, making it 3.", "verifiability_rationale": "The review point contains a claim: 'The planbased method requires manually designing a plan based on the ground truth in advance...'. This is a statement of opinion or judgment. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The justification is present (the manual design), but the lack of further explanation or references makes it 3. Therefore, the claim is present but lacks sufficient justification or references, making it 3.", "helpfulness_rationale": "The review point critiques the manual design of plans in planbased methods and their impact on generalizability. While this highlights a potential limitation of the proposed method, it does not offer specific, actionable feedback or suggestions on how to improve the draft in this area. The reviewer points out that the proposed method may be difficult to generalize to a new dataset without the ground truth summary, indicating a lack of clear guidance for improvement. Therefore, the review point identifies a problem but does not provide a clear path forward for the authors to improve their draft based on this feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the action needed: 'needs to be rewritten'. This is a direct instruction for the author to rewrite the first sentence of the abstract.", "grounding_specificity_rationale": "The comment explicitly mentions 'the first sentence of the abstract', providing a clear and precise reference point within the paper.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a suggestion for improvement.", "helpfulness_rationale": "The comment is a clear and direct suggestion to rewrite the first sentence of the abstract. This is a 5 and helpful piece of feedback for the author."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a problem: 'It appears that in nearly all experiments, the results are reported for a single heldout test set.' They also suggest a concrete solution: 'Standard practice in most papers on GPs involves using a number of train/test splits or folds which give a more accurate illustration of the method\u00e2\u0080\u0099s performance.' This indicates a clear understanding of a potential limitation and a direct suggestion for improvement.", "grounding_specificity_rationale": "The reviewer's comment is about the general methodology of reporting results across all experiments. They do not explicitly identify a specific section, table, figure, or unique aspect of the paper that is being addressed. While they imply the issue is with the *Reporting* of results, they don't pinpoint a specific element within the paper being critiqued.", "verifiability_rationale": "The reviewer makes a claim: 'Standard practice in most papers on GPs involves using a number of train/test splits or folds which give a more accurate illustration of the method\u00e2\u0080\u0099s performance.' This claim is supported by the general understanding of best practices in machine learning, particularly in areas where robust evaluation is crucial. While the reviewer doesn't provide specific citations within this review point, the claim is based on common knowledge and widely accepted standards in the field.", "helpfulness_rationale": "The reviewer's comment is relevant to the typical concerns of researchers, especially those working with limited data or focusing on robust model evaluation. They identify a potential limitation in the experimental design (single test set) and suggest a standard improvement (multiple splits/folds). This is a valuable piece of feedback that directly addresses a likely area of concern for the authors and offers a clear direction for potential improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point is a question and a statement of suspicion, lacking a clear, explicit, and concrete action for the authors to take. It's a hypothesis, not a directive.", "grounding_specificity_rationale": "The review refers to the \"method\" generally, without specifying a particular section, table, figure, or unique aspect. The grounding is weak because the authors can't confidently identify the referenced part.", "verifiability_rationale": "The review contains a statement that could be interpreted as a claim (\"One would suspect,\"), but it lacks supporting evidence or logical reasoning to back up this suspicion. It's not definitively a claim that needs verification, but it's also not a purely factual statement.", "helpfulness_rationale": "The review points out a potential issue with the method but doesn't offer any concrete suggestions or actionable steps for the authors to improve it. It's a speculative observation, not a helpful critique."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states 'Adding a method on the top of other methods to improve transferability is good but cannot be considered a significant contribution.' This indicates an explicit action (adding a method) but lacks specific details on how to do this and the limitations of the suggestion. The negative comment about significance makes it not fully actionable.", "grounding_specificity_rationale": "The comment does not specify which method is being referred to or where this method addition would take place. It lacks a clear reference to a specific part of the paper or a unique element. The comment is a general suggestion without pinpointing the exact location or type of method.", "verifiability_rationale": "The comment contains a claim: 'Adding a method on the top of other methods to improve transferability is good but cannot be considered a significant contribution.' This claim is not 5 because the judgment about its significance is subjective and not supported by concrete evidence or logical reasoning within the review point itself.", "helpfulness_rationale": "The review point offers a suggestion (adding a method) but immediately critiques its significance ('cannot be considered a significant contribution'). This creates a potential conflict and reduces the helpfulness of the comment for the authors. While the suggestion itself might be helpful in certain contexts, the immediate negative judgment makes it less so overall."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential weakness in the hGRU architecture but does not explicitly state an action or suggestion for improvement. It simply states that the architecture seems adhoc and not wellmotivated.", "grounding_specificity_rationale": "The comment refers to 'the hGRU architecture' generally, without specifying a particular section, table, or figure of the paper. It does not identify the specific part of the paper being addressed.", "verifiability_rationale": "The comment contains a claim ('the hGRU architecture seems pretty adhoc and not very well motivated') but does not provide any supporting evidence or justification within the review point itself. It is presented as an observation rather than a claim supported by reasoning, common knowledge, or external references.", "helpfulness_rationale": "The comment points out a potential issue with the hGRU architecture, which could be helpful for the authors to consider. However, it does not provide specific, actionable suggestions or guidance on how to address the identified weakness. It is a constructive critique but lacks concrete recommendations for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment points to a specific line in the algorithm (Algorithm 1, Line 8) and asks for clarification, suggesting an actionable point of improvement. However, the action is not explicitly stated, requiring the authors to infer what needs to be done with s_n and s_t.", "grounding_specificity_rationale": "The comment refers to a specific line in the algorithm (Algorithm 1, Line 8), indicating some level of grounding. However, it also asks for clarification on two distinct aspects (asymptotic performance and experimental results), making the grounding less specific than fully specified.", "verifiability_rationale": "The comment asks for clarification and requests for information (asymptotic performance and experimental results) that are likely available to the authors. While not explicitly stating a claim, the request is a form of implied feedback that could be supported by evidence.", "helpfulness_rationale": "The comment raises a specific technical point (potential error in using s_n instead of s_t) and requests information that would be valuable for the authors (asymptotic performance and experimental results). While the specific action isn't stated, the reviewer points to concrete areas for improvement and asks for crucial information, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly identifies the area of confusion regarding the challenges of analyzing Adam under (L0, L1)smoothness and suggests a specific direction for clarification: explaining the differences from Zhang et al.'s work. This is an explicit statement of a problem and a suggestion for a solution, making it actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions the (L0, L1)smoothness condition and Adam, and even suggests comparing it to Zhang et al.'s work. This provides a clear grounding of the comment in the specific technical details of the paper, making it 5.", "verifiability_rationale": "The reviewer is making a claim: 'standard analysis on the (L0, L1)smoothness condition is not sufficient for analyzing Adam.' This claim requires verification by explaining the specific challenges and differences, which can be supported by logical reasoning and references to existing literature, making it verifiable.", "helpfulness_rationale": "The reviewer's request for clarification on a specific technical point (challenges of Adam under (L0, L1)smoothness) is directly aimed at improving the authors' understanding and addressing a potential area of confusion. This is a 5 suggestion for the authors, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point 'force the neural network to memorize them' is somewhat vague. While it suggests an issue with the neural network's behavior, it doesn't explicitly state *what* needs to be done to achieve this memorization or how to implement it. The reviewer also suggests toning down the statement, implying the original statement was too strong and lacked specificity in its action. Therefore, it's not fully actionable as it doesn't provide clear steps for the authors to take. The minor point about the method section being wordy also lacks specific action, making it less actionable.", "grounding_specificity_rationale": "The review point 'force the neural network to memorize them' generally refers to the neural network. While the reviewer later clarifies their understanding to be about a 'critical point,' the initial phrasing doesn't pinpoint a specific section, table, figure, or unique aspect of the neural network being addressed. The minor point about the method section is also general, lacking specific grounding. Therefore, the initial phrasing is weakly grounded, and while the clarification adds specificity, the initial point lacks it.", "verifiability_rationale": "The review point contains a claim: 'I would tone down this statement, in my understanding, the neural network does not memorize an exact \"critical point\" as such in TopoNet 24.' The reviewer provides a justification for their understanding, stating their interpretation of how neural networks operate in the context of TopoNet. This justification, while based on their understanding, could be considered verifiable as it relies on the reviewer's interpretation of external knowledge (TopoNet). However, it doesn't provide a direct citation or evidence within the review point itself to support this claim. Therefore, it's 3 as it relies on the reviewer's interpretation of external knowledge.", "helpfulness_rationale": "The review point is helpful in identifying a potential issue with the neural network's behavior and suggests a way to tone down the statement. The reviewer also points out areas for improvement in the method section and grammar. While the initial phrasing could be more specific, the reviewer provides clear feedback and actionable suggestions for the authors. The suggestions for the method section and grammar are concrete and directly address potential weaknesses. Therefore, it's 4 as it provides clear feedback and actionable suggestions."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the existence of pedestrian detectorbased twostep methods and endtoend methods, which are implicit actions or suggestions that imply limitations of the former. However, it doesn't provide concrete steps on how to implement these suggestions or modify the current draft. The action is implied but not explicitly stated or detailed.", "grounding_specificity_rationale": "The comment discusses the general basis of person reidentification methods and mentions 'twostep method' and 'endtoend method' without specifying which part of the paper or section it is referring to. It doesn't identify a specific section, table, figure, or unique aspect of the paper. The grounding is at a high level, not pointing to a specific element of the paper.", "verifiability_rationale": "The comment presents factual information about existing methods but does not make any claims or judgments that require verification. It states what is known about the twostep and endtoend methods without providing logical reasoning, common knowledge, or external references to support its statements. It's a descriptive summary, not a claim.", "helpfulness_rationale": "The comment provides context and highlights alternative approaches to person reidentification, which could be helpful for readers to understand the evolution of the field and the potential limitations of the twostep method. However, it doesn't directly address the authors' specific draft or provide actionable feedback on how to improve it. It offers a broader perspective rather than specific, constructive suggestions for the authors' work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of 'add a first sentence' to the specified section, making it a clear and direct instruction. It does not require the authors to infer what needs to be added, thus being explicit. The action is also very concrete, specifying the exact location (Section 3.2) and the nature of the addition (a first sentence).", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 3.2', which is a specific part of the paper. The reviewer clearly identifies the section where the suggestion is directed. The comment also specifies what the suggestion is for this section ('introduce what this section is about'), making it specific to the identified part.", "verifiability_rationale": "The review point is a suggestion or recommendation, not a claim that requires verification. It proposes an improvement to the paper without making a statement that needs to be supported by evidence or reasoning. Therefore, it does not fit into the 'Claim Extraction' step for verifiability verification.", "helpfulness_rationale": "The review point is a clear and specific suggestion to improve the paper by adding a first sentence to a section. This is a direct and actionable piece of feedback that is likely to be helpful for the authors in improving the clarity and structure of their work. The suggestion is concrete and does not require further elaboration or justification within the review point itself."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment \"Line 44: What is meant by the initial rationale selector is perfect?\" is a question about the current state of the rationale selector, not an instruction or suggestion for improvement. It doesn't point to a specific problem or propose a concrete change. It's more of a metacomment about the existing review process.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper or concept being discussed. It's a general statement about the \"initial rationale selector.\" Therefore, the grounding is weak. It also doesn't specify what is meant by \"perfect,\" making it underspecific.", "verifiability_rationale": "The comment contains a claim (\"It seems if it were perfect no additional work needs to be done\"), but it doesn't provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a question and observation, not a verifiable assertion.", "helpfulness_rationale": "The comment is a question about the current state of the review process and doesn't directly provide actionable feedback on how to improve the draft. It doesn't identify a specific weakness or propose a concrete solution. It's more of a reflection on the process rather than a helpful critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the definition of uncertainty is unclear and provides a general suggestion for improvement. While the reviewer identifies a lack of clarity, they don't specify *how* the definition is unclear or what specific aspect needs improvement. The suggestion is to clarify the relationship between the posterior and different types of uncertainty, but it doesn't offer concrete steps on how to do this. Therefore, while the reviewer points out a problem, the lack of specific details makes it 3 but not fully actionable.", "grounding_specificity_rationale": "The reviewer's comment explicitly mentions 'uncertainty is defined based on the posterior distribution.' This directly points to a specific part of the paper and how it's being discussed. However, the reviewer doesn't specify *which* aspect of the posterior distribution is causing confusion. They suggest a different interpretation involving priors and epistemic model uncertainty, but don't link it back to the current definition. Therefore, the grounding is present, but the specificity is limited.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement rather than a claim that can be verified. They are stating that the current definition of uncertainty is unclear and proposing a different explanation. There is no logical reasoning, common knowledge, or external references provided to support this claim. It's a suggestion for clarification, not a verifiable statement about the paper.", "helpfulness_rationale": "The reviewer is attempting to improve the clarity of the paper by suggesting a different interpretation of uncertainty. This is a helpful goal. However, the suggestion is very general and lacks specific details. The reviewer doesn't provide concrete examples of where the current definition is unclear or how their proposed explanation would address those specific issues. Therefore, while the intent is helpful, the lack of specificity makes it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about whether domain ontologies were used, which implies a potential area for improvement. However, the reviewer does not explicitly state what should be done if ontologies were not used, making the action somewhat vague. The reviewer also asks for clarification on a specific implementation detail (line 211), but does not suggest an alternative approach, making the action less explicit.", "grounding_specificity_rationale": "The reviewer asks two questions. The first question, 'It is not clear if authors also experimented with the usage of domain ontologies...', does not explicitly identify a specific part of the paper being addressed. The second question, 'Line 211: How many questions were created for this zeroshot intent classifier and what is the accuracy of this system?', explicitly refers to a specific line in the paper. However, the reviewer is asking for information rather than making a judgment about what should be done, so the specificity is limited to the request for details.", "verifiability_rationale": "The reviewer asks two questions. The first question, 'It is not clear if authors also experimented with the usage of domain ontologies...', implies a claim that the authors did not use ontologies, but the paper does not explicitly state whether they did or did not. The second question, 'Line 211: How many questions were created for this zeroshot intent classifier and what is the accuracy of this system?', implies a claim about the missing information on line 211. However, the paper does not provide any evidence to support or refute these claims.", "helpfulness_rationale": "The reviewer asks two questions. The first question seeks clarification on a potential alternative method (using ontologies) and the second question seeks clarification on a specific implementation detail. While these are valid questions that could help the authors improve their understanding, they do not directly suggest concrete actions or improvements. The reviewer is asking for information rather than providing actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the missingness of citations to recent MARL work. While it doesn't directly tell the authors *what* to cite, it clearly identifies a gap in the related work section. This makes it partially actionable as it points to a specific area for improvement.", "grounding_specificity_rationale": "The review point identifies the relevance of MARL, exploration, and coordination to the paper's content. While it doesn't pinpoint a specific section or element within the paper, it provides a strong indication of where the missing citations are most likely needed. This makes it somewhat grounded.", "verifiability_rationale": "The review point is a statement of a problem (missing citations) rather than a claim that requires justification or support. It doesn't present any logical reasoning, common knowledge, or external references to back up the statement. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper's context of related work. By highlighting the lack of citations to relevant recent MARL papers, it provides the authors with a direction for further research and a better understanding of the current state of the field. While it doesn't offer specific citations, it guides the authors towards important areas of the literature. Therefore, it is 3 in identifying areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a comparison with other selfsupervised learning methods, which can be interpreted as an implicit action to explore alternative approaches. While not explicitly stated as an action, the suggestion implies a desire for improvement by comparing different methods. However, the action is vague and lacks specific details on how to perform the comparison.", "grounding_specificity_rationale": "The review point explicitly mentions 'other selfsupervised learning methods that are not based on contrastive learning.' This clearly identifies a specific aspect of the paper (the related work section or a discussion of different selfsupervised techniques) and what the suggestion is about. This is a strong example of 'Full Grounding' as it pinpoints a specific section and provides a clear target for the suggestion.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a suggestion for improvement rather than a statement of fact or opinion. Therefore, it fits the 'X' category as it doesn't present any verifiable information.", "helpfulness_rationale": "The review point suggests comparing with other selfsupervised learning methods, which could be a valuable direction for the authors to explore. This suggests a potential improvement or alternative approach, which can be helpful in the development of their method. While it might not be the only or most critical issue, it provides a concrete suggestion for further investigation. Therefore, it is better than '2' or '3'."}
{"actionability_label": "3  3", "grounding_specificity_label": "3  3", "verifiability_label": "2  2", "helpfulness_label": "3  3", "actionability_rationale": "The reviewer is asking a question, which is an explicit request for clarification. They are not suggesting a specific action to take based on the information given. The request is clear and directly addresses a potential ambiguity in the implementation of the abstention process. It seeks a definition and a comparison.", "grounding_specificity_rationale": "The reviewer is asking about the 'abstention process,' 'prediction probability threshold,' and 'decision threshold.' These are specific technical terms related to the model's behavior. They are not asking for a general explanation of these concepts. The reviewer is asking about the *relationship* between these specific concepts in the context of their system. They are seeking a comparative explanation.", "verifiability_rationale": "The reviewer is stating a question, which is not a claim in itself. However, the *answer* to the question will be a claim (e.g., \"The abstention process is based on a prediction probability threshold\"). Once the answer is provided, its verifiability can be assessed. The reviewer is asking a question that can be answered with information available to them and the model.", "helpfulness_rationale": "The reviewer is asking for clarification on a mechanism that directly affects how their draft is processed by the model. Understanding this process is valuable for authors who want to optimize their submissions. The question seeks a definition and a comparison, which are concrete pieces of information that would benefit the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point makes a direct statement about Megatron's performance being 'overrated' compared to other models. This is an explicit action or suggestion that the authors should reevaluate Megatron. However, the reviewer does not explicitly state how to improve Megatron or what specific aspects need adjustment. The suggestion is implicit, making it somewhat vague and lacking detail on how to apply it.", "grounding_specificity_rationale": "The reviewer compares Megatron's performance to other models but does not explicitly identify a specific part of the paper being addressed. The comparison is general and does not point to a particular section, table, or figure. The reviewer mentions 'other approaches' like RoBERTa, ELECTRA, and DeBERTa but does not specify which aspect of these models is being compared to Megatron. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer makes a claim that Megatron's performance is 'overrated' and suggests a comparison with other models. However, this claim is not supported by any specific evidence or justification within the review point itself. The reviewer does not provide logical reasoning, common knowledge, or external references to back up this assertion. Therefore, the verifiability is low as the claim is not wellsupported.", "helpfulness_rationale": "The review point raises a question about the impact of switching BPE vocabulary types on performance. While this is a valid question for the authors, it is framed as a question rather than a direct critique or suggestion for improvement. The reviewer also makes a general statement about Megatron's performance being 'overrated,' which is somewhat vague and lacks specific guidance. The overall helpfulness is limited as the points are not strongly constructive or actionable."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point is a critique of the authors' analysis and does not directly suggest any specific actions the authors should take. It questions the interpretation of the results and offers an alternative explanation. Therefore, it lacks explicit and actionable feedback.", "grounding_specificity_rationale": "The reviewer refers to 'lines 128 to 149' and 'Fig 3' but does not explicitly identify which part of the paper is being analyzed or how the observation relates to that specific part. The connection to the paper is implied but not clearly established. The reviewer's statement is general and does not pinpoint a specific section, table, or figure. The mention of external references does not ground the comment within the paper's content.", "verifiability_rationale": "The reviewer provides an alternative interpretation of the results based on established concepts in deep learning (class selectivity and context). This interpretation challenges the authors' hypothesis. While the reviewer does not explicitly claim that 'additional context may allow the network to reduce its dependency' is a fact, the alternative explanation provides a basis for verification. The reviewer's statement is a claim that requires justification, and the alternative explanation serves as a form of logical reasoning. However, the reviewer does not provide specific examples or references to support their alternative interpretation within the context of the paper being reviewed.", "helpfulness_rationale": "The review point is valuable because it identifies a potential flaw in the authors' analysis and offers a plausible alternative explanation based on established literature. This directly helps the authors understand the limitations of their approach and potentially improve their model. The reviewer's comment provides a constructive critique that can lead to further investigation and refinement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a weakness in the paper's conclusions regarding the impact of continuous learning with unlabeled data on representation quality. While the reviewer doesn't provide explicit, detailed steps on how to improve the draft, they *imply* an action: investigating alternative combination methods. The suggestion to explore rehearsalfree and featurereplay methods is a clear direction for improvement, even if the paper doesn't explicitly mention these methods. Therefore, the action is implied and points towards concrete actions.", "grounding_specificity_rationale": "The reviewer mentions 'continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality' as a belief. While this is a general statement, the reviewer doesn't explicitly point to a specific section, table, figure, or unique aspect of the paper where this belief is discussed. The grounding is implied but not precise. The suggestions about rehearsalfree and featurereplay methods are also not explicitly linked to specific parts of the paper. Therefore, the grounding is weakly specific.", "verifiability_rationale": "The reviewer makes a claim: 'The results might come from the limited exploration of combination methods.' They then provide specific suggestions for improvement, namely rehearsalfree methods (like R1 and R2) and featurereplay methods. They also mention a 'recent work R3 also employs feature replay.' These specific methods and references directly support the claim and provide a clear path for the authors to address the identified issue. The reasoning is logical, and the evidence is present in the form of suggested methods and related work. Therefore, the claim is 5.", "helpfulness_rationale": "The reviewer clearly states a problem ('Some conclusions are not convincing') and offers concrete solutions ('The results might come from the limited exploration of combination methods. In rehearsalfree continual learning, featurereplay methods have shown great potential...'). The suggestions are directly related to the identified weakness and provide a clear direction for improvement. The reviewer doesn't just point out a problem; they offer a path towards resolution. The suggestions are actionable and provide specific methods to explore. Therefore, the review point is 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the weakness 'lack of meaningful baselines' and proposes a specific action to address it: 'comparing with a chainofthought prompting approach'. This directly points to an actionable recommendation.", "grounding_specificity_rationale": "The review point refers to 'various model criticism techniques' mentioned in Section 2. While it identifies a general area of concern, it does not explicitly name a specific technique or location in the paper where this lack of baselines is an issue. The reviewer is making a general statement about the experimental setup.", "verifiability_rationale": "The review point states a weakness ('lack of meaningful baselines') and suggests a *solution* ('comparing with a chainofthought prompting approach'). It doesn't explicitly claim that *this specific comparison* is a valid or justified approach. The focus is on identifying the problem of lacking baselines.", "helpfulness_rationale": "The review point clearly identifies a weakness in the experimental design (lack of meaningful baselines) and provides a specific suggestion for improvement (comparing with chainofthought prompting). This directly addresses a practical issue for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about the pretraining dataset but doesn't provide a direct answer or suggest any actions for the authors. It's a question posed without context, leaving the authors without a clear direction. The implicit suggestion is to clarify the training procedure, but it's not explicitly stated or actionable.", "grounding_specificity_rationale": "The review point doesn't explicitly identify a specific aspect of the paper being addressed (e.g., 'Section 3.2', 'Figure 4'). It's a general question about the pretraining process. Therefore, it's 1 in a specific part of the paper. The question is about the *entire* dataset or the *training set*, which are general terms.", "verifiability_rationale": "The review point poses a question about the generalization of the model without providing any evidence, logical reasoning, or external references. There is X being made, so the verifiability scale doesn't apply.", "helpfulness_rationale": "The review point asks a question about the pretraining dataset and the model's generalization ability. While this is relevant information for the authors, the question is posed without providing any context or potential solutions. It doesn't directly answer what the authors should do or how to improve their model based on this information. It's a question without a clear direction or actionable suggestion."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "1 (1)", "verifiability_label": "X (X)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point states a fact about hardware and software dependence but does not specify any action the authors should take. It is a statement of observation rather than a directive.", "grounding_specificity_rationale": "The review point is a general statement about potential hardware and software dependencies and does not specify which part of the paper or unique element this refers to. It lacks grounding specificity as it does not identify a specific section, table, figure, or unique aspect of the paper being addressed.", "verifiability_rationale": "The review point is a statement of fact, not an opinion or suggestion. It does not contain a claim that requires verification. Therefore, it does not have verifiability to evaluate.", "helpfulness_rationale": "The review point highlights a potential limitation of the work related to hardware and software dependencies. While it doesn't directly tell the authors what to change, it points out a potential issue that they should consider for future work, making it 3 in identifying potential areas for improvement and future research."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a small performance difference in an ablation study but does not provide any guidance on how to interpret or act upon this difference. The comment lacks explicit or implicit suggestions on what this discrepancy means for the model or the ablation strategy. The reviewer is essentially stating the existence of a difference without offering any action or interpretation.", "grounding_specificity_rationale": "The reviewer's comment is 1 in the paper itself. They are referring to the results of an ablation study (Tab. specific table number if provided, otherwise implied) without explicitly linking this finding back to a specific section, table, figure, or unique aspect of the paper being discussed. The grounding is implicit, referring to external results rather than directly to the paper's content. The specificity is also low as the reviewer is not detailing what needs to be addressed in this part (the ablation study results) based on their observation.", "verifiability_rationale": "The reviewer's statement about the 'little difference between the results reported for the ablation study in Tab.' is a claim that needs verification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as an observation without any justification or evidence within the review point itself.", "helpfulness_rationale": "The reviewer's comment is 3 in identifying a potential issue or area for further investigation (the small performance difference in the ablation study). However, the lack of grounding and verifiability makes the comment unhelpful in terms of providing actionable guidance or justification for the observed difference. The reviewer is pointing out a problem but not providing a solution or explanation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'No new evaluation metrics are proposed. Only existing evaluation metrics are proposed.' This is a clear, direct statement of what the reviewer is suggesting. The action of not proposing new metrics is also explicitly stated, and the suggestion to focus on existing metrics is clear. Therefore, this comment is 5 as it directly identifies a potential limitation and suggests a specific course of action.", "grounding_specificity_rationale": "The comment refers to 'evaluation metrics' in general, which is a somewhat broad term. While it mentions 'new' and 'existing,' it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper where this concern arises. The grounding is not as precise as it could be. However, the comment does specify the *type* of metric (new vs. existing) and the area of concern ('indepth exploration of experimental results'), which adds a degree of specificity. Therefore, the grounding is weak but not entirely absent.", "verifiability_rationale": "The comment contains a claim: 'No new evaluation metrics are proposed. Only existing evaluation metrics are proposed.' This is a statement of intent or a suggestion. However, the comment does not provide any justification or reasoning for why only existing metrics should be used or why new ones aren't proposed. There are no logical arguments, common knowledge, or external references provided to support this claim. Therefore, the verifiability of this claim is low.", "helpfulness_rationale": "The comment raises a valid point about the limitations of relying solely on existing evaluation metrics and suggests a potential improvement by exploring them in more depth. However, the comment lacks specific suggestions on how to conduct this indepth exploration. It doesn't specify which experimental results need exploration or provide any guidance on the nature of this exploration. While the reviewer identifies a potential area for improvement, the lack of concrete suggestions makes the comment less helpful than it could be. The impact is limited."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out the problem of the dual use of 'K' and provides specific line numbers (L166 and L176) where this occurs. This makes the action clear and allows the authors to directly address the issue.", "grounding_specificity_rationale": "The reviewer not only identifies the problem but also explicitly pinpoints the exact locations in the paper where the dual use of 'K' occurs (L166 and L176). This strong grounding allows the authors to precisely understand where the issue lies.", "verifiability_rationale": "The reviewer makes a clear claim about the notational abuse of 'K'. While they don't provide explicit evidence of the consequences of this abuse (like potential confusion), they do point to specific instances where the problem exists (L166 and L176). This provides strong support for their claim.", "helpfulness_rationale": "The reviewer clearly identifies a problem (notational ambiguity) and provides specific locations where it occurs. This is a direct and actionable feedback that can help the authors improve their paper by ensuring consistent notation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitation of the work being primarily of theoretical interest and the AMP algorithm's unclear utility for nonGaussian problems. This directly implies an action: 'improve the understanding of AMP for nonGaussian problems'. However, the reviewer does not provide specific steps or details on how to achieve this improvement.", "grounding_specificity_rationale": "The reviewer refers to 'the weak recovery problem studied here' and 'the AMP algorithm'. While they identify the area of concern, they do not specify a particular section, table, figure, or unique aspect within these broad categories. The reference remains general.", "verifiability_rationale": "The reviewer makes a claim about the 'limited practical impact' of the work. They support this claim by stating that the 'weak recovery problem studied here is primarily of theoretical interest, and it is not clear if the AMP algorithm is useful for nonGaussian problems'. This provides a logical connection between the identified problem and the claimed limitation, making the claim 3.", "helpfulness_rationale": "The reviewer identifies a potential limitation of the work's scope and applicability, specifically regarding its theoretical focus and the AMP algorithm's performance on nonGaussian data. They suggest focusing on nonGaussian problems as a direction for improvement. While the comment doesn't offer a concrete solution, it points towards a specific area for future work and helps the authors refine their focus, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a point of confusion regarding the relevance of human cognition and asks a direct question about its potential impact. The language is clear and directly identifies the area needing clarification. The reviewer provides a concrete action: 'Perhaps the interaction between cognitively basic adaptation mechanisms and the structure of the CPR itself has more of an effect on whether selforganization will fail or succeed than previously appreciated.' This is a clear statement of what is unclear.", "grounding_specificity_rationale": "The reviewer directly references a specific part of the paper ('Perhaps the interaction between cognitively basic adaptation mechanisms and the structure of the CPR itself has more of an effect on whether selforganization will fail or succeed than previously appreciated.') using literal mention. They also provide further details about the point of confusion ('unclear whether bringing connections to human cognition makes sense' and 'previously appreciated'). This demonstrates a clear understanding of the section and the specific claim being made.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question and making a request for clarification. The point is a question, not a statement that needs to be proven or supported. Therefore, it falls outside the scope of verifiability.", "helpfulness_rationale": "The reviewer identifies a potential area for improvement in the authors' work by suggesting the inclusion of citations to support 'previously appreciated' findings. While the suggestion itself isn't a concrete fix, it is a valuable piece of feedback that directly addresses a potential weakness in the authors' presentation. The reviewer is actively engaging with the authors' work and suggesting a specific improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the issue ('wording is overly exaggerated') and points to a specific section ('conclusion'). However, it does not provide concrete steps on how to fix the exaggerated wording. The reviewer identifies the *problem* but not the *specific action* to address it.", "grounding_specificity_rationale": "The comment explicitly mentions the 'conclusion' and the specific phrase '... our pioneering contributions herald a new era in robotic adaptability ...'. This allows the reader to precisely identify the referenced part of the paper. The comment also generally points to 'word choice being flamboyant' in the writing, which, while not specific to a single phrase, still identifies a clear area for improvement within the paper.", "verifiability_rationale": "The comment contains a claim ('wording is overly exaggerated') and identifies an issue ('word choice is flamboyant'). While it doesn't provide external references or logical reasoning to *prove* the exaggerated wording, the claim itself is a statement that can be verified by reading the conclusion. The reviewer's statement is a reasonable assessment of writing style.", "helpfulness_rationale": "The comment identifies a specific area for improvement ('the conclusion') and points to a specific issue ('overly exaggerated wording'). It also highlights a general problem ('word choice is flamboyant'). This provides a clear direction for the author to focus their revision efforts, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point implicitly suggests an action by mentioning the need for ablation experiments. However, it doesn't explicitly state what needs to be done to perform these experiments or how the results should be interpreted. The action is present but needs to be inferred.", "grounding_specificity_rationale": "The review point explicitly mentions the need to compare the proposed method with TubeR in terms of learnable parameters and GFLOPs. This clearly identifies the specific part of the paper (comparison with TubeR, metrics: learnable parameters, GFLOPs) that needs attention. The grounding is strong and specific.", "verifiability_rationale": "The review point makes a claim that 'the authors need to perform ablation experiments to compare the proposed method with other methods (e.g., TubeR) in terms of the number of learnable parameters and GFLOPs.' This claim is supported by the specific comparison method (TubeR) and metrics (learnable parameters, GFLOPs) mentioned. The evidence is clear and directly related to the point being made.", "helpfulness_rationale": "The review point identifies a valid and relevant area for improvement by suggesting ablation studies to understand the tradeoffs between performance and efficiency compared to a relevant baseline (TubeR). While it doesn't provide specific details on *which* aspects to ablate or *how* to interpret the results, it provides a clear direction for the authors to take, which is helpful in guiding their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the absence of comparison to simple feature acquisition baselines as a weakness. This directly implies an actionable step for the authors: conduct this comparison. While the action is not fully specified (e.g., which metrics to use), the reviewer clearly identifies a missing component that they believe is necessary for proving the effectiveness of their approach. The phrase \"The biggest weakness of the paper is that it does not compare to simple feature acquisition baselines like expected utility or some such measure...\" directly points to a specific area for improvement.", "grounding_specificity_rationale": "The review point mentions 'simple feature acquisition baselines\" and specifically names \"expected utility\". This indicates that the reviewer has identified a specific aspect of the paper (the comparison to a particular type of baseline) and is pointing out a deficiency in this area. The grounding is achieved by naming a specific type of baseline, which provides a clear target for the authors to address. The specificity is also evident as the reviewer names a concrete example of the baseline.", "verifiability_rationale": "The review point makes a claim: \"The biggest weakness of the paper is that it does not compare to simple feature acquisition baselines...\". This is a claim that requires verification. However, the review point itself does not provide any evidence or reasoning to support this claim. The reviewer is stating their assessment of the paper's content, but they are not explaining *why* they believe this is a significant weakness or providing any references to back it up. Therefore, the verifiability is low because the claim is made without sufficient justification or evidence within the review point itself.", "helpfulness_rationale": "The review point identifies a general weakness in the paper's evaluation methodology \u2013 the lack of comparison to feature acquisition baselines. While this is a valid point, the review point itself does not offer any specific suggestions or guidance on how the authors should approach this comparison. The reviewer points out a missing piece but doesn't provide a concrete solution or explain *why* this missing piece is so crucial. The writing style issue is also vague and doesn't provide actionable feedback. The helpfulness is limited because the reviewer identifies a problem but doesn't offer a clear path forward for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out areas for improvement such as 'how about other bit operations?' and 'please give more explanations'. These are explicit actions, but they lack specific details on how to achieve these improvements. The reviewer also suggests improvements related to DVS input handling and energy consumption analysis, which are implicit actions.", "grounding_specificity_rationale": "The reviewer mentions 'Fig. 5 a' which is a specific element of the paper, indicating some level of grounding. However, the reviewer also mentions 'aer format' which is ambiguous and does not clearly identify a specific part of the paper. While the paper element is identified, the broader context is not fully specific.", "verifiability_rationale": "The reviewer states 'Fig. 5 a seems strange' and 'If you can analyze the energy consumption as reference15 did'. The first statement is a claim that is not supported by any evidence or reasoning within the review point. The second statement, while suggesting an improvement, does not provide a clear justification or method for analysis.", "helpfulness_rationale": "The review points out potential issues with Figure 5a and suggests improvements in handling DVS input and analyzing energy consumption. While these suggestions are relevant, they lack specific details on how to address the identified issues or how to implement the suggested improvements. The reviewer's comments are focused on areas that need clarification or further work, but without concrete steps, their helpfulness is limited."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a lack of clarity in how the embeddings are combined and fed into the CSCM. While the paper mentions 'separate embedding and addition with positional encoding,' it doesn't explicitly state the mechanism for combining these embeddings before being used as input for the CSCM. This leaves the reviewer needing to infer the combination method, making the action implicit rather than explicit. The reviewer expects a clear explanation of the combination process to apply the suggested improvement.", "grounding_specificity_rationale": "The review point focuses on a specific aspect of the method: the combination of embeddings and their input to the CSCM. The paper mentions 'separate embedding and addition with positional encoding,' which can be considered a specific part of the method. The reviewer then clarifies that they need to know how these are combined and fed into the CSCM. This specificity allows the authors to identify the exact area they need to improve. The grounding is also specific as the reviewer is asking about a particular implementation detail.", "verifiability_rationale": "The review point identifies a specific technical detail about the method (how embeddings are combined and fed into the CSCM). However, the paper does not provide any justification or evidence for this specific combination method. The reviewer is left to infer the intended process, which makes the claim 1. There are no logical reasons, common knowledge, or external references provided to support this specific combination method.", "helpfulness_rationale": "The review point clearly identifies a lack of clarity in a specific technical detail of the paper. The reviewer explicitly states that the paper mentions 'separate embedding and addition with positional encoding' but fails to explain how the embeddings are combined and fed into the CSCM. This lack of clarity makes it difficult for the authors to understand and potentially implement the suggested improvement. The feedback is specific but lacks the necessary details to be fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of innovation and the similarity to object detection algorithms. They also point out that many MLMs can already accomplish the object detection task by themselves. This provides a clear direction for the authors to address the novelty of their approach.", "grounding_specificity_rationale": "The reviewer doesn't explicitly name a specific section or table, but they refer to 'the article itself' and 'the field of MLMs' generally. They also mention 'multigranularity and multiscale' and 'object detection algorithms,' which provides some level of specificity, although not pinpointing a single section.", "verifiability_rationale": "The reviewer makes a claim that the approach is not innovative and is a common approach migrated from object detection. They support this claim by stating that 'many MLMs can already accomplish the object detection task by themselves nowadays.' This provides logical reasoning and an example, making the claim verifiable.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper's contribution \u2013 the lack of novelty in applying multigranularity and multiscale approaches from object detection to MLMs. They also suggest comparing their approach to object detection algorithms, which is a concrete and helpful suggestion for the authors to consider."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer poses a question about the expressiveness of 'fast SMP' compared to 'SMP' and requests more discussion on the 'power of different architectures'. While the question is specific, it doesn't explicitly state what action the authors should take. The desire for more discussion is general and doesn't point to a specific part of the paper or a concrete issue. Therefore, while the reviewer points to a potential area for improvement, they don't directly instruct the authors on how to address it. The question is openended and doesn't provide a clear action for the authors to follow.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly refer to a specific part of the paper or a specific issue within 'fast SMP' or 'SMP'. The comment is a general question about the 'power of different architectures'. There is no mention of a particular section, table, figure, or unique element of the paper. Therefore, the comment is 1 at all.", "verifiability_rationale": "The reviewer's comment is a statement of desire and a question, not a claim that requires verification. There is no assertion of something being true or false. Therefore, it does not contain a claim that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer's comment raises a relevant question about the expressiveness of 'fast SMP' and requests more discussion on the 'power of different architectures'. This is a pertinent topic that could be beneficial for the authors, especially if they have experience with these concepts. The comment is clear and directly points to a potential area for improvement. While it doesn't offer a solution, it identifies a specific topic that could lead to valuable insights. Therefore, it is a helpful comment that prompts further consideration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests evaluating across different splits, which is an action the authors can take to potentially improve their results. While the action is not explicitly stated, the reviewer implies it. The authors can infer that they should change their evaluation strategy. This suggests the comment is 3 as it points towards a concrete step, even if not directly stated.", "grounding_specificity_rationale": "The reviewer refers to the 'evaluation' section or process, which is a broader concept. While the reviewer implies it's about the evaluation, the authors need to infer that the relevant part is the evaluation section or process. This suggests the comment is 4 as the authors can deduce the area of concern, but it's not explicitly pointed out. The phrasing 'not simply different initialisation seeds' helps to ground it to the evaluation aspect.", "verifiability_rationale": "The reviewer is making a suggestion for improvement, not stating a claim that needs verification. The reviewer is proposing a different experimental design to potentially get better results. This is a proposition, not a verifiable statement. Therefore, it falls under 'X' or 'X' as there is X requiring justification.", "helpfulness_rationale": "The reviewer points out a potential limitation in the current evaluation methodology and suggests an alternative approach that could lead to better results. This is a valuable suggestion for researchers as it highlights a potential area for improvement in their experimental design. While it doesn't directly tell the authors what to do, it guides them towards a potentially better evaluation strategy, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'can be combined together'. This action is also concrete, as it clearly indicates what needs to be done (combine the first two bullets) and where it should be done (the introduction). The reviewer provides a clear instruction on how to implement this action.", "grounding_specificity_rationale": "The review point explicitly refers to 'the first two bullets about contributions (at the end of the intro)'. This is a very specific reference to a particular section of the paper, making the grounding fully specific.", "verifiability_rationale": "The review point is a suggestion for improvement, not a claim that requires verification. There is no statement that needs to be supported by evidence or references. It is a constructive suggestion, not a claim of fact.", "helpfulness_rationale": "The review point identifies a specific, actionable improvement (combining redundant bullets) in the introduction. This is a clear and actionable suggestion that is likely to be helpful for the author in streamlining their work."}
{"actionability_label": "2", "grounding_specificity_label": "1 and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a weakness in the paper by stating that the types of situations/social norms are not clear. While this is a valid observation, the reviewer does not explicitly state what needs to be done to address this weakness. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer refers to 'the main paper' generally, without specifying a particular section, table, figure, or unique element. The issue is broad and doesn't pinpoint the exact location of the lack of clarity.", "verifiability_rationale": "The reviewer makes a claim that 'the types of situations/social norms are not clear in the main paper.' This is a verifiable statement, as the lack of clarity is a factual observation. However, the reviewer does not provide any external references or logical reasoning to support why this lack of clarity is a problem.", "helpfulness_rationale": "The review point identifies a valid weakness in the paper, which can be helpful for the authors to understand. However, the reviewer does not provide any concrete suggestions or actions for the authors to take. The feedback is present but lacks actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests the authors 'do need to refer to more recent trends in the vision community'. While this points towards a direction for improvement, it doesn't explicitly state the steps or how to implement this reference. The action is implied rather than clearly defined.", "grounding_specificity_rationale": "The reviewer mentions 'more recent trends in the vision community' as a potential improvement area. However, they do not specify which part of the paper this refers to or how it directly relates to the algorithm's performance. The grounding is present at a high level but lacks specificity to a particular section or issue.", "verifiability_rationale": "The reviewer makes a claim about the importance of closed contours and robustness to weak boundaries as key tasks. They also suggest referring to 'more recent trends in the vision community' as a way to improve this. This claim is logically connected to the suggested improvement, making it 3. However, it lacks specific references or examples to back up the claim about 'more recent trends'.", "helpfulness_rationale": "The reviewer raises a valid point about the paper's scope and suggests looking into 'more recent trends in the vision community' to demonstrate improvement. This directly addresses a potential ambiguity for the authors regarding the paper's contribution and provides a concrete direction for improvement. The suggestion is clear and relevant."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need for more baselines and domains, making it actionable. While the *why* is missing, the *what* is clear.", "grounding_specificity_rationale": "The reviewer explicitly identifies the need for more baselines and domains, which is a specific request. However, the *section* where this improvement should be reflected isn't explicitly named, making the grounding slightly weak.", "verifiability_rationale": "The reviewer states a desire for more information but doesn't provide any logical reasoning, external references, or examples to support this desire.", "helpfulness_rationale": "The reviewer clearly states a desire for more information, which directly points towards concrete improvements the authors can make. While it doesn't provide *specific* suggestions, it's a helpful direction."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment implicitly suggests an action (defining the dashed lines) but lacks specific details on how to achieve this, making it less directly actionable. Authors can infer the need to understand the purpose and usage of these lines but not the exact definition or how to obtain it.", "grounding_specificity_rationale": "The comment explicitly refers to specific parts of the paper (figures 2AB and 4B), indicating good grounding. However, it doesn't specify what information needs to be defined about these figures, making it less specific. Authors cannot confidently determine what information is missing or needs clarification about the dashed lines in these figures.", "verifiability_rationale": "The comment is not a claim requiring verification. It's a request for clarification. There are no logical reasoning, common knowledge, or external references provided to support the request.", "helpfulness_rationale": "The comment points to a potential area for improvement (clarity on the figures) but doesn't provide direct, actionable feedback or a claim to verify. It's more of a suggestion for the authors to clarify their own figures rather than providing specific instructions or verifiable information to the reviewers."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The statement identifies a potential issue (lack of comparability) but does not explicitly instruct the authors on what to do next. It's a critique of the results rather than a direct action the authors should take based on this review point.", "grounding_specificity_rationale": "The comment does not specify which results or methods are not comparable. It is a general statement about the significance of the results, not tied to a specific part of the paper or analysis.", "verifiability_rationale": "The statement expresses an opinion about the significance of the results without providing any supporting evidence or logical reasoning. It lacks the verification methods required to make the claim verifiable.", "helpfulness_rationale": "The statement is critical and raises concerns, but it does not directly suggest how the authors can improve their method based on this review. It's a statement of concern rather than a constructive suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the perceived lack of novelty and the similarity to DeCorr. While the reasons for this assessment are provided, the reviewer does not offer concrete suggestions for improvement beyond stating the problem. The action is identified (perception of limited novelty), but the lack of specific guidance makes it partially actionable.", "grounding_specificity_rationale": "The reviewer broadly characterizes the work as 'limited novel' and 'straightforward application' without pinpointing a specific section, table, or figure that needs improvement. While they mention 'DeCorr' and 'graph collaborative filtering,' they don't specify which part of the paper is affected. The grounding is general and doesn't clearly identify the issue.", "verifiability_rationale": "The reviewer makes a claim about the paper's perceived lack of novelty and similarity to DeCorr. However, they do not provide any evidence, references, or logical reasoning to support this claim. The statement is presented as an observation rather than a welljustified assertion.", "helpfulness_rationale": "The reviewer's comment is primarily critical, pointing out a perceived weakness (lack of novelty) without offering any concrete suggestions for improvement. While they mention 'different datasets and backbones' and 'lack of unique insights,' they don't translate these into actionable recommendations for the authors. The feedback is presented as a critique rather than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two potential issues. The first, 'the Figure 2 is a little ambiguous, where some symbols are not explained clearly,' is 3. The reviewer could ask for clarification on specific symbols. However, the phrasing is general, making it difficult to pinpoint the exact action needed. The second issue, 'And the reviewer is curious about that whether there is information redundancy and interference in the multisphere icosahedral discretization process,' is also 3. The reviewer could ask for clarification or further explanation on this process. However, the phrasing is general and doesn't specify what kind of redundancy or interference is being referred to.", "grounding_specificity_rationale": "The review point identifies issues related to Figure 2 and the multisphere icosahedral discretization process. However, it does not explicitly state which specific part of the paper is being addressed. The reviewer is generally referring to these areas but doesn't provide precise references. For example, they don't specify 'Section 3.2, Figure 2' or 'Section 4.1, Method, Discretization Process'. This lack of specificity makes it difficult to determine the exact area the reviewer is referring to.", "verifiability_rationale": "The review point contains claims that can be verified. For the first part, 'the Figure 2 is a little ambiguous, where some symbols are not explained clearly,' the reviewer is claiming a lack of clarity. While the verifiability of *fixing* the figure depends on the authors' ability, the *claim* itself is based on an observation. For the second part, 'And the reviewer is curious about that whether there is information redundancy and interference in the multisphere icosahedral discretization process,' the reviewer is making a claim about a potential issue. However, the verifiability of this claim depends on the authors' ability to identify and explain the potential redundancy and interference. Therefore, the claims are 3 as they are based on observations or questions that can be investigated by the authors.", "helpfulness_rationale": "The review point raises two potential issues. The first, 'the Figure 2 is a little ambiguous, where some symbols are not explained clearly,' is 3. The reviewer is pointing out a potential area for improvement in the paper's presentation. The second part, 'And the reviewer is curious about that whether there is information redundancy and interference in the multisphere icosahedral discretization process,' is also 3. The reviewer is expressing a curiosity about a specific aspect of the method, which can prompt the authors to investigate and clarify this further. While the phrasing is general, it still points to specific areas of potential improvement or clarification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the limitation regarding Matern kernels and their polynomial decay, contrasting it with the assumed subgaussian spectrum. This is an explicit statement of a problem that can be directly addressed by the authors. The reviewer provides a clear explanation of why this assumption is restrictive, making the actionable.", "grounding_specificity_rationale": "The reviewer directly mentions \"Matern kernels\" and explains why they are not covered by the 'subgaussian spectrum\" assumption. This is a clear and specific identification of the relevant concept. The reviewer explicitly states the type of decay (polynomial) and how it differs from the assumed type of decay (subgaussian). This is a highly specific explanation of the issue.", "verifiability_rationale": "The reviewer makes a clear claim: \"The results of the paper could be restrictive\" due to the limited assumption about kernel spectra. The reviewer provides a reason for this claim: \"The authors assume that the spectrum of a kernel is subgaussian. This is OK, as the popular Gaussian kernels are in this class. However, another popular class of kernels such as Matern kernels are not included, since their spectrum only decay polynomially.\" This reasoning is logical and provides a basis for understanding the limitation. While it doesn't provide a direct example of how this restricts the results, it clearly explains the difference between the assumed property and the property of a relevant class of kernels.", "helpfulness_rationale": "The reviewer clearly identifies a potential limitation in the paper's methodology and suggests that this limitation could affect the generality of the results. This is a valuable piece of feedback for the authors. The reviewer points out a specific assumption that needs to be considered, which can guide the authors in either broadening their analysis or explicitly acknowledging the limitations of their current approach. This feedback is focused on improving the understanding and scope of the work, rather than simply pointing out a flaw."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the importance of unsupervised pretraining based on their analysis of Table 4. They also suggest focusing more on this aspect, which is a clear action for the authors to take. The reviewer identifies the specific aspect (unsupervised pretraining) and provides a reason for its importance, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer mentions 'unsupervised pretraining' and refers to 'Table 4' to support their claim. While they don't specify the exact section, the reference to a table implies they can identify the relevant part of the paper. The reviewer also specifies how the unsupervised pretraining is important based on the data in Table 4, adding detail to the identified aspect.", "verifiability_rationale": "The reviewer makes a claim about the lack of detailed discussion on unsupervised pretraining in the main paper. They support this claim by referencing the experimental results in Table 4, which they argue indicate its key factor in performance gain. While the claim itself isn't directly verifiable within the paper, the evidence provided (Table 4) supports the implication that there's a gap in the discussion. The reviewer also connects this to the ablation study in Table 5, further strengthening the basis for the claim.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper: the lack of detailed discussion on unsupervised pretraining, which they connect to the significant performance gains observed in the experiments. They also provide a concrete suggestion for improvement: focusing more on the pretraining method in the main paper. This actionable feedback is directly helpful for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question: 'How would we choose which ELM to pick (male/female)?' This constitutes an implicit action or suggestion. However, the reviewer does not provide a concrete solution or guidance on how to make this choice. The action remains to be inferred.", "grounding_specificity_rationale": "The reviewer's question is general and does not specify a particular part of the paper or a unique element within it. They are asking about the process of choosing an ELM in general. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses. The specificity is also low as the comment does not detail what needs to be addressed in this general process.", "verifiability_rationale": "The review point is a question seeking information rather than a claim requiring verification. Therefore, it does not contain a claim that needs to be supported by evidence. This fits the 'X' category where the comment is a factual statement without claims, judgments, or suggestions.", "helpfulness_rationale": "The reviewer raises a practical concern about the ELM selection process and its impact on accuracy within a pipeline. This directly addresses a potential user's concern and provides a clear direction for improvement (understanding the pipeline implications). The question is directly relevant to the ELM selection process and highlights a potential issue in a realworld application, making it 3 in identifying a problem area."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem ('difficult to follow') but does not explicitly state the next action the authors should take. While it suggests improvement, it lacks the specificity of how to achieve it.", "grounding_specificity_rationale": "The comment does not specify which part of the paper is difficult to follow. It refers to the writing in general terms, without pointing to a specific section, table, figure, or element.", "verifiability_rationale": "The comment does not make a claim that can be verified. It is a suggestion for improvement rather than a statement requiring evidence or justification.", "helpfulness_rationale": "The comment identifies a valid issue (difficult to follow writing) but does not provide a concrete solution or actionable steps for the authors to take. It is a helpful observation but lacks the necessary guidance to be fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out a lack of technical substance and the addition of a new loss. While the reviewer suggests adding a new loss to 31, they don't specify how this addition should be implemented or what benefits it would bring. The action of adding a new loss is mentioned, but the details of how to do it are missing.", "grounding_specificity_rationale": "The reviewer mentions '31' but doesn't specify which part of the paper this loss is intended for. They also don't explain why this specific citation is relevant to the addition of a new loss. The reviewer can make an educated guess about the section where the loss might be added, but the connection between the citation and the specific part of the paper is not explicit.", "verifiability_rationale": "The review states that the paper is 'incremental and does not have much technical substance' and that it 'just adds a new loss to 31'. This statement can be considered a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The suggestion to add a new loss is presented without any justification or evidence.", "helpfulness_rationale": "The review is critical, stating that the paper is 'incremental and does not have much technical substance' and that it 'just adds a new loss to 31'. While the suggestion to add a new loss is present, the review lacks any specific details on how this addition would be beneficial or what steps the authors should take to implement it. The criticism is not balanced by a clear and actionable suggestion that would empower the authors to improve their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for 'intuition' regarding Theorem 1, which implies a request for a clearer explanation or understanding of the underlying concepts. They also ask 'how certain distributions P* make it easier to determine f*,' which is a specific question about the relationship between the distribution and the function. Finally, they ask 'In practice, how should you determine which P* to fix?' This is a direct request for guidance on how to implement or apply the concept. These explicit requests for clarification and practical guidance make the review point 5.", "grounding_specificity_rationale": "While the reviewer doesn't explicitly name 'Theorem 1' or the 'invertible function f*,' the context strongly suggests these are the parts of the paper being referred to. The reviewer is implicitly pointing to these elements when asking for 'intuition' about Theorem 1 and how it relates to the invertible function. Therefore, the grounding is not 3, but rather weakly grounded and underspecific, as the exact section or table is not mentioned, but the concept is implied.", "verifiability_rationale": "The reviewer states that the paper lacks clarity regarding the intuition behind Theorem 1 and the role of the invertible function f*. This statement is a claim that needs to be addressed. The reviewer then provides suggestions for how to address this lack of clarity, such as 'asking for intuition' and 'exploring specific distributions.' While these suggestions are not direct external references, they provide some level of support by indicating a direction for further investigation. Therefore, the claim is 3, as there is a suggestion for how to verify it, but it lacks a direct citation.", "helpfulness_rationale": "The reviewer directly asks for clarification and explores the properties of a specific function, which is highly beneficial for the authors. They are seeking to understand a theoretical concept and its practical implications. The suggestions to seek intuition and explore specific distributions are concrete steps that the authors can take to improve their understanding. Therefore, the review point is 5 as it directly addresses a need for clarification and provides actionable steps for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a question seeking clarification, which is an implicit request for action. While they don't explicitly state 'fix this,' they are pointing to a potential issue (the difference between equations) that needs addressing. However, the request itself doesn't provide a concrete action for the author to take. The reviewer is asking *what* is different, not *how* to make them the same or *why* they are different.", "grounding_specificity_rationale": "The reviewer explicitly refers to equations (7) and (10) and the terms X and H^(1). This demonstrates strong grounding specificity, as the reviewer can accurately pinpoint the relevant parts of the paper and the specific elements within those parts that are causing confusion.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question, which is a request for information rather than a statement of opinion or assertion of a problem. Therefore, verifiability is not the primary aspect being evaluated here.", "helpfulness_rationale": "The reviewer's comment is a question seeking clarification. While it is relevant to the author's work and points to a potential area of confusion, it does not directly instruct the author on how to improve their draft. It is more of a request for information than a direct suggestion or critique. Therefore, it is helpful but not as directly impactful as a critique or suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a problem (lack of realworld applicability) but does not explicitly state a concrete action the authors should take to address it. While the reviewer suggests 'providing empirical evidence,' this is a general suggestion and doesn't detail how the authors should go about obtaining or presenting this evidence. The reviewer's statement is a statement of a problem, not a direct instruction on how to solve it.", "grounding_specificity_rationale": "The reviewer mentions 'the applicability of the model to realworld diffusion process' as a problem. While this is a specific area, the reviewer does not pinpoint a specific part of the paper or a specific detail within that process that needs improvement. The suggestion of 'providing empirical evidence' is general and doesn't specify where or how this evidence should be provided. The reviewer identifies a general area of weakness but doesn't specify the exact location or detail within the paper that needs improvement.", "verifiability_rationale": "The reviewer states a problem ('the main concern with the paper is the applicability of the model to realworld diffusion process') and suggests a solution ('providing empirical evidence'). However, the reviewer does not make a claim that requires verification. The statement of the problem is a general observation, and the suggestion of providing evidence is a proposed solution, not a claim that needs logical reasoning, common knowledge, or external references to support. The reviewer points out a limitation but doesn't make a claim that needs verification.", "helpfulness_rationale": "The reviewer identifies a relevant and important area for improvement (the realworld applicability of the model). They highlight a gap in the current work and suggest a general direction for improvement (providing empirical evidence). While the reviewer doesn't provide specific, actionable steps on how to achieve this, they do point out a significant weakness in the paper. This makes the review point 3 in identifying a problem and suggesting a general solution, even if the solution isn't fully detailed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the method is only tested on two datasets. While it doesn't directly imply a need for more datasets, the statement is clear and points to a limitation in the experimental scope. Therefore, it can be considered explicit. However, it is vague because it doesn't specify which datasets were used or why only two were chosen. It also doesn't suggest concrete actions to improve the performance based on this limitation.", "grounding_specificity_rationale": "The comment explicitly mentions 'two datasets' but does not identify which specific datasets were used. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses. However, the comment does specify what is being addressed \u2013 the number of datasets \u2013 and how this relates to the performance evaluation. Thus, the specificity is somewhat clear.", "verifiability_rationale": "The comment contains a claim: 'The method is only tested on two datasets.' However, it does not provide any justification or evidence for this claim. There are no logical reasoning, common knowledge, or external references provided to support this statement. Therefore, the verifiability is 1.", "helpfulness_rationale": "The comment identifies a limitation in the experimental setup (only two datasets) and asks for more information. This points to a need for the authors to provide more details about their current testing. While it doesn't directly ask for a solution, it highlights a missing piece of information that is crucial for evaluating the method's performance. Therefore, it is 3 in identifying a gap in the provided information."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The statement identifies a potential issue (lack of novelty) but doesn't specify how to address it or what concrete changes are needed. It's a critique, not a solution.", "grounding_specificity_rationale": "The reviewer doesn't specify which section or aspect of the paper they are referring to. They are making a broad statement about the *general* contribution.", "verifiability_rationale": "The reviewer *states* that alternatives exist. While they don't provide specific examples or citations *within this review point*, the statement itself is a claim that can be supported or refuted by evidence.", "helpfulness_rationale": "The reviewer identifies a *potential* area for improvement (acknowledging existing alternatives) but doesn't provide concrete suggestions or point to specific weaknesses. The feedback is present but lacks actionable detail."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action of plotting the relative weight change after unlearning. This is a direct and actionable suggestion for the authors to visualize and understand the impact of the unlearning process on different layers.", "grounding_specificity_rationale": "The reviewer mentions 'relative weight change' and 'plot'. This directly refers to the model's weights and the visualization technique. The reviewer is very specific about the *what* and *how* of the visualization, indicating strong grounding specificity.", "verifiability_rationale": "The reviewer provides a clear method for verification: 'plot the relative weight change after unlearning to see which layers are affected the most'. This is a logical and verifiable suggestion, providing a concrete way to analyze the model's behavior.", "helpfulness_rationale": "The reviewer's suggestion directly addresses a potential need for the authors to understand layerwise impact on model weights after unlearning. This provides a concrete visualization technique to analyze and potentially improve their unlearning method. It offers a clear, actionable next step for the authors to gain insights into their model."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states that the novelty of the paper appears to be rather limited and provides a reason for this assessment by comparing it to the ENCODE work. This is a direct statement of an actionable point.", "grounding_specificity_rationale": "The reviewer mentions 'methodology aspect', 'ENCODE part' and 'decomposition part'. While they don't specify the exact section or table number, they clearly point to specific areas within the paper, making the grounding explicit. They also explain why they believe the novelty is limited in the methodology and how the decomposition is incremental, providing detail about the issues within these specific parts.", "verifiability_rationale": "The reviewer makes a claim about the paper's novelty being limited and compares it to the ENCODE work. However, they do not provide any specific examples, citations, or logical reasoning to support this claim. The statement is an opinion without evidence.", "helpfulness_rationale": "The reviewer identifies a potential limitation in the paper's novelty and points to specific areas (methodology, ENCODE, decomposition) for improvement. While this highlights areas for attention, the lack of verifiable evidence to support their claim makes the feedback less actionable and potentially confusing for the authors. It raises a flag about the novelty of the work without providing concrete evidence."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the question 'What is the domain of the inputs?' and provides the suggestion 'They are lying in the same sphere, not mentioned in the paper.' This is an explicit action (asking a question) and a concrete suggestion (identifying a potential issue). The implications are clear and directly address the inputs.", "grounding_specificity_rationale": "The comment explicitly asks 'What is the domain of the inputs?'. However, it does not specify which inputs or where in the paper this 'same sphere' is relevant. The grounding is weak because the authors cannot confidently determine which part the comment addresses beyond a general question about the data.", "verifiability_rationale": "The comment contains a claim: 'They are lying in the same sphere, not mentioned in the paper.' However, this claim is not supported by any logical reasoning, common knowledge, or external references. The suggestion lacks justification and examples, making it 1.", "helpfulness_rationale": "The comment identifies a potential issue (redundant inputs) but does not provide a concrete solution or actionable steps for the authors to take. While the problem is pointed out, the lack of a clear path forward makes it 3 but lacking in actionability and verifiability."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the request to compare the performance of the proposed CLN algorithm with 'this work'. This is a clear and direct instruction, making it an explicit action. Furthermore, the request is concrete in its goal \u2013 to compare performance \u2013 which is a specific direction for the authors to take. While the exact performance metric isn't specified, the request itself is actionable.", "grounding_specificity_rationale": "The reviewer refers to 'A' and 'CLN (region proposal generation algorithm)'. While they don't provide a specific section or figure number, the term 'region proposal generation algorithm' strongly suggests where the proposed method is described. This requires the authors to infer the location, making the grounding weakly grounded. The specificity of the request is underspecified as the reviewer doesn't mention a particular performance metric or comparison method. Therefore, the grounding is underspecific.", "verifiability_rationale": "The reviewer is not making a claim. They are asking a question about the performance comparison. There is no assertion of superiority, inferiority, or any other opinion. The request is a request for information, not a statement that needs verification.", "helpfulness_rationale": "The reviewer is asking for a performance comparison, which is a relevant and useful piece of information for evaluating the proposed CLN algorithm. This directly addresses the functionality and effectiveness of the algorithm. The request is clear and directly points to a potential weakness (the performance of the CLN algorithm) that the authors might be facing or curious about. Therefore, it provides a clear direction for the authors to seek information and understand the algorithm's performance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a specific weakness: 'presentation is at times too equationdriven and notation, especially in chapter 3, quite convoluted and hard to follow.' This indicates a clear issue that needs addressing. Furthermore, the reviewer suggests a concrete action: 'An illustrative figure of the key concepts in section 3 would have been helpful.' This direct suggestion of an improvement demonstrates a clear and actionable step the authors could take. The combination of identifying a problem and suggesting a specific action makes this review point 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'chapter 3' when suggesting an improvement: 'An illustrative figure of the key concepts in section 3 would have been helpful.' This precise identification of the section where the issue lies demonstrates strong grounding. The reviewer doesn't just say 'section 3 is unclear'; they specify 'an illustrative figure of the key concepts.' While not pinpointing every detail, this points to a concrete area for improvement within the section, making it highly specific.", "verifiability_rationale": "The review point does not contain a claim that requires verification. The reviewer identifies a problem ('presentation is at times too equationdriven...') and offers a suggestion ('An illustrative figure...'). This is a suggestion for improvement, not a critique that needs to be supported by evidence or references. Therefore, it does not fall into the 'X' category (X) as it doesn't present a statement that needs to be justified. However, it also doesn't present a claim that is verifiable. The focus is on suggesting a solution rather than making a judgment that needs support.", "helpfulness_rationale": "The reviewer clearly identifies a likely area of weakness for the authors: the presentation being 'equationdriven and notation hard to follow.' They directly address this weakness by suggesting a concrete improvement: 'An illustrative figure of the key concepts in section 3 would have been helpful.' This suggestion is directly aimed at resolving the identified issue. By pointing out a specific problem and offering a practical solution, the reviewer provides valuable guidance for the authors, making this review point 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential conflict between the definition of 'minimal conditional dependence' and Equation (7). They specifically suggest that if the set Z' is considered to be the empty set, then according to the definition, x and y should be independent given W. However, Equation (7) indicates that x and y are not independent given W. This is an explicit statement of a potential issue that requires clarification.", "grounding_specificity_rationale": "The reviewer refers to 'Lemma 2,' 'Eq (7),' and 'minimal conditional dependence,' explicitly pointing to specific parts of the paper. This strong reference makes the grounding very specific.", "verifiability_rationale": "The reviewer states a claim: 'Second rule in Lemma 2, i.e., Eq (7) and the definition of minimal conditional dependence seem to be conflicting.' While the reviewer identifies a potential conflict, they do not provide external references or logical reasoning to support or refute this claim within the review point itself. The verifiability depends on the reader's ability to understand the referenced concepts and equation.", "helpfulness_rationale": "The reviewer identifies a potential point of confusion regarding the relationship between 'minimal conditional dependence' and 'Eq (7)'. This could be helpful for the author to understand a potential flaw in their understanding or the lemma. However, without further clarification or context from the author, the helpfulness is conditional on the accuracy of the reviewer's assessment."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly mentions 'subscripts' and suggests 'enhancement for better readability and aesthetic appeal'. While the suggestion is general, it clearly points to an actionable change related to the identified element. The reviewer could reasonably infer the need for clearer labeling or formatting of the subscripts to improve readability.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'figure3' and specifically mentions 'subscripts'. The reviewer also states the issue as 'could be enhanced', which clearly identifies the specific part of the paper being addressed and the nature of the problem.", "verifiability_rationale": "The reviewer states 'I noticed that the visual presentation, specifically the subscripts, could be enhanced for better readability and aesthetic appeal.' This statement identifies a problem (subscripts are not readable/aesthetic) and suggests a solution (enhancement). While the suggestion is not a definitive statement requiring external references, it implies a flaw in the current presentation and a need for action.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion directly related to the figure in question. They identify a specific element ('subscripts') and propose a concrete improvement ('enhancement for better readability and aesthetic appeal'). This directly points to a change the authors can make to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points to a specific sentence in the paper that explains the difference between Batch Normalization and Online Normalization regarding gradient estimation. The sentence explicitly states the problem with Batch Normalization (using minibatch for gradient bias) and contrasts it with Online Normalization (no dependency on batch size). While the paper identifies a difference and attributes it to a specific mechanism, it doesn't explicitly state an action or suggestion based on this observation. The reviewer's confusion highlights a lack of clear action or guidance stemming from this statement.", "grounding_specificity_rationale": "The reviewer directly references a sentence in the paper that discusses the gradient bias issue. This provides strong grounding as the paper explicitly mentions the relevant section (the explanation of the difference). However, the reviewer is asking *why* Online Normalization is unbiased and Batch Normalization is biased. The paper mentions the *difference* but doesn't explicitly state which is which in a single, clear statement with a strong action. It implies the difference but doesn't explicitly state the unbiased/biased nature in a single, clear statement with a strong action.", "verifiability_rationale": "The reviewer expresses confusion about the paper's claim regarding the bias difference between Batch Normalization and Online Normalization. This constitutes a claim that the paper makes. However, the paper *mentions* the difference but doesn't provide a detailed explanation or evidence to *support* the claim that Online Normalization is unbiased and Batch Normalization is biased. The reasoning is presented as a statement rather than a wellsupported argument, making it somewhat underjustified.", "helpfulness_rationale": "The reviewer explicitly states they will 'stay with my original score.' This indicates that the reviewer did not find the review point helpful in understanding the paper or improving their work. The confusion expressed by the reviewer suggests the point did not provide clear or actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the issue: 'equations are crammed together, captions are too close to the figures.' However, it does not provide specific guidance on how to address these issues. It identifies the *what* but not the *how* to implement the action.", "grounding_specificity_rationale": "The comment explicitly mentions 'equations,' 'captions,' and 'figures,' clearly identifying the specific parts of the paper being addressed. This is a clear indication of full grounding. It also specifies the *problem* with these parts, making it specific to the referenced elements.", "verifiability_rationale": "The comment contains a claim: 'This by itself is grounds for rejection.' This claim is verifiable based on the stated 9page paper limit. The reasoning is clear and directly supports the claim.", "helpfulness_rationale": "The comment clearly identifies a significant issue (poor layout) and points to specific areas within the paper that need adjustment. While it doesn't provide specific solutions, it highlights a clear weakness that requires attention, making it helpful for the authors to know this draft is at risk of rejection due to these formatting issues."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly states that 'Technical details and formulations are limited' and infers that this is a problem by stating 'It seems that the main novelty reflected in the scheme or procedure novelty.' While it identifies an issue, it doesn't specify how to address it or what concrete actions the authors should take.", "grounding_specificity_rationale": "The comment generally refers to 'Technical details and formulations' and 'scheme or procedure' without specifying which exact parts are lacking detail or where the novelty is most prominent. This makes it difficult for the authors to pinpoint the specific area needing improvement.", "verifiability_rationale": "The comment contains claims such as 'Technical details and formulations are limited' and 'It seems that the main novelty reflected in the scheme or procedure novelty.' However, it does not provide any logical reasoning, common knowledge, or external references to support these claims. The justification is implied but not explicitly stated or verified.", "helpfulness_rationale": "The comment identifies a potential area for improvement ('Technical details and formulations are limited') but fails to explain why this is a problem or how it affects the work. It also doesn't suggest concrete actions or improvements for the authors to implement. The lack of specific guidance makes it difficult for the authors to act on this feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the ambiguity of 'local interactions' by asking a question about its definition. This indicates an implicit action: the reviewer wants the authors to clarify what they mean by 'local interactions'. While the action is not directly stated as a request to define it, the question itself is a clear indication of a need for clarification. The reviewer points to two possible interpretations ('time window' vs. 'modality'), suggesting the ambiguity is not fully resolved by the current phrasing.", "grounding_specificity_rationale": "The reviewer's comment is grounded in the term 'local interactions' by directly referencing it. However, the grounding is weak because the reviewer does not specify *which* aspect of 'local interactions' is unclear. They offer two possibilities ('time window' or 'modality') but do not commit to one or narrow down the ambiguity. The comment lacks a clear specification of the exact part of the paper or concept being addressed beyond the term itself.", "verifiability_rationale": "The review point itself does not contain a claim. It is a question posed to the authors to seek clarification. Therefore, the concept of verifiability does not apply to this review point as there is no statement that requires evidence or justification.", "helpfulness_rationale": "The review point is helpful in that it identifies a potential ambiguity in the term 'local interactions'. By asking for clarification, the reviewer is encouraging the authors to be more precise in their terminology. This can prevent confusion and ensure that the concept is understood consistently. While it doesn't provide a direct solution, it prompts a necessary step for improving the clarity of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a discrepancy between the claimed results and the actual outcomes of the constrained method, and suggests adding the method as a concrete action to address the lower validity and diversity.", "grounding_specificity_rationale": "The review point explicitly mentions 'the Molecule generation experiment (Table.3)' and refers to 'validity and diversity' as the metrics affected.", "verifiability_rationale": "The review point presents a statement about the constrained method yielding lower validity and diversity, but it does not contain a claim that requires external verification or justification within the provided text.", "helpfulness_rationale": "The review point directly identifies a contradiction between the paper's claims and experimental results, suggesting a concrete action (adding the constrained method) for the authors to consider."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks for clarification on how the archetype positions are updated after initialisation. While the reviewer identifies a specific area of the paper (Algorithm 2 and the update mechanism), the *specific* method of updating the positions is not explicitly stated in the provided text. The reviewer implies an action (asking for clarification) but doesn't provide concrete steps or details on how the update is performed. Therefore, the action is implicit and vague.", "grounding_specificity_rationale": "The reviewer refers to 'Algorithm 2' and the variables 'z_1, ..., z_k' which are initialised with 'FurthestSum'. However, the *specific* steps or logic for updating these archetype positions after initialisation are not explicitly detailed in the provided text. While the algorithm and initialization method are mentioned, the precise mechanism of the update is missing, making the grounding weak as the reviewer cannot confidently determine the referenced part.", "verifiability_rationale": "The reviewer points out a lack of clarity in the update mechanism of Algorithm 2. The reviewer states, 'it is not quite clear to me how the archetype positions are updated after initialisation.' This statement itself can be considered a claim that requires justification. The paper describes the initialisation but lacks a clear explanation or reference for the update process. Therefore, the claim is somewhat justified by the reviewer's observation of a lack of clarity.", "helpfulness_rationale": "The reviewer's question directly addresses a potential area for improvement in the algorithm's description. By asking how the archetype positions are updated, the reviewer is seeking a crucial detail that would enhance their understanding and potentially the implementation of the algorithm. While the question itself is not a critique of the outcome, it points to a missing piece of information that would be helpful for the reader. Therefore, the comment is 3 as it highlights a missing detail that would be beneficial to understand."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly lists several actions the authors should take, such as providing recording parameters, preprocessing steps, and the resting state condition. These are direct and concrete actions that the authors can readily address. The reviewer also suggests including the number of regions in the parcellation, which is a specific action. The reviewer's point is clear and directly points to what needs to be done.", "grounding_specificity_rationale": "The reviewer provides specific details about what information is missing, including 'recording parameters for the MRI', 'preprocessing steps', 'was the restingstate recorded under eyesopen or eyesclosed condition?', and 'the number of regions in the parcellation'. These are all specific and identifiable parts of the paper. The reviewer also implies that this information should be in the 'main text', which is a clear indication of grounding. The information is not just general or implied, but specific and actionable.", "verifiability_rationale": "The reviewer states that 'important information about the empirical study is missing'. This is a claim that needs to be addressed. While the claim itself is somewhat subjective (what constitutes 'important'), the reviewer's suggestion to provide specific details like 'recording parameters for the MRI', 'preprocessing steps', and 'the number of regions in the parcellation' provides a basis for verification. The claim is 3 because the *type* of information is specified. However, it lacks external references, which would make it 5.", "helpfulness_rationale": "The reviewer provides a list of concrete suggestions for the authors, including specific details about the empirical study. The reviewer explicitly states that this information is 'missing' and should be included in the 'main text'. These are all actionable and directly address potential gaps in the authors' understanding or presentation. The reviewer's suggestions are clear and directly point to areas where the authors can improve their work. The reviewer's point is not just a general comment but a specific call for action."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the problem (datasetspecificity of AU relationships) and suggests a clear, actionable improvement (performing crossdataset experiments). This direct identification of a weakness and a specific solution makes the comment 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'crossdataset experiments' as a way to address the limitations of AUbased methods. This directly identifies the specific part of the paper being addressed, making the comment fully grounded. The reviewer also explains *why* this is important, making it specific as well.", "verifiability_rationale": "The reviewer makes a claim that the paper is lacking and provides a specific reason (the datasetspecificity of AU relationships). This claim is supported by logical reasoning and the identified problem. While the claim is verifiable, it could be strengthened by explicitly referencing Figure 1 if possible, but the core point about verifiability is present.", "helpfulness_rationale": "The reviewer provides a specific and actionable suggestion (crossdataset experiments) to address a clear limitation (datasetspecificity of AU relationships). This directly helps the authors improve their understanding and application of AUbased methods. The suggestion is concrete and directly addresses a practical concern for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'I would have liked more description', indicating an intention to add more detail. However, it lacks specific guidance on *how* to achieve this, making it somewhat vague on the concrete action to be taken.", "grounding_specificity_rationale": "The comment explicitly mentions 'the Starcraft environment', which grounds the feedback to a specific part of the paper. However, it does not specify *what* aspect of the Starcraft environment requires more description, making it not very specific.", "verifiability_rationale": "The comment is a statement of preference, not a claim requiring verification. There is no logical reasoning, common knowledge, or external references provided to support the statement.", "helpfulness_rationale": "The comment clearly expresses a desire for more information about the Starcraft environment. This is a valid feedback point that can help the authors improve their draft by providing more context or details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly criticizes the statement about overparametrization and provides a counterargument by stating 'overparameterization seems to be very helpful for supervised learning of deep neural networks in practice...'. This directly identifies an action: 'correct the statement'. Furthermore, the reviewer provides a reason for this correction ('overparametrization seems to be very helpful...') and offers supporting evidence ('Also, I have seen a number of theoretical work showing the benefits...'). This makes the criticism concrete and actionable.", "grounding_specificity_rationale": "The review point criticizes a general statement about overparameterization: 'overparametrization invariably overfits the data and results in worse performance'. While the reviewer mentions the paper being criticized by line numbers (4748), the criticism itself is about the general principle, not a specific part of the paper. The reviewer does not explicitly identify a unique element or section of the paper being addressed. The grounding is weak because the reviewer is making a general point about overparameterization and providing a general counterargument.", "verifiability_rationale": "The review point contains a claim: 'overparameterization invariably overfits the data and results in worse performance'. This claim is verifiable because the reviewer provides a counterargument ('overparameterization seems to be very helpful for supervised learning of deep neural networks in practice...') and offers supporting evidence ('Also, I have seen a number of theoretical work showing the benefits...'). This provides logical reasoning, examples (implied through 'several theoretical work'), and external references (implied through 'theoretical work').", "helpfulness_rationale": "The review point is 5 because it directly criticizes a potentially harmful statement about overparameterization and offers a clear alternative viewpoint ('overparameterization seems to be very helpful...') with supporting evidence ('I have seen a number of theoretical work showing the benefits...'). This provides the authors with a clear direction to consider and potentially address the limitations of overparameterization."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests improvements such as comparing the processing efficiency of training and testing with existing work and discussing the parsing model. These are explicit suggestions for improvement. However, the reviewer does not specify *how* they would perform the efficiency comparison or what specific aspects of the parsing model they would discuss, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions specific details about the training process, such as the 'pixel level' training, the use of 'landmarks' for sparsity, the independent training on 'all font images and characters,' and the 'four types of factors' in the parsing model. These are specific elements of the method being described. The reviewer also explicitly mentions comparing efficiency with existing work, which is a clear action.", "verifiability_rationale": "The reviewer states that the shape model is trained in a 'timeconsuming' manner and suggests discussing the parsing model. The claim about the training process being 'timeconsuming' is verifiable as it describes an observed characteristic of the method. The suggestion to discuss the parsing model is also a clear action, although the reviewer does not provide any justification for why this discussion is necessary or beneficial.", "helpfulness_rationale": "The reviewer provides concrete suggestions for improvement, such as comparing the processing efficiency of training and testing with existing work and discussing the parsing model. These suggestions are directly related to potential weaknesses in the work and offer clear directions for improvement. The reviewer's comments are actionable and provide valuable insights to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests using 'other domain adaptation methods' to improve performance. This is an explicit action pointing to a specific area for change. The reviewer directly identifies the need to explore alternative methods, which is a clear and actionable suggestion.", "grounding_specificity_rationale": "The reviewer mentions 'the domain adaptation method here is a very old and simple method'. This statement explicitly identifies the specific method being criticized by name and provides characteristics (old and simple). This demonstrates a clear grounding of the comment in a specific part of the paper and its properties.", "verifiability_rationale": "The reviewer makes claims such as 'the adversarial attack or correction method and the domain adaptation method used by the authors are proposed by prior work' and 'the adopted domain adaptation method here is a very old and simple method'. These claims require verification through citations and comparison to existing literature. While the claims are not fully supported with specific examples or references within the review point itself, they are verifiable by examining the paper's content and external knowledge of the field.", "helpfulness_rationale": "The reviewer's suggestion to use 'other domain adaptation methods' is a clear and actionable piece of feedback. This directly addresses a potential weakness (lack of innovation and simplicity of the chosen method) and provides a concrete direction for improvement. The suggestion is welldefined and directly actionable for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of discussion regarding the prompt dataset creation and its source. This is an explicit action that the authors should take. Furthermore, the reviewer provides concrete information about what is missing (discussion of prompt dataset creation and its source). Therefore, the review point is both explicit and concrete.", "grounding_specificity_rationale": "The review point directly mentions 'prompt dataset creation' and 'its source'. This allows the authors to accurately pinpoint the specific aspect of the paper being addressed. Therefore, the grounding is full. While the reviewer doesn't specify *how much* discussion is needed, they clearly indicate that a discussion is missing, making the specificity somewhat underspecified but still present.", "verifiability_rationale": "The review point does not contain a claim in the sense of an assertion or opinion. Instead, it points out a deficiency: the lack of discussion on prompt dataset creation. While this could be considered a 'claim' in the sense that it identifies a missing element, there is no supporting evidence or justification provided. Therefore, it is not 5. If we were to extract a claim, it would be something like 'The paper should discuss prompt dataset creation,' but the review point itself doesn't provide any evidence for this claim.", "helpfulness_rationale": "The review point directly identifies a clear area for improvement in the authors' draft \u2013 the lack of information on prompt dataset creation. This is a valuable piece of feedback that directly addresses a potential weakness. The reviewer is asking the authors to include this information, which is a clear and actionable request. Therefore, the review point is 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states 'Very difficult to follow the motivation of this paper.' This indicates an implicit actionability, as the reviewer identifies a problem (difficult to follow) but doesn't explicitly state what needs to be changed. While the reviewer doesn't provide a concrete action, they clearly express a need for clarification, which implies an action is required. However, the lack of a specific, direct instruction makes it only 2.", "grounding_specificity_rationale": "The review point states 'Very difficult to follow the motivation of this paper. And it looks like an incremental engineering paper.' This comment is 1 at all. The reviewer does not identify a specific part of the paper that is difficult to follow. They make a general statement about the nature of the paper without pinpointing a specific section, table, figure, or unique aspect. The phrase 'it looks like an incremental engineering paper' is a general assessment and does not specify what is unclear.", "verifiability_rationale": "The review point contains a claim: 'it looks like an incremental engineering paper.' However, this claim is not verifiable. The reviewer makes a general assessment about the paper's nature but does not provide any specific evidence, references, or logical reasoning to support this claim. There is no justification for why the paper is considered an 'incremental engineering paper'.", "helpfulness_rationale": "The review point is a critique of the paper's nature ('it looks like an incremental engineering paper') without offering any specific suggestions for improvement. While the reviewer identifies a potential weakness ('difficult to follow the motivation'), they do not provide concrete steps the authors should take to address this. The comment is a general statement about the paper's characteristics rather than specific, actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of 'ablation' on the weighting method of the crossentropy loss. While the reviewer doesn't provide specific details on *how* to ablate it, the suggestion is clear and directly actionable. The reviewer also connects this suggestion to a specific issue they observed ('the game has repetitive background sounds'), which implies a concrete understanding of the problem and how the proposed action might address it.", "grounding_specificity_rationale": "The reviewer grounds the suggestion to the specific issue of 'repetitive background sounds' observed in the Atlantis method. This demonstrates a clear understanding of the paper's content and identifies a specific area for improvement. The reviewer also suggests a specific *action* ('ablation') related to this grounding, making the grounding concrete.", "verifiability_rationale": "The reviewer makes a claim ('The authors note...') and provides a specific example ('This is a scenario I'd expect the weighting might have helped remedy') to support their suggestion. This claim is verifiable based on the reviewer's understanding of the Atlantis method and their expectation of how the weighting might affect it. The reasoning is logical and directly related to the identified issue.", "helpfulness_rationale": "The reviewer provides a clear suggestion ('suggestion to ablate weighting') and connects it to a specific problem ('repetitive background sounds') observed in the paper. This suggests a clear and actionable improvement. The reviewer's tone is positive, implying the suggestion is valuable and could help the authors improve their work. The suggestion is directly related to the identified issue and offers a concrete solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a weakness but does not explicitly state how the authors should address it. While it suggests new datasets and benchmarks, it lacks concrete steps on implementation.", "grounding_specificity_rationale": "The review refers to general areas of the paper (column operations, benchmark papers) but does not specify a particular section, table, or figure where the lack of novelty is evident.", "verifiability_rationale": "The review makes a claim about the lack of novelty but does not provide specific evidence or references within the review point itself to support this claim.", "helpfulness_rationale": "The review identifies a valid concern and offers some relevant ideas, but it lacks explicit guidance on how to implement these suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment identifies a problem ('experiments are only done on one game environment') but does not specify how to address it or make the necessary changes. It lacks concrete steps or actionable items for the authors to follow.", "grounding_specificity_rationale": "The comment is too general and does not specify which game environment or aspect of the experimental setup is limited. It lacks a clear reference to a specific part of the paper.", "verifiability_rationale": "The comment points out a valid limitation ('experiments are only done on one game environment') but does not provide any specific evidence, reasoning, or references to support how this limitation should be addressed or how the suggested improvements can be implemented.", "helpfulness_rationale": "The comment identifies a valid weakness ('experiments are only done on one game environment') but does not offer specific, actionable, or wellsupported suggestions for improvement. It lacks the 'howto' element necessary for truly constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment implicitly states that the authors need to explain the importance of the assumptions and provide examples. However, it does not explicitly state the action the authors should take or how to achieve it.", "grounding_specificity_rationale": "The comment explicitly mentions the assumptions of bounded variance and bounded gradients, providing full grounding. However, it does not specify what is wrong with these assumptions or provide concrete examples to illustrate the importance of relaxing them.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a suggestion for the authors to provide more information.", "helpfulness_rationale": "The comment is a suggestion for the authors to improve their draft by providing more context and justification. While it is a valid point, it does not directly critique the work or offer concrete feedback on specific weaknesses."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem of slow testing and low accuracy, and provides specific details such as the dataset (ImageNet), models (AlexNet and ResNet18), and metrics (time and accuracy). This makes the action very concrete and directly actionable for the authors.", "grounding_specificity_rationale": "The reviewer mentions specific elements of the paper, including the dataset (ImageNet), models (AlexNet and ResNet18), and metrics (time and accuracy). This allows the authors to accurately pinpoint the section, table, figure, or unique aspect being addressed, making the grounding fully specific.", "verifiability_rationale": "The reviewer makes a claim about the performance of the implementation and provides specific numerical data (time and accuracy) to support this claim. This makes the claim thoroughly supported and verifiable.", "helpfulness_rationale": "The reviewer identifies a specific performance issue with a particular implementation and suggests a potential solution. This provides clear, actionable, and constructive feedback that empowers the authors to improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer's request is not explicitly stating what needs to be changed, but rather asking for more explanation. While the implicit request is to add detail to the experimental setting, the action of adding detail is not directly requested. The questions about Figure 3 are implied, but not explicitly stated as a request for clarification. Therefore, the action is implicit and not directly actionable.", "grounding_specificity_rationale": "The reviewer mentions 'Fig 3' and 'experimental setting', which grounds the comment to specific parts of the paper. However, the level of specificity is limited. The reviewer doesn't pinpoint a *unique* section, table, or figure, nor does the request for 'correspondence' imply a deep understanding of the content. The grounding is weak because the authors would need to infer the relevance of Figure 3 and the need for more detail on the experimental setting.", "verifiability_rationale": "The reviewer poses questions about the correspondence of learning curves and MPHATE, the purpose of examining the curves, the interpretation of 'worse performing model', and the presence of accuracy numbers. These questions are based on logical reasoning about what information is needed to understand the results. However, the reviewer does not explicitly state that these are claims that require justification or are based on external references. The questions themselves are verifiable, but the underlying intent isn't explicitly framed as a claim needing verification.", "helpfulness_rationale": "The reviewer's comment is not directly instructing the authors on how to improve their draft. Instead, they are asking for more explanation and clarification regarding existing content (Figure 3 and experimental setting). While this can be helpful, it doesn't directly prompt the authors to make a specific change. The reviewer is essentially pointing out potential areas where the paper could be clearer, but doesn't actively guide the authors on what to add or modify. Therefore, the feedback is not directly actionable in terms of specific edits."}
{"actionability_label": "3. 3", "grounding_specificity_label": "5. 5", "verifiability_label": "4. 4", "helpfulness_label": "4. 4", "actionability_rationale": "The review point introduces a question about a potential modification to consistency training and suggests exploring labeled data for this purpose. While it implies a benefit (it might be beneficial), it doesn't explicitly state an action or propose a concrete change to the current method. The suggestion is openended, lacking specific details on how labeled data would be used or how this approach would differ from unlabeled methods.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'labeled data for consistency training' and 'graph anomaly detection' and names two specific papers related to graph contrastive learning. This clearly identifies the specific aspect of the paper being addressed and provides specific examples.", "verifiability_rationale": "The reviewer suggests that 'labeled data has exact labels, which might provide effective information for consistency training the model in dealing with the taks of graph anomaly detection.' This statement presents a claim about the potential benefits of using labeled data. While it doesn't provide specific examples of how this would work, it offers a general rationale based on the nature of labeled data and the task of graph anomaly detection. The reviewer also mentions the specific application of graph anomaly detection, which further grounds the suggestion.", "helpfulness_rationale": "The review point suggests exploring a potential modification to consistency training and connects it to a specific application (graph anomaly detection) and relevant research. While it doesn't propose a specific change to the author's current method, it highlights a potentially valuable direction and encourages the author to consider a different training approach. The suggestion is openended but points towards a potentially beneficial area of research."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states actions to be taken, such as 'reorganized' and 'further improved', and provides specific suggestions like 'experimental content...does not highlight the superiority of the method well' and 'experimental suggestions...should include'. These actions and suggestions are clear and point towards concrete steps the authors should undertake.", "grounding_specificity_rationale": "The review point refers to 'the experimental part' generally, without specifying a particular section, table, figure, or unique aspect. While it mentions 'experimental content,' it doesn't pinpoint the exact content or its location within the experimental section. Therefore, the grounding is weak as the authors cannot confidently determine the specific part being addressed.", "verifiability_rationale": "The review point contains a claim: 'The experimental part needs to be reorganized and further improved.' However, it does not provide any justification or evidence for why this is necessary or how the suggested improvements will achieve this. The suggestions are general and lack specific reasoning or references.", "helpfulness_rationale": "The review point identifies a weakness ('the experimental content...does not highlight the superiority of the method well') and offers a general suggestion ('experimental suggestions...should include'). While it doesn't provide specific details for improvement, it clearly points to an area that needs attention and offers a general direction for action. Therefore, it is 3 as it guides the authors towards improvement, even if the specifics are missing."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point is 5. The reviewer explicitly states a concern about the classification error of the proposed network compared to softmax and provides a clear action: 'report the classification accuracy of the proposed classifier on ImageNet data? Some theoretical justifications, if possible, would be great for the issue.' This action is concrete and directly addresses the concern.", "grounding_specificity_rationale": "The review point demonstrates good grounding specificity. The reviewer specifies 'ImageNet data' as the context for evaluating the classification accuracy, making it clear which part of the paper is being addressed. Additionally, the request for 'theoretical justifications' further grounds the suggestion within a specific area of concern.", "verifiability_rationale": "The review point is 5. The reviewer identifies a claim: 'its classification error is universally as good as the standard softmax network.' This claim is supported by the suggestion to 'report the classification accuracy of the proposed classifier on ImageNet data' (logical reasoning) and the potential for 'theoretical justifications' (external references or common knowledge about classification performance). The evidence provided is sufficient to understand how to improve the work.", "helpfulness_rationale": "The review point is 5. The reviewer directly addresses a potential weakness (potential tradeoff between OOD detection and classification accuracy) and offers concrete and actionable suggestions: 'report the classification accuracy of the proposed classifier on ImageNet data' and 'some theoretical justifications, if possible, would be great for the issue.' These suggestions are directly aimed at improving the authors' understanding and potentially refining their model."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a potential issue with a specific type of recognition list in a specific scenario (old vs. new judgments). They suggest considering the implications for the model's applicability. This is an explicit action the authors should take.", "grounding_specificity_rationale": "The reviewer mentions 'recognition lists' and 'old vs. new judgments,' clearly identifying the specific part of the paper or scenario they are referring to. They specify the potential issue within this context.", "verifiability_rationale": "The reviewer makes a claim about the applicability of a specific recognition model to a specific recognition scenario. While they don't provide direct evidence, the nature of the claim makes it potentially verifiable through further analysis or experimentation. The claim could be supported by logical reasoning about how exhaustive lists might be implemented in recognition tasks.", "helpfulness_rationale": "The reviewer clearly articulates a potential issue with a specific method in a specific context. They suggest considering the implications for the model's applicability, which is a constructive suggestion for improvement. The specificity of the scenario makes the feedback more targeted."}
{"actionability_label": "2", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises a concern about the fairness of the experimental comparison, suggesting the proposed method's pretraining might give it an advantage. While the reviewer points out the pretraining aspect, the action to be taken (investigating the pretraining of compared methods) is not explicitly stated in the review point itself. The reviewer identifies a potential issue but doesn't provide a direct action or solution.", "grounding_specificity_rationale": "The reviewer's comment is somewhat vague. While they mention 'experimental comparison' and 'pretrained model,' they don't specify *which* part of the paper or experiment they are referring to. The grounding is at a higher level, discussing the experimental setup rather than a specific section, table, or figure. The specificity is also limited as the reviewer doesn't detail *what* is wrong with the compared methods' pretraining.", "verifiability_rationale": "The reviewer's claim about the unfair comparison is presented as a hypothesis or suspicion. They state that the proposed method's pretraining might be an advantage but do not provide any evidence, citations, or logical reasoning to support this claim. The verifiability verification methods (logical reasoning, common knowledge, external references) are not applied or demonstrated in the review point.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the fairness of the experimental comparison. This could be helpful for the authors to understand potential biases in the comparison and potentially replicate or extend the experiments. However, the reviewer does not offer a concrete solution or suggestion to address the identified issue. The helpfulness is limited by the lack of a proposed remedy."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what the authors should do. While the reviewer points out a detail about the metadata used in the experiments and suggests an improvement, they do not provide specific instructions on how to change the metadata embeddings or identify the specific part of the paper that needs adjustment. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer mentions \"zeroshot learning on CUB dataset\" and \"metadata embeddings\" (or \"attribute\"). While they point to a specific experiment, the exact type of metadata is not explicitly identified. The reviewer does not clearly identify the specific section, table, figure, or unique aspect of the paper being addressed. The mention of 'attribute' is general and does not pinpoint a specific part of the paper.", "verifiability_rationale": "The reviewer makes a claim that \"better metadata embeddings options are available\" and suggests an experiment. However, they do not provide specific examples of these better embeddings or explicitly justify why the current \"attribute\" embeddings are suboptimal in this context. While they refer to external literature, this is not a direct verification of the current metadata within the review itself. The reasoning is present but lacks concrete examples or references to support the claim within the review.", "helpfulness_rationale": "The reviewer's point is relevant and suggests a direction for future research. While it is a valid suggestion, it does not directly help the authors identify a specific weakness in their current draft or provide immediate actionable steps to improve it. The suggestion is more of a recommendation for further investigation rather than a direct improvement strategy for the current work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a concrete action: 'include a plot with sparsity on the xaxis and performance on the yaxis'. This action is directly related to the criticism about the limited applicability of SGC and provides a clear path for improvement.", "grounding_specificity_rationale": "The review point mentions specific methods, 'SGC' and 'LoRA', and suggests a specific visualization technique, 'plot with sparsity on the xaxis and performance on the yaxis'. This demonstrates a strong grounding in the paper's content and a clear reference to the relevant aspect.", "verifiability_rationale": "The review point makes a claim about PEFT methods targeting computeconstrained scenarios, which is a generally accepted concept in the field. This claim, while not requiring external references, is logically sound and relevant to the discussion. Furthermore, the suggestion to include a plot is also a claim that *could* be verified by providing examples or data.", "helpfulness_rationale": "The review point is 5 as it directly addresses a specific weakness identified by the authors (limited applicability of SGC) and provides a concrete and actionable suggestion for improvement. The suggestion is clear and directly relevant to the problem."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point directly asks a question about the experimental setup (training times) and relates it to performance (similar performance of different methods) and asks for code. This immediately suggests it's actionable \u2013 the reviewer is asking for clarification or further investigation.", "grounding_specificity_rationale": "The reviewer is asking about the training time difference between the two datasets. However, they do not explicitly state which part of the paper they are referring to when asking this question. They are asking a general question about the experimental setup. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer is asking for clarification on the training time difference and code. While they are *asking* for something, they don't explicitly state *why* they find the existing information unconvincing or lacking justification. The justification comes from the *implication* of similar performance and the request for code.", "helpfulness_rationale": "The reviewer is asking for clarification on the training time difference and code. While these are helpful, the request for clarification is somewhat vague. The helpfulness is present, but it could be more specific."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for clarification on 'alternate formulations for Confidence Diversity (CD)' and 'why is entropy not a good measure of 'amount of spreading of teacher predictions over the probability simplex among different (training) samples''. These are direct requests for information and explanations, making it 3 for the authors to understand the concept better. However, it doesn't identify a specific problem that needs fixing.", "grounding_specificity_rationale": "The reviewer explicitly names 'alternate formulations for Confidence Diversity (CD)' and 'why is entropy not a good measure of 'amount of spreading of teacher predictions over the probability simplex among different (training) samples''. These are very specific concepts, and the reviewer also mentions the location of the question (line 113 and 115), which helps ground the request. This makes the grounding very specific.", "verifiability_rationale": "The reviewer asks for an 'explanation of alternate formulations for Confidence Diversity (CD)' and a 'justification for why entropy is not a good measure'. These are claims that can be supported by referencing existing literature on uncertainty measures and the properties of entropy. While the paper might explain CD, the specific reasoning behind why entropy is not suitable could benefit from further elaboration or citation of relevant literature, making it 4.", "helpfulness_rationale": "The review point directly addresses a potential point of confusion for the authors regarding the definition and measurement of Confidence Diversity (CD). The request for clarification on 'why entropy is not a good measure' is particularly valuable, as it seeks to understand a specific methodological choice. The reviewer is asking for targeted information that is likely to improve the authors' understanding of the concept. While it doesn't ask for a solution, it's a valuable piece of information for the authors to process, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a difference in the amount of time the human and model spent following the paper. While the reviewer explicitly states the time difference (1 hour vs. 15 hours), they don't explicitly state *what* is wrong with the human baseline *based* on this difference. The reviewer implies that the weaker followup time might be a reason for the weaker human baseline performance, but this is an inference rather than a direct action. Therefore, the actionability is somewhat implicit.", "grounding_specificity_rationale": "The reviewer refers to the 'human baseline' and the 'abstract' of the paper. While these are general sections, the reviewer doesn't provide a specific line number, paragraph, or figure number within the paper to pinpoint the issue. The reviewer refers to these sections by name, which can be considered a form of grounding, but it's not as precise as pointing to a specific element like a table or a unique aspect. Therefore, the grounding is somewhat specific.", "verifiability_rationale": "The reviewer makes a claim in the review point: 'In the abstract, the authors mention \"already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources\" which is a bit misleading given the 1 hour vs.' This is a claim that needs verification. The reviewer infers that the 1 hour of followup time might be a reason why the human baseline isn't already at a comparable level to the model's. While the reviewer doesn't provide explicit evidence or citations to support this claim, the reasoning is logical \u2013 less time spent following should lead to a weaker baseline. Therefore, the claim is 3 as it's supported by logical reasoning, even if specific evidence isn't provided.", "helpfulness_rationale": "The reviewer identifies a potential misinterpretation in the abstract regarding the human baseline's performance. This could be helpful for the authors to understand the correct interpretation of the results. However, the reviewer doesn't explicitly state *how* the authors should rephrase the abstract or *what* the correct CER/BLEU should be. They point out a potential issue but don't offer concrete actionable steps for the authors to take. Therefore, the review point is 3 as it highlights a relevant issue, but it doesn't provide direct guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a potential issue with the assumption for termination states in the data, suggesting it might be 'strong'. However, they do not explicitly state an action or provide concrete steps to address this. While they imply a problem, the lack of a direct recommendation makes it difficult to assess actionability fully.", "grounding_specificity_rationale": "The reviewer refers to 'termination states' as a specific aspect of the data. This provides some level of grounding. However, they do not explicitly connect this to a specific section, table, figure, or unique element within the submitted paper. They make a general statement about the cost of labeling, which is vague and lacks specificity regarding the data itself.", "verifiability_rationale": "The reviewer makes a statement about the 'cost of manual labeling' in the 'general case'. This constitutes a claim. However, they do not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a general observation without any backing, making it 1.", "helpfulness_rationale": "The reviewer points out a potential inefficiency in the data labeling process, specifically mentioning the cost of labeling 'termination states'. This is a valuable observation as it highlights a practical challenge in data creation. While they don't explicitly propose a solution, the implication is that researchers would benefit from exploring more efficient labeling methods. The reviewer's statement is directly relevant to improving the data creation process and reducing costs, making it 5 in this context."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out that the paper fails to explicitly state how the number of bins is determined when choosing the number of bins for the ECE_sweep calculation. While the reviewer doesn't directly ask a question, they identify a missing detail that would allow the reader to understand the implementation. The action is implicit: the reviewer is inferring that the binning process is not clearly described. The lack of concreteness makes it 3 in the sense that the reader now knows there's a missing detail, but the action itself isn't directly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'nature of the contribution' and the 'binning process' in relation to the ECE_sweep calculation. They are pointing to a specific aspect of the paper that is unclear. The comment is grounded in identifying the missing information about how the number of bins is chosen. The specificity comes from the fact that the reviewer clearly identifies the missing detail as the binning process.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It's a statement of observation about the lack of clarity in the paper's description of the binning process. Therefore, it doesn't fit the 'Verifiability' category as it doesn't present a claim that needs supporting evidence.", "helpfulness_rationale": "The reviewer's comment is 5 because it clarifies a key point for understanding the contribution. By pointing out the ambiguity in the binning process, the reviewer provides a clear direction for the authors to seek more information or clarification. This directly addresses a potential point of confusion and aids in understanding the paper's contribution."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that 'none of them is used as a baseline' regarding RL methods. This directly identifies a missing element and provides a clear action for the authors to consider in their experiments. The statement is concrete, specifying the type of method (RL) and its intended use (as a baseline).", "grounding_specificity_rationale": "The review point mentions 'RL methods' generally. While it identifies a category of methods that are missing as baselines, it does not specify a particular section, table, figure, or unique aspect of the paper where this omission is most relevant. The grounding is at the level of the method category rather than a specific part of the authors' work.", "verifiability_rationale": "The review point contains a claim: 'none of them is used as a baseline.' This claim could potentially be verified by examining the paper's experimental setup or related work section. While the review point itself doesn't provide evidence, the claim is stated clearly and is potentially verifiable.", "helpfulness_rationale": "The review point is helpful because it identifies a gap in the related work (the absence of RL methods as baselines) and suggests a concrete area for the authors to explore in their experiments. This provides a clear direction for improvement and helps the authors contextualize their work within the broader field of NMT."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the ambiguity surrounding the term \"Efficient Proxy\". While the reviewer doesn't explicitly state what they mean by \"Efficient Proxy\", they clearly indicate that the authors are unclear about whether it refers to a specific proxy or a general family of proxies. This is an explicit statement of a problem. However, the reviewer doesn't provide a concrete action or suggestion to resolve this ambiguity. The reviewer identifies the *area* of confusion (the definition of \"Efficient Proxy\") but doesn't offer a specific direction for the authors to take. Therefore, while the reviewer identifies a problem, they don't provide a clear action for the authors to follow.", "grounding_specificity_rationale": "The reviewer explicitly mentions the term \"Efficient Proxy\" in the review. This demonstrates that the reviewer can identify the specific part of the paper being addressed, even if the exact nature of that part (a specific proxy vs. a family) is unclear. The reviewer also explains the ambiguity, stating that the authors are unclear if it's a particular efficient proxy or efficient proxies in general. This explanation provides clear grounding of the issue within the paper. Therefore, the reviewer not only identifies the *area* of confusion but also clarifies the nature of the ambiguity.", "verifiability_rationale": "The reviewer states that the authors are \"unclear if the authors mean a particular efficient proxy or efficient proxies in general, \"is\" suggests that it is a particular proxy, but then there is not proxy called \"Efficient Proxy\", which suggests that it is rather referring to a family of efficient proxies;\" This statement directly expresses a belief about the authors' understanding. However, the reviewer does not provide any external references or logical reasoning to support this claim. The reviewer is simply stating their observation about the authors' potential confusion. There is X being verified in this review point.", "helpfulness_rationale": "The reviewer's comment is a statement of observation about the potential ambiguity of the term \"Efficient Proxy\". While this observation is valid and could be helpful for the authors to understand the potential confusion, the reviewer does not provide any specific actions or suggestions to address this issue. The comment is a pointer towards a potential problem, but it doesn't actively help the authors improve their draft. Therefore, the comment is not directly actionable or verifiable, making it 3 in identifying a problem but not in providing a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential redundancy. They suggest that the 'stacking' of methods, which already includes a 'Grouplearning setting,' might implicitly handle the grouping that DBSCAN is later used for. While the reviewer doesn't explicitly state that the 'stacking' *is* the grouping, the implication is that it's already being addressed. The action is implied but not explicitly stated as 'use DBSCAN for clustering' without the context of the 'stacking' already handling grouping. The reviewer suggests the 'stacking' might be doing the grouping already, making the explicit use of DBSCAN potentially redundant. This implies a lack of clarity in the description of how the grouping is achieved.", "grounding_specificity_rationale": "The reviewer mentions 'methods of Mirzasoleiman et al., 2020' and 'Grouplearning setting' as well as 'DBSCAN'. These are specific terms and methods. This allows the reader to identify the referenced parts of the paper. The grounding is explicit as the reviewer names specific components of the method.", "verifiability_rationale": "The reviewer makes a statement about the method being 'stacked' and then using DBSCAN. This is a claim about the methodology. However, the reviewer does not provide any evidence or reasoning to support this claim. The reviewer is stating an observation or a potential inefficiency without providing a logical justification or external references. The claim is presented without sufficient support or explanation.", "helpfulness_rationale": "The reviewer points out a potential inefficiency in the method description. They suggest that the 'stacking' of methods might already handle the grouping that DBSCAN is later used for. This implies a lack of clarity in the description of how the grouping is achieved. The reviewer is making an observation about the potential redundancy of the method description. While it doesn't directly criticize the results, it points out a potential area for improvement in the clarity and conciseness of the method description. It's helpful in that it encourages the authors to consider whether the explicit use of DBSCAN is necessary after potentially already grouping the methods through the 'stacking'."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly suggests an action: 'see if the authors can clarify whether the MFTMA scores are resilient to the choice of random projection matrix.' This direct suggestion makes the review actionable.", "grounding_specificity_rationale": "The reviewer's suggestion is general and lacks specific details. They do not specify which aspect of the random projection matrix to vary or how to vary it. They also do not define what 'resilience' means in this context. The lack of specificity makes the grounding weak.", "verifiability_rationale": "The reviewer makes a claim: 'I think one could construct pathological projection matrices that skews the MFTMA capacity and width scores. These are probably unlikely with random projections, but it would still be helpful to see resilience of the metric to the choice of random projection.' While the claim is about resilience, the reviewer does not provide any specific evidence or reasoning to support this claim within the review point itself. Therefore, the verifiability is 3 as the claim lacks strong justification within the provided text.", "helpfulness_rationale": "The reviewer's comment is clearly aimed at improving the paper (or at least understanding the method better). They are offering a concrete suggestion: 'I think one could construct pathological projection matrices that skews the MFTMA capacity and width scores. These are probably unlikely with random projections, but it would still be helpful to see resilience of the metric to the choice of random projection.' This suggests a desire to address a potential weakness in the paper's methodology. Therefore, the review is helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification and explicit details, which can be seen as an implicit action to improve the paper. However, the action is not very concrete, and the reviewer does not explicitly state how to implement the suggested changes.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 1' and asks about specific terms within it ('support data' and 'predicted training count data'). This clearly grounds the comment to a specific part of the paper and its content. The comment also implies a desire for more explicit model details, which can be inferred from the request to add it to the appendix. While the action of adding to the appendix isn't explicitly stated, the grounding is clear.", "verifiability_rationale": "The review point does not make a claim that can be verified. It is a request for clarification and information rather than a statement that needs evidence or justification.", "helpfulness_rationale": "The review point is likely to be 3 as it prompts the authors to clarify their data and provide more explicit details about their model. This can help them identify potential issues in their description and ensure the reproducibility of their work. However, it doesn't provide a definitive critique or solution, so it's not 5."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The statement explicitly mentions 'the evaluation of FGT' and 'the ablation study' and how the former is used in the latter ('which should be used to evaluate the performance of the proposed method and the comparative methods'). While it doesn't specify the exact nature of the evaluation or the ablation study, it clearly identifies the action (evaluation) and its target (ablation study).", "grounding_specificity_rationale": "The statement refers to 'the evaluation of FGT' and 'the ablation study' and 'the performance of the proposed method and the comparative methods'. While not explicitly pointing to a specific section or table, it clearly identifies the part of the paper being addressed (the ablation study and the comparison). The comment also specifies what is being evaluated (FGT performance) and against what (proposed method and baselines).", "verifiability_rationale": "The statement makes a claim: 'the evaluation of FGT is only leveraged to evaluate the method performance in the ablation study'. This is a statement about the methodology. While it doesn't provide explicit reasoning or citations within the review point itself, it presents a logical argument: the ablation study is designed to assess performance, and if FGT evaluation is the primary tool, it's because it's relevant to that performance assessment. The 'only' is the main point of contention here.", "helpfulness_rationale": "The reviewer raises a potential concern about the completeness of the evaluation of the proposed method. If the ablation study *only* leverages FGT evaluation, it might suggest that other aspects of the method's performance are not being adequately assessed. This could be a helpful point for the authors to address, as it highlights a potential limitation in the experimental design or reporting."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment 'The model seems overly simple' does not explicitly state what action the authors should take. While it suggests the authors might want to consider more complex models, it doesn't pinpoint a specific part of the model or the analysis that needs improvement. It's a statement of opinion rather than a directive.", "grounding_specificity_rationale": "The comment 'The model seems overly simple' does not specify which part of the paper the model refers to. It uses the general term 'the model', which could refer to the entire model, a specific component, or the modeling approach in general. Therefore, it does not achieve full grounding specificity.", "verifiability_rationale": "The comment 'The model seems overly simple' is an opinion, not a claim that requires verification. It expresses a subjective assessment of the model's complexity without providing any specific examples or references.", "helpfulness_rationale": "The comment 'The model seems overly simple' identifies a potential weakness in the model but does not offer any concrete suggestions for improvement. It points out a feature (simplicity) but doesn't provide a bug (improvement)."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a declarative statement identifying a limitation, not a directive asking for changes. There is no explicit or implicit action or suggestion for the authors to take.", "grounding_specificity_rationale": "The authors can easily identify the specific part of the paper being addressed: 'narrow task (climate change QA) in a specific language (Arabic)'. This is a literal mention of sections, tables, figures, etc., and unique elements of the paper.", "verifiability_rationale": "The statement about the 'broader impact may be limited' is an opinion or judgment about the paper, not a claim that can be verified using logical reasoning, common knowledge, or external references within the review point itself.", "helpfulness_rationale": "The review point identifies a valid limitation of the work but does not offer any suggestions or constructive feedback on how to address this limitation. It is merely a statement of fact."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the concern about the paper's novelty and provides specific examples like 'simplified settings' and 'most of the findings have been reported in previous works (Sec 5)'. While the reviewer doesn't directly name an action to be taken, the statement 'It's unclear how this paper contributes novelly...' implies a desire for clarification on the novelty. The reviewer also points to specific areas (previous works, Sec 5) which could be seen as hints towards where the novelty might be lacking, although the exact element isn't specified.", "grounding_specificity_rationale": "The reviewer mentions 'previous works' and 'Sec 5' as context for evaluating the paper's contribution. While they identify a potential area of overlap with existing research, they don't explicitly pinpoint a specific section, table, or figure within the paper that is being criticized. The reviewer is general in their reference to previous work and a section, indicating a lack of precise grounding.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a critique of the paper's contribution rather than a statement that needs supporting evidence.", "helpfulness_rationale": "The reviewer raises a valid concern about the paper's novelty and contribution. However, the review point itself doesn't offer concrete suggestions or improvements to the draft. It's more of a critique of the research's novelty rather than a direct improvement suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two explicit suggestions: (1) to mention the computational cost in the main paper and (2) to include runtime examples. These are direct actions the authors can take to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly states the goal is to 'briefly mention' the computational cost in the 'main paper' and suggests including 'runtimes'. These are specific actions and sections within the paper.", "verifiability_rationale": "The reviewer's suggestions are based on the practical importance of computational cost and the usefulness of runtime information for application. While they don't provide external references, the reasoning is logical and directly relevant to the stated goals.", "helpfulness_rationale": "The reviewer provides two clear and actionable suggestions aimed at motivating the method and assisting readers in applying it. The suggestions directly address practical concerns and offer concrete steps for improvement. The reviewer explicitly states the 'why' behind the suggestions, connecting them to motivation and application."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly recommends the authors 'elucidate this procedure in greater detail' and asks a specific question about a key aspect ('whether the spatial arrangement of the EEG sensors played any role in this process'). This directly points to an actionable improvement the authors should make. The reviewer provides a clear direction for the authors to follow, making the action quite concrete. The reviewer is not just pointing out a problem but suggesting a specific way to address it.", "grounding_specificity_rationale": "The reviewer mentions 'Figure 3' which is a specific part of the paper. While they don't explicitly state the section number or title, referring to a specific figure implies they can identify the relevant part. The reviewer also specifies the type of plot ('EEG topography') and asks a question about a specific detail within that plot ('the role of spatial arrangement of the EEG sensors'). This level of detail in identifying the relevant part and the specific issue makes the grounding quite specific.", "verifiability_rationale": "The reviewer doesn't make a definitive claim about what is *wrong* with the EEG token quantization process. They are recommending improvement rather than critiquing the method itself. However, the implication is that the current process is unclear, leading to ambiguity. This could be considered a weak claim. The reviewer's suggestion is not verifiable because it's a recommendation for improvement, not a statement that can be proven true or false with evidence. The reviewer is suggesting the authors *elaborate* on the process, which is a suggestion for clarification, not a claim requiring external references or logical reasoning.", "helpfulness_rationale": "The reviewer provides a clear and actionable recommendation for the authors to improve their understanding of the EEG token quantization process. They specifically ask the authors to 'elucidate this procedure in greater detail' and to consider the 'role of spatial arrangement of the EEG sensors'. This directly addresses a potential area of confusion and provides a concrete direction for the authors to take. The reviewer's comment is not critical but rather constructive and aimed at improving the authors' understanding of a specific technical aspect. The suggestion is specific and directly targets a potential ambiguity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action of 'no need to distinguish' and provides a reason ('they are calculated in the same way'). While the action itself is not very specific on how to simplify, the reviewer clearly identifies a potential improvement. The reviewer also mentions the notations 'SM' and 'DM', which are specific to the paper's context, providing grounding for the suggestion.", "grounding_specificity_rationale": "The reviewer uses the notations 'SM' and 'DM', which are specific to the paper's context, providing grounding. The reviewer also explicitly states the reason for the suggestion ('they are calculated in the same way'), clearly identifying the issue and the potential simplification, making it specific.", "verifiability_rationale": "The reviewer makes a claim ('there may be no need to distinguish') and provides a justification ('as they are calculated in the same way'). This justification is logical and based on the information provided in the review point, making the claim verifiable.", "helpfulness_rationale": "The reviewer clearly identifies a potential improvement (simplifying the distinction between the metrics) and provides a reason for it. This suggests a relevant and actionable feedback for the authors, making it helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a fact ('the authors leverage the complexity...') and offers an opinion ('This feels like...'). While the reviewer points to a specific technical detail, they do not explicitly state what needs to be changed or how the authors should address this complexity. The action is implied but not explicitly stated and lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the Witness oracle,' 'polynomial time,' and 'tabular case.' These are specific technical terms and concepts within the paper, demonstrating a clear understanding of the section being discussed. This can be achieved through:  Literal mentions of sections, tables, figures, etc.  Mentions of unique elements of the paper.  General comments that clearly imply the relevant parts without explicitly naming them. In this case, the reviewer provides literal mentions of key terms.", "verifiability_rationale": "The reviewer states a fact ('the authors leverage the complexity...') which can be verified. However, the reviewer also offers an opinion ('This feels like...'). The claim is partially verifiable as the claim is wellsupported but lacks key elements (e.g., examples, references). The reviewer provides the fact about 'polynomial time' but doesn't elaborate with examples or references to external works to further support their feeling that it's not a 'direct way'.", "helpfulness_rationale": "The reviewer expresses a preference for a 'more direct way' but does not provide specific reasons why the current approach (using the Witness oracle and checking for 'polynomial time') is problematic or how the authors should change it. The comment is critical of the approach but lacks concrete suggestions or explanations of the limitations of the current method. The authors are left without actionable feedback on how to improve their draft based on this review."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out a specific section (lines 2230) and identifies a clear weakness: the lack of discussion on moment matching in distributional RL, despite using quantile regression. The reviewer suggests a concrete action: 'Discuss moment matching...even though the present paper still uses quantile regression instead of moment matching.' This suggests a clear next step for the authors, indicating a direct and actionable piece of feedback.", "grounding_specificity_rationale": "The reviewer provides a very specific section reference (lines 2230) and a precise suggestion (discuss moment matching, even though they use quantile regression). This demonstrates strong grounding specificity, as the reviewer clearly identifies the relevant part of the paper and the specific issue within that part.", "verifiability_rationale": "The reviewer does not explicitly claim that moment matching is better or worse than quantile regression. However, the suggestion to discuss it, even if the paper uses a different method, provides a basis for verification. The reviewer is proposing a concrete action the authors could take, which implies a potential improvement or clarification. While the claim is not explicitly stated as a judgment, the suggestion itself acts as a form of justification \u2013 the reviewer is proposing a relevant piece of information. Therefore, it is 3.", "helpfulness_rationale": "The reviewer's comment is clearly intended to be helpful. They are providing context and suggesting a relevant piece of information (moment matching) that could improve the authors' understanding of distributional RL, even if their paper uses a different method. The suggestion is concrete and actionable, directly pointing to a potential improvement for the authors. The reviewer is not criticizing the authors' choice of quantile regression but rather providing a broader perspective on the field. This makes the comment highly relevant and helpful for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a consequence of the subset choice ('raises questions about generalizability') but does not explicitly propose a solution or action to address this consequence. The action is implied but not clearly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Massive Text Embedding Benchmark (MTEB)' and refers to a 'subset' of it. This clearly identifies the area of the paper being discussed. While not pinpointing a specific section, the reference is clear and unambiguous.", "verifiability_rationale": "The reviewer expresses a concern ('raises questions about generalizability') and suggests further investigation ('it would be helpful to understand the criteria...'). This indicates a claim that the subset choice is problematic. However, the reviewer does not provide specific evidence or references to support this claim about the limitations of a subset.", "helpfulness_rationale": "The reviewer's comment prompts the authors to consider the limitations of their evaluation strategy and explore a broader range of benchmarks. This is a valuable piece of feedback that encourages improvement. However, the comment itself does not offer a concrete solution or specific steps to address the identified issue."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a lack of clarity in the second paragraph of the introduction regarding the subject of the 'modeling curves'. While it points out the ambiguity, it doesn't explicitly state that the curves are intended to model tumor growth or any other specific aspect. The reviewer suggests improving clarity, which is a general suggestion without specifying how to achieve it. Therefore, the action is implied but not explicitly stated, and the action itself (improving clarity) is vague.", "grounding_specificity_rationale": "The comment explicitly refers to the 'second paragraph of the introduction' when identifying the issue with 'modeling curves'. This allows the reader to locate the relevant section of the paper. However, the comment does not specify *what* is being modeled within that paragraph. The grounding is present (mentioning a specific section), but the specificity is lacking as the exact content being modeled is not identified.", "verifiability_rationale": "The comment contains a claim: that the second paragraph of the introduction needs to be clearer about what is being modeled. However, the comment does not provide any justification or examples to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the paragraph is unclear in this specific regard. The claim is stated without any supporting evidence.", "helpfulness_rationale": "The comment identifies a potential area for improvement in the introduction by pointing out the lack of clarity in the 'modeling curves' section. However, the comment does not offer any specific suggestions or guidance on how to improve this clarity. It simply states the problem without providing any actionable steps or examples of how the issue can be addressed. The feedback is identified but not elaborated upon with concrete suggestions."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific experimental detail (the comparison between shift=0 and shift~ N ( 0 , \u03c3 2 ) in shiftedMNIST) and suggests a specific experiment (testing the model and baselines on test samples from the observational distribution). This directly identifies an area where the author's draft could be improved by clarifying the experimental setup and providing results for a specific distribution. The reviewer's suggestions are direct and point to specific actions the author should take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'shiftedMNIST' and focuses on the comparison between 'shift=0' and 'shift~ N ( 0 , \u03c3 2 )'. They also specify the type of performance to show ('test samples from the observational (in) distribution'). This demonstrates a clear understanding of the specific section and table (or unique aspect) being addressed, making the grounding highly specific.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity in the current explanation of the shiftedMNIST experiment and suggests a specific experiment to be performed. This claim is supported by the reviewer's direct statement and the logical reasoning that testing on the observational distribution would provide valuable insights. While not a direct criticism of a claim within the paper itself, the reviewer's suggestion is a clear indication of a point that needs further clarification and verification within the context of the author's draft.", "helpfulness_rationale": "The reviewer's comment is 5 because it directly points out a potential source of confusion in the experimental setup description and provides a concrete suggestion for improvement. By highlighting the ambiguity surrounding the shift parameter and recommending a specific experiment, the reviewer empowers the author to clarify their methodology and potentially identify a weakness in their approach. The suggestion to test on the observational distribution is a practical and actionable step that can significantly enhance the understanding and evaluation of the model."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states 'Description of experimental details would significantly benefit from increased clarity', which directly tells the authors what the issue is and what they should do. This is an explicit and concrete action.", "grounding_specificity_rationale": "The comment refers to 'experimental details' generally, which does not pinpoint a specific section, table, figure, or unique aspect of the paper. While it implies the need for clarity in the methods section, it lacks specificity about the exact part requiring improvement. The suggestion for 'increased clarity' is also vague.", "verifiability_rationale": "The comment does not make a claim that requires verification. It suggests an improvement ('increase clarity') rather than stating a definitive point about the paper that needs justification.", "helpfulness_rationale": "The comment clearly identifies a weakness ('lacking detail') and provides a concrete suggestion for improvement ('increase clarity'). It directly tells the authors what to do and how to address the issue, making it 5 for revision."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'expected' and then provides a concrete suggestion: 'One of the main contributions of this paper is the CBR, so different optimization strategies and the corresponding results should discussion.' This indicates a clear action to be taken: to discuss the CBR and its optimization strategies. Furthermore, the reviewer provides a specific example of how this discussion should be conducted: 'For example, what will happen by minimizing both of the inter and intra terms in Eq 3 or only minimizing the first term?' This explicit and concrete action makes it 5.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'the main contributions of this paper is the CBR' and then asks about 'different optimization strategies and the corresponding results'. This direct mention of the CBR clearly identifies the specific part of the paper being addressed. The reviewer also specifies what needs to be explained about this part: the impact of different optimization strategies. This explicit identification and clear specification make it 5.", "verifiability_rationale": "The reviewer states 'expected' and then provides a rationale for this expectation: 'One of the main contributions of this paper is the CBR, so different optimization strategies and the corresponding results should discussion.' This statement is a claim that the paper lacks sufficient explanation and discussion in these areas. The reviewer provides a logical reasoning for this claim, linking it to the identified contribution (CBR) and the importance of discussing optimization strategies. While the reviewer doesn't provide external references, the reasoning is based on the content of the paper and the importance of these aspects. This makes the claim 3.", "helpfulness_rationale": "The reviewer directly points out a potential weakness in the paper: the lack of explanation and discussion, particularly regarding the CBR and optimization strategies. They then provide a clear and actionable suggestion: to discuss these aspects and provide corresponding results. The reviewer even gives a concrete example of how to do this: 'For example, what will happen by minimizing both of the inter and intra terms in Eq 3 or only minimizing the first term?' This constructive and specific feedback directly addresses a potential area for improvement and guides the authors on how to enhance their work. The reviewer's direct identification of the problem and their proposed solution make this review point 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out that 'treewidth' is central to all the proofs, which is a clear indication of its importance. While the reviewer doesn't explicitly state an action, the suggestion to 'include a formal or intuitive definition' is a direct and actionable step the author can take to improve their draft. The reviewer identifies a specific area where the author might need more context and guidance.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'treewidth' as the central element and suggests a specific way to address it ('include a formal or intuitive definition'). This directly identifies the missing part and provides a clear action, making it 5.", "verifiability_rationale": "The reviewer states a fact ('treewidth is central to all the proofs') and provides a suggestion ('include a formal or intuitive definition'). This claim is verifiable by examining the paper's proofs and by the author's ability to add a definition section. The suggestion is also verifiable by including either a formal definition or a good intuitive explanation.", "helpfulness_rationale": "This review point is 5 because it directly addresses a potential weakness for the reader \u2013 the lack of understanding of 'treewidth' and its importance to the proofs. By suggesting the inclusion of a definition, the reviewer provides a concrete and actionable improvement that would enhance the clarity and accessibility of the paper. The reviewer's point is directly relevant to the paper's core contributions and would significantly benefit the reader's understanding."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the *what* (convergence to permutations as local minima) and *what improvement is desired* (quality of these local minima). They even suggest a specific method for analysis (approximation ratio under certain assumptions). This provides clear guidance on how the authors should improve their draft.", "grounding_specificity_rationale": "The reviewer refers to 'Algorithm 1' and the 'local minima' of that algorithm. This is a specific part of the paper. They also identify the specific concept they want analyzed ('quality of these local minima'). This allows the authors to precisely identify the area needing improvement.", "verifiability_rationale": "The reviewer makes a suggestion for the authors to analyze the 'quality of these local minima' using the 'approximation ratio under certain assumptions'. While the paper doesn't *currently* do this, the *suggestion itself* is based on wellestablished concepts in optimization and theoretical computer science. The *assumptions* are a point of potential limitation, but the *core idea* of analyzing quality is verifiable. The reviewer is *suggesting* a way to improve the paper, not *stating* a fact about the current work.", "helpfulness_rationale": "The reviewer provides a concrete suggestion for the authors to improve their analysis. They are not just pointing out a *where* but also *how* the authors should improve their work by analyzing the quality of the local minima using the approximation ratio. This directly helps the authors improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the paper is not selfcontained and requires the supplementary material for understanding. While the reviewer requests supplementary material and code, the *action* of providing the supplementary material and code is not explicitly stated as a concrete action to be taken by the authors. The reviewer implies that this would help, but doesn't specify *how* the supplementary material or code will address the lack of selfcontainment. Therefore, while the reviewer identifies a problem, the specific action to be taken is not clearly defined.", "grounding_specificity_rationale": "The reviewer states that the paper is not selfcontained and that the supplementary material is necessary to understand 'large parts of the main paper'. This indicates that the reviewer cannot confidently pinpoint the exact section or table that is causing the difficulty. The use of the vague term 'large parts' suggests a lack of specific grounding. Furthermore, the reviewer does not specify what these 'large parts' are or how the supplementary material clarifies them. The request for code is also 1 in a specific aspect of the paper.", "verifiability_rationale": "The reviewer states two things: 1) 'The paper is not self contained Understandable given the NIPS format, but the supplementary is necessary to understand large parts of the main paper and allow reproducibility.' and 2) 'I also hereby request the authors to release the source code of their experiments to allow reproduction of their results.' Neither of these statements are claims that require justification or verification. They are statements of observation and a request for additional resources. Verifiability applies to claims, not requests or observations.", "helpfulness_rationale": "The reviewer clearly identifies a significant issue: the lack of selfcontainment and the need for supplementary material and code to achieve reproducibility. They directly state what is missing and what they believe is necessary to address it. This is a direct and helpful critique aimed at improving the reader's ability to understand and reproduce the work. The reviewer is not just pointing out a problem but also providing a clear direction for how the problem might be addressed."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks 'How important is the added complexity?' and 'Will one IN do?'. These are direct questions that the authors can use to evaluate the design choice. The reviewer also mentions 'a seemingly important novel feature' and 'the dynamics predictor', which are specific aspects of the model. The questions are about the impact of a specific design choice on a particular component of the model.", "grounding_specificity_rationale": "The reviewer refers to 'a seemingly important novel feature' and specifically asks about 'the dynamics predictor'. While not a direct section reference, the connection to the dynamics predictor is implied. The reviewer also mentions 'multiple speeds' in the dynamics predictor, which is a specific detail of the design. The questions directly relate to this specific design choice.", "verifiability_rationale": "The reviewer does not explicitly state a claim about the importance of the multiple INs. However, the reviewer's questions imply a belief that the added complexity might be unnecessary. While the reviewer suggests an investigation through ablation studies, this is a suggestion for future work rather than a claim that is immediately verifiable within the review point itself. The reviewer does not provide specific evidence or logical reasoning to support their belief *before* suggesting the ablation study.", "helpfulness_rationale": "The review point directly addresses a potential weakness of the model, which is the added complexity of the multiple INs at different speeds in the dynamics predictor. The reviewer's questions, 'How important is the added complexity?' and 'Will one IN do?', are directly relevant to the authors' concerns about this novel feature. The suggestion to investigate this through ablation studies is a concrete action the authors can take."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: 'the opponent simply doesn't aim at maximizing it' and provides a reason: 'because the opponent maximizes classical SE and AE'. This is an explicit action or suggestion that authors can directly identify modifications they should apply to their draft, though the specific modifications are not detailed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the experiments,' 'opponent,' 'multiagent payoff,' 'opponents aim,' 'classical SE,' and 'AE' when explaining the issue. This allows the authors to accurately pinpoint the section and concepts being discussed, making it fully grounded.", "verifiability_rationale": "The reviewer makes a claim: 'In particular, in the experiments, it doesn't come as a complete surprise that the opponent can be outperformed w.r.t. the multiagent payoff proposed by the authors, because the opponent simply doesn't aim at maximizing it (e.g. in the experiments he maximizes classical SE and AE).' This claim is verifiable based on the established definitions of Solution Equilibria and Alternating Equilibria in game theory, which are wellaccepted practices. While a formal proof might be needed for absolute certainty, the claim is supported by logical reasoning and common knowledge within the field.", "helpfulness_rationale": "The reviewer points out a potential flaw in the experimental design by highlighting the discrepancy between the authors' payoff and the opponent's objective (SE/AE). This is a valuable piece of feedback for the authors to consider when interpreting their results and potentially redesigning their experiments. The reviewer provides a clear explanation of why this discrepancy might exist, making the feedback constructive."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly asks for justification of the choice of the REINFORCE algorithm over alternatives like PPO. This is a direct request for information and a clear indication of a potential area for improvement. The reviewer also states their presumption that this choice is related to the paper's focus on attention models, which, while not explicitly stated, implies a connection. This explicitness makes it actionable in the sense that the authors should be able to directly identify the modification they should apply: seek justification for the algorithm choice.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'REINFORCE algorithm' and 'PPO' as the two options being considered. This provides a clear and specific reference point. While the reviewer also mentions the potential connection to 'attention model paper', this is an implied connection rather than a direct mention of a specific section or table. Therefore, the grounding is strong but not perfect.", "verifiability_rationale": "The reviewer is not presenting a claim that needs verification. They are asking a question: 'I presume it has to do with the attention model paper this one iterates on, but clarification would be good.' This is a request for information, not a statement that requires evidence or justification. There is X being made that needs to be verified.", "helpfulness_rationale": "The reviewer's point is a valid question that could potentially lead to further clarification and potentially a better methodological choice. However, it does not directly identify a flaw in the current approach, suggest a concrete improvement, or offer a novel insight. The feedback is primarily a request for more information rather than a constructive critique or suggestion. Therefore, it is not 5 in improving the paper's content or methodology."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states they are 'confused' about the statement in Theorem 5.1. While they could identify the theorem as relevant, the action they could take is to understand the comparison between MMD DRO and the variance regularized problem. However, the action itself is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Theorem 5.1' and compares it to a 'variance regularized problem'. This demonstrates a clear identification of the specific part of the paper and the comparison being made, indicating strong grounding and specificity.", "verifiability_rationale": "The reviewer states their confusion about the statement in Theorem 5.1 without providing any supporting evidence or justification. There is no logical reasoning, common knowledge, or external references provided to support their claim about the theorem's implications. The comment is presented as a statement without any backing.", "helpfulness_rationale": "The reviewer's confusion about the statement in Theorem 5.1, and their interpretation of it as potentially indicating a disadvantage for MMD DRO, is intended to provide insight and highlight a point of interest. While the comment is not explicitly asking for clarification or a question, it is intended to be a helpful comment by revealing a potential weakness or area for improvement in the authors' understanding. However, the lack of clarity makes the helpfulness somewhat limited."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states they want more information on how morphologic segmentation is conducted across domains and raises a question about its invariance. This directly points to a need for clarification and action. The reviewer believes this clarification is important for the task of domain adaptation, indicating a clear action the authors should take to understand this aspect better. The request for more detail and clarification is a direct action the authors can take to improve their understanding of the method.", "grounding_specificity_rationale": "The reviewer mentions 'morphologic segmentation' and 'domain adaptation' without explicitly stating which section or table discusses this. While the context strongly suggests they are referring to a specific part of the paper related to their expertise, the connection is not immediately obvious. The reviewer's question about the differences across domains highlights a lack of specific grounding in the paper's treatment of this topic. The grounding is implicit, requiring the reader to infer the relevance of the discussed methods to the specific task.", "verifiability_rationale": "The reviewer states that the paper 'assumed morphologic segmentation will be invariant' and questions this assumption. This is a clear claim made in the paper that lacks explicit justification or evidence within the paper. The reviewer's questioning implies a lack of sufficient support or logical reasoning to back this assumption. The claim is presented without a clear explanation of why this assumption is reasonable or supported by the presented evidence.", "helpfulness_rationale": "The reviewer's point directly addresses a core methodological aspect of the paper \u2013 the domainspecificity of morphologic segmentation. Their request for clarification and the question about the invariance assumption highlight a potential gap in the paper's explanation. This point is likely to be 5 for the authors by guiding them to consider the implications of this assumption and potentially improving the clarity and rigor of their method description. The reviewer's suggestion is constructive and directly addresses a potential area of confusion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the desired experiment ('there should be experimental results of excluding such mixup technique') and clearly identifies the missing element ('there should be experimental results of excluding such mixup technique in the proposed method'). This directly points to a needed action. While the request is clear, the reviewer doesn't *explain* *why* they think this experiment is necessary (beyond the general point about isolating contributions), making it slightly less vague than 'actionable.'", "grounding_specificity_rationale": "The reviewer *mentions* 'Sec. 4.2' and 'mixup technique in LUMP,' which grounds the comment to a specific section and related work. However, they *don't* explicitly state which part of LUMP's mixup technique they are referring to. This lack of precision makes it only somewhat grounded. The reviewer also *implies* the desired experiment, making it somewhat specific.", "verifiability_rationale": "The reviewer states a claim ('the lack of experiments makes it unclear what the pure contribution is') but provides *no* evidence or reasoning to support this claim based *only* on the information given in the review point. There's no logical reasoning, common knowledge, or external references provided to connect the missing experiments to the unclear contribution. Therefore, it's 1 based solely on the statement.", "helpfulness_rationale": "The reviewer clearly states a desire for *experimental results*. This is a direct and actionable request. The reviewer's statement is clear and directly addresses a potential weakness in the paper's experimental validation. While the request is clear, the reviewer doesn't *explain* *why* they think this experiment is crucial for understanding the contribution, making it slightly less actionable than '5.'"}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3.5", "grounding_specificity_label": "4.5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that information is missing. While it doesn't directly tell the authors what to add, it points to a specific area that needs attention. The reviewer is implicitly suggesting that the authors should include a discussion of the Set Transformer and related works using summary tokens. This level of detail suggests a clear area for improvement, making it more than just a vague comment.", "grounding_specificity_rationale": "The comment explicitly mentions 'Set Transformer' and 'other related works that also uses summary tokens'. This is a strong indication of the specific area where information is lacking. The reviewer is not just saying 'missing related work', but specifically pointing to these areas. This high level of specificity makes it easier for the authors to understand what needs to be addressed.", "verifiability_rationale": "The comment contains a claim that information is missing, specifically regarding the Set Transformer and related works using summary tokens. This claim is supported by the reviewer explicitly stating these areas as examples of missing information. The use of specific examples enhances the verifiability of the claim, making it clear and wellsupported.", "helpfulness_rationale": "The comment is helpful by directly pointing out a gap in the related work section. By mentioning the specific areas (Set Transformer and related works using summary tokens), the reviewer provides the authors with a clear direction for further research and discussion. This is a valuable piece of feedback that encourages the authors to broaden their context and potentially position their work more accurately within the field."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question about a specific technical detail in the paper (Fourier features and NTK convergence in the highfrequency range). This constitutes an explicit action, as the reviewer is seeking clarification or confirmation. While it doesn't directly propose a solution, it points to a potential area needing further explanation.", "grounding_specificity_rationale": "The reviewer directly asks a question about a specific aspect of the paper, namely 'How Fourier features accelerate NTK convergence in the highfrequency range?'. This clearly indicates that the reviewer can identify the specific section or concept being discussed, making the grounding explicit. The question is also very specific about the technical details being considered.", "verifiability_rationale": "The review point does not contain a claim. It is a question posed about a specific technical aspect of the paper. Therefore, it does not fall under the categories of verifiable or 1 claims.", "helpfulness_rationale": "The reviewer's comment seeks clarification on a specific technical point. While it doesn't identify a flaw or suggest a solution, it highlights a potential area where the reader's understanding could be improved. This type of feedback can be helpful for the authors by addressing a potential gap in the reader's comprehension."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer states that they cannot find details on a specific training mechanism. While they identify the topic of the missing information, they do not explicitly state how to apply this knowledge or what specific action they should take next. The request is about identifying a missing element, not about performing an action with it.", "grounding_specificity_rationale": "The reviewer refers to 'the network,' 'the residual,' 'the input,' and 'the output' without specifying a particular section, table, figure, or unique element of the paper. They imply it's related to the general training process, making the grounding somewhat weak. While the topic is clear, the exact location is not.", "verifiability_rationale": "The reviewer makes a claim that they 'can't find details on how they make the network fit the residual instead of directly learning the input  output mapping.' This is a claim that can be verified by searching the paper for information related to the training process, network architecture, and the concept of residuals. While the reviewer doesn't provide specific evidence *why* they can't find it, the claim itself is verifiable by looking for relevant sections or descriptions.", "helpfulness_rationale": "The reviewer's request is clear and directly points to a specific area of the paper where more information is needed. They want to understand how the network is trained to fit residuals, which is a crucial detail for understanding the method. This request provides a clear direction for the authors to improve their draft by adding this explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing information: 'What\u2019s the experiment setup in Section 3.3? (data augmentation methods, learning rate, etc)'. This directly points to an actionable step the authors should take to understand the context of their method. The missing information is also concrete, specifying the exact elements of the experiment setup that are needed. Therefore, the reviewer is providing clear guidance on what is missing.", "grounding_specificity_rationale": "The reviewer refers to 'Section 3.3' of the paper, which is a specific part of the document. They then further specify the missing information as 'experiment setup (data augmentation methods, learning rate, etc)'. This demonstrates a clear understanding of where the information is lacking and what specific details are missing within that section. The combination of a specific section reference and a specific detail makes this highly grounded.", "verifiability_rationale": "While the reviewer is pointing out a valid gap in the information provided, the request itself does not contain a claim that can be verified. The reviewer is stating a fact: the experiment setup is missing. There is no suggestion or opinion being made that requires evidence to support it. Therefore, the claim extraction step would classify this as 'X' (X). The request is more of a question or observation than a verifiable statement.", "helpfulness_rationale": "The reviewer clearly identifies a missing piece of information that is directly relevant to understanding the experimental setup of the method described in Section 3.3. This missing information is crucial for the authors to contextualize their work and evaluate its effectiveness. The reviewer's comment directly points to a specific area where the authors need more details. Therefore, the feedback is directly actionable and helpful for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises a question about a potential issue in the calibration steps and suggests a citation. While the reviewer doesn't explicitly state an action to be taken, the suggestion to cite the RVC paper implies a potential next step for the authors. The reviewer also points to a *potential* issue (speed disparity) that could be a result of the calibration steps, but doesn't provide a concrete action to address it. The reviewer's question is not an explicit instruction on what to do, but rather a suggestion for further investigation.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify a specific part of the paper being addressed. The comment is about the algorithm in general and the observed speed disparities. The reviewer does not mention any specific section, table, figure, or unique element of the paper. The comment is about a general observation related to the algorithm.", "verifiability_rationale": "The reviewer's comment is a question and a suggestion for citation. The suggestion to cite the RVC paper provides a reference point, which can be considered a form of justification or verification. However, the question itself is not explicitly justified or supported by any reasoning, common knowledge, or external references within the review point itself.", "helpfulness_rationale": "The reviewer's comment raises a question about a potential issue and suggests a citation. While the suggestion to cite the RVC paper is relevant and provides a potential resource, the question itself is not explicitly addressed or resolved within the review point. The reviewer does not provide a direct explanation or evidence for why an error in the initial calibration steps might explain the speed disparities. The comment is more of a suggestion for further investigation rather than a direct feedback on a specific weakness."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a fact about the difference between ASAP and other methods but does not explicitly recommend any changes or detailed steps for improvement. While the difference is stated, the lack of actionable steps makes it 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'ASAP (and similar methods)' and 'biological networks' and clearly states the difference between the artificial networks trained using ASAP and other techniques. This indicates a high level of grounding specificity.", "verifiability_rationale": "The statement presents a claim about the difference in network resemblance. While the underlying concepts are generally understood within the field, the statement itself is a claim that could be supported by further evidence or references. Therefore, it is 3.", "helpfulness_rationale": "The reviewer points out a potential limitation of ASAP. While it doesn't demand changes, it highlights a difference in the representation learned by ASAP compared to other methods. This could be valuable for authors considering using ASAP, as it helps them understand its potential limitations. However, it doesn't directly instruct the authors on what to do, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question, making it 3. However, the vagueness of the request makes it less actionable.", "grounding_specificity_rationale": "The reviewer asks a general question about statistical significance, which is a broad topic. They don't explicitly point to a specific part of their paper.", "verifiability_rationale": "The reviewer makes a claim (observation about the closeness of numbers). The question about statistical significance isn't a verifiable statement but a request for information.", "helpfulness_rationale": "The question is relevant and could be helpful, but it's a request, not a critique or actionable suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem: 'Which of the common inference tasks in a discrete HMM (filtering, smoothing, marginal observation likelihood) can be computed exactly/approximately with an NPSPECHMM?'. This directly addresses a specific issue within the paper. Furthermore, the reviewer provides a clear direction by asking for clarification on the impact of nonparametric emission distributions on inference. The request is for a direct answer to a specific question, which constitutes an explicit action. While the reviewer doesn't propose a solution, they are directly identifying a gap in the paper's explanation, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'learning HMMs with nonparametric emission distributions' and then directly asks about the 'impact on inference' and specifically which 'inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly/approximately with an NPSPECHMM?'. This clearly identifies the specific part of the paper being addressed. The reviewer provides a unique section (the list of inference tasks) as the grounding point. This falls under the definition of 'fully grounded' as the paper can be easily identified through the provided section and the unique aspect of the inference tasks being asked about. The request is also very specific, asking about the possibility of computing specific inference tasks with a specific type of HMM. This falls under 'specificity' as the question is very focused and clear.", "verifiability_rationale": "The reviewer is essentially posing a question seeking information, which can be considered a claim about what the authors should know. However, the paper does not currently provide the answer to this question. While the potential answer could be considered verifiable (the possibility of computing these tasks with NPSPECHMMs is a claim that could be supported by external references or logical reasoning), the paper itself does not currently provide this information. Therefore, it is not 5 as the information is not present. If we consider the question itself as the claim, the paper does not currently provide sufficient justification or evidence to support the answer to this question. Therefore, it is 2.", "helpfulness_rationale": "The reviewer is asking a very specific question about a relevant aspect of their work. They are trying to improve their understanding and potentially their work by knowing which inference tasks are possible with their specific type of HMM. While the paper does not currently provide this information, the request itself is a valuable piece of feedback that could help the authors improve their understanding and potentially their work. The question is clear and directly addresses a gap in the paper's explanation. Therefore, it is 3 as it points to a specific area where the authors need more information."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the authors 'only mention that the scope prompting method shows poor performance on GPT3.5turbo, but they do not provide any analysis of the underlying reasons behind this outcome.' This directly points out a missing analysis, making the comment actionable for the authors to investigate the reasons for the poor performance. The reviewer suggests the authors should analyze the reasons, which is a clear direction.", "grounding_specificity_rationale": "The reviewer mentions 'the scope prompting method' and 'GPT3.5turbo'. While the model name is specific, the method is described generally. The reviewer doesn't explicitly refer to a specific section, table, or unique aspect of the paper related to this method. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim about the authors' analysis: 'the authors only mention that the scope prompting method shows poor performance on GPT3.5turbo, but they do not provide any analysis of the underlying reasons behind this outcome.' This is a statement of fact about the authors' actions. While the reviewer doesn't provide specific examples of *why* the analysis is missing, the claim is clear and implies a lack of justification. The support is somewhat lacking as it doesn't point to a specific instance or provide a reference.", "helpfulness_rationale": "The reviewer clearly identifies a specific weakness in the authors' analysis: the lack of investigation into the reasons behind the poor performance of the scope prompting method on GPT3.5turbo. This is a direct and constructive criticism that provides a clear direction for the authors to improve their work. The reviewer suggests a specific action the authors should take (perform an analysis)."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a direct question about the discrepancy between the number of datasets mentioned and the number used in the experiments. This constitutes an explicit action or statement that requires further clarification. While the reviewer doesn't *immediately* tell the authors what to do, they are prompting the authors to explain their methodology. The action is somewhat vague as the reviewer doesn't specify *why* only 10 datasets were chosen or what the implications are.", "grounding_specificity_rationale": "The reviewer points out a specific discrepancy between the total number of datasets mentioned (120) and the number used in the experiments (10). This demonstrates a clear identification of a specific part of the paper (the experimental setup and dataset usage) where there appears to be a mismatch. The grounding is implicit because the reviewer is inferring that the 10 datasets are the ones actually used for the batch vs. greedy comparison, rather than explicitly stating the names or indices of these datasets.", "verifiability_rationale": "The reviewer makes a statement about the paper's methodology, questioning the scope of the experiments. This constitutes a claim that needs to be supported. The reviewer is asking *why* only 10 out of 120 datasets were considered. While the reviewer doesn't provide external references or logical reasoning *within this review point*, they are prompting the authors to explain their experimental design and its limitations. The claim is somewhat underspecified as the reviewer doesn't detail the criteria for selecting the 10 datasets or the reasons for excluding the other 110.", "helpfulness_rationale": "The reviewer's comment is informative and points to a potential area of confusion or a limitation in the paper's reporting. They are asking for clarification on a specific aspect of the experimental setup. This is a valuable piece of feedback as it encourages the authors to provide more detail about their methodology. The request is specific and directly related to the reported results."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to remove the lowrank factorization motivation from the introduction and to discuss the implications of the results for lowrank matrix factorization. This is a clear and direct action that authors can readily understand and implement.", "grounding_specificity_rationale": "The reviewer refers to the 'introduction' and the 'lowrank factorization' section. While they mention the specific areas of the paper, they do not explicitly identify the specific sentences, paragraphs, or unique elements within those sections that they believe need improvement. The reference is somewhat general.", "verifiability_rationale": "The reviewer makes a claim about the 'unnecessary nature' of the lowrank factorization motivation and expresses a desire to 'explicitly discuss' its implications. However, they do not provide any logical reasoning, examples, or external references to support this claim. It is presented as a preference or suggestion rather than a verifiable statement.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: to remove the lowrank factorization motivation and discuss the implications for lowrank matrix factorization. This is a valuable suggestion that directly addresses a potential area for improvement and could help the authors better position their work. The reviewer's intent is to enhance the paper's clarity and relevance."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "Weakly Grounded", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete improvement. It's a question about the labels, not a direct instruction on how to generate code. Therefore, it's not actionable as it doesn't tell the authors what to do or how to do it.", "grounding_specificity_rationale": "The reviewer is asking about the source of the labels (dataset itself, evaluation script, etc.). While the question is about the *source*, the reviewer is asking a specific question about the *specificity* of the labels. The labels themselves are not being identified, but the origin of their definition is being questioned. Therefore, it's weakly grounded because the reviewer can infer the labels exist but cannot precisely identify the referenced part (the label definition source).", "verifiability_rationale": "The review point itself does not contain a claim. It's a request for information about the labels. Therefore, it doesn't have verifiability as there's no statement to verify.", "helpfulness_rationale": "The review point is important because it directly addresses a potential ambiguity for the authors regarding the labels used for evaluation. By clarifying the source of these labels, the reviewer is helping the authors understand what constitutes a 'correct' generation for these specific datasets. This allows them to focus their debugging efforts and compare their code against a clear target. This directly helps the authors understand and improve their code."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point mentions adapting an existing architecture and producing heatmaps. While it points to a *change* (adaptation, joint heatmaps), it doesn't explicitly state *what to do next* or *how to implement* the adaptation. The connection to \"identity/tag heatmaps\" is implied but not a concrete action. The vagueness stems from \"adapt the existing architecture\" and \"producing identity/tag heatmaps with the joint heatmaps.\" It's unclear *how* the adaptation was done and *how* the heatmaps were produced. Therefore, it's 2 as it identifies a change but lacks explicit and concrete actions.", "grounding_specificity_rationale": "The review refers to \"31\", indicating a specific prior work. The statement \"The paper is rather incremental with respect to 31\" identifies a weakness in relation to this specific prior work. The weakness is stated clearly \u2013 the current work is seen as a minor adaptation. The authors can easily infer that the weakness is in the lack of significant advancement over 31. Therefore, it's fully grounded as the specific prior work is mentioned. The weakness is also clearly specified as being \"incremental.\"", "verifiability_rationale": "The review point contains the claim \"The paper is rather incremental with respect to 31\". This is a statement of opinion or judgment about the paper's contribution in relation to a specific prior work. The review does not provide any specific evidence, examples, or references to support this claim. It's a general statement about the nature of the contribution. Therefore, it's 1 as it lacks supporting evidence.", "helpfulness_rationale": "The review point identifies a potential lack of novelty or significant advancement over a prior work. While it highlights a potential weakness, it doesn't offer concrete, actionable suggestions for improvement beyond \"adapt the existing architecture.\" The *method* of adaptation is missing. The feedback is somewhat negative and focuses on a potential limitation rather than offering clear guidance on how to improve the paper. Therefore, it's 2 as it doesn't provide specific steps for the authors to take. The authors don't get concrete steps to improve."}
{"actionability_label": "3. 3", "grounding_specificity_label": "2. 2", "verifiability_label": "3. 3", "helpfulness_label": "1. 1", "actionability_rationale": "The review point is 1 because the authors fail to explicitly explain how the \u03bb parameters are calculated. The reviewer is left to infer the process, which is a common issue in reviews lacking explicitness. The request 'How is \u03bb computed from step here?' highlights the missing explicit action. While the authors mention the sensitivity of performance and sample efficiency to \u03bb, they do not provide a clear, stepbystep explanation of the calculation process, leaving the reviewer without a concrete action to take.", "grounding_specificity_rationale": "The review point is 1 and Not Specific regarding the \u03bb calculation. The authors do not explicitly identify the specific part of the paper where the \u03bb calculation is discussed. The reviewer's confusion about the 'step here' where the calculation is mentioned suggests that the authors could not confidently determine which part of the paper they are referring to. While the general area of hyperparameters is mentioned, the exact location or method isn't clear.", "verifiability_rationale": "The review point is not Verifiable regarding the explanation of ELLA's sample efficiency. The authors explain why ELLA does not increase sample efficiency in a COMBO environment, but the reviewer states they don't quite understand what it means. This suggests that the explanation lacks sufficient justification or supporting evidence. The reviewer also mentions specific papers (1, 2, 3) which hints at the expectation for external references to clarify the concept. The lack of clarity makes it difficult to verify the claim or understand the reasoning behind it.", "helpfulness_rationale": "The review point is 1 regarding the \u03bb calculation and ELLA's sample efficiency. The lack of clarity in both areas makes the feedback 1 and potentially confusing for the authors. The reviewer's confusion about the \u03bb calculation and ELLA's sample efficiency makes the feedback unclear and potentially contradictory. Furthermore, the absence of relevant citations (as pointed out in the review) makes the feedback less robust and potentially misleading, significantly impacting its helpfulness."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer asks a question about the alternating direction method, which implies a lack of clarity or detail in its mention. While the reviewer's question prompts the author to seek more information, it doesn't directly instruct them on what to do or how to implement the method. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer mentions 'alternating direction method' and 'minmin problem' generally, without pinpointing a specific section, table, figure, or unique aspect of the paper. While the terms are relevant, they don't provide a precise location or a detailed explanation of the issue within that context. The grounding is present but not fully specific.", "verifiability_rationale": "The reviewer states a fact ('It is briefly mentioned...') and then poses a question. The question itself doesn't present a claim that requires verification using logical reasoning, common knowledge, or external references. It's a request for clarification rather than a statement that needs to be proven.", "helpfulness_rationale": "The review point is a question about a specific implementation detail. While it encourages the author to provide more information, it doesn't directly critique the writing, suggest improvements, or identify a problem that needs to be solved. It's a request for clarification, not a helpful feedback point in itself."}
{"actionability_label": "2", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies potential weaknesses in the lower bound double qlearning algorithm and observes performance trends in different environments. However, the suggestions are very general and do not specify *how* to address these issues. The reviewer doesn't provide concrete steps for the authors to take, such as specific parameter adjustments or algorithm modifications. The suggestions are more like observations than actionable improvements.", "grounding_specificity_rationale": "The reviewer mentions 'double qlearning' and specific environments (MsPacman, WizardOfWor, Zaxxon RoadRunner, BattleZone). This indicates a reasonable level of grounding as the reviewer is referring to specific algorithms and experimental settings. The mention of 'double qlearning' points to a specific implementation, and the environments are clearly identified. However, the reviewer could be more explicit about the *part* of the algorithm being discussed. For example, they could specify if they are referring to the target network or the update rule.", "verifiability_rationale": "The reviewer points out a 'slight performance decrease' and 'convergence into same solutions' without providing specific evidence or references. While the observations are noted, there's no logical reasoning or external references to support these claims. The reviewer doesn't explain *why* these convergence issues might be happening or how they relate to the algorithm's design. The suggestions are based on observations rather than a thorough analysis.", "helpfulness_rationale": "The reviewer raises concerns about the effectiveness and stability of the double qlearning algorithm. While these concerns are generally valid and could be helpful for the authors, the lack of specific suggestions and the reliance on observations rather than concrete evidence make the review less impactful. The reviewer doesn't provide clear directions on how to improve the algorithm or address the observed issues. The suggestions are more like questions or areas for further investigation rather than direct solutions."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation of using linear models for interpreting DNN predictions. While this points to a potential area for improvement, it doesn't explicitly suggest a concrete action or modification to the draft. The statement is more of an observation than a direct instruction for the author.", "grounding_specificity_rationale": "The reviewer makes a general statement about the limited novelty of using linear models for interpreting DNN predictions. They do not specify which part of the paper this relates to or provide any details about the specific linear models or DNNs being discussed. The comment is broad and lacks specificity.", "verifiability_rationale": "The reviewer's statement about the limited novelty of using linear models for interpreting DNN predictions is a claim. While this claim is generally accepted within the field (that linear interpretations are not a novel approach), there isn't strong external evidence or specific examples provided to definitively prove this point. The claim is somewhat broadly stated.", "helpfulness_rationale": "The reviewer's comment identifies a potential limitation in the approach used in the draft. While it doesn't offer a specific solution, it points out an area where the authors could improve their work. This kind of feedback can be helpful for guiding the authors towards better model interpretation techniques."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a problem: 'It is unclear for me why the performance of DNN+MMA becomes worse than vanilla DNN when lambda becomes small? See fig.34.' This directly points to a discrepancy the reviewer is observing. The reviewer then asks a specific question: 'I would expect it will approach vanilla methods from above but from below.' This indicates a clear and actionable issue the reviewer is trying to understand. The reviewer is directly asking for clarification on a specific experimental result.", "grounding_specificity_rationale": "The review point explicitly refers to 'fig.34' as the source of the information. This clearly grounds the comment to a specific part of the paper. Furthermore, the reviewer makes a specific claim about the *expected* behavior based on these figures: 'I would expect it will approach vanilla methods from above but from below.' This specificity indicates that the reviewer has a clear idea of what they are referring to and what they expect to see.", "verifiability_rationale": "The review point contains a claim: 'the performance of DNN+MMA becomes worse than vanilla DNN when lambda becomes small.' This is a statement that requires verification. The reviewer then provides evidence (fig.34) to support their observation. While the reviewer's expectation is based on a common understanding, the *observation* of the figures constitutes evidence. The claim is supported by logical reasoning (the figures) and potentially external references (the figures themselves).", "helpfulness_rationale": "The review point is highly specific and directly addresses a potential issue the authors might be facing. The reviewer clearly states what is *wrong* (performance degradation) and what they *expect* (improvement). This provides the authors with a clear direction to investigate the figures and potentially identify a problem in their experimental setup or implementation. The reviewer's expectation is reasonable, making this a potentially impactful observation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states 'The paper does not compare the results with some of the earlier research work from 2020.' This is an explicit statement of a missing comparison. However, the reviewer does not specify which earlier work from 2020 is being referred to, nor does he suggest any concrete actions for the authors to take regarding this missing comparison. Therefore, while the action is explicit, the lack of specificity makes it 3 but not fully actionable.", "grounding_specificity_rationale": "The reviewer states 'earlier research work from 2020' and specifically names 'Taghipour and Ng (2016)'. This clearly identifies the specific part of the paper being addressed, making the grounding fully grounded. The comment also specifies what is missing \u2013 the comparison to this specific work. Therefore, the grounding is explicit and identifies the relevant part of the paper and the issue.", "verifiability_rationale": "The reviewer makes a claim: 'The paper does not compare the results with some of the earlier research work from 2020.' The reviewer also states that the authors have explained their reasons for not doing so. This provides some level of support for the claim. However, the reviewer does not provide any examples or references to support the claim that the authors' reasons are sufficient or logical. Therefore, the claim is supported by the authors' explanation, making it 3.", "helpfulness_rationale": "The reviewer points out a missing comparison with earlier work, which is a valid point for improvement. However, the reviewer does not provide specific, actionable suggestions for the authors to make regarding this missing comparison. The reviewer's comment is more of a pointer to an area of improvement rather than a direct solution. Therefore, while the comment is helpful in identifying a weakness, it lacks the depth needed for full helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests using a paired test instead of an independent samples ttest. This is a clear and actionable improvement that directly addresses a potential flaw in the statistical analysis. The reviewer identifies the issue (comparing two samples generated from the same input) and proposes a specific methodological change. This action is concrete, as the reviewer clearly states the desired statistical test.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'significane testing' and suggests a change in the test used for significance testing. This demonstrates a clear identification of the specific issue (potential flaw in the statistical analysis) and a specific suggestion for improvement. The reviewer directly addresses the comparison between two samples generated from the same input, pinpointing the methodological concern. The suggestion is directly tied to the identified problem.", "verifiability_rationale": "The reviewer claims that the choice of test might be incorrect and suggests a paired test. While the reviewer doesn't provide a detailed explanation *within this review point* of why the independent test might be incorrect or why the paired test is better, their suggestion implies an understanding of the statistical principles involved. The reviewer is making a claim about the appropriateness of the test, and the suggestion to use a paired test is a logical consequence of the identified issue (samples from the same input).", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion to use a paired test instead of an independent samples ttest. This is a highly specific and actionable improvement that directly addresses a potential flaw in the statistical analysis. The reviewer identifies the issue and offers a concrete solution, making this a 5 comment for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the desired improvements (comprehensive and general experiments) and provides clear reasons (limited model size and restrictive baselines). The reviewer directly indicates what needs to be done, making it 5.", "grounding_specificity_rationale": "The review point discusses the need for more comprehensive experiments in the context of language modeling and image classification. While it mentions these areas, it doesn't specify a particular section, table, or figure within the paper. The grounding is at the level of the task type rather than a specific element, making it weakly grounded.", "verifiability_rationale": "The review point contains a claim that the experiments should be more comprehensive and general. This claim is supported by the reviewer's reasoning that the current model size is limited and the baselines are restrictive. While the authors can infer these limitations themselves, the reviewer's point is based on an assessment of the existing work, making it 3.", "helpfulness_rationale": "The review point is 5 because it clearly identifies areas for improvement (comprehensiveness, generalization, model size, baselines) and provides a rationale for these suggestions. The reviewer guides the authors in enhancing their work with specific, actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential misunderstanding or misapplication of Hoeffding's inequality in the paper's analysis. They explicitly state that the inequality holds true as long as the samples are drawn independently and that stochastic algorithms further guarantee this. This is an explicit statement that suggests a potential issue with the paper's claim about the conditions for Hoeffding's inequality. While the reviewer doesn't provide a specific section or table, the topic itself is related to the paper's methodology, making it 3.", "grounding_specificity_rationale": "The reviewer is discussing a general statistical principle (Hoeffding's inequality) in the context of a specific analysis in the paper. While the topic is relevant to the paper's methodology, the reviewer doesn't explicitly point to a specific section, table, or figure where this issue arises. The connection is implied but not clearly established, making it weakly grounded. However, the topic is directly related to the paper's content, so it can be considered somewhat specific.", "verifiability_rationale": "The reviewer makes a claim about the conditions under which Hoeffding's inequality holds, questioning the paper's assertion. They suggest that the inequality is always true under certain conditions and that stochastic algorithms further guarantee this. This is a claim that can be verified by examining the specific equation and the conditions under which Hoeffding's inequality is typically applied. While the reviewer doesn't provide a specific equation, the claim is verifiable based on the general principles of the inequality. Therefore, it is 3.", "helpfulness_rationale": "The reviewer's comment is directly relevant to the paper's methodology, specifically the application of Hoeffding's inequality. They point out a potential misunderstanding or a need for clarification regarding the conditions under which the inequality holds. This is a helpful comment because it identifies a potential weakness in the paper's analysis and suggests that the stochastic algorithms might offer a better understanding. The reviewer's point is clear and directly addresses a potential issue, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks if it is possible to add a metalearning approach to Table 1, specifically mentioning MAML/implicitMAML. This directly suggests a concrete action the authors could take, making it 5.", "grounding_specificity_rationale": "The review point directly refers to 'Table1', accurately identifying the specific part of the paper. While the 'why' isn't fully elaborated, the 'what' (adding a metalearning approach to this table) is clear, making it 3.", "verifiability_rationale": "The review point is a suggestion rather than a definitive claim. It proposes a possibility but doesn't provide evidence or references to support it, resulting in X.", "helpfulness_rationale": "The review point is very specific and suggests a concrete improvement by adding a metalearning approach to Table 1. While it's a suggestion and not a guarantee of success, it points towards a valuable direction for the authors, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an improvement (an ablation study) and provides a *potential* reason (prompt choice) for it. This suggests it's at least partially actionable. However, it could be more specific about *which* prompts to try and *why* the current prompt is insufficient.", "grounding_specificity_rationale": "The review point is very general. It doesn't specify *which* prompt is being referred to (fewshot, zeroshot, specific prompt details). It also doesn't pinpoint where in the paper this issue arises (e.g., introduction, method section). The reviewer can't confidently identify the specific part of the paper or the exact prompt being discussed.", "verifiability_rationale": "The reviewer point contains a claim: \"The paper lacks an ablation study explaining why they chose the prompt in this specific way\". This is a statement of opinion. However, the reviewer doesn't provide any justification for this claim. They don't explain *why* an ablation study is needed or *why* the prompt choice is questionable. They simply state the problem without supporting evidence.", "helpfulness_rationale": "The review point is relevant and encourages the authors to consider an improvement (an ablation study). However, the lack of specific details about the ablation study makes the suggestion somewhat vague and less immediately actionable. The reviewer doesn't tell the authors *exactly* what prompts to try or *how* to conduct the ablation study. They also don't explain *why* the current prompt is a problem."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment points out a potential misunderstanding or imprecision in the use of terminology. While it doesn't directly instruct the author on what to change, it highlights a specific area where clarification is needed. The reviewer is implicitly suggesting that the authors should be more careful about the distinction between causality and temporal relationships.", "grounding_specificity_rationale": "The comment explicitly mentions the specific concepts being discussed: 'causal mechanisms', 'causality', and 'temporal relationship'. It accurately identifies the section of the paper (page 1) where this discussion takes place. This demonstrates strong grounding as the author can easily pinpoint the relevant part of the paper.", "verifiability_rationale": "The comment itself does not contain a claim that can be verified. It is a suggestion for improvement rather than a statement that can be supported by evidence. While it implies a potential issue with the author's writing, it lacks the necessary elements of a verifiable claim, such as specific examples or references.", "helpfulness_rationale": "The comment is helpful in that it points out a potential area for improvement in the author's writing. It encourages the author to be more precise about the distinction between causality and temporal relationships. While it doesn't provide a solution, it highlights a valuable point that can lead to better clarity in the paper."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue: 'replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance' and provides a comparative statement: 'better than random is a strong demonstration of capability.' This is an explicit statement of a problem and a suggestion for improvement. While the exact location of the procedure step isn't specified, the type of procedure step and the outcome are clear, making it concrete.", "grounding_specificity_rationale": "The reviewer refers to 'procedure steps of XAIFOOLER,' which clearly identifies a part of the paper being discussed. This can be considered 'Full Grounding' as the concept is directly referenced. However, the reviewer doesn't specify a 'specific' procedure step, and they don't provide a 'specific example' of where the random mechanism might be implemented. This makes the grounding somewhat underspecific.", "verifiability_rationale": "The reviewer makes a claim: 'I'm unsure that 'better than random' is a strong demonstration of capability.' However, they do not provide any evidence or justification for this claim. The reasoning, common knowledge, or external references are missing, making the claim 1.", "helpfulness_rationale": "The reviewer points out a potential flaw in the methodology or implementation of the XAIFOOLER algorithm. They are suggesting that a simple random mechanism could potentially outperform a more complex procedure within XAIFOOLER, which raises concerns about the effectiveness or novelty of the proposed method. While the reviewer doesn't offer a direct solution, they highlight a weakness that needs addressing. This can be helpful for the authors to understand a limitation of their approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they would like a discussion of a specific paper and a specific concept within that paper. The action is to discuss the paper, and the implementation is to discuss the specific concept.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific paper \"On the Complexity of Learning with Kernels\" and the specific concept \"kernel learning using lowrank approximation\". This is strong grounding as the paper and concept are clearly identified. The specificity is high as the reviewer is not just saying \"related work\" but a very specific theoretical result.", "verifiability_rationale": "The reviewer makes a claim that the paper should discuss the specified related work. The verification comes from the fact that the paper does discuss kernel learning and lowrank approximations, making the suggestion relevant and plausible.", "helpfulness_rationale": "The reviewer directly points out a specific weakness in the paper: the lack of discussion of a relevant piece of work. The suggestion is actionable (add the discussion), wellgrounded (specific paper and concept), and verifiable (the paper covers the relevant area). This directly helps the authors improve their draft by guiding them to include this relevant theoretical context."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point primarily asks a question ('How well are the assumptions met?') rather than explicitly stating an action or instruction. While the reviewer is implicitly suggesting that the lack of clarity on PCA assumptions is a weakness, the point itself doesn't directly guide the author on how to address this weakness. The action is implied, not explicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'PCA to reduce interaction count' and refers to a specific paper (1) as relevant context. This demonstrates a clear grounding of the comment in the technical details of the paper and relevant external knowledge. The reviewer is directly addressing a potential issue related to a specific aspect of the paper.", "verifiability_rationale": "The reviewer poses a question about the assumptions of PCA, which requires the author to provide justification or evidence. While the reviewer doesn't explicitly state a claim, the request for clarification about assumptions implies a need for verification and justification. The potential for verification exists, but it's not currently presented with supporting evidence or references within the review point itself.", "helpfulness_rationale": "The reviewer explicitly states that the point is unclear to them ('How well are the assumptions met?') and requests clarification. This directly addresses a potential weakness for the author and provides a clear direction for improvement. The request for justification and connection to related work also has the potential to be very helpful. The information is presented in a way that directly addresses a potential lack of understanding."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the fewshot RC models considered are not stateoftheart and suggests a comparison with relation extraction/generation models. This is an explicit action that is concrete, as it clearly identifies the models and the suggested comparison. The reviewer proposes a specific analysis to be conducted.", "grounding_specificity_rationale": "The review point explicitly mentions 'fewshot RC models' and 'relation extraction/generation models in fewshot settings.' This clearly identifies the specific parts of the paper being referred to, indicating strong grounding. The reviewer names the model types and the experimental setup, making it easy to understand which aspects are being discussed.", "verifiability_rationale": "The review point contains a claim that 'the fewshot RC models considered in the paper are not stateoftheart models'. This claim is not 5 within the review point itself, as it relies on the reviewer's external knowledge of what constitutes stateoftheart models. However, the suggestion to 'how does the performance compare to relation extraction/generation models in fewshot settings' is a request for information rather than a claim requiring verification. The core of the claim is about the *absence* of SOTA models, which is a statement of opinion.", "helpfulness_rationale": "The review point identifies a potential limitation in the methodology (using nonSOTA models) and suggests a concrete improvement (comparative analysis with relation extraction models in a fewshot setting). This is a valuable and actionable suggestion that directly addresses a potential weakness and provides a clear direction for further investigation. It helps the authors understand the relative performance of their models compared to a relevant category of models."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action: 'the results in section 4 apply only to shallow fullyconnected ReLU networks.' It clearly indicates what needs to be addressed (section 4) and the limitations (shallow fullyconnected ReLU networks). This makes the action clear and actionable for the author.", "grounding_specificity_rationale": "The comment explicitly mentions 'section 4' and 'shallow fullyconnected ReLU networks,' precisely identifying the part of the paper being referred to. This is a clear and accurate grounding of the comment.", "verifiability_rationale": "The comment contains a claim: 'the results in section 4 apply only to shallow fullyconnected ReLU networks.' While it doesn't provide a justification for this limitation, it clearly states a factual constraint. This makes the claim 3 as it points to a verifiable limitation within the paper's content or structure.", "helpfulness_rationale": "The comment is 5 as it directly points out a potential issue the author might be facing \u2013 that the results in section 4 are limited to a specific type of network. This is a clear and actionable piece of feedback that guides the author to focus their edits on a specific section and network type."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the desired outcome (adding background and moving related work), making the action somewhat explicit. However, the reviewer doesn't provide details on *how* to achieve these actions, making it vague.", "grounding_specificity_rationale": "The reviewer mentions \"background knowledge\" and \"related literatures,\" but doesn't specify the exact section or element of the paper they are referring to. The comment is too general to be considered grounded.", "verifiability_rationale": "The reviewer states an opinion about the paper's organization but doesn't provide any evidence or justification for this claim. There's no explicit recommendation to *do* something that would be verifiable.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the paper's organization and suggests improvements, which is helpful. However, the suggestions are quite general and lack specific details on how to implement them, making them somewhat vague and potentially less impactful."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'compare with other panoptic segmentation models.' This is a clear instruction for the authors to take a specific step in their work. The suggestion to include 'PanopticFPN' and 'Mask2Former' provides concrete examples of models to compare with, making the action even more explicit. The authors know exactly what needs to be added to their paper.", "grounding_specificity_rationale": "The review point explicitly mentions 'PanopticFPN' and 'Mask2Former' as examples of other panoptic segmentation models. This is a strong example of grounding specificity, as the authors can directly identify the specific part of the paper being addressed (the 'other panoptic segmentation models') and the specific elements within it (the named models).", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion to include more comparisons. Therefore, it does not fit into the 'Claim Extraction' category. The 'Assess Verifiability' step would classify this as 'X'  X, as it does not present an opinion, judgment, or suggestion that needs to be supported.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the authors to improve their draft. By suggesting the inclusion of comparisons with other panoptic segmentation models, it directly points to a potential weakness or area for improvement in their current work. The specific mention of 'PanopticFPN' and 'Mask2Former' makes the suggestion concrete and provides a starting point for the authors to explore additional baselines. This level of detail and direction is highly beneficial for the authors in enhancing their research and experimental evaluation."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out a lack of results and asks about the observed outcomes of the MCB vs. MCT comparison. While this is a valid observation, the comment does not explicitly state what action the authors should take based on this missing information. The authors are not told to change anything or to add something specific. The comment is more of a request for clarification and further details rather than a direct instruction on how to improve the draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the discussion of using sequential MCB vs a single MCT layers for the decision head'. This clearly identifies a specific aspect of the paper being discussed. The comment also asks about the 'observed' results, indicating a desire to understand what happened in that specific comparison. Therefore, the reviewer's comment is fully grounded as it refers to a specific section and asks for information about a specific outcome.", "verifiability_rationale": "The reviewer states 'no results were shown' and asks about the 'observed' results. This is a statement of fact and a request for information. It does not contain a claim that can be verified through logical reasoning, common knowledge, or external references. The comment is a statement of a gap in the results, not a claim that needs verification.", "helpfulness_rationale": "The reviewer's comment is not directly helpful in improving the draft. They are pointing out a missing element (results) and asking for more information about a specific comparison. While this is a valid point for the authors to consider, it does not provide a concrete action or suggestion on how to improve the draft. The comment is more of a request for clarification and further details rather than a direct critique of a flaw or a suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies areas for improvement in language usage and suggests fixes. While the reviewer points out 'minor comments' on language, the act of identifying grammatical errors and suggesting improvements constitutes an action. The reviewer could be more specific about the desired changes, but the intention is clear. The reviewer also mentions 'sensitivity to other hyperparameters', which could be interpreted as an implicit action to ensure the model's performance is not affected by these parameters. However, the lack of concrete steps makes it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific instances where language usage could be improved, such as 'we typically considers'. This demonstrates a clear grounding of the comment in the specific parts of the paper being discussed. The reviewer also provides general suggestions for improvement related to these instances, indicating an understanding of what needs to be addressed.", "verifiability_rationale": "The reviewer makes claims about the language usage, such as 'language usage: minor'. They also provide specific examples of grammatical errors, like 'we typically considers'. The reviewer suggests improvements based on these examples, indicating that the claims are verifiable through logical reasoning and examples. The reviewer's suggestions are directly linked to the identified issues.", "helpfulness_rationale": "The reviewer provides a list of specific issues related to language usage and suggests concrete improvements. For example, they point out 'we typically considers' and suggest 'improve language clarity and precision'. This directly identifies problems and offers actionable steps, making the review 5 to the author. The reviewer also provides a general statement about the impact of these issues on the model's performance, further emphasizing the importance of addressing them."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a lack of clarity regarding the choice of 20 distribution sets and provides a clear action for the authors to take: 'What if you select only few number of distribution set?'. This directly addresses a potential ambiguity and guides the authors to investigate further.", "grounding_specificity_rationale": "The reviewer mentions the number '20' and suggests 'controlling the number of distribution sets'. This clearly identifies the specific aspect of the paper being referred to, making the grounding explicit. The suggestion to control the number is also a specific action.", "verifiability_rationale": "The reviewer is not making a claim that needs to be verified. They are asking for clarification on a specific parameter (the number of distribution sets). Therefore, it does not fall under the 'verifiability' aspect.", "helpfulness_rationale": "The reviewer's suggestion to control the number of distribution sets directly addresses a potential point of confusion for the authors. It provides a clear direction for further investigation and potential experimentation, making it a helpful suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a statement of opinion, not a direct instruction or suggestion. It doesn't provide clear actions for the authors to take based on the criticism. The reviewer expresses concern about the framework's limitations but doesn't specify what needs to be improved or how the authors should proceed.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or the framework that is affected by the criticism. It broadly criticizes the framework's scope without pinpointing the relevant sections or experiments.", "verifiability_rationale": "The review point contains a claim ('somewhat limited scope') but does not provide any evidence or reasoning to support this claim. It expresses a concern about the framework's potential generalization without backing it up with logical arguments or references.", "helpfulness_rationale": "The review point expresses reservations about the method's broader applicability but does not offer specific, actionable feedback or suggestions on how the authors' current draft could be improved based on this criticism. It's a concern about the framework itself, not about the current work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem of using obsolete models and suggests transformerbased models as a solution. This indicates an explicit action, but the lack of specific implementation details makes it less actionable.", "grounding_specificity_rationale": "The reviewer names specific models (ngram HMM, RNN) and suggests transformerbased models. This demonstrates a degree of grounding in the review itself by mentioning specific examples. However, the paper itself isn't explicitly criticized for not using these models, so it's not fully grounded in the paper's content.", "verifiability_rationale": "The reviewer makes a claim about the models being obsolete and suggests transformerbased models. While this claim could be verified by checking publication dates and current trends, the review point itself doesn't provide specific evidence to support this claim. Therefore, it's only 2.", "helpfulness_rationale": "The reviewer provides a clear and relevant suggestion to update the perplexity experiments using more current models. This is a helpful comment for the authors as it directly addresses a potential limitation and provides a concrete direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point is a statement of opinion ('The experiments are not sufficient') rather than a direct instruction or suggestion. It doesn't explicitly tell the authors what to do or how to improve their experiments. While it implicitly suggests that more experiments are needed, it doesn't pinpoint which experiments or how to conduct them. Therefore, it lacks explicit and concrete actionability.", "grounding_specificity_rationale": "The review point refers to 'the experiments' in general. It does not specify which part of the paper or experiments is being addressed. The reviewer does not identify a specific section, table, figure, or unique aspect of the paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses. While the reviewer mentions 'empirical experiments' and 'toy experiments,' these are not explicitly linked to a specific part of the paper being discussed in the review point itself.", "verifiability_rationale": "The review point contains a claim: 'The experiments are not sufficient.' The reviewer offers a suggestion: 'More empirical experiments or toy experiments (for the simplified selfattention model considered in the theoretical analysis) need to be done to show the validity of the model relaxations and the consistence of the theoretical analysis with empirical results, besides citing the result in Kaplan et al. 2020.' This provides a potential direction for improvement, acting as supporting evidence for the claim. However, the support is not fully detailed. While the suggestion is helpful, it doesn't provide specific examples of what kind of additional experiments would be beneficial, nor does it cite specific literature to back up this claim beyond Kaplan et al. 2020. Therefore, the claim is somewhat supported but lacks key elements like examples or references in its current form.", "helpfulness_rationale": "The review point identifies a weakness in the experiments ('the experiments are not sufficient') and offers a suggestion ('More empirical experiments or toy experiments... need to be done'). While the suggestion is helpful in general, it is broad and lacks specific details about what kind of additional experiments would address the identified weakness. The reviewer doesn't specify which aspects of the experiments are problematic or provide concrete steps for improvement. Therefore, while the point is relevant and offers a general direction, it lacks the specificity and actionable steps needed for the authors to fully benefit from it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the difficulty in estimating mu, which is a concrete piece of information. While they don't provide specific steps, the identification of the problem is actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'mu, but as it is the proportion of missing observations.' This directly identifies the specific parameter being discussed, indicating strong grounding. However, they do not specify *how* to estimate it, making the specificity low.", "verifiability_rationale": "The reviewer makes a claim that 'as it is the proportion of missing observations  it is not wholly clear how it can be estimated at all.' This is a claim about the lack of clarity. While they don't provide external references or logical reasoning to support this claim, the statement itself is verifiable as an observation about the situation.", "helpfulness_rationale": "The reviewer points out a significant issue (difficulty in estimating mu) but does not offer any suggestions or guidance on how to address it. While they identify a problem, they don't provide actionable steps for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer proposes a specific change to the experimental setup by varying the distance of initialization M^0 to the groundtruth M^*. They suggest using a parameter 'c' to control this distance, ranging from 0.01 to 0.1. This is an explicit action with concrete details on how to implement it. The reviewer clearly states the goal: to report performance as a function of this distance and expects that the mean error and variance will increase as the quality of initialization decreases. This provides a clear path for the experiment and directly addresses the sensitivity to initialization.", "grounding_specificity_rationale": "The reviewer explicitly defines the variable 'c' as the distance between the initialization matrix M^0 and the groundtruth matrix M^*. They also specify the range for 'c' as 0.01 to 0.1. This demonstrates strong grounding specificity as the authors can easily identify the section where the initialization is discussed and the unique element being varied (the distance 'c'). The language is precise and directly addresses a specific part of the paper.", "verifiability_rationale": "The reviewer provides a clear methodology for how the experiment could be conducted. They specify the metric (performance as a function of the distance 'c'), the range of 'c', and the expected outcome (increased mean error and variance with decreasing initialization quality). This is logically sound and provides a basis for empirical validation. The reasoning is clear, and the claim is wellsupported by the proposed methodology. The use of logical reasoning (expecting increased error and variance) and the provision of a clear experimental design contribute to verifiability.", "helpfulness_rationale": "The reviewer's suggestion to vary the distance of initialization is 5. It directly addresses the potential sensitivity of the model to initialization, a common issue in machine learning. By proposing a specific experiment to quantify this sensitivity, the reviewer provides a concrete and actionable step for the authors to take. This is a valuable contribution that could significantly improve the robustness and reliability of the results. The suggestion is clear, specific, and directly addresses a potential weakness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential simplification in the Frobenius norm definition, which could be considered an implicit action. However, it doesn't explicitly state how the absolute value can be removed or what the implications are for the definition. The action is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The comment explicitly mentions the Frobenius norm definition (line 77), making it fully grounded. It clearly identifies the issue with the definition (unnecessary absolute value for real numbers).", "verifiability_rationale": "The claim that the absolute value is unnecessary for realvalued tensors is generally verifiable. The reasoning is based on the fact that the Frobenius norm for real matrices is typically defined using the squared sum of elements, and taking the square root of the sum of squared elements inherently yields a nonnegative result, making the absolute value redundant. However, the comment doesn't provide specific examples or references to external works to support this claim.", "helpfulness_rationale": "The comment points out a minor detail in the Frobenius norm definition that could make it clearer or more efficient for realvalued tensors. It suggests a potential simplification. While the suggestion is valuable, the comment itself doesn't explicitly guide the author on the next step or how to implement the simplification. The helpfulness is moderate as it points out a potential improvement without providing immediate actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a limitation in the methodology (only expectation bounds) and suggests a potential solution (using ensemble methods). While it points out an actionable item (improving bounds), it doesn't explicitly state how to achieve this improvement. The suggestion to use ensemble methods is implicit, requiring the reviewer to connect it to their experience in the experiments. Therefore, while the action is implied, the explicitness and concreteness of the action are lacking.", "grounding_specificity_rationale": "The review point discusses a general limitation of the methodology (bounds) and suggests a potential improvement (ensemble methods). It doesn't explicitly refer to a specific part of the paper being addressed, nor does it detail what is wrong with the current bounds. The mention of 'expectation bounds' is general and doesn't pinpoint a specific issue within the paper's content. The suggestion of 'ensemble methods' is also general and doesn't specify which part of the paper would benefit from it. Therefore, the grounding of the issue and the proposed solution is weak.", "verifiability_rationale": "The review point identifies a limitation in the current methodology (only expectation bounds) and suggests a potential improvement (ensemble methods). While it provides a suggestion based on common knowledge (ensemble methods are used in experiments), it doesn't explicitly connect the use of ensemble methods to a specific gap in the current approach. The suggestion is somewhat general and doesn't provide a detailed explanation of *why* ensemble methods would lead to highprobability bounds in this specific context. Therefore, the claim is present, but the supporting evidence is somewhat lacking in detail and specificity.", "helpfulness_rationale": "The review point identifies a valid limitation in the current methodology (only expectation bounds) and offers a relevant suggestion (using ensemble methods, which are mentioned in the experiments). It highlights a potential area for improvement and provides a direction for future work. While it doesn't provide a direct solution or specific steps, it points towards a concrete and actionable improvement. The suggestion about robustness further adds value. Therefore, the review provides a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states their opinion about the results being 'less impressive' without specifying what needs to be improved or how to achieve it. While they imply a desire for more concrete feedback, the action is not explicitly stated. The reviewer suggests improvements but doesn't detail how to implement them.", "grounding_specificity_rationale": "The reviewer mentions 'more aspects' for evaluation, but they do not explicitly state which parts of the paper or results they are referring to. The grounding is weak because the specific area being addressed is not clearly identified.", "verifiability_rationale": "The reviewer's assessment of the results being 'less impressive' is a subjective opinion without any supporting evidence or justification. The claim is not verifiable based on the information provided.", "helpfulness_rationale": "The reviewer's comment is primarily an opinion about the results and a suggestion for improvement, rather than a constructive critique with actionable feedback. The helpfulness is limited as the comment does not provide clear guidance or identify specific weaknesses in the work itself."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'there is no diversity' and implies the model *should* enforce it. This is a clear, actionable piece of feedback. The reviewer *knows* what they want (explicit diversity enforcement) and *knows* what is currently present (lack of explicit diversity). The vagueness lies in *how* they want it enforced (e.g., specific mechanisms, regularization terms).", "grounding_specificity_rationale": "The reviewer mentions the title contains 'diversity' and the paper 'motivates' diversity extensively. While they don't point to a specific section or table, they clearly identify the *concept* being overemphasized without explicit implementation. This shows grounding at the *conceptual* level.", "verifiability_rationale": "The reviewer states 'My biggest concern with this paper is the fact that it motivates diversity extensively (even the word diversity is in the title)'. This is a statement of concern and a factual observation about the paper's content. It's a claim about the paper's *presentation* and *motivation*. The reviewer *doesn't* provide external references or logical reasoning *within this review point* to *prove* the model doesn't enforce diversity. The support comes from the reviewer's own analysis of the paper.", "helpfulness_rationale": "The reviewer clearly identifies a significant concern (lack of explicit diversity) and points to the paper's emphasis on it. This highlights a potential disconnect between the paper's stated goals and its implementation. While the *how* is vague, the *what* and *why* are clear. This is a valuable piece of feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a weakness ('some experiments are missing') but does not specify what needs to be added or how to improve the draft based on this information. It's a statement of what is lacking, not what to do about it.", "grounding_specificity_rationale": "The comment mentions 'experiments' in general and then provides examples of missing experiments. While it hints at the type of experiments missing, it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper where these experiments are supposed to be. The examples are general, not specific to a particular part of the paper.", "verifiability_rationale": "The comment states a fact ('some experiments are missing') and provides examples. It doesn't make a claim that requires verification or justification. It's a descriptive statement about the current state of the experiments.", "helpfulness_rationale": "The comment identifies a valid point for improvement (the lack of certain types of experiments). However, it doesn't offer concrete suggestions or explain why these experiments are important or missing. It's a diagnosis of a lack, but lacks a prescription for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weaklyly Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an improvement to the bounds but doesn't explicitly state what needs to be done. While it implies an 'independent improvement,' it lacks specific actionable steps.", "grounding_specificity_rationale": "The review point mentions 'graphs' and 'results' but doesn't specify which part of the paper or methodology is affected. The suggestion of using the 'independence number' is general and lacks a clear reference to a specific section or detail.", "verifiability_rationale": "The review points out a discrepancy between bounds and suggests an 'independent improvement.' While it implies a potential issue, it doesn't provide a clear justification or evidence for why the independence number might be a better bound. The reasoning is present but lacks depth and specific references.", "helpfulness_rationale": "The review points out a significant discrepancy between theoretical bounds and suggests an alternative approach (using the independence number). This implies a clear action: investigate the independence number and potentially adjust the bounds. While the justification isn't fully developed, the suggestion of a concrete improvement makes it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states they 'recommend using DinoV2 Frechet Distances' as an alternative to FIDs, which is a direct action. However, the reviewer does not provide specific steps on how to implement this change or what modifications are needed. The action is stated, but the concrete steps are missing.", "grounding_specificity_rationale": "The reviewer clearly identifies 'FIDs' as the problematic metric and suggests an alternative ('DinoV2 Frechet Distances'). They also implicitly refer to the 'Inception network' as the tool associated with the criticized metric. This strong identification of the specific part of the paper and the proposed solution indicates high grounding specificity.", "verifiability_rationale": "The reviewer states that there are 'clear flaws' associated with FIDs and the Inception network, but they do not elaborate on these flaws within the review point itself. They recommend DinoV2 but do not provide any logical reasoning, examples, or references to support the claim that DinoV2 is a superior alternative in this context. The claim is made without sufficient justification based on the information provided in this review point.", "helpfulness_rationale": "The reviewer clearly identifies a problem with a widely used metric (FIDs) and provides a direct recommendation for improvement by suggesting an alternative (DinoV2 Frechet Distances). This is a valuable piece of feedback that directly addresses a common issue. The reviewer's suggestion is actionable and directly points to a potential solution, making it 5 for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their concern about the novelty of the work and asks for a comparison to a specific paper. This is an explicit action to identify a potential weakness. The reviewer also mentions the methodology, which makes the action concrete as they identify the area of comparison and the nature of the difference.", "grounding_specificity_rationale": "The reviewer directly names the paper they are comparing to, which is a literal mention of a section or paper. They also clearly states the nature of the comparison (novelty, similar methodology, new task). This makes the grounding 5.", "verifiability_rationale": "The reviewer makes a claim about the novelty of their work relative to another paper. They also ask for a comparison, which is a request for external reference. This claim is verifiable as it points to a specific paper and a specific comparison.", "helpfulness_rationale": "The reviewer's question directly addresses a potential concern for the authors regarding the novelty of their work. By providing a specific paper for comparison, they are offering a concrete point of reference and potentially highlighting a gap in their contribution. This directly helps the authors understand the context of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a problem: 'In the reported ablation studies in Table 2, for CUB and SOP datasets, the complete loss function performed even worse than those with some terms missing. That does not appear to make sense.' They also indicate what they expect: 'Why?' This is a clear and direct action taken on the part of the reviewer. The reviewer is asking for clarification on a specific experimental result.", "grounding_specificity_rationale": "The reviewer directly references 'Table 2', 'CUB dataset', and 'SOP dataset' in their review point. This is a very explicit grounding of the comment to the specific document and the specific datasets and columns being discussed. They also specify the columns being compared ('complete loss function' vs. 'some terms missing'). This is highly specific.", "verifiability_rationale": "The reviewer makes a claim: 'In the reported ablation studies in Table 2, for CUB and SOP datasets, the complete loss function performed even worse than those with some terms missing. That does not appear to make sense.' This is a verifiable claim. However, the reviewer does not provide any explanation or reasoning *within the review point itself* to support why this might be the case. The expectation is that the original paper or the authors should be able to explain this discrepancy. The lack of internal explanation makes it 3 but not fully so.", "helpfulness_rationale": "The reviewer identifies a clear issue: a discrepancy in the experimental results presented in Table 2. They explicitly state what they find 'not to make sense' and ask for an explanation ('Why?'). This is a 5 and constructive suggestion for improving the clarity and understanding of the experimental findings."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a clear and explicit suggestion for improvement by proposing specific experiments to address potential limitations in the model. The suggestion is concrete, detailing the type of experiments (occluded image, keypoint detection failure simulation, longrange inference inspection) and their intended purpose. The reviewer directly states the action of running these experiments and their expected outcomes, making it actionable for the authors. The request is very direct and prescriptive about what the authors should do.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific aspects of the model they are targeting with their suggestions. They state that the experiments will 'simulate the irregularity that is often present in neural/behavioral data' and 'allow us to inspect the longrange \u201cinference\u201d capacity of the model'. This demonstrates strong grounding specificity as the reviewer not only identifies the *type* of experiment but also the *specific problem* they aim to address within the model. The reviewer also mentions 'keypoint detection failed for some mice in some frames' which is a very specific detail. The suggestion directly addresses specific limitations or areas for improvement in the model's performance.", "verifiability_rationale": "The reviewer presents a claim that the model's performance might be affected by irregularities in the data and that the longrange inference capacity needs to be assessed. The reviewer provides a logical reasoning for this claim by stating that 'irregularity that is often present in neural/behavioral data' could indeed affect the model's performance and that 'inspecting the longrange \u201cinference\u201d capacity of the model' would allow for a better understanding of these limitations. The reviewer also provides a practical example of how this could be tested by simulating keypoint detection failures. The claim is wellsupported by logical reasoning and a clear purpose for the suggested experiments.", "helpfulness_rationale": "The reviewer provides a clear and helpful suggestion for improvement. They explicitly state the *type* of experiments they believe would be beneficial and provide a *reason* for this suggestion based on common challenges in neural/behavioral data and model analysis. The reviewer's request is not just a suggestion; it's a welljustified and practical recommendation for the authors to improve their model. The suggestion is actionable, specific, and directly addresses potential limitations."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"I think figure 6C is a bit awkward\" and suggests an action \"I would suggest using a second yaxis or another visualization\". This indicates a clear and actionable improvement the authors should consider.", "grounding_specificity_rationale": "The reviewer directly identifies \"figure 6C\" as the problematic element and provides a specific suggestion \"use a second yaxis\". This demonstrates a clear and specific reference to the relevant part of the paper and the proposed improvement.", "verifiability_rationale": "The reviewer makes a claim about the visualization being \"awkward\" and suggests a \"change\". This claim can be supported by the visual representation of the data, and the suggestion to use a second yaxis is a common and logical solution to avoid misinterpreting negative rates. While not explicitly citing external work, the reasoning is based on standard data visualization practices.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for improving the visualization of figure 6C. The suggestion to use a second yaxis is a direct and actionable step that would likely enhance the clarity and accuracy of the representation. This is a valuable and constructive feedback for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "High", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states they do not understand the technical terms in the abstract and asks for clarification. This clearly indicates an explicit action that needs to be taken to understand the meaning of the statement. The request for clarification is also concrete, specifying that the terms are unclear.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific part of the abstract as being unclear. They make a general statement about the abstract being unclear due to technicalities. Therefore, the grounding is weak as the authors cannot confidently pinpoint the problematic section.", "verifiability_rationale": "The reviewer makes a claim that the abstract is unclear and contains technicalities. They also suggest making it highlevel, which can be seen as a form of justification. However, the support for this claim within this review point is limited to the statement itself and the request for clarification, without providing specific examples or references.", "helpfulness_rationale": "The reviewer's request for clarification directly addresses a perceived weakness in the abstract. Their suggestion to make it highlevel is a concrete improvement idea. While the review point itself doesn't provide external references, it clearly identifies an area for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential area for improvement (complexity of Algorithm 2) but does not specify how or what aspects need improvement. It is implicit, making it difficult for the author to take a concrete action.", "grounding_specificity_rationale": "The review point explicitly mentions 'Algorithm 2' but does not specify which part of the algorithm or what specific issue within it needs improvement. This makes the grounding weak.", "verifiability_rationale": "The review point does not contain a claim, making it 1.", "helpfulness_rationale": "The review point is a general suggestion and lacks specific details on how to improve the complexity of Algorithm 2. While it points to a valid area, the lack of actionability makes it less helpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests exploring other modalities, but it doesn't specify *which* modalities, *how* to explore them, or *why* this would be beneficial. It's a vague suggestion. (1)", "grounding_specificity_rationale": "The review point is a general suggestion about the type of results the authors should present, not about any specific part of the paper. It doesn't identify a specific section, table, figure, or unique aspect of the paper. (1)", "verifiability_rationale": "The review point is a suggestion, not a declarative statement requiring evidence. Therefore, it doesn't fit the verifiability scale. (X)", "helpfulness_rationale": "The suggestion is relevant to the field (exploring different modalities) and could potentially broaden the authors' understanding and impact. However, it's vague and doesn't provide immediate actionable steps. (3)"}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the shortcomings of the paper: 'The proposed method does not consider how to effectively use \"fewshot\"' and 'how to guarantee the trained model can be generalized well to new tasks with 0/few training steps.' These are direct and actionable criticisms.", "grounding_specificity_rationale": "The reviewer identifies the specific areas where the paper is lacking ('how to effectively use \"fewshot\"' and 'how to guarantee the trained model can be generalized well'). However, they do not explicitly state which part of the paper (e.g., the introduction, methodology, experiments) contains this deficiency. The reviewer refers to the 'entire paper' and 'this paper' generally.", "verifiability_rationale": "The reviewer makes a claim that the paper 'does not consider how to effectively use \"fewshot\"' and 'does not explain how to guarantee the trained model can be generalized well to new tasks with 0/few training steps.' However, the reviewer does not provide any evidence, reasoning, or references to support this claim. They simply state the absence of these elements without explaining why or providing examples from the paper.", "helpfulness_rationale": "The reviewer provides a clear and actionable criticism of the paper. They point out a specific area where the paper is lacking and suggest what the authors should do to address it. This is a valuable piece of feedback for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential area for improvement by suggesting using more sophisticated GP models. However, it lacks specific instructions on how to implement this improvement, making it 3 but not fully actionable.", "grounding_specificity_rationale": "The comment makes a general statement about the GP usage being 'naive' and mentions 'dynamical modeling' and 'Gaussian Process Dynamical Model' in general terms, without specifying which part of the paper or method it's referring to.", "verifiability_rationale": "The comment contains a claim that the GP usage is 'naive' and implicitly suggests it's lacking sophistication by mentioning 'Gaussian Process Dynamical Model'. However, it lacks explicit examples or detailed reasoning within the review point itself to support this claim.", "helpfulness_rationale": "The comment identifies a potential weakness in the GP usage. However, it doesn't provide specific, actionable steps or suggestions on how the author can improve their GP implementation, making it 3 but not fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their disagreement with a specific claim in the appendix (D.4) about the necessity of smaller architectures for language models (LMs) compared to GANs to avoid overfitting. This constitutes an explicit action that the authors should take. While the reviewer doesn't provide a direct solution, they identify a potential area for improvement, making it 3.", "grounding_specificity_rationale": "The reviewer directly references section D.4 of the appendix, indicating a clear understanding of where the issue lies. They also provide a specific example (Zaremba et al. 2014) to support their claim that the baseline models might not be properly regularized. Furthermore, they pose a specific question about the regularization technique (dropout on hidden states), which clearly identifies the area needing attention. This strong grounding and specificity make it '5'.", "verifiability_rationale": "The reviewer makes a claim that the statement in the appendix is questionable and provides evidence (the counterexample of Zaremba et al. 2014) to support their interpretation. They also ask a specific question about the regularization technique, which is a request for clarification and further verification. This claim is wellsupported, making it '5'.", "helpfulness_rationale": "The reviewer directly addresses a potential issue in the appendix (D.4) regarding the necessity of smaller architectures for language models (LMs) compared to GANs to avoid overfitting. They provide a counterexample and a specific question about the regularization technique, which is a valuable contribution. This comment is clear, specific, and directly addresses a potential implementation detail, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that 'some of the ablations mentioned in previous sections are hard to locate' and 'the writing can be improved in this part'. While the reviewer points out a potential issue, they do not explicitly state which ablations are difficult to find or provide specific actions to take. The suggestions are general and lack concrete details. Therefore, the review point lacks explicit and actionable suggestions.", "grounding_specificity_rationale": "The reviewer states that 'some of the ablations mentioned in previous sections are hard to locate'. This indicates a lack of explicit grounding, as the reviewer does not specify which sections or parts of the paper contain the ablations. The suggestion 'the writing can be improved' is vague and does not pinpoint a specific aspect that needs improvement. Therefore, the review point is 1 at all.", "verifiability_rationale": "The reviewer states that 'some of the ablations mentioned in previous sections are hard to locate' and 'the writing can be improved in this part'. These statements are criticisms or suggestions, not claims that require verification. There is no assertion that something is wrong that needs evidence to support it. Therefore, the review point does not contain a claim that needs verifiability.", "helpfulness_rationale": "The reviewer states that 'some of the ablations mentioned in previous sections are hard to locate' and 'the writing can be improved in this part'. These are negative assessments of the information in the previous sections. While identifying areas for improvement is generally helpful, the lack of specific grounding and the vagueness of the suggestions make the feedback less actionable and less useful. Therefore, the review point is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests the authors should 'think more clearly' about the differential privacy application. While this is a general suggestion and not explicitly stated as an action to be taken, it implies a specific area for improvement. The reviewer provides a specific area ('differential privacy application') and a specific issue ('halfbaked'), making the suggestion quite concrete. However, the action is implicit, and the reviewer doesn't specify *how* the authors should think more clearly.", "grounding_specificity_rationale": "The reviewer refers to '2)5)' in their review. This is unclear and does not point to a specific section, table, figure, or unique aspect of the paper. While the *general* area is the differential privacy application, the specific reference is ambiguous. Therefore, the grounding is weak. Furthermore, even if the general area is considered grounded, the specific issue within the DP application is not clearly defined, making the specificity underspecific.", "verifiability_rationale": "The reviewer makes a judgment that the differential privacy application is 'a bit too 'halfbaked''. This constitutes a claim that something is lacking in quality or development. However, the reviewer does not provide any specific examples, citations, or logical reasoning to support this claim. The statement is based on an opinion rather than verifiable evidence. Therefore, the claim is 1.", "helpfulness_rationale": "The review point suggests the authors should 'think more clearly' about the differential privacy application. While this is a helpful direction for improvement, the lack of specific guidance makes it less actionable. The reviewer does not provide concrete steps the authors should take to improve their thinking. The statement is subjective and lacks specific examples or logical reasoning. Therefore, the review point is 3 as it points to a potential area for improvement, but it lacks the necessary specificity and justification to be fully helpful."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement compares two existing approaches, multilingual chainofthought and villa chainofthought, but it doesn't explicitly tell the authors what to do or how to improve their work based on this comparison. It raises a question about the relative contribution of each approach.", "grounding_specificity_rationale": "The comment explicitly mentions 'multilingual chainofthought' and 'villa chainofthought', clearly identifying the specific parts being discussed. It also specifies the comparison being made between the two approaches.", "verifiability_rationale": "The statement presents a claim about the 'incremental contribution' of one approach compared to another. However, it does not provide any evidence, examples, or references to support this claim within the review point itself. It is a statement of opinion without justification.", "helpfulness_rationale": "The comment raises a valid point about the relative impact of different approaches to chainofthought reasoning. It highlights a potential area for further investigation or discussion. While it doesn't directly tell the authors how to improve their specific work, it does point to a relevant difference between two existing methods, making it 3 in identifying a potential area for improvement or further research."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment suggests a more specific type of manipulation ('bimanual manipulation') but does not explicitly state what action the authors should take based on this suggestion. The reviewer implies that the current use of 'robotic manipulation' is too broad, but does not provide a concrete next step for the authors.", "grounding_specificity_rationale": "The comment criticizes the use of the general term 'robotic manipulation' without identifying a specific part of the paper or methodology that is problematic. The reviewer suggests 'bimanual manipulation' as a more precise term, but does not specify why the current approach is inadequate or what needs to be changed. The grounding is weak because the authors cannot confidently determine the exact area of concern.", "verifiability_rationale": "The comment is a critique of the generality of 'robotic manipulation' without providing any external references or logical reasoning to support this claim. It does not present a claim that can be verified. Therefore, it is classified as 'X' (X).", "helpfulness_rationale": "The comment is a critique of the term 'robotic manipulation' and suggests a more specific alternative ('bimanual manipulation') without providing a clear or actionable recommendation for the authors. It is a negative comment that does not offer concrete steps for improvement. Therefore, it is not very helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests providing METEOR results. While this is a clear action, it lacks specific guidance on how the authors should implement this change. The reviewer doesn't specify adding a new section, moving existing data, or creating a new table. The action is to provide the results, but the method of providing them is not defined.", "grounding_specificity_rationale": "The reviewer suggests providing METEOR results, which is a general suggestion about reporting a metric. The reviewer does not specify *where* in the paper the METEOR results should be provided (e.g., as a new section, table, or figure). Additionally, the reviewer does not specify *what* is wrong with the current results or how the METEOR results should be interpreted or discussed. The comment identifies a part of the paper (the paper) that needs improvement (providing METEOR results) but lacks specifics on the implementation.", "verifiability_rationale": "The reviewer makes a suggestion: 'you should provide the METEOR results, which is also reported in recent works 15.' This constitutes a claim that METEOR results are relevant and beneficial. The reviewer provides a justification by referencing recent works, which serves as supporting evidence for the claim. The reference to recent works provides a logical reasoning for why METEOR results might be useful.", "helpfulness_rationale": "The reviewer suggests providing METEOR results. While this is a standard practice in some fields and the reviewer provides a reference to support its relevance, the suggestion itself doesn't directly improve the authors' draft. The reviewer doesn't specify *how* the METEOR results should be presented or how they should address any specific issues in the authors' work. The suggestion is more about improving the evaluation process than directly addressing the authors' manuscript."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem of 'comparability of Geffect values across various unlearning objectives and approaches' and highlights its potential impact on the 'generalizability of conclusions'. This is a clear and actionable point, as it directly identifies a limitation in the experimental design and its implications for interpreting the results. The reviewer also implicitly suggests that this isolation might not reflect the true interactions between unlearning objectives, making the comparison potentially misleading. This provides a concrete direction for the authors to consider when interpreting their results and potentially designing future experiments.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 4' and the specific issue of 'comparability of Geffect values across various unlearning objectives and approaches'. This direct reference to a specific section and a precise description of the problem demonstrates high grounding specificity. The reviewer accurately identifies the location of the concern and the nature of the comparison being questioned. This level of detail allows the authors to directly address the specific area of the paper being criticized.", "verifiability_rationale": "The reviewer raises a concern about the 'comparability of Geffect values across various unlearning objectives and approaches' but does not provide specific examples or references to external work to support this claim within this review point. While the concern is valid and points to a potential methodological limitation, the claim itself is not 5 based solely on the information provided in this review point. The reviewer does not offer any logical reasoning or external references to back up this assertion. Therefore, it is classified as '3' as it points to a potential issue that needs further investigation, but the claim itself lacks strong supporting evidence within this review.", "helpfulness_rationale": "The reviewer raises a valid point about the potential limitations of studying Geffects of each unlearning objective in isolation. This is a helpful comment as it highlights a potential methodological consideration that could affect the interpretation of the results and the generalizability of the conclusions. By pointing out this limitation, the reviewer encourages the authors to consider the interactions between unlearning objectives and whether the isolated effects accurately represent the overall system. This feedback is valuable for improving the authors' understanding and the robustness of their findings."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the UNIFORM method does not always offer a clear advantage, particularly in the 1shot setting. They identify the inconsistency in the results as a weakness. The action is directly stated, and the specifics of the 1shot setting and the UNIFORM method are mentioned, indicating a clear intention to apply the comment.", "grounding_specificity_rationale": "The reviewer specifically mentions 'UNIFORM' and '1shot setting' when pointing out the inconsistency. This direct identification of the method and the experimental condition demonstrates a strong grounding in the relevant part of the paper. The comment clearly specifies the area of concern.", "verifiability_rationale": "The reviewer makes a claim that 'the results in the tables show that UNIFORM does not always offer a clear advantage over the results, especially in the 1shot setting.' This is a direct statement of a finding. The reviewer also states that the results are 'clear,' which provides some level of justification for their claim. However, they do not provide external references or detailed explanations to support this observation.", "helpfulness_rationale": "The reviewer identifies a weakness in the results (UNIFORM's inconsistency in the 1shot setting) and asks for a potential explanation. While they acknowledge the clarity and design of the experiments, their focus is on a specific result. They do not offer a concrete solution or actionable steps for the authors beyond asking a question. The criticism is specific, but it lacks a direct proposal for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the reason why information value is a stronger predictor for dialogue, which is the complementarity discussed in the paper. This is an explicit action suggesting the authors should investigate this further.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Complementarity' (page 7) or 'discussion' (page 8) as the context for the claim about information value. This demonstrates strong grounding as the specific section or aspect is identified.", "verifiability_rationale": "The reviewer makes a claim about the relationship between information value and the strength of predictors for dialogue. While the review point itself doesn't provide direct evidence or citations, the implication is that further investigation and analysis are needed to verify this claim, making it 3 in principle.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors: they should explore the link between information value and the complementarity discussed in the paper. This is a helpful direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a desire for more discussion on the implications of AutoML findings for future architecture design. While the reviewer criticizes the *lack* of this discussion, the review point itself doesn't offer concrete *actions* or *suggestions* on how to address this deficiency. The reviewer points out a *need* but doesn't provide specific steps or guidance within the review point.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly tied to a specific section or table of the paper. While the reviewer mentions 'AutoML approaches' and 'design of new network architectures,' these are general areas rather than specific elements within the paper. The reviewer's statement is a general criticism of the paper's content, rather than a precise identification of a particular finding or section that needs improvement. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer's comment is a critique of the paper's content, specifically the lack of discussion on AutoML implications. This is not a claim that can be verified through logical reasoning, common knowledge, or external references. The reviewer is stating an opinion about the paper's shortcomings, not presenting a statement that requires justification. Therefore, the verifiability is low as there is X to be supported.", "helpfulness_rationale": "The reviewer clearly identifies a gap in the paper regarding the discussion of AutoML and its potential for future architecture design. This is a valuable piece of feedback that highlights a specific area for improvement. However, the reviewer does not provide specific *actions* or *suggestions* on how to address this deficiency. While the feedback is relevant, the lack of concrete guidance makes it less helpful than a review that offers specific improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for the main part to be more concise and the introduction to be more concise. However, they do not specify *which* parts of the main or introduction need to be concise. While the action of making something concise is implied, the lack of specific details makes it not fully actionable. The reviewer also suggests including empirical results but doesn't specify *which* empirical results are needed, further reducing actionability. The suggestions are present but lack concrete details on how to achieve them.", "grounding_specificity_rationale": "The reviewer refers to the 'main part' and the 'introduction part' of the paper. While they don't provide specific section numbers or table references, they clearly identify the *location* where improvements are needed. This indicates a degree of grounding. However, the reviewer does not specify *what* is wrong with the introduction or the specific aspects of the main part that need improvement. Therefore, while the grounding is present, it is not fully specific.", "verifiability_rationale": "The reviewer makes a claim that the introduction is wordy and that empirical results are needed. However, they do not provide any logical reasoning, examples, or external references to support these claims. The suggestion to include empirical results is presented as a general idea without specifying *which* results are missing or *why* they are necessary. Therefore, the claim is not wellsupported, making it 1.", "helpfulness_rationale": "The reviewer provides a comment that identifies areas for improvement, specifically suggesting conciseness in the introduction and the inclusion of empirical results. While these are valid points, the lack of specificity makes it difficult for the author to directly implement the suggestions. The reviewer does not provide any concrete examples of how to make the introduction more concise or what specific empirical results would be beneficial. This vagueness reduces the helpfulness of the comment as it doesn't provide actionable guidance."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification and an explanation regarding the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score. While the action of clarifying and explaining is implied, the reviewer does not explicitly state what the authors should do with this information. The request for an explanation of *why* these adjustments are effective is also not explicitly stated. Therefore, the action is implicit and the explanation is not explicitly provided.", "grounding_specificity_rationale": "The review point refers to 'Figure 3' and 'Frequency Stability score' without explicitly stating which part of the paper these elements correspond to. While the topic is relevant to the paper's content, the connection to a specific section, table, or unique aspect is not clearly established. The reviewer implies a reference to Figure 3, but does not specify which part of that figure or table is being discussed. The reference to 'Frequency Stability score' is also 1 in the paper itself.", "verifiability_rationale": "The review point contains a claim that the adjustments to the amplitudes are effective in enhancing model performance. However, the reasoning or evidence supporting this claim is not provided within the review point itself. The reviewer states the effectiveness of the adjustments but does not logically explain *why* they are effective or provide references to support this claim.", "helpfulness_rationale": "The review point asks for clarification and an explanation regarding the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score. This directly relates to understanding the empirical analysis and improving the model's performance. While the reviewer does not explicitly state what the authors should do, the request for clarification and explanation is a clear indication of a helpful suggestion for the authors. The reviewer also points out a formatting issue, which is a clear observation about a problem."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the lack of comparison with CoCoOp and suggests a necessary comparison. The action is directly identified: 'compare with CoCoOp'. This is a clear and actionable suggestion.", "grounding_specificity_rationale": "The review point explicitly mentions 'CoCoOp' by name. This provides full grounding as the specific work is identified. The specificity is also clear as the comment suggests a comparison, which is a concrete action to be taken.", "verifiability_rationale": "The review point contains a claim: 'It is necessary to compare with CoCoOp'. However, it does not provide any specific justification or evidence for this claim. While the reviewer believes it's necessary, it's not logically deduced or supported by external references within the review point itself.", "helpfulness_rationale": "The review point is clear, concise, and directly identifies a relevant gap in the comparison with a recent related work. The suggestion to compare with CoCoOp is actionable and would likely be helpful for the authors to contextualize their work. The reviewer provides a specific, concrete suggestion without unnecessary ambiguity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'Fig. 1 can also be drawn better', which is a direct instruction for the authors to improve the figure. While the specific details of the improvement are not given, the action is clear: enhance the drawing of Figure 1. The reviewer is not asking for clarification but rather a specific action to be taken.", "grounding_specificity_rationale": "The comment explicitly mentions 'Fig. 1', which is a specific part of the paper. The reviewer is not making a general comment about the entire paper but specifically about Figure 1. Furthermore, the comment clearly states what the reviewer desires: 'drawn better', which is a specific instruction regarding the aspect of the figure being drawn.", "verifiability_rationale": "The comment contains a claim: 'Fig. 1 can also be drawn better'. However, it does not provide any specific examples, references, or logical reasoning to support this claim. The suggestion is based on the current state of the figure and the reviewer's perception of its quality. There is no justification for why the figure needs improvement or what specific aspects should be changed.", "helpfulness_rationale": "The comment directly points to a potential weakness in the paper, which is the quality of Figure 1. The reviewer suggests a concrete improvement: 'drawn better'. This provides a clear direction for the authors to focus on enhancing the visual representation of the processing pipeline described in Figure 1. While the suggestion is general, it is directly related to improving the paper's presentation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitation of using 'two typical games' and suggests testing on 'more complex problems, especially those with larger depth...'. This is an explicit action. While the reviewer doesn't specify the exact 'how' to implement this suggestion, the 'action' is clear.", "grounding_specificity_rationale": "The reviewer mentions 'ReBeL's performance' and 'value and policy function', which are specific aspects of the model. However, they don't pinpoint a specific section, table, or figure. The grounding is to the overall experimental setup and its limitations.", "verifiability_rationale": "The reviewer makes a judgment about the 'limited scope' of the experiments and its potential impact on 'generalizability'. This is a claim requiring justification. However, the reviewer doesn't provide specific examples, citations, or logical reasoning to support this claim. The statement is presented as a suggestion for improvement rather than a claim requiring immediate verification.", "helpfulness_rationale": "The reviewer's point is directly relevant to the authors, highlighting a potential limitation in the experimental validation. Suggesting testing on 'more complex problems' is a constructive suggestion aimed at improving the robustness and generalizability of the findings. This feedback is directly actionable for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the action to be taken: 'remove abbreviations'. While the reviewer doesn't specify *why* they want this change, the action itself is clear and direct. The reviewer also provides an example ('MoCo'), suggesting they are aware of a specific instance where this might be an issue, even if it's not the primary focus of the general instruction.", "grounding_specificity_rationale": "The reviewer identifies the specific part of the paper where the change is intended: 'section headers'. They also provide an example of an abbreviation ('MoCo') that they believe should be removed. While the reviewer doesn't explicitly state the *reason* for removing abbreviations (e.g., 'to improve clarity'), they clearly pinpoint the location of the problem and provide a concrete example of an affected element.", "verifiability_rationale": "The reviewer makes a claim: 'abbreviations like \"MoCo\" should not appear in the section header, since a reader might not know what it means.' This is a judgment or opinion. The reviewer then provides a rationale: 'This is a good practice to improve readability and reduce confusion for the reader.' While the general idea of avoiding ambiguous terminology is generally accepted good practice, the reviewer doesn't provide specific external references or examples to support this claim within the *review point* itself. The reasoning is logical and common sense.", "helpfulness_rationale": "The reviewer provides a suggestion: 'remove abbreviations from section headers'. This is a clear and actionable piece of feedback. The reviewer implies the benefit of this change is to improve readability and reduce confusion for the reader. The suggestion is directly related to the identified issue and provides a practical solution. While the suggestion is general, it is still a helpful direction for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The statement 'The technical contribution is unclear' is an explicit action, as the reviewer is pointing out a deficiency. However, the statement 'Most of the analysis are quite standard' is vague, lacking specific details on what analysis is being referred to and why it is considered standard. This vagueness makes it difficult for the author to take concrete action based on this comment.", "grounding_specificity_rationale": "The reviewer does not specify which part of the paper or analysis is unclear or standard. They make a general statement about the technical contribution and the nature of the analysis. Therefore, the grounding is weak as the authors cannot confidently determine the exact area needing improvement.", "verifiability_rationale": "The review point contains a claim: 'The technical contribution is unclear. Most of the analysis are quite standard.' However, it does not provide any evidence or justification for this claim. There are no logical reasoning, common knowledge, or external references provided to support these statements. Therefore, the claim is 1.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper ('unclear technical contribution') and suggests that the analysis might be standard. However, it does not offer any specific suggestions for improvement or provide any evidence to support its claims. The feedback is general and lacks actionable insights, making it not particularly helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point states \"the paper's primary contribution seems to be an incremental advancement in efficiency over the TACTiS approach.\" While this statement identifies a potential weakness in the paper's contribution, it does not explicitly recommend a specific action or provide concrete details on how to achieve this incremental advancement. The reviewer points out the *what* (efficiency) but not the *how* or *specifics* of how to make it efficient. Therefore, it is not fully actionable, as it lacks explicit and concrete suggestions.", "grounding_specificity_rationale": "The review point mentions \"the paper's primary contribution\" and \"the TACTiS approach.\" While it names the *general* subject, it does not pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. The reviewer refers to the paper's contribution in a general sense, lacking the specificity of mentioning a particular element or section. Therefore, it is 1 at all.", "verifiability_rationale": "The review point states \"the paper's primary contribution seems to be an incremental advancement in efficiency over the TACTiS approach. More substantial evidence or arguments are needed to establish this as a significant contribution to the field.\" This review point makes a claim about the nature of the paper's contribution and the need for more evidence. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The reviewer states a *claim* without *verifying* it. Therefore, it is 1.", "helpfulness_rationale": "The review point highlights a potential lack of substantial evidence for the claimed incremental advancement in efficiency over the TACTiS approach. This directly addresses a potential weakness in the paper's contribution. While it identifies a problem, it does not offer a specific solution or actionable steps to address it. It points out a gap in the evidence, which is valuable feedback for the authors. Therefore, it is 3 in identifying a potential issue, but it does not provide a concrete solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states their opinion about the paper's contributions and suggests a minor improvement. While the reviewer explicitly states their opinion ('trivial,' 'limited,' 'incremental'), the specific action they suggest ('focusing on more significant improvements') is vague and doesn't pinpoint exactly what needs to be changed. The reviewer implies that the current improvement (adding topic entities) is not substantial enough, but doesn't provide concrete examples of what constitutes a 'more significant improvement'.", "grounding_specificity_rationale": "The reviewer refers to 'improvements on different datasets' and 'improvement on the topic entities.' While the reviewer clearly identifies the *area* of improvement, they do not explicitly name the specific datasets or the unique aspects of 'topic entities' being addressed. The reviewer implies improvement but doesn't specify *what* is being improved within these areas.", "verifiability_rationale": "The reviewer makes a claim: 'The improvements on different datasets are trivial and the novelty of this paper is limited. Lots of previous works focus on this topic. Just adding topic entities seems incremental.' This is a clear statement of opinion and assessment. However, the reviewer does not provide any specific examples, references, or logical reasoning to *support* their claim that the improvements are 'trivial' or 'incremental'. They offer *why* they think it's limited but not evidence *for* that assessment.", "helpfulness_rationale": "The reviewer offers a general critique of the paper's contributions and suggests focusing on 'more significant improvements'. While the reviewer identifies a potential area for improvement, the suggestion is very broad and lacks specific details. The reviewer doesn't provide concrete, actionable feedback on how the authors should go about making these 'more significant improvements'. The suggestion is at a high level and doesn't offer specific guidance on what aspects of the work need to be changed or improved."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'lacks discussion,' which implies an action for the authors: 'include a discussion.' However, it doesn't specify the *content* of the discussion or the *specific aspects* of the hierarchical strategy and QUBO problem that should be addressed. Therefore, while it points to an action, it lacks the concrete details needed to be fully actionable.", "grounding_specificity_rationale": "The review point explicitly mentions key terms related to the theoretical analysis of the proposed method, such as 'theoretical guarantee,' 'approximation ratio,' 'hierarchical strategy,' and 'global optimal of original QUBO.' This clearly identifies the specific part of the paper being addressed, making it wellgrounded. Furthermore, it specifies the *nature* of the missing discussion, focusing on the approximation ratio of the hierarchical strategy compared to the global optimal of the original QUBO.", "verifiability_rationale": "The review point does not contain a claim that needs to be verified. It is a statement of a gap or missing information rather than a proposition that requires justification or evidence. Therefore, it does not fit the criteria for verifiability.", "helpfulness_rationale": "The review point identifies a specific area where the paper lacks theoretical analysis. This is likely to be helpful for the authors as it highlights a potential area for deeper understanding and improvement of their proposed method. While it doesn't provide specific instructions on how to conduct this analysis, it points to a relevant gap in the current work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a lack of a quantitative measure, which implies an implicit action of 'add a quantitative measure.' However, it doesn't provide specific guidance on *how* to do this, making the action vague and less actionable.", "grounding_specificity_rationale": "The review point criticizes the lack of a quantitative measure *without specifying where* this measure would be or what it would assess. This implies a lack of grounding in a specific part of the paper or a defined evaluation process. The criticism is about the *lack* of specificity, not a clear identification of a section or element to address.", "verifiability_rationale": "The suggestion of a quantitative measure is generally verifiable. However, the *lack* of such a measure means there's no concrete evidence provided to support the claim of a quantitative evaluation. The suggestion itself could be considered verifiable if implemented, but the absence of it makes this aspect less directly relevant to the current point.", "helpfulness_rationale": "The review point directly identifies a limitation in the current evaluation process (reliance on visual inspection) and suggests an alternative (a quantitative measure). This directly addresses a practical issue for the authors and offers a concrete improvement, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer states \"Only marginal improvements over baselines...\" which is an explicit action, but it lacks detail on *what* is improved and *how*. The reviewer also suggests 'suggesting that the performance differences between some methods are not very significant,\" which is an implicit action that needs to be inferred. The lack of specific details makes the action somewhat vague.", "grounding_specificity_rationale": "The reviewer makes a general statement about the overall performance, not pinpointing a specific section or table. They mention \"the method\" generally. While they imply something is not significant, they don't specify *what* is marginal or *where* the improvements are.", "verifiability_rationale": "The reviewer *claims* \"Only marginal improvements over baselines...\" but doesn't provide any evidence or justification for this claim. They mention \"error bar range\" as a factor, which is a suggestion but not a concrete verification. The statement 'suggesting that the performance differences between some methods are not very significant\" is an interpretation, not a verifiable claim on its own.", "helpfulness_rationale": "The reviewer's comment is primarily critical, focusing on the lack of significant improvement. They don't offer specific suggestions for how the method could be improved or what aspects need attention. While they point out a problem, they don't actively guide the authors towards a solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'significant artifacts' in 'generated videos' and compares the 'action recognition performance' to the 'current stateoftheart' on the 'UCF dataset'. This indicates a clear and direct identification of issues and suggests concrete improvements like 'improving the generation process' and 'increasing the depth of the architectures'.", "grounding_specificity_rationale": "The reviewer refers to 'generated videos' and the 'UCF dataset', which are specific parts of the work being discussed. While not a direct mention of a section number, it's a clear reference to a defined entity. The reviewer also mentions 'action recognition performance being much below the current stateoftheart' and the use of 'deeper architectures and optic flow' in the stateoftheart, providing some detail about what might be causing the performance gap.", "verifiability_rationale": "The reviewer makes a claim: 'action recognition performance is much below the current stateoftheart'. However, this claim is not supported by any specific evidence or references within the review point itself. The reviewer presents it as a general observation based on their understanding of the stateoftheart.", "helpfulness_rationale": "The review point identifies specific weaknesses related to 'artifacts in generated videos' and 'low action recognition performance'. It also provides concrete suggestions for improvement, such as 'improving the generation process' and 'increasing the depth of the architectures'. These suggestions are directly related to enhancing the quality and functionality of the work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states what they find unclear: 'how to make the new proposed evaluation set more diverse and representative' and 'how to select those representative images'. While the action of identifying these unclear aspects is explicit, the reviewer does not explain *how* they plan to achieve this. The action is stated, but the method is not detailed, making it vague.", "grounding_specificity_rationale": "The reviewer's comment is not specific to a particular part of the proposed method or paper. They are broadly stating a general concern about the lack of clarity in the evaluation process. They could be more specific, for example, by saying 'I'm unclear about the criteria for diversity' or 'I don't understand how they select representative images'. As it stands, the referenced part is not clearly identified.", "verifiability_rationale": "The reviewer makes a claim: 'It is still unclear how to make the new proposed evaluation set more diverse and representative than the previous method and how to select those representative images.' However, the reviewer does not provide any evidence, reasoning, or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the statement of uncertainty.", "helpfulness_rationale": "The reviewer's comment is a question about the proposed method, specifically about its novelty and selection process. While it raises a valid point for the authors, it doesn't directly address the current draft or provide actionable feedback on how to improve it. The comment is about the *future* method, not the *current* work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'include a background section to introduce the basic RL framework'. It is also somewhat concrete as it names the specific elements to be included: 'elements of the MDP, trajectories, and policy'. However, it lacks detail on *how* to implement this action, such as suggesting specific textbooks or online resources.", "grounding_specificity_rationale": "The comment explicitly mentions the specific part of the paper being addressed: 'the RL context being considered' within the methods section. It is grounded because it directly points to the area where the authors are currently working. However, it doesn't specify *which* subsection or equation this refers to, making it weakly grounded.", "verifiability_rationale": "The comment contains a claim: 'Without this, it is difficult to follow the subsequent sections' which is supported by reasoning: 'it is difficult to follow the subsequent sections'. It is also 3 as it points to a logical consequence of the missing background. However, it doesn't provide specific examples of *where* the difficulty lies (e.g., understanding policy gradients or the Bellman equation).", "helpfulness_rationale": "The comment is 5 as it identifies a crucial missing element (background section) that would significantly improve the authors' understanding of the paper's context. It also provides a clear reason *why* this is important ('it is difficult to follow the subsequent sections'). While it could be more specific about the *exact* nature of the missing information, it clearly identifies the need for a basic RL introduction. The suggestion to provide context for the modifications in the methods section is also valuable."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly asks a question about the relevance of a specific concept to their work, which is an explicit action.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"DoshiVelez, F., & Kim, B. (2017).\" This is a literal mention of a specific work, indicating full grounding. The reviewer also asks about the \"notion described in the work,\" which specifies the aspect of that work being considered, making it specific.", "verifiability_rationale": "The reviewer is asking a question, which can be considered a claim that requires verification. While the answer isn't a direct statement, the question itself is verifiable based on the definitions of interpretability and the context of the cited work. The connection can be argued based on the definitions of interpretability.", "helpfulness_rationale": "This is a highly relevant and actionable question. The reviewer is directly asking about the connection to a specific, relevant paper. This provides a clear direction for the authors to improve their understanding or the paper's presentation of interpretability."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a limitation in the experimental setup, suggesting that the authors should consider expanding their experiments. However, it does not explicitly state what specific changes or improvements are needed. The suggestion to 'expand' is general and lacks concrete details on how to achieve this.", "grounding_specificity_rationale": "The review point explicitly mentions 'MNIST' and 'a single realworld dataset' as the scope of the experiments. This clearly identifies the specific parts of the paper being addressed, providing strong grounding. It also specifies the *type* of limitation (lack of diversity in datasets), adding further specificity.", "verifiability_rationale": "The review point states a fact about the limited scope of the experiments. While it implies that this limitation is a problem in the field, it does not provide any specific justification or references to support this claim. The statement itself is a claim that requires implicit understanding or acceptance within the field.", "helpfulness_rationale": "The review point identifies a weakness in the experimental design (limited datasets) and suggests that the authors should consider expanding their experiments. This provides a clear direction for improvement, making the review point 3 in guiding the authors towards a better experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their agreement with the efficiency argument regarding FLOPs and activation size but requests more details on the parameter count. The action is clearly stated, and the request for more information is a direct consequence. While the action itself might be considered vague (how exactly are the parameters increasing?), the reviewer's intent is clear and actionable for the authors to seek clarification.", "grounding_specificity_rationale": "The reviewer refers to 'S2D structure' which is a specific part of the paper. While they don't provide a section number or a unique element, the term itself is specific enough to identify the intended part of the architecture. The reviewer is asking for clarification on a specific aspect (parameter count) within this structure, indicating a degree of grounding.", "verifiability_rationale": "The reviewer provides a logical explanation for why the parameter count might increase (due to increased depth when kernel size remains constant) and connects this to the known relationship between activation size and FLOPs. The reasoning is clear and provides a basis for understanding the potential increase in parameters. The claim is supported by logical arguments and common knowledge about convolutional layers.", "helpfulness_rationale": "The reviewer raises a valid point about the potential inconsistency in the description of the S2D structure regarding the number of parameters. They provide context (FLOPs and activation size) and suggest a concrete next step (asking for clarification on parameter count). This is a helpful observation that directly addresses a potential ambiguity for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The reviewer implies a comparison and potential extension of 10 but doesn't explicitly state what the authors should do next (e.g., 'You should try applying this to your method'). The lack of a clear next step makes it 2.", "grounding_specificity_rationale": "The reviewer mentions '10' but doesn't specify which aspect of '10' is relevant or why '10' can't do something. The reference is somewhat general.", "verifiability_rationale": "The review point is a question, not a declarative statement containing a claim.", "helpfulness_rationale": "The review point raises a question and suggests a potential improvement for a related method. It doesn't directly point out a weakness in the reviewed paper."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point does not specify any actions or improvements for the authors. It identifies a limitation in the experimental setup but does not provide guidance on this limitation.", "grounding_specificity_rationale": "The review point does not specify which Atari game or baseline is being referred to. The terms 'the Atari game' and 'a single baseline' are too general and do not pinpoint a specific section, table, or unique aspect of the paper.", "verifiability_rationale": "The review point makes a claim about the limitations of the Atari game results but does not provide any justification or evidence for this claim. It states that the results are 'limited' and 'very hard to interpret' without explaining why or providing supporting arguments.", "helpfulness_rationale": "The review point identifies a weakness in the experimental setup but does not offer any suggestions or guidance on how to improve the results. It is a critique without constructive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "Somewhat Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitation of the proposed method, indicating a clear action the authors should take. The statement 'As such, the model will not be incentivized to use less factors, leading to increasing number of factors and increased computation with more tasks' directly suggests a concrete action the authors should consider to address this issue.", "grounding_specificity_rationale": "The reviewer refers to a general aspect of the method ('the proposed method') and its behavior with more tasks. While the issue is somewhat specific (lack of sparsity constraint), the reference to the method as a whole rather than a specific section or table makes the grounding somewhat weak. The reviewer mentions 'more tasks' which is a general concept rather than a specific section or table.", "verifiability_rationale": "The reviewer makes a claim about the expected behavior of the model due to the absence of a sparsity constraint. This claim can be logically verified based on the understanding of factorization models and sparsity constraints. While the reviewer doesn't provide specific examples or references within this point, the claim is based on a general understanding of the field. The logical reasoning is sound: a lack of sparsity constraint would discourage the model from using fewer factors, potentially leading to an increase in the number of factors and computation with more tasks.", "helpfulness_rationale": "The reviewer points out a potential limitation of the proposed method, specifically its lack of a sparsity constraint and its potential impact on computation with more tasks. This is a valuable piece of feedback for the authors as it highlights a potential area for improvement and a potential challenge they might face. The reviewer suggests that the authors should be aware of this limitation and consider its implications."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the presentation of the simulation study is not favoring the authors and specifically points out the lack of explanation for GPC's outperformance. They even offer a potential reason (bandit feedback and cost function form). This suggests the reviewer has identified a clear area for improvement and has a concrete suggestion.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the presentation of the simulation study' and focuses on the 'authors' and the 'GPC (benchmark) is performing better than BPC (their method)'. They also state that the reason for GPC's outperformance is due to 'bandit feedback' and not using information about the 'form of the cost function'. This demonstrates a clear and specific identification of the relevant part of the paper and the issue within it.", "verifiability_rationale": "The reviewer makes a claim that 'the authors do not really comment on why the GPC (benchmark) is performing better than BPC (their method)'. They also provide a suggestion as to why this might be the case, linking it to 'bandit feedback' and the 'form of the cost function'. This claim is supported by the reviewer's statement and their proposed explanation.", "helpfulness_rationale": "The reviewer's point directly addresses a potential area of confusion for the authors regarding the simulation study results. By highlighting the lack of explanation for GPC's outperformance and suggesting it might be due to bandit feedback and cost function form, the reviewer provides a concrete piece of information that could help the authors understand and potentially replicate the study. The reviewer's suggestion is specific and actionable."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the action of 'ReLU does not work very well in very deep or in convolutional networks.' This is a clear and direct statement that authors can use to understand a potential limitation of ReLU.", "grounding_specificity_rationale": "The review point mentions 'deep or convolutional networks,' which attempts to ground the statement. However, it doesn't specify *which* parts of the network or provide a unique element to identify the issue. The mention is implied through the context of ReLU's limitations.", "verifiability_rationale": "The review point contains a claim: 'ReLU does not work very well in very deep or in convolutional networks.' The reviewer attempts to support this claim by mentioning the AlexNet paper. However, they don't explicitly state that ReLUs were used *in* AlexNet's convolutional layers (they imply it through the general use of ReLUs in the paper and the use of convolution). The connection between ReLU's use in AlexNet and the current point about ReLUs not working well in convolutional networks is not explicitly and clearly established.", "helpfulness_rationale": "The review point provides a clear action (not using ReLU) and encourages further investigation by suggesting the authors look for a counterexample (the AlexNet paper). This shows a desire for the authors to explore the claim further and potentially find a solution."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a potential issue with the reported perplexity, stating it's over 30. While this is a specific issue, the reviewer doesn't explicitly state what action the authors should take based on this. They don't provide a specific, actionable step beyond 'check the perplexity calculation'.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 1' and 'perplexities' in the paper. However, they do not explicitly state that the perplexity values are *within the paper*. They are criticizing the *reported* perplexity. Therefore, the grounding is weak because the authors cannot confidently determine the referenced part of the paper. The reviewer also doesn't specify what needs to be addressed in this part (the high perplexity) beyond stating it's a problem.", "verifiability_rationale": "The reviewer claims that the high perplexity contradicts better BLEU scores in their experience. This is a claim that needs to be supported. However, the review point does not provide any external references, logical reasoning, or examples to support this claim. The reviewer presents the discrepancy without explaining *why* it occurs or providing evidence to back it up. Therefore, the claim is 1 based on the information provided in this review point.", "helpfulness_rationale": "The reviewer's statement is a direct criticism of the reported perplexity value. While they identify a potential issue, the lack of clarity about the calculation makes it difficult for the authors to act upon this feedback. The criticism is about the *reported* value, not a clear, actionable improvement suggestion. The reviewer doesn't offer any specific steps or explanations for why this high perplexity is a problem or how it should be addressed."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the need for 'experiments on distributed deployment' and 'a larger model'. This indicates a clear action the authors should take. While it doesn't specify *how* to conduct the distributed experiments, it clearly identifies the *what*. Therefore, it is explicitly stated and points to a concrete action, although the action itself might be considered somewhat vague depending on the interpretation of 'concrete'.", "grounding_specificity_rationale": "The review point mentions 'distributed deployment' and 'a larger model'. However, it does not explicitly identify *which* specific experiment within 'distributed deployment' or *which* specific 'larger model' is needed. The reviewer is commenting on the *need* for these types of evaluations and model sizes, but not the precise element within those categories. Therefore, the grounding is weak as the authors cannot confidently determine the exact referenced part. The specificity is also underspecific as it doesn't detail the *how* of the distributed deployment or the *specific* large model to use.", "verifiability_rationale": "The review point states 'The evaluation needs experiments on distributed deployment and a larger model'. This is a statement of a need or requirement, not a claim that needs verification. It doesn't present a subjective opinion, a suggestion for change, a judgment about the paper, or a deduction based on existing information. Therefore, it does not contain a claim that requires supporting evidence or justification.", "helpfulness_rationale": "The review point identifies areas where the evaluation could be improved, specifically suggesting more comprehensive experimentation and the use of larger models. This provides a direction for improvement and is helpful in guiding the authors. However, it doesn't offer specific *how* to achieve this, making it somewhat general. It doesn't provide a critique of the current evaluation or suggest specific improvements, so it's not 5 in pinpointing exact flaws. It also doesn't present a claim that needs verification, so it's not unhelpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing information (the importance of rooted patterns and the choice of roots) and suggests a concrete action (providing this information). This is 5.", "grounding_specificity_rationale": "The reviewer does not explicitly name a specific part of the paper being addressed. While the concept of rooted patterns is mentioned, the *specific* section or detail lacking grounding is not clearly identified. The reviewer implies a need for more detail within the definition of rooted patterns, but doesn't pinpoint the exact location. This suggests weak grounding as the authors need to infer the relevance of this section.", "verifiability_rationale": "The reviewer points out a lack of justification for a design choice (the rootedness), which could be considered 1 without further explanation. While the reviewer doesn't explicitly claim something, the implication is that the lack of explanation makes the rootedness assumption less convincing, which relates to verifiability. The reviewer doesn't provide examples or references to support the importance of rooted patterns.", "helpfulness_rationale": "The reviewer's suggestion to either explain the rootedness or simplify to nonrooted patterns directly addresses a potential weakness in the authors' exposition and empowers them to improve their work. This is a 5 suggestion as it directly tackles a potential lack of clarity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the weakness ('that the consistency between training and inference can be easily satisfied') and suggests an improvement ('I would suggest giving more explanations on this'). The explicit identification of the weakness and the suggestion for improvement indicate an actionable point for the authors. While the specifics of the explanation are not detailed, the reviewer clearly points to an area needing attention.", "grounding_specificity_rationale": "The review point explicitly mentions the lines (Line 9597 and Line 308310) where the consistency issue is discussed. This grounds the comment in specific parts of the paper. However, the comment does not specify *what* is wrong with the consistency in those sections. It only suggests providing more explanations without detailing what those explanations should cover. Therefore, while the section is identified, the specific issue within that section is not.", "verifiability_rationale": "The review point contains a claim ('I would suggest giving more explanations on this') that the authors would like to be justified or supported by the paper. However, the paper does not provide any specific justification or examples for why more explanations are needed. The reviewer simply states their suggestion without providing any logical reasoning, common knowledge, or external references to support it.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper (the consistency between training and inference) and suggests an improvement (giving more explanations). While the suggestion itself is vague and lacks specific details, it points to a relevant area for the authors to address. By highlighting this specific point and suggesting more detail, the reviewer provides a direction for improvement, even if the direction is not fully specified. The reviewer's intent to improve the clarity of a potentially confusing concept is a valuable contribution."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states that the hyperparameters k and \u03b7 require finetuning. This is a direct action the authors should take. Furthermore, the comment explains *why* this finetuning is necessary, mentioning the dependency on environment availability or OPE methods. This provides a clear understanding of the practical steps involved.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper where the hyperparameters k and \u03b7 are used. It refers to them in general, without pointing to a particular section, table, figure, or unique aspect of the paper. Therefore, the grounding is weak.", "verifiability_rationale": "The comment contains a claim that the hyperparameters k and \u03b7 require finetuning, which depends on the availability of the environment or a good OPE method. This claim is 3 as the 'what' (hyperparameters require finetuning) is clear. The 'why' (environment availability or OPE methods) provides some justification. However, it lacks detailed examples or references to support the claim fully.", "helpfulness_rationale": "The comment identifies a practical limitation regarding the finetuning of the hyperparameters k and \u03b7. While it informs the authors about the dependency on the environment or OPE methods, it does not provide actionable steps or suggestions on how to overcome this limitation or improve their draft. It serves more as a headsup than a constructive suggestion for improvement."}
{"actionability_label": "3: 4", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a discrepancy in the regularization method used for the GLM model and suggests that the authors might be applying a different technique than what is described in previous work. This points to a potential area for clarification and improvement in the authors' methodology. While the reviewer doesn't explicitly state what action the authors should take, the suggestion to reproduce previous models implies a concrete step they could undertake. Therefore, the reviewer's point is 4, as it guides the authors towards a specific improvement.", "grounding_specificity_rationale": "The reviewer mentions 'the form of regularization' and specifically names 'L1 regularization' and 'lowrank approximation' in the context of the Pillow et al. model. This indicates a degree of grounding as the reviewer is referring to specific regularization techniques. However, the initial statement about 'regularization' is quite general, and the reviewer doesn't pinpoint a specific section or table within the paper where this issue is discussed. Therefore, the grounding is somewhat specific.", "verifiability_rationale": "The reviewer makes a claim about the regularization techniques used in the Pillow et al. model and suggests that reproducing these features would be beneficial. This claim is based on the reviewer's recollection of previous work. The suggestion to reproduce features is a logical next step for the authors. While the reviewer doesn't provide explicit verification of their recollection, the suggestion itself implies an understanding of the potential impact. Therefore, the reviewer's point is 3, as it builds upon a potentially valid observation.", "helpfulness_rationale": "The reviewer identifies a potential inconsistency in the authors' application of regularization and suggests a concrete action (reproducing previous model features) to address it. This is a valuable observation that directly points to a potential improvement in the authors' methodology. The reviewer's suggestion is clear and actionable, making it 5 for the authors to consider. Therefore, the reviewer's point is 5, as it provides a specific direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point suggests discussing 'failure cases,' which could be interpreted as an implicit action. However, the action of 'how to discuss failure cases' is not specified, making it vague. Explicit vs. Implicit: Implicit. Concrete vs. Vague: Vague. While the suggestion points to an area for improvement, the lack of a concrete action makes it 2.", "grounding_specificity_rationale": "The review point suggests discussing 'failure cases' but does not specify which part of the paper or section this refers to. The comment lacks a clear reference point, making it difficult to identify the exact location or nature of the suggested discussion. Explicit vs. Implicit: Implicit. Concrete vs. Implicit: Implicit. The lack of a specific reference makes it 1.", "verifiability_rationale": "The review point itself is not a claim or assertion. It is a suggestion for future work. Since there is X being made, there is nothing to verify. Claim Extraction: X. Verifiability Verification: N/A. The review point is a suggestion, not a claim.", "helpfulness_rationale": "The review point suggests discussing 'failure cases,' which is a relevant direction for improvement. However, it is a general suggestion and lacks specific details on how to implement this. It does not directly address existing weaknesses or provide concrete steps for improvement. The suggestion is relevant but lacks the specificity and actionable steps needed for significant impact. It is a suggestion for future work, not a direct improvement of the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a missing element (the base layer GNN encoding) and suggests an action (ablation study). However, they don't explicitly state that the authors *should* perform this ablation study to improve their draft. The suggestion is presented as a potential solution rather than a direct instruction.", "grounding_specificity_rationale": "The reviewer mentions a specific technical term ('base layer GNN encoding') but doesn't pinpoint its location within the paper. The lack of specificity makes it difficult for the authors to understand the exact issue.", "verifiability_rationale": "The reviewer clearly states a problem ('It's unclear...') and provides a proposed solution ('An ablation study... would be helpful'). While not citing specific evidence *yet*, the suggestion itself offers a logical pathway to understanding the issue.", "helpfulness_rationale": "The reviewer suggests a concrete action (ablation study) that could be beneficial. This indicates a helpful suggestion, but it's not a direct order or demand for the authors to perform it. The helpfulness is moderate because the suggestion is valuable but not immediately actionable."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem of the paper lacking adequate discussion on the computational complexity of counting homomorphisms and provides specific suggestions for improvement, such as 'state the bounds' and 'elaborate on empirical runtimes'. This is a clear and actionable critique.", "grounding_specificity_rationale": "The reviewer focuses specifically on the computational complexity of counting homomorphisms and mentions a specific paper section (line 145) when discussing their example. This demonstrates strong grounding as the reviewer can accurately pinpoint the area being addressed and specify the issue within it.", "verifiability_rationale": "The reviewer presents a claim about the lack of discussion on computational complexity and provides suggestions for improvement. While the suggestions are concrete, they could benefit from further elaboration on why these suggestions are important and how they address the identified issue. However, the claim itself is verifiable by pointing to the absence of such discussion in the paper.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improving the paper. By pointing out the lack of discussion on computational complexity and offering concrete ways to address it, the reviewer directly helps the authors improve their work. The suggestions are directly relevant to the technical content."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The suggestions are explicitly stated ('fix the form', 'correct the grammatical error', 'address the question'). However, the level of detail and specificity for each action is lacking. For instance, 'fix the form' doesn't specify which part needs fixing or how to achieve it. Similarly, 'correct the grammatical error' is too vague. The suggestions are broad and lack concrete steps for the authors to follow. The 'question' is also too general and doesn't provide a specific direction for the authors to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions the lines in the paper where the potential issues are located (line 108 and line 115). This demonstrates strong grounding as the authors can easily identify the specific section being referred to. However, the specificity of the feedback is limited. The reviewer points out a potential typo and a grammatical error but doesn't specify *what* the errors are or how they impact the paper's clarity or correctness. The question about the baseline method is also general and doesn't provide specific details about the method or its convergence.", "verifiability_rationale": "The reviewer makes claims about potential issues at specific line numbers (108 and 115) and raises a question about the convergence of the baseline method. However, the claims are not supported by any logical reasoning, common knowledge, or external references. The reviewer states 'there is a potential typo' and 'the grammatical error is significant' without providing evidence or justification. The question about the baseline method is also presented as a statement without any supporting information or context. The claims are presented as opinions rather than verifiable statements.", "helpfulness_rationale": "The review points out specific potential flaws in the paper (potential typo, grammatical error) and asks a relevant question about a method. However, the suggestions provided are too general and lack specific guidance on how to address these issues. The reviewer doesn't offer concrete steps for the authors to take, such as providing the exact typo, suggesting a specific way to correct the grammar, or explaining the convergence issue in detail. The lack of specific and actionable feedback makes the review less helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a missing element (inference time study) and suggests a reason (direct nature of the method) and a potential solution (comparing to other methods). While the suggestion is not a fully explicit action, it provides a clear direction for improvement, making it actionable.", "grounding_specificity_rationale": "The reviewer mentions 'inference time' and 'pose estimation method' generally but does not specify a particular section, table, figure, or unique aspect of the paper where this issue is present. The criticism is broad and lacks pinpointing of a specific location or detail.", "verifiability_rationale": "The reviewer identifies a claim ('this is a pose estimation method that is direct and does not require detection or keypoint grouping') and suggests a way to verify it ('it is worth to compare its inference speed to previous topdown and bottomup pose estimation method'). While the claim is present and the suggestion points towards verification, the reviewer does not provide specific examples, datasets, or metrics for the comparison, making the verification somewhat underspecified.", "helpfulness_rationale": "The reviewer identifies a valid concern (missing inference time study) and provides a relevant suggestion (comparing to other methods). This suggestion is directly related to improving the pose estimation method and provides a clear direction for the authors to take, making the review point helpful in guiding improvement."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out two specific mathematical errors in the proof of Theorem A.3. They state that the input x has two indices despite being a vector, and that the summation \u2211 k ( W k ( 2 ) ) 2 should equal 1/d, not d. This provides the authors with a clear and actionable indication of where the error lies in the proof. The reviewer also specifies the section (Theorem A.3 proof) and the equations involved, making the action explicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Theorem A.3 proof' and points to the specific equations involving the summation. This indicates a high level of grounding specificity as the authors can directly locate the referenced part of the paper. However, the reviewer does not specify *which* element within the proof is incorrect (e.g., a particular step or line number). Therefore, while the section and equations are mentioned, the exact location of the error within those equations is not specified.", "verifiability_rationale": "The reviewer makes a claim that there is an error in the proof, specifically stating that \u2211 k ( W k ( 2 ) ) 2 should equal 1/d, not d. The reviewer provides a logical argument for why the summation should be 1/d, based on the properties of orthonormal bases. While the reviewer doesn't provide a full derivation within the review point itself, the reasoning is clear and verifiable. The claim is supported by logical reasoning and common knowledge (properties of orthonormal bases).", "helpfulness_rationale": "The reviewer provides a clear and specific indication of an error in the mathematical proof. By pointing out the potential misunderstanding of the input x's dimensionality and the incorrect calculation of the summation, the reviewer guides the authors on how to potentially fix the proof. The reviewer also references a specific section of the appendix (Theorem A.3 proof), making the feedback actionable and directly addressable. The reviewer's suggestion is not just a general comment but a specific, actionable piece of feedback."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the use of terms like 'somewhat' and 'good generative ability' in the description. While these terms describe the quality of the results, they don't explicitly state an action the authors should take. The reviewer's question about the percentage of correct entities/relationships is a specific action the authors could ask, but the initial phrasing focuses on the potential issue rather than the action itself. Therefore, the action is implicit and vague.", "grounding_specificity_rationale": "The reviewer's comment doesn't explicitly identify a specific part of the paper being addressed. They are concerned about the evaluation process and its reliability, but don't pinpoint where the entities/relationships should come from. The comment is about the *potential* issue, not the specific location of the problem. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a clear claim: 'I am concerned that even with beam search, only 77% of the result lists contain the ground truth logical forms. If the relationships and entities were replaced, how do we ensure that the pluggedin entities/relationships were the right one?' This claim is supported by the statement about the 77% accuracy and the question about the correctness of replaced entities. The reasoning is based on the provided percentage and the lack of ground truth. The external references are the percentage itself. Therefore, the claim is verifiable.", "helpfulness_rationale": "The reviewer raises a valid concern about the reliability of the evaluation process, specifically regarding the accuracy of entity/relationship plugging when ground truth is unavailable. While the comment identifies a problem, it doesn't offer a clear solution or actionable steps for the authors to improve their draft based on this feedback. The helpfulness is limited to raising a concern rather than providing actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the claim about evolutional dropout addressing internal covariate shift is 'very limited' and provides a detailed explanation of the limitations, stating that evolutional dropout can only increase the variance of lowvariance units, while batch normalization standardizes and centers activations. This provides a clear action for the authors to consider the specific impact on lowvariance units and compare it to batch normalization's behavior. The reviewer also suggests discussing these points explicitly, which is a concrete action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'evolutional dropout' and discusses its limitations regarding 'lowvariance units'. They also contrast this with the effect of 'batch normalization' in 'standardizing and centering activations'. This demonstrates a clear grounding of the comment in the specific aspect of the paper being discussed, making it fully grounded. The specificity is high as the reviewer details the specific issue and provides a comparison to another relevant concept.", "verifiability_rationale": "The reviewer makes a claim that the original statement is 'very limited' and provides a logical reasoning and specific examples to support this claim. They explain the specific limitations of evolutional dropout and contrast it with the wellknown effects of batch normalization. This provides clear evidence and justification for their assessment, making the claim 5. The use of logical reasoning and specific examples enhances the verifiability.", "helpfulness_rationale": "The reviewer's comment is 5. They not only identify a potential misunderstanding or area for clarification but also provide a clear explanation of the limitations of evolutional dropout and its difference from batch normalization. They suggest discussing these points explicitly, which is a concrete and actionable suggestion for the authors. The comment is specific, logical, and provides clear guidance, making it 5 for improving the authors' understanding and addressing a potential issue."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states: \"The performance of FedPCL heavily relies on the selection of different pretrained models, limiting its applications to more wide areas.\" This is a statement of fact, but it does not explicitly state an action the authors should take. While it identifies a limitation, it doesn't provide a concrete step or suggestion for improvement. The connection to 'more wide areas' is also vague.", "grounding_specificity_rationale": "The review point mentions 'FedPCL' and 'pretrained models' generally. While it mentions FedPCL, it doesn't specify *which* aspect or component of FedPCL is being criticized. Similarly, 'pretrained models' is a broad category. The connection to 'more wide areas' is also vague.", "verifiability_rationale": "The review point states: \"The performance of FedPCL heavily relies on the selection of different pretrained models, limiting its applications to more wide areas.\" This is a statement of opinion or judgment about the limitations of FedPCL. It doesn't present a claim that can be verified with logical reasoning, common knowledge, or external references within the provided text. The sensitivity to pretrained models is presented as a fact without further justification.", "helpfulness_rationale": "The review point identifies a limitation of FedPCL related to pretrained models. However, it doesn't offer any suggestions or actions for the authors to address this limitation. It points out a problem but doesn't provide a path forward. The connection to the 'new try for federated learning' mentioned in the subsequent part of the review is not explicitly linked back to the initial point."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the missing element: 'the tentative attention maps'. This is a direct identification of what needs to be added. The suggestion to 'see them in the qualitative figures' further clarifies the action to be taken. The action is both explicit and concrete.", "grounding_specificity_rationale": "The comment explicitly mentions 'tentative attention maps' and their location 'in the qualitative figures'. This provides a clear and precise identification of the missing element and its context. The grounding is strong as the specific type and location are mentioned.", "verifiability_rationale": "The comment implies a suggestion for improvement ('it would have been interesting to see...') but doesn't provide a logical reasoning or external reference to support why showing tentative attention maps is necessary or beneficial. While the suggestion is implied, the lack of explicit justification makes it less verifiable. It's not a definitive statement, but it sets the stage for a need for more information.", "helpfulness_rationale": "The comment directly points out a specific area for improvement in the authors' analysis ('it would have been interesting to see... tentative attention maps'). This is a clear direction for the authors to focus their attention. The suggestion is actionable, indicating a practical way to enhance their work. While it doesn't delve into the *why* or *how* of showing tentative maps, it provides a concrete target for improvement, making it 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment suggests adding more description, which is an implicit action. It lacks specifics on *how* to add the description, making it less actionable.", "grounding_specificity_rationale": "The comment refers to the 'contribution of this paper' broadly, without specifying a section, table, figure, or unique element. This lack of specificity means it's 1.", "verifiability_rationale": "The comment is a suggestion, not a claim requiring justification or evidence. There's no logical reasoning, common knowledge, or external references provided.", "helpfulness_rationale": "The comment identifies a valid need (more detail) but lacks the specifics (how to add it) to be truly helpful. It's a suggestion, which is better than nothing, but 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the suggestions (separate section for attention, separate section for tricks, current description is scattered). This is an *explicit* action the authors should take. The suggestions are very specific about *where* to put the information. They are not vague or ambiguous. The reviewer directly names the sections where the information should go.", "grounding_specificity_rationale": "The reviewer *mentions* sections (2.3 and 2.4) where the layerwise attention is described. While not a direct name, it points to specific sections. However, it's not a *literal* mention or a clear identification of a unique element within those sections. The reviewer *mentions* the *type* of attention (for deep VAEs) and *tricks* (normalization, feature scaling). This provides some context, but it's not a precise reference to a specific part of the model or algorithm.", "verifiability_rationale": "The reviewer is making a *critical* point about the organization and clarity of the paper. They are stating a problem they perceive exists. There isn't a direct *reference* to external literature to *prove* that the current organization is hindering understanding. The criticism is based on the *absence* of the suggested structure.", "helpfulness_rationale": "The reviewer's suggestions are constructive and directly address potential areas of confusion. They provide a clear direction for improvement. The suggestions are likely to help authors better understand the structure and content of their paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states two possibilities: either they don't understand Figure 5 or the labels are wrong. This is a direct and clear indication of an issue.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 5' and then further specifies the potential issues as 'either I don't understand Figure 5 or the labels are wrong'. This demonstrates a clear identification of the specific part of the paper and the nature of the problem.", "verifiability_rationale": "The reviewer makes a claim about the authors' potential misunderstanding or error in the labels of Figure 5. However, they do not provide any evidence, reasoning, or references to support this claim. There is no logical justification for why this issue might exist.", "helpfulness_rationale": "The reviewer points out a potential area of weakness in the authors' work (either a lack of understanding of Figure 5 or incorrect labels). This directly suggests an improvement area and encourages the authors to address it. While the comment is specific about the figure, it lacks the depth of explanation or solution that would make it 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The suggestion is explicit about the *what* (supervised baselines), but lacks specifics on the *how* or *which* ones, making it *partially* actionable.", "grounding_specificity_rationale": "The comment doesn't pinpoint a specific section, table, figure, or unique element in the paper where the supervised baselines are relevant. It also doesn't specify *what* aspects of the baselines are important. Therefore, it's 'Weakly Grounded and UnderSpecific'.", "verifiability_rationale": "The suggestion to 'add missing supervised baselines' is a claim that lacks sufficient justification or references. It doesn't explain *why* these baselines are needed or *how* they should be implemented. Therefore, it's '1'.", "helpfulness_rationale": "The suggestion is relevant and generally helpful, providing a benchmark for comparison. While not the most specific, it's still a valuable direction for improvement. Therefore, it's '3'."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states a fact ('Performance differences between methods are minimal') and offers a potential explanation ('less than 1 percentage point'). While it points to a *difference*, it doesn't explicitly *recommend* an action or provide a concrete next step for the authors. It's more of an observation.", "grounding_specificity_rationale": "The reviewer comments on 'Performance differences between methods' and 'benchmarks selected.' They are not pinpointing a specific table, figure, or section within the paper. While they *mention* benchmarks, they don't explicitly state which one.", "verifiability_rationale": "The reviewer makes a claim about the performance differences and offers a potential reason ('less than 1 percentage point'). However, they don't explicitly *justify* why a small difference is significant or how this relates to the benchmarks being outdated. The link is implied but not explicitly proven or explained.", "helpfulness_rationale": "The review point presents a finding (minimal differences) and offers a potential explanation (benchmarks). It doesn't directly suggest a *specific* action the authors should take based on this finding. It's more of an observation."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer provides three explicit points for improvement: questioning the method's novelty on deterministic systems, suggesting evaluation on stochastic environments, and pointing out the missing BEAR baseline. While the suggestions are clear, they are not directly actionable as they require further analysis and experimentation from the authors.", "grounding_specificity_rationale": "The reviewer's comments are 1 in specific sections or tables of the paper. They are generally commenting on the method's behavior and the missing baseline without pointing to a specific location in the paper.", "verifiability_rationale": "The reviewer makes several declarative statements, indicating claims. However, these claims are not supported by any reasoning, references, or external evidence.", "helpfulness_rationale": "The reviewer's comments are relevant to the authors' work, raising concerns about the method's novelty and the experimental setup. However, the suggestions are presented as questions and observations rather than direct, actionable recommendations with concrete solutions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the action of 'providing theocratical justification' in relation to 'cotraining and weight averaging'. This directly indicates an intended action. The terms 'cotraining' and 'weight averaging' are also specific techniques, making the action quite clear.", "grounding_specificity_rationale": "The review point directly refers to 'cotraining and weight averaging' as the area needing improvement. This explicit mention allows the reader to precisely identify the section or techniques being discussed, thus achieving 'full grounding'. The point also specifies the *nature* of the improvement needed: 'theocratical justification' and its importance for 'performance', making the specificity high.", "verifiability_rationale": "The review point contains a claim in the form of a suggestion: 'It would be better if the author could provide some theocratical justification in terms of why cotraining and weight averaging can improve results, since they are important for the performance.' This is a statement of what the author should do or what the justification should include, but it doesn't present a factual claim that requires verification in the traditional sense of proving something is wrong or missing in the paper's content itself.", "helpfulness_rationale": "The review point identifies a potential area for improvement in the paper \u2013 the justification for using cotraining and weight averaging. It encourages the authors to provide a clearer explanation of why these methods are expected to improve performance. While it doesn't directly tell the authors how to fix their model or what data to use, it points to a specific aspect of the paper that needs clarification or improvement in its presentation. The helpfulness lies in guiding the authors towards a more welljustified explanation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides a clear and specific suggestion for improving the clarity and actionable nature of a comment. They identify a potential ambiguity in the comment's meaning and propose a concrete way to resolve it by specifying the exact changes needed. This directly addresses the reviewer's point about the comment lacking meaningful information and being vague.", "grounding_specificity_rationale": "The reviewer directly points out a specific issue with the grounding of a comment. They identify a potential problem in section 4 and clearly state that the comment does not identify a specific part of the paper being addressed. They also specify that the comment does not detail what needs to be addressed in that part. This clearly demonstrates a lack of grounding specificity.", "verifiability_rationale": "The reviewer raises a point about the definition of a graph notation. While it could be argued that the authors *should* be using multisets if they are dealing with repeated labels, the reviewer is pointing out a potential *inconsistency* or *ambiguity* in the *definition* itself. It's a suggestion for improvement in the *methodology* used to represent the graph, not a critique of a specific finding or claim made by the authors. The evidence is present, but the conclusion depends on the actual implementation.", "helpfulness_rationale": "The reviewer's suggestion is directly aimed at improving the clarity and accuracy of the graph representation, which is beneficial for the authors. They propose a concrete way to address a potential limitation in the *definition* of the graph notation, making the suggestion actionable and directly helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential limitation of the authors' derivation by referencing the distinction between classical learning theorybased bounds and BayesianPAC based bounds. However, it does not explicitly state what action the authors should take to address this limitation. It points out a potential issue but lacks a direct, actionable suggestion.", "grounding_specificity_rationale": "The comment refers to 'classical learning theorybased bounds' and 'BayesianPAC based bounds' generally, without specifying a particular section, table, figure, or unique aspect of the authors' paper where this distinction is crucial. While it names the types of bounds, it doesn't pinpoint the exact location of the issue within the authors' work.", "verifiability_rationale": "The comment contains a claim: 'the to the best of my knowledge, does not yield realistic bounds, unless Bayesian considerations are taken into account.' This claim is based on the reviewer's understanding and experience. However, the comment does not provide specific examples, references, or detailed explanations to support this claim within this review point itself.", "helpfulness_rationale": "The comment identifies a potential theoretical limitation of the authors' work by highlighting the difference between classical and Bayesian learning theory bounds. While it points out a potential area for improvement or consideration, it does not offer a specific, actionable suggestion for the authors to make their bounds more realistic. It's a statement of a concern rather than a direct prescription for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states what they need: 'how the implicit distribution characterize the uncertainty of each label value' and 'how the model mitigrate the uncertainty of the label distribution'. This is an explicit request for details and a clear indication of what needs to be done. While the reviewer doesn't state *how* to do it, they identify the specific actions required, making it 3.", "grounding_specificity_rationale": "The reviewer refers to a specific methodological aspect: 'how the implicit distribution characterize the uncertainty of each label value and how the model mitigate the uncertainty of the label distribution'. This suggests they can identify the relevant part of the paper if it were explained. However, the review point itself doesn't explicitly point to a specific section, table, or figure, making the grounding somewhat implicit.", "verifiability_rationale": "The review point is a question, not a declarative statement making a claim. There is X being made, so it doesn't fall under the verifiability categories. The underlying *implied* claim is that the paper lacks this information, but the review point itself doesn't explicitly state a claim.", "helpfulness_rationale": "The reviewer is pointing out a specific area where the authors seem to be lacking information. This can be helpful for the authors as it highlights a potential weakness in the paper and encourages them to seek clarification. However, the review point itself doesn't provide the information, so its immediate helpfulness is limited to identifying a need for more detail."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation of the proposed method but does not explicitly state what action the authors should take to address this limitation. The suggestion is more of a concern than a direct instruction. The reviewer identifies a potential problem but doesn't provide concrete steps the authors should follow to mitigate it.", "grounding_specificity_rationale": "The reviewer identifies a limitation of the proposed method regarding its ability to detect hallucinations in openended responses. While the reviewer mentions the variability of outputs, they do not specify a particular section, table, figure, or unique aspect of the paper where this issue is most prominent. The grounding is not as precise as it could be. The reviewer points out a general limitation without pinpointing the exact area of concern within the paper.", "verifiability_rationale": "The reviewer states a claim about the proposed method's potential struggle to detect hallucinations in openended responses. While the reviewer provides a rationale for this belief, they do not provide specific examples, references to external works, or logical reasoning to fully support their claim. The justification is present but lacks the depth and evidence required for full verifiability. The reviewer presents a potential weakness without sufficient backing.", "helpfulness_rationale": "The reviewer criticizes the proposed method for its potential struggle to detect hallucinations in openended responses. While this is a valid concern, the reviewer does not offer specific, actionable improvements or suggestions to address this limitation. The feedback is more of a critique than a constructive suggestion for improvement. The reviewer points out a potential weakness without providing a clear path forward for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "Partially Verifiable", "helpfulness_label": "None", "actionability_rationale": "The reviewer suggests an experiment to verify a conclusion about label noise and model size. While this implies a actionable step, it doesn't explicitly state what needs to be done with the draft. The suggestion is broad and doesn't pinpoint a specific missing element or action to take on the paper itself.", "grounding_specificity_rationale": "The reviewer suggests verifying a conclusion about label noise and model size, but doesn't explicitly mention the specific paper or section where this verification should occur. The connection to 'deep learning models' is implied but not clearly stated as a direct reference to a specific part of the draft.", "verifiability_rationale": "The reviewer claims there's a conclusion about label noise and model size that needs verification and suggests an experiment to do so. The claim is supported by the suggestion of an experiment, but the claim itself isn't explicitly stated as a conclusion within the review point. The evidence for verifiability comes from the *action* of suggesting an experiment.", "helpfulness_rationale": "The reviewer suggests an experiment to verify a conclusion about label noise and model size. This is a relevant and constructive suggestion that could help the authors improve their draft by addressing a perceived lack of clarity. While it doesn't directly critique the paper's content, it offers a concrete way to investigate a potential weakness."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests an improvement by stating 'The writing could be improved' and proposes a concrete action by saying 'It would be helpful to draw a table to compare different CoT prompting methods across different dimensions.' This demonstrates an explicit action with a clear goal. However, the reviewer does not specify *how* the table should be structured or what dimensions to include, making it somewhat vague on the implementation details. Therefore, while the action is explicit, the concreteness of the action is limited.", "grounding_specificity_rationale": "The review point asks specific questions about the methodology, such as 'How and why shall we make an assumption that \u201cquestions of all the wrong demonstrations fall into the same frequenterror cluster\u201d?'. It also asks about the selection criteria, 'Is the selection criteria in section 4.2 reasonable? Namely, why do we not choose questions with more than 60 tokens and rationales with more than 5 reasoning steps?'. These questions directly address specific parts of the paper (methodology and experimental setup) and explain *why* certain choices were made. The grounding is strong because the questions are specific to the paper's content. The specificity is also high as the reviewer is asking for justifications and reasons behind the choices.", "verifiability_rationale": "The review point contains claims that can be verified. For example, the reviewer states 'The paper is wellorganized' and 'The writing is good and most of the content is very clear to me' as observations. The reviewer also poses questions that imply a need for clarification or justification, such as 'How and why shall we make an assumption that \u201cquestions of all the wrong demonstrations fall into the same frequenterror cluster\u201d?'. These claims and questions are supported by logical reasoning and common knowledge within the context of academic writing and research methodology. The external references are not explicitly mentioned in this point, but the questions are based on common practices in the field. The verifiability is good as the claims are generally accepted and the questions are logical.", "helpfulness_rationale": "The review point is 5. It directly addresses a stated weakness ('The writing could be improved') and provides a concrete suggestion ('draw a table to compare different CoT prompting methods across different dimensions'). This is an explicit action with a clear goal. Furthermore, the reviewer asks specific and focused questions about the methodology, which can help the authors understand and potentially refine their approach. The questions are welldefined and directly address aspects of the paper being reviewed. The helpfulness is high because the suggestions are actionable and the questions are clear and relevant."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The review point implicitly suggests that the likelihood function needs to be Gaussian for the Kalman filter to work. While it doesn't explicitly state 'p(y | Hf_bar(tn)) has to be chosen Gaussian', the implication is clear. The reviewer is pointing out a missing detail that needs to be addressed for the Kalman filter to be correctly applied. The action is 'ensure the likelihood is Gaussian', which is concrete but requires further clarification on *how* to achieve this.", "grounding_specificity_rationale": "The review point explicitly mentions 'p(y | Hf_bar(tn))' as the location where the Gaussian requirement needs to be stated. This clearly identifies the specific part of the model description where the issue lies. The grounding is 'p(y | Hf_bar(tn))' and the specificity is 'the Gaussian requirement for Kalman filter implementation'.", "verifiability_rationale": "The review point makes a claim about a requirement for Kalman filtering and smoothing, stating that the likelihood function must be Gaussian. This claim is verifiable based on the fundamental principles of Kalman filter theory. While not explicitly citing external references, the logic is wellestablished within the field.", "helpfulness_rationale": "The review point is 5 because it points out a crucial detail that is often implicitly assumed but needs to be explicitly stated for the correct application of Kalman filters. By highlighting this requirement, the reviewer is directly informing the author of a potential oversight and suggesting a necessary step for accurate implementation. This is a clear and actionable piece of feedback."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "3 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "2 (2)", "actionability_rationale": "The review point points out a *potential* issue (large training loss with suboptimal weight decay) and suggests a *consequence* (suboptimal cosine similarities). It also mentions the *lack of reporting* of cosine similarities for *large* weight decay. While it identifies areas of concern, it doesn't explicitly *recommend* an action like investigating training loss or exploring alternative weight decay strategies. It also doesn't provide a concrete *fix*.", "grounding_specificity_rationale": "The reviewer mentions \"weight decay is applied to all layers\" and \"cosine similarities for such large weight decay strengths are not reported.\" While the *general* concept of weight decay is mentioned, the specific *layers* affected are not explicitly named (e.g., \"all convolutional layers,\" \"recurrent layers\"). The *range* of weight decay strengths is also vague ('such large weight decay strengths\"). However, the reviewer *specifically* mentions \"cosine similarities for such large weight decay strengths are not reported,\" providing a concrete piece of information. The vagueness of \"large\" weight decay strengths and the lack of a precise definition of the affected layers limit the grounding specificity.", "verifiability_rationale": "The reviewer makes a statement about the *expected* outcome of applying suboptimal weight decay (large training loss and suboptimal cosine similarities) and points out the *lack of reporting* of cosine similarities for large weight decay. This constitutes a claim that requires justification. However, the reviewer *does not provide any evidence* or *reasoning* to support this claim. They also don't explain *why* cosine similarities are important or how suboptimal values would manifest.", "helpfulness_rationale": "The review points out a potential issue related to training loss and cosine similarity but doesn't offer a concrete solution or a detailed explanation of how to diagnose the problem. While it identifies a problem, it lacks actionable steps for the author to take. It also doesn't explain the implications of suboptimal cosine similarities or suggest alternative weight decay strategies."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is a clear and direct identification of a missing piece of information, making it an explicit action. The reviewer also provides a clear description of the implications of this omission.", "grounding_specificity_rationale": "The reviewer identifies the specific sections (title, abstract, introduction, and discussion) where the information is missing. While they don't pinpoint the exact element within those sections that lacks clarity, they clearly indicate the *location* of the problem. This makes the grounding somewhat concrete, as the sections are identifiable. However, the lack of specific details within those sections makes the specificity somewhat underspecific.", "verifiability_rationale": "The reviewer's point is not a claim about the paper itself, but rather a critique of the *absence* of information. They are suggesting that readers might misinterpret the results due to the lack of clarity. This is more of an implicit suggestion rather than a direct claim that can be verified by referencing external sources or logical reasoning within the paper. Therefore, it leans towards '1' as a direct claim, but the concern itself could be considered somewhat 'X' as it implies a belief about the reader's understanding. Given the borderline nature of this point, I've opted for '1' as it highlights the lack of direct claim verification.", "helpfulness_rationale": "The reviewer clearly identifies a significant and actionable issue. They point out a lack of clarity regarding the experimental setup, which could lead to misinterpretations. This is a strong and specific piece of feedback that is likely to be helpful for the authors. The reviewer's concern about the implications for publication further emphasizes the importance of this feedback."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "3 (2)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer's suggestions are relevant and point towards improvements, making them 3, even if not fully explicit or concrete. The suggestions are broad and don't specify *how* to create the toy dataset or what visualization to use. However, the suggestions are clear about what needs to be done, which makes them 3.", "grounding_specificity_rationale": "The reviewer is making general suggestions about the need for more experiments and a new metric. They are not explicitly pointing to a specific section, table, or figure in the paper. The reviewer is *implying* these improvements rather than directly stating their location.", "verifiability_rationale": "The reviewer's suggestions are vague and lack specific details or references. There's no clear 'how to do this' or 'examples' provided. The suggestions are presented as claims that need to be verified, but the verification is not provided. The reviewer is making general statements about the need for experiments and a new metric without providing concrete examples or logical reasoning to support these claims.", "helpfulness_rationale": "The suggestions made by the reviewer are relevant and point towards improvements that could benefit the authors. They highlight areas where the paper could be strengthened, such as with additional experiments and a new metric. While the suggestions are broad and lack specific details, they are still generally helpful in guiding the authors towards better practices. The reviewer is not providing negative feedback but rather constructive suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about computational complexity and requests a comparison. While the question is clear and asks for a direct action (comparison), it lacks the specificity needed to be fully actionable. The authors are asked to compare the proposed method with 'other methods' but are not given any context or guidance on which methods to consider. This vagueness makes it less immediately actionable, although it points to a relevant issue.", "grounding_specificity_rationale": "The review point refers to 'other methods' without specifying which ones. The authors cannot confidently determine which part of the paper or concept the reviewer is addressing. While the point clearly specifies what needs to be compared (computational complexity), it doesn't pinpoint the exact area within the paper where this comparison should be made. Therefore, while the grounding is somewhat implicit in the request for a comparison, it's not as precise as it could be.", "verifiability_rationale": "The review point contains a claim: 'Is it true that the proposed method requires much more computation than other methods?'. However, the claim is not supported by any evidence or reasoning within the review point itself. The reviewer is making this assertion, but doesn't provide any justification or comparison to back it up. Therefore, while there is a claim, it is not verifiable within the provided text.", "helpfulness_rationale": "The review point raises a relevant question about the computational cost of the proposed method and requests a comparison with other methods. This points to a potential area for improvement and provides a direction for further investigation. However, the lack of specificity in identifying 'other methods' and the absence of a concrete request for the type of comparison makes it less immediately helpful for the authors. They are left with a broad request without clear guidance on how to proceed."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point suggests areas for further analysis and exploration but does not explicitly state how the authors should modify their draft based on the findings.", "grounding_specificity_rationale": "The review point discusses general aspects like cost, incentives, and performance without explicitly identifying a specific section, table, figure, or unique element of the paper being addressed.", "verifiability_rationale": "The review point presents suggestions and questions rather than explicit claims that require verification or supporting evidence.", "helpfulness_rationale": "The review point offers insights into the system's behavior and potential roles but does not directly instruct the authors on how to improve their current draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'no significance testing is done' and provides a concrete suggestion of 'check the distribution and accounting for multiple comparisons' to address this. This indicates a clear and actionable point.", "grounding_specificity_rationale": "The reviewer identifies specific claims being questioned (ChatGPT vs. GPT4 performance and FeedME2 vs. PPO performance) and points to specific lines (line 486) as examples. They also specify the dBLEU scores and humeval scores, making the identified issue very specific.", "verifiability_rationale": "The reviewer makes a claim 'it's hard to say whether it is significant without proper testing' and supports it by stating 'no significance testing is done' and highlighting the 'minimal difference' between the models. This claim is supported by logical reasoning and observations.", "helpfulness_rationale": "The reviewer directly points out the lack of statistical significance testing, which is a clear weakness in the presented results. They also offer a constructive suggestion ('check the distribution and accounting for multiple comparisons') to address this, making the feedback both identifying a problem and providing a solution."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The comment identifies a problem ('partially difficult to follow') and suggests a solution ('should be revised' and 'extend the approach description'). This is explicit. However, the suggestion to 'extend the approach description' is vague and doesn't provide specific actionable steps, making it partially actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions '\u00a7 3', indicating they understand which part of the paper is being discussed. This is strong grounding. While the *content* of the difficulty is vague, the *location* is clear. Therefore, it's fully grounded.", "verifiability_rationale": "The comment states a claim ('The approach description (\u00a7 3) is partially difficult to follow') but doesn't provide external evidence or reasoning within this review point to *prove* it's difficult to follow. The suggestion to use extra space *implies* it's a problem, but doesn't offer direct evidence within this review. Therefore, it's 1.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper ('approach description (\u00a7 3) is partially difficult to follow') and suggests a concrete improvement ('should be revised' and 'extend the approach description'). This directly addresses a potential issue for the authors. Therefore, it's 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a lack of interpretive insights in the discussion and explicitly points out the absence of comparisons with stateoftheart methods not based on gyrostructures. However, it does not provide concrete actions or specific suggestions on how to address these issues. The action is implied but not directly stated.", "grounding_specificity_rationale": "The comment refers to the 'related discussion' generally and mentions 'manifoldbased learning' broadly. It does not explicitly identify a specific section, table, figure, or unique aspect of the paper where the lack of interpretive insights or comparisons is evident. Therefore, the grounding is weak.", "verifiability_rationale": "The comment contains a claim (the lack of interpretive insights and comparisons) but does not provide any evidence or reasoning to support why this omission is problematic. It does not explicitly reference external works or logical reasoning to justify the importance of these comparisons. Therefore, the verifiability is low.", "helpfulness_rationale": "The comment identifies potential weaknesses in the discussion and experimental evaluation. It suggests that the lack of interpretive insights and comparisons with nongyro methods could impact the assessment of the proposed approach. However, it does not provide specific, actionable recommendations for the authors on how to address these issues. The feedback is present but lacks concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The request for 'more evidence or analysis' and 'other key properties' is broad and lacks a clear, actionable step. The request is somewhat vague.", "grounding_specificity_rationale": "The reference to 'training effectiveness property of the dataset' and 'other key properties' is general and doesn't specify a particular section or detail. The reviewer doesn't pinpoint a specific part of the dataset or provide details about the properties they are interested in.", "verifiability_rationale": "The review point does not contain a claim or assertion that needs to be supported. It's a request for information, not a statement that something is true or false.", "helpfulness_rationale": "The review point requests more information without providing any specific suggestions or guidance on how to use that information. It's a question rather than a constructive critique or suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states they would like to see more details about the two baselines presented in Figure 5. This is a clear and direct request for information, making it 5. The reviewer also specifies *more details about the two baselines*, which is concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 5' and the 'two baselines presented in Figure 5' as the specific part of the paper they are referring to. This provides a clear and explicit grounding. Furthermore, the reviewer specifies that they want 'more details about the two baselines', adding to the specificity of the grounding.", "verifiability_rationale": "The reviewer's point is a request for more information rather than a claim, judgment, or suggestion. While the desire to understand Figure 5 is generally reasonable, the review itself does not provide any logical reasoning, common knowledge, or external references to support the desire for more details. Therefore, based on the provided definition of verifiability, this point is 1.", "helpfulness_rationale": "The reviewer's point is about providing more information to the authors. While this information is valuable, it is not framed as a critique of the work itself or a suggestion for a major improvement. It is more of an information request than a constructive critique or actionable suggestion."}
{"actionability_label": "None", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states they think section 3.2 can be eliminated, which is a direct action. However, they do not specify how to implement this action, such as providing a link to the code or a more detailed explanation of the GumbelSoftmax/Concrete distribution. The action is stated, but the implementation details are missing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 3.2' by name, which demonstrates strong grounding. They also provide a reason for eliminating the section, stating, 'I think that at this point readers can be presumed to know about the GumbelSoftmax/Concrete distribution.' This provides a specific reason for the suggestion.", "verifiability_rationale": "The reviewer makes a judgment about the content of section 3.2, stating, 'I think that at this point readers can be presumed to know about the GumbelSoftmax/Concrete distribution.' This constitutes a claim. However, the reviewer does not provide any evidence or justification for this claim. They do not cite external sources or provide a logical argument to support their assertion that readers are likely familiar with the GumbelSoftmax/Concrete distribution at that point in the paper.", "helpfulness_rationale": "The reviewer suggests eliminating section 3.2, which is a clear suggestion for a structural change. However, the review lacks specific details on why this section is redundant or unnecessary. The reviewer does not explain the perceived value or information density of section 3.2, making it difficult for the author to understand the benefit of its removal."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the improvements could be due to regularization effects and suggests an ablation study as a solution. This is an explicit action and a concrete suggestion for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'regularization effects,' 'finetuning is performed for 10 epochs,' and 'without earlystopping' as potential reasons for the observed improvements. These are specific details about the experimental setup and methodology. The reviewer also implies that the high variance in GLUE finetuning without validation suggests a lack of clarity in the identified issue.", "verifiability_rationale": "The reviewer provides a justification for their concern by stating that 'the finetuning on GLUE without validation earlystopping usually has very high variances.' This provides a logical reasoning and a reference point (GLUE finetuning without validation) to support their claim. The reviewer also suggests 'proper ablation studies are needed' as a solution, which is a specific and actionable suggestion.", "helpfulness_rationale": "The reviewer directly addresses a potential flaw in the methodology (distillation vs. regularization) and provides a clear and actionable suggestion for improvement (ablation studies). This is 5 for the authors as it directly points to a potential issue and offers a concrete next step."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "Both suggestions are explicit, stating the action to be taken. The addition of performance on word similarity and sentence translation tasks is a concrete action with clear implications for evaluating the framework. Similarly, the suggestion to add experiments on morphologically rich and lowresource languages is a concrete action with clear implications for the robustness of the framework.", "grounding_specificity_rationale": "Both suggestions have weak grounding. While the terms 'word similarity and sentence translation tasks' and 'morphologically rich languages' and 'lowresource languages' are descriptive, the reviewer cannot confidently pinpoint the exact sections, tables, or figures in the paper that these tasks or languages correspond to. The reviewer would need to search for these terms or understand their relevance to the existing content to identify the specific parts being addressed.", "verifiability_rationale": "Both suggestions contain claims that are 3. For the word similarity and sentence translation tasks, the claim is that these evaluations would 'lend more credibility' and are 'standard benchmarks'. For the morphologically rich and lowresource languages, the claim is that these additions would be 'good to have' for evaluating robustness. While the claims lack specific references, the reasoning based on common knowledge of NLP tasks and language diversity supports the suggestions.", "helpfulness_rationale": "Both suggestions are 5. The addition of performance on standard NLP tasks like word similarity and sentence translation directly addresses a potential weakness in the framework's evaluation. Similarly, including experiments on diverse languages like Finnish, Hebrew, and lowresource languages would significantly enhance the robustness and generalizability of the framework's evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks two questions: 'how node importance can be used' and 'why the paper doesn't include the 1shot paper setting'. While the questions are clear, the reviewer doesn't provide specific details or examples within the review point itself to demonstrate how node importance is implemented or how the 1shot setting is handled. The questions are somewhat general.", "grounding_specificity_rationale": "The reviewer asks about the use of node importance in the 1shot setting and the absence of a 1shot experiment. While they mention the 1shot setting, they don't explicitly point to a specific section or element of the paper that discusses it. The connection to related works like RALE is implied but not explicitly stated as grounding the 1shot aspect to the RALE paper. The questions are about the *mechanism* and the *reasoning*.", "verifiability_rationale": "The reviewer makes claims about the paper's lack of explanation regarding the use of node importance in the 1shot setting and the absence of a 1shot experiment. These claims are valid based on the provided excerpt. The paper could benefit from clearer explanations and justifications for these aspects.", "helpfulness_rationale": "The reviewer has identified two key areas where they expect more information: how node importance is used in the 1shot setting and why the paper doesn't include a 1shot experiment. The paper doesn't explicitly address these points in the provided excerpt, making the reviewer's questions valid and pointing to areas for improvement in the paper's presentation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states \"There should be more discussions\" regarding two specific areas: \"why LLMs struggle at finegrained hard constraints\" and \"how to address these problems.\" This directly points to actions the authors should take. The reviewer is not just pointing out a problem but suggesting a concrete next step. The request is clear and identifies the scope of the discussion. Therefore, the reviewer is asking the authors to perform a specific action: engage in a discussion about a defined topic.", "grounding_specificity_rationale": "The review point explicitly mentions \"finegrained hard constraints.\" This is a specific technical term within the context of LLM limitations. The reviewer is directly referencing a specific aspect of the problem. The grounding is strong because the term is literal and specific. The reviewer is also implicitly asking for a discussion about the *cause* and *solution* related to this specific type of constraint. While not providing concrete examples within the review point itself, it clearly pinpoints the area of interest. Therefore, the grounding is fully grounded.", "verifiability_rationale": "The review point itself is not a claim that can be verified. It's a suggestion for further discussion. There's no logical reasoning, common knowledge, or external references provided within the review point itself. It's a prescription for the authors to explore a specific area, rather than a statement that can be proven true or false based on existing information. Therefore, the verifiability is 1.", "helpfulness_rationale": "The review point identifies a relevant problem area (LLM limitations with constraints) and suggests a direction for improvement (more discussion on the cause and solution). While it doesn't provide specific implementation details or evidence, it clearly points to a valuable area for the authors to investigate and potentially address. This sets a clear goal for the authors' future work. Therefore, the review point is helpful in guiding the authors towards further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that 'little insights are given about why do we need to do selfsupervised learning on this kind of data.' This directly identifies an actionable gap in the paper. While it doesn't specify *how* to address this, it clearly points to an area for improvement. The reviewer suggests investigating the necessity of this approach, which is a concrete action the authors can take.", "grounding_specificity_rationale": "The review point explicitly refers to 'selfsupervised learning on this kind of data' which is a specific part of the paper. The reviewer can accurately pinpoint the section being addressed, indicating strong grounding. However, the point focuses on the *lack* of insights *why* this is needed, which is a general area of concern rather than a specific issue within that section. Therefore, while grounded, it's not specific about the nature of the problem.", "verifiability_rationale": "The review point contains a claim: 'little insights are given about why do we need to do selfsupervised learning on this kind of data.' This is a statement of a deficiency. However, the point does not provide any evidence, examples, or references to support this claim. It simply states the problem without offering any justification or context. Therefore, the claim is not wellsupported.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper: the lack of justification for using selfsupervised learning on the specific data. This is a valuable point for the authors to consider. While the point doesn't offer a solution, it highlights a crucial area for further investigation and potentially adjustment of the approach. By pointing out this missing justification, the reviewer guides the authors to understand the *why* behind a key decision, which is important for improving the work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "One part of the review point is implicit, as the reviewer doesn't explicitly state how to improve the link between IP and equations. The reader would need to infer that they should try to understand the connection better. The other part is explicit, stating that subfigures in Figs 3 and 4 should have labels, not just be mentioned in the captions. This part is actionable as it clearly states what needs to be done.", "grounding_specificity_rationale": "The reviewer doesn't explicitly state which equations or terms are being referred to when mentioning the link with IP, making it weakly grounded. However, the reviewer explicitly mentions 'subfigures in Figs 3 and 4' and states they should have labels within the figures, making this part specifically grounded.", "verifiability_rationale": "Neither part of the review point makes a claim that needs verification. The first part is a suggestion for improvement, and the second part is a request for a specific formatting change. There are no claims that require logical reasoning, common knowledge, or external references to be considered verifiable.", "helpfulness_rationale": "The review point provides actionable feedback on how to improve the clarity of subfigures, which is directly helpful to the author. However, the suggestion about the link between IP and equations is less specific and requires the author to infer the intended improvement, making it less helpful overall."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need to average results over multiple runs, which is a direct and clear action to improve the statistical significance of the findings. This action is welldefined and directly addresses the issue of variability in results.", "grounding_specificity_rationale": "The reviewer's comment is 1 in a specific part of the paper. They are suggesting a general improvement to the experimental process rather than addressing a specific issue within a figure, table, or section.", "verifiability_rationale": "The reviewer's comment does not contain a claim. It is a suggestion for improvement rather than a statement that requires verification. Therefore, it is classified as 'X' for X.", "helpfulness_rationale": "The reviewer's suggestion to average results over multiple runs is a valid point that can improve the reliability of the findings. However, it is a relatively minor suggestion that does not directly address any specific weaknesses in the current draft. Therefore, it is 3 in identifying a potential flaw in the experimental design, but it does not provide a concrete fix for the current work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'there is no analysis on a seemingly important (see SimCLRv2 and other recent papers that show that) part of that approach, ie the projection head.' This clearly identifies an action the authors should take (analyze the projection head) and is concrete in its suggestion.", "grounding_specificity_rationale": "The reviewer explicitly names 'the projection head' as the missing part of the SimCLR method. This is a clear and specific reference, making it fully grounded. Furthermore, the reviewer explains *why* this is important by referencing 'recent work suggesting that' and mentioning 'SimCLRv2 and other recent papers'. This provides context and justification for the importance of the projection head, making it highly specific.", "verifiability_rationale": "The reviewer makes a claim: 'there is no analysis on a seemingly important (see SimCLRv2 and other recent papers that show that) part of that approach, ie the projection head.' This claim is supported by the reviewer stating that 'recent work suggests that'. However, the reviewer does not provide specific citations or detailed explanations to back up this claim within the review point itself. The justification is based on the reviewer's awareness of recent work, not explicitly stated within the review point's content.", "helpfulness_rationale": "The reviewer identifies a specific area (the projection head) in the SimCLR method that lacks analysis. By pointing this out, the reviewer provides a clear direction for the authors to improve their work. This is a constructive suggestion rather than just a criticism."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies the issue of hidden observations and conclusions but does not explicitly state how the authors should address this. It implies a need for highlighting but lacks concrete steps. The action is implicit rather than explicit.", "grounding_specificity_rationale": "The comment refers to the 'experimental section' generally, without specifying a particular subsection, table, figure, or unique element. This makes the grounding weak as the authors cannot confidently determine the exact area being addressed.", "verifiability_rationale": "The comment states that the observations and conclusions are important and suggests highlighting them. However, it does not provide any evidence, logical reasoning, or external references to support this claim. The claim is presented without sufficient justification.", "helpfulness_rationale": "The comment points out a valid concern (hidden observations) and suggests a potential improvement (highlighting). However, it lacks specific guidance on how the authors should implement this suggestion. The comment identifies a need for action but does not provide concrete steps, making it less helpful than a comment with more specific guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states \"it would be better to provide some ablation experiments of these tricks\". This is a direct and clear indication of an action the authors should take. The phrase \"these tricks\" further clarifies the action being suggested, making it concrete.", "grounding_specificity_rationale": "The comment explicitly refers to \"Section 3.4\" and mentions \"ablation experiments of these tricks\". This demonstrates a high level of grounding as the authors can accurately pinpoint the section and the nature of the suggested experiments. The use of \"these tricks\" further aids in identifying the specific aspect being addressed.", "verifiability_rationale": "The comment contains a claim in the form of a suggestion: \"it would be better to provide some ablation experiments of these tricks\". This is a statement that requires justification. However, the comment does not provide any logical reasoning, common knowledge, or external references to support this suggestion. It simply states what the reviewer believes would be beneficial.", "helpfulness_rationale": "The comment provides a clear suggestion for improvement: conducting ablation studies on the 'tricks' mentioned in Section 3.4. This directly points towards a concrete action the authors can take. While the comment doesn't guarantee the outcome of these experiments or provide specific examples of the 'tricks', it offers a specific direction for further investigation. The reviewer is not questioning the validity of the suggestion itself, but rather pointing out the lack of empirical validation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their intention to ask a question about the performance of their KDE method on datasets with a nonbinary decision space and suggests an experiment to compare it with another method. This constitutes an explicit action with a clear goal.", "grounding_specificity_rationale": "The reviewer mentions 'decision space' and 'binary?', which are specific terms related to the classification problem. However, they do not explicitly identify the specific part of the paper or dataset they are referring to, nor do they provide details about the nature of the nonbinary decision space. The reference to '44' helps ground the context but doesn't fully specify the scope of the request.", "verifiability_rationale": "The reviewer is asking a question about a potential limitation of their method and suggesting an experiment to investigate it. This is a request for information rather than a definitive claim that can be immediately verified or falsified. There is no explicit claim about what should be the case or what the outcome should be.", "helpfulness_rationale": "The reviewer is raising a valid point about a potential limitation of their approach and suggesting an experiment to address it. This is a relevant and potentially helpful feedback for the authors. However, the lack of specificity in the request makes it less immediately actionable and impactful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point lacks explicit and concrete actions for the authors. While it identifies areas for improvement, it doesn't specify *how* to change the SR model's capacity or *why* it affects the FID. Similarly, it mentions unexpected artifacts due to pipelining but doesn't guide the authors on how to address them. The missing details about the SR model's capacity are also not actionable. The reviewer points out issues but doesn't provide clear steps for the authors to take.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or model being discussed. The reviewer refers to 'the SR model's capacity' and 'the FID' generally, without specifying which SR model or where the FID is reported. Similarly, 'the proposed method is pipelining' is a general statement without pointing to a specific section describing the pipelining. The lack of specificity makes it difficult for the authors to pinpoint the exact issue being addressed.", "verifiability_rationale": "The review point presents observations as facts without providing any supporting evidence or justification. The reviewer states that 'the impact of the SR model affects the FID' and 'there are some unexpected artifacts' without explaining *why* these things happen. There is no logical reasoning or references provided to back up these claims. The statements are presented as discoveries rather than questions or suggestions for improvement.", "helpfulness_rationale": "The review point is not particularly helpful to the authors. While it identifies areas where the work could be improved, it does not offer concrete solutions or guidance on how to address the issues raised. The reviewer simply states the problems (impact of capacity, unexpected artifacts, missing details) without suggesting any actions or improvements. The feedback is descriptive rather than prescriptive."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the purpose of Proposition B.1, which can be considered an explicit action. They also point out a clear missing element (the 'proof'), which implies an actionable next step. While the reviewer doesn't provide a detailed explanation of *why* the proof is missing, the identification of the missing proof itself is a concrete action. The reviewer also implies that the proof is missing, which is a concrete action that needs to be applied.", "grounding_specificity_rationale": "The reviewer explicitly names 'Appendix A' and 'Proposition B.1' in their review point. This is a clear indication of full grounding. They also specify the *issue* with Proposition B.1, which is the unclear purpose and the missing proof. This specificity is quite high as the paper section and the exact problem are identified.", "verifiability_rationale": "The reviewer makes a claim that 'this is a wellknown concept' and 'the authors\u2019 socalled 'proof' is missing. The claim about the missing proof requires verification by checking Appendix B. The claim about the proof being 'wellknown' is less directly verifiable, as it's a general statement. However, the core of the point, the missing proof, is verifiable. The reviewer also provides a suggestion ('missing proof') which directly addresses the identified issue.", "helpfulness_rationale": "The reviewer provides a clear weakness in the paper: the unclear purpose of Proposition B.1 and the missing proof. They also offer a concrete suggestion: to include the proof. This directly helps the authors improve their draft by addressing a specific issue and providing a clear direction for improvement. The reviewer's feedback is directly actionable and addresses a specific problem."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the *lack* of *necessary* experiments. While the *type* of experiments (comparison, ablation, hyperparameter) is implicitly suggested, the *action* of conducting these experiments is not explicitly stated or recommended. The reviewer identifies a missing element but doesn't fully specify what needs to be done.", "grounding_specificity_rationale": "The reviewer makes a general statement about the *lack* of *additional* experiments. They do not specify a particular section, table, or unique aspect of the paper where these experiments are missing. The comment is broad and doesn't pinpoint the location of the deficiency.", "verifiability_rationale": "The reviewer states that the paper lacks *additional necessary experiments*. This is a claim that there is a deficiency. However, the reviewer does not provide any evidence, justification, or reasoning to support this claim. They do not explain *why* these experiments are necessary or *where* they should be conducted.", "helpfulness_rationale": "The reviewer identifies a clear area for improvement: the lack of necessary experiments. This directly impacts the reproducibility and completeness of the work. While the reviewer doesn't specify *which* experiments are needed, the identification of this gap is valuable information for the authors. It sets a direction for them to focus their efforts on conducting additional studies."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a vulnerability related to the approximations and suggests a way to address it by expanding the discussion of the feasible set. This constitutes an explicit action. The grounding of this action is the specific mention of 'the assumption of attacks being in the feasible set only in lines 107110', which clearly identifies the area needing improvement. The action is also concrete as the reviewer proposes a specific improvement: 'expand to reassure the readers that it is not a real concern'.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the assumption of attacks being in the feasible set only in lines 107110' as the specific part of the paper being addressed. This is a literal mention, indicating strong grounding. The comment also clearly specifies what needs to be addressed: 'expand to reassure the readers that it is not a real concern'. This specificity is quite detailed and directly relates to the identified approximation.", "verifiability_rationale": "The reviewer makes a claim by suggesting 'expand to reassure the readers that it is not a real concern'. This claim is supported by the general understanding that approximations are necessary and that the specific assumption might be a limitation. While not a direct citation, the reasoning is logical: if the feasible set is too restrictive, it could limit the applicability of the results derived from the approximations. This provides sufficient verifiability based on common knowledge and logical reasoning.", "helpfulness_rationale": "The reviewer directly addresses a potential weakness in the paper (the approximations and the feasible set assumption) by suggesting a concrete improvement: expanding the discussion to alleviate concerns. This suggestion is actionable and directly targets a potential area of confusion for the readers. By addressing this, the reviewer is providing valuable guidance for the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses an opinion about the paper's contribution and the model's approach but does not provide explicit or concrete suggestions on how to improve them. While it implicitly suggests the authors should consider these aspects, it lacks the necessary detail to be actionable.", "grounding_specificity_rationale": "The reviewer refers to the 'entire paper' and makes general statements about the 'contribution' and 'proposed model' without specifying a particular section, table, or figure. The reference to the paper is broad and lacks precision.", "verifiability_rationale": "The review point makes a statement about the 'somewhat limited' contribution and the 'incremental' approach of the model. This is a declarative statement expressing an opinion rather than a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support these statements.", "helpfulness_rationale": "The review point is a general comment about the paper's overall contribution and the model's approach. While it provides some context, it lacks specific, actionable feedback or suggestions on how the authors should improve their work. It doesn't pinpoint a specific issue or offer concrete guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a *possible* improvement ('probably is needed') but doesn't explicitly state what action should be taken. While it points to a *specific area* ('some pretty \"old\" benchmarks'), the exact nature of the problem and the required action are not clearly defined.", "grounding_specificity_rationale": "The review point mentions 'some pretty \"old\" benchmarks,\" which provides some grounding by identifying a specific part of the paper (benchmarks) and even a specific characteristic of them (\"pretty old\"). However, it doesn't explicitly identify a unique section, table, figure, or element within the paper. The suggestion is also vague about what specific problems exist in these benchmarks.", "verifiability_rationale": "The review point contains a claim: \"more careful analysis probably is needed, especially for some pretty \"old\" benchmarks that the data might have been indirectly seen by the model via the \"data curation\" process.\" This claim is supported by logical reasoning ('the model demonstrate impressive performance on many benchmarks (setting new SoTA scores)') and the mention of \"data curation,\" which implies potential indirect data exposure. However, the suggestion itself ('more careful analysis') is vague and doesn't provide specific examples or guidance on what analysis to perform.", "helpfulness_rationale": "The review point raises a valid concern about the model's performance on older benchmarks and suggests a more thorough analysis. This directly addresses a potential limitation of the proposed model and offers a suggestion for improvement, making it a helpful feedback point for the authors."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "2 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer identifies a problem (inconsistent datasets) and suggests comparing metrics, which is a form of action. However, the reviewer does not explicitly state which metrics should be compared or provide detailed guidance on how to implement this action. The action is implied but not fully specified.", "grounding_specificity_rationale": "The reviewer identifies the problem (inconsistent datasets) but does not explicitly point to a specific part of the paper where this issue should be addressed. While the problem is clearly stated, the lack of a specific paper reference makes the grounding weak. The reviewer mentions 'Figure 4 and Figure 5' which are specific parts of the paper, but the issue is the *lack of consistency* across methods, not a specific figure within a method's description.", "verifiability_rationale": "The reviewer makes a claim about the inconsistency in datasets and metrics. They support this claim by pointing to Figure 4 and Figure 5. However, the reviewer does not provide any logical reasoning, examples, or external references to back up this claim. The verifiability is limited to the observation of the inconsistency itself, without further explanation or evidence.", "helpfulness_rationale": "The reviewer states a concern about the inconsistent evaluation and suggests the authors should be aware of it. This is a helpful comment as it points out a potential issue in the experimental design. However, the reviewer does not ask for specific solutions or provide detailed guidance on how to address this issue. The helpfulness is limited to identifying a problem without offering concrete solutions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4: 3", "actionability_rationale": "The review points out a lack of specific instructions on what to do. It criticizes the comparison but doesn't explicitly state how the comparison is unfair or what needs to be done to address it. While it identifies the issue, the action is implicit, making it 2.", "grounding_specificity_rationale": "The authors can identify the general area (experimental results, proposed method). They mention the comparison and the need for prior information, which points to specific aspects of the experimental setup. However, the specificity is limited to explaining why the comparison is potentially unfair and suggesting a way to address it, making it weakly grounded and somewhat specific.", "verifiability_rationale": "The comment contains a claim (the unfair comparison) and provides a reason for it (the need for two models). While the justification is present, it could be more detailed, making it 3.", "helpfulness_rationale": "The comment is relevant and provides guidance on improving the experimental setup. It highlights a potential issue and suggests a modification, which can guide the authors in refining their work. While it's not a direct solution, it's helpful in identifying areas for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly suggests adding a new type of experiment (collaborative games) to the existing experiments. This is a clear and direct action that the authors can readily implement. The suggestion is not just about identifying a missing feature but proposing a specific change to the experimental setup.", "grounding_specificity_rationale": "The review point mentions 'collaborative games' but does not specify where in the paper or experiments this suggestion should be applied. It lacks the precision needed to pinpoint the exact location, making it difficult for the authors to understand the intended impact. While it specifies the *type* of game, it doesn't indicate the *section* or *experiment* where this suggestion is relevant.", "verifiability_rationale": "The review point presents a suggestion for future experiments (improving the paper by adding collaborative games) and a related statement about exploring both collaborative and competitive settings. While it contains a claim (improving the paper), it doesn't provide any logical reasoning, common knowledge, or external references to support why the current experiments are inadequate or insufficient. It's a suggestion, not a critique or verification of the existing work.", "helpfulness_rationale": "The review point suggests adding a new type of experiment (collaborative games) to the existing experiments. While this points towards a potential improvement, it doesn't directly address any specific weaknesses or shortcomings in the current draft. It's more of a forwardlooking suggestion for future research rather than a critique or improvement of the existing work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the problem: 'experimental settings for Figure 1 to Figure 9 are totally missing'. This directly identifies the missing information and provides a clear action for the authors to take: identify and add the experimental settings. The action is also concrete as it specifies 'experimental settings' which tells the authors exactly what information is needed.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1 to Figure 9', which directly and accurately identifies the specific parts of the paper being referred to. This is a literal mention of the sections, making the grounding fully grounded. The specificity is also high as the comment clearly identifies the exact figures being discussed.", "verifiability_rationale": "The comment contains a claim: 'they are totally missing, which makes them hard to be convincing'. This is a judgment or opinion about the impact of the missing information. The verifiability is somewhat implicit. While the reviewer doesn't provide specific examples of *why* the missing information makes the figures unconvincing, the logical connection is clear: Without knowing the experimental setup, it's difficult to interpret what the figures *mean*. The reviewer implies the importance of experimental settings for the interpretation of figures.", "helpfulness_rationale": "The comment is 5 because it clearly identifies a significant issue: the lack of experimental details hindering the interpretation of figures. The reviewer directly points out the *consequence* of this missing information: the figures are not convincing. Furthermore, the reviewer explicitly states *what is missing* in the experimental settings: 'experimental settings'. This information is directly actionable for the authors. They know *what information they are missing* and *why* it's important. While the reviewer doesn't provide specific examples of *what* is missing within the experimental settings, the *category* of missing information is clear, making it a valuable piece of feedback."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer raises a point about potential overlap with existing parameter isolation methods that leverage sparsity. While the paper introduces a new method, the specific mechanism by which it avoids hindering new task knowledge acquisition isn't explicitly stated as an actionable step. The reviewer's question implies a lack of clarity on how the proposed method differentiates itself from existing approaches in this regard. The action is implied (addressing the sparsity issue), but the concrete steps and evidence are missing.", "grounding_specificity_rationale": "The reviewer's question is about a specific aspect of the method: how it avoids impeding the learning of new task knowledge *specifically* by leveraging sparsity. While the paper's focus is on sparsitybased parameter isolation, the *specific mechanism* of its novelty isn't explicitly stated. The paper mentions avoiding hindering new task knowledge, but the details of how it achieves this, especially concerning sparsity, are not clearly grounded in the text.", "verifiability_rationale": "The reviewer's point is a claim: 'some parameter isolation methods are specifically tailored to leverage this sparsity.' The paper attempts to address this by proposing a new method. However, the *specific way* the proposed method avoids this overlap isn't fully detailed or verifiably supported. The claim is present, but the supporting evidence (the proposed method's specific mechanism) is not fully elaborated to make it 5.", "helpfulness_rationale": "The reviewer's question directly addresses a lack of clarity in the paper regarding how the proposed method avoids hindering the learning of new task knowledge, especially in light of existing sparsitybased methods. This question is a helpful point because it highlights a need for the authors to provide a clearer explanation of the novelty and distinctiveness of their approach. The information is relevant and directly addresses a potential ambiguity in the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the regularization term is 'adhoc' and provides a clear rationale for why this is the case, suggesting specific alternatives. The reviewer identifies the components of the regularization (mean and standard deviation) and proposes why they might not be the best choice. This is an explicit statement of a problem and a clear suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The reviewer directly refers to the 'regularization term' and its components, 'mean' and 'standard derivation', which are specific parts of the paper. This explicit identification demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer does not present a claim that can be definitively verified. Instead, they are suggesting alternatives to the current regularization method. While the grounding is clear, the suggestion itself is not a verifiable claim, making it underspecific in terms of verifiability. The grounding is present, but the specific suggestion lacks external references or logical reasoning to justify why the median is a better choice.", "helpfulness_rationale": "The reviewer provides a clear and actionable critique of the regularization term, explaining why it is adhoc and suggesting specific alternatives. This directly addresses a potential weakness in the paper and offers concrete guidance for improvement, making it 5."}
{"actionability_label": "3.5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for comparisons with existing fairness algorithms and clearly indicates the purpose is to enhance the paper and position the framework. This indicates an explicit action. However, the reviewer does not specify *which* algorithms to compare or *how* the comparison should be conducted, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'existing fairness algorithms' generally, without specifying a particular section, table, figure, or unique element in the paper. This indicates weak grounding as the reviewer does not point to a specific location within the paper. Furthermore, the comment lacks specificity regarding *which* algorithms to compare and the experimental setup for the comparison.", "verifiability_rationale": "The reviewer makes a claim about the benefits of benchmark comparisons. However, they do not provide any supporting evidence, reasoning, or references to back up this claim. The reviewer simply states their desire for such comparisons without explaining why they believe it would be beneficial or providing any justification for its expected impact.", "helpfulness_rationale": "The reviewer's comment identifies a potential improvement to the paper by suggesting benchmark comparisons. While this is a relevant suggestion and addresses a potential gap, the lack of specificity and justification makes it somewhat vague and underspecified. The reviewer does not explain *why* these comparisons are necessary or beneficial, or how they would be implemented. This lack of detail reduces the potential helpfulness of the comment."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action: 'The authors should discuss the iteration cost (computational budge) of the proposed method. It will be great if the authors discuss the iteration cost of all related methods.' This action is concrete, as it directly points to a specific aspect of the method and suggests a direct action. While it doesn't provide specific details on *how* to discuss the cost, it clearly identifies the area for improvement. Therefore, it is actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'the iteration cost (computational budge) of the proposed method' and 'the iteration cost of all related methods'. This directly identifies the specific part of the paper being addressed, making the grounding fully grounded. Furthermore, the comment specifies what needs to be addressed: 'discuss' the iteration cost. The comment also clearly identifies the scope: 'proposed method' and 'related methods'. Therefore, the grounding is fully specific.", "verifiability_rationale": "The comment contains a claim: 'The authors should discuss the iteration cost (computational budge) of the proposed method. It will be great if the authors discuss the iteration cost of all related methods.' This claim is supported by logical reasoning, as it suggests a relevant analysis for the method. While it doesn't provide external references, the suggestion itself is a logical point for improvement. Therefore, the claim is 3 as it is logically supported but lacks external references.", "helpfulness_rationale": "The review point directly points out a missing element in the authors' work \u2013 the discussion of iteration cost. It provides a clear suggestion for improvement by stating that this discussion should be included for the proposed method and all related methods. This is a constructive suggestion that guides the authors on what to add to their paper. While it doesn't critique the authors' work, it offers a concrete direction for improvement, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit suggestions for the authors to report average results over multiple runs, discuss decision boundaries in Sec. 3.1, and identify information in specific subfigures of Fig. 9 in Sec. 3.3. These are all direct instructions on what actions the authors should take to improve their work. The actions are clear and specific.", "grounding_specificity_rationale": "The review point explicitly mentions 'Sec. 3.1' and 'Fig. 9 middle and right' in Sec. 3.3, directly pointing to specific sections and figures within the paper. This allows the authors to directly locate the relevant information and understand the context of the suggestions.", "verifiability_rationale": "The review point makes claims that can be verified logically. For example, the suggestion to report averages is based on standard experimental practices. The observation about results being close together is a logical deduction from the presented data. The suggestion to discuss decision boundaries in Sec. 3.1 is based on the nature of toy datasets and the goal of understanding model behavior. The request for information in Fig. 9 is a logical next step for the authors to take.", "helpfulness_rationale": "The review point is very helpful as it directly addresses potential weaknesses or areas for improvement in the authors' work. The suggestions are clear, actionable, and logically derived from the context of the paper. The authors are guided on what to add, what to discuss, and what to explore in their results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the limitation: 'The new proposed model can be used only with a small number of dimensions because of the curse of dimensionality imposed by the core tensor C.' This is an explicit statement of a constraint. Furthermore, the reason for this limitation is clearly stated as 'because of the curse of dimensionality imposed by the core tensor C', providing a concrete explanation of why this limitation occurs. The authors know exactly what the limitation is and how to apply this information.", "grounding_specificity_rationale": "The review point explicitly mentions 'the core tensor C' as the specific part of the model being addressed. This is a literal mention of a specific element within the model. While the reviewer does not explicitly state the *function* of the core tensor C, the mention itself grounds the comment to a specific part of the paper. The comment is not vague in identifying the referenced part.", "verifiability_rationale": "The review point contains a claim: 'The new proposed model can be used only with a small number of dimensions'. This claim is supported by the reasoning: 'because of the curse of dimensionality imposed by the core tensor C'. While a citation might be ideal to back up the 'curse of dimensionality', the reasoning provided is a generally accepted concept in machine learning and data analysis. The claim is supported by a logical explanation.", "helpfulness_rationale": "The review point is helpful because it identifies a clear limitation of the proposed model: its restriction to a small number of dimensions due to the curse of dimensionality. This information is valuable for the authors to understand the practical constraints of their model and potentially explore alternative approaches or modifications. The reviewer provides a specific reason for this limitation, making it actionable for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a potential issue ('may lead to negative transfer') and provides a specific example ('TransformerM performs poorly...'). It also suggests a possible explanation ('contradictory to the description...'). This suggests an explicit action: the authors should investigate if pretraining on the homolumo gap is negatively impacting their model's performance on other tasks. The action is also concrete as it points to investigating the performance on specific tasks.", "grounding_specificity_rationale": "The review point explicitly mentions the 'generalpurpose neural network model' and focuses on the potential issue arising from 'supervised pretraining based on the prediction of homolumo gap'. It also specifies the 'downstream experiments' and mentions 'TransformerM' and the 'QM9 dataset' as examples. This strong mention of specific elements indicates good grounding.", "verifiability_rationale": "The review point makes a claim ('Supervised pretraining...may lead to negative transfer') but does not provide any evidence or citations to support this claim. It presents it as a potential issue based on an example. Therefore, it is not 5. It also does not consist solely of factual statements that require no verification.", "helpfulness_rationale": "The review point identifies a potential problem ('may lead to negative transfer') and suggests a direction for investigation (' TransformerM performs poorly...'). It also offers a possible explanation ('contradictory to the description...'). While it doesn't provide a complete solution, it points to a likely area where the authors might be facing issues and suggests a potential cause. Therefore, it is 3 in guiding the authors to investigate their model's performance on other tasks."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer correctly points out that the authors state on lines 8082 that the center correlation was not insightful for discriminating model defenses. However, the same authors then use this metric in Figure 4 A&B. This implies an implicit action or suggestion: the authors are drawing attention to the fact that the center correlation *is* insightful in this specific context, despite their initial statement. The action is implicit because the authors don't explicitly state *why* the metric was chosen for Figure 4 after stating it's not insightful elsewhere. The suggestion is that the reader should pay attention to the use of the center correlation in Figure 4. The lack of explicit connection makes the action somewhat vague on how to apply it.", "grounding_specificity_rationale": "The reviewer's question highlights a lack of grounding specificity. The authors state on lines 8082 that the center correlation was 'not insightful for discriminating model defenses.' This statement is 1 because the authors do not explicitly identify the specific part of their work they are referring to. They could have said, for example, 'Not insightful for discriminating model defenses in our experiments' or 'Not insightful for discriminating model defenses as shown in section 3.2.' The statement is general and doesn't pinpoint the exact context. Furthermore, the reviewer's question about the usefulness of the metric in Figure 4 A&B is not clearly specified within the statement. The statement only addresses the lack of insight *elsewhere*, not *here* in Figure 4. The lack of specificity makes it difficult to understand what exactly is being claimed and how it relates to the figure.", "verifiability_rationale": "The reviewer's question about the authors' statement on lines 8082 and its use in Figure 4 raises concerns about verifiability. The authors make a claim: 'the center correlation was not insightful for discriminating model defenses.' This is a claim because it expresses an opinion or judgment about the metric's usefulness. However, the paper does not provide sufficient justification for this claim. There is no logical reasoning, common knowledge, or external references to support why the center correlation would be considered unhelpful for this purpose. The lack of justification makes the claim somewhat underjustified. The reviewer's subsequent question about the usefulness of the metric in Figure 4 further highlights the lack of verifiability, as the paper doesn't explicitly connect the initial statement to the visual representation in the figure.", "helpfulness_rationale": "The reviewer's question about the authors' statement on lines 8082 and its use in Figure 4 makes the review point 3. It forces the authors to clarify their reasoning and provide justification for their use of the center correlation. This interaction has the potential to improve the clarity and consistency of the paper. However, the review point itself doesn't directly provide actionable feedback to the authors on what to do. It points out a potential lack of clarity, which is helpful but not a direct prescription for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states an opinion ('not particularly strong') but lacks explicit instructions on how to improve the contribution. It references characteristics of the contribution ('weak,' 'unpractical') but doesn't specify how to make it better. While it identifies a problem, it doesn't tell the authors what to do about it.", "grounding_specificity_rationale": "The reviewer mentions the 'theoretical contribution' generally. While they identify a specific area ('theoretical contribution'), the issue ('weakness') is not detailed enough to be fully specific. The reviewer doesn't pinpoint a specific section, table, figure, or unique element of the paper related to this weakness.", "verifiability_rationale": "The review point contains a claim ('the theoretical contribution is not particularly strong') and provides reasoning and implicit references to support it. The reviewer explains why they believe the contribution is weak and unpractical, referencing 'weak, unpractical bound' and 'the proof...does not provide particular mathematical novelty.' This constitutes a claim being made and is supported by reasoning and implicit references to the nature of the contribution.", "helpfulness_rationale": "The review point is critical and constructive, pointing out specific shortcomings of the theoretical contribution. While it doesn't offer direct, actionable steps, it identifies a significant weakness and encourages the authors to reflect on the practical implications and mathematical rigor of their contribution. This type of feedback is generally helpful for guiding further development."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states weaknesses and suggests improvements, directly addressing the 'picking' step and the CIFAR experiments. The suggestions are clear and point towards specific actions the authors should take, such as adding an ablation for the picking step and using more baselines. While the suggestions are present, they are somewhat highlevel and could be more concrete in terms of specific implementation details. The reviewer also points out a potential methodological flaw, which, while not an action, highlights a lack of clarity.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'picking' step and states that it is not ablated. They also mention the CIFAR experiments and the limited baselines used. The reviewer points out that the comparison on CIFAR is not convincing and specifically mentions that only one approach (DEN) is compared. The reviewer also states that it is unclear if DEN is correctly used/evaluated. In each case, the reviewer identifies the specific aspect of the paper being addressed and states what is missing or unclear. Therefore, the grounding is explicit and specific.", "verifiability_rationale": "The review point does not contain any claims that require verification or justification. It is a critique of the paper's content and experimental setup. Therefore, it does not meet the criteria for verifiability, which involves supporting a claim with logical reasoning, common knowledge, or external references. The reviewer is stating observations and suggestions, not making assertions that need to be proven.", "helpfulness_rationale": "The review point provides several concrete suggestions for the authors to improve their draft. The reviewer suggests adding an ablation for the 'picking' step, comparing against more baselines in the continual learning literature, and ensuring the correct implementation of the baseline (DEN). These suggestions are actionable and directly address the identified weaknesses. The reviewer also points out a potential methodological flaw ('unclear if DEN is correctly used/evaluated'), which is valuable feedback for the authors to consider. The suggestions are clear and specific, making them 5 for the authors to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests removing the 45degree line and adding a thin gray diagonal line to the plot. This is a clear, direct action with no ambiguity about what needs to be changed. The suggestion is concrete, specifying the *type* of line and its *general* location (above/below diagonal).", "grounding_specificity_rationale": "The reviewer refers to the visual element of the plot and the specific annotation ('above/below diagonal'). While they don't explicitly name a section or table, the context strongly implies a specific part of the plot. The reviewer also clearly specifies what should be added ('a thin gray diagonal').", "verifiability_rationale": "The reviewer is making a claim that the current annotation ('above/below diagonal') is less effective than adding a thin gray diagonal line for interpretability. This claim is supported by the reviewer's observation that the diagonal line is less intuitive than the anglebased approach. While there's no external reference, the reasoning is based on a practical, visual assessment, making it 3.", "helpfulness_rationale": "The reviewer is directly addressing a potential point of confusion for the author (the 45degree line) and offering a clear alternative. This is a direct and actionable suggestion that is likely to be helpful for improving the plot's clarity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the lines (240 and 428) where the word 'sufficient' is used and provides a concrete interpretation of what the authors likely meant by 'optimistic hoped for rewards'. This makes the action clear and specific.", "grounding_specificity_rationale": "The comment explicitly mentions the specific lines (240 and 428) being discussed, achieving literal mention and thus full grounding. It also specifies the likely intended meaning of 'sufficient' in the context of optimistic rewards, adding to the specificity.", "verifiability_rationale": "The comment contains a claim about the likely intended use of 'sufficient' but does not provide any supporting evidence or justification for this claim. It's a statement without logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The comment identifies a potential point of confusion in the authors' writing regarding the use of 'sufficient' and offers a plausible alternative interpretation. While it doesn't provide a direct solution, it encourages the authors to clarify their intended meaning, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is presented as a question, which is a direct and explicit way of pointing out a potential issue. The request for clarification about groundtruth building and the prediction mechanism is clear and actionable. Therefore, it is 5.", "grounding_specificity_rationale": "The reviewer is asking *how* the groundtruths are built. This requires understanding the data processing and labeling steps. While not explicitly stated in the review point, we can infer that the reviewer is looking for a connection between the model's output and the ground truth data. The reviewer *cannot* confidently determine how the groundtruths are built from the information given in the review point. They need to refer to the paper's data section. However, the reviewer is asking *specific* questions about the groundtruth building process and the network's prediction mechanism. These are quite specific.", "verifiability_rationale": "The reviewer is asking *how* the groundtruths are built and *how* the network can predict all keypoints. These are questions that ideally would be answered by referring to the paper's methodology and implementation details (specifically the data section and the network architecture description). The reviewer is not making a claim that something is *incorrect* but rather asking for clarification on how something works. Therefore, it's not strictly 'verifiable' in the sense of identifying a flaw, but it's a request for information that should be available in the paper.", "helpfulness_rationale": "The reviewer is pointing out a potential ambiguity or lack of clarity in the paper's description. If the paper is unclear about how groundtruths are built and how the network handles multiple keypoints per part, this can hinder understanding and reproducibility. Therefore, it has the potential to be helpful if the authors clarify these points."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the desired changes (larger font size) and points to specific elements (legends, axis labels, figure captions). While the reviewer doesn't suggest *how* to make these changes (e.g., through a command, a specific tool), the action is clear and the location is specific.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"legends and axis labels\" and \"figure captions,\" which are specific parts of the paper. The reviewer also specifies the *what* (font size) and the *where* (specific elements). They also point out the *confusion* between proposition numbers and equation numbers, adding detail.", "verifiability_rationale": "The reviewer is making a statement about the formatting of text elements in a figure. This is a factual observation about the presentation of the figure. While there isn't a citation or external reference, the claim is likely true based on common knowledge of figure formatting. The reviewer is also pointing out a *conflict* between the formatting of proposition numbers and equation numbers, which is a valid observation.", "helpfulness_rationale": "The reviewer points out a specific formatting issue that is likely to affect the readability of the paper. While the *how* of fixing it isn't specified, the reviewer provides a clear *what*. Authors would likely find this helpful in improving the presentation of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their suggestion to compare against Journey TRAK and provides a specific reason (the difference in effect size shown in 1, Figure 2). The action 'suggest a comparison' is direct and the reviewer identifies the specific parts of their work (counterfactual experiments) and the method (Journey TRAK) to compare against. The reviewer also specifies the *reason* for this comparison, linking it to a published finding, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'counterfactual experiments' and 'Journey TRAK' when stating their suggestion. They also provide a specific reason for the comparison by referencing 'Journey TRAK used at a particular step of the the sampling trajectory' and 'a much larger effect of removing highscoring images according to Journey TRAK, in comparison with CLIP cosine similarity' from 1, Figure 2. This demonstrates a clear understanding of the specific parts of the paper being addressed and the specific suggestion being made.", "verifiability_rationale": "The reviewer makes a claim by suggesting a specific comparison in their counterfactual experiments. This claim is supported by referencing a specific paper (Journey TRAK) and a specific figure (1, Figure 2) within that paper. The reviewer provides a clear justification for why this comparison is relevant, linking it to the observed difference in effect size between Journey TRAK and CLIP cosine similarity. The evidence provided is logical and directly supports the reviewer's suggestion.", "helpfulness_rationale": "The reviewer's suggestion is directly relevant to improving the reader's understanding of their counterfactual experiments. By suggesting a comparison against Journey TRAK, they are addressing a potential weakness in the reader's analysis (the difference in effect size) and providing a concrete improvement. The reviewer also provides a specific reason for the suggestion, linking it to a published finding, making the feedback actionable and valuable for the reader's work."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue with the placement of adaptive convolutions based on experimental results and suggests further analysis. While they don't explicitly state what action to take, they highlight a missing discussion in the original paper. The reviewer implies that the placement is important but doesn't provide concrete guidance on how to determine the optimal placement. The lack of explicit instructions makes this point 1.", "grounding_specificity_rationale": "The reviewer mentions 'adaptive convolutions' generally and refers to specific models (ACNNv3 and ACNNv2) in their analysis. While they identify a specific aspect (placement of adaptive convolutions), they don't explicitly pinpoint the exact section, table, or figure where this placement is discussed in the original paper. The mention of specific models is helpful, but the general reference to 'adaptive convolutions' makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer makes a claim based on their interpretation of the experimental results (Table 3) and the lack of discussion about the placement of adaptive convolutions in the original paper. They state that 'it seems that replacing normal convolutions with adaptive convolutions in not always a good' and that 'there is no analysis or comments on this aspect of the technique.' However, they do not provide any external references or logical reasoning to support this claim within the review point itself. The claim is based on their interpretation and observation, lacking sufficient evidence or justification.", "helpfulness_rationale": "The reviewer's point is valuable because it highlights a potential flaw in the experimental design or analysis of the adaptive convolution technique. They draw attention to the discrepancy between the experimental results and the lack of analysis in the original paper. While they don't explicitly state what action to take, their point encourages the authors to consider the placement of adaptive convolutions more carefully. The point is clear and directly relates to the experimental results, making it 3 in identifying a potential area for improvement in the original work."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a difference between the proposed method and another method (10) regarding the information content of their outputs. While the reviewer explicitly states this difference ('This means that the output of ACI has less information compared to the output of 10 that has a richer search space, i.e., DAGs.'), they do not provide an explicit action or suggestion on how to address this difference or what the implications are for the proposed method. The reviewer is stating a fact about the methods, but not providing a direct instruction on how to improve the proposed method based on this observation.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed method' and '10' by name. While they mention the outputs of these methods (ancestral graphs and DAGs), they do not explicitly point to a specific section, table, or figure in their own paper where these concepts are discussed or relevant. The grounding is implied rather than explicitly stated.", "verifiability_rationale": "The reviewer makes a claim about the information content of the outputs of two different methods. They state: 'This means that the output of ACI has less information compared to the output of 10 that has a richer search space, i.e., DAGs.' This claim can be verified by understanding the relationship between ancestral graphs and DAGs. Ancestral graphs are a coarsened representation of DAGs, and therefore, they contain less information about the causal structure. The reviewer provides a logical reasoning to support their claim.", "helpfulness_rationale": "The reviewer raises a valid point about the information loss when using ancestral graphs instead of DAGs. This is a constructive criticism that highlights a potential limitation of the proposed method. While the reviewer doesn't offer a direct solution or specific improvement, the point itself is valuable for discussion and further investigation. The reviewer identifies a weakness in the method's output."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer clearly states that the method simply discards TF bins with magnitude less than epsilon. This is a direct and actionable criticism of the method's implementation. The reviewer provides a specific action: 'I wouldn't call it a VAD, you are simply discarding TF bins with zero magnitude that will result in a division by zero.' This action is directly tied to the described method.", "grounding_specificity_rationale": "The reviewer provides a very specific description of the method being criticized: 'Your VAD description is puzzling. What is stated in the paper simply discards any TF bins that have a magnitude of less than epsilon.' This specific detail about the TF bins and the magnitude threshold demonstrates a clear grounding of the issue.", "verifiability_rationale": "The reviewer's explanation is logically sound and based on common knowledge within the field of audio signal processing. They connect the described method to the typical understanding of VAD (operating on time, detecting speech presence) and the more common implementation of thresholding. While they don't provide external references, the reasoning is clear and verifiable.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential misunderstanding or misinterpretation of the paper's VAD implementation. By clarifying the actual operation, they are providing valuable feedback that can help the authors better understand and potentially improve their own work. This is a significant contribution to the authors' understanding and the paper's clarity."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point asks a question about the motivation for timevarying parameters, which implicitly suggests a discussion. However, it does not explicitly state what the author should do with this information or how to implement it. The request is a suggestion, not a direct action.", "grounding_specificity_rationale": "The review point asks about the motivation for timevarying Q and S, which are parameters discussed in Section 4.2. While the topic is related to a specific section, the review point does not explicitly identify the section, table, or figure where these parameters are discussed or how they are used. The grounding is implied but not explicitly stated.", "verifiability_rationale": "The review point is a question asking for information about the motivation for timevarying parameters and their implications. It does not make a claim or assertion that requires verification. It is a request for clarification rather than a statement of fact or opinion.", "helpfulness_rationale": "The review point asks a question that, if answered, could provide valuable information for the author regarding the motivation for timevarying parameters and their impact on model volatility and predictive intervals. While it doesn't provide a direct solution, it encourages the author to consider a relevant aspect of their work and think critically about their model. The question itself can be considered a form of actionable feedback, prompting further analysis."}
{"actionability_label": "1", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not contain a proposal for action. The reviewer is asking a question about the technical details of different regression methods, not suggesting how to improve the draft based on this information. Therefore, it lacks explicit action or suggestion on how to apply the information.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or method being discussed. It is a general question about the difference between two regression techniques used in object detection. Therefore, it lacks grounding in a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The review point does not contain a claim. It is a question asking for clarification and explanation rather than making a statement that requires verification. Therefore, it does not have a claim that needs to be supported or verified.", "helpfulness_rationale": "The review point is a question about the technical details of different regression methods used in object detection. While it highlights a potential area for clarification in the paper, it does not provide actionable feedback or suggestions on how to improve the draft based on this information. The reviewer is asking 'why' and 'how' rather than 'what to do'. Therefore, it is not directly helpful in improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out that the paper is 'not particularly easy to follow' and that the 'presentation lacks a clear intuition for how the pieces fit together'. While this identifies a problem, it doesn't explicitly state what needs to be done to improve the flow or clarity. The reviewer doesn't provide specific actions or modifications the authors should apply. Therefore, while the issue is relevant, the specific action isn't clearly defined.", "grounding_specificity_rationale": "The reviewer refers to the 'paper', 'intuition', and 'pieces fit together'. While broad, they do identify a specific part of the paper and a specific aspect of it \u2013 the overall presentation and the connections between the different components. The authors can infer that the reviewer is pointing to the explanation of the method and how the different parts relate. Although not as precise as pointing to a specific table or figure, it's more specific than saying 'the paper needs improvement'.", "verifiability_rationale": "The reviewer makes a claim that the paper is 'not particularly easy to follow' and that the 'presentation lacks a clear intuition'. However, they do not provide any evidence, examples, or logical reasoning to support this claim. There are no references to external works or common knowledge used to back up this assertion. The reviewer simply states the problem without explaining why it's a problem or how it should be addressed. Therefore, the claim is not supported by any verifiable information.", "helpfulness_rationale": "The reviewer's comment identifies a problem with the paper's presentation but does not offer any specific suggestions or guidance on how to improve it. While they point out that the paper is 'not particularly easy to follow' and lacks 'a clear intuition', they don't provide concrete steps the authors should take to address this. The authors still need to figure out what to do based on this feedback. Therefore, the review point is not actionable or informative enough to be 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a potential benefit ('may improve the performance of the teacher network') and suggests a method to address it ('Is the comparison fair? Please provide KID/FID metrics of your teacher network'). While the action is clear, the underlying issue of unfair comparison isn't fully elaborated, making it 3.", "grounding_specificity_rationale": "The comment explicitly mentions 'simultaneous training' and 'teacher network', allowing for precise identification of the networks being discussed. However, it doesn't specify *why* the comparison might be unfair or what aspects of the training are causing the potential benefit. The request for KID/FID metrics focuses on the teacher network, adding a specific element to the grounding, but the initial grounding of the networks themselves is clear. Therefore, it can be considered weakly grounded with some specificity.", "verifiability_rationale": "The comment contains a claim ('simultaneous training may improve the performance of the teacher network') and offers a suggestion to verify it ('Please provide KID/FID metrics of your teacher network'). The verifiability is conditional on the request being helpful and the metrics being provided. The claim itself is somewhat vague ('may improve'), and the verifiability is dependent on external factors. Therefore, it can be considered 3.", "helpfulness_rationale": "The comment raises a valid concern about the fairness of a comparison and offers a concrete suggestion (providing KID/FID metrics) to address it. While the request itself might not be inherently helpful without the metrics, the intention to provide information and potentially improve the comparison process is a valid and helpful feedback point. The uncertainty about the fairness adds value to the helpfulness score."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their point about the scaling factor and provides a clear suggestion for improvement. This is a direct and actionable comment, providing a concrete example of a potential issue and proposing a specific change. The reviewer identifies the action of questioning the scaling and the action of suggesting a scaling variable.", "grounding_specificity_rationale": "The reviewer directly references 'line 157' and provides the mathematical formula for the refined region vector. This is a very specific and grounded comment, clearly identifying the section and the formula being discussed. The reviewer accurately pinpoints the relevant part of the paper.", "verifiability_rationale": "The reviewer provides a clear explanation of why they are questioning the scaling factor (limited to a factor of 2) and offers a specific alternative (a scaling variable). This is a welljustified and verifiable comment. The reviewer logically explains the implication of the current scaling and provides a concrete suggestion for improvement, supported by the understanding of attention weights.", "helpfulness_rationale": "The reviewer raises a valid point about the potential limitation of the scaling factor and suggests a reasonable improvement. This is a helpful comment as it identifies a potential area for enhancement and provides a clear direction for the authors to consider. While the suggestion is relatively simple, it directly addresses a potential weakness."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'Failures on the ALFRED benchmark often occurred due to goal misspecification' which is an explicit action or suggestion that authors should aim to improve. However, it does not provide specific details on how to achieve this improvement, such as whether the natural language description of the goal needs to be revised or if the formal goal predicate is incorrect. The action is stated, but the implementation is left vague.", "grounding_specificity_rationale": "The review point mentions 'ALFRED benchmark' which can be considered a ground, as it is a specific element of the paper. However, it does not specify which part of the ALFRED benchmark or the goal is misspecified. It identifies the *cause* (goal misspecification) but not the *specific* instance of misspecification within the ALFRED framework. The grounding is present but not fully specific.", "verifiability_rationale": "The review point makes a claim: 'Failures on the ALFRED benchmark often occurred due to goal misspecification.' This is a claim that needs to be verified. However, the review point does not provide any specific evidence, examples, or logical reasoning to support this claim. It simply states an observation. There are no external references or detailed explanations provided to justify the claim.", "helpfulness_rationale": "The review point identifies a problem ('Failures on the ALFRED benchmark often occurred due to goal misspecification') that is actionable for the authors. It suggests that addressing this misspecification could improve performance on the ALFRED benchmark. However, the point is somewhat vague and lacks specific details on how to identify and correct the misspecification. It doesn't provide concrete steps or examples for the authors to follow, making it less immediately helpful for largescale improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer offers suggestions and raises a concern. While the suggestion to analyze disparity distributions could be considered an explicit action, the raising of the concern itself is more of a question or observation rather than a direct instruction on how to improve the method. The lack of a clear, stepbystep action makes it less actionable.", "grounding_specificity_rationale": "The reviewer mentions 'iterative optimization schemes similar to IGEV' and 'SamplingGaussian'. While these terms are mentioned, the reviewer does not explicitly state which part of the paper these concepts are relevant to, nor does the reviewer provide a clear explanation of their connection to the reviewed method. The mention is present, but the explanation is missing, indicating weak grounding.", "verifiability_rationale": "The reviewer states that the improvement over SOTA methods is 'small' and raises a concern about the difficulty of improvement for iterative frameworks similar to IGEV. These statements can be considered claims. However, the reviewer does not provide any specific evidence or reasoning to support these claims within the review point itself. The claims are presented without sufficient justification or references, making them 1 based on the information provided in the review point.", "helpfulness_rationale": "The reviewer suggests analyzing disparity distributions and raises a concern about the potential limitations of SamplingGaussian for similar iterative frameworks. These are suggestions and a concern, which generally fall under the scope of helpful feedback. While the suggestions are relevant, the lack of specific evidence or detailed reasoning to support the concern makes the overall feedback somewhat limited in its helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests investigating specific models (GPT4o vs. InternVL2) and presenting differences in false positive rates (FPR). These are concrete actions with clear implications for the authors. The reviewer proposes specific model instances and a specific metric (FPR) for analysis, which are direct actions the authors can take. However, the reviewer does not explicitly state how to *calculate* or *interpret* the FPR differences, making the action somewhat implicit.", "grounding_specificity_rationale": "The review point explicitly mentions 'specific models (e.g., GPT4o vs. InternVL2)' and 'false positive rates (FPR)'. The use of 'e.g.' suggests the reviewer is providing examples, indicating a lack of precise grounding. While the *concept* of investigating specific models and FPR is mentioned, the reviewer doesn't pinpoint the exact section, table, or figure where these models are discussed or the specific FPR values to be presented. The grounding is weak because the authors need to infer the specific parts of the paper related to these models and FPR.", "verifiability_rationale": "The review point suggests investigating specific models and presenting FPR differences. While it doesn't explicitly claim to be *verifiable* in a strict academic sense (e.g., by citing a specific paper), it provides a clear direction for the authors to follow. The reviewer is suggesting a *type* of analysis to perform. The 'how' of this analysis isn't detailed, but the 'what' is clear. The suggestion is not a call for a new experiment but rather a request for a specific type of data presentation. Therefore, it leans towards being 3 as it points towards a specific area of investigation, but lacks the depth of a full literature review or a novel methodological contribution.", "helpfulness_rationale": "The review point offers concrete suggestions for the authors to explore specific models and analyze false positive rates. These suggestions directly address the idea of adding nuance to the conclusions and improving comparisons. By focusing on specific models, the reviewer is suggesting a more detailed and potentially impactful analysis than the current generic findings. The suggestions are actionable and provide a clear direction for the authors to improve their work. While more specific guidance could be provided, the suggestions are still valuable and likely to be helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the action of clarifying the nature of Fourier modes (\"Perhaps clarify if these are reals or complex\"). This makes the action clear and direct. The suggestion is also concrete, specifying the ambiguity as being whether they are real or complex numbers.", "grounding_specificity_rationale": "The comment explicitly refers to \"Fourier modes\" as the part of the paper being addressed. While it doesn't name a specific section or table, it clearly identifies a unique concept within the text. The comment also specifies what needs clarification (whether they are real or complex).", "verifiability_rationale": "The comment itself does not contain a claim that requires verification. It is a suggestion for clarification. Therefore, it does not fit the criteria for verifiability. While the need for clarification can be seen as an implicit request, the review point itself doesn't present a verifiable statement.", "helpfulness_rationale": "The comment directly addresses a potential point of confusion for the authors (the nature of Fourier modes). It provides a clear direction for clarification, which is a valuable piece of feedback. While it doesn't offer a definitive answer, it prompts the authors to consider a specific detail that could impact their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the contribution of different components to the performance gain. While the question itself is direct, it could be made more actionable by specifying the exact components and metrics being compared. The reviewer is implicitly suggesting that the paper should clarify this aspect, but the suggestion lacks concrete details.", "grounding_specificity_rationale": "The reviewer is asking for clarification on a key aspect of the paper (the contribution of task formulation vs. pretrained models). While they don't explicitly state which section or table this refers to, the context suggests it relates to the results. The reviewer is also asking for a *justification* of the results, which is a specific aspect. Therefore, the grounding is weak as the exact location isn't pinpointed, but the specificity is high as the reviewer is asking for a justification of a key finding.", "verifiability_rationale": "The reviewer is not making a claim that needs verification. They are asking for clarification on a point that is already presented in the paper. There is X being made, logical reasoning, or external references required to understand the point. The request is a demand for more information, not an assertion that needs validation.", "helpfulness_rationale": "The reviewer is asking a question about a crucial aspect of the paper. While the question itself isn't a direct solution, it points to a significant area where the authors might need more clarity. By highlighting this, the reviewer is directing the authors' attention to a potential weakness in the paper's presentation and encouraging them to seek further explanation. This is 3 in identifying a need for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the axes of Figure 1 are unclear. This is a direct and actionable suggestion for the authors to understand the data presented in the figure. The action is not vague as it directly points to a specific element of the paper.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1', which is a specific part of the paper. The authors can directly identify the figure being referred to. The specificity is high as the comment clearly identifies what needs clarification.", "verifiability_rationale": "The comment identifies a problem ('It is hard to understand') but does not provide any justification or explanation for why the axes are unclear. There is no external reference or logical reasoning provided to support the claim. While it implies a need for clarification, it doesn't guide the authors on how to achieve that. Therefore, it is 1 as it lacks sufficient evidence or justification.", "helpfulness_rationale": "The comment identifies a genuine issue \u2013 the lack of clarity around Figure 1's axes. This is a valid concern for the authors as it hinders their understanding of the data. While the comment doesn't explicitly tell them how to fix it, it points to a crucial area of improvement. Therefore, it is 3 in highlighting a necessary step for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly suggests an action: 'run experiments on ImageNet'. This is a direct instruction for the authors to modify their experimental setup. The suggestion is clear and actionable, indicating a direct path to improvement.", "grounding_specificity_rationale": "The review point does not specify which part of the paper or method is being improved by using ImageNet. The suggestion is general and does not point to a specific section, table, figure, or unique aspect of the paper. The mention of 'more convincing of the proposed method' is a judgment about the overall results, not a specific critique of a written element.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for future work, proposing a potential experiment (ImageNet) as a way to strengthen the results. There is no logical reasoning, common knowledge, or external references being presented as evidence for *why* this suggestion is valid or beneficial.", "helpfulness_rationale": "The review point offers a suggestion for improvement by proposing additional experiments on ImageNet. This could be helpful for the authors as it provides a concrete direction for future research and potentially strengthens the evaluation of their proposed method. While it doesn't directly identify a flaw in their current work, it offers a valuable suggestion for enhancing it."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing element '2 Direct runtime comparisons with existing methods' and provides a reason for its absence ('The proposed approach is based on implicit differentiation which usually requires additional computational costs'). This clearly indicates an actionable item for the authors: to conduct these runtime comparisons.", "grounding_specificity_rationale": "The review point refers to 'direct runtime comparisons' but does not explicitly identify which specific comparisons are needed. While the reason for their absence is given ('The proposed approach is based on implicit differentiation which usually requires additional computational costs'), the specific comparisons are not detailed. This makes the grounding somewhat weak as the authors need to infer which comparisons are necessary.", "verifiability_rationale": "The review point makes two claims: '2 Direct runtime comparisons with existing methods are missing' and 'The proposed approach is based on implicit differentiation which usually requires additional computational costs.' Both claims are supported by direct statements within the review point itself.", "helpfulness_rationale": "The review point is 5 as it identifies a significant omission in the authors' evaluation: the lack of direct runtime comparisons. This is a crucial piece of information for assessing the practical applicability of the proposed method and encourages the authors to perform this analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer states \"I cannot see any technical contribution.\" While this is an explicit statement about what the authors should do, it lacks specific details on *what* the technical contribution is missing. The action is implied (improve the draft), but the specifics are missing, making it somewhat vague. Therefore, it's not fully actionable but leans towards being explicit.", "grounding_specificity_rationale": "The reviewer mentions \"metalearning\" and \"federated learning\" and states \"I cannot see any technical contribution.\" This clearly identifies the specific part of the paper being addressed (the framework combining these two learning paradigms) and specifies the issue (lack of technical contribution). Therefore, the grounding is explicit and the specificity is clear.", "verifiability_rationale": "The reviewer makes a claim: \"I cannot see any technical contribution.\" However, they do not provide any evidence, reasoning, or references to support this claim. The statement is presented as an opinion without any logical backing or external references. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer points out a potential weakness in the proposed framework (lack of technical contribution) but does not offer any suggestions or guidance on how to address this weakness. The review is critical but lacks constructive feedback. Therefore, it is not particularly helpful for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "2", "actionability_rationale": "The reviewer criticizes the lack of actionable insights, focusing on the absence of concrete steps or solutions to improve model robustness based on the observed connection between multimodal complementarity and robustness. While the reviewer identifies a valid area for improvement, the criticism itself doesn't provide explicit or implicit instructions on how to address this gap. The reviewer's statement about the lack of solutions makes the criticism somewhat vague and doesn't specify the 'how' of leveraging the connection.", "grounding_specificity_rationale": "The reviewer's criticism is not explicitly directed at a specific section or part of the paper. While the focus is on the 'connection between the complementary and the model robustness,' the reviewer doesn't pinpoint a particular section, table, or figure where this connection is discussed. The reviewer's statement is more general, referring to the overall findings or methodology related to this connection. Therefore, while the intent is related to a specific aspect, the criticism itself lacks precise grounding within the paper's structure.", "verifiability_rationale": "The reviewer makes a claim about the intuitiveness of the conclusion (higher complementarity > more delicate robustness under corruption). This claim is not supported by specific evidence, references, or logical reasoning within the review point itself. The reviewer expresses an opinion about the intuitiveness without providing any backing. Therefore, the claim is not fully supported by verifiable information.", "helpfulness_rationale": "The reviewer's concern about the lack of actionable insights is a valid and important point for improving the paper. However, the criticism itself is not constructive in terms of providing specific, actionable feedback. The reviewer points out a gap but doesn't offer any suggestions or directions on how to address it. The helpfulness of this point is limited because it identifies a problem without proposing a solution."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the comparison between focusing on 'best' clusters and analyzing differences in representation. It identifies the action of focusing on 'best' clusters and the absence of the action of analyzing differences. The comparison between these two actions is also explicitly stated.", "grounding_specificity_rationale": "The review point refers to 'clusters' and 'representation' generally. While it implies a specific focus on these aspects, it doesn't explicitly point to a specific section, table, figure, or unique element within the paper. However, it clearly specifies the *what* being compared ('clusters' and 'representation differences'). The reason for the comment ('seems an odd choice given the motivation of the paper') also specifies the *why*.", "verifiability_rationale": "The review point contains a claim: 'Focusing on which clusters are 'best' rather than what the differences in representation are between them, seems an odd choice given the motivation of the paper.' This claim is based on a subjective assessment of the 'oddness' of the approach. While the *what* (clusters and representation) is 3, the *why* (it seems odd) is dependent on external context and the paper's specific motivation, making it less verifiable.", "helpfulness_rationale": "The review point raises a valid concern about a methodological choice made in the paper. It points out a potential area for improvement or clarification. The feedback is specific to the *methodological choice* and *why it seems odd*, connecting it to the paper's motivation. This provides a clear direction for the authors to consider."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the incorrect caption ('Node Dynamics') and the correct caption ('Edge Dynamics'). This is a direct identification of the issue and a clear suggestion for improvement. The action is also concrete, specifying which figure and what change should be made.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 7' and specifies the type of dynamics that is incorrect ('Node Dynamics') and what it should be corrected to ('Edge Dynamics'). This demonstrates strong grounding as the specific part of the paper is identified, and the issue within that part is clearly defined.", "verifiability_rationale": "The reviewer points out that the caption is incorrect and suggests a specific correction. While the paper itself might not explicitly state that 'Node Dynamics' is wrong, the implication is clear: the caption says 'Node Dynamics' when it should be 'Edge Dynamics'. The reviewer's suggestion is a logical inference based on the identified issue.", "helpfulness_rationale": "The reviewer has identified a specific, actionable issue with a figure's caption and has proposed a concrete fix. This directly improves the clarity and accuracy of the paper's presentation of edge dynamics. While it doesn't address broader issues, it provides a clear and actionable improvement for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action the authors should take: 'discuss case studies and error studies'. This action is clear and specific, instructing the authors on what to include in their work. The reviewer also provides a specific example related to the paper's content, further clarifying the action.", "grounding_specificity_rationale": "The review point explicitly mentions 'case studies and error studies' and provides a specific example related to the paper's content, the Elementlevel Graph Pretraining section. This demonstrates strong grounding as the reviewer not only identifies the type of studies but also connects them to a relevant aspect of the paper. The reviewer also explains what these studies are intended to achieve, further enhancing the grounding.", "verifiability_rationale": "The review point contains a claim: 'It could be convincing to discuss case studies and error studies'. The reviewer provides reasoning for this claim by stating that these studies can 'highlight the effectiveness of each proposed component'. Furthermore, the reviewer offers a specific example, 'this paper mentions that the Elementlevel Graph Pretraining abandons the strategy of capturing the complex structure but focuses directly on the core elements. However, without case study, it is less convincing to figure it out. An example of case study can be found in \u201cGraph pretraining for AMR parsing and generation\u201d', which directly links the suggested studies to a specific aspect of the paper and provides a concrete example.", "helpfulness_rationale": "The review point is 5 as it directly suggests a concrete and beneficial improvement for the authors. The reviewer provides a clear rationale for why discussing case studies and error studies would be valuable, explaining that they can 'highlight the effectiveness of each proposed component' and 'identify failure modes'. The reviewer also provides a specific example related to the paper's content, further clarifying the benefit of the suggested approach. This makes the advice actionable and wellsupported."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the suggestion to consider explicitness (E) and size (S) as extra evaluations. However, the reviewer does not provide any concrete steps or details on how to implement this extra evaluation. The action is stated, but the means to achieve it are not specified.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'explicitness (E) and size (S)' as the factors they are considering. This clearly indicates that the authors can identify the specific part of the paper and the issue being addressed, thus achieving full grounding. The comment specifies what needs to be addressed in this part (the entanglement of DCI and ES with E and S).", "verifiability_rationale": "The reviewer's claim about the entanglement of DCI and ES, and the need for explicitness (E) and size (S) as extra evaluations, lacks sufficient justification. There is no logical reasoning, common knowledge, or external references provided to support this claim. The reviewer simply states the motivation without backing it up.", "helpfulness_rationale": "The reviewer's suggestion to consider explicitness (E) and size (S) as extra evaluations is presented without any supporting evidence or justification for its value. The comment does not explain why this is a beneficial addition or how it would be verified. Therefore, it does not provide any actionable feedback to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing information: 'the standard deviation after multiple experiments is not provided'. It also suggests a concrete action to improve the analysis: 'clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method'. This makes the review point both explicit and actionable.", "grounding_specificity_rationale": "The review point explicitly identifies the missing element in the experimental section: 'standard deviation after multiple experiments is not provided'. This is a clear and precise grounding of the issue. It also specifies what the missing information is intended to clarify: 'which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method'. This makes the grounding both explicit and specific.", "verifiability_rationale": "The review point contains a claim: 'The improvement brought by SoRA compared with the baseline is quite limited, which may be due to random fluctuations.' This claim is verifiable because it points to a specific area where further analysis (providing standard deviation) is needed. The suggestion to clarify effects within standard deviation fluctuations is a logical and verifiable step to address the identified issue.", "helpfulness_rationale": "The review point is 5 because it directly addresses a specific weakness in the experimental analysis (lack of standard deviation) and provides a clear and actionable suggestion for improvement ('clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method'). This directly empowers the authors to enhance their work."}
{"actionability_label": "4", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a list of specific issues with the paper's organization and formatting. For example, they mention the small font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the wrong format of the top two lines on page 6. These are all concrete actions the authors should take to improve their draft. The reviewer implies that the authors should fix these issues, making the feedback actionable.", "grounding_specificity_rationale": "The reviewer explicitly refers to specific parts of the paper when mentioning the issues. They use the names 'Figure 1' and 'Figure 2' and 'Table 2'. This clearly indicates that the reviewer can identify the specific sections being addressed, demonstrating strong grounding. Furthermore, they describe the issues within these specific sections, such as the small font size and incorrect placement, making the grounding very clear.", "verifiability_rationale": "The reviewer states that the paper is 'not well organized' and lists specific formatting issues. This constitutes a claim about the paper. While the reviewer doesn't provide explicit logical reasoning for *why* these are problems, the lack of organization and incorrect formatting are generally understood as valid criticisms in academic writing. The reviewer provides specific examples of problems within the mentioned sections (e.g., 'font size of some annotations of Figure1 and Figure 2 is relatively small', 'Table 2 is inserted wrongly inside of a paragraph'). This demonstrates that the claim is supported by specific observations, making it 3.", "helpfulness_rationale": "The reviewer identifies several concrete issues with the paper's organization and formatting. They specifically mention problems with figures (font size, explicitness), tables (placement), and formatting (top lines). These are all actionable suggestions that the authors can directly implement to improve their work. The reviewer's feedback is focused on observable flaws, making it highly valuable for the authors to address."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a concern: 'it would be important to think about whether they are practical and safe for querying in the real world.' This indicates an explicit action or suggestion, even if it's not immediately clear how to implement it. The reviewer points out a weakness in the paper.", "grounding_specificity_rationale": "The review point refers to 'the types of interventions included in the paper' without specifying a particular section, table, figure, or unique element. While it identifies a category of interventions, it doesn't pinpoint the exact part of the paper being addressed. Therefore, the grounding can be considered weak.", "verifiability_rationale": "The review point contains a claim: 'it would be important to think about whether they are practical and safe for querying in the real world.' However, it does not provide any evidence, reasoning, or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the concern about practicality and safety.", "helpfulness_rationale": "The review point raises a relevant concern about the practicality and safety of the interventions. However, it does not offer any specific suggestions or guidance on how to address this concern. The feedback is a statement of a problem without any proposed solutions or actions to take."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point presents two distinct requests for clarification. The first asks for clarification on the meaning of 'upper faces' of the convex hull and the explanation of 'dual subdivision and projection \u03c0'. The second asks for clarification on the variable 'p' in the context of decision boundaries of neural networks. While the authors have not taken any specific action to address these points, the reviewer has explicitly identified actions they would like to be taken. The lack of immediate action does not negate the potential actionability of the requests.", "grounding_specificity_rationale": "The review point explicitly refers to 'the upper faces of the convex hull' and 'dual subdivision and projection \u03c0', which are specific mathematical concepts. The reviewer also refers to 'decision boundaries of neural networks' and the variable 'p', which are specific elements within that context. The reviewer is pointing to specific parts of the paper and concepts within them, indicating strong grounding. While the definitions might be missing, the references are precise.", "verifiability_rationale": "The review point makes claims about the lack of clarity regarding 'upper faces' of the convex hull and the explanation of 'dual subdivision and projection \u03c0', and that the variable 'p' is not explicitly defined and is problematic. While the claims are present, the reviewer does not provide specific examples or references to support these claims. The lack of specific evidence makes the verifiability somewhat low.", "helpfulness_rationale": "The review point is helpful in that it directly points out potential areas of confusion and missing information for the authors. The reviewer is asking for clarification on specific terms and definitions, which is a valuable feedback for improving the paper. The requests are specific and directly address potential issues."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer states their opinion ('not convinced') about treating images and augmentations separately and suggests an alternative ('they can be interchangeable'). While the reviewer expresses a lack of conviction, the suggestion itself is clear and actionable. They are proposing a change to how images are handled. The reviewer explicitly states their intention to suggest a change, making it 3.", "grounding_specificity_rationale": "The reviewer refers to 'images and their augmentations' and suggests they can be 'interchangeable.' This is a specific part of the paper being addressed. They are not making a very general comment about the entire draft. The reviewer is also very specific about the nature of the alternative, which is interchangeability. This indicates a clear identification of the specific aspect being discussed.", "verifiability_rationale": "The reviewer presents a point about the treatment of images and augmentations, stating that they 'need to be treated separately' and suggesting they 'can be interchangeable.' While this presents a point that could be considered a claim (in the sense that it's a proposition for change), the reviewer does not provide any specific examples, citations, or logical reasoning to *support* this claim. The suggestion is presented as a possibility rather than a proven fact. Therefore, it is difficult to verify the claim based on the information provided.", "helpfulness_rationale": "The reviewer's point directly addresses a potential complexity in handling images and augmentations, suggesting a simplification. While the reviewer expresses a lack of conviction ('not convinced'), the suggestion itself is clear and actionable. The reviewer is directly pointing out a potential area for improvement. Even though the reviewer's conviction is low, the suggestion itself is valuable and directly addresses a specific aspect of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'It is unclear which component contributes to the performance gain' and 'Since the proposed approach follows detectionparsing paradigm, it is better to evaluate on baseline detection or parsing techniques sperately to better support the claim.' These are clear statements of action or question, making it explicit and concrete.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed method' and then breaks it down into 'generative shape model' and 'word parsing model'. While they don't point to a specific section or table, they clearly identify the components of the method being discussed, making the grounding somewhat explicit but not perfectly precise.", "verifiability_rationale": "The review point states a finding ('It is unclear...') and suggests a method to address it ('evaluate on baseline...'). This is a statement of observation that can be verified by evaluating on baselines, making it 3 as the suggestion provides a path to clarification.", "helpfulness_rationale": "The review point directly addresses a potential weakness in the paper (unclear contribution of components) and provides a concrete suggestion (evaluate on baselines). This directly targets the authors and offers a clear direction for improvement, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that 'Another issue of the paper is that the disentangling is done manually.' This is an explicit statement about a limitation. Furthermore, the reviewer *specifically identifies* the manual disentanglement as being the 'semantic segmentation network' and *why it's an issue* by asking 'Why is that? Why not something else? It would be interesting if the paper did not have this type of manual disentangling, and everything was learned.' This provides a concrete action the authors could consider.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'manual disentanglement' and then narrows it down to 'the semantic segmentation network' and its position in the pipeline as the 'first module'. This provides a very specific reference point within the paper, indicating strong grounding. The reviewer also asks a question directly about this specific element, highlighting its importance and the need for clarification or improvement.", "verifiability_rationale": "The reviewer does not make a claim that requires verification. Instead, they present a question about a design choice: 'Why is that? Why not something else? It would be interesting if the paper did not have this type of manual disentangling, and everything was learned.' This is a suggestion for improvement rather than a declarative statement that needs to be supported.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the methodology (manual disentanglement) and suggests an alternative approach (endtoend learning). This is a constructive suggestion that directly addresses a potential limitation, making it highly likely to be helpful for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of a clear connection between the theoretical analysis and the proposed method. While this is an explicit statement, the reviewer does not provide specific details on *how* the theory and method are not connected or *what* aspect of the method is lacking. The vagueness of the statement makes it less actionable than a highly specific suggestion.", "grounding_specificity_rationale": "The reviewer mentions 'theoretical analysis' and 'proposed method' but does not specify *which* part of the paper or method the connection is unclear or *which* specific detail of the selfattention mechanism is causing the confusion. The criticism is about the *lack of connection* being unclear, not a specific detail within either. This is weak grounding.", "verifiability_rationale": "The reviewer makes claims about the *lack of connection* and the *lack of explanation* for the method's benefits. These are claims that need to be verified. However, the reviewer does not provide specific examples or references to support these claims. The verifiability is low because the reviewer is making general statements about the lack of connection and explanation, rather than pointing to specific gaps in the paper or method.", "helpfulness_rationale": "The reviewer provides a clear criticism: a lack of connection between theory and method, and an unclear explanation of the method's benefits. This directly points to areas where the authors can improve their paper. While the criticism is somewhat general, it is still a concrete suggestion for the authors to strengthen the link between theory and practice. The reviewer is not asking for a retraction or a completely new idea, but rather a clarification and justification of the existing approach."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The comment directly asks a question about the method's behavior under a specific condition (without the Lipschitz Hessian assumption). This makes it explicitly pointing out a missing piece of information. However, it doesn't provide concrete steps or details on how the behavior differs or what implications arise.", "grounding_specificity_rationale": "The comment explicitly refers to 'the Lipschitz Hessian assumption' by name, making it fully grounded. It also asks about the method's behavior *without* this assumption, which is a specific aspect of the method's performance or theoretical properties.", "verifiability_rationale": "The comment itself does not contain a claim that requires verification. It's a question prompting for clarification or understanding. There is no logical reasoning, common knowledge, or external references provided to support any implicit assumptions or expectations.", "helpfulness_rationale": "The comment identifies a potential area for clarification regarding the method's behavior under a specific condition. However, it doesn't provide direct instructions or guidance on how the author should modify their draft based on this missing information. It's a request for more information rather than a direct suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states 'Some of the pieces are simply using existing methods' and 'the presentation of these methods are also vague (can only be understood after checking the original paper)'. While the reviewer identifies a problem, they don't explicitly state what needs to be done about it. The action of 'understanding' is implied but not directly stated as an action. The vagueness makes it difficult to act upon directly within the review point.", "grounding_specificity_rationale": "The reviewer mentions 'equation (12)' when critiquing the presentation of existing methods. This indicates that the reviewer can identify the specific part of the paper being addressed, making the grounding explicit. However, the reviewer also states that the presentation is 'vague (can only be understood after checking the original paper)'. This lack of specific details about the vagueness makes the action or suggestion underspecific.", "verifiability_rationale": "The reviewer states 'Some of the pieces are simply using existing methods' which can be considered a claim. However, the reviewer does not provide any specific examples, references, or logical reasoning to support this claim within the review point itself. The justification relies on the reader checking the original paper, which is external to the review point.", "helpfulness_rationale": "The reviewer's comment identifies a problem (vague presentation of existing methods) but does not offer concrete suggestions or actionable steps for the authors to improve their draft. The reviewer's point requires the authors to seek external information (the original paper) to understand the issue, which is not helpful in itself."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks 'what are the main rationals for' (a) and (b), which directly requests explanations of *why* certain architectural choices were made. This provides clear guidance for the authors to understand the model's design decisions. While the action isn't explicitly stated, the request for rationale makes it actionable.", "grounding_specificity_rationale": "The reviewer asks about the rationales for specific architectural choices within the context of the provided figure and dataset. While the *model* isn't explicitly named, the request is tied to the *specific components* (timbre encoder, SADTW) and the *dataset* (amateur vs. professional recordings). The grounding is present as the reviewer is asking about the *reasoning* behind these choices within the model's architecture. However, without knowing the exact model, the specificity of the rationale is limited to the model's internal workings.", "verifiability_rationale": "The reviewer asks for the *rationale* behind specific architectural choices. This implies a claim that these choices are made for a *reason*. The request for justification makes this claim verifiable, as the authors would then need to provide evidence for these reasons. The reasoning, while not explicitly stated, is implied by the question itself.", "helpfulness_rationale": "The reviewer asks specific questions about the *rationale* behind architectural choices in a model. Understanding the *why* behind design decisions is crucial for improving a model. This review point provides valuable insights into the model's design, making it 5 for the authors to understand and potentially improve their own work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point does not explicitly state an action or suggest how to improve the paper. While the reviewer implies the need to complete Table 4, they don't specify the exact steps or criteria for completion.", "grounding_specificity_rationale": "The reviewer mentions 'Table 4' which is a specific part of the paper. However, they do not specify *what* is missing or *how* the results should be included. The grounding is present, but the specificity of the suggestion is lacking.", "verifiability_rationale": "The review point does not contain a claim or assertion. It simply states a problem ('Table 4 is incomplete') and suggests a solution ('It should include the results for all four datasets'). There is no logical reasoning, common knowledge, or external references provided to support this suggestion.", "helpfulness_rationale": "The review point identifies a clear weakness ('Table 4 is incomplete') and provides a specific suggestion for improvement ('It should include the results for all four datasets'). This directly informs the author about what is missing and how to address it, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem (jumbledness) but doesn't offer a concrete action or solution.", "grounding_specificity_rationale": "The comment refers to 'writing / presentation' generally, without pinpointing a specific section, table, figure, or element.", "verifiability_rationale": "The comment is a statement of opinion ('I found...') and doesn't require verification.", "helpfulness_rationale": "The feedback is general and lacks specific actionable steps. It's a broad suggestion."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer poses a question about the importance of the annealing scheme, which implicitly suggests it might be relevant. However, the action to take is vague. The reviewer doesn't explicitly state what the authors should do with the information. They are asking a question, which is an implicit action, but it's not clear what the authors should do with this information. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the last paragraph in Section 4' and the 'annealing scheme' within it. This clearly identifies the specific part of the paper being addressed, achieving 'Full Grounding'. The comment refers to a specific section and a specific method within that section.", "verifiability_rationale": "The reviewer makes a claim about the potential drawbacks of the annealing scheme, stating that it could induce a bias that outweighs the benefits of IWAE. However, this claim is not supported by any evidence or reasoning within the review point. There are no references to external works, no logical arguments, and no examples provided to back up this assertion. The reasoning is missing, making the claim 1.", "helpfulness_rationale": "The reviewer raises a concern about the annealing scheme without providing any supporting evidence or reasoning. They are speculating about potential issues but do not offer any concrete suggestions or analysis to address these concerns. The comment is a claim without any justification, making it unhelpful for the authors to understand the potential issues or how to mitigate them."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out a factual error in the authors' description of the IOI circuit, stating that the Induction, Duplicate Token, and Previous Token heads 'primarily attend' to the S2 token, while according to Wang et al., 2023, they are 'active' but not 'primarily attend'. The reviewer provides a clear alternative description and a specific section reference (Section 3 of Wang et al., 2023) to support their claim. This allows the authors to directly understand the error in their terminology and replace it with the correct concept.", "grounding_specificity_rationale": "The reviewer provides a specific section reference (Section 3 of Wang et al., 2023) to support their claim about the attention mechanism behavior. This demonstrates strong grounding specificity as the reviewer accurately identifies the relevant section in the cited work.", "verifiability_rationale": "The reviewer makes a claim that the authors' description of the IOI circuit is incorrect and provides a specific reference to Wang et al., 2023 to support this claim. The reference is verifiable, indicating that the reviewer has evidence to support their statement.", "helpfulness_rationale": "The reviewer's comment is 5 as they clearly identify a factual error in the authors' description and provide a correct alternative. The specific section reference and the clear distinction between 'primary attention' and 'activity' in attention mechanisms equip the authors with concrete information to improve their understanding and potentially their draft."}
{"actionability_label": "None", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point states that the method does not seem to be scalable. While this is a valid concern, the point does not explicitly state what action needs to be taken to address this issue. The reviewer is expressing a limitation rather than providing a concrete, actionable suggestion. Therefore, it is not explicitly stating an action, and the action is also vague as it does not specify how to make the method scalable. Based on the definitions, it is 2 as it points to a limitation but lacks specific details on how to address it.", "grounding_specificity_rationale": "The review point is a general statement about the method's scalability and does not mention any specific part of the paper or method being addressed. It is 1 at all as it does not identify a particular section, table, figure, or unique aspect of the paper. Therefore, it is 1 and specificity is not applicable as there is no reference to a specific part of the paper.", "verifiability_rationale": "The review point contains a claim: 'The method does not seem to be scalable...'. This is a statement of opinion or judgment about the method's limitations. However, the point does not provide any evidence or reasoning to support this claim. It is presented as a statement of what the reviewer thinks is a problem without any backing or justification. Therefore, the claim is present, but it lacks supporting evidence or justification, making it 3.", "helpfulness_rationale": "The review point identifies a significant practical limitation regarding the scalability of the method. However, it does not offer any suggestions or actions to address this limitation. It is a critique of the method's limitations rather than a constructive suggestion for improvement. Since it does not provide any actionable feedback, it is not 5 to the authors. It is more likely to be perceived as a negative comment rather than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for an explanation of why a specific term follows a noncentral chisquared distribution. While the paper mentions the distribution, it doesn't explicitly state the reasoning behind it. The reviewer is implicitly asking for an action: to understand the underlying reasons for this statistical property.", "grounding_specificity_rationale": "The reviewer's comment refers to 'eta_ri term' without specifying which part of the paper this term belongs to. They are making a general statement about the lack of clarity regarding the distribution. Therefore, the grounding is weak as the authors cannot confidently identify the referenced part.", "verifiability_rationale": "The reviewer is making a claim about the paper's content: that the reason for the eta_ri term's distribution is not clear. This claim requires justification, as the paper only states the distribution type. However, the review point itself does not provide any evidence to support this claim. The reasoning is present in the reviewer's mind but not explicitly stated in the paper or the review point.", "helpfulness_rationale": "The reviewer is asking for an explanation of a technical detail. While this can be helpful for the authors, the review point itself does not directly instruct the authors on what to do. The authors would need to infer that they need an explanation for the noncentral chisquared distribution of the eta_ri term. The helpfulness is indirect and requires the reader to take an action (inferring the need for explanation)."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit and concrete suggestions for improvement. On L15, the reviewer points out the vagueness of the statement and suggests looking into specific areas of RNN research (natural language inference and the SNLI leaderboard). On L16L18, the reviewer criticizes the reinforcement learningagent analogy and suggests focusing on generalization capabilities and providing examples later in the paper. These suggestions are clear and directly address potential weaknesses in the work, making them actionable.", "grounding_specificity_rationale": "The reviewer's comment on L15 is somewhat vague in terms of grounding. While they mention 'certain RNNs' and 'natural language reasoning tasks,' they do not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The suggestion on L16L18 is also somewhat vague as it refers to 'reinforcement learning / agent' without pinpointing a specific part of the paper where this analogy is used or where it might be outofplace. While the suggestions are general areas for improvement, they lack the specificity to directly target a particular element within the submitted work.", "verifiability_rationale": "The review point contains claims, as the reviewer expresses opinions and judgments about the clarity of the work and the appropriateness of the reinforcement learning analogy. However, the verifiability of these claims within this review point itself is limited. The reviewer states that the statement on L15 is 'too vague' and that the reinforcement learning analogy is 'outofplace,' but they do not provide specific references, logical reasoning, or external examples to support these claims within this review point. The suggestions are presented as statements of opinion rather than verifiable arguments.", "helpfulness_rationale": "The review point is 5 as it provides clear and actionable feedback. The reviewer explicitly points out a potential weakness ('too vague') and offers specific suggestions for improvement, such as exploring 'certain areas of RNN research' and focusing on 'generalization capabilities' with 'examples later in the paper.' These suggestions are concrete and directly address potential areas for enhancement, making the review point valuable for guiding the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a lack of significant difference in performance and a lack of justification, but it doesn't explicitly state what needs to be done. The claims are present, but the actions are implied rather than clearly stated.", "grounding_specificity_rationale": "The reviewer mentions 'Fig.5' and 'StableDiffusion' when discussing the performance difference, indicating some grounding. However, they don't specify which part of Fig. 5 or what exactly the difference is. The reference to 'Algorithm 1' for the lack of justification is also missing, making the grounding weak. The connection to 'sensitivelayer selection' is implied but not explicitly stated in the grounding.", "verifiability_rationale": "The reviewer states that there is 'no mathematical or theoretical justification' for Algorithm 1, which is a claim lacking support. They don't provide any examples, references, or explanations to back up this assertion. The reasoning is missing, making the claim 1.", "helpfulness_rationale": "The review points out observations (lack of significant difference and lack of justification) without providing concrete suggestions or directions for improvement. While the observations are factual, they don't directly guide the authors on how to proceed."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: \"the authors should change the notation in line 122 from sets to tuples.\" This is a concrete action with a clear goal. The reviewer directly tells the authors what to do and how to do it.", "grounding_specificity_rationale": "The review point explicitly mentions \"line 122\" and the specific notation being used ('sets\" vs. \"tuples\"). This clearly identifies the specific part of the paper and the issue being addressed. The reviewer does not need to infer the location or the problem, making the grounding very precise.", "verifiability_rationale": "The review point is a suggestion for improvement, not a claim that requires verification. It proposes a concrete change to enhance clarity. While it doesn't provide external references, the suggestion itself is logically sound and directly addresses the identified issue. Therefore, it can be considered 3 as it offers a clear and logical suggestion.", "helpfulness_rationale": "The review point is highly specific and directly addresses a concrete issue in the paper. It provides a clear and actionable suggestion for improvement, which is directly beneficial to the authors. It does not criticize the authors personally or make vague generalizations. The suggestion is constructive and directly addresses the identified problem."}
{"actionability_label": "5", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of speed analysis and suggests an alternative (FLOPs comparison). This directly points the authors to what needs improvement.", "grounding_specificity_rationale": "The reviewer mentions 'inference speed' and 'prior work' in general terms. While they imply the area of comparison, they don't specify a unique section, table, or figure. The suggestion to compare FLOPs doesn't add much specificity.", "verifiability_rationale": "The reviewer makes a claim about the importance of speed analysis but doesn't provide any evidence or reasoning to support this claim. The suggestion about FLOPs is presented as a preference, not a necessity or a welljustified alternative.", "helpfulness_rationale": "The review points out a specific area for improvement (inference speed) and provides a suggestion (FLOPs comparison). However, the justification for prioritizing FLOPs over speed is not provided, making the feedback less compelling."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem with quantization: it is not scalable and costly, especially with large datasets (N) and high dimensionality (M). They also state that this hinders the method's ability to achieve fast convergence, a stated goal in the abstract and introduction. The reviewer suggests that this makes the method lose its point, implying a lack of effectiveness. The reviewer identifies the issue and its consequence, which is a clear indication of an actionable point.", "grounding_specificity_rationale": "The reviewer directly addresses the scalability issue of quantization, which is a specific aspect of the method. They don't just say 'the method is bad,' but 'this specific part of the method is a problem.' They also specify the factors contributing to the problem: the cost associated with large datasets (N) and high dimensionality (M). This demonstrates a clear grounding of the issue within the method's technical details. The reviewer focuses on a specific component of the method and explains why it lacks grounding in terms of scalability.", "verifiability_rationale": "The reviewer makes a claim: 'Optimal quantization is not scalable... which makes the method loses its point.' This claim is supported by the reasoning provided, which explains *why* quantization is not scalable (costly to N and M) and *how* this impacts the method's ability to achieve fast convergence. The reviewer provides logical reasoning and specific examples (cost and scalability) to support their claim. The claim is not just a statement of fact but an analysis of the implications for the method's goals.", "helpfulness_rationale": "The reviewer provides a clear and actionable criticism. They identify a specific weakness in the paper's motivation (the lack of scalability of quantization hindering fast convergence) and offer a potential alternative approach by focusing on methods that don't have this issue. The reviewer explains *why* the quantization is a problem and *what* the consequences are for the method's effectiveness. This criticism is directly relevant to the paper's stated goals and provides a valuable insight for the authors to consider alternative approaches. The reviewer doesn't just complain; they offer a constructive critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the need for comparison to contrastive decoding and mentions notational issues. This is an explicit action pointing to specific areas for improvement. However, the reviewer doesn't specify *how* the comparison should be done or *what* the notational issues are, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'existing methods, such as contrastive decoding' and 'notations issues.' While they touch upon a category of methods, they don't pinpoint a specific section or table of the paper. They also don't explicitly state they are referring to a specific section, making the grounding weak. However, the reviewer is generally critical of the methodology, which could be interpreted as specifying the *nature* of the weakness, making it somewhat specific.", "verifiability_rationale": "The reviewer makes a claim: 'as part of the core methodology, the paper should compare its effectiveness against existing methods, such as contrastive decoding... Issues mentioned above should be addressed.' This is a claim that requires verification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no justification for why this comparison is necessary or what the notational issues might be. Therefore, the claim is not supported by any evidence.", "helpfulness_rationale": "The reviewer's comment is a general critique of the methodology and suggests a specific improvement (comparison to contrastive decoding). While this points to a potential area for improvement, the reviewer does not provide concrete steps or examples to make this suggestion helpful for the authors. The lack of specific details makes the comment somewhat vague and less actionable. The reviewer also mentions 'issues mentioned above,' which are not explicitly defined, further reducing the helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitations of the algorithm requiring the entire training dataset and the expectation for it to operate effectively without it. They also explicitly state the need for a time complexity analysis and a clearer technical contribution. These are all concrete and actionable suggestions.", "grounding_specificity_rationale": "The reviewer refers to 'the algorithm' and asks about its operation without the full dataset, time complexity, and technical contribution. While not always pointing to a specific section number, these are generally identifiable concepts within a research paper, and the reviewer is asking about the algorithm in general, which is a specific part of the paper. The reviewer also specifies what they expect the algorithm to do and what they don't like about it.", "verifiability_rationale": "The reviewer makes claims about the algorithm's limitations and expectations (requiring the full dataset, operating effectively without it, analyzing time complexity, and clarifying technical contribution). However, the paper itself, as presented in this context, does not provide specific evidence or references to support these claims. The reviewer is pointing out *what they wish the paper had addressed*.", "helpfulness_rationale": "The reviewer's overall comment is about the comprehensiveness of the validation experiments and the analysis of time complexity, which are valid points for improvement. The reviewer also explicitly states the expectation for a deeper technical contribution, which is a concrete suggestion. The phrasing 'Overall: ... the time complexity of the computation and the efficiency of the algorithm are not clearly analyzed' is particularly direct and actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states a limitation of using neural networks to represent kernels: that they can only represent finitedimensional RKHSs in practice, contrasting this with the infinitedimensional nature of some kernels like RBFs. This is an explicit action with concrete details (finite vs. infinitedimensional RKHSs) and a clear suggestion for improvement (\"make the limitation more clear\"). The reviewer provides a specific example (RBF kernels) to illustrate this point.", "grounding_specificity_rationale": "The review point explicitly mentions \"Reproducing Kernel Hilbert Spaces (RKHS)\" and uses the example of \"RBF kernels\". This clearly grounds the comment in specific aspects of the paper being reviewed. The reviewer also provides a concrete explanation of the issue related to the dimensionality of the RKHS.", "verifiability_rationale": "The claim in the review point, that \"one would need an NN with infinite width to represent it\" for infinitedimensional RKHSes like those of RBF kernels, is wellsupported by established knowledge of RKHS theory. The reasoning is generally accepted and the example of RBF kernels provides a concrete illustration.", "helpfulness_rationale": "The review point is 5 as it provides a specific example (RBF kernels) to illustrate the limitation of using neural networks for kernel representation. It also directly suggests a concrete improvement (\"make the limitation more clear\"), which is actionable for the authors. The reviewer provides a clear and informative critique."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the proposed method is not wellpositioned in literature and then provides specific examples (denoising score matching and scoreinterpolation) and explains the connection. This clearly indicates an actionable suggestion for the authors to improve their literature review and contextualize their work. The reviewer also suggests a thorough literature review, which is a concrete action.", "grounding_specificity_rationale": "The reviewer mentions that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is used in existing works like denoising score matching and scoreinterpolation. This directly grounds the comment in existing literature, as the authors can identify the specific concepts and areas they need to explore. While the reviewer doesn't explicitly point to a specific section, the mention of concrete examples provides grounding. The comment also specifies what needs to be addressed: understanding the connection to existing objectives.", "verifiability_rationale": "The reviewer makes a claim that the key idea of the proposed method is 'quite wellknown' and provides specific examples and explanations to support this claim. The reviewer explicitly names 'denoising score matching' and 'scoreinterpolation' as instances where this property is used, providing clear justification for the claim.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors: to investigate the connection of their method to existing objectives like denoising score matching and scoreinterpolation. This directly points the authors to specific areas of literature to explore and provides a clear purpose for their investigation. The reviewer also suggests a 'thorough literature review', which is a valuable and concrete piece of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer asks a direct question about the benefits of linear attention during inference, which can be interpreted as a suggestion for improvement in understanding the generation process. The question is specific to the interaction between linear attention and autoregressive decoding during the generation phase. The reviewer is seeking clarification on a technical aspect, which can be actionable by providing information or pointing to relevant resources. The question is clear and identifies a potential area for improvement in the understanding of the model's behavior during generation.", "grounding_specificity_rationale": "The reviewer's question is general and does not specify which part of the linear attention mechanism or the autoregressive process they are referring to. They are asking about the benefits of linear attention during inference in general. While the question is relevant, it lacks the specificity needed to pinpoint a particular aspect of the model or process. The reviewer is asking for a broader understanding rather than a detailed explanation of a specific component.", "verifiability_rationale": "The reviewer's question is not a claim or assertion. They are asking for information or clarification rather than making a statement that needs to be verified. Therefore, it does not fit into the categories of 'Claim Extraction' or 'Verifiability Verification'.", "helpfulness_rationale": "The reviewer's question is relevant to understanding a technical aspect of the model's behavior during inference. However, it is a question and does not directly provide actionable advice or a solution. It seeks information rather than a direct suggestion. While it points to a potential area for improvement, it doesn't immediately offer a concrete path forward. Therefore, it is not 5 in providing immediate guidance or improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides a clear argument for why the justification of PCC's relaxation strength over KL divergence is not convincing. They state: 'The assumption that PCC is a more relaxed constraint compared with KL divergence because of its invariance to scale and shift is not convincing enough.' This is a direct and explicit statement of the reviewer's understanding. They then offer a counterargument: 'The constraint strength of a loss function is defined via its gradient distribution. For example, KL divergence and MSE loss have the same optimal solution while MSE loss is stricter than KL because of stricter punishment according to its gradient distribution. From this perspective, it is necessary to provide the gradient comparison between KL and PCC.' This demonstrates that the reviewer understands the concept of constraint strength through gradient distribution and identifies a potential weakness in the paper's justification. The reviewer explicitly states an action: 'It is necessary to provide the gradient comparison between KL and PCC.' This action is directly derived from the reviewer's analysis.", "grounding_specificity_rationale": "The reviewer states their position about the justification of PCC's relaxation strength over KL divergence. However, they do not explicitly identify *where* within the paper this assumption is made. They are criticizing the *justification* of that assumption, but not pointing to a specific section being unclear. The reviewer's statement is a claim about the paper's content, but the grounding specificity is about how clearly the paper identifies the issue. The reviewer is not stating 'I cannot confidently determine which part of the paper this assumption is being made in.' They are stating a general critique about the justification. Therefore, the grounding specificity is not fully grounded. While the reviewer's statement is about a specific aspect of the paper (the comparison of PCC and KL divergence), the *identification* of where this assumption is made is missing.", "verifiability_rationale": "The reviewer makes a claim: 'The assumption that PCC is a more relaxed constraint compared with KL divergence because of its invariance to scale and shift is not convincing enough.' This is a direct statement of opinion. The reviewer then attempts to support this claim by stating: 'The constraint strength of a loss function is defined via its gradient distribution. For example, KL divergence and MSE loss have the same optimal solution while MSE loss is stricter than KL because of stricter punishment according to its gradient distribution. From this perspective, it is necessary to provide the gradient comparison between KL and PCC.' This is an attempt to verify the claim by explaining the concept of constraint strength through gradient distribution and suggesting a specific comparison. However, the reviewer does not provide any concrete evidence or references to support their initial claim that PCC's invariance is not a strong enough justification. The reviewer's argument is presented as a statement of opinion without direct evidence within the provided text. Therefore, the verifiability is '1' as the claim is presented without supporting evidence.", "helpfulness_rationale": "The reviewer provides a clear and logical argument against the justification for using PCC over KL divergence. They state their position: 'The assumption that PCC is a more relaxed constraint compared with KL divergence because of its invariance to scale and shift is not convincing enough.' They then offer a specific alternative: 'The constraint strength of a loss function is defined via its gradient distribution. For example, KL divergence and MSE loss have the same optimal solution while MSE loss is stricter than KL because of stricter punishment according to its gradient distribution. From this perspective, it is necessary to provide the gradient comparison between KL and PCC.' This argument is presented as a statement of opinion, and the reviewer does not provide any evidence or references to support their claim. However, the reviewer's statement directly addresses a potential weakness in the paper's justification and suggests a concrete alternative. This provides valuable information to the authors by highlighting a potential area for improvement in the paper's reasoning. The reviewer's statement is actionable for the authors by suggesting a different approach to constraint strength."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question about the impact of noise addition on GPI's fit with behavioral data, indicating an action to investigate this further. However, the reviewer does not explicitly state the action to be taken after identifying this potential issue (e.g., trying different noise levels, exploring alternative modeling approaches). The action is implied but not clearly articulated.", "grounding_specificity_rationale": "The reviewer refers to 'Fig. 4', 'GPI', 'noise added', 'behavioral data', 'behavioral trajectories', and 'time to goal' as specific elements. This demonstrates a clear attempt to pinpoint the area of concern and the specific aspects of the data being questioned. The language used, such as 'is it possible that GPI with noise added could reproduce the data similarly well', directly targets specific components of the analysis.", "verifiability_rationale": "The reviewer suggests exploring alternative measures beyond just the data in Fig. 4 and mentions 'pattern separation tasks' as a potential area for GPI. While this provides a direction for further investigation, the reviewer does not explicitly state how these alternative measures or tasks are verifiable or supported. The suggestions are presented as possibilities without clear justification or references.", "helpfulness_rationale": "The reviewer provides concrete suggestions, such as 'it seems to be suitable for modelling pattern separation tasks' and 'it would be nice to have some discussion on this'. These suggestions directly address potential limitations and offer actionable improvements for the authors. The reviewer is actively trying to help the authors understand and improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the experiment ('small learning rate for attention parameters') and the comparison ('with the proposed approach'). This is a clear and direct statement of an action to be taken. The action is also concrete, as the specific experiment and comparison are welldefined.", "grounding_specificity_rationale": "The reviewer mentions 'small learning rate for attention parameters' and 'proposed approach'. While they don't explicitly name a section or table, the concepts are quite specific. A reader familiar with the paper would likely understand what these terms refer to. The reviewer also implies a desire to compare these two aspects, which is a clear indication of grounding the comment in specific parts of the paper. The comment specifies what needs to be addressed (the experiment and the comparison).", "verifiability_rationale": "The reviewer suggests an experiment ('If you have the resources, I would be very interested to see how the \u201csmall learning rate for attention parameters\u201d benchmark...'). This is a suggestion, which can be considered a claim requiring justification. While the suggestion itself is verifiable in the sense that it's a concrete proposal, it doesn't provide a definitive answer or evidence. It points towards a specific area of investigation and is therefore 3 as it guides the authors towards a specific experiment.", "helpfulness_rationale": "The reviewer's suggestion to compare the 'small learning rate for attention parameters' benchmark with the 'proposed approach' is directly relevant to understanding the strengths and weaknesses of the proposed approach. This is a concrete suggestion that is likely to provide valuable empirical insights for the authors. It addresses a clear need for further experimentation and comparison."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the paper 'carelessly resolves a debate' and questions the methodology behind this resolution. They also explicitly ask 'why can't it be that the distribution has changed?' indicating a lack of clarity in the reasoning. While the reviewer doesn't provide concrete solutions, they clearly identify a potential area for improvement in the paper's methodology. The reviewer's statement 'Things I didn't understand:' suggests a lack of clarity in the paper's explanation, making the action implicit but the action itself clear.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'the paper' and asks specific questions about 'how it was previously handled,' 'distribution shifts,' and 'experiments disentangling.' This demonstrates strong grounding as the reviewer directly refers to the paper's content and methodology. The reviewer is also very specific about what they are questioning, indicating a clear specification of the issue.", "verifiability_rationale": "The reviewer mentions 'experiments disentangling changes in distribution from removal of information' as a potential gap. While the reviewer doesn't explicitly claim that this is a factual error, the lack of such experiments is a factual omission that could be considered a claim that needs justification. The reviewer's statement 'Things I didn't understand:' suggests a lack of clarity in the paper's explanation, which could be interpreted as a lack of justification for a claim.", "helpfulness_rationale": "The reviewer's comment is 5 as they are seeking clarification and understanding of the paper's methodology. They are pointing to a potential area of confusion or a flaw in the paper's approach. The reviewer is asking specific questions, which are actionable points for the authors. However, the reviewer does not offer solutions or alternative approaches, focusing more on identifying the problem than proposing a resolution."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to reproduce the baseline methods using the same training setup as the proposed method. This is a clear and direct action to address the identified issue.", "grounding_specificity_rationale": "The reviewer identifies a specific aspect of the paper being reviewed (the training parameters) and explains why it is important for a fair comparison. They pinpoint the lack of consistency in the training setup as a key factor that needs to be addressed. The reviewer also suggests a concrete solution (reproducing with the same settings), indicating a clear understanding of the problem and a specific plan to solve it.", "verifiability_rationale": "The reviewer makes a claim about the unfairness of the comparison due to the different training settings. While the reviewer identifies the specific issue (different training parameters), the *justification* for why this makes the comparison unfair is implied rather than explicitly stated with examples or references. The reviewer's intent is to highlight a potential flaw in the experimental setup.", "helpfulness_rationale": "The reviewer's comment is highly constructive and directly addresses a potential weakness in the paper being reviewed. They propose a concrete, actionable step (reproducing baselines with the same training settings) to improve the fairness and rigor of the comparison. This is a valuable suggestion that directly contributes to the improvement of the reviewed work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The suggestion to explore the combination of SOTA and an adaptive metric is explicit in mentioning the combination, which is a clear direction for improvement. However, it lacks specifics on which SOTA method or adaptive metric is being referred to, and how they should be combined, making it 3 but vague.", "grounding_specificity_rationale": "The comment refers to 'SOTA method' and 'adaptive metric' without specifying which ones or providing any context within the paper. This means the authors cannot confidently determine which part the comment addresses, making the grounding weak. Furthermore, the comment does not specify what needs to be addressed in this part, resulting in a lack of specificity.", "verifiability_rationale": "The review point does not present a claim or assertion that requires verification. It is a suggestion for further exploration rather than a statement that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The suggestion to explore the combination of SOTA and an adaptive metric is relevant to the potential for improvement in the paper. While the suggestion is vague, it points towards a valuable area of investigation and could lead to further discussion and potentially new experiments. Therefore, it is 3 in guiding the authors towards a potentially fruitful direction."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states several problems with the plots, such as them being 'too small,' having 'hard to distinguish' colors, 'poorly labeled' axes, and 'visually too similar' labels. These are all concrete actions or suggestions that the authors can directly implement to improve the presentation of their experimental results. The reviewer also implies an action by stating that these plots are the 'main presentation of the experimental results' and should be 'much clearer', indicating a desire for improvement.", "grounding_specificity_rationale": "The reviewer explicitly identifies the 'plots' as the problematic area and even specifies the exact plots being referred to as 'sdropout(tr)' and 'edropout(tr)'. This demonstrates a strong grounding as the authors can easily identify the specific part of the paper being addressed. Furthermore, the reviewer provides specific criticisms within those plots, such as the size, color contrast, and label similarity, indicating a high level of specificity.", "verifiability_rationale": "The review point contains a claim that the 'plots are terrible'. This claim is supported by the reviewer providing reasons for their assessment, such as them being 'too small,' having 'hard to distinguish' colors, 'poorly labeled' axes, and having 'visually too similar' labels. While these reasons are subjective, they provide a basis for understanding why the plots are problematic and how they could be improved. The reviewer does not explicitly cite external references for poor plot design, but the reasons provided are generally accepted principles of data visualization.", "helpfulness_rationale": "The review point is 5 because it directly addresses a critical aspect of the presentation of the experimental results. The reviewer not only identifies the problem ('plots are terrible') but also provides specific suggestions for improvement, such as making the plots larger, using colors that contrast better, labeling the axes clearly, and using different labels for the similar plots. These suggestions are concrete and actionable, giving the authors a clear direction for revising their figures."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states that the performance gains are 'not very high' and 'less than 1%'. This is a direct action pointing out a potential issue with the proposed changes (caption and warmup). The reviewer is suggesting the authors review their caption and warmup strategies based on this observation.", "grounding_specificity_rationale": "The comment refers to 'caption' and 'warmup' without explicitly naming specific sections or tables. However, it's a common practice in NLP papers to describe these components. The reviewer implicitly refers to the caption of the model and the warmup schedule used. The comment specifies the impact of these components on performance (not very high, less than 1%).", "verifiability_rationale": "The comment contains a claim: 'the performance gains are not very high...less than 1%'. However, it does not provide any evidence or justification to support this claim. It simply states the observation. There is no logical reasoning, common knowledge, or external references provided to verify this statement. The reviewer is pointing out a discrepancy, not verifying a claim.", "helpfulness_rationale": "The comment is helpful in guiding the authors to reevaluate their caption and warmup strategies based on the observed lack of significant performance gains. It provides a clear direction for improvement by suggesting a review of these specific components. While it doesn't offer a solution, it highlights a potential area for investigation, which can be beneficial for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "Not Helpfulness", "actionability_rationale": "The review point itself does not explicitly state what action should be taken. The reviewer is suggesting improvements to the feedback system, which is an implicit action. While the reviewer implies that the feedback system should value specific details, the point itself lacks a clear instruction on how to apply this.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or system being discussed. It is a general question about the feedback system. While it implies referring to a feedback system, it doesn't pinpoint a specific instance or component within that system.", "verifiability_rationale": "The review point does not contain a claim that can be verified. It is a suggestion for improvement rather than a statement that requires justification. There is no logical reasoning, common knowledge, or external references provided within the review point itself.", "helpfulness_rationale": "The review point does not directly address the feedback being reviewed. It focuses on the feedback system and its value. While the reviewer believes this feedback is helpful, the point itself does not provide actionable advice or insights specific to the paper being critiqued."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that Table 1 does not show standard deviations. While it doesn't explicitly say *how* to fix this, it implies the authors should add them. This makes the action somewhat explicit but not fully concrete.", "grounding_specificity_rationale": "The review point explicitly refers to 'Table 1' and mentions 'standard deviations'. This clearly identifies the specific part of the paper being addressed and the specific issue. Therefore, it is 5.", "verifiability_rationale": "The claim that 'Table 1 does not show standard deviations' is verifiable by checking the table. However, the reviewer also states that 'this includes' other related points, which are not explicitly justified within this part of the review point. The suggestion to make experiments more extensive is a general statement.", "helpfulness_rationale": "The review point directly points out a missing element (standard deviations) in a specific table. It also provides a suggestion to improve the experiments, which is a helpful and actionable comment. The reviewer clearly implies the authors should add the standard deviations."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer raises a question about the interpretation of the experimental results but does not explicitly state a concrete action or suggestion for the authors to take. While the question is relevant, the lack of a direct action makes it less actionable. The reviewer asks 'is there still a performance boost?' but does not propose a specific experiment or analysis to investigate this.", "grounding_specificity_rationale": "The reviewer refers to 'LinearTop', 'NLTop', and 'Unary' in the context of the tables, which suggests an attempt to ground the comment in specific elements of the paper. However, the reviewer does not explicitly state which section or table within the paper they are referring to. While the terms are mentioned, the connection to a specific part of the paper is not clearly established.", "verifiability_rationale": "The reviewer claims there is a potential inconsistency in the interpretation of the results, specifically regarding the performance of different models and the comparison to 14. However, the reviewer does not provide any explicit evidence, reasoning, or references within the review point to support this claim. The claim is based on an external reference (14) rather than internal justification within the provided text.", "helpfulness_rationale": "The reviewer raises a valid point about the potential inconsistency in the interpretation of the experimental results. However, the reviewer does not offer any concrete suggestions or actions for the authors to take based on this observation. The comment is primarily a question and a statement of concern, lacking actionable guidance."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests improvements such as 'improve the structure' and 'improve the visualization of the Fig 7, and Fig.' While these suggestions are relevant, the specific actions are not detailed. The reviewer does not explicitly state how to improve the structure or how to visualize the figures better. The suggestions are general and lack concrete steps. Therefore, the reviewer points out areas for improvement, making the comment actionable in principle, but the lack of specific details makes it vague.", "grounding_specificity_rationale": "The reviewer suggests improvements for 'introduction>method>experiments' and 'put more focus on the IEM in Fig 3'. While the reviewer *mentions* specific sections and a specific figure, they do not explicitly identify the *exact* part within those sections or the figure that needs improvement. The suggestions are general, indicating a lack of precise identification of the problematic areas. Therefore, the reviewer points to areas needing improvement, but the lack of specific identification within those areas makes the grounding weak.", "verifiability_rationale": "The reviewer states 'The paper is a bit hard to follow' and offers suggestions like 'improving the structure' and 'improving the visualization of the Fig 7, and Fig.' There are no explicit claims being made. The reviewer is providing feedback and suggestions, not stating something that requires verification or justification. Therefore, there are no claims in the review point, fitting the 'X' category.", "helpfulness_rationale": "The reviewer identifies a clear issue ('The paper is a bit hard to follow') and offers relevant suggestions ('improve the structure', 'improve the visualization of the Fig 7, and Fig.', 'improve the visualization of the Fig 7, and Fig.'). The suggestions are directly related to the identified issue and provide a direction for improvement. While the specific actions are not detailed, the feedback itself is helpful in guiding the authors on what needs to be addressed. Therefore, the reviewer provides feedback that is relevant and actionable, even if the specific actions are not fully defined."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests expanding the experiments to other architectures and classification tasks. While this is a valid suggestion for improving the paper, it is not an explicit action or a concrete step that the authors can directly follow. The reviewer implies a broad scope rather than a specific, actionable change. Therefore, the actionability is implicit and lacks clear direction.", "grounding_specificity_rationale": "The reviewer suggests expanding the experiments to other architectures and classification tasks. However, the reviewer does not explicitly identify which part of the paper is lacking or specify the exact nature of the missing information. The suggestion is general and does not pinpoint a specific section, table, figure, or unique element of the paper. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The reviewer's comment contains a claim: 'It would be interesting to see the performance of attack on other architecture and classification tasks.' This claim is not supported by any evidence or reasoning within the review point. The reviewer is simply stating their suggestion without providing any justification or references. Therefore, the verifiability is low as there is no supporting evidence for the claim.", "helpfulness_rationale": "The reviewer's comment suggests expanding the experiments to other architectures and classification tasks. While this could be a valuable suggestion for the authors, it is not a direct critique or a clear set of actionable steps. The reviewer is making a suggestion for future work rather than providing immediate feedback. Therefore, the helpfulness is moderate as it points to a potential improvement but lacks specific guidance."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the desired information: 'I'd like to know the final used learning rates for the deep models (particularly CIFAR10 and CIFAR100)'. This is a clear and direct request for action. The reviewer also implies a concern about the limited search space of learning rates, suggesting they believe the optimal rate might be outside the tested interval. This further indicates an actionable request for clarification or information.", "grounding_specificity_rationale": "The reviewer mentions 'deep models' and specifically 'CIFAR10 and CIFAR100', but does not identify a *specific* model or implementation within those categories. While the general area is clear, the exact model or architecture is not specified. This provides some grounding but lacks the specificity of identifying a unique element. The reviewer is implicitly asking for information relevant to the experiments conducted, which is a form of grounding, but it's not as precise as identifying a section or table by name.", "verifiability_rationale": "The reviewer is not presenting a claim or making a judgment. They are directly asking for information about the final learning rates used in the experiments. There is no logical reasoning, common knowledge, or external references provided in this review point. It is a factual request.", "helpfulness_rationale": "The reviewer's comment is directly pointing out a missing piece of information (final learning rates) that is crucial for understanding and potentially reproducing the results. They are also expressing concern about the limited search space of learning rates, which could potentially affect the validity of the findings. This feedback is specific and actionable, highlighting a potential issue with the experimental setup or reporting. While it doesn't directly instruct how to improve the paper, it identifies a significant gap in the provided information."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer expresses a disagreement with the choice of a 'no locality bias' transformer model and asks for a justification. While they don't explicitly state a specific action they want the authors to take, the implicit suggestion is that the current choice might be suboptimal. The reviewer is pointing towards a potential area for improvement, but the action isn't directly stated.", "grounding_specificity_rationale": "The reviewer refers to 'transformer free of localitybias' and 'neighborhood agents' as examples of issues. However, they do not explicitly identify the specific section, table, or unique aspect of the paper they are referring to. The concepts are mentioned generally, without pointing to a particular location in the paper. The reviewer also doesn't provide a specific example of where this bias might be a problem. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer does not present a claim that requires justification. They are simply expressing an opinion about the suitability of a particular model choice and asking for a rationale. There are no statements that need to be logically reasoned, supported by common knowledge, or backed by external references to be considered verifiable.", "helpfulness_rationale": "The reviewer directly addresses a specific design choice in the paper ('transformer free of localitybias') and asks for a justification. This is a clear and actionable feedback that directly targets a potential improvement. The reviewer is actively engaging with the paper and seeking to understand a key decision, making this feedback highly valuable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement is explicit about the potential dependency and suggests clarifying the issue. The reviewer is indicating a concrete action (clarification) is needed. While the dependency itself might be vague, the reviewer explicitly states it, making it more actionable than '1 and underspecific' or '3'.", "grounding_specificity_rationale": "The reviewer makes a general statement about the algorithm's dependency on the order of data processing. They do not explicitly point to a specific part of the paper or data being affected. The statement is about the algorithm in general, not a specific section of the draft. Therefore, it lacks grounding specificity.", "verifiability_rationale": "The statement is a factual observation about how algorithms work. It doesn't present a claim that requires verification in the context of the paper itself. It's a statement about the algorithm's behavior, not a claim about the paper's content or quality. Therefore, it's not verifiable in the sense of providing new information about the paper.", "helpfulness_rationale": "The statement identifies a potential issue with the algorithm's documentation or implementation and suggests clarifying it. This points to a concrete action (clarification) that could improve the draft. While it might not be a major discovery, it's a valuable piece of feedback that suggests a specific improvement. Therefore, it's 3 as it points towards actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the impact on performance: \"it's unclear what impact they might have on the overall performance of the model.\" It also suggests a potential consequence: \"If these mitigation strategies significantly impair the model's utility, it might deter their adoption.\" This suggests a clear action the authors could take: investigate the performance impact and check for utility deters.", "grounding_specificity_rationale": "The review point refers to \"mitigation strategies\" generally. It mentions \"performance of the model\" generally. It discusses a \"tradeoff\" generally. It refers to \"utility of the model\" generally. There is no specific section, table, figure, or unique aspect of the paper being directly addressed.", "verifiability_rationale": "The review point contains the claim: \"it's unclear what impact they might have on the overall performance of the model.\" This claim is based on the general understanding of mitigation strategies and their potential tradeoffs with performance, which is a common knowledge or logical reasoning point. The statement \"Often, there's a tradeoff between reducing a particular behavior and maintaining high performance\" provides justification for the first claim. The second part, \"If these mitigation strategies significantly impair the model's utility, it might deter their adoption,\" is a logical consequence and doesn't require external references in this context.", "helpfulness_rationale": "The review point raises a valid concern about the potential negative impact of mitigation strategies on model utility. It connects this concern to a practical consequence (detering adoption). This provides the authors with a reason to investigate further and potentially adjust their mitigation strategies."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer identifies a missing justification for using 6fold crossvalidation. While they don't explicitly state what action is being taken *with* the crossvalidation, the implication is that the crossvalidation is being used to evaluate the model's performance on unseen data. The action is implicit, requiring the authors to infer the purpose. The concreteness of the action is unclear as the reviewer doesn't specify *how* the crossvalidation is being used to improve the draft.", "grounding_specificity_rationale": "The reviewer is primarily concerned with the *reason* for using 6fold crossvalidation. They are asking *why* it's necessary, which implies they are not explicitly stating what the crossvalidation is being used for *in this specific paper*. The grounding is in the *reasoning* behind the choice, which is not clearly articulated. The specificity is low as the reviewer is not pinpointing a specific part of the paper being addressed in relation to the crossvalidation.", "verifiability_rationale": "The reviewer expresses uncertainty about the *justification* for using 6fold crossvalidation. They are questioning the *reasoning* behind their claim that the reason is not understood. This lack of clear reasoning or supporting evidence makes the claim somewhat 1. The reviewer is essentially stating a lack of justification, which is a claim that requires verification.", "helpfulness_rationale": "The reviewer's uncertainty about the *justification* for using 6fold crossvalidation translates to a lack of clear *value* for the authors. The comment is framed as a question about the *reason* for the crossvalidation, rather than a statement of how it helps them improve their draft. Therefore, the feedback is not clearly actionable and impactful."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "1", "actionability_rationale": "The review point criticizes the experimental evaluation but does not provide explicit or implicit suggestions on how to improve the evaluation itself or the proposed methods. The comment focuses on the *results* of the experiments rather than guiding the authors on *what to do* to address the identified limitations. Therefore, the action is implied but not explicitly stated in the review point.", "grounding_specificity_rationale": "The reviewer mentions 'Table 2' as the specific part of the paper being criticized, which can be considered 'full grounding'. However, the criticism is general, stating that the proposed approaches only outperform in one setup and there's no consistent trend. While the part of the paper is identified, the specific issue or flaw within Table 2 and the comparison between different proposed methods are not clearly defined. The reviewer doesn't specify *which* part of Table 2 is problematic or *which* method is better. Therefore, it's weakly grounded but not fully specific.", "verifiability_rationale": "The reviewer makes a claim that 'the results presented are insufficient to prove the benefits of the proposed methods.' This claim can be considered verifiable because it points to a logical consequence of the experimental results \u2013 the lack of consistent and significant outperformance. While the claim doesn't provide specific examples or references, the reasoning is clear and based on the observed data. Therefore, the claim is verifiable, but it lacks specific justification.", "helpfulness_rationale": "The review point criticizes the experimental evaluation and the lack of sufficient results. While this is a valid concern for the authors who likely spent time on the proposed methods, the review point itself does not offer any actionable suggestions or insights on how the authors can improve their methods or experiments based on this criticism. The feedback is focused on the evaluation rather than providing guidance on how to address its shortcomings. Therefore, the review point is not helpful in terms of providing concrete improvements to the authors' work."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a potential area for improvement by pointing out the presence of heuristic components. However, it does not explicitly state what actions the authors should take to address this. The reviewer raises a question about the impact, but lacks a direct action for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions 'NonAmbiguous Query Generation procedure relies on a sophisticated filtering template.' This clearly identifies a specific part of the paper and how the authors can locate it. The reviewer can easily find the relevant section.", "verifiability_rationale": "The review point makes a claim that 'It would be helpful if the author could clarify the impact of these heuristic components.' However, it does not provide any supporting evidence, examples, or references to back up this claim. The reasoning is vague and lacks detail.", "helpfulness_rationale": "The review point identifies a valid concern about the heuristic components. However, it does not offer concrete actions or guidance on how the authors should analyze or improve these components. It is a call for clarification rather than a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a missing piece of information needed for the proposed method (ray marching) to function correctly. They identify the 'knowledge of CAD model correspondences' as essential for determining the 'ray origin'. While the reviewer doesn't explicitly state an *action* to take, they highlight a necessary input that is missing, making the criticism 3 in identifying a gap.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'knowledge of CAD model correspondences' as a specific piece of information needed to address the limitation of not having camera information. They connect this specific detail to the proposed method (ray marching), indicating a clear grounding of the criticism in a specific aspect of the paper.", "verifiability_rationale": "The reviewer questions the claim that the proposed method can be trained without camera information, specifically the 'knowledge of CAD model correspondences'. They argue that without this knowledge, determining the 'ray origin' becomes impossible. The reviewer provides a logical argument based on their understanding of the method, suggesting a partially verifiable claim as they provide reasoning but might be missing some explicit references or examples to fully support their claim within this specific point.", "helpfulness_rationale": "The reviewer raises a valid point about a potential limitation of the proposed method. They highlight a specific assumption that might not hold true in all scenarios. While they don't offer a direct solution, they point out a potential area for improvement, making the critique 3 in identifying a potential weakness."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the paper would benefit from a more detailed comparison with related work. This is an explicit action. Furthermore, the reviewer specifies the *content* of this comparison, mentioning 'time complexity and competitiveness'. This specificity makes the action concrete. Therefore, the review point provides clear guidance on what the authors should do.", "grounding_specificity_rationale": "The reviewer mentions 'related work' generally but does not specify which section, table, figure, or unique aspect of the paper is being addressed. While the reviewer mentions specific *topics* for comparison ('time complexity and competitiveness'), the *location* within the paper is not pinpointed. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The reviewer makes a statement about the paper 'benefiting' from a more detailed comparison. This is a suggestion, not a direct claim requiring verification in the traditional sense. However, the *implied* claim is that the *absence* of this comparison is a weakness. This is a bit ambiguous. Crucially, the reviewer does not provide any evidence or justification for their claim. There is no logical reasoning, common knowledge, or external references provided to support the assertion that a detailed comparison is indeed beneficial or necessary. Therefore, the verifiability is low as there is no supporting evidence or justification for the claim.", "helpfulness_rationale": "The reviewer's desire for a more detailed comparison with related work, especially regarding 'time complexity and competitiveness', is a valuable direction for improvement. Even though the reviewer does not provide a strong justification for this desire, the *content* of the feedback is constructive and points towards a specific area for enhancement. Therefore, the review point has some inherent value in terms of guiding improvement, even without explicit justification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the presented method does not clearly show how it improves performance and computation speed compared to just using ODA. While the reviewer identifies a potential weakness in the paper's presentation, the actionability of this point is somewhat vague. The reviewer doesn't explicitly state what aspect of the method's improvement is unclear, leaving the reader to infer the ambiguity. The reviewer identifies an implicit action (identifying a lack of clarity) but doesn't provide concrete details on what needs to be done to address this issue.", "grounding_specificity_rationale": "The reviewer's comment refers to 'ODA' and 'the presented method' in a general sense. While they are addressing the relationship between these two, they do not explicitly point to a specific section, table, figure, or unique element of the paper where this lack of clarity exists. The reviewer's comment is more about the general flow and explanation of the methods rather than pinpointing a precise location within the paper.", "verifiability_rationale": "The reviewer makes a claim that 'the presented method has learned the policy to imitate the problemsolving method, but it did not clearly suggest how the presented method improved the performance and computation speed of the solution rather than just using ODA.' This is a claim that requires verification. The reviewer's statement is based on their interpretation of the paper's content and identifies a gap in the explanation. However, the paper itself doesn't explicitly state that the presented method *only* imitates ODA in terms of problemsolving. The reviewer is inferring this limitation based on the paper's description of the presented method. Therefore, the claim is not directly supported by explicit evidence within the paper, making it 1 based on the provided text.", "helpfulness_rationale": "The reviewer's comment is a question about how the presented method improves upon ODA. While this points out a potential area for clarification in the paper, it doesn't offer a solution or suggestion for how to address this lack of clarity. The reviewer is identifying a problem but not proposing a concrete improvement. Therefore, the helpfulness of this comment is limited as it doesn't directly contribute to resolving the identified issue."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'clarify' as an action and points to specific lines in Figure 4 ('No adapt or Finetune are covered by other lines'), indicating a concrete action to be taken.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 4' and then points to specific lines within that figure ('No adapt or Finetune'), indicating a clear and accurate identification of the part of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim about the figure's clarity and provides a specific example ('the line of No adapt or Finetune are covered by other lines'), which can be verified by examining the figure itself.", "helpfulness_rationale": "The reviewer directly points out a problem ('Some figures are not selfexplanatory') and provides a specific suggestion ('For instance, in Figure 4, the line of No adapt or Finetune are covered by other lines, without additional explanation'), making the feedback actionable and directly useful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the importance of the sampling method for convergence. However, it does not specify which sampling method is important or how to apply this action to improve the draft. The action is stated but not concretely implemented.", "grounding_specificity_rationale": "The review point mentions the importance of sampling and convergence but does not explicitly identify a specific part of the paper or a specific element within the optimization process that needs improvement. The comparison to uniform sampling in the supplementary material is a general point about experimental evaluation, not a specific detail within the current work.", "verifiability_rationale": "The review point contains a claim that the sampling method is important for convergence. However, it does not provide specific evidence or reasoning to support this claim within the main text. The reasoning provided is a general statement about the lack of experimental evaluation, which is not as strong as providing specific examples or references.", "helpfulness_rationale": "The review point identifies a potential weakness in the experimental evaluation by highlighting the lack of careful evaluation of the sampling method's impact on convergence. While this points to an area for improvement, it does not provide specific guidance on how to address this issue or what experiments to conduct. The helpfulness is limited by the lack of concrete suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer raises several questions about the rationale for the comparisons, the justification for computational cost comparisons, and the lack of discussion on computational cost. While the paper states the comparisons and computational costs, it does not explicitly explain the *why* behind these choices. The reviewer's questions highlight a lack of clear reasoning and a potential lack of clarity in the paper's methodology and experimental setup. The paper mentions the comparisons with 9 and 16 but doesn't elaborate on the *rationale* for this specific selection or the *reasons* for not comparing with other methods. Similarly, the paper states the computational cost but doesn't explain *why* these comparisons are important or *why not* compare with other methods. The lack of discussion on computational cost further contributes to the lack of actionability. The reviewer's questions are not just 'what' but also crucial 'why'. The paper presents the comparisons and costs but doesn't delve into the *reasoning* behind them.", "grounding_specificity_rationale": "The reviewer's questions about the rationale for comparisons and computational cost are not explicitly linked to specific parts of the paper. The paper mentions the comparisons and computational costs but doesn't specify *where* in the paper these are relevant. For example, the paper might compare with 9 because it's a common baseline, but this isn't stated. Similarly, the paper might compare computational cost with 9 due to its accessibility, but this isn't explained. The lack of specificity makes it difficult to pinpoint the exact issues being addressed. The reviewer's questions are general and don't target specific sections, tables, or figures. The paper doesn't provide *specific* examples or references to support these claims. The lack of grounding makes it difficult for the authors to understand the *specific* issues being addressed.", "verifiability_rationale": "The reviewer claims that the paper lacks justification and verifiability. The paper states the computational cost but doesn't provide *reasons* or *evidence* to support this claim. The paper presents the comparisons and computational costs but doesn't explain *why* these are important or *why not* compare with other methods. The lack of justification and evidence makes it difficult to verify the claims made in the paper. The reviewer's questions highlight the absence of logical reasoning and external references to support the claims. The paper presents the information but doesn't provide the *why* or the *how*.", "helpfulness_rationale": "The reviewer's concerns about the lack of justification and grounding significantly impact the helpfulness of the review point. The paper states the comparisons and computational costs but doesn't explain *why* these are important or *why not* compare with other methods. The lack of justification makes it difficult for the authors to understand the *rationale* behind these choices. The paper mentions the computational cost but doesn't specify *where* in the paper this is relevant, making it difficult for the authors to understand the *implications* of this cost. The lack of discussion on computational cost further contributes to the lack of helpfulness. The reviewer's questions are not just 'what' but also crucial 'why' and 'how', which are missing from the paper."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests \"conducing experiments\" or \"conducting experiments,\" which is an explicit action. However, the reviewer does not provide concrete details on how to apply this action, such as which additional datasets to use, how to analyze the results, or what specific aspects of the method should be evaluated on these new datasets. The action is stated, but the implementation details are missing, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions \"more datasets\" but does not specify which particular datasets are lacking results or what characteristics of the datasets are relevant. The reviewer does not identify a specific section, table, figure, or unique aspect of the paper being addressed. The reference is general, and the authors cannot pinpoint the exact area of improvement.", "verifiability_rationale": "The reviewer states that there is a \"lack of experimental results on more datasets\". This is a claim that needs to be supported. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to back up this claim. The claim is made without sufficient justification or examples.", "helpfulness_rationale": "The reviewer suggests conducting experiments on 'more datasets'. While this is a relevant point for improving the evaluation of the proposed method, the suggestion lacks specific details and justification. The reviewer does not explain why more datasets are needed, what specific aspects of the method should be evaluated on these new datasets, or how the results should be analyzed. The feedback is present but lacks clarity and actionable steps, making it less helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' While they identify a lack of understanding, they don't explicitly state what is unclear or suggest a specific action to take. The reviewer's statement indicates a lack of clarity, but not a direct instruction on how to improve the draft based on this lack of clarity.", "grounding_specificity_rationale": "The reviewer states that 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' and 'All in all, the whole dataset transformation and the ensuing experimental setup felt very cumbersome, and not very clear.' The reviewer criticizes the process but does not identify a specific part of the paper or dataset that is unclear. They are broadly criticizing the process, not pinpointing a specific element within the paper.", "verifiability_rationale": "The reviewer states that 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' This statement can be considered a claim, as it expresses an opinion or a judgment about the clarity of the methodology. However, the reviewer does not provide any evidence or justification to support this claim. The criticism is about the lack of clarity of a process, not about the verifiability of a statement within the paper itself.", "helpfulness_rationale": "The reviewer states that 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' and 'All in all, the whole dataset transformation and the ensuing experimental setup felt very cumbersome, and not very clear.' This comment primarily criticizes the methodology without offering any suggestions or improvements. The reviewer does not provide any actionable feedback to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the PL condition and its relation to a specific paper. While it doesn't explicitly state an action or demand a change, it implicitly suggests that the PL condition used in the paper might be relevant to the work in the cited paper. This could be seen as a suggestion for improvement by prompting the authors to consider alternative PL conditions or a more thorough literature review. However, the action is not explicitly stated, making it less actionable.", "grounding_specificity_rationale": "The review point asks a question about the PL condition and its relation to a specific paper. It does not explicitly identify a specific part of the paper being addressed. The question is general and doesn't pinpoint a particular section, table, figure, or unique aspect of the paper. Therefore, the grounding is weak as the authors have to infer which part of their work the PL condition is relevant to.", "verifiability_rationale": "The review point asks a question about the PL condition and its relation to a specific paper. It does not contain a claim that requires verification. It's a question posed to the authors, not a statement that needs to be proven or justified. Therefore, verifiability is not applicable as there is X being made.", "helpfulness_rationale": "The review point asks a question about the PL condition and its relation to a specific paper. While this could be valuable information for the authors, it is a broad request and does not directly identify a weakness in their work or provide a specific suggestion for improvement. It encourages the authors to do more research but doesn't pinpoint an actionable step. Therefore, it is not 5 as it lacks specificity and directness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the 'complete lack of discussing the impact of adding additional parameters and additional computational effort'. This is a clear indication of an actionable point for the authors. While the action is not fully specified, the reviewer identifies a missing piece of information.", "grounding_specificity_rationale": "The reviewer mentions 'computational effort', 'multistage training', and 'multiple discriminators'. While they identify the *types* of information missing, they do not explicitly identify the specific section, table, figure, or unique element of the paper where this discussion is lacking. The grounding is present in the general areas of concern, but not in a precise location.", "verifiability_rationale": "The reviewer makes a claim: 'there is a complete lack of discussing the impact of adding additional parameters and additional computational effort'. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as an observation rather than a welljustified assertion.", "helpfulness_rationale": "The reviewer points out a specific and relevant weakness in the paper: the absence of a discussion regarding the computational cost implications of the proposed method. This is a clear and actionable feedback for the authors, highlighting a potential area for improvement in their analysis or presentation."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem: 'the analysis of the correlation between dataset size and the Frobenius norm and the singular values is underwhelming.' It also provides clear actions for improvement: 'the trend isn't clear across different model architectures' and 'no theoretical evidence is advanced'. These actions are concrete and directly address the identified issue.", "grounding_specificity_rationale": "The reviewer refers to 'the analysis of the correlation between dataset size and the Frobenius norm and the singular values' without specifying a particular section, table, or unique aspect of the paper. While the issue is specific to the analysis, the reference to the analysis itself is broad.", "verifiability_rationale": "The review point contains a claim: 'the analysis of the correlation between dataset size and the Frobenius norm and the singular values is underwhelming.' However, this claim is not supported by any evidence or justification within the review point itself. The reviewer states their opinion about the analysis's quality without providing specific examples or references to external works.", "helpfulness_rationale": "The review point identifies a clear weakness in the analysis: the lack of generalizability of the correlation across different model architectures and the absence of theoretical backing. It provides actionable suggestions: 'investigate different model architectures' and 'advanced theoretical evidence.' These suggestions are specific and directly address the identified limitations, making the review point valuable for guiding improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer raises a question about a potential flaw in the experimental setup (AutoAugment's training data) and its implications. While the question itself is not explicitly stated as an action, it implicitly suggests a need to consider the impact of the training data on the learned augmentation policy. This could be interpreted as an actionable suggestion for the authors to investigate the potential for information leakage and its consequences.", "grounding_specificity_rationale": "The reviewer mentions 'L114,' indicating they are referencing a specific part of the paper. They are also asking a question about the implications of a finding, which could be seen as indirectly referring to a specific section. However, the question is more about the *implications* of a potential flaw rather than a direct critique of the content at that specific location. Therefore, it can be considered weakly grounded as the reference is explicit, but the subsequent question is more about interpretation.", "verifiability_rationale": "The reviewer is making an inference about a potential flaw in the experimental setup (AutoAugment's training data) and its implications for SSL algorithms. While the general idea of information leakage is a known concept, the specific claim about AutoAugment's policy being obtained through supervised training on ImageNet and the resulting information leakage is a plausible hypothesis. The reviewer also raises a question about the impact on SSL algorithms that strive for generic representations, which could be supported by logical reasoning about the nature of pretraining and SSL. Therefore, the claim is 3 as it is based on logical reasoning and common knowledge in the field, although the specific details might require further investigation.", "helpfulness_rationale": "The reviewer raises a valid concern about a potential flaw in the experimental setup (AutoAugment's training data) and poses a relevant question about its implications for SSL algorithms. This could help the authors refine their understanding of the relationship between pretraining data, augmentation strategies, and SSL. The question about whether matching datasets is a setback for SSL and the connection to combining datasets are also relevant and thoughtprovoking. This review point offers valuable insights and raises important questions for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "6: X (X)", "helpfulness_label": "1", "actionability_rationale": "The review point suggests an *interesting* possibility but doesn't *imply* any action. It's a statement of fact about a potential future direction. While it points out a potential area, it lacks the explicit and concrete actions needed for actionability. Therefore, it's 2 as it doesn't clearly state what needs to be done or how to do it.", "grounding_specificity_rationale": "The review point is about *general* multimodal data, not specifically about a particular section, table, figure, or unique element within the paper. The reviewer is making a general observation about a potential future direction, not referencing a specific part of the current paper. Therefore, it doesn't ground the discussion in a specific part of the paper, making it **1**.", "verifiability_rationale": "The review point is a suggestion for future research. It's not presenting a claim that needs verification. It's an *interesting* observation, not a critique or a statement of what *is* lacking. Since it's not a claim, there's no evidence to assess its verifiability. Therefore, it's **X (X)**.", "helpfulness_rationale": "The review point is about exploring multimodal data as a future direction. While interesting, it doesn't directly address *any* specific weaknesses or improvements in the *current draft*. It offers a potential avenue for future work but doesn't provide immediate, actionable feedback for improving the existing paper. Therefore, it's **1**."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The first part of the review point, 'For the languageagnostic characters of entity representations, the paper has weak analysis on the alignment of entity representations,' is an **implicit** action. The reviewer doesn't explicitly state what they want to do, but rather points out a deficiency in the existing analysis. It is also **vague** because it doesn't specify what aspects of the alignment are weak or how the analysis is lacking. The second part, 'the authors could add more analysis about the multilingual alignment of entity representations,' is an **explicit** action, as the reviewer directly states they want more analysis. However, it is **vague** because it doesn't specify what kind of analysis, how much more, or what specific aspects of alignment they want examined. Overall, the review point lacks clear and concrete actions or suggestions.", "grounding_specificity_rationale": "The first part of the review point, 'For the languageagnostic characters of entity representations, the paper has weak analysis on the alignment of entity representations,' is **weakly grounded**. The reviewer mentions 'entity representations' and 'alignment' but doesn't explicitly identify a specific section, table, figure, or unique aspect of the paper where this weakness manifests. While the concepts are related to the paper, the connection isn't clearly established. The second part, 'the authors could add more analysis about the multilingual alignment of entity representations,' is also **weakly grounded**. Similar to the first part, the reviewer mentions 'multilingual alignment' and 'entity representations' but doesn't pinpoint a specific section or aspect where this analysis is lacking. Although the mention of 'language families' and 'lowresource languages' adds a bit of specificity, the overall suggestion remains broad and doesn't directly point to a concrete part of the paper.", "verifiability_rationale": "The review point makes a claim: 'the paper has weak analysis on the alignment of entity representations.' This is a statement of opinion or judgment. However, the **verifiability** of this claim is **low**. The reviewer states the weakness but doesn't provide any evidence, logical reasoning, or external references to support this claim. There are no specific examples or references to external works that would justify the assertion of 'weak analysis'. The reasoning provided is simply a statement of opinion without any backing.", "helpfulness_rationale": "The review point provides **specific areas for improvement**, such as 'multilingual alignment,' 'language families,' and 'lowresource languages.' This suggests a desire to enhance the paper. However, the **helpfulness** is **low** because the reviewer doesn't provide any concrete evidence or reasoning to support their claim about the 'weak analysis.' Without evidence, the authors have no basis to understand what specific changes are needed or how to approach them. The suggestion to 'add more analysis' is broad and lacks direction, making it less helpful than a more specific suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a need for more details but lacks specific instructions on how to achieve this or where to implement the suggestion. It points to a potential area for improvement but doesn't specify the exact changes required or the location for these changes.", "grounding_specificity_rationale": "The comment refers to 'attention' generally, without specifying which part of the paper it relates to, and mentions 'an extra appendix' without linking it directly to the attention concept. The reference to 'attention' is vague, and the suggestion of an appendix is a specific location but not a specific part of the paper being discussed.", "verifiability_rationale": "The comment is a suggestion for improvement, not a claim that requires verification or justification. There is no assertion of a problem that needs to be proven or supported with evidence.", "helpfulness_rationale": "The comment identifies a valid area for improvement (more details) and suggests a reasonable location for it (appendix). While it doesn't provide specific *howto* details, it points in a helpful direction by suggesting a place to add more information."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the issues: 'duplicates' and 'missing publication venues' and 'missing publication years'. This indicates that the authors should be aware of these problems. However, it doesn't provide specific instructions on how to address them, making it 3 but not fully actionable.", "grounding_specificity_rationale": "The comment refers to the 'references list' but doesn't specify the exact section, table, figure, or unique element within that list where the issues are present. While it identifies the general area (references), it lacks precise grounding. The specificity is also limited as it doesn't detail *which* duplicate entries or *which* papers are missing.", "verifiability_rationale": "The comment contains a claim: 'The references list contains duplicates and the publication venues and/or the publication years of many of the papers are missing.' However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The implications are implied (inaccurate citations can harm credibility), but there is no explicit justification for why these are problems or how they should be addressed.", "helpfulness_rationale": "The comment identifies a significant issue with the references section, which is crucial for academic integrity. However, it lacks specific suggestions or guidance on how to improve the references. The authors are informed about the problems but are left without concrete steps to take, making it 3 but not 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the theoretical analysis in Theorem 1 is unclear and weak. They also point out that the error bound in Theorem 1 is not welldefined and that the analysis needs to be compared with other comparable methods. These are concrete actions that the authors can take to improve their understanding of the theoretical analysis.", "grounding_specificity_rationale": "The reviewer specifically mentions 'The theoretical analysis in Theorem 1' and highlights the 'error bound' as the problematic element. They also suggest comparing with 'comparable methods'. This indicates a strong grounding of the comment in the specific part of the paper and the nature of the issue.", "verifiability_rationale": "The reviewer makes a claim that the theoretical analysis is unclear and that it needs to be compared with other comparable methods to understand the error bound. This claim is 3 as the reviewer provides a method (comparing with other methods) for the authors to assess the clarity and meaning of the analysis. However, the reviewer does not provide specific examples or references to support this claim within the review point itself.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the theoretical analysis and provides a specific suggestion for improvement: clarifying the error bound and comparing it with other methods. This is a 5 and constructive comment that directly addresses a potential area of confusion for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks 'why the explicit methods perform better than implicit methods on the locomotion tasks'. This is a direct question about a relationship between two concepts. The reviewer also points out that the pseudocode of the proposed method is missing, which is a specific detail. While the question itself is somewhat general, the identification of the missing pseudocode adds a concrete element.", "grounding_specificity_rationale": "The review point mentions 'locomotion tasks' and the performance difference between 'explicit methods' and 'implicit methods'. While it doesn't explicitly identify a specific section, table, figure, or unique aspect of a paper, the general concepts are referenced. The reviewer also points out the 'missing pseudocode of the proposed method', which could be interpreted as implicitly referring to a specific implementation detail. However, without further clarification, the grounding is not as precise as 'fully grounded'.", "verifiability_rationale": "The review point contains a claim: 'why the explicit methods perform better than implicit methods on the locomotion tasks'. However, this claim is not supported by any logical reasoning, common knowledge, or external references within the review point itself. The reviewer simply states the observation and the missing pseudocode without explaining the underlying reasons or providing evidence. The statement 'the pseudocode of the proposed method is missing' is also a factual observation but doesn't explain why it's relevant to the performance difference.", "helpfulness_rationale": "The review point raises a relevant question about the performance difference between explicit and implicit methods, which is a common concern for researchers in the field. The reviewer also highlights the absence of pseudocode, which is a specific implementation detail that could be helpful for understanding and reproducing the proposed method. The combination of a relevant observation and a specific detail makes the review point helpful."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly mentions 'lowresource language pairs' and 'multilingual model' as potential limitations, which are direct actions or suggestions for the authors. However, the suggestion to 'use the method like R3F' is vague and lacks specific details on how to implement it. The lack of specificity makes it difficult for the authors to take concrete action based on this suggestion.", "grounding_specificity_rationale": "The reviewer refers to 'lowresource language pairs' and 'multilingual model' as areas needing further finetuning and the use of the R3F method. While these are specific parts of the model or data, the reviewer does not explicitly state which specific section, table, figure, or unique aspect of the paper they are addressing. The criticism about the 'insignificant improvement' is also not tied to a specific part of the paper.", "verifiability_rationale": "The reviewer makes a claim: 'Missing References: Aghajanyan, Armen, et al. 'Better FineTuning by Reducing Representational Collapse.' International Conference on Learning Representations. 2020.' However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a fact without justification.", "helpfulness_rationale": "The review point identifies a potential limitation regarding lowresource language pairs and suggests considering the R3F method. While this offers a direction for improvement, the lack of specificity regarding the R3F method and the missing reference make it difficult for the authors to understand the practical implications or how to implement it. The criticism about the 'insignificant improvement' is a valid point but does not provide a concrete solution or actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer is implicitly suggesting that the authors should broaden their experimental validation to include other types of image noise. While they don't explicitly state 'improve the experiments,' the question implies a desire for more comprehensive results. This is a form of implicit actionability.", "grounding_specificity_rationale": "The reviewer explicitly points out the discrepancy between the claim of the model working for various image noise types and the actual experimental results being shown only for Gaussian noise. They directly identify the specific part of the paper (the experimental section) and clearly state what is missing (results for other noise types). This is a clear and explicit identification of the gap.", "verifiability_rationale": "The reviewer makes a claim about the model's applicability to various image noise types and then identifies a lack of supporting evidence in the paper \u2013 specifically, the absence of results for noise types other than Gaussian. This claim is not explicitly justified by any reasoning, common knowledge, or external references within the review point itself. Therefore, the verifiability is somewhat lacking.", "helpfulness_rationale": "The reviewer's comment directly points to a concrete area for improvement in the paper \u2013 the limited scope of the experimental validation. They suggest that the authors should include results for other types of image noise to support the claim of broader applicability. This is a clear and helpful suggestion that directly addresses a gap in the current work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding a visualization to address the performance decline, which is a concrete action. However, it does not specify the exact steps or tools to use for creating the visualization, making the action implicit rather than fully explicit. The action is also somewhat vague as it doesn't detail the specific aspects of the performance decline to visualize.", "grounding_specificity_rationale": "The review point discusses the general issue of performance decline in PU learning with increasing dimensionality. It does not explicitly refer to a specific section, table, figure, or unique aspect of the paper. While it identifies a problem, it doesn't pinpoint the exact location or nature of the problem within the paper, making the grounding weak. The specificity is also somewhat vague as it doesn't detail the type of visualization or the specific performance metrics to be analyzed.", "verifiability_rationale": "The review point is a suggestion for improvement rather than a claim that needs verification. It doesn't make any assertions about the current state of the paper or propose solutions based on evidence. Therefore, it doesn't fall under the 'Claim Extraction' category, and there's no evidence to assess its verifiability.", "helpfulness_rationale": "The review point identifies a relevant area for improvement by suggesting a visualization to address the performance decline. This directly relates to the stated motivation of the paper. However, it lacks specific guidance on *how* to create the visualization, making it a helpful suggestion but not fully actionable or detailed enough to be fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the suggestion to move the empirical result to supplementary materials. This action is directly identified, making it explicit. Furthermore, the reviewer clearly states *where* to move the result, which is the supplementary materials, making the action concrete.", "grounding_specificity_rationale": "The reviewer mentions the 'empirical version of the objective (3)' but does not explicitly identify the specific section, table, figure, or unique aspect of the paper being addressed. The reference is implicit, implying the relevant part is related to objective (3). Therefore, the grounding is weak. The comment also does not specify what is wrong or missing in this part, focusing solely on the location of the result. Thus, the specificity is also low.", "verifiability_rationale": "The reviewer's comment does not contain a claim in the sense of stating an opinion or judgment about the paper. They are simply suggesting a change in the presentation format. Therefore, there is X to be verified.", "helpfulness_rationale": "The reviewer provides a suggestion to move the empirical result to supplementary materials. While this is a straightforward suggestion, it directly addresses the presentation of a key result and helps the authors organize their paper more effectively. It is helpful, though not a profound critique or suggestion for major changes."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests looking at 'topography plots' and 'differences in figures' as a way to investigate the issue. While 'topography plots' is somewhat general, it's a specific type of visualization. The reviewer also provides a concrete *method* for investigation: 'Although the topography plots plots seem to indicate something reasonable going on.'", "grounding_specificity_rationale": "The reviewer refers to 'result description' and 'figures,' which are reasonably clear indicators of the section and figures being discussed. They also mention ' listener gets reset,' which points to a specific concept within the result description. The reviewer then suggests investigating 'topography plots' and examining 'differences in figures,' which are specific to the content of those sections.", "verifiability_rationale": "The reviewer makes a claim that 'the differences in figures seem too small' and suggests investigating 'topography plots' and 'differences in figures.' They also provide external references and logical reasoning to support their claim, such as 'related ideas of speakerlistener communication from a teachability perspective' and 'check that useful communication is actually happening.'", "helpfulness_rationale": "The reviewer identifies a potential issue with the interpretation of results ('differences in figures seem too small') and provides specific suggestions for investigation, including 'a related idea of speakerlistener communication from a teachability perspective' and examining 'topography plots' and 'differences in figures.' These suggestions are clear and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests providing a 'mathematical characterization' of the approximation error. While they don't explicitly state the formula or method, the suggestion implies a concrete action: 'Calculate the error using this formula' (concrete). However, the reviewer doesn't explicitly state the formula or method, making the action implicit rather than explicit. Therefore, it's 3 as the reviewer clearly indicates a desire for a mathematical approach, but the specific steps are not laid out.", "grounding_specificity_rationale": "The reviewer refers to 'the approximation error' and 'objective values.' While they understand the general concept of the error and the values involved, they don't explicitly point to a specific section, table, figure, or unique element of the paper where these values are located. The reviewer's comment is general and doesn't provide precise grounding. Therefore, it's 2.", "verifiability_rationale": "The reviewer makes a claim: 'It would be better to provide a mathematical characterization.' This is a clear statement and a suggestion for improvement. The reviewer's statement is logically sound and based on a common understanding of how to define errors. While the reviewer doesn't provide the mathematical details in this review point, the suggestion itself is verifiable based on general knowledge of mathematical definitions and error analysis. Therefore, it's 3 as the suggestion is logically sound and based on common practices, even if the reviewer doesn't provide the details.", "helpfulness_rationale": "The reviewer explicitly states their desire for a 'mathematical characterization' of the approximation error. This directly addresses a potential ambiguity and provides a concrete direction for improvement. The reviewer's suggestion is actionable and directly targets a potential weakness in the paper. Therefore, it's 5 as the reviewer clearly indicates a desire for a mathematical approach, which directly addresses a stated problem."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly points out a specific issue with a technical claim (Corollary 10) and provides a clear action for the authors: to understand the difference between minimizing the expected 01 loss and the convex surrogate in this context. The action is explicit and concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Corollar 10' and discusses the concepts of 'uncertainty sampling', 'expected 01 loss', and 'expected convex surrogate'. This clearly identifies the specific part of the paper being addressed, making the grounding fully specific.", "verifiability_rationale": "The reviewer makes a claim about the interpretation of Corollary 10. While the claim itself might not be directly supported by external references, the reviewer's point about the interpretation of the corollary regarding the difference between 01 loss and convex surrogate is a logical deduction that can be verified by examining the mathematical details of the corollary and its proof (if available). Therefore, it is 3.", "helpfulness_rationale": "The reviewer's point is highly specific and directly addresses a potential area of confusion for the authors regarding a technical detail. By clarifying the relationship between the 01 loss and the convex surrogate in the context of Corollary 10, the reviewer provides a valuable insight that can significantly improve the authors' understanding. This makes the feedback 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitations of the model, such as the slow dynamics due to the reassignment probability and the simplicity of the evolution model. These are direct observations of the model's behavior.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed model' and 'the reassignment probability' without specifying a particular section, table, or unique aspect of the paper being addressed. While the concept of the model is implied, the specific part of the paper being criticized is not clearly identified.", "verifiability_rationale": "The reviewer makes claims about the model's behavior (e.g., 'only produces 1 node changing cluster per time step on average' and 'allows for only very slow dynamics') without providing any supporting evidence or justification. There is no logical reasoning, common knowledge, or external references to back up these statements.", "helpfulness_rationale": "The reviewer identifies limitations of the proposed model. While these criticisms are valid, they do not offer specific suggestions or guidance on how to improve the model or the draft. The feedback is primarily about what is wrong rather than how to fix it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing details: \"missing details about division to train and test sets, numbers as well as how the division was made (simply random? Any other considerations?)\". This directly points to what needs to be addressed, making it explicit. Furthermore, the reviewer provides specific information (numbers, description of the method) that should be included, making it concrete.", "grounding_specificity_rationale": "The reviewer points out a deficiency in the paper but does not specify *which* part of the paper is lacking these details. They are broadly criticizing the lack of information regarding the train/test split. While they mention \"numbers\" and \"how the division was made,\" they don't point to a specific section or table in the paper where this information is missing. The criticism is about the absence of information in general, not about a specific element.", "verifiability_rationale": "The reviewer does not make a claim in the traditional sense of stating an opinion or judgment. They are pointing out a deficiency or a missing piece of information. However, the lack of specific information about the train/test split can be considered implicitly verifiable. The reviewer is essentially saying, \"If you did this, you should have included these details.\" While there are no explicit examples or references provided to verify the absence of this information, the reviewer's suggestion implies a verification of the gap. Therefore, it's underspecific as the reviewer doesn't pinpoint where the information is missing, but the absence of it is a verifiable fact.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, including crossvalidation, which directly addresses the lack of detail regarding the train/test split. They are not asking for a general review but are actively suggesting concrete steps the authors should take. This makes the feedback 5 and directly helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the 'lack of automation' in building text descriptions and the 'variability' of optimal textual formats, providing clear actions for improvement. While the specific type of format and the exact tasks aren't pinpointed, the suggestion to explore different formats is a concrete action the authors can take.", "grounding_specificity_rationale": "The reviewer mentions 'text descriptions for each task' and 'optimal textual format,' but the 'each task' aspect is general, leading to weak grounding. However, the reviewer does specify a direction for improvement ('exploring different textual formats') within the realm of text descriptions and optimal formats, indicating some level of specificity within the suggested area.", "verifiability_rationale": "The reviewer presents observations about the 'lack of automation' and 'variability' without providing any evidence, justification, or references to support these claims. The statement is presented as a statement of observation and a suggestion for future work, but lacks the supporting elements needed for verifiability.", "helpfulness_rationale": "The review point raises a practical concern about the current reliance on human labor and suggests a potential area for future research or development by exploring different textual formats. While it doesn't offer a definitive solution, it provides a clear observation and a direction for improvement, making it a 3 comment."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point mentions a 'performance improvement' and a specific number (0.02). It also suggests an alternative way to present the data (tables). While it points to a *potential* improvement, it doesn't explicitly state *what* needs to be done. The suggestions are highlevel.", "grounding_specificity_rationale": "The review mentions 'the bank dataset' and 'figure 3'. This shows an attempt to refer to a specific part of the paper. However, it doesn't explicitly state the *section*, *table*, or *unique aspect* being addressed. The grounding is implicit.", "verifiability_rationale": "The review states 'the performance improvement of proposed methods seems not so significant, the biggest improvement in the bank dataset was ~0.02.' This is a claim. However, the review *mentions* the 0.02 improvement but doesn't *explain* why it's not significant or *refer to external literature* to support this claim. The justification is weak.", "helpfulness_rationale": "The review provides some relevant information about the results and suggests a way to improve clarity. However, the suggestions are general and don't pinpoint the exact cause of the lack of significant improvement. The advice on using tables is highlevel and doesn't provide specific guidance on how to create them or what data to present. The feedback is relevant but lacks the specific and actionable advice needed to help the authors improve their draft significantly."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the limitations of the experimental validation, mentioning 'only shallow networks are considered (2 or 3 layers)' and 'the optimization strategy, including the grid search strategy for hyperparameters selection, is not described.' These are concrete actions the authors should take. While the positioning point is more of a minor issue, the explicit nature of the experimental validation criticism makes it partially actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'experimental validation' and then narrows it down to 'shallow networks' and 'optimization strategy.' This indicates a clear identification of the specific aspect being addressed, making it fully grounded. The comment also specifies what is lacking: 'the optimization strategy, including the grid search strategy for hyperparameters selection, is not described.' This adds to the grounding and specificity.", "verifiability_rationale": "The comment contains a claim: 'Experimental validation are not convincing.' This claim is partially verifiable. While the reviewer points out 'only shallow networks are considered (2 or 3 layers)' and 'the optimization strategy, including the grid search strategy for hyperparameters selection, is not described,' these points could be considered somewhat underspecific in the context of directly verifying the 'convincingness' of the validation. However, they do provide some basis for understanding why the validation might be limited. The lack of external references is also implied but not explicitly stated.", "helpfulness_rationale": "The comment raises concerns about the experimental validation, which is a relevant and actionable area for improvement. The reviewer provides specific points of criticism, such as the use of shallow networks and the lack of detail on the optimization strategy. While the positioning point is a minor issue, the feedback on the experimental validation is likely to be helpful for the authors in understanding the limitations of their work and how to improve it. The suggestion to compare with related work on layer redundancy is also a valuable direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out that the work does not prove any new theoretical results. While this is a clear statement of a weakness, the reviewer does not explicitly state how to address this lack of theoretical results or what specific changes are needed. The weakness is identified, but the action to improve is not detailed.", "grounding_specificity_rationale": "The reviewer refers to 'this work' and 'this setting' when mentioning the lack of new theoretical results. This suggests an attempt to ground the comment in the specific context of the paper. However, the reviewer does not specify *which* theoretical results are missing or how they relate to the specific loss function and setting. The grounding is present but not fully specific.", "verifiability_rationale": "The reviewer states that 'this work does not prove any new theoretical results.' This is a claim that needs to be supported. However, the reviewer does not provide any evidence or reasoning to back up this claim. The statement is presented as a potential reason for the lack of theoretical results, but without further justification or references, it remains 1.", "helpfulness_rationale": "The reviewer's comment identifies a clear weakness in the work \u2013 the absence of new theoretical results. This is a valuable piece of feedback for the authors, as it highlights a potential area for future research and improvement. While the comment doesn't provide specific steps on how to address this, it points to a meaningful gap in the theoretical contribution, making it helpful in guiding future work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a hypothesis about the 'trivial part' and 'impossible part' of the images. This directly points to a specific area within the paper that needs further investigation. The reviewer also asks for evidence to support this hypothesis, which is a clear action for the authors to take. The explicit nature of the action (identifying a specific area and asking for evidence) makes it 5.", "grounding_specificity_rationale": "The reviewer refers to 'trivial part' and 'impossible part' without explicitly naming them or specifying their location within the paper. This makes the grounding weak. However, within the *proposed* trivial and impossible parts, the reviewer offers specific examples like 'consistent training data' or 'ambiguous labels'. This demonstrates a level of specificity within the vague grounding. Therefore, it's somewhat grounded but not fully specific.", "verifiability_rationale": "The reviewer proposes a hypothesis and asks for evidence to support it. This constitutes a claim that needs to be verified. While the reviewer provides some reasoning for the hypothesis, it's based on intuition and general observations rather than direct, verifiable facts or external references. The claim is present, and there's some justification, but it lacks strong support. Therefore, it's 3.", "helpfulness_rationale": "The reviewer directly asks the authors for evidence to support their hypothesis. This is a clear and actionable request that directly addresses a potential weakness or area for improvement in the authors' work. The request is specific enough to guide the authors' investigation. Therefore, it is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment implicitly suggests an action: investigating the performance of the model on other 'bAbI' tasks. While it doesn't explicitly state 'look at Task 2 and Task 3', the mention of 'other tasks' implies this. However, the action is vague as it doesn't specify how to go about this investigation or what to expect.", "grounding_specificity_rationale": "The comment mentions 'single supporting fact dataset' and 'other tasks' of the 'bAbI' project. While it identifies a category of datasets, it doesn't specify a particular paper, section, or table within the 'bAbI' literature that was used. The grounding is weak because the authors cannot confidently determine which part of the 'bAbI' literature is being addressed.", "verifiability_rationale": "The comment doesn't make a claim that can be verified. It's a suggestion for further experimentation rather than a statement that requires justification. Therefore, there's no evidence to assess its verifiability.", "helpfulness_rationale": "The comment provides a suggestion for further investigation, which can be considered a form of actionable feedback. However, it lacks specific details on how to investigate 'other tasks' or what the expected outcome should be. Therefore, it's 3 but could be more concrete."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The statement 'The technical contribution is limited' is a direct and explicit identification of a problem. It clearly indicates that the paper lacks significant novelty or advancement in its technical aspects. The reviewer directly points out the weakness, making it actionable for the authors to understand what needs improvement.", "grounding_specificity_rationale": "The statement 'The technical contribution is limited' is 1 at a specific technical aspect. While it identifies a problem related to 'technical contribution', it doesn't pinpoint the exact area within that contribution that is limited. It refers to a broad category rather than a specific element of the work.", "verifiability_rationale": "The statement 'The technical contribution is limited' is a claim that requires verification. To fully verify this, the reviewers would need to compare the paper's technical approach with established standards and typical models in the relevant field. While the statement itself is a claim, fully supporting it would require external references and a detailed analysis of the paper's technical details. Therefore, it is partially verifiable.", "helpfulness_rationale": "The reviewer's comment is 5 as it points out a potential weakness in the paper's technical contribution. By highlighting this, the reviewer provides valuable feedback for the authors to understand the limitations of their work and identify areas for improvement. This type of feedback is crucial for constructive peer review."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The reviewer is pointing out a potential issue (time complexity) related to the algorithm. While they don't explicitly state what action they would take, they identify the problem and its potential impact, which constitutes an implicit action. The specificity of the action is that it's about the hypervolume calculation in LaMOO.", "grounding_specificity_rationale": "The reviewer mentions 'hypervolume calculation' and 'LaMOO algorithm' generally. They do not explicitly identify a specific part of the paper they are referring to, such as a particular section, table, or figure. The mention is broad and doesn't pinpoint a specific element within the paper.", "verifiability_rationale": "The reviewer makes a claim about the impracticality of LaMOO for manyobjective problems due to hypervolume calculation. This is a claim that requires justification. While the claim is plausible based on general knowledge of hypervolume calculation complexity, the reviewer does not provide specific references or examples within this review point to support the claim.", "helpfulness_rationale": "The reviewer raises a concern about the scalability of LaMOO. However, they do not offer any suggestions or solutions to address this concern. The review point is primarily a question or observation, not a suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "None", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The comment suggests a potential improvement for future work by using larger datasets. While this is a valuable suggestion, it does not directly instruct the authors on what changes to make to their current paper. The authors are aware of their paper, and the comment is about the experimental setup, not the content of the paper itself. Therefore, it does not provide explicit or direct actions that the authors should take to improve their draft.", "grounding_specificity_rationale": "The comment refers to 'the dataset used in the experiments' as a potential area for improvement. While this relates to the paper's experimental validation, it does not specify a particular section, table, figure, or unique aspect of the paper that needs improvement. The suggestion is about the experimental setup in general, not a specific flaw or area within the paper. Therefore, it does not identify a specific part of the paper being addressed.", "verifiability_rationale": "The comment does not contain a claim or assertion about the paper's quality or specific issues. It is a suggestion for future work, not a critique or evaluation of the current paper's content or methodology. There is no logical reasoning, common knowledge, or external references provided to support a claim. Therefore, it does not make a claim that requires verification.", "helpfulness_rationale": "The comment offers a suggestion for future research by proposing the use of larger datasets. While this is a valuable and potentially helpful suggestion, it does not directly address any perceived weaknesses or areas for improvement in the current paper. The authors are aware of their paper, and the comment is about the experimental setup, not the content of the paper itself. Therefore, it does not provide actionable feedback that empowers the authors to significantly improve their draft."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "2 (3)", "verifiability_label": "2 (Weakly Verifiable)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer suggests 'honest and direct feedback' and asks a question ('What does 'brittle convergence properties mean'?'). These actions are explicit, but the level of detail in the question is low, making the actionable part somewhat vague. Explicit actions are generally considered more actionable than implicit ones.", "grounding_specificity_rationale": "The reviewer mentions 'evolutionary methods,' 'state, reactiveness, and learning during an episode,' and 'brittle convergence properties' as areas for improvement. While they *mention* these areas, they don't explicitly state *which* specific part of these broad categories they are criticizing. The title is mentioned generally without a specific connection to a detail. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes claims about the limitations of evolutionary methods and the adoption of DeepRL. While they *suggest* these are limitations, they don't provide specific evidence or references to back up these claims within the review point itself. The request for clarification ('What does 'brittle convergence properties mean'?') indicates a lack of immediate understanding or justification for their point. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer provides specific suggestions ('honest and direct feedback') and asks a question. The act of providing feedback is generally considered helpful. While the depth and clarity could be improved, the *act* of offering feedback makes it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies the key steps and challenges in the methodology, but it doesn't explicitly state what the authors should do with this information. The questions posed are clear and direct, indicating an explicit action, but the answers are not provided, making it 3.", "grounding_specificity_rationale": "The review point explicitly refers to 'the paper' and asks specific questions about its components (focal stack, defocus map, image, edges). This makes it 5.", "verifiability_rationale": "The review point presents a claim that the authors need to understand how the focal stack is synthesized and the challenges at image edges. It doesn't provide explicit justification or references for this claim, making it 3.", "helpfulness_rationale": "The review point raises several important questions about the methodology and implementation details of the paper. These questions directly address potential gaps in the authors' understanding and could significantly improve their work. The questions are clear and specific, making it 5 for the authors to address these points."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests 'there should be some empirical justification'. This is a direct and explicit action the reviewer proposes. While the reviewer doesn't specify *how* this empirical justification should be done, the suggestion itself is clear and actionable for the authors. Therefore, the action is explicit, even if not fully concrete.", "grounding_specificity_rationale": "The reviewer refers to 'the first claimed contribution' of the paper. This indicates they are specifically addressing a previously stated claim. They also mention 'points' and 'apriori knowledge about dimensions of subspaces,' which likely refers to specific details or descriptions in the paper. This shows the reviewer is identifying a weakness in a specific part of the paper's claims. Therefore, the grounding is explicit and specific to the claim being discussed.", "verifiability_rationale": "The reviewer makes the claim that the paper lacks 'empirical justification' for its first contribution. This is a clear statement of a deficiency. They also suggest 'there should be some empirical justification,' providing a logical reasoning for why this is a desirable addition. This supports the claim with a clear justification.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential weakness in the paper's presentation of its contribution. They suggest adding 'empirical justification,' which is a concrete and actionable suggestion for the authors. This is a valuable and constructive comment that directly helps improve the paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the lack of novelty in the approach, the use of nonnovel algorithms (MLP, Regression Tree, Random Forest), the similarity of the sampling strategy to existing methods (epsilongreedy, BRPNAS), and the similar performance results. These are all direct statements that the authors can directly identify modifications they should apply to their draft. The reviewer provides specific examples of the algorithms used and refers to a table in the appendix, making the suggestions concrete enough for the authors to investigate.", "grounding_specificity_rationale": "The reviewer does not explicitly name a specific section, table, or figure in the paper where the lack of novelty is discussed. They refer to 'the approach' and mention the algorithms and sampling strategy generally. However, they do specify what aspects of the approach are being criticized (the algorithms and the sampling strategy) and even refer to a table in the appendix (Table 2 in Appendix C) where the performance is compared. This makes the grounding somewhat weak but the specificity of the critique is high.", "verifiability_rationale": "The reviewer makes a claim that the proposed method lacks novelty and uses similar techniques to existing work. This is a clear claim that requires verification. The reviewer provides specific examples of the algorithms used (MLP, Regression Tree, Random Forest) and the sampling strategy (similar to epsilongreedy and exactly the same as BRPNAS). These provide sufficient justification for the claim. The reviewer also points out the similar performance results, which further supports the claim and makes it verifiable.", "helpfulness_rationale": "The reviewer provides several concrete points for the authors to consider. They point out specific algorithm choices (MLP, Regression Tree, Random Forest), a sampling strategy (similar to epsilongreedy and BRPNAS), and a performance comparison. These points directly help the authors understand the limitations of their approach and potential areas for improvement. The reviewer's criticism is wellsupported by specific examples and references to existing work, making it 5 for the authors to understand and address the identified issues."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a concern about the similarity of the proposed S1DBED algorithm to RMED and the lack of discussion about this similarity in the paper. This directly points to a potential issue and identifies the area where more discussion is needed. The reviewer clearly identifies the potential problem and the area where more discussion is needed. The reviewer explicitly states the concern and the area of improvement.", "grounding_specificity_rationale": "The reviewer names the proposed S1DBED algorithm and the existing RMED algorithm by name. They also specify the concern is about the similarity and the lack of discussion. This is very specific. The reviewer isn't just saying 'the algorithms are similar'; they're pointing to a *specific* area of the paper where this similarity needs to be addressed. This is **fully grounded** and **specific**. The reviewer names the specific algorithms and the area of concern, making it highly specific.", "verifiability_rationale": "The reviewer makes a judgment about the *novelty* of the algorithm based on the similarity to RMED. This is a claim that needs to be supported. While the reviewer doesn't provide *new* evidence, they are highlighting a potential issue that the authors should consider. This claim is **partially verifiable** because it points to a potential problem that the authors could investigate further (e.g., by looking at the differences between the algorithms and the impact of the similarity). The reviewer makes a claim about the similarity and its impact on novelty, which can be verified by examining the algorithm details and existing literature. The reviewer's statement about similarity and limited novelty is a claim that can be supported by examining the algorithm details and existing literature, making it partially verifiable.", "helpfulness_rationale": "The reviewer clearly states a concern about the similarity of the proposed S1DBED algorithm to RMED and the lack of discussion about this similarity in the paper. This directly helps the authors improve their paper by highlighting a potential lack of novelty and prompting them to include a more thorough comparison with RMED. This is a 5 comment because it directly addresses a potential weakness and guides the authors to a specific area for improvement. The reviewer's comment directly addresses a potential weakness and guides the authors to a specific area for improvement, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point implicitly states that the authors should discuss previous work more comprehensively but does not explicitly tell them what to do. The authors need to infer the action from the comment, making it implicit.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper or a unique element being addressed. It only mentions the lack of a comprehensive discussion of previous work. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment refers to. The specificity is also low as the comment does not specify what aspects of previous work are missing or why a comprehensive discussion is needed.", "verifiability_rationale": "The comment states a fact (the authors did not give a comprehensive discussion) but does not provide any justification or examples to support this claim. It lacks external references or logical reasoning to back up the assertion. Therefore, it is not verifiable as it stands.", "helpfulness_rationale": "The review point identifies a valid weakness in the authors' draft (the lack of a comprehensive discussion of previous work) and suggests an improvement (adding more discussion). This points to a need for the authors to enhance their work. However, it does not provide specific guidance on *how* to improve this aspect, making it 3 but not fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "Partially Verifiable", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks multiple questions about the OT sample selection process and its relation to training. These questions are directly related to the paper's methodology and ask for specific details like 'onetime' or 'iterative' and 'runtime'. The reviewer is directly identifying modifications they should apply to their draft by clarifying these aspects.", "grounding_specificity_rationale": "The reviewer asks about the iterative nature of the OT sample selection process and the relationship between training steps and OT solving. These are specific aspects of the method. However, the reviewer also asks about the *purpose* of solving the OT problem, which is not explicitly stated in the paper. While the *process* is reasonably welldefined, the *purpose* could be clearer.", "verifiability_rationale": "The reviewer asks questions that are directly related to the paper's methodology. They are asking about the relationship between training and OT, which is a logical point. They are also asking about the *runtime*, which is a practical detail that *could* be found in the paper (if it were included). However, the paper doesn't explicitly state the runtime. The *purpose* of solving the OT problem is to select a representative subset of samples, which is a reasonable inference, but not explicitly stated.", "helpfulness_rationale": "The reviewer is directly addressing a potential point of confusion for someone trying to understand the method. They are asking for clarification on a key aspect of the training process. This is clearly beneficial for the authors who are trying to understand and potentially reproduce or improve the method."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing experiments for continuous tasks and the absence of empirical comparison for entropy methods. They also ask for specific actions, such as 'how to include experiments' and 'how to compare the empirical performance'. This indicates a clear and actionable feedback.", "grounding_specificity_rationale": "The reviewer implies the missing experiments are related to the discussion of continuous task settings in the paper. While they don't explicitly name a section, the context suggests the grounding is in the general idea of continuous tasks. The specificity is in pointing out the lack of experiments and comparison for entropy methods, but it's not as precise as identifying a specific table or figure. Therefore, it's somewhat grounded but not fully specific.", "verifiability_rationale": "The reviewer makes a clear claim about the missing empirical validation of entropy methods derived in the appendix. They also provide reasoning for why these methods are not included in the experiments, stating 'why are these not included in the experiments? How does the empirical performance of these methods compare to ConBO?'. This claim is supported by logical reasoning and the expectation of empirical validation for novel methods. Therefore, it is highly verifiable.", "helpfulness_rationale": "The reviewer's points are directly actionable and address specific shortcomings identified by the authors. They are asking for concrete improvements and comparisons, which are essential for the authors to address the weaknesses. The questions are clear and specific, making the feedback 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests a *specific* improvement: comparing GCG's transferability across LLMs. This is a clear indication of an explicit action. The reviewer also suggests *how* this comparison could be included, which further strengthens the actionability of the suggestion.", "grounding_specificity_rationale": "The reviewer refers to 'GCG' and 'other LLMs' which implies the relevance of their work. However, they don't explicitly point to a specific section, table, or figure in the original paper where this connection is most relevant. They could have mentioned a specific section or table, which would have improved grounding.", "verifiability_rationale": "The reviewer states 'It would be good if such a comparison *could be included*.' This clearly indicates a suggestion or claim. The reviewer also provides a *reason* for this suggestion: 'A minor point: The jailbreaking percentage is low for certain LLMs.' This provides a justification for the suggestion, making it verifiable.", "helpfulness_rationale": "The reviewer directly states the suggestion and its potential benefit: 'It would be good if such a comparison *could be included*.' This clearly indicates a desire for the authors to improve their work. The suggestion is actionable, and the reviewer provides a reason for why this comparison would be beneficial, making it helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they 'hope the author can give me a more detailed explanation'. This indicates a clear need for an explanation, making the review actionable. However, the action itself (providing the explanation) is not yet explicitly stated or implemented in the paper. The reviewer is aware of the concepts but needs guidance on their application.", "grounding_specificity_rationale": "The reviewer mentions 'similarity' and 'exit times in nature' as the core of their confusion. These are specific terms. However, the reviewer's lack of understanding suggests that the paper does not clearly ground the application of these terms within the context of unsupervised feature selection from a diffusion perspective. The terms are mentioned, but their specific meaning and relationship are not welldefined or explained in a way that makes the reviewer's confusion understandable.", "verifiability_rationale": "The reviewer makes a claim: 'I think this is a very novel thing for feature selection, but i can't understand what is the difference between similarity and exit times in nature.' This constitutes a claim that needs to be verified. The reviewer is stating a difference they believe exists (between similarity and exit times) and is expressing a lack of understanding of this difference. While the claim is about a difference, the reviewer doesn't provide any external references or logical reasoning to support this claim within the review point itself. The verifiability depends on whether the paper provides a clear explanation and justification for the relationship between these two concepts.", "helpfulness_rationale": "The reviewer explicitly states they 'hope the author can give me a more detailed explanation'. This is a direct and specific desire for feedback that directly addresses a core concept in the paper. The reviewer is clearly indicating that the current explanation is not sufficient for them to understand the difference between similarity and exit times. This constitutes 5 feedback as it directly addresses a perceived weakness in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking about the limitations of the framework, which implies a desire for improvement or clarification. While not directly stating a missing element, the question is related to actionable steps. Therefore, it's 3.", "grounding_specificity_rationale": "The reviewer's comment is general and doesn't specify a particular part of the paper or the framework's implementation. It's a broad inquiry about the framework's capabilities.", "verifiability_rationale": "The core of the review point is a question, not a statement that requires verification. Questions don't have the same verifiable evidence as claims.", "helpfulness_rationale": "The question about the framework's limitations is relevant for the authors. It helps them understand the scope and potential applicability of the framework, which is 3 for their decisionmaking process."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer's question directly addresses a potential point of confusion for the authors regarding the calculation of precision, recall, and F1score. They are asking for clarification on how these metrics were specifically calculated for the 4class classification of breast density. This is a direct request for information that could help the authors understand and potentially improve their model's performance. The reviewer is asking for a specific action (clarification) related to their work.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'precision/recall/F1score for 4class classification of breast density' and 'AUC results for comparisons'. This clearly grounds the feedback in the specific details of the authors' work. The reviewer is directly referencing the metrics and the context. This is strong grounding as the reviewer is directly referencing the specific aspects of the authors' work.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are suggesting an alternative evaluation metric (AUC) for model performance, specifically for breast cancer detection. This is more of a suggestion or critique rather than a statement that needs to be supported by evidence. While the suggestion is valuable, it's not a claim that needs verification in the sense of stating something that requires logical reasoning, common knowledge, or external references to be supported.", "helpfulness_rationale": "The reviewer's question is very specific and directly addresses a potential point of confusion for the authors regarding the evaluation of their 4class breast density classification model. They are asking for clarification on the calculation of precision, recall, and F1score. This is a clear and actionable request that directly impacts the authors' understanding and interpretation of their results. The reviewer is directly asking for information relevant to their work, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests an alternative to the dataset created by the authors (Kialo dataset) but does not explicitly state that the authors *must* use the Kialo dataset or provide a concrete action to take if they choose to follow this suggestion. The reviewer is presenting a potential solution without mandating its adoption.", "grounding_specificity_rationale": "The review point explicitly identifies the problem: \"the creation of the dataset is optional.\" It then provides specific reasons why the Kialo dataset might be preferable: \"the Kialo dataset is wellstudied in the community,\" \"it provides exactly what the authors need (pairs of short claims and their counters),\" and \"it is even cleaner (no automatic processes exist to construct it).\" This clearly grounds the suggestion in the authors' needs and the characteristics of an ideal dataset.", "verifiability_rationale": "The claim that \"the Kialo dataset is wellstudied in the community\" is generally verifiable based on common knowledge within the NLP community. The claim that \"it provides exactly what the authors need\" (short claims and their counters) is also generally verifiable based on common practices for dataset creation. The claim that it is \"cleaner\" is also verifiable by the absence of automatic construction processes compared to the dataset the authors created.", "helpfulness_rationale": "The review point offers a concrete alternative (the Kialo dataset) and highlights its potential benefits. It directly addresses the perceived limitation of the authors' current dataset by suggesting a wellestablished, readily available resource. This is a clear and actionable suggestion that directly helps the authors improve their draft by providing a readily available resource."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the limitations of the crosslayer attention modification in terms of providing significant machine learning insight and quantifies the improvement of selfcross attention. It also points out that the main improvements come from using a naive transformer. These are all direct statements that authors can use to understand areas for improvement.", "grounding_specificity_rationale": "The reviewer makes a general statement about the nonnovelty of the transformer in NLP and vision, which could be considered weak grounding as the authors might not be explicitly discussing a specific section. However, the reviewer then focuses on the crosslayer attention modification and the limited improvement of selfcross attention, which are more specific. The statement about the main improvements coming from using a naive transformer is fully grounded as it directly points to the core contribution.", "verifiability_rationale": "The claim about the limited improvement of selfcross attention (1%) is wellsupported by the data in Tables 4 and 5, making it 5. However, the claims about the nonnovelty of the transformer and the lack of ML insight from the modification are general statements without specific examples or references, making them 1.", "helpfulness_rationale": "The review point is 5 as it directly points out a significant weakness in the proposed modification (lack of ML insight and limited improvement) and provides quantitative evidence to support this claim. It also highlights the core contribution (using a naive transformer), guiding the authors to focus on the most impactful aspect."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the perceived limitation of the number of tasks and directly suggests an improvement by mentioning a specific number (at least 10). This indicates a clear and direct action the authors should take.", "grounding_specificity_rationale": "The comment explicitly mentions 'the number of tasks' and suggests a specific number ('several tasks (at least 10)'). This clearly identifies the specific part of the paper being addressed. Additionally, the comment implicitly suggests a change in the type of results reported ('epochs' vs. 'sequential results'), which is a specific aspect of the experimental setup.", "verifiability_rationale": "The comment presents an opinion ('I consider the number of tasks quite limited') without providing specific examples, references, or logical reasoning to support this claim. While the suggestion for 'sequential results' is 3, the initial statement about the number of tasks lacks sufficient evidence.", "helpfulness_rationale": "The comment is 5 as it directly points out a potential weakness ('limited number of tasks') and provides a clear and actionable suggestion ('to be convinced, see several tasks'). The suggestion for 'sequential results' is also a concrete, actionable item for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests adding sentence inference tasks like MNLI and RTE to the experiments. While the reviewer doesn't explicitly state 'You should add MNLI and RTE to your experiments,' the suggestion implies an action: identifying a gap in the current experimental scope and proposing a concrete solution. The reviewer points to a weakness (limited scope) and suggests a specific improvement (including sentence inference tasks).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'sentence similarity tasks,' 'open domain QA tasks,' 'MNLI,' and 'RTE.' These are specific types of tasks within the broader category of sentence pair tasks. The reviewer provides clear examples, indicating a strong grounding in the specific areas being addressed.", "verifiability_rationale": "The reviewer provides specific examples of sentence pair tasks (MNLI, RTE) that are wellestablished in the NLP field. While they don't cite external references, the mention of these specific tasks provides a basis for understanding their relevance and potential impact. The reasoning is implicit, but the examples offer a degree of verifiability.", "helpfulness_rationale": "The reviewer identifies a clear limitation in the experimental scope (only sentence similarity and opendomain QA) and provides specific, relevant suggestions (sentence inference tasks like MNLI and RTE). This directly addresses a potential weakness for the authors and offers concrete directions for improvement. The suggestions are actionable, even if not perfectly explicit. The reviewer's point is directly relevant to enhancing the evaluation of the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the prompt should be in the appendix or supplement. It also implies that the prompt might be in a supplement if the appendix doesn't contain it. This is an explicit action that the authors should take.", "grounding_specificity_rationale": "The comment refers to 'the prompt' which is a specific part of the paper. However, it does not specify the exact section, table, figure, or unique element where the prompt is located. Therefore, while it identifies a specific part, it lacks the precision needed for full grounding. The comment also doesn't specify *why* the prompt should be in the appendix or supplement, making it somewhat specific but not fully specific.", "verifiability_rationale": "The comment does not contain a claim. It is a suggestion or request for information. Therefore, it does not have verifiability.", "helpfulness_rationale": "The comment points out a potential issue (prompt not in appendix/supplement) but does not provide specific guidance on what to do next or what the consequences are. It lacks the actionable steps and details that would make it 5. While it identifies a problem, it doesn't offer a clear solution, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4: 5", "actionability_rationale": "The reviewer explicitly states the motivation for analyzing the last convolutional layer and asks a question prompting for clarification on why numerosity might not appear in earlier layers. While the request for explanation implies a desire for more information, making it 3 rather than 1.", "grounding_specificity_rationale": "The reviewer explicitly refers to the motivation for analyzing the last convolutional layer, clearly identifying the specific part of the paper (the section discussing layer analysis) and the specific element within that section (the discussion of numerosity). However, the specificity of the reason why numerosity might not appear earlier is lacking.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity in the motivation for analyzing only the last convolutional layer. The support for this claim comes from the lack of explicit reasoning or evidence in the paper, making it only 3.", "helpfulness_rationale": "The reviewer points out a potential weakness in the methodology by questioning the rationale for focusing on the last layer. This directly addresses a gap in the paper's explanation and could be valuable information for the authors to consider, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks 'How to set the parameter S remains a problem.' This is a question, not a direct instruction on how to modify the paper. It identifies a weakness but doesn't provide an action to address it.", "grounding_specificity_rationale": "The review point refers to 'parameter S' generally, without specifying which part of the paper or where this parameter is located. This makes the grounding weak as the authors cannot pinpoint the referenced part.", "verifiability_rationale": "The review point is a question, not a claim that needs verification. It identifies a problem but doesn't state something is incorrect or needs improvement.", "helpfulness_rationale": "The review point identifies a problem with parameter S but does not provide any guidance on how to set it. It's a diagnostic question rather than a prescriptive solution."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that 'human evaluation' would be 'more convincing' as the 'automatic evaluation metrics can be misleading'. This is an explicit action, but it lacks specific details on how human evaluation would address the limitations of automatic metrics. Therefore, the action is explicit but vague.", "grounding_specificity_rationale": "The reviewer suggests 'human evaluation' without specifying which aspects of caption generation need human evaluation. This comment does not identify a specific part of the paper being addressed, making it 1.", "verifiability_rationale": "The reviewer's suggestion of 'human evaluation' could be interpreted as a claim that 'automatic evaluation metrics can be misleading'. However, the reviewer does not provide any supporting evidence or justification for this claim. Therefore, the claim is not wellsupported.", "helpfulness_rationale": "The reviewer's suggestion of 'human evaluation' is a relatively highlevel proposal. While it could be considered a 3 suggestion as it proposes a concrete change, it does not directly address specific weaknesses in caption generation or provide concrete steps for improvement in that area."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the *choice* of employing different types of constraints as a hyperparameter that needs tuning. This directly identifies a concrete action the authors should take: consider different constraint types and evaluate their impact on generalization. The reviewer provides a clear and actionable suggestion.", "grounding_specificity_rationale": "The review point explicitly mentions 'convex or concave constraint' and 'increasing/decreasing constraint'. This directly and accurately identifies the specific aspects of the shape constraints being discussed, providing clear grounding for the suggestion. The reviewer does not need to infer these parts from the paper.", "verifiability_rationale": "The review point makes a practical observation about the common practice of considering different types of shape constraints in machine learning. While it might not be based on a formal citation, it's a wellestablished concept within the field. The reviewer provides a clear justification based on common knowledge and the potential impact on generalization, making the claim 3.", "helpfulness_rationale": "The review point directly addresses a practical choice the authors will need to make when implementing shape constraints: considering convex/concave vs. increasing/decreasing. By highlighting the potential impact on generalization, the reviewer provides a clear reason and rationale for why this choice should be considered. This directly empowers the authors to make a more informed decision, making the review point 5."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "High", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states the issues with the convergence proof, such as the i.i.d. assumption in Assumption 4.1 and its implications for the covariance of Z. They also point out that modifications in Appendix C allow for straightforward adjustments. These are concrete and specific actions the authors can take to address the perceived weakness.", "grounding_specificity_rationale": "The reviewer directly references 'Assumption 4.1' and 'Modification 1 in Appendix C'. This explicit mention of specific sections in the paper clearly grounds the comment. The reviewer also explains the implications of the i.i.d. assumption for the covariance of Z, further specifying the issue.", "verifiability_rationale": "The reviewer makes a claim about the convergence proof's lack of novelty and rigor. This claim is supported by the logical reasoning that the i.i.d. assumption leads to a clear covariance matrix and allows for straightforward modifications. The reference to Appendix C provides external evidence. While the reviewers' suggestions for improvement are not direct verifications, they point towards verifiable steps the authors can take.", "helpfulness_rationale": "The reviewer's comment is 5 as it directly points to a potential weakness in the theoretical analysis and suggests concrete steps the authors can take to address it. The specific mention of Assumption 4.1 and Appendix C provides clear directions for further investigation and potential modifications. The reviewer's suggestions, while not definitive solutions, are actionable and constructive."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the multinode seed cascades are 'artificially created by merging singlenode seed cascades'. This provides a clear action for the authors to take: they should be aware that the experimental setup deviates from a fully realistic scenario. The reviewer also implies that this artificiality might affect the generalizability of the results. The reviewer's statement is direct and identifies a specific methodological choice.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the experimental setup' as the area of concern. This clearly identifies the specific part of the paper being addressed. The reviewer does not need to infer which part is being discussed, as the term 'experimental setup' is a common and wellunderstood term in the context of research papers. The reviewer also specifies that the multinode cascades are 'artificially created', which clearly indicates what is being discussed within the experimental setup.", "verifiability_rationale": "The reviewer makes a claim that the experimental setup is 'semireal' and that multinode seed cascades are 'artificially created'. This claim is supported by the statement that they are 'merged singlenode seed cascades'. The reviewer provides a logical reasoning for why the setup is not fully realistic. The evidence is present in the description provided by the reviewer, making the claim verifiable.", "helpfulness_rationale": "The reviewer points out a specific limitation in the experimental methodology, namely the semireal nature of the multinode seed cascades. This is a valuable piece of feedback for the authors as it directly impacts the interpretation of the experimental results. The reviewer clearly identifies a methodological choice that could affect the generalizability and reliability of the findings. This information is actionable and directly addresses a potential weakness in the experimental design."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point mentions \"bias benchmarks only assess gender, race, and religion\" which is an explicit action or suggestion. However, it doesn't specify how to address this limitation or what steps should be taken. The statement \"Other important biases and datasets are not measured\" is also explicit but lacks concrete steps on how to measure them. The statement \"missing are assessments on stateoftheart generative models like GPT\" is explicit but doesn't detail how to incorporate these models. While the reviewer identifies a problem, they don't provide specific actions or concrete steps to address it.", "grounding_specificity_rationale": "The review points to \"bias benchmarks,\" \"datasets,\" and \"models.\" While it identifies specific areas lacking information, it doesn't explicitly state which *part* of these areas is missing information about. For example, within \"datasets,\" it doesn't specify which type of dataset is missing. Similarly, within \"models,\" it doesn't specify which generative model is missing. The reviewer implies a general deficiency rather than pinpointing a specific missing element.", "verifiability_rationale": "The review contains claims such as \"bias benchmarks only assess gender, race, and religion\" and \"Other important biases and datasets are not measured.\" These are statements that require justification or evidence. However, the review does not provide any logical reasoning, common knowledge, or external references to support these claims. The statement about missing generative models also lacks supporting evidence. The claims are presented without any verification.", "helpfulness_rationale": "The review point identifies a limitation in the evaluation of bias. While this is a valid observation, it does not offer any suggestions or actions to address this limitation. It points out a problem but doesn't propose solutions or provide guidance on how to improve the evaluation process. The feedback is diagnostic rather than prescriptive."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "1 (1)", "verifiability_label": "3 (3)", "helpfulness_label": "4 (4)", "actionability_rationale": "The review point encourages clarification but does not explicitly state a specific action or modification the author should make based on the identified performance loss and knowledge sharing. While it points to a potential area for improvement, it doesn't directly tell the author what to do.", "grounding_specificity_rationale": "The review point is a general statement about the multienv model's performance and knowledge sharing, without specifying which part of the paper or result it refers to. It lacks a clear reference to a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The review point is a question about the interpretation of results, not a claim that requires verification. While it could be expanded to include references or examples, as it stands, it doesn't present a statement that needs to be justified or supported by evidence.", "helpfulness_rationale": "The review point identifies a potential source of confusion for the author regarding the multienv model's performance and knowledge sharing. By encouraging clarification, it prompts the author to engage with the results and potentially resolve the apparent contradiction, making it a helpful suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need to find a proper \u03b1, which is a clear action for the authors to take. The suggestion is direct and targets a specific hyperparameter.", "grounding_specificity_rationale": "The reviewer explicitly mentions the hyperparameter \u03b1, indicating they are focusing on a specific part of the method. However, they don't specify *how* to find the proper \u03b1, making it less grounded in terms of specific steps.", "verifiability_rationale": "The reviewer makes a general statement about hyperparameter sensitivity. While likely true, they don't provide specific examples or references, making the claim somewhat supported but not 5.", "helpfulness_rationale": "The reviewer's point is directly relevant to the authors' workflow. They are given a specific action to take (search for \u03b1) that is likely to improve their results."}
{"actionability_label": "Low", "grounding_specificity_label": "Weak Grounding", "verifiability_label": "1", "helpfulness_label": "Low", "actionability_rationale": "The review point does not explicitly state the metrics being referred to, making it difficult to understand the context and the nature of the metrics. Therefore, it's impossible to determine the explicitness and concreteness of the feedback regarding these metrics. The reviewer's comment is vague and doesn't provide specific actions or suggestions related to the metrics.", "grounding_specificity_rationale": "The reviewer's comment is general and does not specify which metrics are lacking explanation or grounding. It refers to 'the metrics used in the paper' without identifying them or providing context. Therefore, the grounding is weak as the authors cannot pinpoint the specific area needing clarification.", "verifiability_rationale": "The reviewer's comment suggests a need for a citation, which can be considered a claim requiring justification. However, the specific citation is missing, and the reasoning for needing a citation is implied rather than explicitly stated and justified. The lack of a specific reference makes it difficult to verify the claim fully.", "helpfulness_rationale": "The reviewer's comment highlights a significant lack of detail and specificity regarding the metrics used in the paper. While the general direction of suggesting a citation is helpful, the absence of a concrete citation and the lack of explanation about the metrics themselves make the review point unhelpful for the authors in terms of providing actionable feedback. The authors would need to refer to the original paper to find the metrics, which is not ideal."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that Figure 3 is 'challenging to understand' and that the 'workflow and captions are unclear, and the representation of communication modes on the left side is confusing.' This indicates that the reviewer did not find the information presented to be explicitly stated or easily interpretable. While the reviewer points to specific elements of the figure, they do not provide explicit instructions on how to address these issues. The reviewer implies that the authors need to infer the meaning of the unclear elements, making the action implicit.", "grounding_specificity_rationale": "The reviewer explicitly names the 'figure' as the part of the paper being addressed, indicating strong grounding. Furthermore, they specify *what* is unclear within that figure: 'workflow,' 'captions,' and 'representation of communication modes.' This level of detail demonstrates a clear understanding of the specific section and its contents that needs clarification.", "verifiability_rationale": "The comment does not contain a claim or assertion that needs verification. The reviewer is stating a problem with the figure's clarity, not making a judgment about its correctness or suggesting a specific solution that can be evaluated. Therefore, there is no evidence of verifiability in this comment.", "helpfulness_rationale": "The reviewer's comment identifies a weakness in the paper (Figure 3 being unclear) but does not provide any specific suggestions or guidance on how to improve it. While it points to an area needing attention, it lacks the actionable elements necessary for the authors to make changes. Therefore, it is not 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out the lack of clarity regarding 'learned MASK embedding' in the SSL pretraining stage. This constitutes an explicit action or suggestion that is directly identifiable. While the action is somewhat vague in terms of *how* to understand it, the reviewer clearly identifies a missing piece of information. Therefore, it is 3.", "grounding_specificity_rationale": "The reviewer directly addresses a specific technical term ('learned MASK embedding') within the context of the SSL pretraining stage. This demonstrates strong grounding specificity. The reviewer is not making an educated guess; they are directly pointing to a specific part of the paper and highlighting a missing definition. The use of the exact phrase 'learned MASK embedding' further emphasizes the specific identification. Therefore, it is 5.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. Instead, they are pointing out a lack of information. While the absence of a definition is a verifiable fact, the reviewer is not presenting a claim that needs to be supported by evidence. The phrasing focuses on identifying a missing definition rather than making a statement that can be verified. Therefore, it is not verifiable in the sense of requiring justification or evidence. This is a borderline case, as the reviewer is highlighting a gap, but not a claim needing verification.", "helpfulness_rationale": "The reviewer's point directly addresses a potential obstacle for the reader \u2013 a lack of clarity on a specific technical detail. This is 5 as it directly points to a potential area where the reader (and potentially the authors) might be struggling. By highlighting this, the reviewer is providing a clear direction for improvement or clarification. Therefore, it is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the concern about the derivative work. It identifies the *type* of derivative work (extension to hypernetworks) and the *area* of comparison (results for standard networks). However, it does not directly suggest *how* the extension was done or what the implications are for the authors.", "grounding_specificity_rationale": "The comment mentions 'hypernetworks' and 'results already presented in the literature for standard networks,' providing some grounding. However, the reviewer infers the nature of the derivative work, making the grounding not absolute. The specificity is about the areas being compared, but the degree of derivative work is implied rather than explicitly stated.", "verifiability_rationale": "The comment contains a claim ('the reported results seem to be partially derivative') and provides a logical reasoning ('extension to hypernetworks of results already presented in the literature for standard networks') to support it. While the reasoning is logical, the claim itself is based on an inference rather than a direct observation or citation, making it 3.", "helpfulness_rationale": "The comment raises a valid concern about the novelty and contribution of the work. It points out a potential issue that could hinder the authors' perception of the value of their research. This directly impacts the authors' ability to understand and build upon the existing literature, making it 5 and helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues with the paper's framing and experimental setup. They point out that the paper starts with an objective but doesn't motivate the applications, and that the datasets used are static instead of streaming. These are clear and direct statements about what needs to be improved. The reviewer also suggests concrete actions, such as 'motivating the applications' and 'using streaming datasets'. These actions are specific and actionable for the authors.", "grounding_specificity_rationale": "The reviewer identifies specific issues with the paper's grounding. They point out that the paper doesn't explicitly state which part of the paper addresses the lack of motivation or the use of static datasets. While the reviewer's general criticism implies the motivation is in the introduction, it's not explicitly labeled or referenced. However, the reviewer does clearly specify the *what* \u2013 the lack of motivation and the use of static datasets.", "verifiability_rationale": "The reviewer states a fact: 'The paper starts with the objective of designing fast label aggregation algorithms for a streaming setting. But it doesn\u00e2\u0080\u0099t spend any time motivating the applications in which such algorithms are needed.' This is a factual statement without any claim or opinion. There is no evidence presented to support or refute this statement. Therefore, it is classified as 'X (X)'.", "helpfulness_rationale": "The reviewer provides clear and actionable feedback. They point out a significant weakness in the paper's motivation and suggest a concrete improvement: 'motivating the applications'. They also identify a specific experimental limitation: 'the use of static datasets instead of streaming data' and suggest a solution: 'using streaming datasets'. These suggestions are directly aimed at helping the authors improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the 'scope of the study is underspecified' and then provides a specific example of what the reviewer believes is missing ('the work focuses on injecting CoT based approach to smallscale Language Models'). This clearly indicates an explicit action the authors should take, which is to either clarify the scope or include relevant CoT baselines for LLMs.", "grounding_specificity_rationale": "The reviewer attempts to ground the comment by mentioning 'the work focuses on injecting CoT based approach to smallscale Language Models'. They further specify what is missing by suggesting 'additional relevant CoT baselines for incontext learning of Large Language Models (for text003 and ChatGPT) are missing in Table 2 and 3'. This shows a clear understanding of the specific aspect of the paper being discussed and the specific issue.", "verifiability_rationale": "The reviewer states a potential issue ('the scope of the study is underspecified') but does not provide explicit justification or evidence for why this is the case within the review point itself. While they suggest potential solutions ('additional relevant CoT baselines for incontext learning of Large Language Models...'), this is presented as a suggestion rather than a direct claim that needs verification. The reviewer is essentially pointing out a potential gap or area for improvement without explicitly stating a claim that requires further substantiation.", "helpfulness_rationale": "The review point raises a valid concern about the underspecification of the study's scope and suggests relevant baselines as a potential solution. This provides a clear direction for the authors to improve their draft. While the initial statement about the scope being underspecified might not be verifiable on its own, the suggestion of including relevant baselines is a concrete and actionable piece of feedback that can help the authors improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the action of 'improving the figure' and identifies the issue as 'hard to read anything'. While the specific type of improvement isn't detailed, the action itself is clear. This makes it 3 as the authors know they need to address the figure's readability.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 3' and states that it is 'very hard to read anything on the figure'. The use of the section reference makes it fully grounded. The comment also clearly specifies the issue within the referenced section, making it specific.", "verifiability_rationale": "The comment contains a claim that 'Figure 3 is very hard to read anything on the figure'. However, it does not provide any justification or evidence for this claim. There are no logical reasons, common knowledge, or external references provided to support the assertion that the figure is hard to read. Therefore, it is 1.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper (a difficulttoread figure) and suggests an action to address it (improve the figure). This directly points the authors in a direction for improvement. While it lacks specific details on how to improve the figure, it is a helpful starting point. The reviewer is directing the authors to focus on Figure 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer is asking for an explanation of how the general statement about the difficulty of symmetric tensor decomposition connects to the specific finding about the 'nice' landscape of symmetric order4 tensors. This is a direct and explicit request for clarification and a logical action for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions the paper 1 and specifies the type of tensor (symmetric, orthogonal, order4) and the property of the objective function ( 'nice' landscape). This provides strong grounding and high specificity.", "verifiability_rationale": "The reviewer is making a claim about the connection between the general statement and the specific finding. This claim requires logical reasoning and verification, making it 3. The verifiability depends on the authors' understanding and the reviewer's ability to find relevant connections in the literature.", "helpfulness_rationale": "The reviewer is asking for a connection between a general observation and a specific finding. This is a 5 comment as it encourages the authors to explore the relationship between these two points, potentially leading to new insights or improvements in their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3: Weakly Helpful", "actionability_rationale": "The comment implies the GAT is trained with the whole model but doesn't explicitly state it. It suggests reviewing by a native speaker and rewriting sentences for clarity, but doesn't specify which sentences or how to rewrite them. The level of detail is low, making it implicit and vague.", "grounding_specificity_rationale": "The comment refers to 'the GAT' and 'the whole model,' but it doesn't explicitly point to a specific section, table, figure, or a unique aspect of the model being discussed. The connection is implied but not explicit in the paper.", "verifiability_rationale": "The comment contains suggestions for improvement, such as 'Needs to be reviewed by a English native speaker' and 'some sentences need to be rewriting for improving the clarity.' However, it doesn't provide any specific evidence or reasoning to justify these suggestions. The claims are presented without sufficient support.", "helpfulness_rationale": "The comment raises a valid question ('The GAT is trained with the whole model?') which could be helpful for clarification. However, the suggestion to 'rewrite some sentences for improving the clarity' is vague and lacks specific guidance. The overall feedback is limited in its actionable value."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states two concrete actions: 'Replace `n^2/(2*s^2)` with an arbitrary parameter `lambda`' and 'Taking SGD learning rate ~ 0.1'. These are direct instructions on how to modify the paper, making the action explicit. The changes are also concrete, specifying exactly what replacement and learning rate value should be used. Therefore, the review point is 5.", "grounding_specificity_rationale": "The review point explicitly references 'lines 119121' for the first suggestion and 'line 164' for the second. These are literal mentions of specific sections and lines, making the grounding fully explicit and precise. The suggestion to take the learning rate as 'approximately 0.1' is also specific, indicating a clear target value. Therefore, the review point is 5.", "verifiability_rationale": "The review point makes a claim about the SGD learning rate: 'Taking SGD learning rate ~ 0.1 is unlike the Adam default value, it is unclear what the justification *is*.' This is a statement that something is missing or requires explanation. While the review does not provide the justification, the fact that it is *unlike the Adam default value* and *unclear what the justification is* is a verifiable claim. The reasoning is that the reviewer is identifying a gap in the explanation. The common knowledge aspect is that different optimizers often have different default learning rates, and the lack of justification is a verifiable observation. The external references aspect is not directly applicable here as the lack of justification is an internal point. Therefore, the review point is 3.", "helpfulness_rationale": "The review point provides clear and actionable feedback by directly instructing the authors on what changes to make: 'Replace `n^2/(2*s^2)` with an arbitrary parameter `lambda' and 'Taking SGD learning rate ~ 0.1'. These instructions are directly applicable and empower the authors to improve their draft. The feedback is not vague or general, and it points to specific areas for modification. Therefore, the review point is 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the importance of conducting error analysis and provides clear instructions on what the authors should do (conduct error analysis) and how to do it (under different scenarios). This makes the action clear and actionable for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'model performance' but does not explicitly point to a specific section, table, figure, or unique aspect of the paper where this performance is discussed. While the intent is clear, the reviewer would need to infer which part of the paper relates to the model performance.", "verifiability_rationale": "The reviewer makes a claim that 'Error analysis plays a crucial role in evaluating model performance and identifying potential issues.' While this is a generally accepted truth in model evaluation, the reviewer does not provide specific examples or references to back up this claim within the context of the paper being reviewed.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors, specifically recommending the inclusion of error analysis in their evaluation. This is a valuable piece of feedback that directly addresses a common area for improvement in research papers."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests analyzing the domain gap and adding discussions about the gap between datasets. While this is a relevant suggestion, it lacks specific actions or concrete steps on how to achieve this. The reviewer does not explicitly state what needs to be done or how to analyze the domain gap. The suggestion to finetune on synthetic data is also a potential solution but lacks specifics. Therefore, the review point is implicit and lacks concrete actions, making it 2.", "grounding_specificity_rationale": "The review point discusses the domain gap and suggests adding discussions about the gap between datasets. It does not specify which part of the paper or dataset this refers to. The reviewer mentions 'the paper' generally, without pointing to a specific section, table, figure, or unique aspect. Therefore, the review point does not identify a specific part of the paper being addressed, making it 1.", "verifiability_rationale": "The review point contains a claim: 'It would be nice to add some discussions about the gap between datasets.' This is a statement that the current draft lacks this discussion. The reviewer provides some justification for this claim by stating 'Some datasets are closer to each other thus the adaption may not be a big issue.' This justification, while not a direct citation, offers a reason for the suggestion. The reviewer also suggests 'If the method is able to finetune a pretrained model on synthetic data, then the value of the approach would be much higher.' This provides a potential solution, further supporting the claim. Therefore, the review point contains a claim that is supported by some justification and potential solutions, making it 3.", "helpfulness_rationale": "The review point suggests analyzing the domain gap and adding discussions about the gap between datasets. While this is a relevant suggestion and points towards a potential area for improvement, it does not provide specific actionable steps for the authors. The reviewer suggests a general direction for improvement but lacks specific details on how to analyze the domain gap or what aspects of the gap to focus on. The suggestion to finetune on synthetic data is a potential solution but lacks specifics. Therefore, the review point is helpful in guiding the authors towards further improvements, but it lacks concrete action, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem of performance degradation with increasing identities and suggests a potential solution by presetting a small capacity. This indicates an explicit action and a concrete suggestion on how to address the issue.", "grounding_specificity_rationale": "The reviewer refers to 'Table 3 (a)' and 'maximum number of identities,' which are specific parts of the paper. This demonstrates that the reviewer can identify the relevant section and the specific element being discussed.", "verifiability_rationale": "The reviewer makes a claim about the performance trend based on Table 3 (a). However, they do not explicitly provide evidence or justification within the review point itself to support this claim. The verifiability relies on the reader having access to Table 3 (a) and being able to observe the trend.", "helpfulness_rationale": "The reviewer identifies a clear issue related to scalability and provides a suggestion. While the suggestion is somewhat general ('think about how to scale up'), it does offer a direction for improvement. The reviewer's identification of the problem and potential solution makes the feedback 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the authors' claim about LLP being a preliminary work with NLPspecific application is incorrect. While the reviewer identifies a flaw in the authors' claim, they don't explicitly state what is *not* NLPspecific or how the authors should revise their work to be NLPspecific. The reviewer's statement is a direct criticism of the authors' claim, but lacks specific actionable steps for the authors.", "grounding_specificity_rationale": "The reviewer criticizes the authors' claim about LLP being a preliminary work with NLPspecific application by stating 'I don't see anything NLPspecific in their approach.' While the reviewer mentions LLP and NLP, they don't pinpoint a specific part of the paper that lacks NLPspecificity. The criticism is general and doesn't identify a concrete element of the work being critiqued. The reviewer's statement is about the absence of something, not the presence of a specific detail.", "verifiability_rationale": "The reviewer's statement 'I don't see anything NLPspecific in their approach' is a claim that lacks supporting evidence. There is no logical reasoning, common knowledge, or external references provided to back up this assertion. The reviewer simply states their opinion about the authors' work without providing any basis for it. This claim is not verifiable because there is no justification for it.", "helpfulness_rationale": "The reviewer's comment is a critique of the authors' claim about LLP being a preliminary work with NLPspecific application. While the reviewer identifies a potential flaw in the authors' understanding, the comment itself doesn't offer any specific suggestions or corrections. It's a statement of what the reviewer believes is incorrect, but without any guidance on how to address it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests adding a significance test to the human evaluation results and comparing the proposed method with recent LLMs. These are direct, actionable suggestions that guide the authors on what improvements to implement. The reviewer is implying that the current evaluation lacks rigor and that the proposed method needs to be benchmarked against current stateoftheart models.", "grounding_specificity_rationale": "The review point mentions 'the experiment section' and 'the human evaluation results' and 'some most recent LLM'. While the general area is clear, the specific sections, tables, figures, or unique elements within the experiment section and the exact nature of the human evaluation results and the specific recent LLMs are not precisely identified. The reviewer can infer the general areas but needs to refer back to the paper for specifics.", "verifiability_rationale": "The review point makes claims by suggesting that adding a significance test to the human evaluation results is beneficial and that comparing the proposed method with recent LLMs is beneficial. However, the reasoning behind these claims is not explicitly provided or supported by external references. The reviewer is making general assumptions about the importance of statistical significance and model comparisons, but lacks the necessary evidence to fully convince the authors.", "helpfulness_rationale": "The review point provides suggestions for improvement, specifically suggesting the addition of a significance test to the human evaluation results and the comparison of the proposed method with recent LLMs. However, the suggestions are somewhat vague and lack specific details. The reviewer does not specify *how* to carry out the significance test or which specific human evaluation results are being referred to. Similarly, the comparison with LLMs is suggested without providing concrete examples or data points, making it less actionable for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the authors' claim about 'no research focusing on the joint error for UDA' and then names a specific paper ('Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment') that contradicts this claim. The reviewer also states the intention to discuss the relationship between the two works and justify the proposed method, which is a concrete action.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific paper ('Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment') and the specific concept ('joint error for UDA') that the authors' claim refers to. They also clearly state the intention to discuss the relationship and justify the proposed method, further specifying the area of concern.", "verifiability_rationale": "The reviewer makes a clear claim that the authors' claim is incorrect and requires addressing. The reviewer then provides a specific reference and a clear explanation of how this work relates to the authors' claim. The suggestions to 'discuss on that work', 'directly illustrate the relationship', and 'why the proposed method is better' are logical next steps to verify the reviewer's point.", "helpfulness_rationale": "The reviewer provides a clear and actionable critique. They identify a specific gap in the authors' discussion (lack of mention of prior work on joint error) and offers concrete suggestions for improvement (discuss the work, illustrate the relationship, justify the proposed method). This directly helps the authors address a potential weakness in their understanding or framing of the problem."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state any actions or suggest any changes to the paper. It is a critique of the comparison, not a proposal for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'comparison with the SOTA methods' and 'newly collected 209M dataset' and 'smaller datasets' as examples. While the grounding is somewhat present, the reviewer does not specify *which* part of the paper or comparison these elements refer to. The grounding is implied but not explicitly pointed out within the text of the review point itself.", "verifiability_rationale": "The claim that the comparison is 'unfair' is presented as a potential issue. While the reviewer *identifies* a problem (dataset size difference), they do not provide any specific examples, references, or logical reasoning to *justify* why this constitutes a significant flaw in the comparison. The claim is stated, but not wellsupported within the review point.", "helpfulness_rationale": "The review point raises a concern about the fairness of a comparison. While this is a valuable piece of feedback, the reviewer does not offer any concrete suggestions or actions to address the identified issue. The point is critical but lacks actionable recommendations."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the absence of a justification for designing a new curriculum learning method and the lack of discussion regarding the limitations of existing methods. It directly identifies the gap in the paper and suggests addressing it by providing a rationale and discussing limitations. The action is clearly stated, making it 5.", "grounding_specificity_rationale": "The review point explicitly refers to 'Section 1' and the 'need for designing a new curriculum learning method for text graphs'. This direct and specific reference clearly identifies the part of the paper being addressed, making the grounding fully specific. The reviewer also states what is missing, further emphasizing the specificity.", "verifiability_rationale": "The review point makes a claim that 'Several curriculum learning methods have been discussed in Section 1. However, the need for designing a new curriculum learning method for text graphs is not justified. The research gap, e.g., why existing methods can\u2019t be applied, is not discussed.' This claim is supported by stating the absence of a justification and a discussion of limitations, making it 5. No external references or logical reasoning beyond stating the facts are needed to understand the claim.", "helpfulness_rationale": "The review point is 5 as it directly points out a significant gap in the related work section. By highlighting the lack of justification for a new method and the absence of discussion on the limitations of existing methods, the reviewer provides clear direction for the authors. This information is valuable for the authors to understand the research gap and motivate them to explore new approaches. The feedback is constructive and directly addresses a potential weakness."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the suggestion to use pretrained language models as a base encoder and compare the transfer parts. This is an explicit action. However, the reviewer does not provide concrete details on *how* to implement this, such as which specific models to use or how to train the transfer parts. Therefore, it's partially actionable.", "grounding_specificity_rationale": "The reviewer mentions \"pretrained language models\" in the \"NLP field.\" They do not explicitly refer to a specific section, table, figure, or unique aspect of the authors' paper. Furthermore, they do not specify which pretrained models (e.g., BERT, XLNet) or how they should be used as a base. This lack of specificity in both grounding and detailing the models makes it 2.", "verifiability_rationale": "The reviewer makes a claim about the effectiveness of pretrained language models in overcoming domain shift. This claim is supported by general knowledge about the capabilities of these models in the NLP field. While not a formal proof, the suggestion is based on established principles.", "helpfulness_rationale": "The reviewer's suggestion to use pretrained language models as a base encoder is relevant to the field of NLP and addresses a potential limitation of ngram features (lack of semantic understanding). The suggestion provides a clear direction for improvement by focusing on the transfer learning aspect. However, it lacks specific implementation details, making it 3 but not the most detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the issue and suggests an investigation, indicating a degree of actionability. However, the vagueness of the identified performance gain makes the action somewhat unclear on the exact steps to take.", "grounding_specificity_rationale": "The review point makes general statements about the method (complicated modules, more parameters) without explicitly identifying the specific parts or issues. The specificity of the problems is also not clearly defined, making it difficult to pinpoint the exact areas needing improvement.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity in the ablation study. However, the support for this claim is limited to a suggestion for further investigation, lacking specific evidence or references.", "helpfulness_rationale": "The reviewer identifies a potential issue and suggests a direction for improvement. However, the lack of specific details makes the feedback less immediately actionable and more of a general suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests an action: 'this requires more explanation'. However, the specifics of what needs more explanation and why are not provided. The action is implied but not explicitly stated or detailed.", "grounding_specificity_rationale": "The reviewer refers to 'two quantities' but does not specify which quantities they are referring to. The section or context of the review point is needed to identify the specific parts of the paper being addressed. The grounding is weak as the referenced part is not explicitly identified.", "verifiability_rationale": "The reviewer makes a claim: 'this requires more explanation'. However, they do not provide any evidence or justification for why this explanation is needed or how it would be beneficial. The claim is stated without supporting reasoning or references.", "helpfulness_rationale": "The reviewer identifies a weakness in the paper ('this requires more explanation') and suggests an improvement ('more explanation'). However, the suggestion is vague and lacks specific details. The reviewer is pointing out a potential area for improvement, but the lack of concrete suggestions makes the feedback less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point asks the authors to discuss the sensitivity of fixed tuning parameters. While not explicitly stated as an action, the reviewer implies the authors should analyze how changes to these parameters affect the model's performance. This requires the authors to identify fixed tuning parameters and then perform an analysis, making it 3.", "grounding_specificity_rationale": "The reviewer refers to 'fixed tuning parameters.' While not explicitly stating the section or table, this is a fairly specific concept within the context of model tuning. The authors can reasonably infer the reviewer is interested in a specific aspect of their model's configuration. Therefore, it can be considered weakly grounded as the authors can make an educated guess about the referenced part.", "verifiability_rationale": "", "helpfulness_rationale": "This review point is 5. It prompts the authors to investigate a crucial aspect of their model: the sensitivity of fixed tuning parameters. Understanding how these parameters affect performance is essential for model optimization and robustness. It provides a clear direction for the authors to conduct further analysis and potentially improve their model. The request for both strengths and weaknesses makes it particularly valuable."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X (X)", "helpfulness_label": "Not 5", "actionability_rationale": "The review point asks a question about the framework's compatibility with different policy gradient approaches and requests experimental details. It doesn't explicitly state what needs to be done or suggest an alternative, making it not fully actionable. It's a request for information rather than a proposed change.", "grounding_specificity_rationale": "The review point directly asks about the number of random seeds used in experiments, explicitly mentioning 'DDPO and IPPG'. This clearly grounds the review in the specific experimental setup and asks a very specific question about it.", "verifiability_rationale": "The review point is a question seeking information, not a statement of opinion or assertion. Therefore, it doesn't contain a claim that needs verification.", "helpfulness_rationale": "The review point is a request for experimental details, which is valuable for understanding the framework but doesn't directly improve the reviewed draft. It's more of a request for information about the reviewed paper's experiments than a suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests a specific action: evaluating the paper on more datasets and tasks. This is a clear and direct suggestion for improvement, making it 5. The reviewer implies they understand the current limitations and are proposing a concrete solution.", "grounding_specificity_rationale": "The reviewer explicitly states 'one dataset' and 'one task' in the paper evaluation. This directly identifies the specific part of the paper being addressed, making it fully grounded. The reviewer provides precise information about the scope of the evaluation.", "verifiability_rationale": "The reviewer's suggestion is logically sound and directly addresses a limitation of the paper's conclusions. The reasoning behind the suggestion is clear and beneficial, making it 5. The reviewer doesn't need external references to justify their point.", "helpfulness_rationale": "The reviewer's suggestion is directly aimed at improving the paper's conclusions by expanding the evaluation. This is a highly beneficial and actionable suggestion for the authors, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question ('what are the \"relevant\" auxiliary model weights?') rather than stating an explicit action to be taken. While the intent is to improve clarity, the request itself doesn't directly instruct the authors on what to do. They still need to figure out what \"relevant\" means in this context.", "grounding_specificity_rationale": "The reviewer refers to \"definition 2.1\" which is specific. However, the comment itself doesn't explicitly identify the specific part of that definition that is unclear or problematic. The focus is on the *definition* itself rather than a specific element within it.", "verifiability_rationale": "The reviewer doesn't explicitly state a claim or assertion about the paper's quality or correctness. They are suggesting that the definition is unclear, which could be interpreted as a claim, but it lacks specific examples or references to external sources to support this claim. It's more of a constructive suggestion for the authors to clarify rather than a direct criticism of a flaw.", "helpfulness_rationale": "The reviewer's comment points to a potential area for improvement (clarity in definition 2.1). This can be helpful for the authors as it guides them towards selfcorrection. However, the vagueness of the comment ('relevant' weights) makes it less impactful than a more specific suggestion. It's not a direct fix, so its helpfulness is limited."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'Dependence on MIA (Membership Inference Attack) Testing via Ulira: While the paper uses MIA testing as a metric for unlearning effectiveness, the effectiveness of MIA testing itself is not sufficiently robust for privacy guarantees. Additionally the use of ULiRA 1 is recommended.' The reviewer clearly identifies the area of the paper being discussed and provides a specific suggestion to improve it by using ULiRA. The action is both explicit (the reviewer points to a specific aspect) and concrete (the reviewer specifies the issue and the solution).", "grounding_specificity_rationale": "The review point identifies the specific aspect of the paper being discussed by mentioning 'MIA testing' and 'Ulira'. The reviewer can accurately pinpoint the section or table where these concepts are discussed. Furthermore, the reviewer explicitly states the issue with MIA testing ('not sufficiently robust for privacy guarantees') and recommends a specific improvement ('the use of ULiRA 1'). This demonstrates a high level of grounding and specificity.", "verifiability_rationale": "The review point contains claims that need verification. The claim 'the effectiveness of MIA testing itself is not sufficiently robust for privacy guarantees' is stated without providing specific evidence or citations to support this assertion. While the reviewer recommends 'the use of ULiRA 1', this is a suggestion, not a claim requiring the same level of verifiable evidence. The lack of supporting evidence for the negative assessment of MIA testing makes the claim 1.", "helpfulness_rationale": "The review point is actionable, as it clearly states what the authors should do (improve MIA testing and consider ULiRA). It is also grounded, as the reviewer refers to 'MIA testing' and 'Ulira', which are specific concepts within the paper. However, the claim about the limitations of MIA testing lacks supporting evidence, making the advice less certain. While the reviewer suggests a solution, the lack of verifiable support for the problem makes the overall feedback less helpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation in the evaluation process but doesn't explicitly state a desired action or solution. While they imply a need for more concrete feedback, the current statement is more of a critique than a directive action. The reviewer suggests a quantitive comparison on the final outputs, which could be seen as an implicit action, but it's not a fully explicit or concrete action to be taken by the authors.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 3' and 'Figure 4' in their review point. These are specific elements of the paper, indicating a clear identification of the part being addressed. This aligns with the definition of 'Full Grounding' as the reviewer accurately pinpoints the sections being discussed.", "verifiability_rationale": "The reviewer makes a claim about the evaluation results being 'not convincing enough' and suggests a 'quantitive comparison on the final outputs.' While the reviewer identifies a problem with the current evaluation, the claim about the evaluation being 'not convincing enough' lacks specific justification or evidence. The suggestion for a 'quantitive comparison on the final outputs' is a potential action, but the current statement is a critique without concrete supporting evidence. Therefore, it's partially verifiable as the reviewer makes a claim, but lacks sufficient justification.", "helpfulness_rationale": "The reviewer's comment about the evaluation being 'not convincing enough' suggests a lack of clear and actionable feedback. While the reviewer identifies a problem with the current evaluation, they don't provide specific suggestions or evidence to support their claim. The reviewer's comment is more of a critique of the evaluation's current state rather than a direct suggestion for improvement. Therefore, it's not currently 5 as it lacks specific and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides explicit suggestions for improvement, such as 'add details to the experimental procedures,' 'add error bars and pvalues to statistical inferences,' and 'include supplementary information.' While the suggestions are clear, they are somewhat vague in terms of *how* to add these details. For example, 'add details' doesn't specify *which* details are needed. Similarly, 'include supplementary information' is broad. The reviewer also points out the lack of specificity in the procedures, which makes it difficult to know exactly what needs to be added. Therefore, while the suggestions are explicit, the lack of concrete details makes them somewhat vague in terms of actionable steps.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'explanations,' 'procedures,' and 'figures' where the issues lie. For example, they state, 'Most importantly, the explanations are very qualitative.' They also point out the confusion in Figure 2 regarding the 'sample count.' This directly identifies the specific parts of the paper being addressed, making the grounding quite explicit. The reviewer doesn't just say 'there's a problem,' but rather pinpoints the location of the problem.", "verifiability_rationale": "The reviewer makes claims about the paper being 'qualitative,' 'lacking detail in experimental procedures,' 'confusing figures,' and 'lacking statistical rigor.' These are clear claims that the reviewer believes are supported by the content of the paper. For example, they state, 'whenever simulation or experimentbased evidence is given, the procedures are described very minimally or not at all.' While the reviewer's claims are valid, they lack specific examples or references to support these claims. The reasoning is present, but the evidence is general and not explicitly linked to specific sections or figures. Therefore, the claims are 3, as there is a basis for the criticism, but it lacks the depth of external references or specific examples.", "helpfulness_rationale": "The reviewer provides clear and actionable feedback, directly addressing specific areas of the paper. They explicitly state what is missing and what should be added. For example, they say, 'Most importantly, the explanations are very qualitative and whenever simulation or experimentbased evidence is given, the procedures are described very minimally or not at all, and some figures are confusing.' This clearly identifies the weaknesses. They also suggest concrete improvements, such as 'adding details to the experimental procedures,' 'adding error bars and pvalues to statistical inferences,' and 'including supplementary information.' These suggestions are directly linked to the identified weaknesses and are likely to be helpful for the authors. The feedback is not just a general criticism but points to specific areas for improvement."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests adding references to existing studies. While this is a valid suggestion, the review point itself doesn't explicitly state how to add these references or where to find them. The action of adding references is implied but not explicitly stated as a step for the author.", "grounding_specificity_rationale": "The reviewer mentions specific factors (order sensitivity, complexity, diversity, style sensitivity) that have been discussed in existing studies. This demonstrates that the reviewer has identified parts of the paper (prompting strategies) and connected them to existing literature. However, the reviewer does not explicitly state which specific studies are relevant or how these factors directly impact the paper's specific implementation of chainofthought prompting.", "verifiability_rationale": "The reviewer states that 'most of the above factors have been discussed in existing studies.' This is a claim that something exists. However, the reviewer does not provide any specific examples or references to support this claim within the review point itself.", "helpfulness_rationale": "The reviewer's suggestion to add references is relevant to the paper's content, as it relates to the factors affecting chainofthought prompting. However, the suggestion is quite general. It doesn't specify which references to add, where to add them, or how these references would improve the draft. The impact on the authors' ability to improve their work is limited."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests explicitly showing the settings for the various knobs of the algorithm to mimic prior work. While the reviewer identifies a potential improvement (showing settings), the exact *method* or *implementation* of how to show these settings is not specified. The reviewer states the *goal* (mimicking prior work), but the *how* remains vague. Therefore, while the reviewer points out a valuable suggestion, the lack of concrete details makes the action somewhat ambiguous.", "grounding_specificity_rationale": "The reviewer mentions 'various knobs of this algorithm' and 'prior work: Dagger, searn, etc...'. This indicates a clear identification of the specific part of the paper being discussed (the algorithm's parameters and its relation to existing algorithms). Furthermore, the reviewer names specific algorithms (Dagger and SEAR/SEAR). This demonstrates a high level of specificity in identifying the relevant aspects of the paper and providing concrete examples of prior work. The reviewer is not just talking about 'prior work' in general, but about specific algorithms and their parameters.", "verifiability_rationale": "The reviewer states a suggestion: 'This paper could be improved by explicitly showing the settings for the various knobs of this algorithm to mimic prior work...'. This constitutes a claim, as the reviewer is making a statement that could lead to improvement. However, the reviewer does not provide any justification or reasoning for why this suggestion is valuable or how it would be implemented. There is no logical reasoning, common knowledge, or external references provided to support the claim. The reviewer simply states the suggestion without backing it up.", "helpfulness_rationale": "The reviewer suggests explicitly showing the settings for the various knobs of the algorithm to mimic prior work. While this is a potentially useful suggestion, the reviewer does not provide any details on how this would be done or why it would be beneficial for the authors. The suggestion is presented as a general idea without any specific implementation details or justification. The reviewer states the *what* (showing settings) but lacks the *how* and *why*, making the suggestion somewhat vague and lacking a clear contribution to the community."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the problem: 'we are not sure how general these situations are.' This indicates an awareness of a potential issue. However, the reviewer does not provide a concrete action or suggestion to address this lack of clarity. The action is implied rather than explicitly stated and acted upon.", "grounding_specificity_rationale": "The reviewer mentions 'section 3.2' and 'Theorem 1', which demonstrates a clear grounding in the paper's structure and content. However, the reviewer is pointing out a lack of grounding in the *generalizability* aspect of the biases and prediction shifts. While the grounding is specific to the examples, the lack of grounding in the generalizability is a broader, less specific issue.", "verifiability_rationale": "The reviewer is suggesting that the paper should investigate the generalizability of the biases and prediction shifts. This is a suggestion or a recommendation, not a claim that something is or is not generalizable. There is no logical reasoning, common knowledge, or external references provided to support this suggestion within the review point itself.", "helpfulness_rationale": "The reviewer is pointing out a limitation in the paper's analysis by highlighting the lack of clarity regarding the generalizability of the discussed concepts. This is a constructive comment aimed at improving the paper by suggesting further investigation. While it doesn't offer a direct solution, it identifies a valuable area for future work."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment suggests the need for more datasets but lacks specific details on how to implement this suggestion, making it only implicitly actionable.", "grounding_specificity_rationale": "The comment refers to 'datasets' and 'crosstask transferability' generally without pinpointing a specific section or element of the paper, making the grounding weak. While it mentions specific areas, it doesn't detail what is missing or how to address it, making the specificity also weak.", "verifiability_rationale": "The comment is a suggestion for improvement rather than a claim that something is wrong or needs fixing. Therefore, it doesn't have a claim to verify.", "helpfulness_rationale": "The comment is relevant to the authors as it points to a potential area for improvement (more data for crosstask transferability). However, the vagueness of the suggestion makes it less actionable and potentially less helpful than a more specific comment."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests 'some unique tasks created from this nice dataset showcasing the diversity of images/plots' and gives an example 'Question Answering from images'. While this suggests a potential improvement, it lacks specific details on how to implement these unique tasks or how they differ from existing tasks. The reviewer doesn't explicitly state an action or provide concrete steps on how to achieve this. The suggestion is present, but the 'how' is missing.", "grounding_specificity_rationale": "The reviewer mentions 'Figure captioning' and 'matching figures/subfigures to appropriate captions' but doesn't specify which figures or sections of the paper are being referred to. The criticism is about the general nature of these tasks being 'somewhat standard' rather than pinpointing a specific part of the paper. The reviewer doesn't provide a clear explanation of what is wrong with these tasks in a specific section or table.", "verifiability_rationale": "The reviewer states 'It would have been nice to see some unique tasks created from this nice dataset showcasing the diversity of images/plots. e.g. some variety of interleaved imagetext tasks such as Question Answering from images could have been considered.' This statement presents a suggestion and implies a difference from current practices. However, it doesn't provide a claim that something is wrong with the current tasks or that these new tasks are needed. There is no explicit claim being made, and no logical reasoning or external references are provided to support this suggestion.", "helpfulness_rationale": "The reviewer's suggestion to introduce 'some unique tasks created from this nice dataset showcasing the diversity of images/plots' is relevant to the field and could be a valuable addition. It points out a potential area for improvement in dataset creation. However, the suggestion is quite general and doesn't offer specific details on how to implement these unique tasks or what makes them different from existing ones. It lacks a strong justification for why these specific unique tasks are necessary or beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the method in Sec. 3.1 follows Luciddreamer but doesn't explicitly state it's *novel*. They imply it's not different, which is an implicit statement but lacks detail on *how* it's similar. The vagueness makes it difficult to pinpoint an actionable improvement.", "grounding_specificity_rationale": "The reviewer mentions 'Sec. 3.1' and 'Luciddreamer' but doesn't specify *which* part of Sec. 3.1 they're referring to or provide a detailed comparison with Luciddreamer. This makes it difficult to pinpoint the exact issue and understand the grounding.", "verifiability_rationale": "The reviewer claims the method follows Luciddreamer without providing any evidence, examples, or logical reasoning to support this claim. There's no external reference or justification given to back up their assertion.", "helpfulness_rationale": "The reviewer's comment raises a valid question about the novelty of the method. While this can be helpful for the authors to understand the context of their work, it doesn't directly provide actionable feedback on how to improve the draft. It's more of a diagnostic statement than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitations of MMD DRO, such as the lack of a tractable exact reformulation, the looseness of the upper bound, and the restrictive assumption about the loss function belonging to the RKHS. These are all concrete actions or suggestions that the authors could potentially implement or address. While the reviewer doesn't explicitly state *how* to address these issues, the identification of these problems is actionable.", "grounding_specificity_rationale": "The reviewer refers to 'MMD DRO,' 'Theorem 3.1,' 'RKHS,' and 'loss function.' While they don't explicitly state which specific part of their own paper or the referenced work they are referring to, the mention of 'Theorem 3.1' strongly implies they are referring to a specific result or section in the paper they are reviewing. This provides some level of grounding, but it's not as precise as referring to a specific table or figure. Therefore, it's 'Weakly Grounded'.", "verifiability_rationale": "The reviewer provides specific reasons *why* they find MMD DRO problematic. They explain *how* the lack of an exact reformulation, the looseness of the bound, and the RKHS assumption lead to a 'severe drawback.' This provides a clear logical reasoning for their criticism. The reviewer's argument is based on established concepts in optimization and functional analysis, making it verifiable.", "helpfulness_rationale": "The reviewer clearly articulates their concerns and suggests potential improvements. They point out specific limitations of MMD DRO and propose directions for future work. While they don't explicitly state *what* changes should be made, the underlying criticism and the implied suggestions for improvement make this review quite helpful for the authors. The reviewer is not just pointing out a problem but also offering a direction to potentially solve it."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer directly asks questions about the framework's relevance and limitations in specific scenarios (nonconvex losses/nonnorm constraints, binary classification with oracle mean). These questions prompt the authors to consider the framework's applicability and potential shortcomings in these contexts. While the reviewer doesn't explicitly state an action, the questions implicitly guide the authors towards investigating these aspects. The reviewer also asks about the implications of the nonvanishing duality gap and difficulty of maximization, which are actions the authors could take to explore further.", "grounding_specificity_rationale": "The reviewer's questions are general and do not explicitly point to a specific part of the paper they are referring to. They ask about the framework's relevance to 'nonconvex losses and/or nonnorm type defenses' and 'binary classification' without specifying which section or table this relates to. While the questions are about specific concepts, the lack of a direct reference to a specific part of the paper makes the grounding weak.", "verifiability_rationale": "The reviewer presents specific scenarios and asks questions about the framework's limitations and potential extensions. For example, they ask if the nonvanishing duality gap and difficulty of maximization over nonnorm constraints make the algorithm irrelevant or if it still gives intuitions on the risk upperbound. They also ask if covariance or other statistics can be used when the true mean is known through an oracle. These are claims that the authors need to verify or consider, but the paper does not explicitly provide immediate references or derivations to support these specific claims within the provided text. The reviewer is making assertions that require further investigation.", "helpfulness_rationale": "The reviewer provides a list of questions and suggestions for the authors. These are actionable and directly address potential limitations of the framework in specific contexts. The reviewer asks about the framework's relevance to nonconvex losses/nonnorm constraints, the implications of the nonvanishing duality gap, and suggests exploring covariance when the true mean is known. These are concrete points that the authors can consider and potentially improve their work based on. The reviewer's suggestions for improvement are also helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests an action: 'sparsify the trained models' and a comparison: 'compare accuracy to the proposed model'. While the action is clear, the method of sparsification is not specified, making it somewhat vague on how to implement it. The comparison is explicit. Therefore, it is 3 but lacks concrete implementation details for the action.", "grounding_specificity_rationale": "The reviewer refers to 'the baselines on the left hand side' of Figure 3, which implies they have seen the figure and are specifically pointing to a subset of the baselines. This is strong grounding as the section, table, figure, or unique aspect is accurately pinpointed. The reviewer also specifies the comparison to the 'proposed model', adding to the specificity of the referenced part.", "verifiability_rationale": "The reviewer does not explicitly state a claim. They are suggesting an experiment and asking a question. While the suggestion to sparsify is a valid point for investigation, there is X being made or supported by evidence within the review point itself. Therefore, it is best classified as having X.", "helpfulness_rationale": "The reviewer's suggestion to sparsify the trained models and compare accuracy to the proposed model is a relevant and actionable point for improving the draft. It directly addresses the performance of the baseline models. However, the suggestion lacks specific details on how to perform the sparsification, which limits its immediate helpfulness. It provides a direction for further investigation but doesn't offer a concrete solution or a detailed analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the lack of detail regarding the techniques, which is a direct identification of an action the authors should take. The examples provided (sparsification, landmark generation, feature types, radius) are concrete actions. However, the reviewer doesn't specify *how* these actions should be performed, making it only partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'techniques' generally, which doesn't strongly ground the specific part of the paper being addressed. However, they do specify *what aspects* of the techniques are lacking detail (landmarks, features, radius). This provides some level of specificity about the areas needing clarification.", "verifiability_rationale": "The reviewer makes a claim that the paper 'lacks detail about the techniques and make it hard to reproduce the result.' However, they do not provide any specific evidence or reasoning to support this claim. The reviewer lists missing information but doesn't explain *why* this lack of detail is problematic or *cite* any specific examples of how this information is crucial for reproducibility. Therefore, the claim is not wellverified.", "helpfulness_rationale": "The reviewer identifies a significant issue ('lacks detail about the techniques and make it hard to reproduce the result') that is crucial for the authors to understand and implement. However, the lack of specificity regarding the *nature* of this missing detail makes the feedback less helpful. The authors don't know *exactly* what information is missing or *how* it impacts reproducibility. This makes the point somewhat vague in its guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the desired action: 'it should be reorganized'. This clearly indicates a direction for improvement. While the specifics of the reorganization are not provided, the action itself is clear and actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'Appendix H', which is a specific part of the paper. This demonstrates strong grounding as the reviewer can easily identify the referenced section. However, the comment does not specify *what* is wrong with Appendix H, making it only '4'.", "verifiability_rationale": "The comment contains a claim: 'Appendix H is difficult to follow'. This claim is supported by the statement itself, indicating a belief or judgment about the paper's content. The suggestion to 'reorganized' implies a logical connection between the identified problem and the proposed solution.", "helpfulness_rationale": "The comment identifies a specific area for improvement ('Appendix H') and offers a clear suggestion ('reorganized'). While the suggestion is somewhat general, it points to a valuable direction for the authors. The reviewer's intent is to help the authors improve their draft by addressing a concrete issue."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the need for more details to reproduce the work and provides specific examples of missing information, such as the number of units in the RNN implementation. While it doesn't directly tell the authors what to add, it clearly points out the areas where information is lacking, making it actionable.", "grounding_specificity_rationale": "The comment explicitly mentions specific parts of the paper where details are lacking, such as the RNN implementation, and provides examples of what is missing. The reviewer accurately identifies the specific aspects of the implementation that require clarification, making the comment 5.", "verifiability_rationale": "The comment contains a claim (i.e., 'I don't get the feeling the paper is written to be reproduced') and provides supporting evidence (pseudocode and supplementary material) to back up this claim. The reviewer logically explains why the provided information might not be sufficient for reproduction, making the claim verifiable.", "helpfulness_rationale": "The comment clearly states a need for more information to reproduce the work and provides a rationale for this feeling. The reviewer explains that the lack of specific implementation details hinders reproducibility, making the comment 5 for the authors to understand what information is missing and how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action (adding error bars) and provides a concrete detail on how to implement it (improving the visual representation of the data). This fits the definition of 'Explicit' and 'Concrete'.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 1' and suggests a modification directly related to this figure. This clearly identifies the specific part of the paper being addressed and the issue.", "verifiability_rationale": "The review point does not make a definitive statement about what Figure 1 'should' look like. It's a suggestion for improvement, not a claim requiring verification. The suggestion is open to interpretation.", "helpfulness_rationale": "The review point directly addresses a potential weakness (lack of error bars/visibility of results) and suggests a concrete improvement (adding error bars). While the suggestion to 'potentially get rid of fluctuations' is less specific, the core focus is on improving the clarity and rigor of the results presentation. It provides a clear direction for the author to take."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests adding an introduction to energy models in the related work section, which is a direct action the authors can take. However, the suggestion lacks specific details on where this introduction should be placed within the related work section or what specific aspects of energy models should be covered. The request to clarify Figure 1 is an implicit action, as the reviewer identifies a missing element (labels) that needs to be addressed, but the authors still don't know how to carry out this action.", "grounding_specificity_rationale": "The suggestion to add an introduction to energy models in the related work section is 1, as the authors cannot confidently determine which part the comment addresses. The reviewer mentions 'energy models' but doesn't specify which section, table, figure, or unique aspect of the paper this should relate to. However, the request to clarify Figure 1 is partially grounded, as the authors can identify the specific part of the paper (Figure 1) where the information is missing.", "verifiability_rationale": "The review point does not contain a claim that requires verification. The suggestions are recommendations for improvement rather than statements that need to be supported by evidence or reasoning.", "helpfulness_rationale": "The review point offers two suggestions. The suggestion to add an introduction to energy models in the related work section is generally helpful for providing context. The request to clarify Figure 1 is 5 as it directly addresses a potential issue with the clarity of the experimental setup or results. The combination of these suggestions makes the review point 3."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem of premature evictions based on utility scores and suggests considering chunk age as an action to address this issue. The action is clear and directly actionable for the authors.", "grounding_specificity_rationale": "The review point discusses the FIITED framework and the concept of utilitybased eviction. While it doesn't explicitly name a section or table, it clearly identifies the issue as 'premature evictions' within the context of the 'utilitybased approach.' This makes it fully grounded in the described framework but underspecific as it doesn't target a particular element like a table or figure.", "verifiability_rationale": "The review point makes a claim about the potential for bias in utilitybased eviction. It provides a logical explanation and an example of how this bias might manifest ('recent chunks might gain a temporary high utility'). This logical reasoning and example support the claim, making it verifiable.", "helpfulness_rationale": "The review point is clear, identifies a specific problem within the FIITED framework, and provides a concrete suggestion for improvement ('consider chunk age'). This actionable feedback is directly relevant to the authors' work and is likely to be helpful in refining their chunk management strategy."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the first paragraph of the Introduction is about DNNs but lacks any mention of drift. They clearly identify the action needed: 'This entire paragraph provides little valuable information to readers.' The reviewer provides a direct and specific suggestion for improvement, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly identifies the section of the paper being addressed as 'the first paragraph of the Introduction' and the specific topic within that section as 'DNNs'. They also specify the *absence* of driftrelated information. This demonstrates strong grounding as the reviewer can confidently identify the referenced part and clearly identifies the issue with it.", "verifiability_rationale": "The reviewer makes a claim that the DNN introduction is 'not central' and 'provides little valuable information' to readers. They support this claim by arguing that a general DNN introduction is not directly relevant to 'detecting drift types and drift magnitude'. The reviewer provides a clear justification for their claim based on the paper's stated focus, making the claim verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable critique. They identify a specific section of the paper and its lack of relevance to the paper's core focus. They suggest a concrete improvement: 'This entire paragraph provides little valuable information to readers.' This critique is directly relevant to improving the paper's clarity and focus, making it 5."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer suggests improvements to the framework, such as 'quantitative experiments and comparison between selection of algorithms' and 'detailed explanations on the presented ones.' However, the review lacks specific details on *how* these improvements should be implemented. The reviewer doesn't specify which parts of the framework need new experiments or comparisons, nor does they provide a clear methodology for the 'detailed explanations.' Therefore, while the intent is to improve the framework, the lack of concrete action makes it difficult to act upon. The reviewer suggests *what* should be improved but not *how* to improve it.", "grounding_specificity_rationale": "The reviewer mentions 'how the different part of this framework performs and contribute to the final result' and refers to the 'result section.' However, they do not specify *which* part of the framework they are referring to or *how* the performance is being evaluated. The reviewer also mentions 'individual parts compared to other solutions' without specifying which parts or solutions are being compared. The reference to the 'result section' is too general and doesn't pinpoint the specific information needed for grounding. The reviewer is vague about the *specifics* of the framework's performance and the *nature* of the comparisons.", "verifiability_rationale": "The reviewer states, 'it lacks either quantitative experiments and comparison between algorithms, or a more detailed explanations on the presented ones.' They also express uncertainty about 'what the exact performance of the whole framework and individual parts compared to other solutions.' This indicates a lack of supporting evidence or justification for the claims being made. The reviewer doesn't provide any references, examples, or logical reasoning to back up their assessment of the framework's performance. The claims are presented without sufficient grounding or verifiability.", "helpfulness_rationale": "The reviewer expresses a lack of clarity regarding the framework's performance and contribution to the final result. They state that the comment lacks supporting evidence or justification, making it difficult to understand the framework's effectiveness. The reviewer is uncertain about the performance of the framework and the lack of quantitative experiments, comparisons, and detailed explanations makes it hard to gain actionable feedback. The reviewer's statement that the comment is '1' reflects their inability to extract meaningful information from the review point."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not provide explicit or implicit actions that the authors can directly implement. The reviewer is questioning the potential of the work rather than suggesting concrete changes to the authors' current draft. There is no guidance on what the authors should do or how they should apply the feedback.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or unique element that it is addressing. It is a general question about the potential of the work, not a critique of a particular section, table, figure, or unique aspect of the authors' paper. The reviewer is asking about the broader implications rather than specific issues within the current draft.", "verifiability_rationale": "The review point does not contain a claim that is verifiably supported. It is a question about the potential of the work, not a statement that can be proven or disproven based on the current draft. There are no references to external works or logical reasoning provided within the review point itself.", "helpfulness_rationale": "The review point raises important questions about the potential of the work, which could be helpful for the authors to consider. However, it does not provide specific, actionable feedback on how to improve their current draft. It lacks concrete suggestions or guidance on what changes to make or how to address the identified issues. While it prompts reflection, it doesn't directly help the authors improve their immediate work."}
{"actionability_label": "0", "grounding_specificity_label": "1", "verifiability_label": "0", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, not a directive. It doesn't tell the authors what to do or how to do it. It's a request for information about presenting the theorems simply.", "grounding_specificity_rationale": "The review point is about presenting the theorems simply, but it doesn't specify *which* theorem or definition this refers to. It's a general suggestion about presentation.", "verifiability_rationale": "The review point is a suggestion, not a claim that needs verification.", "helpfulness_rationale": "The review point suggests a valuable direction for the authors (presenting theorems simply), but it doesn't directly address a specific weakness or provide immediate actionable steps. It's a forwardlooking suggestion."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential experiment (using larger resolution) but does not explicitly state how to conduct it or what action needs to be taken. While it implies an action (running the experiment), the lack of specific steps makes it less actionable. The reviewer suggests an improvement to the experiments section but doesn't provide the details to make it actionable.", "grounding_specificity_rationale": "The review point is general and does not specify which part of the paper or experiment it is addressing. It suggests an improvement to the experiments section as a whole but doesn't point to a specific issue or component within the current experiments. The reviewer doesn't identify a specific section, table, figure, or unique aspect of the paper being addressed.", "verifiability_rationale": "The review point suggests an experiment (using larger resolution) and asks a question about its impact. However, it does not provide any justification or reasoning for why this experiment is relevant or how the impact will be verified. The reviewer doesn't cite any external references or provide a logical argument for the suggestion. The claim is made without sufficient support.", "helpfulness_rationale": "The review point identifies a potential experiment (using larger resolution) and asks a relevant question about its impact on performance. This provides some value to the authors in terms of exploring potential improvements and understanding the limitations of the current experiments. However, it lacks the specifics to make the experiment actionable or verifiable. The suggestion is interesting and prompts further investigation, making it 3 in exploring avenues for improvement, even if it doesn't provide concrete steps."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the exact mathematical operation to perform on the feature map, making it 5.", "grounding_specificity_rationale": "The review point directly references a specific section and a concept within that section, fully grounding the comment. It also specifies the mathematical operation, making it specific.", "verifiability_rationale": "The review point is a question seeking clarification, not a declarative statement making a claim. Therefore, it has X and is not verifiable.", "helpfulness_rationale": "The review point is helpful in that it seeks clarification on a specific implementation detail. However, it doesn't identify a weakness or suggest an alternative approach, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the location of the issue ('Figure 2 right.') and provides concrete suggestions for improvement ('maybe make use of styles (e.g. dashed lines) or add color'). This indicates an explicit and concrete action to be taken.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 2 right', which is a specific part of the paper. This constitutes full grounding. The review also specifies the nature of the problem ('difficult to distinguish between the different curves') and provides concrete suggestions ('make use of styles... or add color'), making it fully specific.", "verifiability_rationale": "The review point contains a claim ('I found it difficult to distinguish between the different curves') and provides direct suggestions for improvement ('maybe make use of styles... or add color'). While the suggestions are not claims requiring external verification, the actionability and grounding specificity are what makes this potentially helpful. The claim is supported by the reasoning that better visualization would improve clarity.", "helpfulness_rationale": "The review point identifies a clear weakness ('difficult to distinguish between the different curves') and offers concrete, actionable suggestions ('maybe make use of styles... or add color'). While the suggestions could be more specific, they are directly tied to the identified problem and are intended to improve the figure. This makes it a '3' point."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review points out a clear mismatch between the stated goals (language learning) and the actual evaluation (question answering). While it doesn't explicitly say 'fix the intro,' it provides a concrete, actionable point for the authors to address the discrepancy between the language learning claim and the evaluation method.", "grounding_specificity_rationale": "The reviewer identifies the 'introduction' as the problematic area but doesn't specify a particular section, table, figure, or unique element within that area. This makes the grounding weak.", "verifiability_rationale": "The review states a discrepancy between the introduction's claims and the evaluation method. While this is a verifiable claim, the review point itself doesn't provide explicit evidence or justification for this discrepancy. The verifiability relies on the authors' ability to investigate further.", "helpfulness_rationale": "The review highlights a significant issue: the mismatch between the language learning claim and the questionanswering evaluation. This is a clear and actionable feedback that guides the authors to reevaluate their framing and evaluation process. While it doesn't offer a complete solution, it is highly relevant and actionable."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer raises a concern about the novelty and validity of a specific problem (ODE weight evolution inaccuracy) in the context of the paper's contribution. While the reviewer identifies a potential issue, they do not provide a clear action for the authors to take. They are questioning the problem itself rather than suggesting a solution. The reviewer's statement, 'The reviewer is not convinced about this problem,' indicates a lack of conviction rather than a direct instruction.", "grounding_specificity_rationale": "The reviewer mentions 'ODEs,' 'neural ODEs,' and 'weight evolution' but does not pinpoint a specific part of the paper or methodology where this problem is occurring. The reviewer's statement is general and does not provide a clear reference point for the authors. The lack of a specific section or table number makes the grounding weak.", "verifiability_rationale": "The reviewer states a claim, 'appears a previous paper first reported this issue. The reviewer is not convinced about this problem,' which could be considered verifiable as they are pointing out a potential discrepancy or lack of clarity. However, the reviewer does not provide any evidence or reasoning to support their conviction. The statement is presented as a question of belief rather than a wellsupported claim. The lack of external references or logical reasoning makes the verifiability low.", "helpfulness_rationale": "The reviewer raises a valid concern about the core methodology, specifically the modeling of weight evolution using ODEs. By questioning the accuracy of this approach, the reviewer highlights a potential weakness in the paper's foundation. This raises a helpful point for the authors to consider and potentially address. However, the reviewer's lack of conviction in their assessment reduces the overall helpfulness of the comment. The comment identifies a problem but doesn't offer a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "6: X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a potential improvement by mentioning the sampled policy. While it implies an action (improving clarity), it lacks specific details on how to implement this action. The suggestion is general and doesn't provide concrete steps for the authors to take. Therefore, it is 3 but lacks the necessary detail to be fully actionable.", "grounding_specificity_rationale": "The review point refers to 'these algorithms,' which are reasonably clear in the context of the discussion, but it doesn't explicitly identify a specific section, table, or figure. This requires the authors to infer the target. The suggestion to 'mention the sampled policy' is also vague and doesn't specify how or why. Therefore, the grounding is weak, and the specificity is underdefined.", "verifiability_rationale": "The review point itself does not contain a claim or assertion that needs verification. It's a suggestion for improvement. While the *implied* claim is that the current description might be lacking detail about the sampled policy, the review point doesn't explicitly state this as a claim that requires justification. Therefore, it has X.", "helpfulness_rationale": "The review point suggests a potential improvement by mentioning the sampled policy. This directly addresses a potential weakness in the current description of the algorithms. While the suggestion is relevant and aims to enhance the clarity and completeness of the draft, the lack of specific details about *how* to mention the sampled policy limits the immediate helpfulness. The authors would need to infer the implementation, making the improvement somewhat conditional."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point clearly states the weakness: 'Also, proving lower bounds for round complexity is the major chuck of work involved in proving results for batched ranking problems.' It then directly explains the reason for this weakness: 'However, this paper exploits an easy reduction from the problem of collaborative ranking, and hence, the lower bound results follow as an easy corrayory of these collaborative ranking results.' The term 'easy corrayory' (intended to mean 'easy corollary') explicitly indicates a straightforward deduction. The reviewer identifies a specific aspect of the paper's contribution (lower bound proofs for round complexity) and explains how it is lacking due to a simple methodological approach. This information is directly extractable and actionable for the authors.", "grounding_specificity_rationale": "The review point starts by referring to 'proving lower bounds for round complexity' as a 'major chuck of work involved in proving results for batched ranking problems.' While this is a specific area of contribution, the reviewer does not explicitly identify a specific part of the paper or method that is being criticized in relation to this. They are more broadly criticizing the overall approach of proving lower bounds. The reviewer does not mention a specific section, table, figure, or unique element of the paper that they are referring to. The criticism is about the *difficulty* of a general area rather than a specific flaw in a particular part of the paper. Therefore, it is 1 in a specific part of the paper.", "verifiability_rationale": "The review point contains a claim: 'this paper exploits an easy reduction from the problem of collaborative ranking, and hence, the lower bound results follow as an easy corrayory of these collaborative ranking results.' This is a statement of opinion and a deduction. The reviewer provides logical reasoning ('easy reduction', 'easy corrayory') to support this claim. While the reviewer does not provide external references, the logic is based on the understanding of reductions and corollaries within the field. The claim is supported by reasoning and common knowledge within the field of ranking problems. The reviewer's assessment of the method's simplicity and its direct connection to existing results makes the claim verifiable.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper's approach to proving lower bounds for round complexity. The reviewer points out that the paper relies on an 'easy reduction' and that the 'lower bound results follow as an easy corrayory of these collaborative ranking results.' While this critique highlights a potential limitation in the paper's methodology, it does not offer specific suggestions or guidance on how the authors should improve their work. The reviewer explains *why* their work might be limited but does not provide concrete steps or alternative approaches. The feedback is about the *difficulty* of a general aspect and the *potential* impact on the results, but it lacks direct actionable advice for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review states that the prompting technique is 'basic' and suggests 'carefully curated prompts' could be better. While the reviewer identifies a potential improvement, the specific action to take is not explicitly stated. The reviewer implies the current technique is lacking, but doesn't detail how to make it better. Therefore, the action is implicit and vague.", "grounding_specificity_rationale": "The review mentions 'prompting technique' generally and 'systematic reviews' specifically. It doesn't pinpoint *which* aspect of the prompting technique or the systematic review process is flawed. The reviewer is making a general comment about the limitations of the technique in the context of systematic reviews, but not specifically addressing a deficiency in a particular part of the prompt or the review process. Therefore, the grounding is weak as the specific area being criticized is not clearly defined.", "verifiability_rationale": "The review states that the prompting technique is 'basic' and suggests 'carefully curated prompts' could be better. This is a statement of opinion about the current technique's potential and a suggestion for improvement. There is no explicit claim being made that requires verification. The reviewer is not presenting a statement that can be logically reasoned, referenced, or supported by external evidence. Therefore, there is X to be verified.", "helpfulness_rationale": "The review offers a suggestion that 'carefully curated prompts' could be better than the current 'basic' technique. However, this suggestion is very general and lacks specific, actionable steps for the authors to take *now* to improve their draft. The reviewer doesn't provide concrete examples of how to implement 'careful curation' or what specific improvements could be made. The suggestion is broad and lacks the necessary detail to be truly helpful. Therefore, the review offers a suggestion but lacks the specific, actionable steps needed for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment implicitly suggests an improvement by mentioning 'Additional experiments on larger data sets' but doesn't explicitly state what needs to be done. The phrase 'but I understand that compute might be an issue' indicates a lack of concrete guidance on how to address this. While the intent is clear, the action is not directly stated, making it implicit.", "grounding_specificity_rationale": "The comment refers to 'larger data sets' generally, without specifying which part of the paper or experiment this relates to. The reviewer is not pointing to a specific section, table, or figure. The mention of 'probabilities' is vague and doesn't pinpoint a specific aspect of the method or results.", "verifiability_rationale": "The comment doesn't contain a claim that requires verification. It's a suggestion for improvement rather than a critique or assertion about the paper's content. There's no logical reasoning, common knowledge, or external references provided.", "helpfulness_rationale": "The review point offers a specific concern about 'maintaining the probabilities' with large batch sizes, which is a relevant issue for the authors. While it doesn't provide a solution, it identifies a potential area of concern and acknowledges the previous feedback. The reviewer also expresses a desire for more experiments, which is a valid suggestion, albeit vague. The overall intent is to provide feedback that, while not fully actionable, is relevant to the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the performance gap between the submitted model and GLaMM and UNINEXT. While it doesn't provide specific instructions on how to improve, it points to a clear area for improvement by highlighting the lower performance on REC and RES. The mention of specific metrics (cIoU and IoU>0.5) provides some guidance on where the issues might lie.", "grounding_specificity_rationale": "The review point explicitly refers to 'Table 4' and names specific models, GLaMM and UNINEXT, by name and citation. It also specifies the performance metrics (REC and RES) and provides concrete performance numbers from these models as examples. This clearly identifies the specific part of the paper and the relevant information being discussed.", "verifiability_rationale": "The review point contains a claim: 'Table 4: The performance on REC and RES are clearly behind more recent models.' This claim is supported by providing specific examples of more recent models, GLaMM and UNINEXT, and citing their performance on the same metrics in RefCOCO and RefCOCOg datasets. The reasoning is logical, and the references are external works.", "helpfulness_rationale": "The review point identifies a clear weakness in the submitted work by pointing out the performance gap on REC and RES compared to more recent models. This is a valuable piece of feedback as it highlights an area where the authors could improve their model's performance. However, it does not offer specific, actionable steps on how to address this weakness."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer identifies a potential issue ('shows evidence that some information is learned before the model is able to use the concepts'). This identifies an explicit action: 'improve the model's ability to use concepts after learning them'. However, the reviewer does not specify *how* this improvement should be made or *what* specific changes are needed. The action is implied but not explicitly stated with concrete details.", "grounding_specificity_rationale": "The reviewer refers to 'some information' and 'the model' generally, without pinpointing a specific part of the paper or concept. There is no explicit mention of a section, table, figure, or unique element. The reference is vague and does not clearly identify the issue. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim ('shows evidence...'), but does not provide any specific evidence, references, or logical reasoning to support this claim. The statement is presented as a possibility ('I think') rather than a verifiable observation. Therefore, the claim is not supported by verifiable evidence.", "helpfulness_rationale": "The reviewer points out a potential issue in the model's development. While this highlights a weakness, it does not offer concrete, actionable feedback or suggestions that would directly improve the authors' draft. The comment is about the model's capabilities, not directly about improving the authors' work. Therefore, the feedback is not directly helpful for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the similarity to ConsiStory's approach ('mirrors the approach used in ConsiStory') and highlights the difference in the mask source ('utilizing CLIPseg and OTSU segmentation rather than crossattention'). This provides a clear action for the authors to take: acknowledge the similarity and emphasize their contribution in the mask source.", "grounding_specificity_rationale": "While the reviewer doesn't explicitly state which part of the paper they are referring to, the context implies they are discussing the 'video storyboarding' method. The reviewer then specifies what is being compared ('framewise SDSA') and what the difference is ('the mask source'), and mentions specific techniques used in the difference ('CLIPseg and OTSU segmentation') and the technique the original method uses ('crossattention'). This provides a degree of specificity about the aspect being discussed.", "verifiability_rationale": "The reviewer makes a claim ('The innovation of the proposed video storyboarding approach is limited') and provides a reason ('The primary method relies on framewise SDSA, which largely mirrors the approach used in ConsiStory'). This claim can be verified by comparing the proposed method to ConsiStory. While the reviewer doesn't provide external references, the comparison to an existing method provides a basis for evaluation.", "helpfulness_rationale": "The reviewer's point directly challenges the perceived novelty of the work by pointing out the similarity to ConsiStory. This is a valuable piece of feedback for the authors, as it helps them contextualize their contribution within existing research. While it might not be the most constructive critique (as it doesn't offer a direct solution), it is still helpful in guiding the authors to reevaluate their claims."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review points out a *potential* weakness and suggests a *specific* way to test it. This suggests it *could* be actionable if clarified. While the action is somewhat vague, the potential for action exists.", "grounding_specificity_rationale": "The review clearly refers to \"this method\" and \"fewshot classification,\" indicating a strong grounding in the specific area being discussed. It also suggests comparing against previous methods on a *specific* dataset, which further grounds the comment and specifies the area of investigation.", "verifiability_rationale": "The review makes a claim about the potential prominence of the weakness in certain scenarios and suggests a concrete experiment (comparing against previous methods on a specific dataset) to verify this claim. This provides a clear method for investigation, making the claim verifiable.", "helpfulness_rationale": "The review identifies a potential weakness and offers a concrete suggestion for investigation, which is valuable feedback for the authors. While the exact *how* of the experiment isn't specified, the *what* and *why* are clear, making the feedback actionable and specific, thus 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'I think the paper could greatly benefit from more explanation of the meaning of the bounds (perhaps in the appendix).' This clearly indicates that the authors should provide more details about the bounds. The action is directly stated, making it 5.", "grounding_specificity_rationale": "The review point refers to 'the bounds' generally, without specifying a particular section, table, figure, or unique aspect of the paper. While the reviewer implies it's related to the 'space limitations' mentioned in the introduction (assuming the context), they don't pinpoint the exact location or specific element within it. Therefore, the grounding is weak, although the specific aspect (explaining bounds) is clear.", "verifiability_rationale": "The review point contains a claim: 'I think the paper could greatly benefit from more explanation of the meaning of the bounds.' This is a statement of opinion. However, the reviewer does not provide any supporting evidence or justification for this claim. There is no logical reasoning, common knowledge, or external references provided to back up their assertion. Therefore, the claim is 1.", "helpfulness_rationale": "The review point identifies a potential area for improvement in the paper \u2013 providing more explanation of the bounds. While the specific bound is not mentioned, the reviewer clearly states that more explanation is needed. This provides some actionable feedback for the authors. The suggestion to put this explanation in the appendix is also a general recommendation for improvement. Therefore, the review point is helpful, even if it lacks precise details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the implementation framework (OpenAI's Triton) and the alternative (CUDA), providing a clear action for the authors to adopt the correct framework. It also implicitly suggests a change in presentation style by recommending conciseness. The reviewer identifies a specific technical detail and proposes a concrete change.", "grounding_specificity_rationale": "The comment implicitly refers to the implementation details of the kernels, which is a specific part of the paper. While not explicitly stating a section or table number, the context clearly points to the implementation aspect. The reviewer also implies they are referring to the implementation details by mentioning 'OpenAI's Triton' and 'CUDA'.", "verifiability_rationale": "The comment makes a claim about the implementation framework and provides a justification for conciseness based on 'wellknown engineering improvements'. While not a direct citation, this provides a logical reason for the suggestion. The reviewer identifies a factual error and offers a clear rationale for a specific presentation choice.", "helpfulness_rationale": "The review point directly identifies a factual error regarding the implementation framework and provides a clear suggestion for improvement by recommending conciseness. The justification for conciseness, based on 'wellknown engineering improvements', adds value to the feedback. This information is directly actionable and will help the authors improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer criticizes the zeroshot claim but does not propose an action or suggest how to improve it. They are pointing out a limitation or a potential issue with the zeroshot approach, but they do not offer a concrete solution or modification. The criticism itself is a statement of a problem, but it lacks a proposed action or remedy.", "grounding_specificity_rationale": "The reviewer provides specific examples of tasks (walkerrun, walkerwalk, 3prong, 4prong) and mentions the source and target tasks. They are pointing out limitations related to the difficulty of the source task and the sufficiency of the experimental setup. While they don't explicitly state which section or table these tasks belong to, they clearly identify the concepts being discussed. The grounding is present, but it could be more explicit about the location within the paper.", "verifiability_rationale": "The reviewer makes claims about the difficulty of the source and target tasks and the sufficiency of the experimental setup. While they don't provide direct evidence *within this review point* to support these claims, the reasoning is logical and based on common knowledge about task complexity. They argue that the difficulty gap between the tasks makes the zeroshot transferability questionable and that the experimental setup might provide sufficient information. The claims are supported by logical reasoning, but lack specific citations within this point.", "helpfulness_rationale": "The reviewer provides a clear and actionable critique of the zeroshot claim. They explain why the difficulty gap between the source and target tasks makes the transferability questionable and suggest that the experimental setup might already provide sufficient information. This critique directly challenges a key assumption and provides a reason for the authors to reconsider their approach. It offers a specific alternative or at least a more nuanced perspective."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "Weakly Verifiable", "helpfulness_label": "Not Very Helpful", "actionability_rationale": "The reviewer suggests trying larger backbones as a potential improvement. While this is a direction for future work, it doesn't explicitly state what specific changes need to be made to the current draft or how to evaluate the performance on larger backbones. The suggestion is more of a general direction than a concrete action to be taken on the existing work.", "grounding_specificity_rationale": "The reviewer mentions 'the paper' generally but then focuses on 'the small backbone ResNet50' when discussing the relative gains. While the context is specific, the initial part of the review doesn't pinpoint a particular section, table, figure, or unique aspect of the paper being addressed. The grounding is present but could be more explicit.", "verifiability_rationale": "The reviewer claims that the gains are 'not very strong' and speculates that the global pooling might be the reason. This is a claim that could potentially be supported by further analysis or experiments. However, the review point itself doesn't provide specific examples of where the current draft falls short or suggest concrete ways to address these issues. The claim is present, but the supporting evidence is missing within the review point itself.", "helpfulness_rationale": "The reviewer provides a potential direction for future research (trying larger backbones) but doesn't directly address the weaknesses or shortcomings of the current draft. While the suggestion is relevant, it doesn't offer specific, actionable feedback on how to improve the existing work. The review point is more about future work than directly helping with the current submission."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The statement explicitly states that the extension from linear models to wide fullyconnected neural networks is 'trivial' and that the work only considers 'easy wide fullyconnected neural networks'. This directly implies a lack of significant contribution in this area, making the action implicit but clear.", "grounding_specificity_rationale": "The comment mentions 'wide fullyconnected neural networks' and 'Section 3.2, 3.3', indicating a general reference to a specific area. However, it doesn't pinpoint a specific part of a section, table, figure, or unique element within those sections that needs addressing. The reviewer is making a general comment about the type of neural networks considered, rather than a specific critique of a particular element.", "verifiability_rationale": "The comment contains a claim: 'With the existing NTK theorem, the extension from linear models to wide fullyconnected neural networks is trivial' and 'The work bypasses the core problem of overparametrized neural networks and only considers the easy wide fullyconnected neural networks'. These claims are supported by logical reasoning ('with the existing NTK theorem') and by stating the consequences ('is trivial...only considers the easy...').", "helpfulness_rationale": "The review point is highly critical, stating that the analysis of neural networks contributes 'less' and explicitly points out the limitations regarding the triviality of the extension and the focus on 'easy' networks. This directly informs the authors on what aspects of their neural network analysis are lacking and how to improve them."}
{"actionability_label": "N/A", "grounding_specificity_label": "N/A", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly address the aspects of actionability, such as whether it suggests concrete steps for improvement or leaves the authors to infer them. There is no mention of specific actions or recommendations related to the paper's content or structure.", "grounding_specificity_rationale": "The review point does not discuss the specific part of the paper or task being addressed. It focuses on the *number* of datasets used for evaluation, not on the details of the experimental setup or the tasks themselves.", "verifiability_rationale": "The review point contains a claim (the concern about the number and size of datasets) and provides some justification (the authors' reply clarifies the situation). However, the verifiability of this claim is somewhat borderline as the justification is presented as a clarification rather than a strong argument or evidence.", "helpfulness_rationale": "The review point is 3 as it raises a valid concern about the rigor of the evaluation due to the number and potential size limitations of the datasets. It encourages the authors to consider a more comprehensive evaluation strategy. However, the mention of the authors' detailed reply and their commitment to a repository are not helpful at this stage as they are responses and future actions, not feedback on the current review point itself."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the absence of results for larger models, which is a clear indication of a weakness. However, it does not directly instruct the authors on what to do about this weakness.", "grounding_specificity_rationale": "The comment mentions 'imageNet classification with ResNet50/34/18' and then introduces 'larger models like ResNet101/152'. While it implicitly relates the two, it doesn't explicitly identify a specific part of the paper being addressed in relation to this gap in results. The grounding is weak because the authors can only infer the relevance of the missing results.", "verifiability_rationale": "The comment states a fact: 'there are no results with larger models like ResNet101/152.' This is a declarative statement and does not present a claim that requires verification or justification.", "helpfulness_rationale": "The comment identifies a missing and potentially important piece of information (results for larger models) for the imageNet classification task. This can be helpful for the authors as it highlights a gap in their current evaluation and suggests a direction for further experimentation or analysis."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential confusion regarding the terms 'relatively inexpensive' and 'expensive to evaluate'. While the reviewer doesn't explicitly state an action, they imply a need for clarification. This could involve explaining the context in which these terms are used, providing examples of what constitutes 'inexpensive' or 'expensive', or defining the criteria used to make such assessments. The lack of explicit action makes it less actionable compared to a direct suggestion on how to improve something.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017)' and highlights a potential point of confusion in the abstract and introduction regarding the terms 'relatively inexpensive' and 'expensive to evaluate'. This demonstrates a clear identification of a specific paper and a specific area within the paper where clarification is needed. Therefore, the grounding is strong. However, the reviewer doesn't specify *what* needs to be improved regarding the terminology, making it somewhat underspecific.", "verifiability_rationale": "The reviewer makes a claim: 'somewhat confusing to read \"relatively inexpensive\" in the abstract and then \"expensive to evaluate\" in the first line of the introduction!'. This claim is verifiable as the reviewer identifies a potential inconsistency in terminology. The reasoning is clear: the terms seem contradictory. However, the reviewer doesn't provide external references or examples to support this claim, making it somewhat underjustified.", "helpfulness_rationale": "The reviewer's point about the potential confusion in terminology is directly relevant to the reader's experience. It highlights a practical issue that a reader might encounter when trying to understand the paper. By pointing out this inconsistency, the reviewer provides a suggestion for improvement, which is to clarify the terms. Therefore, the review offers a clear direction for the authors to take, making it helpful."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states \"How does this method address sparse reward problems in a better way?\" which is a question, not an action. While they imply the proposed method *should* address the issue better, they don't provide specific instructions on how to do it. The minor comment about subtask rewards is also a statement of opinion, not an actionable suggestion. The Qmix point is a suggestion, but it's a *general* suggestion, not specific to the current paper being reviewed.", "grounding_specificity_rationale": "The reviewer refers to \"this method\" without explicitly naming the paper or the specific section describing the reward mechanism. The reference to 'sparse reward problems\" is general. The claim about 'subtaskspecific rewards\" is a possible interpretation but not directly linked to the reviewed paper. The Qmix suggestion is general.", "verifiability_rationale": "The reviewer states \"From the experiments, this does not support well.\" This is a claim. However, they *don't* provide any specific evidence or reasoning to *prove* that the method doesn't support well. They offer a potential alternative (Qmix) but don't explain *why* they think Qmix would or wouldn't work in this context. The minor comment is speculative.", "helpfulness_rationale": "The reviewer's point is about the *effectiveness* of a method in addressing sparse reward problems. While relevant to the general topic of reinforcement learning, it doesn't directly *guide* the authors on how to improve *their specific method*. The suggestion of subtask rewards is a general idea, not a specific improvement for their work. The Qmix suggestion is also too general. The lack of specific evidence makes it difficult for the authors to act on this feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point directly addresses the use of the AH36M dataset and its potential role in training. While it doesn't explicitly state whether it's used for training, it implies this through the context of a draft and the comparison with other methods. The reviewer asks for clarification, suggesting an implicit action: to investigate the training process and ensure fair comparisons. However, the action of identifying the missing information is not explicitly stated, making it somewhat implicit.", "grounding_specificity_rationale": "The review point explicitly mentions the 'AH36M dataset' and the potential issue of its usage in training. It directly refers to a specific part of the paper (the dataset) and what might be missing from it (its use in training). This demonstrates strong grounding specificity as the reviewer can precisely identify the referenced part and clearly identify the issue with it.", "verifiability_rationale": "The review point poses questions about the AH36M dataset's usage in training. These are factual questions that could be answered by referring to the authors' methodology or by conducting a quick search. The questions are based on established practices (training data) and a specific dataset, making them verifiable. While no external references are provided, the questions themselves are logically sound and directly related to the topic.", "helpfulness_rationale": "The review point raises important questions about the methodology and potential unfairness in comparisons. It encourages the authors to clarify a key aspect of their work (dataset usage) and ensures transparency. This information is valuable for the authors to improve their draft and address potential concerns about the validity of their comparisons. While it doesn't directly tell the authors what to do, it prompts them to be more explicit about their methodology, which is a crucial step in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer states 'there are some confusing mistake in the proof of the main results' without specifying which part of the proof or what the mistake is. They also say 'this paper lacks a detailed discussion and comparison with the previous work' and 'this paper seemed not to give any new insight on this field' without pointing to specific areas needing improvement. While the reviewer identifies problems, they lack the specificity needed for the authors to know exactly what to do or what information is missing.", "grounding_specificity_rationale": "The reviewer mentions 'the proof of the main results,' 'discussion,' and 'new insight' generally, but doesn't pinpoint the exact location within the paper (e.g., a specific theorem, lemma, or section). This lack of specificity makes it difficult for the authors to understand where the issues lie. Furthermore, the reviewer doesn't specify what is missing in the discussion or what new insight is lacking, making it unclear what needs to be added or improved.", "verifiability_rationale": "The reviewer makes several claims: 'there are some confusing mistakes,' 'the paper lacks a detailed discussion,' and 'the paper seemed not to give any new insight.' These are statements of opinion or judgment. However, the reviewer does not provide any specific examples, references, or logical reasoning to support these claims. The language used is speculative, and there is no evidence presented to back up the assertions.", "helpfulness_rationale": "The review point provides a general critique of the paper, mentioning issues with the proof, the lack of discussion, and the lack of new insights. However, it does not offer specific suggestions or actionable steps for the authors to take. The feedback is broad and lacks the necessary detail to be truly helpful. The reviewer points out problems but doesn't guide the authors on how to address them."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states the motivation is unclear and that the comparison is unfair due to a larger model and pretrained model. However, the reviewer does not explicitly state what specific aspects of the motivation are unclear or what concrete actions the authors should take to address these issues. The reviewer provides a general statement without offering specific, actionable steps. Therefore, the comment lacks explicit and actionable feedback.", "grounding_specificity_rationale": "The reviewer mentions 'adversarial network' and 'model' in the context of unclear motivation and unfair comparison. However, the reviewer does not explicitly identify the specific section, table, figure, or unique aspect of the paper being addressed. The reviewer refers to general concepts without pinpointing the exact location or detail in the paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer states that the motivation is unclear and that the comparison is unfair. However, the reviewer does not provide any evidence or reasoning to support these claims. The reviewer simply states the problems without explaining why they are problems or how they impact the paper. Therefore, the claims are not wellsupported by logical reasoning, common knowledge, or external references, making them 1.", "helpfulness_rationale": "The reviewer's comments are criticized as unclear and unfair. However, the reviewer does not provide specific suggestions or ask for clarification. The reviewer points out problems but does not offer concrete solutions or explain how these problems should be addressed. Therefore, the review point is not helpful for the authors in improving their draft as there are no actionable feedback provided."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desired outcome (comparison to the official COOC leaderboard) and contrasts it with the actual outcome (comparison to dev/test sets). This constitutes an implicit action: to highlight a deficiency in the current evaluation approach and suggest a more rigorous alternative. While not stated directly, the reviewer implies the action of comparing against the official leaderboard.", "grounding_specificity_rationale": "The reviewer mentions the 'official COOC leaderboard' and the 'blind test set' as specific elements of the evaluation framework. While the paper could have explicitly stated 'The results should be compared on the official COOC leaderboard using the blind test set,' the reviewer's phrasing implies a specific reference point. The 'grounding' is present, but it's not absolute certainty.", "verifiability_rationale": "The reviewer provides a link to the COOC leaderboard and mentions that 5,17 have won the challenge and been evaluated on the blind test set. This provides some level of verifiability by referencing a specific resource and demonstrating the significance of the blind test set. However, the paper could have provided more explicit references or explanations to support the claim.", "helpfulness_rationale": "The reviewer's comment directly targets improving the paper by highlighting a specific limitation in the evaluation methodology and suggesting a more comprehensive approach. The suggestion to compare against the official leaderboard is a concrete and actionable step that would likely enhance the paper's findings. This clearly benefits the authors by providing a more robust evaluation framework."}
{"actionability_label": "3. 3", "grounding_specificity_label": "5. 5", "verifiability_label": "1. 1", "helpfulness_label": "2. 2", "actionability_rationale": "The comment explicitly states an action or suggestion: \"the experimental results are unreliable, especially in Table 1, where the MSE is significantly smaller than the MAE, which raises concerns about their validity.\" While it doesn't explicitly state the next step, it clearly indicates a problem that needs addressing.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 1\" and specifies the metrics \"MSE\" and \"MAE\". This clearly identifies the specific part of the paper being addressed.", "verifiability_rationale": "The comment contains a claim: \"the experimental results are unreliable, especially in Table 1, where the MSE is significantly smaller than the MAE, which raises concerns about their validity.\" However, it does not provide any justification or evidence to support this claim. It simply states the observation without logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The comment identifies a weakness in the experimental results but does not provide any specific suggestions or actionable steps for the authors to take to address this issue. It points out the problem but doesn't offer a path forward."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment identifies the lack of novelty in the methodology but does not specify any concrete actions or improvements the authors should implement. It's a valid observation but lacks actionable steps.", "grounding_specificity_rationale": "The comment is general and does not specify which part of the paper or methodology is lacking novelty. It applies to the entire methodology.", "verifiability_rationale": "The comment is a statement of opinion about the lack of novelty, not a claim that requires verification or evidence. It's descriptive, not assertive with supporting facts.", "helpfulness_rationale": "The comment identifies a valid weakness in the methodology but does not provide specific, actionable suggestions for improvement. It's a constructive observation but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment states a fact about the loss function but does not provide any actionable steps or guidance on how to implement or apply it to the paper. It describes a training detail, not a general improvement to the draft.", "grounding_specificity_rationale": "The comment is a general statement about adversarial loss and data perturbation, without specifying which part of the paper or issue it addresses. It lacks grounding as it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The comment is a factual statement about the loss function and its goal. It does not contain a claim that requires verification or justification.", "helpfulness_rationale": "The comment is about a training detail and doesn't directly address any issues or areas for improvement in the submitted paper. It's more relevant to the training process than to the paper's content."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "X (X)", "actionability_rationale": "The reviewer explicitly states 'improve clarity' as a suggestion, making it at least 3. However, the suggestion lacks specific details on how to achieve this goal. The reviewer points to the lack of 'nuance' at L255 as the issue, implying the need for more specific guidance, but doesn't offer concrete steps for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'the nuance of this position at L255,' indicating they are addressing a specific part of the paper. However, they do not explicitly state the exact line number or section they are addressing. They are pointing to the *content* of that line. The reviewer's criticism is specific to the explanation at L248.", "verifiability_rationale": "The reviewer makes a judgment about the quality of the explanation at L248 ('the paper gets into some of the nuance of this position at L255, but it would be helpful to clarify what is meant by a good/bad/wrong explanation before using those concepts'). However, the reviewer does not provide any external references or logical reasoning to justify why the explanation is 'wrong.' They offer a definition of 'wrong' but do not explain why the explanation at L248 falls into that category.", "helpfulness_rationale": "The review point is a suggestion for improvement ('improve clarity') and does not contain a direct claim or assertion. It's an actionable suggestion, but without a specific basis for improvement, it doesn't fit the criteria for a claim."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The reviewer states that the proposed method is 'not consistently better' than other methods. While this suggests a direction for improvement, it lacks specific guidance on *how* the comparison should be expanded or *why* the proposed method is failing in the inferior cases. The reviewer does not explicitly state the actions the authors should take to address this issue. Therefore, the reviewer's point is implicit and lacks concrete action.", "grounding_specificity_rationale": "The reviewer mentions 'few methods' but does not specify which part of the comparison is lacking. They also state that the results 'violate the motivation' but do not identify the specific aspect of the motivation that is not met. The reviewer's criticism is general and does not pinpoint the exact location of the problem. While the reviewer *knows* there's an issue, they don't clearly identify *where* the problem lies within the paper or the comparison.", "verifiability_rationale": "The reviewer states that the results 'violate the motivation.' This is a claim that needs to be supported by evidence or logical reasoning. The reviewer does not provide any specific examples or justifications for why the results are inconsistent with the stated motivation. Therefore, the claim is not supported by logical reasoning, common knowledge, or external references, making it 1.", "helpfulness_rationale": "The reviewer explicitly states that the review point is '1' because the results are inconsistent and violate the motivation. This directly indicates a lack of value for the authors in the provided feedback. The authors are left without clear guidance on how to improve their method given the seemingly contradictory results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of sufficient experimental demonstration and highlights the missing comparison with Mid Vision Feedback (MVF). It suggests including the image classification result of MVF to support the claim about the superiority of the schema searched by ELF. This is an explicit and concrete action that the authors can readily implement to improve their draft.", "grounding_specificity_rationale": "The review point explicitly mentions 'Mid Vision Feedback (MVF)' and explains why its inclusion is necessary to validate the contribution points. The authors can clearly identify the specific part of the paper (experimental setup or results) where this comparison should be made. This demonstrates strong grounding specificity as the reviewer provides a clear reference point within the paper.", "verifiability_rationale": "The review point makes a claim about the *absence* of sufficient experimental demonstration and a *specific* missing comparison (MVF). However, it does not provide any logical reasoning, examples, or external references to support this claim. The verifiability of this statement depends on the authors' ability to prove their point, not the reviewer's assertion of its absence. Therefore, without evidence to support the claim itself, it is 1.", "helpfulness_rationale": "The review point directly identifies a significant weakness in the experimental validation of the paper. It provides a clear direction for improvement by suggesting a crucial comparison. This actionable feedback is highly relevant and directly addresses a key area for enhancement, making it 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states that the authors have not covered more on the types of activities captured in the datasets and their importance in smart homes. This directly points to a specific area where the authors should make improvements. The reviewer is suggesting that this information is relevant to the paper's goals, particularly regarding occupant comfort and energy efficiency. The comment is clear about the nature of the missing information and the need for its inclusion.", "grounding_specificity_rationale": "The comment refers to 'datasets' and 'smart homes' generally. While it identifies a relevant area for discussion, it doesn't explicitly pinpoint a specific section, table, figure, or unique aspect of the paper where this information should be added. The authors would need to infer the appropriate location based on the paper's structure and content. The comment is general about the types of activities and their importance, lacking specific details about which activities or how they relate to comfort and energy efficiency.", "verifiability_rationale": "The comment contains a claim that the authors have not covered more on the types of activities and their importance in smart homes. The reviewer provides a logical reasoning for this claim, suggesting that this information is crucial for occupant comfort and energy efficiency. However, the claim lacks specific examples or references to external works to support the assertion that this information is indeed missing and important. The reasoning is present but lacks concrete evidence.", "helpfulness_rationale": "The comment identifies a clear gap in the authors' discussion by pointing out the absence of a detailed explanation of the types of activities captured in the datasets and their significance for occupant comfort and energy efficiency. This is a relevant and actionable suggestion for the authors. By highlighting this gap, the reviewer guides the authors to expand their discussion and provide a more comprehensive analysis of their dataset in the context of smart home applications. This feedback is directly helpful in improving the paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states the problem (D used for two different things) and suggests a solution (use different notation). This is a clear and direct action. The reviewer is pointing out a specific issue and offering a concrete fix.", "grounding_specificity_rationale": "The reviewer refers to the symbol 'D'. While they don't explicitly say 'D is in Section X', the context implies it's related to the summary. The grounding is *weak* because the reviewer has to infer that 'D' relates to the summary. However, the comment is *specific* about the *meaning* of 'D' \u2013 it's suggesting it's being used for two different things. This specificity is high *within* the context of the summary.", "verifiability_rationale": "The review point is making a judgment: 'D is used to represent both dimensionality of points and dilation factor. Better to use different notation to avoid confusion.' This is a statement of opinion and a suggestion. While it doesn't *necessarily* *need* verification (it's a suggestion for clarity), it's a *recommendation*. The lack of external references is clear. The lack of logical reasoning is also clear \u2013 it's a suggestion, not a claim requiring proof.", "helpfulness_rationale": "The review point is relevant and suggests a concrete change to improve clarity. While it might not be *critical* confusion, it's still a valid point. The reviewer is pointing out a potential source of ambiguity and suggesting a specific solution. This is generally helpful for the author's understanding and potentially the paper's presentation. It's not a completely useless comment, but it's not a groundbreaking insight either."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their understanding of 'state' as 'agent position' and asks a direct question about the meaning of 'elements' in relation to this understanding. This is an explicit action, and the reviewer provides a concrete example to support their interpretation. The action is clear and directly addresses a potential point of confusion.", "grounding_specificity_rationale": "The reviewer directly refers to lines 186187 of the paper, indicating a specific part of the text they are concerned about. They also ask a question about the relationship between 'elements' and their understanding of 'state,' further specifying the area of confusion. This shows a clear identification of the specific aspect of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim that 'elements' are equivalent to their understanding of 'state' (agent position). While the paper describes 'elements' as the 'input to the environment,' it doesn't explicitly state that these are the same as the agent's 'position.' The reviewer is prompting for clarification, suggesting the connection isn't immediately obvious or explicitly stated in a verifiable way.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential point of confusion regarding the definition of 'state' and 'elements' in the context of the reinforcement learning framework. By asking for clarification, they are actively seeking to improve their understanding of the method. While the paper describes 'elements,' the reviewer's point highlights a potential lack of clarity or explicit connection to their interpretation of 'state'."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point is a question about comparing support, not a directive to the author. It doesn't explicitly state what needs to be done or how to achieve it. The reviewer asks 'how' to compare, implying a need for further clarification, but doesn't provide a concrete action. Therefore, it lacks explicitness and concreteness required for actionability.", "grounding_specificity_rationale": "The review point is about comparing support in general, not a specific part of the paper. It doesn't identify a unique section, table, figure, or aspect where this comparison is being made. The grounding is implicit and broad, lacking specificity to a particular element of the paper. Therefore, it doesn't identify a specific part, making it 1.", "verifiability_rationale": "The review point is a question, not a declarative statement that makes a claim. It doesn't assert anything about the paper or propose a solution that can be verified. Verifiability requires a claim that can be supported by evidence. Since there's X, there's nothing to verify. Therefore, it doesn't contain a claim that can be evaluated for verifiability.", "helpfulness_rationale": "The review point is a question about comparing support, which is a valid area for improvement. However, it doesn't provide specific, actionable feedback or suggestions to the author. It asks a question but doesn't directly guide the author on how to implement the comparison or why it's important. The helpfulness is limited to raising awareness of the concept of support, but it doesn't offer concrete steps or insights. Therefore, it's not 5 as it doesn't directly address the author's needs for improvement in a specific way."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific experimental observation (generator collapse with RGCN discriminator vs. the proposed module) and explicitly states a missing explanation (the mechanism behind the proposed module's stability). While the reviewer doesn't explicitly state an action or a concrete step, the request to 'see why the proposed module can prevent a generator from collapsing' implies a desire for a specific type of action (explanation of the mechanism).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Sec 5.3' and compares 'a generator equipped with a standard RGCN as discriminator' with 'the proposed module.' This clearly identifies the specific part of the paper and the elements being discussed, making the grounding explicit. However, the reviewer does not specify *what* is wrong with the RGCN discriminator or *how* the proposed module prevents collapse, making the specificity somewhat lacking.", "verifiability_rationale": "The reviewer presents a factual observation ('a generator equipped with a standard RGCN as discriminator tends to collapse...') and a request for an explanation ('I would like to see why the proposed module can prevent a generator from collapsing'). The observation itself could potentially be verified through analysis or experimentation, making it partially verifiable. However, the request for explanation is not a claim that can be verified, making the overall verifiability somewhat ambiguous.", "helpfulness_rationale": "The reviewer identifies a specific experimental observation and explicitly requests an explanation for a discrepancy. This directly points to a potential weakness in the submission (lack of explanation for the stability). The request is clear and directly addresses a relevant aspect of the proposed method. While it's a request, it's a specific and relevant request for improving the understanding of a key mechanism."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue (resemblance) but doesn't provide a clear action for the authors to take. It asks a question about novelty, which is a valid concern, but doesn't specify what needs to be changed or how to address it. The suggestion is vague. Is the extension 'trivial'? 'Significant'? The degree of novelty is unclear.", "grounding_specificity_rationale": "The review refers to the 'article's reasoning and writing logic' generally, without pinpointing a specific section, figure, or table. The reviewer asks a question about novelty, which is a valid concern, but doesn't pinpoint a specific problematic element within the reasoning or writing logic. The grounding is weak because it's hard to know exactly where the similarity is impacting the work.", "verifiability_rationale": "The review points out a similarity and asks a question about novelty. These are more like observations or questions than explicit claims that need verification. There is no clear claim, so it falls into the 'X' category (X).", "helpfulness_rationale": "The review raises a valid concern about the potential lack of novelty. However, it doesn't offer a concrete solution or actionable steps for the authors to address this concern. It's more of a question and observation. While it identifies a potential issue, it lacks the actionable elements needed for significant improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment identifies a potential area for improvement (unclear theoretical comparisons) but does not explicitly state what aspect of the comparison is unclear or how the authors should go about clarifying it. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The comment mentions 'adaptive learning of GPRGNN' which provides some grounding by naming a specific area. However, it does not specify which part of the GPRGNN method or the comparison process is unclear. The specificity of the referenced part is weak.", "verifiability_rationale": "The comment does not contain a claim that can be verified. It's a statement of uncertainty or lack of clarity, not a critique supported by evidence or reasoning.", "helpfulness_rationale": "The comment points out a potential issue (unclear theoretical comparisons) but does not offer any specific advice or guidance on how to address it. It lacks concrete suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their suggestion: 'Consider using a more nuanced evaluation method, such as a Likert scale or a detailed annotation scheme.' This clearly indicates an action the authors should take.", "grounding_specificity_rationale": "The reviewer's suggestion to use a Likert scale or a detailed annotation scheme is grounded in the limitations of yes/no responses. They explicitly state that yes responses 'may not indicate that the model comprehends the presence of the object in the image.' This shows an attempt to identify the specific issue and propose a solution. However, the suggestion itself is somewhat general, not pinpointing a specific part of the paper or a unique element.", "verifiability_rationale": "The reviewer makes a claim: 'Yes response does not necessarily indicate that the model comprehends the presence of the object in the image, as it may still produce incorrect objects when undertaking other tasks.' This claim is supported by logical reasoning \u2013 the binary nature of yes/no responses doesn't capture the nuances of object comprehension or potential errors in other tasks. While it lacks specific examples, the reasoning is clear and based on common understanding of evaluation metrics.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'Consider using a more nuanced evaluation method, such as a Likert scale or a detailed annotation scheme.' This directly addresses a potential limitation of the current evaluation method and offers a concrete alternative. While the suggestions are general, they are likely to be helpful for researchers working on object hallucination."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states actions to be taken, such as 'conducing experiments on more datasets' and 'training the baseline models with the 'correct' forecast horizon.' These actions are further detailed, making the comment 5.", "grounding_specificity_rationale": "The review point directly refers to 'the verylongterm forecasting task,' providing a clear and specific reference point within the paper. It also offers concrete suggestions for improvement related to this specific task.", "verifiability_rationale": "The review point contains a claim about the 'limited practical significance' of the verylongterm forecasting task. While the suggestions for improvement ('conducing experiments on more datasets' and 'training the baseline models with the 'correct' forecast horizon') are verifiable through experimentation, the initial claim lacks supporting evidence or external references, making it 3.", "helpfulness_rationale": "The review point is 4 as it provides clear and actionable suggestions for improving the evaluation of the verylongterm forecasting task. While it begins with a subjective observation about the task's significance, it offers concrete directions for further experimentation and analysis, empowering the authors to consider these improvements."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the missing components as 'experiments and explanation regarding the different queries used in spatiotemporal representation' and suggests exploring 'what if only have spatial one, or temporal and summary one?'. This indicates a clear and actionable request for the authors to include more detailed experimental analysis and explore different configurations of their queries. The reviewer provides a clear direction for improvement by specifying the type of experiments needed and the variations to consider.", "grounding_specificity_rationale": "The reviewer mentions 'experiments' and 'different queries' but doesn't specify a particular section, table, or unique element of the paper where these experiments are located. While the reviewer identifies the *type* of queries (spatial, temporal, summary), the overall *area* of the experiments is not precisely grounded. The grounding is present at a general level, but the specificity of the grounded element is limited.", "verifiability_rationale": "The reviewer makes a claim that 'experiments and explanation regarding the different queries used in spatiotemporal representation, i.e., spatial, temporal and summary' are missing. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a suggestion for improvement rather than a verified assertion. Therefore, the claim is not fully supported by evidence.", "helpfulness_rationale": "The reviewer identifies a clear gap in the experimental evaluation by pointing out the absence of experiments and explanation regarding different query types. They also suggest exploring variations of these queries, which is a valuable direction for the authors to consider. While the reviewer doesn't provide concrete evidence of the missing experiments, their suggestion is actionable and addresses a specific aspect of the model's design. The reviewer's point is helpful in guiding the authors to further investigate and potentially improve their model's spatiotemporal representation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the proposed FRM is a 'simple combination' of channel attention and spatial attention and lacks 'indepth innovative detail'. This is an explicit statement about the method's composition and a request for more specific information about its innovation. While the reviewer identifies a potential area for improvement, the lack of detail makes it difficult to pinpoint exactly what is meant by 'simple combination' or 'indepth innovative detail'.", "grounding_specificity_rationale": "The reviewer mentions 'channel attention' and 'spatial attention' as components of the FRM. While these are specific techniques, the reviewer does not explicitly identify the specific section, table, figure, or unique aspect of the paper where these concepts are discussed. The reviewer also does not specify which particular channel or spatial attention mechanisms are being referred to. The lack of specificity in identifying the exact part of the paper being addressed makes the grounding somewhat weak. However, the reviewer does point to specific technical terms, which provides a degree of grounding.", "verifiability_rationale": "The reviewer makes a claim that the proposed FRM is a 'simple combination' of channel attention and spatial attention. To verify this claim, one would need to examine the authors' method description to see if they explicitly state or imply this combination. However, the reviewer does not provide any evidence or justification to support this claim. The lack of detail in the reviewer's assessment makes it difficult to verify this statement. The reviewer also claims a lack of 'indepth innovative detail', which, while not a direct claim about verifiability, contributes to the lack of verifiable information about the method's novelty.", "helpfulness_rationale": "The review point identifies a potential issue with the authors' description of their proposed FRM, suggesting it might be a 'simple combination' of existing attention mechanisms and lacking 'indepth innovative detail'. This is a helpful comment as it points out a specific area for improvement in the authors' work. However, the lack of specificity in the reviewer's assessment makes it difficult for the authors to pinpoint exactly what is meant by 'simple combination' or 'indepth innovative detail'. This lack of clarity reduces the helpfulness of the comment, as the authors have a general direction for improvement but lack concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's comment is an *implicit* statement regarding a potential weakness (the lack of anticipated negative impact). While the reviewer suggests *specific examples* (increased automation, dual use risks) as potential areas for the authors to address, the *action* isn't fully clear. The authors could improve the paper by *discussing* the societal impact, even if they don't believe it's negative. The reviewer's suggestion is helpful but not a direct instruction for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions the authors' statement about 'no negative social impacts' made at 'line 379'. This is a clear reference to a specific part of the paper. The reviewer then *specifies* the potential impacts by mentioning 'increased automation' and 'risks from the dual use of their method'. This adds further specificity to the discussion.", "verifiability_rationale": "The reviewer's comment is a statement of opinion ('I do not believe this work has the potential for significant negative social impact') and a suggestion for improvement ('the authors could always mention...'). It's not a claim that requires verification. Therefore, it's **1**.", "helpfulness_rationale": "The reviewer's primary point is to encourage the authors to discuss societal impact. While this is helpful, it's a suggestion rather than a direct instruction for improvement. The reviewer acknowledges this uncertainty ('I'm not quite sure if/how I'm meant to review this aspect of their work'). This suggests the comment is somewhat incomplete or open to interpretation. Therefore, it's **3**."}
{"actionability_label": "4 (4)", "grounding_specificity_label": "4 (5)", "verifiability_label": "X (X)", "helpfulness_label": "4 (4)", "actionability_rationale": "The reviewer explicitly states 'reorganize Sections 3 and 4,' which is a direct and clear action. While the reviewer doesn't specify *how* to reorganize, the suggestion itself is a concrete action that the authors can take. The reviewer is pointing out a potential issue and offering a solution, which is more actionable than simply stating a problem.", "grounding_specificity_rationale": "The reviewer refers to 'Sections 3 and 4,' which are specific parts of the paper. They further specify the *exact* parts to be moved ('the first paragraph of sec 4' and 'the remainder of sec 4'). This demonstrates a high level of specificity in identifying the relevant sections and the specific elements within them that are being considered for reorganization. The authors can easily pinpoint the areas being discussed.", "verifiability_rationale": "The reviewer's comment is primarily a suggestion for improvement rather than a claim that requires verification. They are proposing a reorganization based on their perception of potential redundancy. While the suggestion itself is logical and potentially helpful, it doesn't present a verifiable fact or require external references to be considered valid. The reviewer is offering a constructive idea, not a statement that needs to be proven.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by proposing a reorganization of Sections 3 and 4. They identify a potential issue (redundancy) and offer a specific solution (moving the first paragraph of Section 4 to the beginning of Section 3 and the remainder before Section 3). This is a concrete and actionable suggestion that directly addresses a potential weakness in the current structure. The authors can readily understand and implement this change. While it might not be a groundbreaking insight, it is a valuable piece of feedback that directly points towards a potential improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of connection between the two aspects, which constitutes an action. However, the specifics of where this disconnect is most apparent are not clearly identified, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions the two concepts ('improved variance control of prediction y^ or the smoothness of loss landscape' and 'zeroshot learning effectiveness'), indicating some grounding. However, the specific part of the paper being addressed is not explicitly identified, making the grounding weak. The reviewer also mentions the lack of clarity as the reason for the unclear connection, which specifies what needs to be addressed, adding a degree of specificity. However, the overall grounding is still weak because the section or table isn't pointed out.", "verifiability_rationale": "The reviewer states that there is a 'lack of connection' between the two aspects. This constitutes a claim. The reviewer attributes this lack of connection to 'poor clarity'. While this provides some justification, it is not a strong or specific example of poor clarity, making the verifiability somewhat borderline.", "helpfulness_rationale": "The reviewer points out a potential misunderstanding or a gap in the paper's explanation regarding the connection between the two aspects. While this could be helpful for the authors to clarify their work, the lack of explicit grounding and the weak justification for the claim make the overall helpfulness somewhat limited."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "Partially Verifiable", "helpfulness_label": "2", "actionability_rationale": "The reviewer states a suggestion for deeper analysis but doesn't explicitly define how to perform it, making the action implicit.", "grounding_specificity_rationale": "The reviewer identifies a lack of explanation for why certain methods perform better, making the grounding weak. The specificity is also underspecified as the reviewer doesn't pinpoint the exact missing elements.", "verifiability_rationale": "The reviewer makes a claim about the missing rigorous analyses, but the verifiability is partially verifiable because the paper presents results but lacks the explanation the reviewer is asking for.", "helpfulness_rationale": "The reviewer's comment is a request for improvement, not a direct critique of the paper's current content. It provides some feedback but lacks the actionable improvement to directly guide the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review points out a *lack* of discussion. It's not *saying* something is missing, but *asking* where it is. This leans towards implicit. The question is general. It doesn't specify *where* else the problem was discussed or *what* was discussed. It's a broad request for information. This is very vague.", "grounding_specificity_rationale": "The reviewer is asking \"Where else...\" This is a general question. They *don't* specify a particular section, table, or figure. They don't even imply a specific location. The grounding is weak. The question is about the *kmax problem* itself, but it doesn't specify *what* was discussed or *where* it was discussed. The specificity is low.", "verifiability_rationale": "The request is a question and a request for information (a citation). It's not making a claim that needs verification. It's a request for external information. While it *could* be considered a request for justification of their own work in relation to prior work, the review itself doesn't make a claim about *their* work's novelty or contribution in this specific regard. It's a request for information about * someone else's work.", "helpfulness_rationale": "The request for a citation is a common and valid request in academic writing. It directly addresses the need to contextualize the work within existing literature. While it doesn't directly tell the authors *how* to improve their draft, it provides a crucial piece of information that will likely lead to improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states a lack of information and implicitly asks for it. While it points to a specific element (Equation 1), it doesn't provide the details of how the function was estimated. This makes it an implicit instruction but not a fully explicit one.", "grounding_specificity_rationale": "The review point mentions 'the function for the optimal sequence length' and 'Equation 1'. While it doesn't explicitly name a section, table, or figure, the reference to a specific element of the paper allows for inference. However, it doesn't specify what the implications are for the authors' work or why this information is crucial.", "verifiability_rationale": "The review point contains a claim: 'There is no information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable we expect this model to be.' However, it does not provide any justification or references to support this claim. It simply states the absence of information.", "helpfulness_rationale": "The review point identifies a missing piece of information relevant to the authors' work. However, it doesn't provide any suggestions or guidance on how to address this lack of information or what the implications are for their specific research or methodology. It raises a concern without offering a constructive solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the 'strong assumptions' required for the methods to work, such as 'extrinsics and intrinsics are known' and 'object segmentation'. This directly identifies a limitation and provides a clear action for the authors to take \u2013 they need these assumptions to be met for the methods to be applicable. The reviewer also implies that the lack of these assumptions limits the realworld applicability, which is a concrete action the authors can consider.", "grounding_specificity_rationale": "The reviewer refers to 'strong assumptions about the availability of camera parameters (extrinsics and intrinsics are known) and object segmentation.' This explicitly names the specific parts of the paper or concepts being discussed, providing full grounding. Furthermore, the reviewer specifies what is missing \u2013 the lack of these parameters and segmentation \u2013 and what the consequence is \u2013 limited applicability. This specificity clearly identifies the issue.", "verifiability_rationale": "The reviewer states a limitation ('The applicability... is rather limited...') and provides a logical explanation for why this limitation exists ('strong assumptions are made about the availability of camera parameters... and object segmentation'). This explanation, without requiring external references, verifies the claim. The reviewer implies that the methods 'require' these parameters and segmentation, making the claim verifiable.", "helpfulness_rationale": "The review point directly addresses a crucial limitation for the practical application of the methods. By highlighting the strong assumptions required (extrinsics, intrinsics, object segmentation), the reviewer provides the authors with a clear understanding of the scope and limitations of their work. This actionable feedback helps the authors consider alternative approaches or data requirements, making the review 5 for improving their draft in a realworld context."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the inaccuracy of the number and suggests a specific way to improve the description. While the action is implied (the authors need to correct the number and add detail), it is concrete enough that they know exactly what needs to be done. The suggestion to add 'on the subword level' is a specific action.", "grounding_specificity_rationale": "The review point directly mentions a specific line number (L006), which is strong evidence of good grounding. The authors can easily identify the section being referred to. Furthermore, the review point specifies the *type* of inaccuracy (the number being too small) and even suggests a specific way to fix it ('add 'on the subword level''). This level of detail indicates high specificity.", "verifiability_rationale": "The review point contains a claim that 'thousands' is not accurate. This claim is supported by the suggestion to change it to 'millions' and add 'on the subword level'. While it doesn't provide a direct citation, the logical connection between the identified inaccuracy and the suggested fix makes it 3. The authors can infer the need for verification and the suggested approach.", "helpfulness_rationale": "The review point is directly pointing out a factual error in the paper and suggesting a concrete improvement. This is 5 for the authors as it directly addresses a discrepancy and provides a clear direction for correction. The suggestion to add 'on the subword level' is a specific and actionable piece of feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions the absence of hyperparameters and suggests providing them. This is an explicit action. For the figure behavior, the reviewer infers that the y=0 at x=0 might be due to normalization, which is an implicit action that could be made concrete by suggesting a specific normalization method. For the further analysis suggestion, the reviewer explicitly states 'I would be interested in seeing some further analysis on this model, perhaps using the interpolations themselves', which is an explicit action.", "grounding_specificity_rationale": "The review point explicitly mentions 'regularization' as an example of a hyperparameter, which grounds the discussion to a specific part of the paper. It also generally refers to 'latent path figures' and then specifically asks about 'why is the y value at x= 0 always 0?', indicating a clear grounding to the figure. The suggestion to use 'the interpolations themselves' also grounds the discussion to a specific element of the model.", "verifiability_rationale": "The review point does not explicitly state a claim about the missing hyperparameters. It infers that the y=0 at x=0 might be due to normalization, which is a claim that could be supported by external references or logical reasoning. The suggestion to use 'the interpolations themselves' is a suggestion without a claim requiring immediate verification.", "helpfulness_rationale": "The suggestion to provide specific hyperparameters is generally helpful for reproducibility. The suggestion to investigate the y=0 at x=0 behavior is helpful but lacks specific guidance on how to do it. The suggestion to use 'the interpolations themselves' for further analysis is a very helpful suggestion that directly addresses a potential area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly mentions two issues: 'material is introduced without proper explanation' and 'material supporting the main contributions seems to be in the appendix and not the main sections'. These are explicit statements that authors can directly address. However, the review point does not provide specific guidance on *how* to improve the explanation or reorganize the content. The actions are identified but not detailed.", "grounding_specificity_rationale": "The review point explicitly refers to 'Figure 1' and mentions the 'deeprag algorithm' and 'discussion on the high concurrency'. These are specific parts of the paper being addressed. However, the reviewer does not specify *what* is wrong with Figure 1 or how the deeprag algorithm or high concurrency discussion should be improved. The grounding is present, but the specificity of the issues is not detailed.", "verifiability_rationale": "The review point makes factual observations about the paper's structure and content: 'material is introduced without proper explanation' and 'supporting the main contributions seems to be in the appendix'. These are claims that can be verified by examining the paper. However, the review point does not provide *justification* for why these issues are problematic or why the content is misplaced. The claims are stated but not logically supported or referenced to external knowledge.", "helpfulness_rationale": "The review point identifies two key weaknesses in the paper: the lack of explanation for introduced material and the placement of key components in the appendix. While these are valid points, the review point does not offer specific suggestions or guidance on how to address these issues. The feedback is identified but lacks actionable recommendations."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks two questions: 'What is the effect on the approximation in the full tensor error?' and 'Is there any error bound in terms of epsilon?'. These are direct requests for information, making the action somewhat explicit. However, the reviewer does not specify *how* they want this information, leaving the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'the paper it is mentioned that the obtained core tensors can be rounded...', providing a clear reference point within the paper. This indicates strong grounding. Furthermore, the reviewer asks specifically about the 'error bound in terms of epsilon', which is a precise and specific request related to the mentioned rounding method, indicating high specificity.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question about a specific aspect of the paper. Therefore, the 'X' category applies.", "helpfulness_rationale": "The reviewer is asking a question directly related to the paper's content and seeks clarification on a specific methodological aspect. While it doesn't directly identify a bug or error, it seeks to understand the implications of a method. This information can be helpful for the authors to better understand and potentially improve their work. Therefore, it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing information in Table 1 and clearly indicates the generative setting. The action is to look for the results in the generative setting, and the details are provided in the comment.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 1' and the two 'test settings' (discriminative and generative), clearly identifying the specific part of the paper being addressed. The information requested is also very specific: 'the result on the generative setting'.", "verifiability_rationale": "The reviewer is not making a claim but rather asking a question. There is no statement that requires verification.", "helpfulness_rationale": "The reviewer directly points out a missing piece of information in the results table and asks for it. This directly guides the authors to look for the generative setting results, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point is a statement of opinion about the feasibility of 'SEARCH' queries. It doesn't propose any concrete actions or modifications to the paper. Therefore, it's 1.", "grounding_specificity_rationale": "The comment uses generic terms like 'query of the type SEARCH' and 'realistic scenario' without linking them to any specific part of the paper or document. This lack of specificity means it's 1.", "verifiability_rationale": "The comment is more of a suggestion for improvement than a declarative statement that requires verification. There's no 'yes' or 'no' question, and no specific evidence is being referenced.", "helpfulness_rationale": "While the comment identifies a potential area for improvement, it lacks concrete suggestions or actionable steps. It's a direction for improvement, but not a direct solution, making it 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a potential weakness (unknown effectiveness for other languages) but doesn't provide any actionable steps or specific information to address it. It's a diagnosis, not a prescription.", "grounding_specificity_rationale": "The reviewer is expressing a concern about a general aspect of the approach's applicability, not specifically referencing a previously mentioned section or detail. It's about 'other language families' in general, without specifying which ones or providing context.", "verifiability_rationale": "The comment points out a potential issue ('unknown effectiveness') but doesn't provide any evidence or justification to support why it's unknown. It's a statement of a problem without further explanation or references.", "helpfulness_rationale": "The comment highlights a potential area for improvement but lacks specific details or actionable steps. It's a mild suggestion to investigate further, rather than a concrete improvement plan."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the authors 'do not analyze the security (i.e., protection of the privacy) of the proposed framework'. This directly points to a missing action. However, it does not specify *how* this analysis should be conducted, leaving the authors with a general direction but lacking specific guidance on the implementation. Therefore, while the action is identified, the details are missing, making it 3 but not fully actionable.", "grounding_specificity_rationale": "The comment explicitly refers to 'the security (i.e., protection of the privacy) of the proposed framework'. This directly identifies the specific part of the paper being addressed. While it mentions 'privacy' as a specific aspect of security, it doesn't pinpoint a unique element within that framework. Therefore, the grounding is explicit, but the specificity is slightly lacking.", "verifiability_rationale": "The comment makes a clear claim: 'the authors do not analyze the security (i.e., protection of the privacy) of the proposed framework'. This claim is supported by the common understanding that a thorough evaluation of security, including privacy, is a standard expectation in the field. There is no missing information or external references needed to understand this claim. Therefore, the claim is wellsupported and verifiable.", "helpfulness_rationale": "The comment clearly identifies a significant deficiency in the authors' work: the absence of a privacy analysis. This is a valuable piece of feedback as it directly points to an area where the authors can improve their work. While the comment doesn't provide specific suggestions for how to perform the analysis, it does highlight a concrete need for such an analysis. Therefore, the feedback is clear and relevant to the authors' draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their desire for a description near line 135, making the action explicit. However, the reviewer does not specify *how* this description should be provided, making it implicit. Therefore, while the action is explicit, the lack of detail makes it only partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'near line 135,' which provides a specific location in the paper, indicating weak grounding. However, the *content* of what should be described at line 135 is not specified, making the grounding incomplete and not specific.", "verifiability_rationale": "The reviewer makes a claim that 'it would help if the form of p was described somewhere near line 135.' This is a claim that needs to be verified. The reviewer *assumes* it is a Gaussian distribution without providing justification or evidence. Therefore, the claim is made without sufficient support, making it 1.", "helpfulness_rationale": "The reviewer points out a lack of clarity in the paper and suggests a specific improvement (describing the distribution at line 135). While this points to a valid issue, the suggestion lacks specificity and detail. The reviewer doesn't explain *why* this is a problem or *why* they think it's important to describe the distribution. Therefore, the helpfulness is limited as the suggestion is vague and lacks context."}
{"actionability_label": "2", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that 'related work could be improved' but does not specify any concrete actions or modifications that the authors should make. While the reviewer identifies a problem, they do not provide any guidance on how to address it. The lack of explicit and actionable suggestions makes this review point less helpful for the authors.", "grounding_specificity_rationale": "The review point mentions 'related work' generally but does not pinpoint a specific section, table, figure, or unique element within the paper. The reviewer implies that the related work is unclear, but they do not specify which part of the related work needs improvement or what aspects are lacking. This lack of specific identification makes the grounding of the review point weak.", "verifiability_rationale": "The review point makes a claim that 'related work could be improved' but does not provide any evidence or reasoning to support this claim. The reviewer states a problem but does not explain why the related work is unclear or suggest any specific examples or references to back up their assertion. Without supporting evidence, the claim remains 1.", "helpfulness_rationale": "The review point identifies a weakness in the related work section but fails to offer any constructive suggestions or directions for improvement. The reviewer acknowledges the lack of differences between related works but does not propose any specific actions to address this issue. The review point is essentially a negative statement without any positive or actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the importance of understanding PPP effects using PPP maps but does not provide any actionable steps or specific details on how to achieve this understanding. The reviewer asks a direct question about the type of understanding one reaches by looking at the PPP maps, indicating a lack of clarity on the expected outcome. This suggests the reviewer's point is not actionable as it is presented.", "grounding_specificity_rationale": "The review point does not explicitly identify the specific aspect of the paper being addressed. The reviewer is asking a general question about the understanding of PPP effects using maps. There is no mention of a specific section, table, figure, or unique element of the paper. Therefore, the grounding is weak as the reviewer cannot pinpoint the area being discussed.", "verifiability_rationale": "The review point raises a question about the understanding of PPP effects using maps. While the reviewer implies that the paper should explain this understanding, the paper itself does not explicitly state what type of understanding is expected. The reviewer's point is a suggestion for improvement rather than a claim that can be verified with evidence from the paper.", "helpfulness_rationale": "The review point identifies a potential improvement to the paper by suggesting a more detailed explanation of PPP maps and their implications for understanding PPP effects. While the paper itself doesn't explicitly address this, the reviewer's point is a constructive suggestion for enhancing the clarity and impact of the work. The reviewer's question directly points to a potential gap in the current explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the lack of comparison with other stateoftheart methods, which can be considered an implicit action suggesting the reviewer wants a comparison. While the reviewer doesn't identify a specific part of the paper being addressed, the suggestion itself is a clear action for the authors to take.", "grounding_specificity_rationale": "The comment refers to 'other stateoftheart methods' generally, which is vague and doesn't pinpoint a specific part of the paper. However, when the specific method 'SpanBERT' is mentioned, it clearly specifies what needs to be addressed. Therefore, the grounding is weak until the specific method is mentioned.", "verifiability_rationale": "The comment contains a claim (lack of comparison) and mentions specific methods (SpanBERT) which can serve as external references. However, it doesn't explain *why* this comparison is important or *how* the authors should go about it. The claim is stated, but the reasoning and justification are lacking.", "helpfulness_rationale": "The comment identifies a valid weakness (lack of comparison) and provides a suggestion (comparing with SpanBERT). However, the suggestion lacks detail and doesn't explain *why* this comparison is crucial or *how* the authors should perform it. The reviewer identifies a problem but doesn't provide a fully developed solution, making it 3 but not entirely helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point directly addresses a potential inconsistency in the paper's discussion of regret. The reviewer explicitly points out the statement \"the regret cannot be sublinear\" and the subsequent proof of T^(1/2) regret. The reviewer is asking for clarification on what is meant by 'sublinear\" in this context. This is a clear indication of an actionable request. The reviewer proposes a clarification to resolve the ambiguity.", "grounding_specificity_rationale": "The review point directly refers to the lines mentioned by the reviewer (lines 32  37). The reviewer provides a clear reference point for where the issue lies in the paper. The comment is explicitly linked to a specific section of the text.", "verifiability_rationale": "The review point doesn't present a claim that requires verification. It's a question about the interpretation of a statement within the paper. There's no assertion of a fact that needs supporting evidence. The reviewer is seeking clarification, not proposing a new piece of information that needs verification.", "helpfulness_rationale": "The review point identifies a potential source of confusion for the authors regarding the definition of 'sublinear\" in the context of regret. While it doesn't directly propose a solution, it highlights a gap in the clarity of the paper. It points to a specific area where the authors might need to reread or clarify the paper. This is a helpful point that guides the authors to understand a specific concept better."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for the authors to 'explain the forwardprediction model' and even suggests a specific action, 'redrawing the figure.' This is a clear call for action, making the review actionable. The reviewer directly identifies the missing explanation as a problem, which is a concrete action the authors should take.", "grounding_specificity_rationale": "The reviewer specifically mentions 'Figure 2(b) does not really show the schematic representation of the forward prediction model' and highlights the difficulty in connecting the 'pieces of the text with the figure as well as the equations.' This indicates a clear understanding of the specific part of the paper and its lack of clarity in relation to the surrounding information, demonstrating strong grounding specificity.", "verifiability_rationale": "While the reviewer states that the model is 'not well explained' and 'Figure 2(b) does not really show the schematic representation,' these statements, in themselves, could be considered 1 without specific examples of missing information or logical gaps. However, the reviewer's suggestions to 'redraw the figure' and the general feedback about the difficulty in connecting the text, figure, and equations, *could* be argued as implicitly suggesting that the schematic is missing or unclear, which could be considered partially verifiable. However, without concrete examples of missing citations or logical reasoning, it's borderline.", "helpfulness_rationale": "The reviewer provides concrete suggestions such as 'It was hard to connect the pieces of the text with the figure as well as the equations' and 'recommend to redraw the figure.' These are actionable and directly address the authors' understanding of the model, making the review 5. The reviewer's suggestions are specific and directly aimed at improving the authors' ability to understand and work with the model description."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the idea of training only on rewarded actions in RBI and suggests that the absence of supervision from rewardless actions could be a factor in FP+RBI's success. However, the reviewer does not provide specific details on how to implement this change or what types of rewardless actions would be most beneficial. The suggestion is present, but the lack of concrete action makes it 2.", "grounding_specificity_rationale": "The reviewer mentions 'RBI training' and 'rewarded actions' generally. While they imply it's related to their experiments, they do not specify a particular section, table, or unique element in the paper that they are referring to. The reference is vague, indicating weak grounding. Furthermore, while they mention the potential benefit of rewardless actions, they do not specify *which* actions or provide examples, making the grounding even less specific.", "verifiability_rationale": "The reviewer makes a claim that 'This could be one significant factor that makes FP + RBI better than RBI alone.' This claim is presented as a possibility without providing any evidence, reasoning, or references to support it. The reviewer does not offer any logical reasoning, common knowledge, or external references to back up their assertion. Therefore, the claim is not wellsupported, making it 1.", "helpfulness_rationale": "While the reviewer raises a valid point about a potential limitation of the standard RBI approach and suggests that incorporating supervision from rewardless actions could improve FP+RBI's performance, the review point lacks the necessary details to be truly helpful. The suggestion is not specific enough for the authors to implement it directly. The reviewer also requests a stronger baseline for the RB, which, without further elaboration, remains a vague suggestion. The lack of concrete actionability and the unsupported nature of the claim limit the helpfulness of the review point."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states two points: (1) the multiscale statement is misleading regarding physical time scales, and (2) the benefit of the slow RNN is reduced gradient path mitigation. These are direct and clear criticisms of the paper's description. The reviewer provides a specific alternative explanation for the first point and a clear specification of the benefit for the second. There's no ambiguity about what needs to be addressed.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific part of the paper being discussed \u2013 the \"multiscale statement.\" They also specify the potential misunderstanding regarding \"physical time scales\" and the benefit of the slow RNN in terms of \"reduced gradient path.\" This demonstrates strong grounding as the reviewer can accurately pinpoint the referenced part and clearly detail what is being criticized or explained.", "verifiability_rationale": "The reviewer provides a clear explanation for their claim about the misleading statement, linking it to the logical processing of sequential data in graph structures. For the benefit of the slow RNN, they specify the mechanism as \"reduced gradient path.\" While they don't provide external references, the reasoning is based on fundamental understanding of RNNs and graph neural networks. The claims are supported by logical reasoning and a clear explanation of the underlying mechanisms.", "helpfulness_rationale": "The reviewer provides a clear critique of a specific aspect of the paper and offers a specific alternative explanation. They also highlight a beneficial aspect (the slow RNN's role in gradient mitigation). This feedback is actionable and provides valuable insights for the authors to improve their understanding and potentially refine their approach. The reviewer's points are specific and directly address potential ambiguities in the paper's description."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the weakness of baseline methods and the lack of discussion on limitations. While it identifies a problem, it doesn't specify *how* to improve the baselines or *how* to address the limitations. The suggestions are general and lack concrete steps.", "grounding_specificity_rationale": "The review point refers to 'baseline methods' generally and doesn't specify a particular section, table, figure, or unique element of the paper. The grounding is weak because it's not tied to a specific part of the paper being discussed.", "verifiability_rationale": "The review point makes claims about the weakness of baseline methods and the lack of discussion on limitations. While these are valid observations, the evidence provided is somewhat general and lacks specific examples or references to external works to fully support these claims.", "helpfulness_rationale": "The review point identifies a valid issue (weak baselines) and suggests a potential direction for the conclusion. However, it doesn't offer specific, actionable steps for the authors to take to address this issue or the limitations. The suggestion about the conclusion is a potential improvement but not a concrete, actionable change."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the difference between expected performance under observation noise and the stochastic noisy function. They also point out that the paper focuses on the latter. This is an explicit statement of a difference and a clear identification of the two concepts. However, the reviewer does not provide concrete, actionable steps for the authors on how to change their objective function or how to evaluate performance under observation noise. The reviewer identifies a potential area for improvement in the paper's presentation, but doesn't directly instruct the authors on what to do.", "grounding_specificity_rationale": "The reviewer points out a potential issue with the paper's framing of the objective function and noise. However, they do not explicitly identify a specific section, table, figure, or unique aspect of the paper where this confusion arises. The reviewer is making a general comment about the paper's focus. While the reviewer implies a lack of clarity, they do not provide specific examples or point to a particular element in the paper that is causing confusion.", "verifiability_rationale": "The reviewer makes a claim about the paper's focus and the potential benefit of considering expected performance under observation noise. This claim is supported by the definitions provided in the review point. The reviewer states a difference and suggests a potential area for improvement in the paper's presentation. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The claim is based on the reviewer's interpretation of the concepts.", "helpfulness_rationale": "The reviewer's point is helpful in that it highlights a potential area for improvement in the paper's presentation and could guide authors to consider alternative evaluation strategies. The reviewer points out a difference and suggests a potential area for the paper to clarify. This could potentially help authors understand their objective function better and potentially consider evaluating performance under observation noise. However, the reviewer does not provide specific, actionable steps for the authors on how to implement this change or how to evaluate performance under observation noise. The reviewer's point is more about the paper's presentation than directly helping the authors improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests two concrete actions: (1) trying to run VGAE with a Vamp prior and (2) suggesting an experiment to keep the generative model fixed while optimizing only the inference part. These actions are direct and point towards specific improvements. While the reviewer doesn't explicitly state 'how to implement' the Vamp prior with VGAE, the suggestion is clear and actionable. The suggestion about Figure 3 also points towards a specific experiment. Therefore, the reviewer provides clear directions for the authors to take.", "grounding_specificity_rationale": "The reviewer's suggestion about Figure 3 is precise, as they mention 'Figure 3' and specific inference models ('SIGVAE' and 'VGAE'). This demonstrates strong grounding as the authors can easily identify the referenced part. However, the suggestion about the Vamp prior is less precise. While it relates to the 'doubly stochastic construction', it doesn't explicitly point to a specific section or table. Therefore, this part of the suggestion is weakly grounded. Overall, the grounding specificity is a mix of weak and full grounding.", "verifiability_rationale": "The reviewer provides clear claims and suggests ways to verify them. For the suggestion about the Vamp prior, the reviewer proposes running the experiment and observing the results, which is a logical way to verify the impact. For the suggestion about Figure 3, the reviewer proposes a specific experiment and asks a question that can be answered through implementation and analysis. Both suggestions are verifiable as they propose concrete actions and ask questions that can be investigated. The reviewer doesn't mention any external references, but the suggestions are based on logical reasoning and the understanding of variational inference.", "helpfulness_rationale": "The reviewer's suggestions are directly relevant to the potential ambiguity in the analysis. The suggestion about the Vamp prior directly addresses the question of whether the benefits are from a better generative model or better inference. The suggestion about Figure 3 directly addresses the difficulty of comparing representations when the generative models are different. Both suggestions provide clear directions for the authors to investigate and improve their work. The reviewer's questions are also helpful in guiding the authors towards specific experiments."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a weakness in the perceived novelty and contribution but does not provide specific, actionable steps on how to improve the method or network design.", "grounding_specificity_rationale": "The comment refers to the 'method' and 'network design' in general, without specifying a particular section, table, figure, or unique element of the paper.", "verifiability_rationale": "The comment contains a claim about the 'somewhat incremental' novelty and offers an opinion based on inspiration from prior work, but lacks concrete evidence or references to support this assessment.", "helpfulness_rationale": "The comment identifies a potential area for improvement by acknowledging prior work, but lacks specific, actionable suggestions on how to modify the method or network design to address this perceived lack of novelty."}
{"actionability_label": "Partially Actionable (3)", "grounding_specificity_label": "3 (3)", "verifiability_label": "3 (3)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer states their suspicion about the graph structure and its relation to locality, which can be considered an implicit action. However, the reviewer does not explicitly state how to apply this suspicion or what specific changes are needed based on this suspicion. The connection between the observed longrange dependencies and the lack of explicit 2D locality in the graph is implied but not explicitly verified or supported.", "grounding_specificity_rationale": "The reviewer mentions 'longrange dependencies' and 'graph structure' but does not explicitly identify the specific part of the paper they are referring to. While they mention 'Table 3' where they observed longrange dependencies, they do not clearly link it to the discussion of locality. The reviewer can infer the relevance of Table 3 but cannot precisely identify the referenced part.", "verifiability_rationale": "The reviewer presents a claim about the lack of 2D locality encoding in the graph structure and its potential impact. This claim is 3 as the reviewer provides a logical reasoning based on the observed longrange dependencies in semantic segmentation. However, the reviewer does not provide specific examples or references within the paper to support their claim about the graph structure. The connection between the observed longrange dependencies and the lack of explicit 2D locality in the graph is implied but not explicitly verified or supported with external references.", "helpfulness_rationale": "The reviewer raises a relevant point about the potential role of locality in the graph structure and its impact on predictions. This could be helpful for the authors to understand potential limitations or areas for further exploration. However, the lack of explicit verification and the implicit nature of the claim make it less directly actionable for the authors to implement changes immediately."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a weakness in the theoretical framework by pointing out the lack of definition for $e_l$ in Eq. (3) and the exponential dependence on the diameter $M$ in several theoretical results. It suggests concrete actions: define $e_l$ and investigate the impact of $M$ on the constant factor. This provides clear directions for the authors to improve their draft.", "grounding_specificity_rationale": "The review point explicitly mentions 'Eq. (3)' and discusses specific results (Corollaries 1, 2 and 3 and Theorem 4), indicating a strong understanding of the relevant section. It even pinpoints the *type* of weakness (exponential dependence). It also specifies *which* part of the theory is lacking information ($e_l$) and *what the consequence* of the exponential dependence is (a required feature size increases exponentially).", "verifiability_rationale": "The review point contains a claim: 'This may exhibit the weakness of the proposed approaches (or at least of the theoretical results)'. It provides evidence for this claim by pointing to the specific theorems and corollaries with the exponential dependence and connects this theoretical weakness to the observed performance in Figure 1, suggesting a link between theory and practice.", "helpfulness_rationale": "The review point is 5 as it directly points out two significant weaknesses in the proposed approaches. It provides clear suggestions for improvement: define the missing term $e_l$ and investigate the impact of the diameter $M$ on the constant factor. These suggestions are concrete and actionable for the authors, directly addressing potential limitations and guiding further analysis."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks questions about the model's behavior with less data and the commonality of gradient vanishing. While the questions are direct, they are general and do not provide specific actionable steps for the authors to take. The reviewer is seeking information, which is a form of implicit actionability, but lacks concrete guidance on how to address it.", "grounding_specificity_rationale": "The review point explicitly mentions 'line 159' and 'your experiments,' which grounds the comment to a specific section and the authors' own work. However, the questions are general and do not specify *how* this relates to the observed gradient vanishing or the experiments. The grounding is present, but the specificity of the referenced issue is lacking.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It is a question about observed phenomena, which falls under the 'X' category (X).", "helpfulness_rationale": "The review point raises relevant questions about a phenomenon the reviewer has observed or expects to occur. This is generally helpful as it prompts the authors to consider the implications of gradient vanishing and the impact of data quantity. However, the questions are openended and do not provide specific guidance or suggestions for improvement, making the helpfulness somewhat limited."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point identifies a weakness in the paper's problem formulation but does not provide any actionable steps or suggestions for improvement. It simply states the issue, which is not an explicit action or suggestion.", "grounding_specificity_rationale": "The review point refers to the 'statement and introduction examples' generally, without identifying a specific section, paragraph, or concept within those parts that is unclear. The phrasing is too broad to be considered specific.", "verifiability_rationale": "The review point is a statement identifying a problem ('somewhat unclear') rather than a claim that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The review point identifies a weakness in the paper's presentation but does not offer any suggestions or guidance on how to improve it. It is a critique, not a constructive suggestion."}
{"actionability_label": "None", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The statement explicitly identifies a limitation of the method, stating 'This method seems to only work for generative models that can be finetuned as an in/outpainting model.' This is a clear and direct action, indicating the reviewer is pointing out a specific constraint. Therefore, the action is explicit.", "grounding_specificity_rationale": "The reviewer's statement does not identify a specific part of the paper or the author's work that is affected by this limitation. They are making a general statement about the method's capabilities. While the statement refers to 'in/outpainting models,' it doesn't pinpoint where this limitation is relevant within the author's specific paper or analysis. Therefore, the grounding is weak as the specific part is not identified.", "verifiability_rationale": "The statement is a claim about the limitations of a method. It is a verifiable statement based on the design and capabilities of generative models. The reviewer is stating a generally accepted understanding about the finetuning requirements of certain types of generative models. Therefore, the claim is fully supported by external knowledge or common sense about the field.", "helpfulness_rationale": "The statement is helpful because it informs the author about a limitation of their method. Understanding the scope and limitations of a tool is crucial for effective use. While it doesn't directly suggest a fix, it provides valuable context and helps the author make informed decisions about their approach. Therefore, the feedback is 4 in understanding the method's boundaries."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Partially Grounded", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests an alternative interpretation of the 'curve finding' method and raises a computational concern. While these are potential areas for clarification, they don't explicitly state a concrete action or provide a detailed explanation of how to implement the alternative or the computational steps. The reviewer implies actions but lacks detail on how to apply them.", "grounding_specificity_rationale": "The reviewer mentions 'curve finding' and 'FGE', providing some grounding by referencing specific terms. However, they also state 'computational demanding' without specifying which aspects or providing examples, making the grounding somewhat vague.", "verifiability_rationale": "The reviewer states a potential misunderstanding between the 'curve finding' method and FGE and raises a computational concern. While they present a logical argument about the potential misunderstanding, they don't provide specific examples or references to external works to support these claims, making the verifiability somewhat lacking in robustness.", "helpfulness_rationale": "The comment identifies a potential misunderstanding between the 'curve finding' method and FGE and raises a computational concern. While this information is valuable for the authors, the comment lacks specific details and concrete examples to fully address the potential issue. The reviewer doesn't provide a clear, stepbystep explanation of the alternative interpretation or the computational implications, making it less helpful than it could be."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the disagreement with the chosen baselines and provides a clear suggestion for improvement by including Concorde. The suggestion is concrete, identifying the specific method (linear scalarization + Concorde) and explaining why it is relevant (SOTA heuristic for singleobjective TSP, nonconvex Pareto front). The reviewer directly points out the missing comparison, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer does not explicitly mention a specific section, table, or figure in the paper. While the reviewer refers to the 'experimental results' and mentions 'Pareto front' and 'linear scalarization', they do not directly link these terms to a specific part of the paper. The grounding is implicit, requiring the reviewer to infer the relevance of these concepts to the experimental setup. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim by suggesting the inclusion of Concorde for a better comparison. The reviewer provides some justification for this claim, stating that Concorde is a SOTA heuristic for singleobjective TSP and that the nonconvex Pareto front makes this comparison relevant. However, the justification is somewhat highlevel and lacks specific references to external works or detailed explanations of how Concorde's performance would differ in this specific context. The claim is supported by logical reasoning and the context of the paper, making it 3.", "helpfulness_rationale": "The reviewer's point is highly relevant to the experimental evaluation. By suggesting the inclusion of Concorde, the reviewer identifies a potential gap in the current comparison of learningbased and heuristic solvers for the singleobjective TSP. This suggestion is concrete and directly addresses the observed performance differences. It provides a clear and actionable improvement to the experimental setup, making the reviewer's point 5 for the authors to understand and improve their work."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point is a statement of opinion, not a directive. It does not explicitly state what the authors should do or how to apply the suggested actions.", "grounding_specificity_rationale": "The reviewer mentions existing methods but does not explicitly state which part of the proposed method is being criticized and how it relates to these methods. The grounding is implied but not clearly defined.", "verifiability_rationale": "The review contains a claim that some general ideas are already present in other methods. However, the support for this claim is the listing of methods, which is not a clear explanation of how the proposed method relates to these existing ones. The reasoning is present but lacks depth and justification.", "helpfulness_rationale": "The review raises a valid point about the potential overlap with existing methods, which could be helpful for the authors to understand the novelty of their approach. However, the lack of specific examples or actionable steps makes the feedback less helpful than it could be."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential issue (appendix hindering interpretation) and offers a solution (moving details back). They also suggest moving background to the appendix. While the suggestions are general, they are still actionable in the sense that they point towards specific locations within the paper. However, the lack of specifics makes it less actionable. The reviewer doesn't specify *which* details are problematic or *how many* should be moved back. They also don't suggest *specific* background information to move.", "grounding_specificity_rationale": "The reviewer refers to \"experimental setup, tasks, and other details\" generally, without specifying a *part* of the paper or a *specific* detail. They refer broadly to \"the appendix\" and \"experimental setup.\" The criticism about the appendix being hard to interpret is general. The suggestion to move 'some\" details is also vague. There's no specific example of what is unclear or missing.", "verifiability_rationale": "The reviewer makes a claim: \"The experimental setup, tasks, and other details are also moved to the appendix which makes it hard to interpret this anyway.\" They also suggest a solution: \"I would suggest moving some of these details back in and moving some background from Section 2 to the appendix instead.\" While the reviewer claims the appendix makes things hard to interpret, they don't provide direct evidence *within* the review point to *prove* that the appendix is indeed causing interpretability issues. They offer a suggestion as evidence, but the suggestion itself isn't verifiable.", "helpfulness_rationale": "The reviewer points out a potential issue (appendix hindering interpretation) and offers a solution (moving details back). They also suggest moving background to the appendix. While the reviewer identifies a potential weakness in the current organization and offers concrete suggestions for improvement, the lack of specifics makes it less helpful. The authors would need to infer *which* details are missing and *why* they are important. The suggestions are general and could apply to multiple sections or details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding glosses to Figure 2, which is an explicit action. However, it does not specify how to add them, making the action somewhat vague.", "grounding_specificity_rationale": "The review point directly refers to 'Figure 2', which is a specific and identifiable part of the paper. This clearly identifies the section being addressed.", "verifiability_rationale": "The review point is a suggestion, not a claim that something is wrong or needs improvement. It lacks any logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point identifies a potential area for improvement (clarity of Figure 2) but doesn't specify how to achieve it. This makes it 3 as it points towards a concrete action, but lacks the necessary detail for immediate implementation."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point states \"Memb is apparently the previous stateoftheart, but there is no mention to any reference.\" This tells the authors what is missing (a reference for \"Memb\") but doesn't explicitly tell them how to fix it (e.g., suggest a specific paper). The lack of a concrete action makes it borderline.", "grounding_specificity_rationale": "The review point is very general. It mentions \"Memb\" and the lack of a reference but doesn't specify *where* in the paper \"Memb\" is used or what specific issue arises from its lack of referencing. The grounding is weak because the section isn't identified, and the issue isn't localized.", "verifiability_rationale": "The review point makes a claim: \"Memb is apparently the previous stateoftheart, but there is no mention to any reference.\" It claims there's a gap in referencing. However, it doesn't *justify* why this is a problem or *suggest* how to address it. The support is present (the statement about no reference), but the reasoning is missing.", "helpfulness_rationale": "The review point points out a valid issue (missing reference for \"Memb\"). However, it lacks concrete guidance on how to fix it. Authors will likely understand *what's missing* but won't know *what to do next*. This makes it 3 but not fully so."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "2 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "4 (4)", "actionability_rationale": "The comment asks a question about a potential improvement (finer grouping) rather than explicitly stating what is wrong with the current approach (pertensor and perchannel). While it implies a potential limitation, the action is not directly stated.", "grounding_specificity_rationale": "The comment doesn't explicitly point to a specific part of the paper it's referring to. It's a general question about quantization granularity. However, it does suggest a potential *improvement* or *alternative*, which could be considered specific to the current method.", "verifiability_rationale": "The comment itself doesn't contain a claim that requires verification. It's a question prompting for justification. While the *implied* claim is that the current granularity might be limiting, there's no explicit evidence or reasoning provided to support this implied claim within the review point itself.", "helpfulness_rationale": "The comment is a direct question for the authors to justify their choice of quantization granularity. It encourages them to consider a potentially beneficial alternative. While it doesn't immediately provide evidence, it serves as a prompt for further investigation and can lead to improvement if the authors engage with it constructively."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point suggests a *direction* for further investigation (studying the impact of unseen classes) but does not provide a specific *action* or *change* to be made in the author's current draft. It is a suggestion for future research, not a direct instruction on how to improve the current work.", "grounding_specificity_rationale": "The review point mentions the concept of 'unseen classes' but does not explicitly identify a specific part of the paper (e.g., a section, table, figure, or unique element) that is being addressed. It refers to a general concept rather than a specific element within the author's draft.", "verifiability_rationale": "The review point is a suggestion for future research, recommending the study of the impact of the ratio of unseen classes. It does not contain a claim that can be verified through logical reasoning, common knowledge, or external references. It is a recommendation, not a statement about the current paper that requires validation.", "helpfulness_rationale": "The review point is relevant to the field and points to a valuable area of investigation. However, it does not directly address any specific weaknesses or issues in the author's current draft. It is a suggestion for future research, not constructive feedback on the submitted paper. Therefore, its helpfulness in improving the current draft is limited."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking *why* specific architectures (GRU and LSTM) were chosen for specific parts of the model (Pyramid and sequential). While this is a request for justification rather than a direct instruction on what to do, it's an implicit action of questioning the *reasoning* behind the implementation. The reviewer is essentially asking the authors to explain their *why*.", "grounding_specificity_rationale": "The reviewer explicitly states *'Why are you using GRU for the Pyramid and LSTM for the sequential part?' and *'Is the combination of two architectures a reason for your improvements?' These questions directly address the specific parts of the model where these architectures were used. The reviewer is accurately identifying the referenced parts, making the grounding strong. The questions are also specific to the *why* of the choices, not just a general criticism of the architectures.", "verifiability_rationale": "The reviewer is posing a question about the *reasoning* behind the architectural choices. This is a valid request for understanding, and it could be considered *partially verifiable* if the authors provide evidence or explanations for their choices. While it's not a direct claim, it's a request that could be supported by logical reasoning or references to external knowledge.", "helpfulness_rationale": "The reviewer is asking questions that are directly relevant to understanding the model's architecture and potentially identifying areas for improvement. By asking *'Why are you using GRU for the Pyramid and LSTM for the sequential part?' and *'Is the combination of two architectures a reason for your improvements?', the reviewer is seeking clarification and justification for the design choices. This information is valuable for the authors and directly addresses their needs for understanding and potentially replicating or adapting the approach. Therefore, it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer needs to infer the definition of 'active vertices' from the context of the sentence 'Initially the network only has a few active vertices, due to sparsity.' The definition is not explicitly stated, requiring the reviewer to understand that 'active vertices' likely refers to nodes with a nonzero or significant value in the network's adjacency matrix or similar representation, and that this sparsity is the reason for their limited number. This requires inference, making it implicit and vague.", "grounding_specificity_rationale": "The reviewer is asked to identify the specific part of the paper where 'active vertices' is mentioned and understand what needs revision. However, the term 'active vertices' is not explicitly mentioned in the sentence 'Initially the network only has a few active vertices, due to sparsity.' The reviewer would need to infer its meaning from the context or external knowledge. While the concept of sparsity is mentioned, it doesn't directly pinpoint the definition of 'active vertices'. Therefore, the grounding is weak as the reviewer cannot confidently determine which part the comment addresses. The specificity of what needs revision related to 'active vertices' is also unclear as the term itself is not defined in the sentence.", "verifiability_rationale": "The original text does not contain a claim. It simply states a fact: 'Initially the network only has a few active vertices, due to sparsity.' There are no opinions, suggestions, or judgments being made. Therefore, the verifiability criteria do not apply as there is X to verify.", "helpfulness_rationale": "The reviewer's request to define 'active vertices' is a direct attempt to improve the clarity and understandability of the text. By defining this term, the reviewer can help the authors communicate more precisely, potentially resolving ambiguity and facilitating further development of the network model. This directly addresses a lack of information that would hinder the authors' ability to convey their ideas clearly. While it doesn't identify a weakness in the authors' writing, it is a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out two key issues: the lack of acknowledgment of the theory's inapplicability to the used model and the underestimation of GNNs' societal impact. While the reviewer doesn't explicitly state what the authors should do, they clearly identify areas where the paper is lacking. The implicit nature of the actionable feedback makes it less actionable than a fully explicit comment. The reviewer suggests specific areas for improvement, but the authors still need to determine the exact scope and focus.", "grounding_specificity_rationale": "The reviewer makes general comments about the limitations section and the societal impact of GNNs. They do not specify a particular section, table, figure, or unique element of the paper that they are referring to. The reviewer's comments are broad and apply to the entire paper. While the general areas are identified, the specific part being addressed is not clearly pinpointed.", "verifiability_rationale": "The reviewer makes several claims: (1) the theory's inapplicability isn't acknowledged, (2) the 'structural assumptions' are vague, (3) the authors underestimate GNNs, and (4) more elaboration on societal impact is needed. The reviewer provides logical reasoning to support these claims. However, they do not provide specific examples or references to back up their assertions. While the claims are verifiable in principle, the lack of concrete evidence makes the verifiability somewhat lacking.", "helpfulness_rationale": "The reviewer identifies two distinct and relevant areas for improvement in the paper: the limitations section and the discussion of the societal impact of GNNs. By pointing out these gaps, the reviewer provides valuable guidance for the authors. While the suggestions are not fully detailed, the reviewer clearly indicates what needs to be addressed, making the feedback helpful in a general sense. The reviewer's comments provide a clear direction for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a question about the implementation of epsilongreedy exploration, which is a direct request for clarification on how this technique is being used. This constitutes an explicit action that the authors should take to clarify their method.", "grounding_specificity_rationale": "The reviewer is asking about a specific implementation detail (epsilongreedy exploration) in the context of their proposed strategy. While the original paper likely mentions using epsilongreedy, the *relationship* between this exploration technique and their specific strategy is not explicitly stated. The reviewer needs to *imagine* the connection to understand the implementation, indicating a lack of explicit grounding. The comment does not specify what needs to be addressed in this part (the implementation details), making it underspecific.", "verifiability_rationale": "The reviewer is asking a question, not making a claim. There is no assertion of what should be the case or any attempt to provide justification for their request. Therefore, verifiability is not applicable.", "helpfulness_rationale": "The reviewer's request for clarification on the implementation of epsilongreedy exploration is a valid need for the authors. Understanding how this technique is integrated with their proposed strategy is crucial for reproducibility and further development. While it doesn't directly identify a flaw, it's a helpful suggestion that could lead to improvements in the clarity and completeness of the paper."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer states their understanding of the method as a combination of GCN and normalizing flow, which is an explicit statement. However, they do not provide specific guidance on how to improve the method based on this observation. The action is identified, but the implementation details are missing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'GCN' and 'normalizing flow' as components of the method, indicating a clear identification of the specific part being addressed. They also specify the modification to the Gaussian distribution. This demonstrates strong grounding. However, while the components are named, the reviewer doesn't detail *how* these components interact or what specific issues arise from this combination, making the specificity somewhat underdefined.", "verifiability_rationale": "The reviewer makes a claim about the lack of 'new stuffs' in the method. However, they do not provide any evidence or reasoning to support this claim. There are no logical arguments, common knowledge, or external references provided to justify their assertion. The claim is presented without sufficient backing.", "helpfulness_rationale": "The reviewer's comment is a critique of the method's novelty. While they identify a potential weakness in the method's composition, they do not offer any concrete suggestions or improvements. The comment is a statement of opinion about the contribution of the work, rather than a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the difference between the projection head and the classification head, which is an implicit action. However, it does not provide concrete steps or suggestions on how to apply this knowledge to improve the draft, making it 2.", "grounding_specificity_rationale": "The review point explicitly mentions 'projection head (CNN layers)' and 'classification head (FCN layer)', providing clear grounding. It also specifies the difference between these two parts, making it 5.", "verifiability_rationale": "The review point makes a claim about the model's architecture. While it's a factual statement, it doesn't provide a suggestion for improvement, making it 1 in the context of offering actionable feedback.", "helpfulness_rationale": "The review point provides information about the model's architecture, which could be useful for the authors. However, it doesn't directly suggest improvements, making it 3 as it offers insights that could lead to further discussion or actions."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their opinion about the discussion section needing more clarity. This is a clear indication of an actionable point. While the action itself (improving clarity) is clear, the specific *part* of the discussion lacking clarity is not identified, making it somewhat vague on how to apply the action.", "grounding_specificity_rationale": "The reviewer mentions the 'discussion' section as the area needing improvement. This constitutes explicit grounding as the section name is directly referenced. However, the reviewer does not specify *which* part of the discussion is unclear, only that it is necessary. Therefore, while grounded, it is not specific about the exact element within the discussion that requires attention.", "verifiability_rationale": "The reviewer states their opinion about the discussion section needing more clarity and provides a rationale for this opinion. This constitutes a claim that requires justification. The reviewer argues that the discussion is vital and lacks clarity, implying a logical reasoning process. Therefore, the claim is verifiable based on the provided reasoning.", "helpfulness_rationale": "The reviewer identifies a lack of clarity in the discussion section as a problem and suggests that this lack of clarity hinders the differentiation of the work from related ones. This is a clear statement of a problem and a suggestion for improvement, making it a helpful comment. While the suggestion is general, it indicates a clear need for action."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the weakness of the analogy between the paper's approach and HOI analysis and Harmonic analysis. They point out that the paper's context has only two 'basis' (human and object) for forming an HOI, which weakens the connection. However, the reviewer does not provide concrete, actionable steps for the authors to take to improve their draft based on this critique. The comment identifies a problem but doesn't offer a specific solution.", "grounding_specificity_rationale": "The reviewer refers to 'HOI analysis,' 'Harmonic analysis,' and 'Fourier analysis,' which grounds the comment in specific concepts. They also specify the areas where they believe the connection is weak ('decomposition/integration steps'). However, the reviewer does not explicitly identify a specific part of the paper (e.g., a particular section or table) where the analogy is problematic. The grounding is at a more conceptual level.", "verifiability_rationale": "The reviewer makes a claim that the analogy between the paper's approach and HOI analysis is weak and that the decomposition/integration steps do not have a close connection with Fourier analysis. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a critique without evidence.", "helpfulness_rationale": "The reviewer expresses a critical view of the analogy between the paper's approach and HOI analysis and Harmonic analysis. They point out the limitations of the paper's context and the disconnect between the decomposition/integration steps and Fourier analysis. While the reviewer identifies a weakness, they do not offer any suggestions or insights on how the authors can improve their draft based on these observations. The comment is primarily critical without providing constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'this might restrict the implications of the proposed methodology,' which is an action. They also specifically mention 'bitparallel fixedpoint numbers,' providing strong grounding.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'bitparallel fixedpoint numbers' as the specific area of concern. This can be achieved through:  Literal mentions of sections, tables, figures, etc.  Mentions of unique elements of the paper. This can be achieved through:  General comments that clearly imply the relevant parts without explicitly naming them.  Mentions of specific technical details like 'bitparallel fixedpoint numbers' which is a unique element.", "verifiability_rationale": "The reviewer makes a claim ('this might restrict the implications...') but doesn't provide any supporting evidence or logical reasoning to back it up. They are stating a potential limitation without further elaboration or justification.", "helpfulness_rationale": "The reviewer raises a valid point about the limitations of the findings' applicability, which is relevant information for the authors to consider the scope of their work. While they don't offer a direct solution, they identify a potential issue that can guide the authors in further investigation or refinement of their methodology."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue with Figure 8: 'fig 8 shows images with different focusing distance, but it only shows 1m and 5m, which both exist in the training data.' They also ask a direct question: 'How about focusing distance other than those appeared in training? does it generalize well?'. This clearly indicates an actionable point for the authors to examine the limitations of the figure and consider the generalization of their model to unseen focusing distances. The reviewer provides a clear action: 'Examine Figure 8 and consider its limitations regarding generalization to unseen focusing distances'.", "grounding_specificity_rationale": "The reviewer mentions 'fig 8' as the part of the paper being addressed. While they identify the *topic* of the issue (generalization to unseen focusing distances), they do not explicitly identify the *specific* section, table, or unique aspect of Figure 8 within the paper. They imply it's in the appendix ('fig 8'), but don't provide a direct reference. Therefore, the grounding is not fully explicit.", "verifiability_rationale": "The reviewer makes a claim about Figure 8: 'fig 8 shows images with different focusing distance, but it only shows 1m and 5m, which both exist in the training data.' They also pose a question about generalization, which implies a claim that the model *should* generalize. However, the reviewer does not provide any evidence, references, or logical reasoning to *support* this claim. There is no explicit justification for why the model should generalize to unseen focusing distances based on the information provided. The claim is presented without sufficient backing.", "helpfulness_rationale": "The reviewer raises a relevant point about the limitations of Figure 8 and the importance of the model's generalization ability to unseen focusing distances. They are directing the authors to examine a specific aspect of the paper (the figures) and to consider a crucial evaluation aspect (generalization). The reviewer's comment highlights a potential area for further investigation or clarification regarding the model's performance beyond the training data. While the reviewer doesn't offer a solution, they provide a clear direction for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential conceptual issue regarding the authors' definition of 'content' and 'style' in the context of their nonsequential model. While the reviewer doesn't explicitly state what action the authors should take, they are implicitly suggesting that their current understanding of 'style' might be too narrow and not aligned with the model's 'movement dynamic'. This could be seen as an implicit action to reconsider the authors' conceptual framework. However, the reviewer doesn't provide specific steps on how the authors should go about this reconsideration, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer raises a point about the authors' distinction between 'content' and 'style' but doesn't pinpoint a specific section or concept within the paper where this distinction is unclear. They are referring to these concepts in a general sense, particularly concerning the model's 'nonsequential' nature and 'style' as 'movement dynamic'. While the reviewer identifies a potential area for clarification, they don't explicitly state which part of the paper or concept they are referring to, making the grounding weak.", "verifiability_rationale": "The reviewer's point about the authors' conceptualization of 'style' and 'content' is a suggestion for improvement rather than a claim requiring verification. While they are making a judgment about the authors' current understanding, they are not providing evidence or references to support this judgment. Therefore, it doesn't fit the criteria for a verifiable claim as it lacks justification or reasoning.", "helpfulness_rationale": "The reviewer's comment prompts the authors to consider a broader conceptual framework, which could be helpful for selfimprovement. However, the comment is vague and doesn't provide specific suggestions or actions for the authors. It's more of a suggestion for reflection than a concrete improvement. Therefore, while potentially 3 in prompting selfreflection, it lacks the specificity and actionable steps needed for full helpfulness."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues with the paper's claims about direct quantization and the proposed method's limitations. They also identify areas for improvement, such as providing a deeper explanation and comparing with other methods. This indicates a clear and actionable critique.", "grounding_specificity_rationale": "The reviewer refers to 'vit quantification' and specifically mentions 'Line 45' and compares figures (Fig1(b) vs. Fig5(b)). They also discuss 'MHSA' and cite examples from 'NLP' (QBERT, Q8BERT, etc.). This demonstrates a strong grounding of the specific parts of the paper and the relevant concepts being discussed.", "verifiability_rationale": "The reviewer provides numerical data from the figures to support their claims about the variance difference. They also reference existing literature on quantization loss in NLP, providing external evidence for their point. This shows that the claims are wellsupported by logical reasoning and references.", "helpfulness_rationale": "The reviewer's comments highlight significant weaknesses in the paper's claims and suggest areas for improvement. While they don't propose a specific fix, the feedback is constructive and points to concrete areas where the paper needs refinement. This makes the feedback 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the similarity of the proposed method to STNs and the lack of comparison. It also mentions the local application and cites specific examples of STNs being used locally (neighborhood STNs, PointNet). This provides a clear action for the authors to take: compare their method to these existing approaches. The specificity is further enhanced by mentioning the 'Xtransformation'.", "grounding_specificity_rationale": "The comment mentions 'spatial transformer networks (STN)' and implicitly refers to existing works using STNs locally (neighborhood STNs, PointNet). While it doesn't explicitly name 'STN' initially, the context and later mention make it grounded. The specificity is high as the comment clearly identifies the similarity and the missing comparisons.", "verifiability_rationale": "The comment makes a claim about the limited technical novelty due to the similarity to STNs and the absence of comparisons. It provides some justification by mentioning existing works. However, it lacks explicit references to external works or detailed explanations of why the similarity is a significant limitation. The evidence is present but could be stronger.", "helpfulness_rationale": "The comment clearly identifies a weakness in the paper's novelty and points out the absence of crucial comparisons to relevant prior work. This directly helps the authors understand the limitations of their approach and where they could improve their work. The reviewer provides specific examples of related work, making the feedback actionable."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks two questions: 'Where does the reward come from at each trial?' and 'Is one of the r_i taken from Eq. 11?'. These are direct and specific questions that require the authors to identify the source of the reward and its relation to another equation. The suggestion to explain the network model with equations is also a clear action the authors can take. The reviewer is prompting the authors to take concrete actions to understand a specific part of the paper and improve its clarity.", "grounding_specificity_rationale": "The review point explicitly mentions 'Eq. 12' and asks about the 'reward' and 'r_i'. This directly identifies the location of the issue within the paper. The suggestion to explain the network model in 'Sec. 4.2' further pinpoints the exact section. The reviewer is not making an inference but directly pointing to a specific part of the paper and asking clarifying questions about it. The actions are also very specific, asking about the origin of the reward and its relation to another equation.", "verifiability_rationale": "The reviewer is not making a claim but is asking for clarification regarding the reward mechanism in Eq. 12. This can be considered a request for justification or further explanation. While the reviewer doesn't explicitly state a claim, the underlying need for clarity is a valid point that can be addressed with further information or examples. The reviewer is prompting the authors to seek evidence or reasoning to understand the reward mechanism better.", "helpfulness_rationale": "The review point directly identifies a potential area of confusion for the authors (the reward mechanism in Eq. 12) and provides a concrete suggestion for improvement: explaining the network model with equations. This actionable feedback is likely to be helpful for the authors to better understand and improve their work. The reviewer is prompting the authors to take specific actions to clarify a specific aspect of their paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out a factual error ('Fig.7' should be 'Fig.12') and provides a concrete suggestion ('each theorem and corollary appearing in the main paper should be attached to its corresponding proof link'). The action is directly stated and the method of correction is clearly defined.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'each theorem and corollary appearing in the main paper,' which clearly identifies the specific elements of the paper being addressed. While the exact instances are not named, the category is specific. The comment specifies what needs to be addressed in this part (linked proofs).", "verifiability_rationale": "The reviewer makes a claim that 'the paper's theoretical results (theorems and corollaries) lack linked proofs' and provides a justification that linked proofs would improve readability. This justification, while not a direct citation, is a logical reasoning supporting the claim.", "helpfulness_rationale": "The reviewer's comment is clear, actionable, and directly points out a factual error. The suggestion to link proofs is also constructive and would likely improve the paper's clarity and accessibility for readers. The combination of identifying a specific error and offering a concrete improvement makes this comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies issues in Section 3 regarding the selection and tagging of action verbs and in Section 3.306ff regarding the selection of action frames. While it points out the missing determiner and the lack of clarity in the selection process, it doesn't explicitly state an action or recommendation for the authors to take. The reviewer asks 'Which 50 classes do you pick' and 'Are the verbs that you pick all explicitly tagged as action verbs by Levin?' and 'What are \"action frames\"? How do you pick them?', which implies a lack of understanding or a potential area for improvement, but it doesn't directly instruct the authors on how to address these issues.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 3' and 'Section 3.306ff', indicating a clear identification of the specific part of the paper being addressed. It also asks 'Which 50 classes do you pick' and 'What are \"action frames\"? How do you pick them?', which directly specifies the elements the authors need to consider and how they might select them. This strong grounding allows the authors to understand the specific area of concern and the criteria for selection.", "verifiability_rationale": "The review point raises questions about the selection process of action verbs and action frames but doesn't provide any external references or logical reasoning to support its claims. It asks 'Are the verbs that you pick all explicitly tagged as action verbs by Levin?' without offering a definitive answer or a standard for selection. While it points out a potential area for improvement, it doesn't provide sufficient evidence or justification to be considered 5. The questions posed indicate a lack of clarity or a potential gap in the authors' understanding, but without offering a rule or reference, it's not 5.", "helpfulness_rationale": "The review point identifies specific areas in Section 3 where the authors seem to be lacking clarity and understanding, particularly regarding the selection and tagging of action verbs and the concept of action frames. While it doesn't offer direct solutions or recommendations, it points out a gap in the authors' knowledge or implementation. This raises a helpful flag for the authors, indicating a potential area where they need more guidance or clarification. However, it doesn't actively guide them on how to improve their draft based on this review."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue ('Ln 32 on Page 1, \u2018Empiically\u2019 should be \u2018Empirically\u2019') and provides the exact location and the correct spelling. This is a clear and concrete action for the author to take. The action is not inferred and is directly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions the line number ('Ln 32 on Page 1') and the section of the text ('the word \u201cEmpiically\u201d'). This provides a precise and unambiguous reference point within the paper, fully grounding the issue. The reviewer does not need to make any educated guesses to identify the relevant part of the document.", "verifiability_rationale": "This review point does not contain a claim. It is a factual correction suggesting a spelling error. There is no need for verification as it is a direct observation and a suggestion for improvement.", "helpfulness_rationale": "The reviewer provides a clear and direct suggestion to check the spelling of 'Empirical' on line 32. This is a very actionable and helpful comment for the author, as it points to a specific, minor issue that can be easily corrected."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a clear and explicit critique of the proposed invariant learning module. They directly point out that the framework in Section 4.2 focuses on mask selection and rawlevel features, and they explicitly state that the former framework (Line 167174, Sec. 4) seems not limited to rawlevel selection. This is an explicit statement of a discrepancy and a critique of the current approach. The reviewer also suggests considering representation learning as a potential improvement, which is a concrete, actionable suggestion. The criticism is welldefined and points to a specific area for improvement.", "grounding_specificity_rationale": "The reviewer demonstrates strong grounding specificity by explicitly mentioning 'Section 4.2' and 'Line 167174' within the paper. They also specify the type of features being criticized as 'rawlevel features'. This level of detail shows that the reviewer has carefully located the specific aspect of the method being discussed and has identified a specific technical detail as the point of critique. The suggestion to consider 'representation learning' further enhances the grounding specificity by linking the criticism to a broader concept within the field.", "verifiability_rationale": "The reviewer presents a claim that the feature selection in Section 4.2 could be further improved by considering representation learning. This claim is supported by the existing literature on representation learning and its potential benefits for feature selection. While the reviewer does not provide a specific citation within the review point, the suggestion is grounded in established knowledge and provides a direction for potential improvement. The reviewer's statement is logical and points towards a plausible enhancement to the proposed method.", "helpfulness_rationale": "The reviewer's review point is 5 for the authors. They clearly identify a potential limitation in the proposed invariant learning module (the focus on rawlevel features) and offer a specific suggestion for improvement (considering representation learning). This is a valuable critique because it guides the authors towards a potentially more effective approach. While the suggestion is not a detailed solution, it provides a concrete direction for further investigation and development. The reviewer's feedback is actionable and points towards a relevant area of research."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a problem ('some details are missing') and provides an example ('how to design the rewards is not fully understandable'). While the example points to a specific area of confusion, the initial statement is very broad. The comment identifies a problem but doesn't explicitly state how to address it or provide specific steps. It identifies a gap in information but doesn't tell the authors *how* to fill that gap.", "grounding_specificity_rationale": "The comment states 'some details are missing' generally and provides an *example* of 'how to design the rewards is not fully understandable'. While the example helps ground the comment by specifying a particular area of missing detail, the initial statement itself does not explicitly refer to a specific section, table, figure, or unique aspect of the paper. The grounding is implicit through the example.", "verifiability_rationale": "The comment states a problem ('some details are missing') and provides an example ('how to design the rewards is not fully understandable'). This can be considered a *claim* or *opinion* about the paper's state. However, the comment does not provide any logical reasoning, external references, or specific examples to *justify* the missing details. It points out a gap but doesn't explain *why* it's a problem or how it should be addressed.", "helpfulness_rationale": "The review point identifies a genuine issue: the lack of clarity regarding certain details, specifically the design of rewards. However, it stops short of providing any actionable steps or guidance on how the authors should go about understanding or addressing these missing details. It points out a problem but doesn't offer concrete improvement strategies."}
{"actionability_label": "1", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a problem (generalization to different numbers of entities) but does not explicitly state a solution or a direct action to be taken. The statement is framed as a question about Figure 3 of INs, indicating a lack of immediate actionability.", "grounding_specificity_rationale": "The reviewer mentions 'Figure 3 of INs,' which provides a specific reference point. However, they do not explicitly identify a specific section, table, figure, or unique aspect within their own paper that is causing the difficulty. The reference is general, making the grounding somewhat weak.", "verifiability_rationale": "The statement itself is a statement of difficulty and does not present a claim that requires verification or justification. There is no logical reasoning, common knowledge, or external references provided to support the claim (which is not explicitly stated).", "helpfulness_rationale": "The reviewer is seeking clarification on a technical issue. While this can be helpful for understanding, it does not directly critique or suggest improvements to the work itself. The feedback is about understanding a limitation rather than a direct improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the incremental nature and lack of novelty of the work compared to KNN MT, suggesting a hypothetical consequence (code release). While the reviewer doesn't explicitly state 'I suggest focusing more on the nuances...', the implication is clear. The suggestion, though hypothetical, indicates a potential action. Therefore, it's considered **3** as the reviewer identifies a weakness and suggests a potential consequence.", "grounding_specificity_rationale": "The reviewer mentions 'KNN based MT approach' when criticizing the work's incremental nature and lack of novelty. This indicates that the reviewer can identify the specific method being discussed. However, the criticism itself is quite general and doesn't pinpoint a specific part or feature of the KNN MT approach that needs improvement. The grounding is present, but it's not very specific. Therefore, it's considered **3 (3)**.", "verifiability_rationale": "The reviewer states that the work is an 'incremental improvement' with 'little novelty'. This constitutes a claim. However, the reviewer doesn't provide any specific evidence or references to support this claim. The suggestion about code release is a hypothetical consequence rather than a direct verification of the claim. Therefore, it's considered **1 (1)**.", "helpfulness_rationale": "The reviewer clearly states their opinion that the work is an 'incremental improvement' with 'little novelty' and suggests a potential remedy (code release after revision). This provides some direction for the authors. However, the criticism is quite general and lacks specific actionable steps. The suggestion about code release is a consequence, not a direct improvement suggestion. Therefore, it's considered **3 (3)**."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'the runtime of Prithvi WxC should be discussed'. This is a direct and actionable suggestion for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions 'Prithvi WxC' and the concept of 'runtime' in the context of MLbased emulators and climate model parametrizations. This demonstrates a clear understanding of the relevant terminology and the specific model being discussed. The grounding is fully explicit and specific to the model and the aspect being addressed.", "verifiability_rationale": "The review point presents a claim: 'the selling point for MLbased emulators of climate model parametrizations is often their computational cheapness. Thus, the runtime of Prithvi WxC should be discussed'. This claim is supported by the common justification for using ML emulators (computational efficiency) and logically connects it to the need to discuss runtime. While it doesn't provide specific evidence or citations, the reasoning is clear and verifiable.", "helpfulness_rationale": "The review point is directly relevant to the authors and provides a clear direction for improving their draft. It highlights a practical aspect (runtime) that is often considered a strength of MLbased emulators and encourages the authors to address a potential limitation. While it doesn't provide a concrete number, it is a helpful prompt for discussion."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "6", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a problem (lack of novelty) but lacks specific instructions on how to address it. It's a diagnosis, not a prescription with concrete implementation details.", "grounding_specificity_rationale": "The comment is about the *idea* and the *metrics/methods* in general, not a specific section, table, figure, or element. It's a general critique of the idea and its components.", "verifiability_rationale": "The comment states a subjective judgment about the novelty of the idea and doesn't present a specific claim that can be verified with evidence. It's a diagnosis, not a prescription with verifiable evidence.", "helpfulness_rationale": "The comment identifies a potential problem (lack of novelty) but doesn't offer concrete steps for the authors to address it. It's a critique, not a prescription with actionable implementation details."}
{"actionability_label": "Not actionable", "grounding_specificity_label": "1", "verifiability_label": "Not verifiable", "helpfulness_label": "None", "actionability_rationale": "The reviewer identifies a potential issue ('oversell the method') and its consequence ('contribution less clear'), but does not specify a concrete action or how to address it. It's a potential problem, not a clear instruction.", "grounding_specificity_rationale": "The comment refers to the 'framing of the paper' and the 'method' generally, without pinpointing a specific section, table, figure, or a unique aspect of the method being oversold. The consequence, 'contribution less clear,' is a general statement about the paper's impact.", "verifiability_rationale": "The review point is a statement of opinion or judgment ('The framing of the paper seems to oversell the method...') about the paper's presentation and the perceived clarity of its contribution. There's X that can be verified with evidence from the paper itself.", "helpfulness_rationale": "The review point identifies a potential issue with the paper's framing and the clarity of its contribution. While it highlights a problem, it doesn't offer a specific solution or actionable steps for the authors to address it. The suggestion is vague: 'This framing needs to be revised.'"}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states two concrete actions: 'presenting such process in separate steps' and 'too many symbols and a notation table could be better'. These actions are direct and tell the authors exactly what to do to improve their draft.", "grounding_specificity_rationale": "The reviewer refers to 'the model description' in general, which is a specific part of the paper. However, the reviewer does not pinpoint a specific section, table, figure, or unique element within the model description where the issue lies. The suggestions are broad and general to the entire description.", "verifiability_rationale": "The review point makes a claim: 'e.g., the generative process is in detail but presenting such process in separate steps should be better for understanding, too many symbols and a notation table could be better.' While it could be better supported by referencing specific papers or providing a more detailed explanation of *why* separate steps are better, it's not explicitly making a claim that requires external verification to be understood. The suggestions are generally wellestablished practices and easily verifiable.", "helpfulness_rationale": "The review point provides clear and actionable feedback on the model description. It tells the authors specifically what aspects need improvement ('presenting such process in separate steps' and 'too many symbols and a notation table') and offers concrete suggestions for how to do so. This makes the review point 5 for guiding the authors' revisions."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a *problem* regarding the clarity of paraphrases but doesn't propose specific actions the authors should take to address it. While they suggest the model relies *on* the quality, they don't offer concrete steps to improve it. This aligns with the definition of explicit vs. implicit actions, where the action is implied rather than stated directly.", "grounding_specificity_rationale": "The reviewer explicitly states 'When generating paraphrases for the training data, it is unclear how different the paraphrases are from the original sentences.' This directly identifies the specific part of the paper/paraphrase being discussed, making it fully grounded. The phrase 'how different' is a clear indicator of the specific issue being addressed.", "verifiability_rationale": "The reviewer raises a concern about the *quality* of paraphrases, which directly relates to the model's reliance on them. They are questioning the *justification* for using potentially lowquality paraphrases. While they observe a lack of clarity, they don't provide external references or logical reasoning to support their claim about the poor quality. This fits the definition of a claim that is undersupported.", "helpfulness_rationale": "The reviewer identifies a significant issue (unclear paraphrases) that could negatively impact the training data quality. They are pointing out a *problem* that, if not addressed, could hinder the authors' progress. While they don't offer solutions, they highlight a crucial concern that could be helpful in directing the authors' attention to a potential flaw."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"improving the paper\" and provides specific examples like \"identifying rationales is not a simple problem for more complicated NLP tasks like machine translation.\" This indicates an explicit action. However, the reviewer does not provide concrete steps on how to achieve this improvement. The suggestion is broad and lacks specific details on the modifications needed. Therefore, while the action is explicit, the lack of concrete details makes it 3.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"Figure 2 is a bit cluttered and the \"bold\" text is hard to see,\" which directly identifies a specific part of the paper (Figure 2) and a specific issue with it (the bold text). This indicates strong grounding as the reviewer can confidently identify the referenced part and the issue within it. However, the reviewer does not specify *why* this is a problem or what needs to be done to fix it. The specificity is limited to the observation of the visual issue, not the underlying problem.", "verifiability_rationale": "The reviewer makes a claim by stating \"Figure 2 is a bit cluttered and the \"bold\" text is hard to see.\" This claim is supported by logical reasoning (the observation is based on direct experience or visual assessment) and common knowledge ( readability is a standard concern). While the level of detail could be improved, the claim is verifiable based on the reviewer's observation. Therefore, the claim is 4.", "helpfulness_rationale": "The reviewer provides suggestions for improvement, such as \"improving the paper\" and specifically suggesting 'suggestions for improving the clarity of Figure 2.\" This directly addresses potential weaknesses or areas for improvement in the paper. The suggestions are relevant and actionable. Therefore, the review point is 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states an action: 'further verify effectiveness and universality'. This action is clear and concrete, indicating a direct understanding of what needs to be done. The reviewer proposes testing the framework on 'nonLLMbased models like HiTeA and InternVideo', which provides specific directions for the verification process.", "grounding_specificity_rationale": "The reviewer identifies a specific aspect of the framework (its applicability to LLMs) and suggests specific models (HiTeA and InternVideo) to test. This demonstrates a strong grounding in the paper's content and a clear understanding of the proposed action. The mention of 'nonLLMbased models' and 'specific models' indicates precise identification of the relevant part of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim: 'the framework's effectiveness and universality'. They then suggest a method for verification: 'empirical testing on the suggested models'. This claim is logical and verifiable through concrete experimentation. The reviewer provides a clear reasoning for how the verification can be done, linking the claim to a specific experimental approach.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential limitation of the paper's evaluation by focusing on the *generality* of the FlippedQA framework. They provide a clear suggestion for improvement: 'further verify effectiveness and universality'. This is a valuable and actionable suggestion that directly contributes to enhancing the understanding and applicability of the framework. The comment is not vague or general but rather specific and focused on a concrete area of improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states that 'the writing could be improved' and provides context about the difficulty in understanding the 'main idea' and 'theoretical analysis'. While it identifies a problem, it doesn't explicitly state what needs to be improved or how to achieve it. The reviewer implies the need for improvement but doesn't provide concrete steps or actions. Therefore, it is not fully actionable. It is also not implicit because the action of 'improving the writing' is not directly stated as a specific action to be taken. The reviewer indicates the need for improvement but doesn't specify the exact areas or methods.", "grounding_specificity_rationale": "The reviewer mentions 'the writing,' 'the main idea,' and 'the theoretical analysis' as areas needing improvement. While they express difficulty in understanding these aspects, they do not explicitly identify a specific section, table, figure, or unique element of the paper as the source of their confusion. The grounding is implied rather than explicitly stated. Therefore, the grounding is weak because the authors cannot confidently determine which part the comment addresses. The specificity is also lacking because the comment does not detail what needs to be improved in this general area.", "verifiability_rationale": "The reviewer states that 'the writing could be improved' and that 'it took me quite a lot of effort to go back and forth to understand the main idea and the theoretical analysis of the paper.' This statement can be considered a claim that the writing needs improvement. However, the reviewer does not provide any specific examples, references, or logical reasoning to support this claim. The statement is presented as a general observation rather than a specific assertion backed by evidence. Therefore, the claim is not supported by any verifiable information.", "helpfulness_rationale": "The reviewer points out that they 'took me quite a lot of effort to go back and forth to understand the main idea and the theoretical analysis of the paper.' This indicates a clear problem the author is facing with the writing. While the reviewer doesn't offer specific solutions, they identify a significant issue that needs addressing. The comment highlights a gap in clarity and understanding, which could motivate the author to seek further assistance or improvements. Therefore, the comment provides some information about a problem, making it 3 in identifying an area that needs attention."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the method primarily builds upon a combination of existing methods and lacks theoretical novelty. While this is an explicit statement of an action (to combine and address novelty), the reviewer does not provide specific details on how this combination should be achieved or what the novel aspect would be. The action is implied rather than explicitly stated with concrete steps.", "grounding_specificity_rationale": "The reviewer mentions 'ClopperPearson intervals' and 'Gaussian elimination' in the context of the proposed method. This explicitly identifies the specific part of the paper being addressed, demonstrating strong grounding. The reviewer names the methods, which are specific techniques used in the field.", "verifiability_rationale": "The reviewer states that the proposed method 'primarily builds upon a combination of existing methods' and 'doesn't present significant theoretical novelty'. This is a claim made without providing any evidence or justification within the review point itself. There is no logical reasoning, common knowledge, or external references provided to support or refute this claim.", "helpfulness_rationale": "The reviewer expresses a desire to improve their score if the authors address the concerns about the combination of existing methods and the lack of theoretical novelty. While this indicates a desire for helpful feedback, the review point itself does not provide specific, actionable suggestions on how to address these concerns. The helpfulness is conditional on the authors' response to the identified issues."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a question about the validity of text input concatenation from object elements. While the action of concatenation is explicit, the reviewer is not directly stating what needs to be done. The authors would need to infer the potential issue and its implications.", "grounding_specificity_rationale": "The reviewer mentions 'text input' and 'four text elements of an object', which provides some grounding. However, they don't explicitly state which part of their work this relates to, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer is posing a question about a technical detail. This is a claim that can be verified by checking the documentation or source code of the relevant tool or framework. The verifiability is high as the claim is about a specific implementation detail.", "helpfulness_rationale": "The reviewer is asking a question that, if answered, would help the authors understand a specific implementation detail. While helpful, it might not be a critical issue that requires immediate attention, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point is a suggestion to improve the paper by first motivating the 'Why'. While it implicitly suggests adding a motivation section, it lacks specific details on what aspects need motivation and how to achieve it. The action is implied but not explicitly stated, and the method of implementation is vague.", "grounding_specificity_rationale": "The reviewer mentions 'motivation' as an area for improvement but does not specify which part of the paper or section requires it. The comment is general and does not point to a specific element (e.g., a section, a figure, or a unique aspect) that needs improvement. The grounding is implied but not explicitly stated.", "verifiability_rationale": "The reviewer states a claim that 'the paper could do better to first motivate' but does not provide any specific examples, references, or logical reasoning to support this claim. The suggestion is general and lacks justification. There is X extraction in this review point as it is a suggestion rather than a statement of opinion or judgment.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper \u2013 the lack of clear motivation \u2013 but the suggestion to 'first motivate' is very general and lacks specific guidance on how to motivate the reader. While it points to a potential area for improvement, it doesn't offer concrete steps or examples to address this issue. The helpfulness is limited because the suggestion is broad and lacks actionable steps."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the suggestion to clarify the abstract and provides a concrete action: 'clarify the abstract'. This directly addresses the identified issue and provides a clear path for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'lines 1217' in the abstract, which is a precise and obvious identification of the specific part of the paper being addressed. The comment also clearly identifies the issue as being with the 'sentence' within those lines.", "verifiability_rationale": "The comment does not contain a claim. It is a suggestion for improvement rather than a statement that requires verification.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion to 'clarify the abstract'. While it might not be a major flaw, it is a specific and helpful piece of feedback for the authors to improve their writing."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out a discrepancy in the experimental setup (Pix3D training and testing) and compares it to zeroshot methods. This doesn't directly instruct the authors on what to do. It highlights a problem but doesn't provide a solution or a clear action to take.", "grounding_specificity_rationale": "The review mentions \"Pix3D training and testing\" and \"zeroshot singleimage 3D reconstruction models.\" While it names the datasets involved, it doesn't pinpoint a specific section, table, figure, or unique aspect within the Pix3D dataset or the comparison to zeroshot models that necessitates this specific comparison. The grounding is implied but not explicitly stated.", "verifiability_rationale": "The review states \"Such comparisons to those zeroshot singleimage 3D reconstruction models are even more unfair.\" This is a claim that needs justification. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. They don't explain why it's unfair or suggest how the comparison should be different.", "helpfulness_rationale": "The review identifies a valid concern about the experimental setup. However, it doesn't offer any concrete suggestions or guidance on how the authors should address this issue. It highlights the problem but doesn't provide a solution or actionable steps. The lack of specific advice makes it not helpful for improving the draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states that the proposed approach does not outperform or is even worse than Decouple Kang et al.. This is a clear indication of an explicit action, as the reviewer directly points out a deficiency in the proposed method. However, the reviewer does not specify *how* the proposed approach underperforms or *what* needs to be improved. Therefore, while the action is explicit, the lack of detail makes it only partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'Decouple Kang et al.' and 'head/tail categories' without explicitly identifying the specific section, table, or unique aspect of the paper being addressed. While the paper and the general concept of head/tail categories are mentioned, the connection to the specific paper being reviewed and the exact nature of the issue within those categories is not clearly established. Therefore, the grounding is weak. The reviewer also states that there is a tradeoff between head and tail categories, but this tradeoff is not specified for the proposed method or the baselines, making it underspecific.", "verifiability_rationale": "The reviewer makes claims about the proposed approach's performance relative to Decouple Kang et al. and the existence of a tradeoff in head and tail categories. However, the reviewer does not provide any evidence or justification for these claims. They simply state the results without explaining *why* or providing supporting arguments. This makes the claims 1. The reviewer also states that the paper is 'not ready for this ICLR,' which is a subjective judgment without any supporting evidence.", "helpfulness_rationale": "The reviewer states that the proposed approach does not outperform or is even worse than Decouple Kang et al.. This is a factual statement about the performance. However, the reviewer does not provide any suggestions for improvement or explain *why* this is a significant issue. The reviewer also criticizes the lack of similar analysis for the baselines but does not offer any concrete steps to address this. The review is a statement of fact without further insight or actionable suggestions. Therefore, the review is not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point suggests *what* to do (additional experiments) but doesn't specify *how* to do it or what specific results are needed. The phrase \"more support\" is vague.", "grounding_specificity_rationale": "The comment explicitly mentions \"realistic noisy datasets like WebVision\" and \"C2D\", clearly identifying the specific aspect of the paper being addressed and providing a concrete example. The suggestion to use these datasets is directly related to improving the support for C2D.", "verifiability_rationale": "The comment contains a claim (\"would have provided more support\") but does not provide any logical reasoning, examples, or external references to support this claim within the review point itself.", "helpfulness_rationale": "The review point identifies a potential weakness (lack of support for C2D) and suggests a relevant improvement (additional experiments on noisy datasets). While the action is implied rather than explicitly stated and concretely defined, the grounding is strong, making it likely the authors would find the suggestion relevant. However, the lack of concrete actionability makes the potential impact somewhat limited."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the evaluation 'relying on 4 OCR QA datasets' and suggests 'more scenarios like the LLaVA benchmark.' These are concrete actions the authors could take to improve their evaluation. The reviewer also points out a potential issue with the current evaluation method, which is actionable.", "grounding_specificity_rationale": "The reviewer refers to '4 OCR QA datasets' and 'LLaVA benchmark' by name, which is a strong form of grounding. They also point out a specific area of potential improvement: 'evaluation is limited.' The reviewer is very specific about the type of datasets and the nature of the suggested improvement (ablation studies with LLaVA).", "verifiability_rationale": "The reviewer makes a clear claim: 'This evaluation may be unreliable.' This is a statement of concern based on the limited data. While the reviewer doesn't provide direct evidence of unreliability, they point out a potential issue that the authors acknowledge. The suggestion to use LLaVA is an attempt to verify the need for more diverse evaluation scenarios.", "helpfulness_rationale": "The reviewer's assessment of the evaluation being 'limited' and 'reliable' is a negative statement. While the reviewer's suggestion to use LLaVA is a concrete action that could help improve the evaluation, the initial negative framing makes the overall impact less strong. The authors could use this to improve their evaluation, but the initial statement is a bit harsh."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two explicit and concrete suggestions. First, they suggest a potential improvement to the notation by indicating the dropping of the noop action in the policy function. This is a clear, actionable suggestion that authors can directly implement. Second, they explicitly point out a potential inconsistency in the dimensions of the matrices in equation (2) and suggest a simpler way to handle the noop action. This is also a clear and actionable suggestion that authors can directly address. Both points are welldefined and provide clear directions for improvement.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'equation (2)' and the notation around the policy function pi. They also specify the column of the matrix X_t that they believe should be dropped. This demonstrates a strong grounding as the reviewer can accurately pinpoint the relevant part of the paper and clearly identify the issue within that specific section. The use of specific terms like 'pi', 'equation (2)', 'X_t', and 'column' further strengthens the grounding.", "verifiability_rationale": "The reviewer's claim is verifiable. They identify a potential issue in the formulation of equation (2) regarding the dimensions of the matrices. They suggest a specific solution (dropping the first column of X_t) and explain the reasoning behind it. This claim is supported by logical reasoning and a clear suggestion for resolution. The reviewer is not making a subjective judgment but rather pointing out a potential flaw in the current formulation and offering a concrete alternative.", "helpfulness_rationale": "The reviewer's comment is 5. They identify a specific area for improvement in the notation and point out a potential inconsistency in a key equation. Their suggestions are clear, actionable, and directly address potential issues authors might encounter. The reviewer is not just pointing out a problem but also offering a potential solution, which is valuable for guiding authors to improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The reviewer explicitly states their concern about the importance of the result and the connection to prior work on perturbed gradient descent. They also explicitly state their concern about the change in dimension dependence. These are clear actions or suggestions that the authors should apply.", "grounding_specificity_rationale": "The reviewer refers to \"Theorem 3\" and \"15\", which grounds the comment to specific parts of the paper and external work. They also specify the *nature* of the concern \u2013 the lack of surprisingness given prior work and the change in dimension dependence. This specificity is quite high.", "verifiability_rationale": "The reviewer states their concern but does not provide any evidence or justification for why the cited work on perturbed gradient descent directly supports or contradicts their claim about the decentralized algorithm's ability to escape saddle points. They are raising a question without providing a logical reasoning or external reference to support it.", "helpfulness_rationale": "While the reviewer raises a valid concern, they do not offer any specific suggestions or evidence to address it. They simply state the problem without proposing solutions or providing context. Therefore, the review point is not particularly helpful in improving the authors' understanding or the paper itself."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors should include keypoint detection results in the experiments section. This is an explicit action, as the authors are directed to a specific location in the paper and what to do with the results (include them). While it doesn't specify *how* to present the results, it is a clear instruction.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or the nature of the keypoint detection results. It simply states that these results should be included in the 'experiments section'. This implies a general location rather than a precise reference to a table, figure, or a specific subsection. Therefore, the grounding is weak.", "verifiability_rationale": "The review point itself is not a claim that needs verification. It's a suggestion for the authors to include certain results. Therefore, it doesn't fall under the 'Verifiability' aspect, which focuses on the evaluation of claims and their support.", "helpfulness_rationale": "The review point suggests including keypoint detection results in the experiments section. While this is a helpful suggestion as it provides relevant information, it doesn't offer specific guidance on *what* is missing or *why* the current results are insufficient. It's a general suggestion rather than a detailed improvement plan. Therefore, it is 3 but lacks the depth of a 5 comment."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests a comparison with a specific existing model (Revisiting Visual Question Answering Baselines) and identifies a key factor (ternary potential) that is important for performance. While it doesn't explicitly state 'Look at the section on 'Ternary Potentials' and compare...', the specificity of the suggestion makes it actionable. The authors can directly implement this comparison to see if it improves their model's performance.", "grounding_specificity_rationale": "The review point explicitly mentions a specific existing model by name (Revisiting Visual Question Answering Baselines) and even provides a citation. This clearly grounds the suggestion in a concrete piece of existing work. The authors can directly compare their model with this specific paper.", "verifiability_rationale": "The review point makes a claim that comparing with a model that uses answers as inputs (like the proposed model) is relevant because ternary potential is a key factor in performance improvement. This claim is logically sound and verifiable. The authors can easily find the suggested paper and understand the concept of using answers as inputs. The reasoning is clear and directly supports the suggestion.", "helpfulness_rationale": "The review point identifies a key performance factor (ternary potential) and provides a clear suggestion for improvement by comparing with a relevant existing model. This directly addresses a potential area for improvement and provides a concrete next step for the authors. While it doesn't explicitly tell the authors *how* to implement the comparison or what specific insights to expect, it clearly points to a valuable direction for experimentation."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly asks a question related to the validation set, which is a specific aspect of the experimental procedure. While it doesn't directly tell the authors what to do, it points to a crucial detail that they need to clarify. Therefore, it is considered 3 as it identifies a specific area of concern.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific section, table, figure, or unique aspect of the paper. It is a general question about the validation set used in the grid search. Therefore, it is considered 1.", "verifiability_rationale": "The comment is a question posed to the authors and does not contain a claim that needs verification. Therefore, it does not fit the verifiability criteria and is classified as having X (X).", "helpfulness_rationale": "The question directly addresses a common practice in machine learning, specifically whether the grid search of learning rate is performed on the validation set. This is a relevant and helpful clarification for the authors, as it pertains to the proper separation of data for model training and evaluation. Therefore, it is considered 4 as it raises a valid point that would likely improve the authors' understanding and experimental rigor."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a specific observation about the number of discourse relations in the authors' treebank and asks a direct question about the interpretation of 'discourse' and 'dobj' relations. While the observation is present, the reviewer doesn't explicitly state how to *act* on this information or what the implications are for the authors' work.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Table A2' in the authors' paper, clearly identifying the section being discussed. They also ask a specific question about the nature of 'discourse' and 'dobj' relations, indicating a high level of specificity in their request.", "verifiability_rationale": "The reviewer presents an observation ('there seem to be a lot of discourse relations...') and asks a question. While the observation itself can be considered verifiable by examining the treebank, the reviewer doesn't provide external references or logical reasoning to *justify* why this observation is significant or how it should be interpreted. The question itself is verifiable, but the claim isn't fully supported.", "helpfulness_rationale": "The reviewer raises a valid point about the discrepancy in discourse relation terminology and the high number of `dobj` relations. This could potentially be helpful for the authors to clarify their definitions and ensure consistency. However, the reviewer doesn't offer concrete suggestions or propose a specific action for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question about a specific aspect of the data (racial/economic diversity) and its implications for generalizability. This directly points to a potential area for improvement in the authors' analysis and reporting. The action is explicit, as the reviewer directly asks a question, and concrete, as they specify the aspect (diversity) and the implication (generalizability).", "grounding_specificity_rationale": "The reviewer explicitly mentions the line number (L393) where the question originates. This provides a clear and precise reference point for the authors to locate the relevant information. The specificity is high because the reviewer not only identifies the location but also asks a specific question about the content of that section (diversity and generalizability).", "verifiability_rationale": "The reviewer raises a point that requires verification (generalizability) but doesn't provide immediate evidence or justification *within the review itself*. While the question is valid, the lack of supporting evidence or references within the review makes it 3. The reviewer is prompting the authors to consider something, implying a need for justification, but doesn't provide it directly.", "helpfulness_rationale": "The reviewer is asking a specific question about a potential limitation of the study (lack of diversity and its impact on generalizability). This is a valuable point that encourages the authors to critically assess their sample and consider its implications. The feedback is directly relevant to the authors' work and prompts them to think about improving the robustness and generalizability of their findings. While it's a question, it clearly identifies a potential weakness and a direction for improvement, making it 4."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a direction for improvement (higher output quality) but doesn't specify how to achieve it. The phrase \"there\u2019s still much room for improvement\" is a general statement, not a concrete action the authors should take. The suggestion is implicit. The level of \"room for improvement\" is vague. How much higher should the quality be? What specific techniques should be used? The review points out a valid concern but doesn't offer actionable feedback.", "grounding_specificity_rationale": "The review point refers to \"Recent GAN works\" and \"amazing quality in synthesized results\" in a general way. It doesn't pinpoint a specific section, table, figure, or unique aspect of the paper being criticized. The reviewer is making a general statement about the field, not directly referencing a specific part of their work. While the *cause* of the quality difference (lack of resolution, hardware requirements) could be inferred, the *review point itself lacks specificity*.", "verifiability_rationale": "The review point makes a claim about the output quality being \"reasonable, but still far from realistic.\" It then offers a justification based on the limitations of the paper's novelty, low resolution, and high hardware requirements. The reviewer attempts to support this claim by referencing the progress in GANs and the limitations of the paper's specific aspects. However, the connection between the GAN advancements and the *specific* shortcomings of *this paper's* output isn't explicitly and clearly established. The reviewer *suggests* a link but doesn't provide concrete examples or evidence *within the paper* to support this specific claim. The supporting evidence is weak.", "helpfulness_rationale": "The review point identifies a valid concern about the output quality. It highlights a gap between the expected quality based on recent advancements and the actual quality of the paper's results. The reviewer also provides a rationale based on the paper's limitations. While the suggestion is broad, it points to a clear area for improvement. The reviewer doesn't offer *no* actionable feedback, but the lack of specific guidance might limit its immediate helpfulness."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer expresses a concern about the hyperparameters used but does not explicitly state what the authors should do to address this concern. They suggest a potential reason (subpar hyperparameters) but do not provide a concrete action for the authors to take. The reviewer's statement is more of a question than a clear instruction on how to improve the draft.", "grounding_specificity_rationale": "The reviewer mentions 'soft labels', 'CRM', and 'Crossentropy' but does not specify which part of the paper or what exact aspect of the implementation they are referring to. They do not point to a specific section, table, or figure. The reference to 'subpar hyperparameters' is also general and lacks specificity.", "verifiability_rationale": "The reviewer expresses a concern but does not provide any specific evidence or reasoning to support it. They offer a potential explanation ('similarly to') but do not elaborate on the basis for this concern. The statement is more of a question than a verifiable claim.", "helpfulness_rationale": "The reviewer raises a concern about the results and suggests a potential reason (subpar hyperparameters) but does not offer any concrete suggestions or insights to address this concern. The review is primarily a question and a caution, not a helpful suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point mentions a desire for more evaluation on unseen characters and suggests adding translations to Figure 6. While it implies an action (improving evaluation), the specific action of 'adding evaluation' is not explicitly stated. The suggestion to add translations is also implicit within the context of improving evaluation for unseen characters. Therefore, the action is implicit and needs to be inferred.", "grounding_specificity_rationale": "The review point refers to 'the simple/traditional experiment for unseen characters' and suggests 'eval in this direction' and 'classifying unseen words'. It also specifically mentions 'translations to Figure 6'. This clearly identifies the part of the paper and the specific improvement being suggested. The reviewer can confidently identify the area and the specific aspect of improvement.", "verifiability_rationale": "The review point states a desire to 'improve the evaluation of unseen characters' and suggests 'adding translations to Figure 6'. This constitutes a claim that needs to be supported. While the suggestion itself provides a basis for verification (translating for evaluation), the reviewer does not explicitly state *why* translations would be beneficial or provide any specific examples or references to external works to support this claim. The reasoning is present but lacks depth and specific justification.", "helpfulness_rationale": "The review point directly addresses a potential weakness in the paper (limited evaluation of unseen characters) and offers a concrete suggestion (adding translations to Figure 6). This is a clear attempt to provide actionable feedback that could improve the paper. The reviewer is directly addressing a specific area for improvement and offering a concrete suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the concern about the dataset size and its impact on testing, which is a direct and clear action. They identify the potential issue (small dataset) and the area it affects (texting validity).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'VioT dataset' and the specific number of images (20 per category). This clearly grounds the comment to a specific part of the paper. They also specify the concern about 'texting the validity of the approach', making it specific.", "verifiability_rationale": "The reviewer makes a claim about the dataset size being small and its impact on testing. However, they do not provide any evidence or justification for this claim. There is no logical reasoning, common knowledge, or external references provided to support their assertion about the verifiability of the dataset size affecting testing.", "helpfulness_rationale": "The reviewer's comment primarily identifies a potential weakness (small dataset) and its implication for testing. While they raise a valid concern, the comment itself does not offer specific, actionable steps or solutions for the authors to address this issue. It is more of a critique pointing out a potential limitation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer suggests an ablation study of the number of layers versus performance. This is an *implied* action, as the reviewer is suggesting a type of experiment to conduct. However, the *how* and *why* are not specified. The action is not explicitly stated, making it implicit. The suggestion is also vague, as it doesn't specify which layers to ablate or how performance should be measured. Therefore, while the reviewer points out a potential area for improvement, the action is not concrete enough to be actionable.", "grounding_specificity_rationale": "The reviewer suggests an ablation study of the number of layers versus performance. The reviewer does not specify *which* part of the paper this suggestion is related to. They are making a general suggestion about the model architecture. Therefore, the reviewer cannot be considered to have identified a specific part of the paper being addressed. The grounding is weak because the reviewer's comment is not tied to a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer suggests an ablation study of the number of layers versus performance. This is a suggestion, not a claim or opinion. The reviewer is proposing a future experiment, not critiquing the current work or making a judgment about it. Therefore, there is X being made, and the verifiability aspect is not applicable.", "helpfulness_rationale": "The reviewer suggests an ablation study of the number of layers versus performance. While this is a valid suggestion for future research, it does not directly address any specific issues or weaknesses in the current draft. The reviewer is not pointing out any errors, ambiguities, or areas that need improvement in the current work. The suggestion is about future experimentation, not about improving the existing draft. Therefore, the review point is not helpful for guiding changes to the current work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for 'intuitive explanations' and points out issues with figure captions, indicating a desire for actionable improvements. However, the request lacks specific details on *how* to achieve these explanations or address the figure issues. The action (providing explanations) is clear, but the implementation details are missing, making it 3 but not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions 'mathematical derivations' and 'figure elements' without specifying *which* derivation or *which* part of the figures needs improvement. The grounding is weak because the authors cannot confidently determine the exact area the comment addresses. While the specificity is about the *content* of the explanation, the lack of a clear reference point makes it not fully specific.", "verifiability_rationale": "The reviewer states that the paper is 'hard to follow' and suggests improvements like 'more intuitive explanations' and 'explanations for figure elements.' This constitutes a claim that needs verification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The claims are suggestions for improvement but lack the necessary evidence to be considered verifiable.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as 'more intuitive explanations' and 'explanations for figure elements.' These suggestions are concrete and point towards actionable changes that could benefit the authors. Even though the claims themselves are not verifiable, the suggestions themselves offer a degree of helpfulness by guiding the authors on what needs to be addressed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment asks a question and expresses a concern but does not provide explicit instructions on how to address the issue of hyperparameter sensitivity.", "grounding_specificity_rationale": "The comment refers to 'hyperparameter choices' and 'empirical results' generally, without pinpointing a specific section, table, figure, or unique detail.", "verifiability_rationale": "The comment is a statement of concern and a request for further investigation, not a claim that requires verification.", "helpfulness_rationale": "The comment raises a valid concern and is relevant to the authors' work. However, it lacks explicit instructions or guidance on how to address the issue, making it less than 5."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the work 'utilizes existing attack methods on a surrogate model' and 'is similar to use the transferability of adversarial examples directly'. This directly points out a potential lack of novelty and suggests the authors should focus on claiming their contribution. The action is explicit, and the direction is clear.", "grounding_specificity_rationale": "The reviewer's comment is a general statement about the method's similarity to existing techniques. They do not specify which part of the paper or method they are referring to. The grounding is weak as the comment is not tied to a specific section, table, or figure.", "verifiability_rationale": "The reviewer makes a claim about the method's similarity to existing techniques. However, they do not provide any evidence or justification for this claim. The claim is stated without supporting references or logical reasoning, making it 1.", "helpfulness_rationale": "The reviewer's comment is directly relevant to the authors and points out a potential weakness in their methodology. They suggest the authors focus on claiming their novelty. This is a clear and actionable piece of feedback that could help the authors improve their work. The reviewer identifies a specific area for improvement and provides a direction for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states two actions: 'text in table 1 is too small' and 'Algorithm 1: gradient symbol is missing in line 4'. These are direct and concrete actions that the authors can easily implement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'table 1' and 'Algorithm 1' in their review point. This is a clear and accurate identification of the specific parts of the paper being addressed, resulting in full grounding. Furthermore, the reviewer specifies the *problems* within these sections, making the specificity high.", "verifiability_rationale": "The reviewer identifies issues in the paper, stating 'text in table 1 is too small' and 'Algorithm 1: gradient symbol is missing in line 4'. However, the reviewer does not provide any justification or reasoning for why these issues are important or how they should be addressed. There are no external references or logical explanations provided to support the claims.", "helpfulness_rationale": "The reviewer points out two concrete issues: the readability of table text and the missing gradient symbol in an algorithm. While the reviewer identifies areas for improvement, they do not explain *why* these are important or *how* fixing them would benefit the authors' work. The feedback is focused on pointing out problems without further explanation or context."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential issue with the practical applicability of the proposed methods in highdimensional settings. They highlight a specific technical detail: 'solving several LPs in high dimensions, each involving a parameter that is not easily calculable.' While the reviewer doesn't explicitly state what needs to be done, they identify a concrete problem that the authors should investigate. The action is implicit (identifying a potential issue), but the reviewer provides enough detail for the authors to understand the concern and potentially address it.", "grounding_specificity_rationale": "The reviewer mentions 'high dimensions' as a context for their concern. However, they do not explicitly identify which specific section, table, or unique aspect of the paper they are referring to. While the concept of 'high dimensions' is specific, the lack of a direct reference point makes the grounding somewhat weak. The specificity refers to the type of problem ( difficulty of calculating a parameter in high dimensions), which is clearly stated.", "verifiability_rationale": "The reviewer provides a specific technical detail: 'solving several LPs in high dimensions, each involving a parameter that is not easily calculable.' This statement can be considered verifiable as it points to a concrete problem. However, the reviewer does not provide any examples, references, or logical reasoning to support this claim within the provided review point. Therefore, while the claim is 3, it lacks sufficient evidence within the immediate context of the review.", "helpfulness_rationale": "The reviewer's point directly addresses a potential practical limitation of the proposed methods. They highlight a specific technical detail ('solving several LPs in high dimensions, each involving a parameter that is not easily calculable') that could hinder the practical application of the work. This is a relevant and actionable concern for the authors, making the review point 5 in identifying a gap between theory and practice."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer's comment implicitly suggests an action: 'Check if the ResNet in section 7.1 shares parameters between residual blocks.' They also suggest a 'deeper ResNet with parameter sharing' as a baseline and connect it to 'ODE nets with a fixed timestep Euler integrator'. While the reviewer doesn't explicitly state 'Do something!', the suggestion of a baseline experiment and the connection to a more advanced concept indicate a desire for clarification and further exploration.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 7.1' and asks a question about the ResNet in that section. They also mention 'parameter sharing' and 'deeper ResNet', which are specific aspects of the paper. While they don't explicitly state 'the unique section, table, figure, or unique aspect being addressed', the context strongly points to the ResNet described in section 7.1. The mention of 'ODE nets' and 'Euler integrator' further implies a connection to a specific concept within the paper or a broader field.", "verifiability_rationale": "The reviewer is *proffering* a suggestion and a connection to a concept. They are not stating a fact that needs verification. They are offering a potential improvement or insight. The comment lacks a claim that requires logical reasoning, common knowledge, or external references to be supported. It's a suggestion for a new experiment and a connection to a concept, not a statement that needs to be proven.", "helpfulness_rationale": "The reviewer's comment raises a valid point about a potential implementation detail (parameter sharing) and suggests a relevant baseline experiment. They also connect their suggestion to a concept from a different field (ODE nets). This comment provides a clear direction for the authors to consider and explore further. While it doesn't directly tell them what to do, it highlights a potential area of improvement and provides a connection to a relevant concept, making it helpful in guiding further investigation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a claim about the crossencoder architecture, suggesting it's not 'ignoring crossentity comparison' and that it 'attends to all candidates at once'. While the reviewer implies a lack of specificity in the crossencoder's behavior, they don't explicitly state what action or improvement they suggest. The reviewer's statement is somewhat vague about how the crossencoder attends to all candidates and why it might be ignoring crossentity comparison. The suggestion to 'improve the motivation' is general and doesn't provide a concrete action.", "grounding_specificity_rationale": "The reviewer makes a claim about the crossencoder architecture in the context of the paper's motivation. While the reviewer doesn't explicitly name the crossencoder or any specific part of it, they clearly refer to its behavior ('ignoring crossentity comparison', 'attends to all candidates at once'). This indicates some level of grounding. However, the reviewer doesn't specify *how* the crossencoder is performing these actions or what specific aspect of the crossencoder is responsible. The grounding is present but not fully explicit.", "verifiability_rationale": "The reviewer makes a claim about the crossencoder architecture and its impact on the motivation. This claim is based on the reviewer's understanding of how crossencoders typically operate and the potential limitations of attending to all candidates. While the reviewer doesn't provide external references, their reasoning is based on general knowledge of neural networks and attention mechanisms. The claim is supported by logical reasoning and common knowledge about crossencoder behavior.", "helpfulness_rationale": "The reviewer provides a specific criticism of the crossencoder architecture and its relation to the paper's motivation. They suggest that the crossencoder is not 'ignoring crossentity comparison' and that its 'attending to all candidates at once' might be a limitation. While the criticism is somewhat general, it clearly identifies a weakness in the proposed approach and suggests a direction for improvement. The reviewer's comment directly points to a specific area that needs clarification or adjustment in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly identifies the design choice of trimming questions after the first 10. However, the suggestion for improvement is vague and doesn't provide concrete steps on how to make it better. The reviewer states the implication of the design choice on a bagofwords model but doesn't offer specific alternatives or actionable improvements.", "grounding_specificity_rationale": "The reviewer refers to 'questions' and 'first 10' in the context of L254, which implies they are referring to a specific part of the paper. This can be considered weak grounding as they can infer the section but don't explicitly name it. The specificity of their critique is limited as they don't provide specific examples of what could be improved or suggest concrete alternatives.", "verifiability_rationale": "The reviewer states a potential issue: 'trimming the questions after the first 10 seems like an odd design choice, especially since the question model is just a bag of words (so it is not expensive to encode longer sequences)'. This is a claim about the design choice's effectiveness. However, the reviewer doesn't provide evidence or reasoning to support their claim about the 'oddness' or inefficiency.", "helpfulness_rationale": "The reviewer raises a point about a specific implementation detail and its potential impact on a bagofwords model. While relevant, it might not be a major bottleneck or offer significant actionable insights for most users. The impact is implied but not clearly articulated or actionable."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out that while the paper claims the method produces the explanation for Figure 1, it doesn't explicitly detail *how* this is achieved. The mention of 'additional adhoc postanalysis' suggests a gap in the method's integration or explanation, making the process less concrete. While the method is claimed to produce the explanation, the *specific mechanism* isn't fully clear, falling between explicit and implicit, and between concrete and vague.", "grounding_specificity_rationale": "The reviewer is asking for more specific information about *how* the proposed method identifies the NO2 group in Figure 1. They cannot confidently determine which part of the paper is being addressed until they ask the question. The paper mentions the method's ability to produce the explanation but doesn't pinpoint the exact mechanism or the specific element being analyzed in Figure 1, making the grounding less certain.", "verifiability_rationale": "The reviewer makes a claim about the method's ability to produce the explanation for Figure 1. However, the paper lacks a clear justification or explanation of *why* the method can do this. The need for 'additional adhoc postanalysis' suggests a gap in the provided reasoning or commonsense arguments. The claim is presented without sufficient supporting evidence or justification within the provided text.", "helpfulness_rationale": "The reviewer provides a specific example of a gap in the paper by pointing out the lack of clarity in how the method produces the explanation for Figure 1. While the paper claims the method can do this, it doesn't fully explain the process. This specific example is helpful for the authors to understand the method's capabilities and limitations, and it suggests a way to improve the clarity of the explanation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of the experiment and provides concrete suggestions for improvement. They mention the reliance on Prop 3.2 and the importance of a large enough perturbation value, which are specific details that can be acted upon. The reviewer also points out that the difference between the tested method and the pseudo feature importance is only the number of perturbations, which is a clear and actionable observation.", "grounding_specificity_rationale": "The reviewer refers to 'this experiment' and 'Prop 3.2', which indicates a degree of grounding. They also specify the issue with the perturbation value, suggesting a further level of specificity in identifying the problem. While the initial reference to the experiment is somewhat vague, the subsequent mention of Prop 3.2 and the perturbation value provides a clearer reference point.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the experiment due to its reliance on Prop 3.2 and the choice of perturbation value. They provide a logical explanation of why this is a concern, stating that it makes it difficult to judge the correctness of the pseudo feature importance. While the reviewer doesn't explicitly provide external references to support this claim, the logical reasoning makes it 3.", "helpfulness_rationale": "The reviewer provides a clear critique of the experiment and offers two specific and actionable suggestions for improvement. The suggestions are directly related to the identified weaknesses and are likely to be understood and implemented by the authors. The reviewer's comments are focused and directly address the stated issue, making them 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The comment suggests a potential consideration regarding the properties of the loss function Z and its impact on SGD convergence. While it implies an action (further analysis or consideration), it does not explicitly state what needs to be done or how to implement it. The action is implicit.", "grounding_specificity_rationale": "The comment explicitly refers to 'the loss function Z' and 'SGD convergence', which are specific elements of the paper. The authors can easily identify the section or concept being addressed.", "verifiability_rationale": "The comment makes a claim about the potential relationship between the properties of the loss function Z and the convergence of SGD. However, it does not provide specific examples, references, or detailed explanations to support this claim. The verifiability relies on the reader's ability to infer and potentially verify the claim through further research or analysis.", "helpfulness_rationale": "The comment raises a relevant point about a potential nuance in the analysis of SGD convergence with nonconvex loss functions. It could be helpful for the authors to consider the 'good properties' mentioned, but it does not provide a concrete solution or specific guidance on how to address the issue."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the location of the errors in the SuppMat (lines 502 and 507) and the nature of the errors (two lines should be green, specific section/table/algorithm references are incorrect). The reviewer also suggests a concrete action: changing the color of two lines to green. While the action is direct, the reviewer does not specify *how* to identify the two lines that should be green, making it only partially concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'SuppMat' section of the paper (L502, L507, L509). They also specify the exact lines and the *nature* of the errors (missing color, incorrect section/table/algorithm number). This strong grounding makes it clear which part of the paper the reviewer is referring to and what specific issues exist within that part.", "verifiability_rationale": "The reviewer contains claims about the errors in the SuppMat (L502, L507, L509). They provide specific examples of where these errors are located (lines 502 and 507 in SuppMat, specific sections, tables, and algorithms). The reviewer also suggests a correction (change the color to green). The reasoning is implicit but the evidence is explicit and points to a clear issue.", "helpfulness_rationale": "The reviewer provides specific feedback about errors in the SuppMat and suggests a concrete action (changing the color of two lines to green). They also point out inconsistencies in referencing within the SuppMat. This feedback is directly actionable and helps the authors improve their manuscript by correcting a formatting issue and clarifying references."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a desired outcome ('a much more comprehensive and dataintensive analysis') but does not specify a concrete action the authors should take to achieve this. The authors are not told what specific changes are needed or how to implement the suggestion.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper being addressed. It refers to the paper as a whole ('this paper significantly') and does not specify what is missing or needs improvement. The authors are not told to focus on a particular section, table, figure, or unique aspect.", "verifiability_rationale": "The review point makes a claim ('a much more comprehensive and dataintensive analysis would improve this paper significantly') but does not provide sufficient evidence or justification to support this claim. The reasoning is vague, and there are no specific references to external works or logical arguments to back up the assertion that more data will necessarily improve the paper.", "helpfulness_rationale": "The review point offers a suggestion for improvement ('a much more comprehensive and dataintensive analysis') but lacks specific details and concrete steps. While it is a valid direction for future work, it does not directly address specific weaknesses or issues in the current draft, making it less helpful for immediate improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states 'The experimental settings are not mentioned properly.' This clearly indicates an action the authors should take: to provide a detailed description of the experimental settings. However, the comment does not specify *how* the settings are not mentioned (e.g., missing from the methods section, unclear in the results section). Therefore, while the action is implied, it is not fully concrete.", "grounding_specificity_rationale": "The comment identifies the *area* where the information is lacking ('experimental settings') but does not specify the *exact* section, table, or figure where this information should be found. While it implies a lack of clarity, it doesn't point to a specific location. However, it does specify *what* is missing ('not mentioned properly').", "verifiability_rationale": "The comment contains a claim: 'The experimental settings are not mentioned properly.' This claim suggests a deficiency. However, the reviewer does not provide specific evidence or references to support this claim. For example, they don't specify *which* parts of the paper are missing the settings, nor do they provide examples of what constitutes 'not mentioned properly' (e.g., no section number, no table number, unclear language). Therefore, while the claim is present, it lacks sufficient justification.", "helpfulness_rationale": "The comment correctly identifies a crucial issue: the lack of proper mention of experimental settings, which is vital for reproducibility. However, the comment does not offer any specific suggestions or guidance on how the authors should improve their description of the experimental settings. The suggestion to 'add the code' is vague and doesn't explain *why* the code is missing or how it would help."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out several implicit actions that need to be inferred. For example, the reviewer implies that the authors should investigate the practical considerations of online learning and RL, and they should explore the challenges of including them in the evaluation. While the authors are likely aware of these implicit actions, the reviewer's point is that these should be explicitly stated in the paper to avoid confusion. The reviewer also implies that the authors should consider the retraining cost comparison, which is not explicitly mentioned in the paper. The reviewer's point is that these should be explicitly addressed to improve the clarity and completeness of the paper.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'online learning formulation', 'RL', and 'retraining cost' as areas where the paper lacks clarity. They directly reference specific sections or aspects of the paper that are not welldefined. The reviewer's comment is directly addressing the paper's content, pinpointing the missing information. The reviewer is not just stating an opinion but is directly referencing the paper's lack of explanation in these specific areas.", "verifiability_rationale": "The reviewer makes a claim about the paper's lack of explanation regarding the exclusion of online learning and RL. They state that the paper 'overlooks key practical considerations' and 'lacks comparison' against these methods. This is a claim that requires verification. The reviewer does not provide specific examples or references to external works to support their claim. The reviewer's point is that the paper needs to justify its exclusion of these methods and explain the challenges of including them. The reviewer is making a statement that needs to be supported by evidence or reasoning within the paper.", "helpfulness_rationale": "The reviewer raises several valid points about the lack of justification for excluding online learning and RL from the evaluation. They highlight the missing discussion of practical considerations, the absence of a retraining cost comparison, and the unaddressed challenges of including these methods. These are all areas where the authors could improve their paper by providing more context and a clearer rationale for their choices. The reviewer's point is that the paper needs to explain *why* these methods are being excluded and what the implications are. This is a valuable point for the authors to consider when revising their paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests a connection to metalearning and provides concrete examples of relevant research areas (RL for architecture search and optimizers). This directly points to actionable steps the authors can take to enhance their work by exploring these connections.", "grounding_specificity_rationale": "The review point mentions 'metalearning' generally and suggests exploring 'RL for architecture search' and 'optimizers' without specifying a particular section, table, or figure in the authors' paper. While it implies the relevance of these areas to the paper's topic (continual learning), it doesn't pinpoint a specific part of the authors' work that needs addressing. Therefore, it can be considered weakly grounded as it implies relevance but doesn't explicitly point to a specific issue.", "verifiability_rationale": "The review point presents a suggestion about exploring related work and applying it to the paper. It doesn't make a claim about the correctness or quality of the paper itself, nor does it provide evidence to support such a claim. Therefore, it doesn't meet the criteria for verifiability.", "helpfulness_rationale": "The review point offers a constructive suggestion about connecting the paper's work to metalearning and citing relevant papers. This is a valuable piece of feedback that could help the authors position their work better and potentially identify future research directions. It provides a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The comment expresses an intention regarding feedback diversity but does not specify any concrete actions or modifications the authors should make to their draft based on this. The reviewer states 'assuming the teacher feedback was autogenerated, do you intend to turk the teacher feedback and / or generate a few different kinds of feedback (which is more reallife situation)?' This is a question about the process of generating feedback, not a direct instruction on how to improve the paper. Therefore, the comment lacks explicit or direct instructions for the authors, making it 1.", "grounding_specificity_rationale": "The comment is about the *process* of generating feedback (turking or generating diverse feedback) rather than a specific element within the paper itself. It does not identify a particular section, table, figure, or unique aspect of the paper that is affected by this feedback diversity concern. The reviewer is asking about the feedback process, not about a specific weakness in the paper. Therefore, the comment does not ground the authors in a specific part of the paper, making it 1.", "verifiability_rationale": "The comment expresses an opinion about the diversity of feedback but does not provide any evidence, logical reasoning, or external references to support this claim. The reviewer states 'assuming the teacher feedback was autogenerated, do you intend to turk the teacher feedback and / or generate a few different kinds of feedback (which is more reallife situation)?' This is a statement of intent and opinion, not a claim that can be verified. There is no logical reasoning or external evidence presented to support the idea that autogenerated feedback is inherently less diverse. Therefore, the comment does not make a claim that can be verified, making it 1.", "helpfulness_rationale": "The comment raises a valid concern about the diversity of feedback, which could be helpful for the authors in understanding potential limitations in the feedback process. However, the comment itself does not offer any concrete solutions or actionable steps for the authors to improve their draft based on this concern. The reviewer is asking a question about the feedback process, not providing a direct critique or suggestion for the paper itself. Therefore, the comment does not provide direct and actionable feedback that empowers the authors to improve their draft, making it not helpful."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the main text should 'make it more clear that there are additional experiments in the supplement' and 'summarize their results'. These are direct actions the authors should take. The reviewer also asks 'Questions:' which implies they believe this information is important and relevant for the reader's understanding.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the supplement' of the paper. This is a clear and identifiable section of the document. The reviewer's request to 'summarize their results' further specifies the information needed from the supplement.", "verifiability_rationale": "The reviewer's claim is that the main text should 'make it more clear that there are additional experiments in the supplement and preferably summarize their results'. While the reviewer implies this is a beneficial addition, the claim itself is somewhat vague. The reviewer doesn't provide specific examples of what constitutes 'clear' or 'summarize their results'. The 'Questions:' suggests the reviewer believes this is a valuable addition, but the specific nature of the claim could be more concrete.", "helpfulness_rationale": "The reviewer's point directly addresses a common issue for authors \u2013 the organization and presentation of supplementary information. The reviewer provides a clear direction for improvement by stating 'The main text should make it more clear that there are additional experiments in the supplement (and preferably summarize their results)'. This is a direct and actionable suggestion. The reviewer also asks 'Questions:' which implies they believe this information is important and relevant for the reader's understanding. However, the phrasing 'Questions:' might make it slightly less direct than a more explicit statement of benefit."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'Important references are missing' and names two specific relevant works: Gated Fully Fusion (GFF) and EfficientFCN. They also suggest a 'comprehensive comparison' with these works, indicating a concrete action the authors should take. While the reviewer doesn't provide specific details on *how* these works directly relate to the authors' current work, the identification of a missing area and a suggested improvement make this point actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Important references are missing' and names two specific relevant works: Gated Fully Fusion (GFF) and EfficientFCN. They even suggest a 'holisticallyguided decoding' comparison. This strong statement, coupled with the naming of specific papers and a suggested type of comparison, indicates a high level of grounding. The reviewer is clearly pointing to a deficiency in the related work section, specifically regarding comparisons to these architectures/methods.", "verifiability_rationale": "The reviewer states a fact: 'The GFF1 and EfficientFCN2 both aims to implement the fast semantic segmentation method in the encodedecoder architecture.' This claim is verifiable based on the provided references. However, the reviewer does not provide any justification or reasoning to support why this is a problem or how it impacts the current work. The claim is stated, but the verifiable evidence is presented without context or explanation of its significance to the authors' paper.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the related work section (missing important references) and suggests a concrete improvement (a comprehensive comparison). They also mention the 'societal impact' of the work, which is a positive addition. The reviewer provides a clear direction for the authors to improve their work by including and comparing with relevant prior art. The societal impact adds a layer of importance and relevance to the work, making the missing references even more crucial. The reviewer's suggestion for a 'comprehensive comparison' is a valuable piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review points out that the slight improvement doesn't support the claim. While this implies a need for better prompts, it doesn't explicitly state what needs to be changed or how to implement the improvement. The action is implicit.", "grounding_specificity_rationale": "The review refers to \"our proposed prompts\" generally, without specifying which prompts are being questioned or what aspects of their design are problematic. The connection to the experimental results in Tables 6 and 7 is implied but not tied to specific prompt components.", "verifiability_rationale": "The claim that the slight improvement doesn't support the claim is directly supported by the data presented in Tables 6 and 7. The numerical results clearly show a difference between the performance with and without DSP.", "helpfulness_rationale": "The review highlights a discrepancy between the claimed effectiveness and the experimental results. This points the authors in a direction for further investigation and raises concerns about the validity of the claims made about the proposed prompts."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly suggests comparing the performance with two specific papers. This is an explicit action, as the authors can directly apply this suggestion by looking up and implementing the comparisons. The reviewer also implies a critique of the original paper for not including such comparisons, which can be seen as an implicit action to improve the original work by adding these comparisons. However, the suggestion itself is direct and actionable.", "grounding_specificity_rationale": "The reviewer suggests comparing with two specific papers. While the papers themselves are specific, the reviewer does not explicitly identify the *part* of the original paper where these comparisons should be made. The reference is general, referring to 'the performance' without specifying a section, table, or figure. Therefore, the grounding is weak. The specificity of the suggested papers is present, but the lack of grounding makes it difficult to know *where* to apply this suggestion.", "verifiability_rationale": "The reviewer makes a suggestion: 'It is also recommended to compare the performance with \"Multilingual unsupervised neural machine translation with denoising adapters. \" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\", which trains adapters on top of a well trained multilingual pretrained model.' This statement itself does not contain a claim that requires verification. However, the reviewer's underlying sentiment is likely a critique of the original paper for not including such comparisons, which could be interpreted as an implicit claim that the original work is missing valuable insights. The verifiability is borderline because the suggestion itself is somewhat inferable, and the implicit critique lacks strong justification.", "helpfulness_rationale": "The reviewer provides a suggestion for improvement by recommending comparisons with two specific papers. This is a helpful suggestion as it points the authors towards relevant related work and potential areas for further investigation. However, the lack of specificity regarding *where* and *how* to perform these comparisons makes the suggestion less impactful. The authors need more guidance to fully benefit from this feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly suggests exploring different designs and provides examples (different sampling intervals and sample size). However, the level of detail and specificity in how to implement these changes is not provided. While the action is implied, it's not fully explicit.", "grounding_specificity_rationale": "The reviewer mentions 'different spatial locations' and 'the same channel' in the context of 'Cycle FC'. This provides a basis for the authors to identify the specific part of the model being discussed, making the grounding somewhat explicit. However, the reviewer does not specify *what* aspect of these locations and channels is being analyzed, leading to underspecification.", "verifiability_rationale": "The reviewer states that the 'analysis is slightly insufficient' without providing any evidence or justification for this claim. The suggestion to explore different sampling intervals and sample sizes is presented as a potential solution but lacks a clear connection to the identified weakness. There is X being made that is supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer's comment is primarily a suggestion for improvement rather than a critique identifying a specific weakness. While the suggestion to explore different parameters is relevant, it lacks the necessary detail and justification to be truly helpful. The comment does not offer concrete steps or evidence to support the claim of 'slightly insufficient' analysis, making it difficult to act upon."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the absence of standard deviations and the consequence of this absence on the certainty of the best method. This is a clear and direct statement of a missing piece of information and its impact.", "grounding_specificity_rationale": "The reviewer explicitly identifies the missing standard deviations and clearly states that this makes it unclear which method is the best. They pinpoint the missing information (standard deviations) and its direct consequence (uncertainty about the best method). This is 5 about the missing element and its impact.", "verifiability_rationale": "The reviewer makes a claim about the absence of standard deviations and a consequence about the uncertainty of the best method. While they don't provide external references or detailed logical reasoning to fully justify this impact, the connection between the missing standard deviations and the uncertainty is logically implied. The reviewer clearly identifies the missing information and its likely effect.", "helpfulness_rationale": "The reviewer clearly identifies a critical missing element in the evaluation \u2013 the standard deviations. This directly impacts the ability to determine the best method and makes the review highly specific and informative for the authors. It highlights a concrete gap in the presented information, making it 5 for the authors to understand the limitations of the results."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a relevant and actionable question about the limitations of the approach and how it can be generalized. This directly addresses a potential area for improvement and provides a clear direction for the authors to consider. The question is specific enough to guide the authors' thinking about the scope of their method.", "grounding_specificity_rationale": "The reviewer's question is general and does not specify a particular part of the paper being addressed. While the question is relevant to the overall approach, it lacks the specificity required to pinpoint a particular section, table, or figure. The reviewer is not asking about a specific issue within a defined part of the paper, but rather about the general applicability of the method.", "verifiability_rationale": "The reviewer's question is a suggestion for an extension or a thought experiment, not a claim that needs verification. It doesn't present a definitive statement that requires supporting evidence. The question is about exploring possibilities rather than making a judgment about the current method.", "helpfulness_rationale": "The reviewer's question, while not a direct solution, is still likely to be helpful for the authors. It encourages them to think critically about the limitations of their current approach and consider how it might be adapted to broader settings. This type of reflection and exploration is generally beneficial for research development."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking for clarification on a specific detail (the feature extractor) related to the dimensionality of the regions. While they are asking for information, the action they are implicitly prompting is to identify a missing piece of information. This falls under the category of an implicit action. However, the action is not very concrete; the reviewer doesn't immediately know *which* feature extractor was used. They would need to search for it. Therefore, it's 2.", "grounding_specificity_rationale": "The reviewer is specifically pointing out a detail in the paper (the dimensionality of each region being 512) and asking about a related component (the feature extractor). This clearly identifies the specific part of the paper being addressed. The reviewer is also asking for a specific piece of information (which feature extractor was used). Therefore, the grounding is strong, and the specificity is high as they are asking about a specific technical detail.", "verifiability_rationale": "The reviewer is not making a claim that can be verified. They are simply asking a question to seek clarification on a detail. There is no logical reasoning, common knowledge, or external references being presented in the review point itself. Therefore, it doesn't meet the criteria for verifiability.", "helpfulness_rationale": "The reviewer is asking a question to seek clarification on a specific detail. While this can be helpful in guiding the authors to doublecheck their feature extraction, it doesn't directly improve the content or structure of the paper itself. It's a request for more information rather than a direct suggestion for improvement. Therefore, it's 3 in identifying a potential missing piece of information but doesn't directly enhance the work."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point states: 'It would be helpful for readers if computation/algorithm/implementation details are given.' This comment identifies a potential improvement but does not specify how to achieve it. It lacks explicit instructions or concrete steps on what needs to be added or how the details should be presented. While it points to a missing element, it doesn't tell the authors what to do next.", "grounding_specificity_rationale": "The review point is a general statement about the lack of computation/algorithm/implementation details. It does not specify which section, table, figure, or unique aspect of the paper is lacking these details. The reviewer is not pointing to a specific part of the paper being addressed, making it difficult to identify what needs revision and why.", "verifiability_rationale": "The review point is a suggestion for improvement rather than a claim that something is wrong or needs verification. It does not make any assertion that the current computation/algorithm/implementation details are lacking, incorrect, or require justification. Therefore, there is X to be verified.", "helpfulness_rationale": "The review point identifies a valid area for improvement \u2013 the clarity and detail of the computational aspects. However, it does not provide specific guidance on how to achieve this improvement. It is a suggestion, not a concrete step that would directly help the authors address a perceived weakness. While it highlights a potential issue, it doesn't offer actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for justification for the choice of p < 0.4. While the action is to understand the reasoning, the information provided is vague. The paper doesn't explain why this specific threshold was chosen. The reviewer is essentially asking how to *apply* this value, but the paper doesn't provide a clear explanation of its significance or how it was derived. Therefore, the action is not explicitly stated, and the explanation is lacking, making it somewhat difficult for the authors to act upon this information.", "grounding_specificity_rationale": "The reviewer is asking about the parameter 'p' in the algorithm. However, the paper does not explicitly state which algorithm is being referred to. Without knowing the algorithm, it's impossible to pinpoint the specific part of the paper where 'p' is defined or discussed. The reviewer is asking 'how did you choose p < 0.4?', implying they are looking for a specific location and definition within the paper. Therefore, the grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer is not making a claim. They are asking a question about the justification for a specific parameter in the algorithm. Since there is X, this point does not fall under the 'Verifiability' category as defined. The instruction to evaluate review points based on 'Verifiability' requires the presence of a claim that needs verification. Therefore, this review point does not contain a claim and is not verifiable.", "helpfulness_rationale": "The reviewer is asking for justification for the choice of p < 0.4. While this is a valid question and can be helpful for the authors, the paper does not provide any explanation or reasoning for this specific value. The reviewer is essentially asking for a *criticism* or *suggestion* to improve the draft, but instead, they are seeking clarification on a parameter. The lack of justification makes the feedback less actionable and less helpful for the authors to improve their work. Therefore, the feedback is not actively harmful, but it doesn't directly guide the authors towards a better solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the actions the authors should take: 'explain why there are negative numbers in Figure 1' and 'analyze the implications of Figure 2 and Figure 3.' These are direct and clear instructions.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 1', 'Figure 2', and 'Figure 3' by name, indicating a high level of grounding. The reviewer also asks for specific 'explanations' and 'analysis' of these figures, adding to the specificity.", "verifiability_rationale": "The reviewer makes a claim that the figures lack explanation and analysis. While the reviewer doesn't provide external references, the absence of explanation and analysis in the paper itself serves as implicit evidence supporting their claim. The reviewer's request for explanation and analysis is a logical step to address this lack of information.", "helpfulness_rationale": "The reviewer provides very specific and actionable feedback, directly instructing the authors to explain and analyze certain figures. This is a highly constructive and helpful suggestion for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a lack of clarity regarding the motivation for using CMD in federated learning. While it suggests the authors should understand this better, the specific action they should take is not explicitly stated. This makes it 2.", "grounding_specificity_rationale": "The comment refers to \"CMD in federated learning\" generally, without specifying which part of the paper or implementation is causing the confusion. This makes it 1.", "verifiability_rationale": "The comment expresses an opinion about the clarity of the motivation and suggests a way to improve it. It does not make a claim that requires verification.", "helpfulness_rationale": "The review highlights a genuine issue (lack of clarity) that the authors would benefit from addressing. While it doesn't provide a solution, it points to a problem that needs to be resolved, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the 'lack of analysis' and 'lack of comparison' to other paraphrasing methods. While it identifies the problem, it doesn't specify what aspects of the analysis are missing or how the comparison should be structured, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'data augmentation methods' and provides specific examples like 'EDA or LLMbased paraphrasing'. This clearly indicates that the reviewer is referring to specific parts of the paper, making the grounding fully grounded. However, while the grounding is specific, the reviewer doesn't detail what specific aspects of these methods are lacking in analysis or how the comparison should be conducted, making it somewhat specific.", "verifiability_rationale": "The reviewer makes a claim about the 'lack of analysis' and 'lack of comparison'. However, the reasoning provided is general and doesn't offer specific evidence or justification for this claim. There's no logical reasoning, common knowledge, or external references provided to support the assertion that the analysis is lacking or that the comparison is unnecessary. Therefore, it is 1.", "helpfulness_rationale": "The review point clearly identifies a problem ('lack of analysis' and 'lack of comparison') and provides suggestions for improvement ('analyzing the effectiveness of each data augmentation method' and 'comparing their approach to other paraphrasing methods'). The suggestions are specific and directly address the identified problem. The reviewer also implies the importance of this comparison by stating that it would clarify the unique advantages of their method. This makes the review point 5 as it directly points out areas for improvement and provides a clear direction for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests alternative ablation targets, which are direct suggestions for improvement. However, the reviewer does not explicitly state how these alternative ablations would address the lack of clarity regarding the effect of each component. The action is implied but not clearly stated.", "grounding_specificity_rationale": "The reviewer explicitly states the problem: 'Without an ablation study, it is hard to see the net effect of each component.' They also suggest specific alternative ablation targets: 'typical knowledge distillation loss' and 'distilling a Hydra architecture with MMD loss.' This clearly identifies the specific issue and proposes concrete solutions, indicating strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim: 'Without an ablation study, it is hard to see the net effect of each component.' This claim is 3 because the reviewer suggests alternative ablation targets, which serve as examples of how the effect could be investigated. However, the reviewer does not provide explicit justification or evidence to support why these alternative ablations would definitively resolve the issue of seeing the net effect of each component.", "helpfulness_rationale": "The reviewer identifies a potential limitation in the proposed learning approach (lack of ablation study) and offers concrete suggestions for improvement (alternative ablations). This directly addresses a potential weakness and provides a path for further investigation, making the feedback valuable. However, the reviewer does not explicitly demonstrate the benefit of these suggestions or how they will lead to a better understanding of the model's components."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The action is stated explicitly ('assign all negative samples to a distractor class'). However, the action itself is vague and lacks detail on how to apply it. The authors are left to infer what this means in the context of their specific model and dataset. The suggestion is a general idea rather than a concrete step to improve their draft.", "grounding_specificity_rationale": "This review point does not explicitly refer to a specific part of the paper or model. It presents a general suggestion about a baseline experiment. Therefore, it is 1 in a specific aspect of the work. The distractor class is not defined, and the authors cannot infer where this idea applies.", "verifiability_rationale": "The review point makes a claim about the performance of the baseline model. It provides a logical reasoning that the model would perform poorly because it has no information to distinguish between the actual negative samples and the distractor class. However, it lacks specific examples or references to external works to support this claim. The reasoning is present, but the lack of concrete evidence weakens the verifiability.", "helpfulness_rationale": "The review point identifies a potential flaw in the model's approach by suggesting a simple baseline that likely performs poorly. This is a valuable piece of information for the authors to consider. It prompts them to think about the limitations of their current method and the need for a more sophisticated approach. While it doesn't directly tell them how to improve their model, it highlights a concrete issue that they should investigate. The suggestion is clear and relevant to their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the 'shrinking' advantage and the 'remains to be seen' about the future scalability. This is an explicit statement of a trend and a question. While it points to a trend, it doesn't directly tell the authors what to do. It highlights a potential area for further investigation. Therefore, it's partially actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'RLCD,' 'RLAIF,' '7B,' '30B,' and 'Tab. 2.' This clearly grounds the comment in specific elements of the paper. The mention of unique aspects like 'Tab. 2' enhances the grounding. The comment specifies what is being compared and the context of the comparison, making it highly specific within the paper's context.", "verifiability_rationale": "The review point makes a claim about the trend observed in the table. While it doesn't provide proof *within the review itself*, it's a reasonable inference based on the information provided. The phrasing 'It remains to be seen' acknowledges the lack of definitive proof *at the time of writing*. Therefore, it's 3.", "helpfulness_rationale": "The review points out a trend and raises a question about future scalability. While it provides some information, it doesn't directly suggest how the authors should adjust their models or what experiments they should run. It's informative but not a direct solution. Therefore, it's 3."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a problem (scalability) and suggests a question as a way to address it. While the suggestion is relevant, it doesn't provide explicit steps on how the method is learned or applied. The action is implied but not explicitly stated or detailed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the whole training and test datasets as input' and then provides an example of a large dataset (ImageNet). This clearly identifies the specific aspect of the method being critiqued. The grounding is explicit and specific to the method's description.", "verifiability_rationale": "The reviewer makes a claim about the method's limitations regarding scalability for large datasets. They support this claim by stating the impracticality for ImageNet and the potential reduction in practical contribution. This claim is supported by logical reasoning and the context of large datasets.", "helpfulness_rationale": "The reviewer provides a clear criticism of the method's scalability and suggests a potential improvement (addressing scalability). This is a constructive and helpful comment for the authors, highlighting a significant limitation and offering a direction for future work. The claim is wellsupported and directly addresses a potential issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the *lack of quantitative analysis* on computational gains, which directly contradicts the paper's claim of efficiency improvements. It then *sugests* specific metrics (GPU hours, memory usage, training time) as a way to substantiate these gains. This is a clear and actionable suggestion for the authors to improve their draft by providing concrete evidence for their claims.", "grounding_specificity_rationale": "The review point explicitly mentions \"quantitative analysis,\" \"GPU hours,\" \"memory usage,\" and \"training time.\" This demonstrates strong grounding as the authors are pointing to specific metrics and types of data that would be relevant.", "verifiability_rationale": "The review point contains a claim: \"a quantitative analysis\u2014such as GPU hours, memory usage, or training time\u2014would provide stronger evidence of the efficiency improvements in DQ V2.\" This claim is then followed by specific examples of how this analysis could be conducted, making it highly verifiable.", "helpfulness_rationale": "The review point directly addresses a stated claim in the paper (the lack of quantitative analysis) and provides a clear and actionable suggestion for the authors to improve their draft. It guides the authors on what specific data they need to collect and how to present it, making the revision process much easier and more focused."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the *reason* for the efficiency issue (time). This is explicit. However, it does not provide concrete steps on how to address the inefficiency, making it somewhat vague in terms of actionability. The point identifies the *techniques* affected (COLMAP and scenebyscene finetuning) and the *area* where the inefficiency occurs (these scenes), providing some level of specificity.", "grounding_specificity_rationale": "The authors can explicitly identify the specific part of the paper being addressed, namely the time taken for COLMAP and scenebyscene finetuning. They can also clearly specify what is meant by 'inefficient' in the context of these scenes. This demonstrates strong grounding. The comment also specifies what needs to be addressed in this part, which is taking the time into account. The authors can deduce that this means considering the computational cost and potential bottlenecks associated with these techniques for the specific scenes.", "verifiability_rationale": "The claim that 'the time for COLMAP and scenebyscene finetuning should be taken into account' is supported by the understanding that computational time is a relevant factor, especially for specific scenes. This is a logical reasoning. While it doesn't provide specific examples or citations, the underlying principle of efficiency is generally accepted knowledge in the field. The comment specifies what is meant by 'time' and 'inefficient'.", "helpfulness_rationale": "The review point identifies a practical consideration (time) that affects the efficiency of a method. This is a relevant concern for researchers. While it points out a problem and its cause, it doesn't offer specific solutions or detailed guidance on how to address the inefficiency. The feedback is somewhat limited in its actionable scope."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a lack of discussion and analysis regarding the 'filter manifold network' (FMN), which is a core component of the technique. While the reviewer doesn't explicitly state what action the authors should take, they imply that further analysis and discussion are needed. The suggestion to experiment with other architectures and analyze scaling behavior is a clear, albeit implicit, action. However, the reviewer doesn't specify *how* the authors should perform this analysis, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer directly asks specific questions about the FMN, such as whether the authors experimented with other architectures and how adaptive convolutions scale. They also specify the range of input and output channels used in the experiments (around 32) and ask about scalability to larger ranges (128512). These questions are directly related to specific aspects of the FMN, indicating good grounding. The reviewer is asking for details about the implementation and behavior of the FMN.", "verifiability_rationale": "The reviewer states that there is 'almost no discussion or analysis' on the FMN and asks questions about specific aspects like scaling. While the reviewer's claim about 'almost no discussion' is a strong statement, the questions themselves are verifiable. The reviewer is asking for specific information about the FMN's behavior and implementation. However, the reviewer doesn't provide any evidence or justification for their claim about the lack of analysis, making it only 3.", "helpfulness_rationale": "The reviewer provides specific questions and suggestions regarding the FMN, which could be valuable for the authors. They are pointing out a gap in the paper's analysis and suggesting concrete improvements. While the reviewer doesn't explicitly state that the current work is flawed or lacking, the suggestions and questions imply that the authors should have explored these aspects. The feedback is constructive and directly addresses a potential area for improvement, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer directly asks a question about a specific claim made in the original paper (implicitly, by criticizing the complexity of the UNet). They are asking 'which is the important part?' This is a clear and direct question that points to a specific action the authors should take to investigate the model's performance. The reviewer is also implying that the UNet architecture might be a contributing factor, suggesting a specific comparison. This makes the point actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the UNet part in the proposed CoNO model' and asks about its contribution to the performance boost. This clearly identifies a specific aspect of the model being addressed. They also suggest a specific comparison ('comparisons to UNets'), further emphasizing the specificity of the point. The reviewer is not just saying 'the UNet is important'; they are pinpointing a specific component and a specific type of comparison.", "verifiability_rationale": "The reviewer makes a claim about the source of the performance boost, suggesting that the UNet part in the fractional Fourier domain might be the key contributor. However, they do not provide any direct evidence or justification for this claim within the review point itself. They are relying on their understanding of UNet performance on regular grids. While the claim is plausible, the lack of direct verification within this review point makes it 2.", "helpfulness_rationale": "The reviewer's question directly addresses a potential weakness in the proposed CoNO model: the lack of clarity regarding the contribution of the UNet part. They are asking a very specific and relevant question about how the performance boost might be achieved. By suggesting a comparison to standard UNets, they are providing a concrete direction for future experiments. This review point directly helps the authors understand a potential area for improvement and guides them towards a specific type of investigation. It is a valuable and targeted suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the potential issue with computational cost and provides a specific detail from Algorithm 1 (flipping previous layer output) as evidence.", "grounding_specificity_rationale": "The reviewer mentions 'Algorithm 1' and 'forward pass' in their review, providing some grounding by indicating where the issue might be discussed. However, they do not explicitly identify a specific section, table, figure, or unique element of the paper being addressed. The reviewer suggests a *type* of comparison (computation complexity) but doesn't provide specific examples of where this comparison is lacking in the experimental setup.", "verifiability_rationale": "The reviewer makes a claim about the computational cost of the proposed PSA method and suggests a way to verify this claim by comparing it with baselines in the experimental part. However, they do not provide any logical reasoning, common knowledge, or external references to support this claim about the computational cost.", "helpfulness_rationale": "The reviewer raises a relevant concern about the computational cost of the proposed method, which is a practical consideration for its applicability. The suggestion to compare computational complexity with baselines is a concrete and helpful piece of feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point directly addresses a specific question about the contribution of different factors to the model's performance. It asks how much gain can be obtained by removing noise, which is a clear and actionable question for the authors. The reviewer is prompting an investigation into a specific aspect of the model. This directly leads to actionable steps for the authors to experiment with their model.", "grounding_specificity_rationale": "The reviewer explicitly names the two factors being considered: 'noise' and 'exponential moving average'. They also ask a specific question about the contribution of each. This clearly targets a specific part of the model and its behavior. The grounding is explicit and directly related to the components being discussed.", "verifiability_rationale": "The reviewer is asking a question that could potentially be answered through experimentation or further analysis. While it's not a definitive statement with a clear 'yes' or 'no', it's a request for information that *could* be verified. The question is about the potential impact of a specific modification to the model, which could be investigated.", "helpfulness_rationale": "The review point is helpful because it identifies a potential area for improvement in the model and guides the authors towards further investigation. By asking how much gain can be obtained by removing noise, the reviewer is prompting the authors to consider the impact of a specific factor on the model's performance. This is a valuable direction for further experimentation and analysis. While the review point itself doesn't directly tell the authors the answer, it provides a clear question and a potential avenue for improvement, making it 5 in guiding the authors' own investigations."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides specific locations (V_mem, Th_i, U_i^t in Fig 1) and suggests concrete improvements (larger font). While the reviewer doesn't explicitly state 'I will change the font,' the action is implied by the suggestion. The reviewer also suggests a table for comparison, which is a concrete action.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific elements in Figure 1 (V_mem, Th_i, U_i^t) that need larger fonts and the grey box that might benefit from larger fonts. They also point to specific parameters (v_mem, Th_i, U_i^t) and suggest a table for comparison. The grounding is strong as the specific parts are identified, and the specificity is high as the issues and solutions are clearly stated.", "verifiability_rationale": "The reviewer presents suggestions for improvement, such as making the font in Figure 2 larger and suggesting a table for comparison. These are suggestions or recommendations, not claims that require verification. There is no explicit claim being made that needs logical reasoning, common knowledge, or external references to be supported.", "helpfulness_rationale": "The reviewer provides specific suggestions for improving the clarity of figures and the presentation of comparisons. The suggestions are actionable and could be helpful for the authors. However, the review primarily focuses on *what* to do rather than *identifying* a specific weakness or area of improvement that needs to be addressed. The suggestions are more about presentation and comparison style than pointing out a concrete flaw."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a question about the relevance of reporting results while learning and a speculation about the behavior of model parameters and the planning component. Neither of these elements are explicit or direct actions that the author should take. The speculative nature of the second part further reduces the actionability.", "grounding_specificity_rationale": "The review point mentions 'results,' 'training,' and 'RL' generally but does not specify a particular section, table, figure, or unique aspect of the paper that the reviewer is referring to. The second part mentions 'model parameters' and 'planning component' without pointing to a specific part of the author's work. Therefore, the grounding is weak.", "verifiability_rationale": "The review point does not contain a claim that can be verified. The first part is a statement of interest, and the second part is a speculative hypothesis. There is no assertion that something is correct or incorrect, supported by evidence or reasoning.", "helpfulness_rationale": "The review point raises a valid point about the importance of understanding agent behavior during learning. However, the second part, which is a speculation about model parameters and the planning component, does not provide concrete feedback or actionable advice to the authors. It is more of a question or hypothesis than helpful information."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states they don't understand the sentence, indicating a need for clarification, which is an actionable suggestion.", "grounding_specificity_rationale": "The reviewer provides the exact page numbers and line number where the unclear sentence occurs, along with the context ('inference steps'). This shows strong grounding and specificity.", "verifiability_rationale": "The reviewer is pointing out a lack of clarity, not making a claim that needs verification.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the writing and provides a clear direction for improvement (rewrite the sentence), making the feedback actionable and helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point directly asks for clarification on a specific methodological choice (handling entire sentences in DocRED) and a specific challenge (entity disambiguation). This is an explicit action that the authors should take to address the identified gap. The reviewer is prompting them to provide information that is currently missing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'DocRED', 'entire sentence', and 'multiple entity mentions referring to the same entity', which clearly identifies the specific aspect of the paper being addressed. This demonstrates strong grounding as the authors can easily identify the referenced part.", "verifiability_rationale": "The reviewer is stating a factual observation about the current state of the manuscript: that the information on how 'multiple entity mentions referring to the same entity' is handled for DocRED is missing. While it's not a claim requiring verification, it's a valid point that the authors need to address. The statement is supported by the current lack of information in the manuscript.", "helpfulness_rationale": "The review point identifies a specific piece of information that is currently absent from the manuscript. The reviewer is asking the authors to provide details on how they handle entity disambiguation within sentences for the DocRED task. This is a valuable piece of information for the authors to include, as it directly addresses a potential gap in the paper and would improve its completeness and clarity."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The reviewer states their opinion directly ('marginal'), which is explicit. They also provide a reason ('methods used are welldesigned and demonstrated'), which offers some context, making it less vague than a completely unsupported claim. Therefore, the action is explicitly stated and has some basis for implementation, making it 3.", "grounding_specificity_rationale": "The reviewer does not identify a specific part of the paper as being the issue. They offer a general assessment of the contribution's quality ('marginal'). They also do not specify what needs to be addressed in this part. Therefore, the authors cannot confidently determine which part the comment addresses, making it weakly grounded. The comment also does not specify what needs to be addressed in this part, making it not specific. Therefore, it is 2.", "verifiability_rationale": "The reviewer makes a claim ('the contribution looks marginal...'). They also provide a reason ('all the methods used in different stage are well designed and demonstrated'). This reason offers some justification for the claim, making it verifiable. However, the reviewer's assessment of the methods' quality is subjective and not directly verifiable through logical reasoning, common knowledge, or external references within the review point itself. Therefore, the claim is somewhat supported by evidence, making it 3.", "helpfulness_rationale": "The reviewer provides a clear negative opinion ('marginal to me') about the contribution. They do not offer any specific suggestions or improvements. The comment is essentially a criticism without any constructive feedback. Therefore, it does not provide any actionable feedback to the authors, making it 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that 'the main contribution is somehow a little bit unclear' and asks 'any other motivations for PBSD?' These are explicit actions the reviewer is taking based on their reading of the paper. However, the paper does not explicitly state what the main contribution is or provide concrete reasons beyond tail class discrimination for the motivation of PBSD. The reviewer is inferring the main contribution from the ablation study results, which is not explicitly stated in the paper itself. Therefore, while the reviewer is taking an action, it is based on an implicit understanding rather than an explicitly stated claim in the paper.", "grounding_specificity_rationale": "The reviewer states 'However this paper is mostly motivated by supervised contrastive learning, that is, the DSCL part.' This indicates that the reviewer can identify the general area of motivation (supervised contrastive learning) and even the specific component (DSCL) being discussed. However, the paper does not explicitly state that its primary motivation stems from supervised contrastive learning or that DSCL is a key component of its motivation. The connection is implied but not explicitly grounded in the paper's text. Therefore, the grounding is weak, but the reviewer can identify the general area, making it somewhat grounded.", "verifiability_rationale": "The reviewer states 'The main contribution is somehow a little bit unclear.' This is a claim made without explicit justification or supporting evidence within the provided review point. The reviewer's question about other motivations for PBSD also points to a lack of explicit justification for the method's purpose. While the reviewer's inference about the ablation study results is a logical reasoning step, the initial statement about the unclear contribution lacks direct support or verification within the review point itself. Therefore, the claim is not fully supported.", "helpfulness_rationale": "The reviewer's point highlights a potential lack of clarity in the paper's contribution and motivation. This could hinder the authors' ability to understand the paper's value and potentially replicate or build upon it. The reviewer's questions and comments suggest that the paper could be more explicit and provide clearer justifications for its methods and findings. While the reviewer's comment about the ablation study is a logical progression, the initial lack of clarity makes the overall feedback less helpful. The reviewer's questions also indicate a need for more detailed motivation, further reducing the helpfulness score."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question about the relationship between the described 'active learning pipeline' and traditional active learning. This constitutes an explicit action, as the reviewer is directly addressing a potential ambiguity in the authors' description. The reviewer is also inferring that the 'active learning pipeline' is the section describing the method, which, while implied, is not explicitly stated, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'step 2' when asking about the active learning pipeline. This makes the grounding somewhat weak, as the reviewer is inferring the specific part of the paper being addressed rather than explicitly pointing to it. The reviewer is also asking a general question about the relationship to traditional active learning, rather than specifying a particular aspect of the described method that needs clarification.", "verifiability_rationale": "The reviewer makes a claim that the described 'active learning pipeline' might be the same as traditional active learning. This claim requires verification, as it is a statement that needs to be supported by evidence or reasoning. The verifiability is medium, as the reviewer is asking a question that could be answered by comparing the description of the active learning pipeline with the general understanding of traditional active learning.", "helpfulness_rationale": "The reviewer's point is 5. By asking whether the described 'active learning pipeline' is the same as traditional active learning, the reviewer is directly prompting the authors to clarify a potential point of confusion. This is a valuable suggestion that could significantly improve the clarity of the paper. The reviewer is not asking for external references, making the request relatively straightforward to address."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggest how to improve the dataset distribution. It identifies a problem (unclear distribution) but doesn't offer concrete steps or guidance on how to address it.", "grounding_specificity_rationale": "The reviewer mentions 'the proposed dataset' but does not specify which part of the paper or unique aspect of the dataset is unclear. The reference is vague and does not identify a specific section, table, figure, or unique element.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a statement of a problem (unclear distribution) without any suggestion of how to confirm or address it.", "helpfulness_rationale": "The review point identifies a lack of clarity in the dataset distribution but does not offer any suggestions or guidance on how to improve this. It is a diagnostic comment without constructive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for 'annotated labels for learning semantic tokens' and implies this limits the method to 'supervised training'. This directly identifies a procedural requirement and its consequence, making it 5. The reviewer clearly indicates what needs to be done to address the limitation.", "grounding_specificity_rationale": "The reviewer does not explicitly identify a specific part of the paper where the annotation is needed (e.g., a particular section, table, or figure). While they mention 'semantic tokens', they don't pinpoint where these tokens are learned or the specific issue related to annotation. Therefore, the grounding is weak. The reviewer also doesn't specify *what* is wrong with the current approach regarding these annotations. They suggest an alternative but don't detail the specific shortcomings of the current method. Thus, the specificity is also low.", "verifiability_rationale": "The reviewer makes a claim about a potential improvement: 'A selfsupervised pretraining approach without annotations could be more appealing.' This is a suggestion and a potential solution, not a factual statement requiring verification. The reviewer doesn't provide evidence or reasoning to support why this alternative is better or how the current method's performance is affected by the need for annotations. The claim is presented as a preference rather than a verifiable statement. Therefore, the verifiability is low, as the claim lacks sufficient justification.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'A selfsupervised pretraining approach without annotations could be more appealing.' This directly addresses the limitation of requiring annotated labels for supervised training. The suggestion offers a concrete alternative that could potentially overcome this limitation. The reviewer's point is directly relevant to improving the method and provides a clear direction for future work. Therefore, the review is 5 as it offers a direct path for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a gap in the evaluation of LFF by pointing out that most experiments are done on simple tasks. While it highlights the importance of demonstrating scalability to more complex tasks, it doesn't explicitly tell the author how to perform these experiments or what specific steps they should take. The suggestion is present, but the concrete implementation details are missing.", "grounding_specificity_rationale": "The review point explicitly mentions \"continuous control experiments,\" 'simple and lowdimensional tasks\" (cartpole or mountain car), and \"more challenging DRL tasks\" (locomotion of ants or humanoids). It clearly identifies the type of tasks being discussed and even provides examples of both the simple and complex task categories. This demonstrates a strong grounding in the specific area of the paper being discussed.", "verifiability_rationale": "The review point makes a claim: \"It\u2019s important to show LFF can also help to solve more challenging DRL tasks with higher input dimensionality.\" It provides reasoning by stating the current trend of simple tasks and suggesting it as a necessary step for demonstrating scalability. While it doesn't provide specific citations, the logic is based on observed practices and a clear understanding of the goal (demonstrating scalability). The claim is supported by logical reasoning and examples of the task differences.", "helpfulness_rationale": "The review point raises a valid concern about the limited scope of the current evaluation of LFF. By highlighting the gap between simple and complex tasks, it points out a crucial limitation and suggests a valuable direction for future research. While it doesn't provide specific instructions on how to conduct the experiments, it identifies a significant area where the method could be further evaluated and potentially improved. This makes it a valuable piece of feedback that, while not fully actionable, points towards a clear and important area for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two suggestions, both of which are implicit actions. The first suggests adding a sentence to the abstract, and the second suggests including learning curves in the appendix. While the suggestions are clear, they do not explicitly state how to implement them (e.g., the exact sentence to add or the specific experiments for learning curves). Therefore, they are implicit actions that need to be inferred, making them 2.", "grounding_specificity_rationale": "The reviewer's first suggestion explicitly mentions the abstract, providing a clear grounding point. However, the second suggestion about learning curves lacks specificity regarding which experiments should have these curves. Therefore, the grounding is present for the abstract but underspecific for the learning curves.", "verifiability_rationale": "The reviewer's suggestions do not contain any claims that require verification. They are recommendations for improvement rather than statements that need to be supported by evidence or references. Therefore, they do not have verifiability.", "helpfulness_rationale": "The reviewer's suggestions are both relevant and actionable. The first suggests improving the abstract by making it more specific, which is a clear direction for the authors. The second suggests including learning curves, which is also a clear direction for improving the experimental evaluation. Both suggestions are directly relevant to the paper's content and provide concrete directions for improvement, making them 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of clarity regarding the motivation and application of the proposed method. While they don't provide a specific action, the statement itself is a clear indication of an actionable need for the authors to clarify these aspects. The reviewer identifies a gap in understanding that the authors should address.", "grounding_specificity_rationale": "The reviewer does not pinpoint a specific section, table, figure, or unique aspect of the paper as the source of their confusion. They are broadly questioning the motivation and application of the method. While they are asking for clarification, they are not referring to a specific element within the paper.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity in the paper's motivation and application. However, they do not provide any evidence or justification for this claim. The statement is presented as a problem without any supporting arguments or references.", "helpfulness_rationale": "The reviewer raises a significant concern about the lack of clarity regarding the motivation and application of the proposed method. This directly addresses a potential barrier for the authors, forcing them to explicitly explain the context and potential uses of their work. While they don't offer a solution, identifying this gap is a valuable piece of feedback that can guide the authors in improving their communication."}
{"actionability_label": "3", "grounding_specificity_label": "4: Mostly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a critique of the MISA baseline, which can be interpreted as an actionable suggestion to consider more recent work. However, the initial part of the review point, mentioning two specific papers, does not provide any actionable feedback as it simply states facts without suggesting improvements or modifications. Therefore, while one aspect of the review point is actionable, the other is not, making it 3 overall.", "grounding_specificity_rationale": "The review point mentions 'MISA' and 'MULT' as deep learning baselines. While it names specific terms, it doesn't explicitly refer to a particular section, table, figure, or unique aspect of the paper being reviewed where these baselines are discussed or their relevance is questioned. The critique about MULT being 'out of fashion' is general and doesn't ground the feedback in a specific part of the reviewed work. Therefore, while the terms are named, the connection to the specific paper being reviewed is weak, making it mostly grounded but underspecific.", "verifiability_rationale": "The review point makes a claim by stating that the MISA baseline is 'out of fashion'. This claim is 3 as it's a general statement about the age of the baseline. However, it lacks specific examples or references to support this claim within the context of the reviewed paper. The lack of specific evidence makes the verifiability somewhat lacking.", "helpfulness_rationale": "The review point offers two distinct parts. The first, mentioning specific papers, doesn't provide any actionable feedback. The second part, criticizing the MISA baseline, is a suggestion for improvement and is therefore helpful. While one aspect is helpful, the other isn't, making the overall review point 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggestion. It raises a question about the fairness of the comparison by highlighting the omission of model parameter counts. While it implies an action (reviewing the comparison), it doesn't specify what the authors should do next.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or the models being compared. It is a general comment about the experimental setup and the need for a fairer comparison. Therefore, it does not ground the authors in a specific area of their work.", "verifiability_rationale": "The review point does not contain a claim. It is a critique of the experimental comparison rather than a statement of a finding that needs verification. Therefore, it doesn't fit the criteria for verifiability.", "helpfulness_rationale": "The review point highlights a significant lack of clarity in the experimental comparison. By pointing out the omission of model parameter counts, it forces the authors to critically evaluate their experimental design and potentially gather more information or reanalyze their results. This is valuable information for improving the rigor of their analysis, even though it doesn't provide a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'In Table 2' and 'under the leave one out setting', which are explicit actions identifying a specific part of the paper. However, the action of *comparing* to ATA is not explicitly stated or demonstrated within the review point itself. The reviewer implies it as a suggestion.", "grounding_specificity_rationale": "The comment explicitly mentions 'In Table 2' and 'under the leave one out setting', which are literal mentions of a specific section and setting. This clearly grounds the comment to a specific part of the paper.", "verifiability_rationale": "The comment contains a claim that 'As ATA is a bit better than FP according to the results in Table 1, it would be more convincing to also including it in the comparison.' This claim is supported by the results in Table 1, making it '3'. However, the comment does not provide specific examples or references to support this claim within the context of Table 2.", "helpfulness_rationale": "The comment identifies a missing comparison in Table 2 and suggests including ATA based on results from Table 1. While the suggestion points to a potentially valuable improvement, the comment itself does not provide concrete steps or a clear explanation of *why* including ATA would be beneficial in the specific context of Table 2. The suggestion is based on observed results in another table, making it 3 but not fully convincing without further justification in the specific setting."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a discrepancy between versions and suggests standardization of icons. While they identify a potential issue, the exact modules and versions are not specified, making it less actionable for the authors to directly address. The request for guidance on improving the draft is general.", "grounding_specificity_rationale": "The reviewer refers to 'the normalization module' and 'the two versions,' indicating they can identify the specific area being discussed, albeit not with perfect precision. They also point out a specific issue in Figure 4, detailing a potential problem with overlapping symbols in a particular range. This shows some level of grounding and specificity regarding the observed issue.", "verifiability_rationale": "The reviewer states that 'Fig. 4 is a bit confusing...' This is a claim about the clarity of a figure. However, the reviewer does not provide any evidence or reasoning to support this claim within the provided text. There is no logical reasoning, common knowledge, or external references provided to justify the confusion about Figure 4.", "helpfulness_rationale": "The reviewer identifies a potential issue with the visualization in Figure 4 and suggests standardization of icons. While this points towards improvement, it is a somewhat general observation without concrete suggestions for how to achieve the standardization or how to improve the visualization itself. The feedback is present but lacks detailed actionable steps."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly asks for 'detailed explanation' and 'computational cost' regarding the algorithm. This is a very explicit request for specific information that would directly improve the paper. The reviewer is not just pointing out a missing element but actively asking for it.", "grounding_specificity_rationale": "The reviewer refers to the 'theoretical part' and the 'proposed algorithm'. While they don't explicitly name a section or subsection, they clearly point to the area where the relevant information should be found. The request is specific enough to guide the authors to the relevant area, even if it's not a literal mention.", "verifiability_rationale": "The reviewer is posing a question about the algorithm's details and computational cost. This is not a claim that can be verified or unverified. They are stating a concern about the lack of information, not making a statement that requires evidence. The reviewer is not providing a claim that needs verification, but rather highlighting a missing element.", "helpfulness_rationale": "The reviewer's questions directly address the identified weakness in the paper's claim \u2013 the lack of detail regarding the algorithm. By asking for specific details about the algorithm's implementation and its computational cost, the reviewer is providing clear and actionable feedback that directly empowers the authors to improve their work. This is a 5 suggestion as it directly addresses a concrete weakness and provides a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that W1 and W2 are not defined and then points to the equations where these variables are used. This is an explicit statement of a missing action, and the reviewer provides a clear indication of where this action is needed.", "grounding_specificity_rationale": "The reviewer identifies the specific equations (A4) where the undefined variables appear and explicitly states that W1 and W2 are not defined. This demonstrates a strong grounding as the reviewer clearly identifies the section and the variables being referred to.", "verifiability_rationale": "The reviewer makes a claim that the variables are not defined and attempts to verify this by stating they are 'guessing' at the definitions. While the reviewer identifies a claim and provides some justification (their guess), they do not provide concrete evidence or references to support their claim beyond stating they are guessing.", "helpfulness_rationale": "The reviewer's comment primarily focuses on the lack of definition of variables in their model description. While this is a valid point, the reviewer does not offer any specific suggestions or actionable steps for the authors to take to address this issue. The comment is more of a criticism than a helpful suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer's point does not directly address the actionability of providing feedback. They are questioning the *justification* of a comparison, not suggesting a specific action or improvement.", "grounding_specificity_rationale": "The reviewer is not explicitly pointing to a specific part of the paper or method lacking grounding. They are questioning the *overall comparison* process.", "verifiability_rationale": "The reviewer is not claiming something is true or false. They are expressing a doubt about the validity of a comparison, which relates to the *justification* of the comparison, not the verifiability of a statement within the comparison itself.", "helpfulness_rationale": "The reviewer is questioning the fairness of the comparison, suggesting it might be *unhelpful* due to the lack of justification for the baselines' potential lack of prior knowledge or language embedding computation. They are expressing a doubt about the validity of the comparison as a basis for feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "2", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The reviewer asks 'why the outputside layers do not benefit from it?' and 'why the dimensionality remains the same after upsampling in Figure 2. (b)?'. While these questions point to a lack of explicit explanation, the reviewer doesn't directly state an action they would like to take based on this information. The questions are more about understanding the current state rather than suggesting a change. Therefore, it's 2.", "grounding_specificity_rationale": "The reviewer asks 'what details of Pixelshuffle are not clearly presented?' and 'is it the pixelshuffle operation used in the superresolution field?'. This indicates a lack of specific information about the Pixelshuffle operation within the paper. The reviewer is asking for a more precise reference point. While the paper should ideally identify this, the lack of detail makes the comment somewhat grounded in identifying the area of uncertainty.", "verifiability_rationale": "The reviewer asks 'why the outputside layers do not benefit from it?' and 'why the dimensionality remains the same after upsampling in Figure 2. (b)?'. These are questions that require justification or explanation. The paper should provide a logical reasoning for these observations. The lack of explanation makes the comment 2 as it lacks sufficient evidence or justification.", "helpfulness_rationale": "The reviewer's overall tone is one of requesting more information and clearer explanations. They are asking 'why' certain things are happening, which directly translates to a lack of helpfulness. The paper needs to provide more details and justify its claims. Therefore, it's borderline helpful as it doesn't provide clear and actionable feedback."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer poses a question about the state of negative chips and suggests an alternative training approach. While the reviewer points to a potential area for improvement, the review itself doesn't explicitly state the action or provide details on how to implement it. The reviewer's intent is to ask a question rather than provide a direct solution or suggestion.", "grounding_specificity_rationale": "The reviewer refers to 'negative chips' and the 'RPN training process.' While they are related to the RPN, they don't explicitly identify a specific part of the paper or methodology being discussed. The reviewer uses general terms, making it difficult to pinpoint the exact area of reference. This suggests a lack of strong grounding in the specific context of the paper or methodology.", "verifiability_rationale": "The reviewer poses a question about the relationship between negative chips and RPN training without providing any evidence, reasoning, or references to support their claim. The statement is presented as a question rather than a verifiable claim. Therefore, there is no verifiable evidence provided within the review point itself.", "helpfulness_rationale": "The reviewer raises a question about a specific aspect of the RPN process. While the question is relevant to understanding and potentially improving the system, it doesn't provide concrete, actionable feedback or suggestions. The review is primarily a query rather than a constructive critique or improvement proposal. Therefore, the helpfulness is limited to gaining understanding, but not to actionable changes."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a need to evaluate the proposed approach differently for new and returning patients. This is an explicit action with a clear objective. The reviewer also implicitly suggests conducting this evaluation, which is a concrete action once the evaluation is set up.", "grounding_specificity_rationale": "The review point explicitly mentions the issue of 'patient is the first time visitor' and the proposed solution of evaluating the approach on 'new patients' and 'old patients' respectively. This clearly identifies the specific part of the paper and the specific issue being addressed. The reviewer also implies the need to adjust the evaluation methodology based on this factor, which is a specific request.", "verifiability_rationale": "The review point is a suggestion for an experiment (evaluating the approach on different patient groups) and does not contain a claim that can be verified. It is a request for a specific evaluation rather than a statement of what will happen.", "helpfulness_rationale": "The review point directly addresses a potential limitation the authors have identified (the impact of patient visit history on evaluation). It provides a clear direction for the authors to take, which is to evaluate the approach on new and returning patients separately. This is a helpful and actionable suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a problem: 'Most baselines do not use 300WLP dataset in their training. Is 300WLP used in all experiments or just some? If it is used in all this would provide an unfair advantage to the proposed method.' This is an explicit statement identifying a discrepancy in the methodology. The reviewer clearly indicates that the proposed method uses 300WLP while the baselines do not, or potentially do, creating a potential bias. The reviewer's question directly points to a lack of clarity in the experimental setup description.", "grounding_specificity_rationale": "The reviewer's comment is 1 in a specific section or table of the paper. While they mention 'experimental methodology,' they do not point to a specific part of the paper where this detail should be found. The reviewer refers to the general methodology without providing a precise location. However, the reviewer does specify the *issue* being questioned: 'the potential unfair advantage to the proposed method' related to the 300WLP training data. This specificity pertains to the *problem* identified, not the specific section containing the detail.", "verifiability_rationale": "The reviewer's comment does not contain a claim that requires verification. They are pointing out a potential inconsistency or lack of clarity in the paper's description of the experimental methodology. While the reviewer's suggestion to check the baselines' training procedures is a valid point, the *review point itself* does not present a claim that can be supported or unsupported. The reviewer is highlighting a potential gap in the paper's description rather than making a statement that can be verified.", "helpfulness_rationale": "The reviewer's comment is 3 in that it raises a valid concern about the experimental setup. It encourages the authors to doublecheck their methodology and potentially address the potential unfair advantage. However, it does not directly suggest a concrete fix or improvement. The reviewer is pointing out a potential flaw in the experimental design rather than providing a direct solution. The helpfulness is limited because the reviewer is not proposing a specific action to take."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment is vague and doesn't explicitly state what the author should do or how to do it. It implies a problem but doesn't provide clear instructions. For example, it mentions 'computation offloading and gradient augmentation may not be that novel' but doesn't specify which techniques, how they are implemented, or what the implications are for the author's work. The connection between the techniques and the lack of novelty is implied but not explicitly stated or linked to specific parts of the paper. Therefore, while the comment points to a potential issue, it lacks the specific guidance needed for action.", "grounding_specificity_rationale": "The comment refers to 'computation offloading' and 'gradient augmentation' generally. It doesn't explicitly state which section, table, figure, or unique aspect of the paper it is addressing. While it mentions these techniques, it doesn't specify where they are discussed in the paper. The reviewer uses these terms broadly without pointing to a specific location in the paper where these techniques are described. Therefore, the grounding is weak as the author cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The comment contains a claim: 'Some technique behind the algorithm may not be that novel.' This is a statement of opinion or judgment. However, the comment does not provide any evidence, examples, or references to support this claim. It's an assertion without justification. The reviewer states something is 'not that novel' but doesn't explain why or provide any basis for this assertion. Therefore, the claim is not wellsupported by evidence or reasoning, making it 1. The comment doesn't offer any logical reasoning, common knowledge, or external references to back up the claim about the novelty of the techniques.", "helpfulness_rationale": "The comment identifies a potential lack of novelty in the techniques used but doesn't provide specific directions or suggestions on how to address this. It doesn't tell the author what to compare their method to or how to demonstrate its unique contribution. The reviewer points out a concern but doesn't offer concrete guidance for the author. The comment is an assertion without actionable steps. Therefore, the feedback is present but lacks the specific guidance needed to improve the draft."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential limitation in the model's assumption about how observations are generated, suggesting alternative aggregation methods. While the reviewer doesn't explicitly state, 'You should change Equation 1 to use summation instead of averaging,' they imply a mismatch between the model and the actual data aggregation process. This suggests a need for the authors to consider alternative aggregation methods. However, the reviewer doesn't provide a specific, actionable step on how to implement this change, making it not fully actionable.", "grounding_specificity_rationale": "The reviewer refers to 'Equation (1)' and mentions 'bag observation model' or 'spatial aggregation process' in the context of that equation. While they don't give a specific section number, the reference to 'Equation (1)' itself grounds the discussion to that specific part of the paper. The reviewer is specifically addressing a potential issue related to the formulation in that equation.", "verifiability_rationale": "The reviewer states a potential limitation in the model's assumption about observation aggregation and suggests alternative methods. This is a logical argument based on common knowledge about disease incident data often being in count or rate form. While they don't provide specific citations, the reasoning is sound and suggests a direction for the authors to explore. The claim is supported by logical reasoning and common knowledge, making it 3.", "helpfulness_rationale": "The reviewer points out a potential mismatch between the model's assumption about observation aggregation and the actual nature of the data. They suggest considering alternative aggregation methods, which directly addresses a modeling assumption and offers a concrete direction for improvement. This review provides actionable feedback on a specific aspect of the model and helps the authors refine their approach. The suggestion is clear and directly relevant to improving the model's alignment with the data."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'no indepth analysis' and asks 'why?'. This indicates a clear request for a specific action (providing analysis). However, the request lacks specific details about the type of analysis or the scope of the 'why'. Therefore, while the action is explicit, it is not concrete enough to be 5.", "grounding_specificity_rationale": "The reviewer does not point to a specific section, table, figure, or unique aspect of the paper. They are referring to the general area of 'training dynamics'. Therefore, the grounding is weak. While the topic of 'inverse scaling' is somewhat specific, the request for 'why' is broad and doesn't pinpoint a specific part of the paper or methodology to address.", "verifiability_rationale": "The reviewer presents a statement about a missing element ('no indepth analysis') and a request for information ('why?'). This is not a claim that needs verification. It's a suggestion for improvement rather than a statement that can be supported or unsupported.", "helpfulness_rationale": "The reviewer's comment directly points to a weakness in the paper ('lack of indepth analysis') and provides a clear suggestion for improvement ('provide some analysis explaining such training dynamics'). This directly addresses a perceived gap in the paper and would likely be beneficial for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states their questions about the multihead attention mechanism and the split arrow in Figure 2, indicating a direct request for clarification on implementation details. While they don't directly instruct a change, they point to a specific area needing attention, making it 3.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 2 right, bottom right' and asks specific questions about 'keys' and 'values'. This demonstrates a clear understanding of the relevant section and its components, making the grounding fully grounded. The questions also specify what needs clarification, adding to the specificity.", "verifiability_rationale": "The reviewer identifies a lack of clarity in the description of multihead attention and asks specific questions about Figure 2. While they don't explicitly state a claim to be wrong, their request implies a potential issue that needs clarification. The lack of mathematical detail makes the interpretation ambiguous, making it partially verifiable.", "helpfulness_rationale": "The reviewer provides specific questions and requests for clarification regarding the multihead attention mechanism and Figure 2. This directly addresses a potential area of confusion for the authors and offers a concrete direction for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly criticizes the paper's assumption of independent and identically distributed (IID) data for each user. They explain that this assumption is crucial for the mathematical argument involving the sqrt(m) term and the application of Theorem 6 to prove Theorem 7. The reviewer argues that this assumption is unrealistic because user preferences for emojis are likely to be different. This is a clear and actionable criticism of a core assumption.", "grounding_specificity_rationale": "The reviewer explicitly names the 'IID assumption' and explains how it directly relates to the convergence argument and the sqrt(m) term. They also connect it to the applicability of Theorem 6 for proving Theorem 7. This provides a precise and clear grounding of the criticism to a specific part of the paper's methodology. The reviewer doesn't just say 'the assumptions are wrong'; they specify *which* assumption and *how* it impacts the math.", "verifiability_rationale": "The reviewer provides a clear explanation of how the IID assumption affects the mathematical arguments. They explain that without this assumption, the convergence proof and the derivation of the sqrt(m) rate become invalid. The reviewer also points to the specific theorems (Theorem 6 and 7) and the sqrt(m) term as being directly impacted by this assumption. This provides strong and explicit evidence for their claim.", "helpfulness_rationale": "The reviewer's comment is highly relevant and directly addresses a key aspect of the paper's methodology. By highlighting the unrealistic IID assumption, they are likely to provide the authors with valuable information for revising their approach. The reviewer's explanation of the impact on the mathematical arguments makes the criticism constructive and actionable for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need to explore more complex tasks and compares against a reinforcement learning baseline, providing clear guidance on how to modify the policy. The suggestion to compare with an RL algorithm baseline is a direct action to improve the current policy.", "grounding_specificity_rationale": "The reviewer refers to the 'fixed policy' conceptually, and the suggestion to compare with an RL baseline implies a change related to the current policy. While not a direct reference to a specific section, the implications are clear.", "verifiability_rationale": "The reviewer makes a claim about the limitations of a fixed policy and provides a logical suggestion for improvement (exploring complex tasks and comparing with RL). The logical reasoning is present.", "helpfulness_rationale": "The reviewer points out a potential area for improvement and offers a concrete direction for the author to explore, which is helpful for guiding the author's work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "None", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a desire to improve the analyses of the method and experimental outcomes, which is an explicit action. However, the reviewer does not specify *how* these analyses should be improved, making the action vague.", "grounding_specificity_rationale": "The comment explicitly mentions which part of the paper it addresses, or it should be obvious to the authors. However, this comment does not specify what needs to be addressed in this part.", "verifiability_rationale": "None", "helpfulness_rationale": "The reviewer points out a potential area for improvement ('the analyses of the method itself and the experimental outcomes are not comprehensive enough') and suggests focusing on 'improving the analyses'. However, they do not provide specific *how* to improve the analyses or *why* the current analyses are insufficient."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a limitation of the paper's scope (multitask models limiting applicability) but doesn't explicitly state what needs to be changed or how to address it. It identifies a problem but lacks specific, actionable steps.", "grounding_specificity_rationale": "The review mentions 'multitask models' and 'applicability' but doesn't pinpoint a specific section, table, figure, or unique aspect of the paper where this limitation is evident. The reference is general.", "verifiability_rationale": "The review contains a claim ('This paper mainly focuses on explaining multitask models, which somehow limits the applicability') but doesn't provide any evidence, reasoning, or references to support this statement. It presents an observation or suggestion without verification.", "helpfulness_rationale": "The review identifies a potential limitation of the paper's scope (multitask models limiting applicability). While it doesn't offer specific solutions, it points to a direction for improvement, guiding the authors towards rebalancing their work."}
{"actionability_label": "5", "grounding_specificity_label": "Full Grounding and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the literature review ignores relevant papers 1 and 2. It also mentions that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This provides clear information for the authors to address the missing literature and compare their approach to existing methods.", "grounding_specificity_rationale": "The comment explicitly mentions the papers 1 and 2 as relevant. While it doesn't provide a unique identifier within the text, the association with 'VRMARINA' and 'DASHAMVR' strongly implies which specific papers are being referred to. This allows the authors to identify the specific sections or even the papers themselves.", "verifiability_rationale": "The comment contains a claim that the literature review is incomplete and suggests specific reasons why (1 and 2 are relevant due to satisfying Assumption 2 and having a better rate than QSGD). However, the claim about the performance of VRMARINA and DASHAMVR is based on the reviewer's understanding and is not directly supported by evidence *within this review point* itself. The lack of a literature review is a verifiable fact.", "helpfulness_rationale": "The comment identifies a potential weakness in the draft (insufficient literature review) and provides suggestions for improvement (include 1 and 2, compare to existing methods). The reviewer also points towards a direction for further investigation regarding the performance of other algorithms. This provides a clear direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a problem with the paper's presentation but lacks specific details on what is difficult to follow and how the authors should address it. It's implicit and vague, making it 3 but not fully so.", "grounding_specificity_rationale": "The comment is a general statement about the paper's presentation being hard to follow, without specifying which section, table, or figure is problematic. Therefore, it is 1 in a specific part of the paper.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is an observation about the presentation, not a statement that needs supporting evidence.", "helpfulness_rationale": "The comment identifies a weakness in the presentation but does not offer any specific, actionable suggestions for improvement. Therefore, it is not 5 to the authors, as it lacks guidance on how to address the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or provide concrete suggestions. It poses questions that require the authors to perform further analysis or experimentation, but doesn't directly tell them what to do. The questions are openended and could be interpreted in multiple ways.", "grounding_specificity_rationale": "The review point does not explicitly mention any specific part of the paper or dataset (like Clothing1M or WebVision) when posing the questions. The questions are general and apply to the algorithm's performance in general. Therefore, it cannot be grounded to a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The review point does not contain a claim or assertion that needs verification. It is a question posed to the authors, not a statement that requires justification or evidence.", "helpfulness_rationale": "The review point poses questions that are relevant to understanding the algorithm's performance and potential generalizability. While it doesn't provide immediate solutions, it highlights areas where the authors might need further investigation or clarification. It is a valid point that could help the authors improve their understanding and potentially their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for a comment on the computation requirements of the three methods. This is a direct request for information that the authors should provide, making it actionable. The reviewer clearly identifies the gap in the paper and suggests a specific area for improvement.", "grounding_specificity_rationale": "The reviewer asks for more detail about the compared models (DMM, DVBF, KVAE) and specifically about the computation requirements. While they mention the differences with KVAE, their request for computation details is general and doesn't pinpoint a specific part of the paper or method. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer is asking for information that is not explicitly stated in the paper. They are inferring the need for this information based on their understanding of the models and the potential benefits for the authors. While the request is not directly challenged, it is not explicitly supported by evidence within the paper. Therefore, it is 3 as the authors are making a claim (that more detail is needed) that requires justification.", "helpfulness_rationale": "The reviewer's request directly addresses a potential area for improvement in the paper by providing more information about the compared methods, particularly their computational requirements. This information could help the authors better understand and potentially improve their own work. Therefore, the comment is 5 as it directly addresses a potential need for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for more experiments on LLaMA and Falcon, which is an explicit action. Furthermore, they specify *which* experiments are missing, making the action concrete. The reviewer implies that the authors should perform these additional experiments, making it actionable.", "grounding_specificity_rationale": "The reviewer mentions 'different famous LLMs like LLaMA, Falcon, etc.' which are specific models. However, they do not explicitly state which *experiment* within the T5, PaLM, and GPT series experiments they are referring to. The connection to the existing experiments is implied but not explicitly stated, making the grounding weak. The specificity is also underspecific as the reviewer doesn't detail *why* these models are important for the benchmark or what specific aspects of these models they want to see.", "verifiability_rationale": "The reviewer makes a claim that 'I think more experiments on different famous LLMs like LLaMA, Falcon, etc are needed as benchmark baselines.' This is a clear statement of a requirement. The reviewer provides a reason for this suggestion by stating 'benchmark score.' While the phrasing is a bit informal, it still conveys a justification for the need for more experiments. The reviewer implies that these additional experiments will improve the benchmark scores, providing a basis for verifiability.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors to improve their benchmarking. They identify a specific area for improvement (more experiments on LLaMA and Falcon) and explain *why* this is beneficial ('more comprehensive benchmarking'). This directly addresses a potential limitation of the authors' work and provides a clear path for improvement. The suggestion is directly relevant and likely to have a positive impact on the authors' results."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the paper does not describe what hyperparameters are used by each defense nor how those hyperparameters are derived. This is an explicit statement of missing information. However, the reviewer does not provide specific guidance on how to derive these hyperparameters, making the actionable aspect somewhat lacking.", "grounding_specificity_rationale": "The reviewer points out that the paper does not explicitly link specific hyperparameters to specific defense mechanisms. While the reviewer can infer this connection, the paper itself lacks this explicit grounding. The specificity of the missing information is about the type of information (hyperparameters for each defense), which is present, but the grounding of *which* hyperparameters relate to *which* defense is not explicitly stated.", "verifiability_rationale": "The reviewer states that the paper does not describe what hyperparameters are used by each defense nor how those hyperparameters are derived. This is a factual statement about the paper's content, not a claim that requires verification. Therefore, there is no verifiable aspect to this comment.", "helpfulness_rationale": "The reviewer identifies a clear gap in the paper's description regarding hyperparameters. This lack of information can be considered a weakness that the authors would find helpful to address. While the comment doesn't provide specific solutions, it points to a concrete area needing improvement, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points to a 'main takeaway point' and a specific action ('query a cluster proportionally to the square root of its size'), but it doesn't explicitly state how to implement this action. The formula or algorithm isn't provided, making the action only implicitly suggested.", "grounding_specificity_rationale": "The review refers to 'theoretical results' and 'main takeaway point,' which are general areas. While it hints at the area of interest ('practical implications'), it doesn't pinpoint a specific section, table, figure, or a unique element within the paper. The connection to the 'square root of its size' is also vague.", "verifiability_rationale": "The review makes a claim ('query a cluster proportionally to the square root of its size' is a 'main takeaway point') and supports it by stating its implications for practitioners. However, the critique of novelty is an opinion. The claim about the square root of size isn't *fully* verifiable without knowing the exact takeaway.", "helpfulness_rationale": "The review identifies a potential practical takeaway ('query a cluster proportionally to the square root of its size') but fails to provide concrete guidance on *how* to achieve it. The critique of novelty is a valid point but doesn't directly offer a solution. The lack of a specific takeaway makes it difficult for the author to act."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks 'why' and 'what additional info' regarding the use of separators in section 4. This directly requests an explanation of the action (providing justification for the use of separators). The request is clear and directly identifies the action to be explained.", "grounding_specificity_rationale": "The reviewer's question directly refers to 'section 4', which is a specific part of the paper. The comment clearly identifies the issue (separators) within that specific section. This demonstrates strong grounding as the issue is localized to a specific part of the paper.", "verifiability_rationale": "The reviewer is asking for clarification and a justification for the use of separators. While the paper itself might contain the information, the reviewer is explicitly requesting a *reason* and *additional information*. This is a valid point, but it might not be universally available or explicitly stated in a way that immediately jumps out. Therefore, it's 3 as the information exists but requires further explanation or context.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific aspect of their work (separators in section 4). This directly addresses a potential point of confusion or lack of understanding for the authors. By seeking clarification, the authors can potentially improve their draft by addressing this specific issue. Therefore, this is a helpful review point as it prompts the authors to reflect on and potentially improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the current pooling method (mean pooling) and suggests exploring alternatives like max pooling or learned pooling. This indicates an action to try different pooling strategies. However, the suggestion is quite broad and lacks specific details on how to implement or evaluate these alternatives.", "grounding_specificity_rationale": "The reviewer refers to 'tokens' in general, without specifying a particular section, table, figure, or unique aspect of the paper where the token pooling is being applied. This makes the grounding of the review somewhat weak as the authors cannot confidently pinpoint the exact area being addressed.", "verifiability_rationale": "The reviewer makes a claim about the current pooling method (mean pooling) and suggests exploring alternatives. This claim could be considered 3 as it points to a specific method being used and proposes a different approach. However, it lacks specific examples or references to support the claim about mean pooling's limitations.", "helpfulness_rationale": "The reviewer suggests exploring different pooling strategies, which is a relevant and potentially helpful suggestion for the authors. However, the suggestion is quite general and doesn't provide specific reasons or guidance on *how* to approach this exploration. It lacks concrete suggestions or actionable steps beyond 'try different methods'."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states 'real search cost (e.g. in terms of GPU days)' as a better metric for comparison, which is a direct and actionable suggestion. The reviewer is clearly indicating what improvement they believe is needed.", "grounding_specificity_rationale": "The comment mentions 'Table 3' and the concept of 'search cost,' which provides some grounding. However, it doesn't explicitly and accurately pinpoint the specific part of Table 3 being referred to. The suggestion is implied rather than directly stated as 'the number of queries in Table 3 is insufficient'.", "verifiability_rationale": "The comment suggests using 'GPU days' as a metric but does not provide a clear explanation or justification for why this is a better approach than simply using the 'number of queries'. While the suggestion is concrete, the lack of supporting reasoning makes it less verifiable.", "helpfulness_rationale": "The comment provides a clear and specific suggestion for improving the analysis by proposing the use of 'GPU days' as a metric for 'search cost'. This directly addresses a potential weakness in the current approach (just using the number of queries) and offers a concrete alternative, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a specific gap in the paper by asking about the training details of the VQGAN. While they don't explicitly state an action to take, the questions directly suggest a need for clarification on whether the VQGAN is pretrained and what data was used. This implies a desire for more information, making it 3 in terms of seeking clarification.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'VQGAN' and 'the Computer Vision Figures dataset' in their review point. This strong referencing clearly indicates that they are identifying a specific part of the paper and asking about details within that part, making the grounding very specific.", "verifiability_rationale": "The reviewer is essentially stating a claim: 'the paper lacks details about the VQGAN training process.' However, at this point, there is no external reference or logical reasoning provided to support this claim. The lack of information itself is the basis for the comment, making it 1 at this stage.", "helpfulness_rationale": "The reviewer directly points out a missing detail (training details of the VQGAN) that would be valuable for the authors. They are asking a specific question about where this information should be found. This directly addresses a potential area for improvement in the authors' paper presentation, making the review point 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the importance of taskoriented dialogue systems and the need to differentiate their work from 'chatbox' research. They also provide concrete examples of relevant works and suggest a direction for discussion. This constitutes an explicit action with concrete details on how to implement it.", "grounding_specificity_rationale": "The reviewer mentions 'taskoriented recommendation' as a general perspective, which is not a specific part of the paper being criticized. However, the reviewer also suggests specific works and a direction for discussion, which can be considered grounded. The specificity lies in the *type* of work and the *direction* of the comparison.", "verifiability_rationale": "The reviewer states that the suggested works are 'important to include' and that the discussion on the difference is 'very useful'. While the *content* of the suggestions might be debatable, the *action* of including these works and discussing the differences is verifiable. The reviewer provides a clear direction for improvement.", "helpfulness_rationale": "The reviewer provides specific examples of relevant related work and a clear direction for discussion. This directly addresses a potential weakness in the paper's framing and provides actionable guidance for improvement. The suggestions are concrete and directly relevant to the paper's stated goals."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point states that the proposed methods are not generic on some crossmodel retrieval tasks, specifically showing minor improvements on MSVD. While this points out a potential issue, it does not explicitly instruct the authors on how to address this. The reviewer identifies the problem but doesn't provide concrete steps or actions to take. Therefore, it is not 5, but it is not completely 1 either as it highlights a specific area for improvement.", "grounding_specificity_rationale": "The review point explicitly mentions the 'performance in MSVD' and the 'performance (improvements) on some crossmodel retrieval tasks'. This clearly identifies the specific part of the paper being addressed, making it fully grounded. The comment specifies what needs to be addressed \u2013 the performance on the MSVD dataset.", "verifiability_rationale": "The review point contains a claim: 'The proposed methods (DualIS and DualDIS) are not generic on some crossmodel retrieval tasks, i.e., the performance in MSVD (Table 3) shows minor improvements.' This claim is directly supported by the experimental results mentioned (MSVD, Table 3, minor improvements). The reasoning is based on the observed performance differences, making it 5.", "helpfulness_rationale": "The review point identifies a potential issue with the proposed methods \u2013 their nongeneric performance on specific tasks. While this observation is valid, it does not offer concrete suggestions or further analysis to address the issue. The reviewer points out a problem but doesn't provide actionable steps or insights for improvement. Therefore, it is not 5, but it is not completely unhelpful either as it highlights a potential limitation of the work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states a potential alternative (vanilla Adam with random restarts) and highlights a key difference in the number of runs required. This is an explicit and concrete suggestion for improvement.", "grounding_specificity_rationale": "While the reviewer doesn't explicitly name a section, table, or figure, the comparison of the proposed method to a wellknown optimization technique (vanilla Adam with random restarts) implies a lack of clarity in the description of the proposed method's experimental setup. The reviewer points to a specific aspect (the number of runs) as a potential issue, but doesn't directly link it to a specific part of the paper.", "verifiability_rationale": "The reviewer makes a claim about the experimental strengths of the approach and provides a clear and logical argument comparing it to a wellestablished alternative (vanilla Adam with random restarts). They explain why the alternative is more efficient and effective. This provides strong support for their concern.", "helpfulness_rationale": "The reviewer's point is clear and directly addresses a potential weakness in the experimental setup. They suggest a concrete alternative and explain why it is more efficient. This makes the comment 5 for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a limitation in the study's scope, specifically the lack of established relationships between top selected patches and the disease. While it implicitly suggests that this limitation should be addressed, it doesn't explicitly state what action the authors should take. The action is implied rather than directly stated.", "grounding_specificity_rationale": "The comment refers to 'top selected patches' without specifying which patches are being discussed. This indicates that the authors cannot confidently determine the exact part of the paper being addressed. The reference is general and lacks precise identification.", "verifiability_rationale": "The comment states that the 'relationship between the top selected patches and the disease is not yet established' without providing any evidence or justification for this claim. It presents a statement of a problem or missing information without logical reasoning, common knowledge, or external references to support it.", "helpfulness_rationale": "The comment identifies a potential weakness in the study's scope by pointing out the incomplete establishment of relationships between patches and the disease. This serves as a reminder to the authors to consider the broader context and potential limitations of their work. While it doesn't offer a specific solution, it highlights an area for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: 'In the phrase \"for \"inbetween\" uncertainty\", the first quotation mark on \"inbetween\" needs to be the forward mark rather than the backward mark (i.e., \u2018 i n \u2212 b e t w e e n \u2019 ).' The action is clear: identify the incorrect quotation mark. The implementation is also clear: specify the correct forward quote. The reviewer directly points out the need for a change.", "grounding_specificity_rationale": "The reviewer accurately identifies the specific phrase 'for \"inbetween\" uncertainty' and the specific part of that phrase, 'inbetween', where the error occurs. They provide a clear reference to the location of the problematic element within the text.", "verifiability_rationale": "The reviewer points out a factual error in the text. While not requiring external references, the statement is verifiable by examining the quoted phrase. The reviewer states a fact: the current quotation mark is incorrect and the forward quote is the appropriate one. This is a direct observation, not a complex logical deduction.", "helpfulness_rationale": "The reviewer provides a clear and direct suggestion for improvement: replace the backward quotation mark with a forward quotation mark. This is a specific, actionable piece of feedback that directly addresses a minor error in the text. The reviewer's comment is immediately useful for the author."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a weakness ('the performance of FedSP is not the best'), but it does not explicitly state what needs to be improved or how to address this weakness. The action is implied but not directly stated.", "grounding_specificity_rationale": "The comment refers to 'FedSP' and 'Tables 1 and 2' but does not specify which table or dataset within those tables is experiencing the performance issue. The grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The comment presents a claim ('the performance of FedSP is not the best') without providing any evidence, justification, or references to support this statement. The claim is not verifiable based on the information provided in the review point.", "helpfulness_rationale": "The comment identifies a weakness in the performance of FedSP but does not provide any actionable suggestions or guidance on how to improve it. While it points out a problem, it lacks the necessary steps for the authors to address it."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for the definition of Omega and points out the lack of clarity regarding OMD, the link function, and the regret guarantee. While the reviewer doesn't explicitly state an action, the request itself is a clear indication of an actionable improvement needed by the authors. The reviewer directly identifies what information is missing and how it should be presented.", "grounding_specificity_rationale": "The reviewer points out the lack of clarity regarding Omega and OMD. They do not explicitly state which section or table contains the definition of Omega. While the reviewer's request for the link function and theorem makes the issue more specific, the initial point about Omega and OMD is vague in terms of location. The reviewer can infer the need for more detail, but cannot precisely identify the referenced part without further clarification from the authors.", "verifiability_rationale": "The reviewer states that the paper lacks clarity regarding Omega, OMD, the link function, and the regret guarantee. The reviewer does not provide any external references or logical reasoning to support this claim. They are simply stating their observation about the potential lack of clarity. There is X being made, just a statement of what might be missing.", "helpfulness_rationale": "The reviewer's point directly targets specific areas where the authors can improve their understanding and potentially the paper itself. By asking for the definition of Omega and more details about the OMD algorithm, the reviewer provides a clear direction for the authors' improvement efforts. The request for specific details like the link function and theorem makes it 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a problem ('learned directly from pixels') and suggests a solution ('without a Markovian state'). While the suggestion is broad, it indicates an actionable direction for improvement.", "grounding_specificity_rationale": "The reviewer can identify the specific aspect of the model being criticized ('Markovian state') and the part of the paper being addressed ('models'). However, the review doesn't specify *what* is missing or *how* to implement the suggested change, making it underspecific.", "verifiability_rationale": "The review point is a statement of a perceived issue and a suggestion for improvement, not a claim requiring verification.", "helpfulness_rationale": "The review point offers a potential improvement to the model architecture by avoiding a Markovian state. While the suggestion is broad and lacks specific details, it points in a constructive direction for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer's comment is not explicitly suggesting an action or improvement to the paper. While they are pointing out a discrepancy and asking for clarification, the suggestion to use crossentropy loss is implicit. The reviewer is indicating a potential area for improvement but doesn't directly instruct the authors on how to implement it. The lack of a direct action makes it less actionable.", "grounding_specificity_rationale": "The reviewer is not explicitly pointing to a specific part of the paper they are reviewing where the Hamming distance is used as a loss function. They are referring to a general concept ('common practice in the context of CRF') and asking for references. While they are asking about a specific loss function (Hamming distance), the grounding is weak because they cannot pinpoint the exact location in the paper where this concept is discussed. They are inferring a potential issue based on a general statement.", "verifiability_rationale": "The reviewer makes a claim by stating, 'I'm a bit surprised that you mention in Example 2 a 'common' practice in the context of CRF corresponding to using as a scoring loss the Hamming distance over entire parts of the sequence.' This is a statement of opinion and requires justification. The reviewer then provides a piece of evidence by stating, 'I've never seen this type of approach there,' which directly supports their claim. This evidence is clear and directly addresses the claim.", "helpfulness_rationale": "The reviewer's comment is 5. They are directly asking for clarification on a specific methodological detail (the use of Hamming distance as a loss function in CRFs) that they believe is a 'common practice'. This is a very specific and actionable question that could significantly improve the reviewer's understanding of the paper and potentially the authors' understanding of the method. The request for references makes the comment very useful for the authors as well."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment suggests a change in terminology ('Evaluation' to 'Metrics') but doesn't explicitly state what action the authors should take next. While the suggestion is present, the lack of a clear 'how to' translates to a lack of explicit actionability. The comment is somewhat vague about the benefits of the change.", "grounding_specificity_rationale": "The comment suggests a change in terminology but doesn't specify which 'Evaluation' element is being criticized. It doesn't identify a specific part of the paper or analysis where the terminology is considered general or problematic. Therefore, it is 1 in a specific section or aspect of the paper. While the suggestion is about terminology, it doesn't pinpoint what is wrong with it.", "verifiability_rationale": "The comment claims that 'Evaluation' is a general term and 'Metrics' is more specific. While this claim is generally true, the review point doesn't provide any specific examples or evidence to support why the change would be beneficial for the authors. It lacks concrete reasoning or justification.", "helpfulness_rationale": "The comment offers a suggestion for improvement in terminology. While the suggestion is relevant to the authors' work, it doesn't provide specific guidance on how the authors should implement the change or what advantages the new terminology offers. It's a suggestion without concrete action steps."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete change to be made. It is a suggestion for future exploration of a dataset, which is a general idea and not a direct instruction on how to improve the current draft.", "grounding_specificity_rationale": "The review point does not specify which part of the paper the DRRI dataset should be explored. It is a general suggestion and does not identify a specific section, table, or figure.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for future research, not a critique or assertion about the current work.", "helpfulness_rationale": "The review point suggests exploring a new dataset, which is relevant to the broader field but does not directly identify weaknesses in the current paper or provide concrete suggestions for improvement. It is a suggestion for future work rather than immediate feedback for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests using more objective terms than 'remarkable' and questions the use of this term in the context of the observed improvement in accuracy. While the reviewer doesn't explicitly point to a missing element, they are implicitly suggesting a change in the *wording* of the result, which can be interpreted as an *implicit* action. However, the reviewer does specify *where* this suggestion should be applied: 'with same size of networks' and 'looking at the axes.' This specificity makes the action relatively concrete, as the reviewer isn't asking for a *general* improvement, but a specific one related to a particular observation. The reviewer is also pointing to a *concrete* action, as once the action is identified (using more objective terms), the authors know exactly what needs to be done and how to apply the action, although the authors might still need to infer the *specific* objective term to use.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper being addressed. The reviewer is criticizing the use of the word 'remarkable' in the context of the observed improvement. The comment is a general critique of the presentation and clarity of the results, rather than a specific instruction to focus on a particular section, table, figure, or unique aspect of the paper. Therefore, the grounding is 'Weakly Grounded' as the authors cannot confidently determine which part the comment addresses. The comment also does not specify what needs to be addressed in this part, as it is a general critique. Therefore, the specificity is 'Not Specific' as there is no clear indication of what aspect of the paper is being referred to or what needs to be improved in that aspect.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a suggestion for improvement, not a critique that needs to be supported by evidence or reasoning. Therefore, it does not fit into the 'Verifiability' category. The comment is a suggestion to use more objective terms, which is a constructive feedback, but it doesn't involve making a claim that needs to be verified.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement by criticizing the use of the word 'remarkable' and suggesting the use of more objective terms. This directly addresses a presentation issue and aims to improve the reader's understanding of the results. The feedback is constructive and provides a specific direction for the authors to follow. Therefore, the feedback is '5' as it directly addresses a clear weakness and offers a specific, actionable improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review points out a limitation in the field of pruning on GPUs but does not specify how the authors should modify their work to address this limitation. It identifies a problem but lacks concrete steps for the authors to take.", "grounding_specificity_rationale": "The review makes a general statement about the limitations of GPU pruning in the field, without specifying which part of the authors' work this applies to. It lacks grounding to a specific aspect of the paper or research.", "verifiability_rationale": "The review states a limitation in the field but does not present a claim that requires verification or justification. It is a statement about the current state of the field, not a claim about the authors' work that needs supporting evidence.", "helpfulness_rationale": "The review highlights a limitation in the field but does not provide specific, actionable feedback or suggestions for the authors to improve their draft. It is a general observation about the field, not a targeted improvement suggestion for the authors' work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitations of the numerical evaluation and the use of synthetic data. For example, they say, 'The numerical evaluation is not fully convincing' and 'The method is only evaluated on synthetic data.' These statements directly indicate that the reviewer has identified actionable information that is lacking or could be improved.", "grounding_specificity_rationale": "The reviewer mentions 'numerical evaluation' and 'synthetic data' as limitations. While they point to a general area of the problem, they don't explicitly identify a specific section, table, figure, or unique aspect of the paper related to the numerical evaluation. Therefore, the grounding is weak. However, the reviewer does specify the *type* of data used (synthetic), which adds some level of specificity. The reviewer also mentions a comparison with prior work and its limitations regarding camera pose parameters, which could be considered specific to a certain implementation or evaluation context.", "verifiability_rationale": "The reviewer makes a claim that the evaluation is 'not fully convincing' and provides reasons for this assessment, such as the use of 'synthetic data' and the 'lack of knowledge of the camera pose parameters' in the comparison with prior work. These reasons are logical and point to potential limitations, making the claim verifiable.", "helpfulness_rationale": "The reviewer finds the information provided ('the numerical evaluation is not fully convincing') to be lacking in strong, actionable feedback. While they identify a problem, the critique is somewhat general and doesn't offer specific, detailed suggestions for improvement. The lack of concrete examples or detailed explanations makes the feedback less helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a question and suggests an experiment. This is an explicit action. The concreteness is good \u2013 it's not a vague request for more data. The reviewer is clearly pointing out a potential weakness or area for improvement.", "grounding_specificity_rationale": "The reviewer refers to \"numbers of bits in logits\" and \"PGD attack,\" which are specific technical terms within the field. While not a direct section reference, the combination of these terms strongly implies a specific part of the paper. I'd say it's **partially grounded**. The reviewer could be more explicit about which figure or table relates to \"numbers of bits in logits,\" but the combination strongly suggests a specific section. The comment specifies what needs to be addressed (the experiment and the suggestion).", "verifiability_rationale": "The reviewer does not explicitly state a claim. They are suggesting an experiment and asking a question. The underlying implicit claim is that the current experiment is insufficient given the intuition about 32bit logit robustness. There is no logical reasoning, common knowledge, or external references provided to support this implicit claim.", "helpfulness_rationale": "The reviewer is suggesting a specific experiment and asking a wellreasoned question based on an intuition about the impact of logit bit precision on robustness. This directly addresses a potential weakness and offers a concrete improvement suggestion. The reviewer is likely trying to help the authors improve their draft by highlighting a potential area for further investigation and providing a clear direction for experimentation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point asks a question about the outcome of applying a method but does not explicitly state what needs to be done or how to achieve it. The action is implied but not clearly defined, making it vague and lacking detail on how to apply it.", "grounding_specificity_rationale": "The review point refers to 'men' and 'women' in the context of insurance payments, which implicitly points to a genderbased analysis. However, it does not explicitly identify the specific section, table, figure, or unique aspect of the paper where this analysis is discussed or needs to be applied. The grounding is implied but not explicit.", "verifiability_rationale": "The review point is a question about the results of a specific analysis but does not contain a claim that needs verification. It is not a statement that requires logical reasoning, common knowledge, or external references to be supported.", "helpfulness_rationale": "The review point asks a question about a specific aspect of the paper's content but does not provide any actionable feedback or suggestions on how to improve the draft. It is a request for information rather than a constructive critique that guides the authors towards specific changes."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential ambiguity in the description of 'meta solvers' and suggests clarifying their relationship to 'centralized RL'. This is a direct identification of a potential point of confusion and a suggestion for improvement, making it actionable in terms of prompting clarification.", "grounding_specificity_rationale": "The reviewer refers to 'meta solvers' generally and suggests a clarification related to 'centralized RL'. While they identify a potential area for clarification, they don't explicitly point to a specific section, table, figure, or unique element of the paper as being problematic. The grounding is implied rather than explicit.", "verifiability_rationale": "The reviewer suggests clarifying the difference between 'meta solvers' and 'centralized RL'. This can be considered a claim that requires justification. The suggestion itself could be considered verifiable by pointing out the shared aspect of weight sharing in centralized RL.", "helpfulness_rationale": "The reviewer's suggestion to clarify the relationship between 'meta solvers' and 'centralized RL' is generally helpful for the authors. It addresses a potential point of confusion and encourages a deeper understanding of the related work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states their understanding of M_T's domain, which is an *implicit* statement. They do not explicitly define M_T or provide concrete steps on how to apply it. The explanation is vague and lacks detail on how to use the concept.", "grounding_specificity_rationale": "The reviewer addresses a *specific* concept (M_T's definition) by mentioning page 3. However, they do not pinpoint the exact section or table containing the definition. The explanation of *how* M_T operates is also vague and lacks specific examples.", "verifiability_rationale": "The reviewer questions the clarity and completeness of the explanation regarding M_T. They do not provide sufficient justification or examples to support their understanding of its domain. The claim about M_T being over atomic events is not wellverified.", "helpfulness_rationale": "The reviewer explicitly states that the comment is unhelpful and suggests it is only slightly beneficial. The lack of clarity and examples makes it difficult for the authors to improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment does not explicitly state what needs to be done or how to do it. It uses vague language like 'modest' and 'further refinement' which are not actionable.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper being addressed. It is a general statement about 'the observed performance enhancements' without pinpointing a section, table, figure, or unique aspect.", "verifiability_rationale": "The comment does not make a claim. It is a statement of observation ('somewhat modest') and a suggestion ('further refinement').", "helpfulness_rationale": "The comment identifies a valid observation about the results and suggests a relevant direction for future research. While it doesn't provide specific actions, it is not detrimental or unhelpful."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the missing references and the undefined acronym 'MLP'. While they don't directly identify an action, the lack of these elements implies the action of providing these references and defining 'MLP'. The reviewer's point is clear and directly points to missing information that should be present in an academic paper. The reviewer's intention is to prompt the authors to include these details.", "grounding_specificity_rationale": "The reviewer explicitly points to the lines 230234 where the missing information is most relevant. They state 'please provide references for the following two passages' and then specify the lines. They also explicitly state 'Figure 2: What is \"MLP\"?'. This demonstrates a clear understanding of where the information should be located and what specific information is needed. The reviewer's actions are directly aimed at improving the clarity and completeness of the paper.", "verifiability_rationale": "The reviewer does not make a claim in the traditional sense of criticizing or judging the paper. Instead, they point out missing information that should be present for academic rigor. While the absence of references and the undefined acronym can be considered verifiable in the sense that it's verifiably missing, the reviewer's point is more about the lack of *justification* or *explanation* rather than a claim that needs verification. Therefore, it leans towards being underspecific without a clear claim to verify.", "helpfulness_rationale": "The reviewer's point about missing references is extremely helpful for the authors. It directly addresses a fundamental aspect of academic writing. The point about 'MLP' is also helpful, although less critical, as it's a specific detail in a figure. The reviewer's feedback is direct and constructive, prompting the authors to include necessary information. While there's no explicit claim, the feedback is 5 and addresses specific gaps in the paper's presentation."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the * issue with the experimental results ('the performance is similar to IRM') but does not provide specific details on *how* this is a problem or *how* the datasets or experimental setup are flawed. While they identify a weakness, the action is not fully explicit or concrete.", "grounding_specificity_rationale": "The reviewer mentions 'the experimental results on the last two datasets' and 'the performance is similar to IRM'. This provides some grounding by narrowing down the area of concern. However, they do not explicitly identify a specific part of the paper, model, or dataset (e.g., a specific table or figure). The grounding is present but not fully explicit.", "verifiability_rationale": "The reviewer makes a claim ('the experimental results on the last two datasets are not convincing enough') but does not provide any evidence, reasoning, or external references to support this claim. The statement is presented as a question or observation without any justification.", "helpfulness_rationale": "The reviewer raises a valid concern about the experimental results and points to a potential issue ('the performance is similar to IRM'). However, they do not offer any concrete suggestions or improvements based on this observation. The feedback is presented as a question or observation without actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "X", "actionability_rationale": "The reviewer is asking for an explanation of *why* both entities are needed in Figure 2's example, rather than directly stating what needs to be done. While the action of understanding the example is implicit, the reasoning behind it is not explicitly stated, making it somewhat vague. The reviewer could be interpreted as inferring the need for both entities from the context of Figure 2, but the explicit action of explaining *why* is missing.", "grounding_specificity_rationale": "The reviewer is directly referencing Figure 2 when asking the question. This provides a clear and specific context for the discussion. The question is about the *purpose* of detecting both entities *within* that specific example, making the grounding quite precise.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question seeking clarification on the *purpose* of detecting both entities in Figure 2. There is no assertion of truth or falsity, so verifiability is not the primary concern here.", "helpfulness_rationale": "The reviewer is asking a question for clarification, not providing feedback on the paper's content or suggesting improvements. While the question is relevant to understanding Figure 2, it does not directly contribute to enhancing the authors' work, making it not 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the desire for empirical validation, which is an action. However, the specific action of 'seeing experiments' is vague as it doesn't specify which experiments or the 'bounds' being referred to. The lack of specificity makes it less actionable than a comment that says, for example, 'The experimental setup in Section 3.2 needs improvement'.", "grounding_specificity_rationale": "The comment refers to 'empirical validation' generally, without specifying which part of the paper this relates to. It doesn't mention a specific section, table, figure, or unique element. Therefore, the grounding is weak. The specificity is also low as it doesn't detail what is lacking in the empirical validation.", "verifiability_rationale": "The comment does not contain a claim about the paper itself. It is a suggestion for improvement rather than a statement that requires verification. Therefore, it does not fit the criteria for verifiability.", "helpfulness_rationale": "The comment identifies a valid area for improvement \u2013 the lack of empirical validation \u2013 which is a common concern for researchers. However, the suggestion is vague and lacks specific details, making it less helpful than a comment that says, for example, 'The experiments in Section 4.1 should be repeated with a different random seed to ensure reproducibility'. The vagueness makes it difficult for the author to immediately understand how to address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The reviewer is directly asking for a definition of 'chunks' in a specific context. This is an explicit action that the authors should take to clarify their terminology. While the action is clear, the lack of detail on *how* to implement this action (i.e., what specific definition to provide) makes it somewhat vague.", "grounding_specificity_rationale": "The authors need to identify the specific part of their paper they are referring to when using the term 'chunks.' They need to explicitly define what they mean by 'chunks' in their work. While the grounding is present as they are referring to their own work, the specificity is limited to the term 'chunks' without further context or examples.", "verifiability_rationale": "The reviewer is asking a question about the meaning of a term, not making a claim that needs verification. This is a request for information, not a statement that requires justification.", "helpfulness_rationale": "The reviewer is directly asking for clarification on a potentially confusing term. This is a valuable piece of feedback that can directly improve the clarity and understanding of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential discrepancy between the description in equation 9 and the visual representation in Figure 1. They question whether the output patches described in equation 9 are simply masked versions of the input image with mostly black pixels, as suggested by Figure 1. This raises a valid point about the clarity of the method's implementation. While the reviewer doesn't explicitly state how to fix it, they identify a potential ambiguity in the description, which is actionable for the authors to investigate further.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'eq. 9' and 'Figure 1' in their review point. This clearly grounds the comment to the specific parts of the paper being discussed. They also imply a connection between the equation and the figure, suggesting they understand the context. The comment is precise about the potential issue related to these specific elements.", "verifiability_rationale": "The reviewer states a potential discrepancy between equation 9 and Figure 1 but does not provide any evidence or explanation to support this claim. They suggest that the output patches might be masked versions with mostly black pixels, but this is a hypothesis based on their interpretation, not a verifiable statement supported by logical reasoning, common knowledge, or external references. The reviewer's statement is a possibility, not a confirmed fact.", "helpfulness_rationale": "The reviewer raises a potential issue regarding the implementation of equation 9 and the interpretation of Figure 1. While this points to a potential area for improvement in the method's description or visualization, it doesn't offer a concrete, actionable suggestion for the authors to implement a fix or improvement. The reviewer's comment is more of a question or observation about potential inconsistencies rather than a direct recommendation for change."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4: 5", "actionability_rationale": "The review point directly asks a question about a specific scenario (a node with 0 neighbors) related to Theorem 1. This implies an action: to explain how this exception can be reconciled with the theorem's upper bound. While the reviewer doesn't explicitly state an action, the nature of the question strongly suggests an expectation of clarification and a call to action on the part of the authors. The action is implicit but clear.", "grounding_specificity_rationale": "The review point explicitly mentions 'Theorem 1' and the concept of 'neighbors' in the context of the upper bound. It directly points to a specific part of the paper where the issue lies. The reviewer is also asking for an explanation, which implies a need to understand the relationship between nodes and neighbors. This level of specificity suggests a strong grounding in the paper's content.", "verifiability_rationale": "The review point raises a question about the validity of a specific scenario (a node with 0 neighbors) in the context of the theorem's upper bound. This implies a need for justification or verification of the theorem's claim. The reviewer is asking for an explanation of *how to explain this exception*, which directly addresses the verifiability of the claim. The claim is that the upper bound holds even for a node with 0 neighbors, and the reviewer is seeking evidence or reasoning to support this. The request for an explanation indicates a lack of immediate sufficient justification.", "helpfulness_rationale": "The review point directly addresses a potential inconsistency or error in the paper's logic regarding the upper bound of Theorem 1. The reviewer is asking for an explanation of *how to explain this exception*, which is a clear and actionable suggestion for improving the paper. This question directly targets a potential weakness in the paper's presentation and offers a concrete direction for clarification. It is 5 as it guides the authors to reexamine their theorem and potentially correct it or clarify its scope."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the similarity to the two mentioned papers and the specific elements (idea, coattention mechanism, and architecture). This is an explicit statement of an action the authors could take  investigate the similarity. However, the reviewer doesn't specify *how* this similarity limits novelty or what specific changes are needed, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'two mentioned papers' and specifies elements like 'idea, coattention mechanism, and architecture' as being similar. This demonstrates some grounding as the reviewer can identify the specific aspects being compared. However, the reviewer doesn't pinpoint a *specific* section or table within the paper that is affected, making the grounding somewhat underspecific.", "verifiability_rationale": "The reviewer makes a claim: 'Limited technical novelty.' This is a verifiable statement. However, the reviewer's assessment of the similarity as 'quite similar' is subjective and lacks concrete evidence or references to support this claim. There's no logical reasoning or external references provided to back up the degree of similarity.", "helpfulness_rationale": "The reviewer's comment primarily criticizes the paper's novelty and suggests a comparison to other works. While this points to a potential area for improvement, the reviewer doesn't offer specific, actionable steps or evidence to support their claim. The comment is more of a statement of opinion than a constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the observation about the Discussion section and provides a clear action: 'This seems not to have been revisited in the Discussion (which is fine, just delete \u201cDiscussion\u201d).' This clearly indicates an action to be taken.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Pg. 5' and then provides a specific reason why the Discussion wasn't revisited ('This seems not to have been revisited in the Discussion...'). This demonstrates a clear grounding in the specific part of the paper and an explanation for the observed issue.", "verifiability_rationale": "The reviewer makes a claim ('This seems not to have been revisited in the Discussion...') and provides direct evidence for this claim by referencing the statement on 'Pg. 5: \u201cThe training time reduction is less drastic than the parameter reduction because most gradients are still computed for early downsampling layers (Discussion).\u201d'. This provides clear justification for the claim.", "helpfulness_rationale": "The reviewer's comment identifies a potential oversight in the Discussion section and offers a clear suggestion for improvement ('This seems not to have been revisited in the Discussion (which is fine, just delete \u201cDiscussion\u201d).'). This is a direct and actionable feedback that is likely to be helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer poses a question about the problem's applicability to other downstream tasks. While the question is clear and identifies a potential area for discussion, it doesn't explicitly state an action or provide a concrete next step for the authors. The reviewer asks 'why' this problem is specific to binding affinity prediction, which is a question rather than a directive. Therefore, while the question is relevant, it lacks the explicit and concrete action expected for high actionability.", "grounding_specificity_rationale": "The reviewer's question about the problem's applicability to 'other downstream tasks' is not explicitly grounded in a specific part of the paper. While they mention 'other downstream tasks,' they don't point to a particular section, table, figure, or unique element that this question is directly related to. The grounding is weak because it's a general question about broader applicability. The specificity is also low as the question is about the generalizability of the problem, not a specific issue within binding affinity prediction.", "verifiability_rationale": "The review point itself does not contain a claim or assertion that requires verification. It is a question posed to the authors. Therefore, according to the provided definitions, the verifiability score would be 'X'.", "helpfulness_rationale": "The review point raises a valid question about the scope and limitations of the problem. This can be helpful for the authors to understand the broader context and potential implications of their work. However, it doesn't directly provide the authors with actionable steps or specific guidance on how to address this question. It's a question that prompts further thought but doesn't offer immediate constructive feedback. Therefore, it's 3 in prompting further consideration but lacks the direct actionability of a more specific suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of deeper analysis or solutions and raises a specific question about why GPTgenerated rumors are as hard to detect as natural rumors, given that both are humanwritten. While the reviewer identifies a gap in the paper's analysis, they do not provide a concrete action or suggestion for the authors to take. The reviewer's question is quite general and does not pinpoint a specific area within the detection of GPTgenerated rumors that needs improvement. The suggestion is broad and lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer mentions the challenges of detecting rumors generated by GPT, but the comment does not explicitly identify a specific part of the paper being addressed. While the reviewer mentions GPT, they do not specify *which* section, table, figure, or unique aspect of the paper's analysis of GPTgenerated rumors is lacking. The grounding is present (the reviewer is talking about GPTgenerated rumors), but it's not precise enough to pinpoint the exact issue.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are pointing out a gap or a weakness in the existing analysis but do not offer a logical reasoning, common knowledge, or external references to support their claim. The comment is not a statement that needs to be proven or justified.", "helpfulness_rationale": "The reviewer identifies a weakness in the paper's analysis of GPTgenerated rumors and raises a relevant question. While the question is valuable for prompting further research or discussion, the review does not offer a concrete solution or suggestion for the authors on how to address the identified gap. The helpfulness is limited because the reviewer does not provide actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a limitation ('The technical contribution is limited') and provides a specific example ('the contents of Section 4 are not about a formal and principled solution, but most about heuristics'). This makes the action clear and concrete.", "grounding_specificity_rationale": "The comment identifies a general limitation in the technical contribution and specifically mentions Section 4. While it doesn't pinpoint a specific element within Section 4 that is problematic, the mention of 'heuristics' provides some specificity regarding the nature of the content in Section 4.", "verifiability_rationale": "The comment contains a claim ('The technical contribution is limited') and provides supporting information ('the contents of Section 4 are not about a formal and principled solution, but most about heuristics') that could be considered common knowledge or evidence within the relevant field.", "helpfulness_rationale": "The comment identifies a valid concern about the technical contribution and provides an example. However, it does not offer specific, actionable steps or guidance for the authors to take immediately to address this limitation. The feedback is present but lacks concrete, constructive suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action to be taken: 'increase the font size in Figure 6'. This action is both explicit and concrete, providing a clear direction for the authors to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific part of the paper being addressed: 'Figure 6'. They also clearly specify the issue: 'the font size is a little bit small'. This demonstrates strong grounding specificity.", "verifiability_rationale": "While the reviewer makes a statement about the font size, it is more of a suggestion or recommendation rather than a claim that requires verification. There is no logical reasoning, common knowledge, or external reference provided to support this statement as a claim. Therefore, it is not 5.", "helpfulness_rationale": "The reviewer directly points out a visual element (font size in Figure 6) that is likely to affect the readability and clarity of the paper. They also provide a clear and actionable suggestion ('increase the font size'). This directly addresses a potential issue and guides the authors on how to improve their draft, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that exploring *other* probability mass functions (PMFs) would be beneficial, indicating a clear action the authors should take. While they don't specify *how* to explore other PMFs, the suggestion itself is actionable and points to a concrete area for improvement.", "grounding_specificity_rationale": "The reviewer mentions the probability mass function (PMF) and its practical exploitation in MixBoost, grounding the suggestion in a specific aspect of the paper. However, they do not specify *which* PMF is being referred to or *why* the quasiuniform distribution is chosen. They are suggesting exploring *other* PMFs, which is a general suggestion without pinpointing the exact location within the PMF discussion.", "verifiability_rationale": "The reviewer makes a claim that the quasiuniform distribution is 'regrettably' used and suggests exploring alternatives. This claim is 3 because the reviewer is making a logical argument about the limitations of a singleparameter quasiuniform distribution and suggesting a more flexible approach. However, they do not provide specific references or examples to support this claim.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors to improve their draft by exploring different probability mass functions. This suggestion is directly relevant to the experimental setup and offers a concrete direction for future work. The reviewer's point about considering various PMFs would add depth to the experimental setting, making it a valuable contribution to the authors."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "1 (1 and Not Specific)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The comment does not propose an action or improvement based on the observed behavior of ChatGPT. It raises a question about the fairness of comparing models with different abstention rates, which is a critique of the comparison methodology rather than a suggestion for action within the paper.", "grounding_specificity_rationale": "The comment does not specify which aspect of the paper or evaluation process is being questioned. It is a general statement about the comparison of models, not a critique of a specific part of the paper or methodology.", "verifiability_rationale": "The comment itself is an opinion and does not contain a claim that can be verified. While the *claim* being made (that higher abstention is unfair) could be considered verifiable if evidence were provided, the comment itself lacks supporting evidence or justification.", "helpfulness_rationale": "The comment is a question and a critique of the comparison methodology. It does not offer a concrete solution or actionable insight for improving the draft. It points out a potential flaw in the evaluation but doesn't provide a path forward."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'Missing references: the references below are relevant to your topic, especially a. Please discuss connections with a...'. This is an explicit action, as the reviewer is directly identifying a deficiency in the paper (missing references) and providing a concrete suggestion (discuss connections with a specific paper). The action is also concrete, as the reviewer is not just stating that something is missing, but rather specifying exactly what is missing and how it should be addressed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the references below are relevant to your topic, especially a... Please discuss connections with a...'. This clearly identifies a specific part of the paper (the references) and how it relates to the current work. The reviewer can accurately pinpoint the section, table, figure, or unique aspect being addressed (the missing references). The comment specifies what needs to be addressed in this part (a discussion of connections with a specific paper).", "verifiability_rationale": "The reviewer makes a claim that 'the references below are relevant to your topic, especially a. Please discuss connections with a, which uses supervised learning in QBF solving, where QBF generalizes SMT.' This is a claim that requires verification. The reviewer provides a justification by stating the relevance of the paper a (Samulowitz & Memisevic, 2008) to supervised learning in QBF solving, which is a key aspect of the paper. This justification, while brief, provides the basis for verifying the claim. The claim is supported by the paper's focus on supervised learning in the context of QBF generalizing SMT.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion to improve the paper by discussing connections with a specific relevant paper (a Samulowitz & Memisevic, 2008). This directly addresses a potential weakness in the literature review (missing relevant references) and provides a concrete direction for improvement. The reviewer's request is specific and directly targets a potential area for enhancement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that a 'monotonic relationship is imposed' between the degree of predictor participation and the weight of the corresponding task loss. They also suggest exploring 'other relationships' as an alternative. This provides a clear action for the authors: they can investigate different functional forms for this relationship to potentially achieve a better tradeoff. The suggestion is concrete, stating that exploring alternatives is a valid direction for improvement.", "grounding_specificity_rationale": "The reviewer refers to a specific aspect of the method, namely the 'degree of a singletask predictor participation' and the 'weight of the corresponding task loss'. This clearly identifies a specific part of the paper being addressed. Furthermore, the reviewer explains *why* this specific aspect is important (it 'imposes a monotonic relationship' and 'limits flexibility'). This provides a clear grounding and a specific reason for considering alternatives. The grounding is explicit, and the explanation is directly related to the identified part.", "verifiability_rationale": "The reviewer does not make a claim about the paper itself. They are suggesting an *exploration* or *alternative* to the current method. Therefore, there is X to be verified. The reviewer's suggestion is a suggestion, not a claim that needs evidence.", "helpfulness_rationale": "The reviewer provides a clear rationale for their suggestion: that the 'imposed monotonic relationship limits flexibility'. They also provide a relevant citation 1 to support their point. This suggests a valuable direction for improvement that can be investigated. While it's an suggestion and not a criticism, it offers a concrete next step for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the focus on 'computation cost' and 'running time', which are concrete aspects of the paper. While it doesn't provide the *method* of comparison, it clearly identifies the area of comparison, making it a concrete suggestion.", "grounding_specificity_rationale": "The reviewer is suggesting a comparison of 'computation cost' and 'running time', which are not explicitly detailed within the paper itself. The paper doesn't have a specific section or table dedicated to this comparison, making the grounding weak. However, the request is somewhat specific in identifying the metrics (computation cost and running time), but lacks a reference to a specific part of the paper where this comparison should occur.", "verifiability_rationale": "The review point itself doesn't contain a clear claim or assertion. It's a suggestion for improvement. While the potential impact of this suggestion (improving the paper's evaluation of efficiency) could be considered a deduction, the review point itself lacks supporting evidence or logical reasoning to be classified as a verifiable claim.", "helpfulness_rationale": "The review point is relevant as it addresses a practical aspect of the paper (efficiency). It encourages a comparison, which is a valuable type of analysis. However, it lacks the specifics of *how* to perform this comparison, making it less actionable and therefore less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their belief that the introduction's goal is unclear and provides specific suggestions for improvement. They mention 'I did not get a clear picture' and 'My guess is that the examples chosen did not convince me that there are problems which require a lot of interprocess communication.' These statements indicate a clear action the authors should take: to clarify the introduction and focus on alternative problem areas. The suggestions, such as 'try to focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms such as Hogwild,' are concrete and directly address the identified weakness.", "grounding_specificity_rationale": "The reviewer's comment is 1 in a specific part of the paper. They are critiquing the overall clarity of the introduction's goal without pointing to a particular section, table, figure, or unique element. While they offer suggestions, these suggestions are general and do not pinpoint where the authors should look for improvements. The reviewer's statement is a general critique rather than a specific request for information about a particular aspect of the paper.", "verifiability_rationale": "The reviewer makes a claim: 'I did not get a clear picture from the goal of the paper in the introduction. My guess is that the examples chosen did not convince me that there are problems which require a lot of interprocess communication.' This is a subjective statement expressing doubt. While the reviewer offers suggestions for alternative problem areas, these suggestions are presented as a way to *justify* their claim, not as a direct verification. The claim is 3 because the reviewer provides examples (the current examples) and alternative areas (Hogwild) as a basis for their opinion. However, the connection between the examples and the claim is not explicitly stated or logically deduced within the review point itself.", "helpfulness_rationale": "The reviewer provides specific suggestions for improving the introduction and focusing on alternative problem areas. They suggest 'try to focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms such as Hogwild.' These suggestions are actionable and directly address the perceived lack of clarity in the introduction's goal. The reviewer's point is 5 because it guides the authors towards a specific direction for improvement and offers concrete examples of alternative problem areas."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly asks a question about privacy preservation, which implies a potential weakness. However, the reviewer does not explicitly state what makes the approach more privacypreserving. The question is posed, but the action is implicit.", "grounding_specificity_rationale": "The reviewer mentions 'other federated learning approaches' and a specific example of 'one traffic signal not to know what is the color of the next one'. This grounds the discussion to specific parts of the paper. However, the reviewer does not explicitly state which other approaches are being compared, and the connection between the general privacy claim and the specific traffic signal example is not fully elaborated.", "verifiability_rationale": "The reviewer poses a question about privacy preservation and critiques the traffic signal application. While this can be considered a claim, the reviewer does not provide any evidence or reasoning to support these claims. There is no logical reasoning, common knowledge, or external references provided to back up the statements.", "helpfulness_rationale": "The reviewer raises concerns about the privacy preservation of the proposed approach and the suitability of the traffic signal control application. However, the reviewer does not provide any justification or evidence to support these concerns. The comments are presented as questions and critiques without any supporting arguments, making them unhelpful for the authors to address."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the unfair comparison between CPEF and PMEF due to PMEF's lack of a pretrained module (lines 529534). The reviewer then clearly suggests a solution by comparing CPEF with another pretrained model, ExpertBert. The action is directly identified: 'To ensure fairness, it is recommended to compare CPEF with another pretrained model, such as ExpertBert'. This action is concrete, stating the specific comparison to be made.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 3' and 'lines 529lin534', which are specific references to the paper. They also mention 'CPEF', 'PMEF', and 'pretrained module' as the key elements being discussed. The reviewer accurately identifies the comparison being made between these specific models and highlights the absence of a pretrained module in PMEF. The grounding is explicit, pointing to the figure and table, and the specific feature being compared.", "verifiability_rationale": "The reviewer makes a claim about the unfairness of the comparison between CPEF and PMEF. This claim is supported by logical reasoning: PMEF's lack of a pretrained module gives it a disadvantage when comparing against CPEF, which utilizes one. The reviewer suggests comparing CPEF with ExpertBert, a wellknown pretrained model, as a valid way to address this unfairness. The reasoning is clear and based on the established role of pretraining in improving model performance, especially with limited data. There are no missing external references as the reasoning is based on common knowledge in the field.", "helpfulness_rationale": "The review point clearly identifies a weakness in the experimental setup \u2013 the lack of a fair comparison due to the absence of a pretrained module in PMEF. The reviewer provides a specific and actionable suggestion to address this weakness by comparing CPEF with ExpertBert. This feedback is directly relevant to the authors and provides a clear direction for improving their experimental design. The reviewer's suggestion is concrete and directly addresses the identified issue, making it 5 for the authors to understand and improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point is a statement of fact: \"The hyperlink for footnote 3 and 4 do not seem to work.\" It does not explicitly state what action the author should take. While it identifies a problem, the specific action to fix it is not provided.", "grounding_specificity_rationale": "The review point explicitly mentions \"footnote 3 and 4.\" These are specific elements within the paper. The reviewer is pinpointing the exact location of the issue.", "verifiability_rationale": "The review point makes a claim: \"The hyperlink for footnote 3 and 4 do not seem to work.\" This is a statement that can be verified by attempting to click the links. While it doesn't provide a specific verification method, the claim is clear and verifiable.", "helpfulness_rationale": "The review point identifies a specific, actionable issue: the hyperlink not working. This directly impacts the user experience if the paper is intended to be shared or accessed via those footnotes. It provides a clear direction for improvement (fixing the links). While it doesn't suggest a major rewrite, it's a concrete, actionable piece of feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states suggestions for improvement, such as 'better formalization of the architecture' and 'clarify the architecture'. These are concrete actions the authors can take to address the identified weakness in the modeling section. The reviewer also points out a potential issue with the figure, which is a direct action the authors can take to correct it. The suggestions are clear and directly address the identified problem.", "grounding_specificity_rationale": "The reviewer explicitly identifies the 'modeling section' as the area needing improvement. This is a clear and specific identification of the part of the paper being addressed. Furthermore, the reviewer provides specific suggestions within this section, such as 'better formalization of the architecture' and 'clarify the architecture', indicating a clear understanding of what needs to be improved within this section. The reviewer also points out a potential error in the figure, which is a specific detail within the section that needs addressing.", "verifiability_rationale": "The reviewer makes a claim about the modeling section being 'not clear enough'. This is a statement of opinion or judgment about the paper's clarity. While the reviewer suggests improvements like 'better formalization of the architecture', this is a potential solution rather than a direct verification of the claim. The reviewer also points out a potential issue with the figure, which could be considered a suggestion for verification if the authors were to investigate it further. However, the reviewer does not provide any concrete evidence or references to support their claim about the lack of clarity.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as 'better formalization of the architecture' and 'clarify the architecture'. These suggestions are directly actionable and directly address the identified weakness in the modeling section. The reviewer also points out a potential error in the figure, which is another actionable suggestion. The suggestions are clear and provide a clear path for the authors to improve their draft. The reviewer's comments are not just observations but also constructive suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer states that the description is 'hard to understand' and suggests starting the section with the clearer explanation from the final paragraph. This indicates an implicit suggestion to improve the clarity of the description. While not explicitly stating 'improve this,' the implication is clear. The reviewer identifies the problem (unclear description) and points to the solution (the final paragraph). Therefore, it can be inferred that the reviewer desires a clearer explanation.", "grounding_specificity_rationale": "The reviewer refers to 'the section' and 'the final paragraph' when describing the unclear description. This clearly identifies the specific part of the paper being addressed. The reviewer is not just guessing which part is unclear but is specifically pointing to where the clearer explanation is located. This indicates strong grounding. Furthermore, the reviewer states the description is 'hard to understand' and the final paragraph 'makes it clear,' which specifies what needs to be understood.", "verifiability_rationale": "The reviewer states that the description is 'hard to understand' and that the final paragraph 'makes it clear.' This is a factual statement about the clarity of the writing, not a claim requiring justification. There is X being made in this review point. The reviewer is simply stating an observation about the current state of the description.", "helpfulness_rationale": "The reviewer explicitly states that the section is 'hard to understand' and suggests starting the section with the clearer explanation from the final paragraph. This clearly identifies a weakness in the current version of the paper. The reviewer also provides a suggestion for improvement, which is to start with the clearer explanation. This actionable feedback is directly aimed at helping the authors understand the content better."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests an alternative training method (attentionbased encdec training) as a potential solution to the current limitation of CTC loss. This is a direct and actionable suggestion for the authors to consider. The authors can directly implement this suggestion by exploring attentionbased encoders and decoders in their training framework.", "grounding_specificity_rationale": "The reviewer explicitly states 'It seems like the model is limited to CTC loss...' This directly identifies the specific issue (CTC loss) that needs to be addressed. The authors can easily pinpoint the relevant part of their model or training process that is currently constrained by this loss function. The mention is precise and identifies a clear area for improvement.", "verifiability_rationale": "The review point suggests exploring attentionbased encdec training but does not provide any specific justification or references to support this suggestion. While it's a valid research direction, the point itself lacks evidence or logical reasoning to back up the claim that this approach is feasible or beneficial. The reviewer offers a potential direction but doesn't explain *why* it would work or how to implement it.", "helpfulness_rationale": "The review point suggests exploring attentionbased encdec training as a potential improvement for the model. This directly points to a concrete area for the authors to investigate and potentially enhance their model's capabilities. While the suggestion is valuable, it doesn't provide a detailed plan or specific steps on how to achieve this, making it a good starting point but not a fully detailed solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the observation about tables being divided into three types and asks a question, making the action implicit. While the reviewer points to a specific location, the action of investigating and potentially changing the division is not explicitly stated or concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3 (line 247252)' and the specific detail about the 'three types' of tables, indicating a clear identification of the part of the paper being addressed. The specificity is also clear as the reviewer is questioning a specific division within that section.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a question and a point of confusion, not a statement of fact or suggestion for improvement.", "helpfulness_rationale": "The review points out a potential issue and asks for clarification, which can be helpful for the authors to understand their table structure. However, it does not offer concrete suggestions or actions for the authors to take based on this observation. The feedback is more about understanding a detail rather than providing a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests considering alternative attack methods, which can be interpreted as an implicit action to improve the evaluation. While not explicitly stating 'You should use X', the suggestion implies a change in approach.", "grounding_specificity_rationale": "The reviewer's comment is general and does not explicitly point to a specific section, table, or figure in the paper. The mention of 'toy setting' and 'classification tasks' is a general observation without specific references.", "verifiability_rationale": "The reviewer makes claims about the 'naivety' of other attack methods and the lack of consideration in the paper. This provides some basis for verification, but the suggestion to 'check the following papers' lacks immediate supporting evidence or justification.", "helpfulness_rationale": "The reviewer's suggestion to use other attack methods is a helpful direction for the authors. It points them towards potentially improving their work. However, it lacks specific guidance on how to implement these methods."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that mitigation methods affect the image generation capabilities of diffusion models. This is an explicit statement, as the action is directly identified. However, the reviewer does not specify how to address this issue or what changes are needed. The action is stated, but the implementation is left vague. Therefore, the action is explicit but not concrete.", "grounding_specificity_rationale": "The reviewer refers to 'image generation capabilities of diffusion models' and explicitly mentions that 'mitigation methods affect the image generation capabilities of diffusion models'. This clearly identifies the specific part of the paper being addressed, indicating full grounding. The reviewer also specifies the nature of the effect as a 'potential negative impact', providing some detail about the issue within the identified area. Therefore, the grounding is both explicit and specific.", "verifiability_rationale": "The reviewer states that 'mitigation methods affect the image generation capabilities of diffusion models'. This is a claim that needs to be supported. However, the reviewer does not provide any evidence, reasoning, or references to back up this claim. The statement is presented as an assertion without justification. Therefore, the claim is made but not verified.", "helpfulness_rationale": "The reviewer points out a potential negative impact of mitigation methods on image generation capabilities. While the issue is identified, the reviewer does not provide any actionable steps or guidance for the authors to take. The feedback is presented as a problem without offering any concrete solutions or directions for improvement. Therefore, the feedback is identified but not helpful in terms of providing actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential methodological flaw (leakage of information) that could affect the validity of comparisons. While the reviewer identifies a problem, the specifics of how this leakage might occur or how to mitigate it are not detailed. The reviewer's statement is a direct identification of a weakness, making it somewhat explicit. However, the lack of specific guidance on how to address this issue makes it less actionable than a 5 comment.", "grounding_specificity_rationale": "The reviewer mentions 'prior knowledge,' 'pretrained visual model,' and 'target dataset' but does not explicitly identify a specific part of the paper where this information might be present or how it might be leaking. The references are general and do not pinpoint the exact location or details within the paper. Therefore, the grounding is weak. While the reviewer specifies what might be leaking (additional information), the lack of a clear reference point makes it underspecific.", "verifiability_rationale": "The reviewer states a concern about potential information leakage from 'pretrained visual model' and 'target dataset' into the model, which constitutes a claim. However, the reviewer does not provide any specific evidence, examples, or references to support this claim. The reasoning is based on the *possibility* of leakage, which is a valid concern but requires further investigation. The claim is presented without sufficient justification or backing, making it 1.", "helpfulness_rationale": "The reviewer raises a valid concern about potential information leakage that could affect the fairness of comparisons. However, the comment lacks concrete suggestions or details on how this leakage might manifest or how to address it. The feedback is diagnostic, identifying a potential issue but not providing specific guidance on how to resolve it. The lack of actionable steps or evidence makes the feedback less directly helpful for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer expresses surprise at the dominance of function words over content words in a Japanese sentence and asks for clarification. While they imply a potential issue, the statement itself is not an explicit instruction or suggestion on how to address it. The action is implied but not directly stated, making it less actionable. The reviewer is pointing towards a general linguistic phenomenon rather than a specific action to be taken on the paper.", "grounding_specificity_rationale": "The reviewer mentions 'function words' and 'content words' generally, without specifying which part of the paper or unique aspect they are referring to. They do not explicitly point to a specific section, table, figure, or unique element of the paper. The grounding is implied but not clearly stated, making it weakly grounded.", "verifiability_rationale": "The reviewer states a 'surprise' and asks for clarification, which can be considered a claim requiring justification. However, the reasoning provided is general and lacks specific examples or references to external works. The claim is present but not wellsupported, making it partially verifiable.", "helpfulness_rationale": "The reviewer's comment is about a general linguistic phenomenon and seeks clarification, not a specific issue within the authors' draft. While the reviewer is expressing a concern, it is not framed as a direct request for improvement or clarification of the authors' work. The feedback is general and lacks actionable insights, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their suggestion: 'I think the minimal kmeans objective over multiple seeds is more reasonable.' This is a clear and direct action. The reviewer also provides reasons for this action: 'It's more reasonable'. This makes the action explicit and concrete.", "grounding_specificity_rationale": "The reviewer directly addresses the calculation of the baseline kmeans objective. They specify 'the minimal kmeans objective over multiple seeds' as the correct approach. This clearly identifies the specific aspect of the paper being addressed, making the grounding fully explicit. The reviewer also explains *why* this is better, adding to the specificity.", "verifiability_rationale": "The reviewer makes a claim: 'I think the minimal kmeans objective over multiple seeds is more reasonable.' This claim is supported by the reasoning 'It's more reasonable'. Furthermore, the reviewer provides references 1 Jin, Chi, et al. 'Local maxima in the likelihood of gaussian mixture models: Structural results and algorithmic consequences.' Advances in neural information processing systems 29 (2016): 41164124. and 2 Fr\u00e4nti, Pasi, and Sami Sieranoja. 'Kmeans properties on six clustering benchmark datasets.' Applied Intelligence 48.12 (2018): 47434759.' These references provide external justification for their claim.", "helpfulness_rationale": "The reviewer's suggestion is directly related to the evaluation of the paper's method (kmeans). By proposing a change to the baseline calculation, they are providing a specific and actionable improvement for the authors to consider. This directly addresses a methodological choice and could influence the interpretation of results. The suggestion is clear, and the references provided support the reasoning behind the suggestion, making it highly verifiable. The impact on the authors is significant as it directly relates to the evaluation metric."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "1", "verifiability_label": "Not Verifiable", "helpfulness_label": "None", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete change to the paper. It raises a conceptual point about the nature of the task.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper it is referring to. It is a general statement about the task.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is an opinion about the nature of the task.", "helpfulness_rationale": "The review point raises a valid point about the conceptual nature of the task but does not provide specific feedback or suggestions on how to improve the paper. It is a statement of opinion rather than a constructive critique."}
{"actionability_label": "4", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about the order of operations and the relationship between temperature and uncertainty calibration, which implies a need for clarification on how to apply these concepts. The reviewer also suggests a concrete action: 'Could the authors clarify this point?' indicating a desire for a specific resolution. The reviewer infers an actionable step: 'Regarding H: Reducing the entropy, makes the predictions more confident. This is against the paper motivation to calibrate the networks since they are already over confident (lines 133136).' This suggests a desire for a specific resolution regarding the effect of H on confidence and its alignment with the paper's goals.", "grounding_specificity_rationale": "The reviewer refers to specific lines (155160, 133136) and the concept of a regularization term H, indicating an attempt to ground the comment in the paper. However, the exact placement of H and its effect on confidence are not explicitly stated within the review itself. The reviewer infers the placement from the description of H's effect on entropy. The reviewer also suggests a concrete action: 'Could the authors clarify this point?' indicating a desire for a specific resolution.", "verifiability_rationale": "The reviewer points out a potential contradiction: 'However in lines 155160 it appears that they are both are required to do uncertainty calibration.' and 'Regarding H: Reducing the entropy, makes the predictions more confident. This is against the paper motivation to calibrate the networks since they are already over confident (lines 133136).' The reviewer's statement about H reducing confidence directly contradicts the stated motivation of calibrating overconfident networks. This contradiction is verifiable based on the reviewer's interpretation of the paper's claims and the described effect of H.", "helpfulness_rationale": "The reviewer clearly identifies a point of confusion and asks a question. This directly points to a potential improvement for the authors. The reviewer also suggests a concrete action: 'Could the authors clarify this point?' indicating a desire for a specific resolution. The reviewer highlights a verifiable inconsistency: 'This is against the paper motivation to calibrate the networks since they are already over confident (lines 133136).' This inconsistency is verifiable based on the reviewer's interpretation of the paper's goals and the described effect of H."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that 'Important reference missing' and names the specific paper 'Lista' with a provided link. This clearly identifies a missing element and provides a clear direction for improvement, making it actionable. The reviewer is essentially pointing out a gap in the literature that the authors should address.", "grounding_specificity_rationale": "The reviewer not only identifies the missing reference but also explicitly names the paper 'Lista' and provides a direct link. This level of specificity ensures that the authors can easily locate the relevant work, making the grounding fully explicit. Furthermore, the reviewer explains the relevance of this missing reference by stating, 'While there are important similarities and differences between the proposed work and Lista, it is important that the paper talks about them and places itself in appropriate context.' This specificity extends to explaining *why* the reference is important, making it fully specific.", "verifiability_rationale": "The reviewer makes a claim by stating 'Important reference missing' and provides context by saying 'While there are important similarities and differences between the proposed work and Lista, it is important that the paper talks about them and places itself in appropriate context.' This claim is supported by logical reasoning and the explanation of the importance of the missing reference. The reviewer does not explicitly provide external references, but the logical argument and the explanation of the relevance make the claim 3.", "helpfulness_rationale": "The reviewer's comment is helpful because it points out a crucial missing piece of information that is directly relevant to the paper's topic. By highlighting the absence of the 'Lista' paper and explaining its importance, the reviewer guides the authors to a specific area of literature that they should engage with. While the comment doesn't directly instruct the authors on how to add the citation, it provides a clear direction for further research and contextualization, which is valuable for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need to understand the objective and constraints of the linear program in Theorem 3. This is an explicit action, as the reviewer directly identifies a missing piece of information. However, the reviewer does not specify *how* to understand these aspects, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'Theorem 3' in their review point, indicating they have identified the specific section of the paper being addressed. This demonstrates strong grounding. Furthermore, the reviewer explicitly asks for the explanation of the 'objective and the constraints in (3)', which are specific elements within that section. This indicates a high level of specificity in identifying the issue.", "verifiability_rationale": "The reviewer states that the linear program in Theorem 3 needs to be explained intuitively. This statement itself can be considered a claim that requires justification (i.e., an explanation of the objective and constraints). This justification can be derived from common knowledge about the purpose of linear programs and their application in optimization problems. While the reviewer doesn't provide a specific reference, the claim is verifiable through general understanding and common practices in the field.", "helpfulness_rationale": "The reviewer explicitly states that the lack of explanation for the linear program in Theorem 3 is a problem that needs to be addressed. This indicates a clear need for improvement and suggests a concrete way to achieve it (providing an intuitive explanation). The reviewer's focus on a very specific part of the theorem makes the feedback highly targeted and actionable."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the name of the missing component ('FLOT cost matrix') and its location within the paper ('Algorithm 1'). This directly identifies the action the authors should take: find the definition of the FLOT cost matrix in Algorithm 1. The action is clearly stated and does not require inference.", "grounding_specificity_rationale": "The comment explicitly mentions 'Algorithm 1', a specific part of the paper, and then refers to a specific element within that algorithm, 'FLOT cost matrix'. This demonstrates strong grounding as the authors can directly identify the section and the specific component being addressed. The comment is literal and specific.", "verifiability_rationale": "The comment contains a claim: 'FLOT cost matrix in Algorithm 1 is not defined.' This is a statement that requires verification. However, the comment does not provide any justification or reasoning for why the cost matrix is undefined, nor does it suggest any potential sources or methods for defining it. It lacks external references or logical explanations. Therefore, while it points to a missing definition, it doesn't provide sufficient evidence to be 5.", "helpfulness_rationale": "The comment identifies a clear omission: the absence of a definition for the FLOT cost matrix in Algorithm 1. This is a specific piece of information that the authors would likely need to understand and implement the algorithm. However, the comment does not suggest any specific type of definition (e.g., mathematical, algorithmic, empirical) or provide any guidance on how to approach defining it. While it points to a problem, it doesn't offer a constructive suggestion for resolution."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a question and asks for a *proof*. This is a direct request for action. The request is also very concrete, specifying the second term in Eq. (30) and asking to prove its convergence to 0. The level of detail is high, leaving no ambiguity about the desired action.", "grounding_specificity_rationale": "The reviewer refers to 'the bound in Theorem 2, Eq. (30)' and 'Grunewalder et al, 2010, Eq. (27)'. While they don't explicitly state the section or table number, they provide specific equation numbers, which allows the authors to identify the relevant part. The reviewer also clearly specifies the *term* in Eq. (30) that needs to be addressed, making the grounding quite specific.", "verifiability_rationale": "The reviewer makes a claim that the second term in Eq. (30) doesn't trivially converge to zero and is difficult to prove. This claim requires justification. The reviewer offers a potential basis for verification by referencing the convergence of a similar term in another work, providing a logical reasoning for their claim. The reference to Grunewalder et al, 2010 and the discussion of Eq. (27) provide external support. The claim about the difficulty of deriving the convergence of the second term in Eq. (30) is a logical deduction based on the observation that the first term converges trivially.", "helpfulness_rationale": "The reviewer's point directly addresses a potential weakness in the theoretical analysis of the paper. Suggesting a proof is a concrete step to improve the work. The reviewer also explicitly states their willingness to increase their score if the authors address the question, indicating a clear connection to their own development. This suggests the review is not just a critique but a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1: X", "helpfulness_label": "3", "actionability_rationale": "The review points out a *possibility* and asks a question about Algorithm 2. While it identifies a potential feature, it doesn't explicitly * tell the authors how to implement it or what changes to make. The criticism about 'avg' not being used and the unclear meaning of j' and i' are suggestions for improvement, not direct actionable steps for the authors. The request to update the response is a request, not an action. Therefore, the review identifies a potential issue but doesn't provide explicit, actionable steps for the authors to address it.", "grounding_specificity_rationale": "The review refers to \"Algorithm 2\" generally. It doesn't specify *which* part of Algorithm 2 is problematic or *what* the issue is within that algorithm. The variables 'j'' and 'i'' are mentioned, but their connection to specific parts of the paper or algorithm isn't made explicit. The suggestion to update Algorithm 2 is a broad idea, not a specific reference to a part of the paper. Therefore, the review refers to a general algorithm without pinpointing the specific issue or the relevant part of the paper.", "verifiability_rationale": "The review states a *possibility* and questions the implementation of Algorithm 2. It doesn't make a claim about what *should* be happening or why the current implementation is problematic. The suggestion to update Algorithm 2 is a suggestion, not a claim requiring evidence. Therefore, the review raises a point but doesn't make a claim that needs verification.", "helpfulness_rationale": "The review raises a valid point about the potential functionality of updating nodes based on connected nodes and highlights a lack of clarity in Algorithm 2. However, it doesn't provide concrete steps for the authors to implement this or explain the issues with Algorithm 2 in detail. The request to update the response is a call for action, not a helpful suggestion. Therefore, the review raises a valid concern but doesn't offer sufficient detail or actionable steps to be 5."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer's comment implicitly suggests an action: seeking clarification on the definition of sparsity and a request for evidence and comparisons. While the action is clear, the lack of explicit instructions on *how* to clarify or *what* evidence is needed makes it less concrete. The reviewer is asking for information, which is an implicit action.", "grounding_specificity_rationale": "The reviewer refers to the 'residual term' and 'sparsity assumption' generally, without specifying a particular section, table, or unique element of the paper. This indicates weak grounding. The reviewer also asks for evidence and comparisons, but doesn't explicitly state what aspect of the sparsity assumption needs to be shown across various noisy cases, making it underspecific.", "verifiability_rationale": "The reviewer makes a claim that the definition of the sparsity of the residual term is unclear and asks for evidence to support the sparsity assumption across various noisy cases and a comparison with existing methods. This is a claim that *could* be supported if the paper provided a definition, evidence, and comparisons. However, the *verifiability* depends on whether the paper *actually* contains this information. The claim itself is verifiable, but the lack of explicit justification or examples makes it 3.", "helpfulness_rationale": "The reviewer's comment is generally helpful as it points out potential areas for improvement in the paper (clarity of sparsity definition, evidence for assumptions, comparison with existing methods). The suggestions are clear and actionable, even if not explicitly stated. However, the helpfulness is conditional on the paper actually lacking this information, which is not guaranteed."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that 'connectivity' is misleading. This is a direct action the reviewer is taking \u2013 pointing out a specific issue with the terminology. The reviewer also specifies what they believe 'connectivity' should refer to ('structural connections between the brain and body'), making the actionable suggestion concrete.", "grounding_specificity_rationale": "The reviewer does not explicitly name a specific section, table, or figure. They are making a general comment about the terminology used. However, they are pointing to a specific concept \u2013 the structural connections between the brain and body. While not perfectly grounded at the element level, they are grounding the issue at a higher level of concept. The comment specifies what needs to be addressed in this general area ('how the brain and body are connected').", "verifiability_rationale": "The reviewer makes a claim: 'connectivity is misleading.' However, they do not provide any evidence or justification to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up their assertion that 'connectivity' is misleading. The reviewer identifies the issue but doesn't explain *why* it's misleading or provide examples to support their claim.", "helpfulness_rationale": "The reviewer identifies a potential ambiguity in the use of the term 'connectivity'. They point out that it might be misleading. While they suggest that 'connectivity' should refer to 'structural connections between the brain and body', they do not provide a concrete alternative term or suggest how this ambiguity could be addressed in the paper. The reviewer identifies a weakness in clarity but doesn't offer a specific, actionable improvement."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies the need for improvements in the paper but does not explicitly state what those improvements should be. While the reviewer mentions 'missing details' in related work, experiments, and writing, they do not specify what those details are or how they should be added. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer mentions specific sections of the paper ('related work', 'experiments', 'writing') which indicates some level of grounding. However, the specifics within each of these sections are not detailed. For example, the reviewer mentions 'missing details' but does not specify what those details are or how they impact the paper. The grounding is present but lacks the precision required for full grounding.", "verifiability_rationale": "The reviewer makes a claim about the paper's state ('not polished and not ready to publish, with missing details...') but does not provide any evidence or justification for this claim. There are no references to external sources, logical reasoning, or specific examples to support the assertion that the paper lacks polish or has missing details. The claim is presented without any backing.", "helpfulness_rationale": "The review point criticizes the paper's polish and points out missing details, which is a valuable piece of feedback. However, it fails to offer any concrete suggestions or guidance on how to improve the paper based on these observations. The reviewer identifies a problem but does not provide any actionable steps for the authors to take. The feedback is present but lacks direction and practical advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of justification for using orthogonal matrices as a 'vital part' and suggests studying the benefit as a potential improvement. While the reviewer identifies a potential issue (lack of justification) and offers a suggestion, the suggestion itself is not a concrete action to be taken, making it somewhat vague. The reviewer also implies the importance of orthogonal matrices but doesn't explicitly state an action to improve the paper's handling of them.", "grounding_specificity_rationale": "The reviewer mentions 'Step 3' and the 'weight matrix of this local window MLP is orthogonal or not' as the specific part of the paper being criticized. This indicates that the reviewer can identify the specific section or element being addressed. However, the reviewer does not clearly specify *what* is wrong with this part or how the lack of justification impacts it. The criticism is more about the perceived importance of justification rather than a direct critique of a specific flaw within that step.", "verifiability_rationale": "The reviewer makes a claim that 'Step 3 is the vital part that only orthogonal matrix weight can perform' and suggests studying the benefit as a way to validate the importance of orthogonal matrices. This claim is not directly supported by external references or logical reasoning within the review point itself. The reviewer provides a potential justification (the benefit of orthogonal matrices) but doesn't provide concrete evidence or examples to back up the claim that *only* orthogonal matrices can perform this step effectively.", "helpfulness_rationale": "The reviewer offers a suggestion to 'study the benefit' of using orthogonal matrices. This is a constructive suggestion aimed at improving the paper. While the suggestion is not a direct solution to a specific problem, it is a clear direction for future work and addresses the perceived lack of justification. The reviewer's comment is directly aimed at improving the paper by addressing a perceived gap."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer is asking a question about the observed trend in Figure 5, which implies an interest in understanding the phenomenon. While they are prompting for an explanation, the *action* of directly addressing a specific part of the author's draft is not explicitly stated. The reviewer is asking 'why' and 'is it due to overfitting', which are questions that could lead to actionable feedback, but the feedback itself is not provided.", "grounding_specificity_rationale": "The reviewer mentions 'Figure 5' but does not specify which part of the figure they are referring to. They are asking about the accuracy drop in general, which is a specific observation, but the grounding of this observation to a particular element in the figure is lacking.", "verifiability_rationale": "The reviewer is posing a question about the results of their experiment. There is no explicit claim being made that requires verification. The reviewer is asking for an interpretation of the results, which is a request for information, not a statement that needs justification.", "helpfulness_rationale": "The reviewer is asking a question about the results of their experiment. While this can be helpful for their own understanding, it does not directly provide feedback on the author's work. The reviewer is not pointing out a specific flaw or improvement needed in the author's draft. The feedback is internal to their own analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem with the models and datasets and provides concrete suggestions for improvement.", "grounding_specificity_rationale": "The reviewer clearly identifies the models and datasets as the areas needing improvement and provides specific examples of what constitutes better models and datasets.", "verifiability_rationale": "The reviewer is suggesting improvements rather than making a claim that needs verification.", "helpfulness_rationale": "The reviewer provides clear suggestions for improvement, indicating a need for more rigorous evaluation. However, the lack of a direct critique or recommendation makes it less than fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a suggestion to evaluate the performance of scratchGAN without pretraining. This is an explicit action that authors can directly address by conducting this ablation study. The action is concrete as it identifies the specific model (scratchGAN) and the action (evaluating performance without pretraining).", "grounding_specificity_rationale": "The review point mentions the name of a specific model, scratchGAN. While it doesn't explicitly state the section, table, or unique aspect where this information would be found, the mention of a specific model is a strong indicator of grounding. However, it doesn't provide a literal mention of a section, table, or figure, which would be full grounding. Therefore, it's weakly grounded as it implies the information is available but doesn't explicitly point to it.", "verifiability_rationale": "The review point poses a question about the expected performance of scratchGAN without pretraining. This constitutes a claim that scratchGAN will perform poorly in this scenario. However, the review point does not provide any specific evidence or references to support this claim. It's a general expectation based on common knowledge in the field, but without supporting evidence, it's not 5.", "helpfulness_rationale": "The review point is 5 as it directly addresses a potential experiment (scratchGAN without pretraining) and asks a specific question about its expected outcome. This provides the authors with a concrete direction for further investigation and highlights a potential area for improvement in their model. While it doesn't provide a definitive answer, it points towards a crucial experiment and guides the authors towards a specific area of improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific technical detail in the code related to calculating the distance between episodes with different lengths. They identify the padding method and the lack of a normalization factor. This is an explicit statement of a potential issue and a suggestion for improvement. The reviewer directly addresses a specific part of the implementation.", "grounding_specificity_rationale": "The reviewer explicitly states where the issue lies in the code (between lines 282 and 283) and describes how the comparison is done (padding the shorter sequence with the last state and not normalizing by trajectory length). This clearly identifies the specific part of the paper or code being addressed, making it fully grounded. The description of the padding and lack of normalization is also specific.", "verifiability_rationale": "The reviewer's point is that padding can lead to misleading similarity scores and that normalizing by trajectory length is a standard practice to address this. While the reviewer doesn't provide a direct link to external literature, the description of the potential flaw and the suggested improvement is reasonably clear and verifiable. The reviewer provides a logical explanation of why the lack of normalization is a problem.", "helpfulness_rationale": "The reviewer's point is valid and directly addresses a potential implementation detail that could affect the results. By highlighting the padding method and the lack of normalization, they are providing valuable information for readers to understand the method thoroughly. This information is actionable and directly addresses a potential ambiguity in the code or description. It helps the authors understand how comparisons are made, which is crucial for interpreting their results."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'In the experiment, the author didn\u2019t consider Vision Transformer' and asks a question about the pruning strategy in 'self attention layers.' These are clear, actionable suggestions for the author. The reviewer directly points out a gap in the author's consideration.", "grounding_specificity_rationale": "The review point mentions 'experiment' and 'author\u2019s consideration' but doesn't explicitly state which section, table, or figure the author missed the Vision Transformer in. While it implies a location, it's not a precise reference. However, it does specify the *type* of model (Vision Transformer) and the *dataset* (implied by 'larger image dataset' and the context of pruning in selfattention layers, which is often explored on datasets like ImageNet). This provides some specificity about the *what*.", "verifiability_rationale": "The review point makes claims such as 'In the experiment, the author didn\u2019t consider Vision Transformer' and 'And it is unsure if such technique is still working for larger image dataset such as ImageNet.' These are statements that can be verified (or not) with evidence. However, the review point *doesn't* provide any specific examples or references to support the claim that the author *didn't* consider Vision Transformers. It's a statement of observation, but without backing.", "helpfulness_rationale": "The review point provides clear and actionable feedback. It highlights specific areas where the author's experiment could be strengthened by considering a relevant stateoftheart model (Vision Transformer) and exploring the impact of pruning techniques on a larger dataset (implied by 'larger image dataset'). The suggestions are relevant to the field and could be valuable for the author's research. While the suggestions are broad, they are still actionable and provide a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the absence of comparison against baselines and explains why this is a problem. It identifies the specific area of missing information: 'comparison against baselines' and further specifies the type: 'architectureagnostic similarity comparison (or often reported as codesearch)'. This clearly indicates an explicit and concrete action: 'include a comparison to existing baselines in the functionality similarity comparison study'. The reviewer also states the impact of this missing information: 'difficult to assess the significance' of the study, which is a concrete consequence of the action.", "grounding_specificity_rationale": "The review point explicitly identifies the 'comparison against baselines' as the missing information. It further specifies the type of baselines as 'architectureagnostic similarity comparison (or often reported as codesearch)'. This precise identification of the missing information demonstrates strong grounding specificity. The reviewer clearly states what is missing in the paper and how it should be addressed.", "verifiability_rationale": "The review point makes a claim that 'the functionality similarity comparison study reports only accuracy across optimization levels of binaries, but no baselines are considered. This is a widelyunderstood binary analysis application and many papers have developed architectureagnostic similarity comparison (or often reported as codesearch, which is a similar task). Many papers in this field have already developed and reported such similarity comparison methods.' This claim is verifiable by understanding the importance of baselines in evaluating novel methods and by knowledge of the existing literature in binary analysis and similarity comparison. While the reviewer doesn't provide specific examples of relevant baselines, the claim itself is verifiable based on general knowledge of research evaluation in this field.", "helpfulness_rationale": "The review point is 5 because it directly addresses a significant gap in the information provided by the paper. By highlighting the absence of comparison to existing baselines, the reviewer provides the authors with a clear direction for improving their work. This helps the authors understand the limitations of their study and how it relates to existing research in the field of binary analysis and similarity comparison. This feedback is actionable and provides a concrete next step for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a change in the evaluation methodology for SI 6.5, which can be considered an explicit action. However, it lacks specific details on what needs to be done or how to implement this change. The reviewer points out a difference from a previous work 7 but doesn't elaborate on the implications for the authors' current work.", "grounding_specificity_rationale": "The comment explicitly mentions 'SI 6.5' as the location of the change, which can be considered 'fully grounded'. However, it doesn't specify what needs to be addressed in SI 6.5 or how this change affects the evaluation of the authors' work. The grounding is present but lacks specificity regarding the impact on the authors' draft.", "verifiability_rationale": "The comment presents a statement about a change in evaluation methodology. Verifiability requires justification or evidence. The comment doesn't provide any reasoning or references to support why this change is relevant or how it should be applied. The reviewer simply states the change without providing any context or explanation.", "helpfulness_rationale": "The comment identifies a potential area for improvement (the change in evaluation methodology) and provides a location (SI 6.5). However, it lacks the necessary details and reasoning to guide the authors effectively. The reviewer needs to explain *why* this change is being made and *how* it affects their work. Without this information, the comment is not fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues with the figures: 'Fig.1 to Fig.3 are very difficult to parse.' They further elaborate on the specific problems: 'the texts in the figures are too small,' 'the inputs and outputs for each task are not clearly explained,' and 'the captions are not selfcontained, and it is also very hard to link them to certain parts of the main text.' These statements are direct and specific, indicating actions the authors should take. The reviewer provides clear examples of what needs to be improved, making the actionable nature of the comment evident.", "grounding_specificity_rationale": "The reviewer explicitly mentions the figures (Fig. 1 to Fig. 3) as the specific part of the paper being addressed. They then detail the issues within these figures: 'the texts in the figures are too small,' 'the inputs and outputs for each task are not clearly explained,' and 'the captions are not selfcontained, and it is also very hard to link them to certain parts of the main text.' This demonstrates a clear understanding of the referenced part and a detailed explanation of the problems within it, fitting the definition of full grounding and specific identification of issues.", "verifiability_rationale": "The reviewer makes a claim about the figures: 'Fig.1 to Fig.3 are very difficult to parse.' They then provide justifications for this claim: 'the texts in the figures are too small,' 'the inputs and outputs for each task are not clearly explained,' and 'the captions are not selfcontained, and it is also very hard to link them to certain parts of the main text.' These justifications are logical and provide examples, making the claim verifiable. While no external references are explicitly provided, the suggestions for improvement are based on common practices in data visualization and reporting, which could be considered implicitly verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable critique of the figures. They identify specific problems (difficult parsing, small text, unclear explanations, poorly linked captions) and offer concrete suggestions for improvement (increase text size, provide clearer explanations, ensure captions are selfcontained and link to the main text). These suggestions are directly aimed at addressing the identified issues and are easy for the authors to understand and implement, making the review point 5."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a statement that criticizes the authors' claim about efficiency without providing any specific action or instruction on how to address this. It does not identify what needs to be done or how to implement it. The reviewer states the authors' claim is unsubstantiated but does not offer a concrete step for the authors to take to demonstrate efficiency.", "grounding_specificity_rationale": "The review point mentions 'efficiency' as an advantage of the proposed method but does not specify which part of the paper or experiment this refers to. It does not clearly identify the specific aspect of efficiency that is lacking evidence for. While it implies a deficiency, it doesn't pinpoint the exact location or nature of the missing information.", "verifiability_rationale": "The review point makes a claim that the authors' claim about efficiency is unsubstantiated. However, it does not provide any evidence, references, or logical reasoning to support this claim. There are no external references or specific examples given to back up the criticism. The claim is presented without any justification.", "helpfulness_rationale": "The review point criticizes the authors' claim about efficiency and points out the lack of evidence. However, it does not offer any suggestions or guidance on how the authors could demonstrate efficiency or address the identified weakness. The feedback is a statement of a problem without a constructive solution for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X (X)", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the contribution is 'not enough' and suggests 'improving the contribution.' While this points towards a potential area for improvement, it lacks specific details on what needs to be changed. The reviewer doesn't explicitly state an action the authors should take or how they should implement it. The suggestion is general and doesn't provide a clear path forward for the authors. Therefore, it is 2 as it doesn't clearly identify an action or provide sufficient detail on how to act.", "grounding_specificity_rationale": "The reviewer mentions 'overfitting problem of training GANs with limited data' and 'differentiable augmentation.' While they touch upon specific aspects of the paper, they do not explicitly identify a specific section, table, figure, or unique element within the paper that needs improvement. The mention is general and doesn't point to a concrete location for the authors to focus their attention. Therefore, it is weakly grounded and underspecific as it doesn't clearly identify the referenced part of the paper.", "verifiability_rationale": "The review point is a statement of opinion: 'the contribution is not enough' and a suggestion: 'improve the contribution.' There is X that requires verification or justification. The reviewer doesn't present any specific evidence or reasoning to support their opinion about the contribution being 'not enough.' Therefore, it is X (X) as there is X that needs to be verified.", "helpfulness_rationale": "The review point criticizes the contribution of the paper but does not offer specific suggestions or identify concrete weaknesses that the authors need to address. The reviewer suggests 'improving the contribution' but doesn't specify what aspects of the contribution need improvement or how they should go about it. The feedback is general and lacks actionable insights for the authors. Therefore, it is 2 as it doesn't provide concrete guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer states a need for more details, which implies an implicit action, but the specifics of what is needed are not explicitly stated. The reviewer wants the information, making the action implicit rather than explicit.", "grounding_specificity_rationale": "The reviewer points out a potential issue (unclear statespace) but does not specify *which* part of the paper this refers to. The reference is general, indicating weak grounding as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The reviewer is not making a claim that something is correct or incorrect. They are simply asking for clarification on a potential issue. There is X being made, thus no verifiability.", "helpfulness_rationale": "The reviewer's request for more details about the statespace directly aims to improve the authors' understanding and the clarity of their work. This feedback is directly actionable and beneficial to the authors."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point identifies a weakness in the method's performance on general reasoning tasks compared to mathematical reasoning. While it highlights a difference, it does not specify how the authors should address this discrepancy. The weakness is explicitly stated, but the lack of a concrete action leaves the authors without a clear direction for improvement.", "grounding_specificity_rationale": "The review point mentions 'general reasoning tasks' and 'mathematic reasoning' but does not specify which part of the paper or methodology is being referred to. The weakness is the lack of specificity, making it difficult for the authors to pinpoint the exact area needing improvement.", "verifiability_rationale": "The review point makes a claim about the method's ineffectiveness on general reasoning tasks compared to mathematical reasoning. However, it does not provide any evidence, examples, or references to support this claim, making it 1.", "helpfulness_rationale": "The review point identifies a limitation but does not offer any suggestions or insights on how the authors can improve their method based on this observation. The weakness is identified, but the lack of actionable advice makes it unhelpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the proof relies on a special case where a contradiction arises as matrix norms approach infinity. This directly identifies a potential flaw in the proof technique. The reviewer also connects this to the inapplicability of Theorem 1 due to normalization, which is a concrete action the authors should consider. The reviewer's statement is clear and directly points to a specific aspect of the proof that needs attention.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Appendix A' and 'Section 3' when referring to the proof and the issue with Theorem 1. This indicates that the reviewer can accurately pinpoint the specific part of the paper being addressed, fulfilling the criteria for 'full grounding'. Furthermore, the reviewer clearly specifies the type of contradiction and the consequence of normalization, making the grounding very specific.", "verifiability_rationale": "The reviewer makes a claim about the proof technique, stating 'After reviewing Appendix A, I noticed that the proof relies on a special case where a contradiction arises as matrix norms approach infinity.' This is a claim that requires verification. The reviewer then provides a justification for this claim by stating 'This is acknowledged by the authors in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable.' This provides a clear reference point and explains the connection between the issue and the normalization, making the claim 5.", "helpfulness_rationale": "The reviewer's comment directly points out a potential issue with the proof technique in Appendix A. By highlighting a specific scenario and linking it to a previously mentioned problem (normalization and Theorem 1), the reviewer provides the authors with a concrete point of reference to examine their proof. The reviewer's statement is clear and directly addresses a potential weakness in the methodology, making it 5 for the authors to understand and potentially address."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests comparing models in a new setting (conditional generation task) and cites a related work as a potential baseline. While it implies an action (conducting the comparison), it doesn't explicitly state the steps or the expected outcome. The action is implicit and requires the authors to infer the next steps.", "grounding_specificity_rationale": "The review point explicitly refers to 'Table 2' and 'Table 3' and mentions 'conditional generation task'. It also specifies the models being compared ('continuous diffusion model' and 'discrete diffusion model') and mentions 'GDSS' and 'DiGress'. Furthermore, it refers to 'classifier guidance based on GDSS', which is a specific technique. This indicates a high level of grounding and specificity.", "verifiability_rationale": "The review point makes a claim that 'GDSS should be compared as a baseline in Table 3' and provides justification by referencing its superior performance in Table 2 and citing a recent work on conditional molecule generation using GDSS. This claim is supported by logical reasoning and external references, making it 5.", "helpfulness_rationale": "The review point identifies a specific gap in the evaluation (lack of a conditional baseline in Table 3) and provides a concrete suggestion (using the conditional framework from recent work). This is a 5 comment as it directly addresses a potential limitation and provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a weakness in the choice of object detection as a downstream task for a LiDARbased model, suggesting that LiDAR segmentation might be more appropriate, especially given the use of IoUbased metrics like those in KITTI and Waymo. This points to a potential improvement area. However, the reviewer does not explicitly state how the pretraining should be changed or what specific steps the authors should take to address this issue. The weakness is implied but not concretely actionable.", "grounding_specificity_rationale": "The reviewer mentions 'LiDARbased segmentation' as a potentially better choice and specifically names 'KITTI and Waymo' metrics, which are relevant for object detection tasks. This clearly identifies the specific part of the paper being addressed and provides specific examples of issues. The reviewer also suggests 'accurate locations and poses' as a solution, further grounding the feedback in a concrete aspect of the task.", "verifiability_rationale": "The reviewer makes a claim about the limitations of colorizationbased pretraining for object detection, particularly in the context of IoUbased metrics. This claim is supported by the understanding that colorization primarily learns semantic information rather than precise spatial information needed for accurate object detection and evaluation using IoU. The reviewer provides a logical argument based on the nature of these pretraining techniques and the evaluation metrics used.", "helpfulness_rationale": "The reviewer provides a clear criticism of the choice of object detection as a downstream task and suggests an alternative (LiDAR segmentation). They also explain *why* this alternative might be beneficial, linking it to the limitations of colorization pretraining for IoUbased metrics. This critique is directly relevant to the authors and offers a concrete suggestion for improvement, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states a potential contradiction between the objective of Eq (12) and the IPO principle. This constitutes an explicit action or suggestion, indicating a degree of actionability. However, the specifics of the contradiction are not elaborated upon, making it somewhat vague and less actionable.", "grounding_specificity_rationale": "The comment explicitly refers to 'Eq (12)', which is a specific element of the paper. This indicates that the authors can identify the specific part being addressed, fulfilling the 'grounding' criteria. However, the comment does not specify *what* is wrong with Eq (12) or how it contradicts IPO, making it less specific.", "verifiability_rationale": "The comment contains a claim: 'the objective of Eq (12) seems to be in contradiction with IPO'. However, it does not provide any evidence, reasoning, or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion of a contradiction. Therefore, the verifiability of this claim is low.", "helpfulness_rationale": "The comment raises a concern about a potential issue related to a core principle (IPO) and a key component of the method (Eq (12)). This could be helpful for the authors as it highlights a potential flaw or area for improvement. However, the comment lacks specific details about the contradiction and does not offer any concrete suggestions or guidance. Therefore, while potentially helpful, the lack of concrete information makes it only '2'."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a concrete action: replacing the variable 't' with the size of T in the histogram intersection kernel. This action is directly tied to improving clarity and understanding of the mathematical notation used.", "grounding_specificity_rationale": "The review point explicitly identifies the 'histogram intersection kernel' and the variable 't' within that context. The reviewer directly points out a specific area within the paper where a change is needed. This indicates a strong grounding of the comment in the specific part of the paper being discussed.", "verifiability_rationale": "The review point makes a judgment about clarity and provides a concrete suggestion for improvement. While it doesn't explicitly cite external references, the suggestion itself is a logical consequence of the reviewer's understanding of mathematical notation and the importance of clear variable naming. The 'why' is implied (improving readability and understanding).", "helpfulness_rationale": "The review point directly addresses a specific, technical detail (the variable 't' in the histogram intersection kernel) and provides a clear, actionable suggestion for improvement. This is a targeted and helpful comment for authors trying to understand and implement the method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their 'doubt' about the assumption that DINO embeddings are sufficient for adapting to new concepts. This is a clear indication of an explicit action or suggestion. The reviewer also provides specific examples (geometrically vs. semantically distinct concepts), making the concern concrete. The question directly points to a potential area for improvement (further investigation or clarification).", "grounding_specificity_rationale": "The reviewer connects their concern to the 'adaptation capacity of the image encoder' and the 'assumption about DINO representations'. While not a direct mention of a specific section, the context implies a connection to the model architecture and its ability to handle new data. This can be considered weak grounding as the connection is implied rather than explicitly stated. The reviewer also specifies 'new concepts', 'geometric vs. semantic', and 'adaptation capacity', which adds to the specificity.", "verifiability_rationale": "The reviewer states their concern as a question ('I wonder if the adaptation capacity still holds'), indicating a perceived limitation or area needing verification. The reviewer then attempts to provide justification by stating their belief that DINO's rich geometric information makes it less of a concern for geometrically distinct concepts and that semantic correlations are less of an issue. This provides some examples and reasoning, making the claim 3.", "helpfulness_rationale": "The review point is clear and directly addresses a potential limitation of the proposed method. The reviewer's question is a valuable point for discussion and further investigation. It highlights a potential area for improvement in the model's architecture or training. While it doesn't offer a direct solution, it identifies a concrete problem that needs attention."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly names the loss functions (CenterLoss, ASoftmax, AMSoftmax, ArcFace), which makes the action explicit. However, it doesn't provide details on how to apply this action or what specific changes are needed. Therefore, it is 3.", "grounding_specificity_rationale": "The review point explicitly mentions the specific loss functions (CenterLoss, ASoftmax, AMSoftmax, ArcFace) and clearly identifies the issue as a missing comparison against stateoftheart loss functions in face/iris verification. This allows the authors to pinpoint the relevant part of their work and the specific issue. Therefore, it is 5.", "verifiability_rationale": "The review point contains a claim that 'the comparison against the stateoftheart loss functions widely used in face/iris verification should be added'. However, it does not provide any reasoning or evidence to support this claim. It simply states the suggestion without explaining why it's necessary or beneficial. Therefore, it is 1.", "helpfulness_rationale": "The review point identifies a potential area for improvement (missing comparison of loss functions) and suggests an action (adding the comparison). However, it lacks specific details on how to perform this comparison or what benefits it would bring in the context of biometric verification learning. The suggestion is general and lacks actionable steps. Therefore, it is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the issues with specific line numbers and examples (e.g., 'Line 029: \u2018\u2026 as it a lightweight \u2026\u2019', 'Line 188: PLN > NLP', 'Table 3, row 2, column 3: 72,0 > 72.0'). The reviewer also suggests concrete improvements like 'Technical comments: Line 029: \u2018\u2026 as it a lightweight \u2026\u2019 > Line 029: \u2018\u2026 as in a lightweight \u2026\u2019'. This provides a clear action to be taken.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific sections and lines of the paper (e.g., 'Line 029', 'Line 188', 'Table 3, row 2, column 3'). They also point out a specific cell in a table with a clear error ('72,0 > 72.0'). This demonstrates a strong grounding of the specific part of the paper being addressed. The comment specifies what needs to be addressed in this part (e.g., 'out of cookie out of the cookie\u2019 \u2013 some words are repeated twice').", "verifiability_rationale": "The review point does not contain a claim in the sense of stating an opinion or making a judgment. Instead, it points out factual errors and suggests improvements based on their understanding of best practices. While the reviewer's suggestions are based on their own understanding, the 'claim' in this context is the identification of these issues. The evidence provided in the rationale supports the idea that the issues are verifiable based on the reviewer's interpretation of the text and formatting.", "helpfulness_rationale": "The review point provides specific, actionable feedback on several identified issues. The reviewer points out concrete errors (e.g., the repeated words, the numerical error in the table) and suggests clear improvements (e.g., changing 'as it' to 'as in'). The suggestions are directly tied to the identified problems, making them 5 and helpful for the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'Notation is confusing' and 'M and N are used without definition' and proposes a solution ('Suggest  Spell out F.L.T.R in figure 4'). This indicates a clear identification of a problem and a proposed fix, making it actionable.", "grounding_specificity_rationale": "The reviewer mentions 'M and N are used without definition' and 'Figure 1 text is too small to see'. While the reviewer points to specific elements (M, N, Figure 1), they do not explicitly state *which* part of Figure 1 is too small or *how* M and N are used without definition. The suggestion to 'spell out F.L.T.R' is also vague. Therefore, while the reviewer identifies a location, the specificity of the grounding is weak.", "verifiability_rationale": "The reviewer states 'Notation is confusing' and 'M and N are used without definition'. These are claims that need verification. The reviewer also suggests 'It is recommended to have notation and figure crossreferencing (e.g. M and N are not shown in the figure)'. While the *suggestion* is verifiable, the *initial claims* themselves require justification. The lack of explicit reasoning makes the verifiability somewhat lacking.", "helpfulness_rationale": "The reviewer provides specific suggestions for improving the clarity of notation ('Suggest  Spell out F.L.T.R in figure 4') and addressing the readability of Figure 1 ('Figure 1 text is too small to see'). These suggestions are directly related to the identified issue of confusing notation and are likely to be helpful for the authors. The reviewer's use of 'It is recommended...' indicates a constructive intent."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The comment directly points out a potential issue (using 'p' for two different things) and suggests a solution (using a different symbol for the dummy variable in Phase 2). This constitutes an explicit and concrete action that authors can easily implement.", "grounding_specificity_rationale": "The comment identifies a potential issue within the description of Algorithm 1, specifically in Phase 2. While it doesn't pinpoint a specific equation or line number, it clearly refers to the 'dummy variable in Phase 2' within the context of Algorithm 1. This implies a focus on a specific part of the algorithm's description, making it somewhat specific, but lacking the explicit referencing of a concrete element.", "verifiability_rationale": "The comment identifies a potential issue (confusion due to using 'p' for two different things) and suggests a solution (using a different symbol). This is a clear claim that can be verified by understanding the context of Algorithm 1. The reasoning is logical: using the same symbol for different purposes can lead to misinterpretation.", "helpfulness_rationale": "The comment clearly identifies a potential source of confusion in the algorithm description and provides a specific and direct suggestion to improve clarity. Authors are likely to understand and implement this suggestion easily, making the feedback 5 and beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests a mathematical formulation in the appendix and a figure depicting the WiC task. While these suggestions are concrete and actionable, they are presented as future actions rather than immediate recommendations based on the current state of the paper. The reviewer identifies a lack of detail in the highlevel description, which is a suggestion for improvement, but not a direct, actionable step at this moment.", "grounding_specificity_rationale": "The reviewer mentions 'the highlevel description' and 'the figure' as areas lacking detail and alignment. While they point to specific parts of the paper (the description and the figure), they don't explicitly identify the *section*, *table*, *figure*, or *unique aspect* of these parts. The mention is general, indicating a lack of precise identification.", "verifiability_rationale": "The reviewer states that the highlevel description 'lacks detail' and that the figure is 'abstract and misaligned'. These are claims that can be considered verifiable, as they point to potential issues with the clarity and relevance of the description and the figure. However, the reviewer does not provide specific examples or references to support these claims, making the verifiability somewhat low.", "helpfulness_rationale": "The reviewer provides suggestions for improvement, such as a mathematical formulation and a figure depicting the WiC task. These suggestions are concrete and directly related to the identified weaknesses. However, the suggestions are presented as future actions rather than immediate, actionable improvements for the authors at this point in time. The reviewer's comments are helpful in pointing out areas for improvement, but the immediate actionability is limited."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that more benchmarking tasks should be included but does not specify how these tasks should be selected, implemented, or evaluated. The action is present, but the details are lacking.", "grounding_specificity_rationale": "The review point does not refer to any specific part of the paper or the work being done. It is a general suggestion to include more benchmarking tasks.", "verifiability_rationale": "The review point is a suggestion, not a claim that needs verification. It does not state something is correct or incorrect.", "helpfulness_rationale": "The review point suggests a valuable addition to the work (more benchmarking tasks), indicating a helpful direction. However, the lack of specific guidance on how to incorporate these tasks makes it less immediately helpful than a more detailed suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for a comparison of YOSO with Linformer on an iterationwise convergence, specifying the metric (perplexity) and the context (Figure 4). They also ask for an explanation of why Linformer, which generally performs better on downstream tasks, shows different results. These are explicit actions with concrete details.", "grounding_specificity_rationale": "The reviewer identifies a specific missing piece of information (periteration comparison) and mentions a baseline (Linformer). They also mention downstream tasks, which further specifies the area of comparison. The comment clearly pinpoints the relevant parts of the paper (comparison, convergence, performance) and the specific elements being compared (YOSO, Linformer, perplexity).", "verifiability_rationale": "The reviewer claims that the paper lacks a comparison of YOSO with Linformer on iterationwise convergence and an explanation for the performance difference on downstream tasks. They provide a logical reasoning for their claim, stating that the paper doesn't provide these details. The claim is supported by the absence of the requested information in the paper.", "helpfulness_rationale": "The reviewer's comments directly address weaknesses in the experimental section by pointing out the missing periteration comparison and the lack of explanation for the performance discrepancy on downstream tasks. These are actionable suggestions that would help the authors understand the model's behavior and the reasons behind the performance differences."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the discrepancy between the abstract's claim and the text's clarification regarding the proposal distribution. While it doesn't directly tell the authors how to fix it, it points to a potential misunderstanding. The reviewer identifies the 'proposal distribution' and the 'target everywhere' as the specific parts of the paper being addressed, making the action somewhat explicit.", "grounding_specificity_rationale": "The comment explicitly mentions 'the abstract' as the specific part of the paper being addressed. It also clearly specifies the issue: 'the proposal distribution to upper bound the target everywhere which is not true as the authors themselves clarify in the text.' This provides precise information about the location and nature of the problem.", "verifiability_rationale": "The comment contains a claim: 'In the abstract the authors require the proposal distribution to upper bound the target everywhere which is not true as the authors themselves clarify in the text.' This claim is fully supported by the reasoning that the authors clarify it's 'everywhere an upper bound'. There are no missing references or logical gaps.", "helpfulness_rationale": "The comment is helpful because it points out a potential point of confusion for the authors regarding the abstract. By highlighting the difference between 'upper bounding the target everywhere' and 'upper bounding the target,' the reviewer is likely to help the authors understand the precise wording intended. The feedback is specific and likely to be actionable, though it doesn't directly tell them how to change the abstract. The authors can infer the need to clarify the abstract based on this feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential confusion arising from referencing '15' as 'PointNet'. While the reviewer identifies a problem, they don't offer a direct action or solution. They are highlighting a potential issue in the referencing, but not specifying how the authors should address it. The action is implied but not explicitly stated or concrete.", "grounding_specificity_rationale": "The reviewer's comment is general and doesn't specify where in the paper the citation '15' is being used. They are making a statement about the potential confusion without pinpointing the exact location or nature of the issue. The grounding is implied but not explicitly stated or specific.", "verifiability_rationale": "The reviewer makes a claim: 'Referring to 15 as 'PointNet' is confusing...'. However, they do not provide any evidence or justification for this claim. The reasoning, common knowledge, or external references are missing. The claim is stated, but it lacks support.", "helpfulness_rationale": "The reviewer identifies a potential source of confusion for the authors by pointing out the ambiguity in referencing '15' as 'PointNet'. While this highlights a potential issue, the reviewer does not offer a concrete solution or clear guidance on how the authors should address this confusion. The feedback is identified, but the action to take is not specified."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer asks specific questions about the optimality of the policy gradient method (Eq. 6) in relation to the overall goal (Eq. 5). While the comment doesn't explicitly state 'Do X to Y', it directly addresses the implications of using policy gradient methods. The reviewer is prompting clarification on a key aspect of the method's theoretical underpinnings. This constitutes an explicit action or suggestion, albeit one that requires further explanation rather than a direct implementation instruction. Therefore, it can be considered 3 as it points towards a specific area needing attention.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Eq. 6' and 'Eq. 5' in their comment. This clearly identifies the specific parts of the paper being addressed. The reviewer also points out a potential ambiguity in 'Line 132'. This strong referencing demonstrates a clear understanding of where the information is located and highlights a specific point of confusion. Therefore, the comment is fully grounded in the paper's content.", "verifiability_rationale": "The reviewer poses questions about the optimality of the policy gradient method and its convergence properties. These questions can be considered claims that require justification. The reviewer is making a statement about the potential limitations of the method and asking for clarification on the impact of learning. This claim is verifiable based on knowledge of policy gradient methods in reinforcement learning, where finding the global optimum is not guaranteed and learning plays a significant role. The reviewer's questions are grounded in the paper's content and point to a specific area needing further explanation or justification. Therefore, the claim is 4 as it is supported by logical reasoning and common knowledge in the field.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential weakness in the paper's methodology by questioning the optimality of the policy gradient method. They also point out a potential ambiguity in a specific line. This is a 5 comment as it identifies a specific area that requires clarification and suggests a direction for improvement (by clarifying the ambiguity). The questions are directly relevant to the paper's claims and methodology, making it a valuable feedback point for the authors. Therefore, the comment is 5 as it directly addresses a key aspect of the paper and suggests a concrete improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question about a specific aspect of the algorithm (Gaussian distribution) and requests a comparison. This directly points to a potential improvement or difference. The action is clear: 'What is the difference?' The information is directly relevant to the algorithm description.", "grounding_specificity_rationale": "The reviewer is asking about a specific aspect of the algorithm (Gaussian distribution). However, the paper itself doesn't explicitly mention this specific distribution in the context of its algorithm. The reviewer is inferring this based on the algorithm description. Therefore, the grounding is weak because the authors cannot confidently determine which part the comment addresses. The specificity is high because once the grounding is established (even if implicit), the question directly asks for a comparison.", "verifiability_rationale": "The reviewer makes a claim: 'Is it possible to assume the general gaussian distribution rather than isotropic gaussian in the proposed algorithm? What is the difference?' This is a direct assertion. Assuming the paper *does* explain the difference and the rationale for choosing the isotropic Gaussian, the claim is verifiable. However, the paper *doesn't* explicitly address this comparison, making the claim 1 based on the provided information. The lack of explicit grounding also contributes to this.", "helpfulness_rationale": "The reviewer is asking a direct question about a specific technical detail of the algorithm. This is a valuable piece of information for understanding and potentially improving the algorithm. The reviewer is likely to take action to understand the difference if this information is provided. The request is clear and directly addresses a potential improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly identifies a potential issue ('freezing the partitioning in the first iteration seems like a risky choice') and suggests an action ('makes strong assumptions about the coverage of the initial data. At least discuss the limitations of this'). While it doesn't provide a concrete solution, it points the authors towards a potential problem and encourages them to consider its implications.", "grounding_specificity_rationale": "The comment refers to a general methodological choice ('partitioning') and its potential impact ('strong assumptions about the coverage of the initial data') but does not explicitly identify a specific part of the paper (e.g., a section, table, or figure) where this partitioning is applied or its implications are discussed. The reference is more conceptual than to a specific element of the paper.", "verifiability_rationale": "This review point does not contain a claim that needs to be verified. It is a suggestion for improvement rather than a statement of fact or opinion. Therefore, it does not fall under the 'X' category for X.", "helpfulness_rationale": "The comment identifies a potential weakness ('freezing the partitioning') and suggests an action ('discuss the limitations'). While it doesn't provide a direct solution or specific guidance on how to discuss the limitations, it points the authors towards a relevant area of concern and encourages them to consider the implications of their methodological choice. It is not a completely unhelpful suggestion, but it's also not a direct critique of a specific element."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, which is not inherently actionable. While the question implies the reviewer wants to understand the intent of Section 5.2, it doesn't explicitly state what needs to be done or how to improve the section. The actionable aspect is implicit rather than explicit.", "grounding_specificity_rationale": "The review point explicitly refers to 'Section 5.2', which is a specific part of the paper. This demonstrates strong grounding as the reviewer is directly addressing a defined section.", "verifiability_rationale": "The review point is a question, not a claim that requires verification. Questions, in themselves, do not provide verifiable information. Therefore, this review point does not address verifiability.", "helpfulness_rationale": "The review point is a question about the intent of a section. While it doesn't directly point out specific weaknesses, it highlights a potential area for improvement: the clarity or focus of Section 5.2. By asking about the intent, the reviewer is implicitly suggesting a lack of clarity or a need for better definition. This indirect feedback can be helpful for the authors to selfreflect and improve their writing."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies several areas where the approach is unclear (many aspects) and mentions specific elements like 'object knowledge' and 'verb knowledge'. However, it does not explicitly state how the authors should go about clarifying these aspects or how to address the interaction between object and verb knowledge or the overcoming of reporting bias. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The review point mentions 'many aspects of the approach' and specifically names 'object knowledge', 'verb knowledge', and 'reporting bias'. While it doesn't point to a specific section or table, it clearly identifies the specific elements of the paper being discussed. The grounding is to the general area of the approach, and the specific elements are mentioned.", "verifiability_rationale": "The review point makes a claim that the paper is unclear and doesn't provide any evidence or reasoning to support this claim. It doesn't offer any external references or logical arguments to back up its assessment of the paper's clarity. The claim is presented without justification.", "helpfulness_rationale": "The review point criticizes the paper's clarity and organization but doesn't offer any suggestions or insights on how to improve these aspects. It doesn't provide any actionable steps or explanations for the identified weaknesses. The feedback is diagnostic but not constructive in terms of providing direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action the authors should take: 'clarify the threat model with specific details regarding the attacker's level of access, capabilities, and the defender's available resources.' This is a clear and direct action the authors can readily implement.", "grounding_specificity_rationale": "The reviewer explicitly identifies the 'threat model' as the specific part of the paper they are referring to. This is a clear and precise identification. The reviewer also provides specific areas within the threat model that they believe need clarification: 'attacker's level of access,' 'capabilities,' and 'defender's available resources.' This demonstrates strong grounding by specifying the exact aspect of the paper being addressed and providing concrete areas for improvement.", "verifiability_rationale": "The reviewer's point, while not a direct claim about the paper's correctness, implies a need for more detail and clarification. The suggestion itself is clear and actionable. However, the *specific content* of the clarification is not verifiable at this point. The reviewer is essentially stating 'I think more detail is needed here,' which is 3 as the *nature* of the needed detail is clear, but the *specifics* are unknown. The primary focus of the review is on the actionable aspect.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improving the paper. They are directly pointing out a potential area of confusion (the threat model) and offering a concrete direction for clarification. This is 5 for the authors as it directly addresses a potential weakness and provides a specific goal for the authors to work towards."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a missing justification for their choice of using link prediction accuracy for early stopping. This directly points to a potential area for improvement in the paper's methodology.", "grounding_specificity_rationale": "The reviewer directly refers to the same point, so the grounding specificity is the same as actionability. The reviewer does not identify a specific section or table, but they do identify the issue (lack of justification for their accuracy metric).", "verifiability_rationale": "The reviewer makes a claim about the paper's methodology (that it lacks justification for the early stopping metric). The verifiability of this claim depends on whether the paper actually provides this justification. The reviewer's question about why they chose link prediction accuracy is a request for logical reasoning and justification.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential weakness in the paper's methodology (lack of justification for the early stopping metric). The helpfulness of this comment depends on whether the paper actually identifies this gap and provides an explanation. If the paper does not, the reviewer's comment is 5 in pointing out this potential area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'Can authors explain with concrete details?' This directly prompts the authors to provide more information about their implementation. It is also concrete because it asks for specific information rather than a general suggestion.", "grounding_specificity_rationale": "The comment refers to 'classimbalanced task' within the context of 'fewshot learning.' This demonstrates a clear understanding of the relevant section of the paper. The request for 'concrete details' further emphasizes the need for specific guidance.", "verifiability_rationale": "The comment requests 'concrete details' regarding how to set up the classimbalanced task in a fewshot learning setting. While there isn't a single 'right' answer, the request implies a desire for wellreasoned and practical advice. It could be considered '4' as the authors could potentially provide examples or common strategies.", "helpfulness_rationale": "The review point directly addresses a potential area of confusion for the author (how to handle class imbalance in a fewshot setting). The request for 'concrete details' is a clear call for actionable feedback and encourages the author to elaborate on their implementation. While there might not be a single 'correct' answer, the request implies a desire for wellreasoned and practical advice, making it '4'."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "None of the claims in the review point provide explicit and concrete actions for the authors. The reviewer states that the ChatGPT baseline is 'rudimentary' and that 'fewshot approach isn\u2019t tested,' but these are general statements about the model and experimental setup, not specific instructions on how to improve the draft. The suggestion to 'include the discourse relation information in the prompts (probably in a ChainofThought style approach) might yield good results' is a potential improvement but lacks specific guidance on how to implement it. The statement that 'it is extraneous to their line of evaluation' is an opinion, not an actionable suggestion.", "grounding_specificity_rationale": "The comment is not fully grounded regarding the ChatGPT baseline and the lack of fewshot testing. However, it *does* point to a specific aspect of the model prompting (discourse relations and ChainofThought) as a potential area for improvement. This suggests a partial grounding in the model's input, as it refers to a specific component of the prompting strategy.", "verifiability_rationale": "The claim that the 'ChatGPT baseline is very rudimentary' is a subjective assessment without specific evidence or references. Similarly, the statement that 'fewshot approach isn\u2019t tested' lacks specific details or citations. While the suggestion to 'include the discourse relation information in the prompts (probably in a ChainofThought style approach) might yield good results' is based on common knowledge in the field, it could be strengthened with references to relevant literature on ChainofThought prompting. The statement that 'it is extraneous to their line of evaluation' is an opinion, not a verifiable claim.", "helpfulness_rationale": "The review point provides some helpful insights for the authors. The statement that the 'ChatGPT baseline is very rudimentary' helps the authors understand the limitations of their starting point. The suggestion to 'include the discourse relation information in the prompts (probably in a ChainofThought style approach) might yield good results' offers a potential direction for further experimentation and improvement. However, the lack of specific guidance on how to implement this makes it less helpful than it could be. The statement that 'it is extraneous to their line of evaluation' is an opinion and does not provide direct improvement suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the paper 'just say they first estimate a layer's sensitivity by pruning ...' but doesn't provide details on how actual pruning was done. This implies the action is not explicitly stated, and the vagueness of 'how it was done' makes it difficult to understand the method. The reviewer is implicitly asking for clarification on the pruning process, but the paper doesn't provide the necessary details to understand or replicate this step.", "grounding_specificity_rationale": "The reviewer mentions 'lines 238239' but doesn't specify which part of that section they are referring to or how the ground truth of sensitivity is achieved. This indicates a lack of precise identification of the relevant section. While the reviewer has pointed to a location, they haven't specified the exact element within that section being criticized.", "verifiability_rationale": "The reviewer's comment doesn't contain a clear claim or assertion that requires verification. They are pointing out a lack of detail in the paper. While this could be interpreted as a claim that the paper is missing information, the claim itself is not wellsupported or verified within the review point itself.", "helpfulness_rationale": "The reviewer's point about the lack of detail on pruning is valid and would likely be helpful for the authors to understand and reproduce the sensitivity estimation. However, the criticism is vague and doesn't provide a concrete suggestion for improvement. Therefore, while the feedback is relevant, it's not specific enough to be 5."}
{"actionability_label": "4", "grounding_specificity_label": "Weakly Grounded and Partially Specific", "verifiability_label": "UnderSpecific and Not Specific", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for explanations regarding specific concepts (rotation matrix) and potential solutions to a problem (nonpositive semidefinite matrix). While the action of explaining and suggesting solutions is present, the level of detail on how to apply these actions is not explicitly stated. The reviewer asks 'could the authors explicitly explain what is a proper rotation matrix in line 97?' and 'what exactly is meant in l. 105106 regarding solving the problem of the matrix being non positive semidefinite?'. These are clear requests for information and problemsolving guidance, making them actionable, but the specific steps to take are not fully defined.", "grounding_specificity_rationale": "The review point explicitly asks for the definition of a 'proper rotation matrix' in line 97, directly referencing a specific part of the paper. This provides strong grounding. However, the reviewer also asks about the meaning of solving the problem of the matrix being non positive semidefinite in lines 105106, without explicitly referencing a specific part of the paper. This makes the grounding specific for the rotation matrix but not for the positive semidefinite matrix.", "verifiability_rationale": "The review point makes claims that require justification. In line 97, the reviewer asks for an explanation of a concept, implying a need for justification. In lines 105106, the reviewer points out a problem and asks for a solution, which also requires justification. While the claims are present and require support, the level of detail and explicitness of the justification could be improved.", "helpfulness_rationale": "The review point is 5 as it directly addresses potential areas of confusion or lack of clarity for the authors. The specific requests for explanation and solution provide clear directions for improvement. The reviewer asks 'could the authors explicitly explain what is a proper rotation matrix in line 97?' and 'what exactly is meant in l. 105106 regarding solving the problem of the matrix being non positive semidefinite?'. These are actionable and specific requests that the authors can readily address."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the suggestion to change the term 'g' to 'binary operator' and provides a reason for this suggestion by drawing an analogy to a specific paper (Cohen and Shashua, 2016). This makes the action clear and direct.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'g activation function' and draws a parallel to 'Cohen and Shashua, 2016'. This clearly identifies the specific part of the paper being addressed and provides a relevant reference, demonstrating strong grounding. The reviewer also specifies the potential alternative term ('binary operator').", "verifiability_rationale": "The reviewer makes a claim by suggesting the change in terminology and provides a reference to external work ('Cohen and Shashua, 2016') as supporting evidence for their suggestion. While the connection between the cited work and the specific benefit of the change isn't explicitly detailed in the review point itself, the reference indicates an attempt to justify the suggestion.", "helpfulness_rationale": "The reviewer's point is relevant to the technical details of the paper, specifically the terminology used for activation functions. Suggesting a more precise term can improve clarity and understanding. While the reviewer doesn't explicitly state the *impact* of this change on the paper's contribution, the suggestion itself is a concrete improvement to the technical description."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the action: 'shrinking the captions' and provides a concrete suggestion: 'leaving more space for methods or related work'. This directly addresses what needs to be changed and how it should be changed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Fig. 1 and Fig. 2' and explains the issue: 'have large overlaps with your content' and suggests a solution: 'leaving more space for methods or related work'. This clearly identifies the specific part of the paper being addressed and the implications of the issue.", "verifiability_rationale": "The reviewer points out the issue of 'large overlaps with your content' in the figure captions. While this is a valid observation, the reviewer does not provide explicit evidence or references to support this claim. The suggestion to 'shrink the captions' is a direct action, but the underlying problem is not explicitly verified by providing examples of these overlaps or citing literature that highlights this as a problem.", "helpfulness_rationale": "The reviewer identifies a potential issue ('large overlaps with your content' in figure captions) and suggests a practical improvement ('shrinking the captions' to allow for more space for methods or related work). This directly addresses a potential problem and offers a concrete solution, making it a helpful comment for the author."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer's point is explicit in identifying the omission of Vidgen et al. (2021) and the significant difference in dataset size as a reason for not using it as a benchmark. The action is 'to investigate the role of context,' which is a clear and direct action to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Vidgen et al., 2021' as a missing work and states the dataset size varies significantly. This directly identifies the missing element and the issue with the current dataset. The grounding is 'the dataset of Vidgen et al., 2021' and the specificity is 'why it wasn't used as a benchmark'. The reviewer provides a clear reference and a reason for the variation in size.", "verifiability_rationale": "The reviewer states that Vidgen et al. (2021) might be 'really similar' to the dataset presented in the work, which provides a basis for verifiability. The reasoning is that similarity suggests a potential benchmark. The evidence is the potential overlap in the type of hate speech investigated. This is a logical and commonsense argument, although it might require further investigation to confirm the similarity.", "helpfulness_rationale": "The reviewer's point is helpful in identifying a potential limitation of the current work and suggesting a direction for future research. The reviewer asks a relevant question about why a potentially similar dataset wasn't used as a benchmark. This highlights a gap in the current work and encourages further exploration. However, the review doesn't provide specific actionable steps on how to incorporate Vidgen et al. (2021) as a benchmark or how to address the size difference. The information provided is sufficient to understand the potential issue but lacks concrete solutions for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem with the presentation of the results, indicating a clear and actionable feedback regarding the lack of statistical rigor and the incorrect presentation of results. The reviewer points out that the results should have been presented as a mean over many runs with error bars, while the plotted curves are from single runs. This is a clear indication of a lack of actionable feedback for the authors on how to improve their experimental methodology or reporting.", "grounding_specificity_rationale": "While the reviewer mentions 'the results comparing standard vs. evolutional dropout on shallow models,' the specific experiment or model details are not explicitly stated in the review point itself. The grounding is based on the general area of the paper (comparison of different dropout methods). Therefore, the grounding is **Weakly Grounded**. The reviewer does specify the *type* of models as 'shallow,' which adds some specificity, but the exact model architecture or dataset is not mentioned.", "verifiability_rationale": "The reviewer makes a clear claim about the *lack of statistical rigor* in the reported results and the *incorrect presentation* of the results as single runs instead of means with error bars. This claim is **wellsupported** by the reviewer's statements. The reviewer provides specific details about what the results *should* have been, indicating a clear and verifiable point of improvement for the authors.", "helpfulness_rationale": "The reviewer's comment points out a significant issue in the *presentation and rigor* of the results. While the feedback is relevant to the authors' work, it doesn't directly suggest a concrete change to their current draft. The reviewer is highlighting a deficiency in the *review process* or the *paper being reviewed*. Therefore, the feedback is **3** in identifying an area for improvement in the authors' methodology or reporting, but it doesn't directly guide the authors on how to improve their current work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a limitation of the proposed approach, stating that it still requires 'carefully choosing basis functions and meshes and assembling stiffness matrices'. This points to a lack of automation in certain steps that are typically involved in traditional FEM. However, the reviewer also suggests 'operator learning methods' as an alternative, which is a broad statement and doesn't provide a specific, actionable next step. The criticism is general and doesn't pinpoint a specific deficiency that needs immediate action. While the reviewer points out a potential improvement, they don't offer concrete, actionable steps to achieve it.", "grounding_specificity_rationale": "The reviewer mentions 'traditional FEM components' and 'operator learning methods' when critiquing the approach. While they categorize the limitations, they don't explicitly identify a specific part of the paper being addressed. The criticism is general and doesn't point to a particular section, table, figure, or unique element of the paper. The reviewer's statement is highlevel and lacks the precision required for strong grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about operator learning methods being 'more universal' and 'not needing adaptation'. This is a subjective statement and doesn't provide specific evidence or references to support this claim within the review point itself. The reviewer is making an opinion about the potential of operator learning, but without concrete examples or logical reasoning based on the provided text, it's difficult to verify this claim. The claim is present, but the lack of supporting evidence makes it 1 based solely on the provided text.", "helpfulness_rationale": "The reviewer offers a critique of the approach and suggests an alternative ('operator learning methods') as a potential improvement. While this offers a direction for improvement, the critique is somewhat general and doesn't provide very specific guidance on how to implement the suggested change. The reviewer's point is valuable in pointing out a potential limitation, but it lacks the immediate actionable steps needed for maximum helpfulness. The suggestion is present, but it's not framed as a concrete, immediate solution."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the information needed (CUDA version and PyTorch version) and clearly indicates the area of the paper where this information should be described (the experimental environment). The reviewer does not need to infer what is missing, making the action explicit. The information provided is precise and directly addresses the potential impact of these versions on training and inference speeds. This provides a clear and actionable step for the authors to improve their description.", "grounding_specificity_rationale": "The review point identifies the 'experimental environment' as the area needing more detail. While this is a specific area, the reviewer does not explicitly pinpoint a section, table, figure, or unique element within that area. The information needed (CUDA and PyTorch versions) is general and doesn't directly link to a specific visual or textual element in the paper. Therefore, while the reviewer targets a specific *area*, they don't pinpoint the exact *part* within that area, making the grounding somewhat weak.", "verifiability_rationale": "The review point is a suggestion for improvement rather than a claim that something is incorrect or missing. It doesn't state that the current description of the experimental environment is flawed or that specific versions are impacting performance. There is X that requires verification or evidence. The point is about suggesting what information is missing, not identifying a problem that needs justification. Therefore, there is X to be verified, making it 1.", "helpfulness_rationale": "The review point is 5 because it directly and explicitly tells the authors what information is missing and what specific details they should provide. The suggestion is actionable, meaning the authors can directly implement the advice. The reviewer clearly identifies the *what* (describe the experimental environment in detail) and the *how* (mention CUDA and PyTorch versions). This provides a clear and practical improvement for the authors to enhance their paper's reproducibility."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states a fact and expresses an opinion. While they identify a limitation, they don't provide explicit or concrete actions on how to address it.", "grounding_specificity_rationale": "The reviewer makes a general statement about the limitations of realistic datasets and the societal impact. They do not specify which aspects of variation are difficult to control or which specific societal impacts are being referred to.", "verifiability_rationale": "The reviewer presents claims about the limitations of realistic datasets and the societal impact without providing any supporting evidence or reasoning.", "helpfulness_rationale": "The reviewer offers a critique without providing any actionable feedback or suggestions for improvement. They simply state the limitations and their opinion on the societal impact."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue with the figure and its caption ('Dashed lines indicate that the agent can plan ahead...') as a lack of clarity. This action is both explicit and concrete, as the reviewer points to a specific section and identifies a specific problem within that section.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the figure' and provides a specific suggestion for improvement ('improve the caption to explain what the dashed lines represent'). This demonstrates strong grounding as the reviewer can accurately pinpoint the referenced part and suggest a concrete change.", "verifiability_rationale": "The reviewer states a claim ('Dashed lines indicate that the agent can plan ahead...') and provides a suggestion for improvement ('improve the caption to explain what the dashed lines represent'). However, the reviewer does not provide external references or logical reasoning to *justify* the *correctness* of their interpretation of the dashed lines. They are pointing out a lack of clarity, not necessarily stating something is wrong *logically*. Therefore, it is underspecific as the reviewer doesn't explain *why* the caption is vague, just that it is. It is also not 5 because the claim is about the clarity of the figure, which is a subjective assessment.", "helpfulness_rationale": "The reviewer provides a clear critique of a specific element of the paper (the figure and its caption) and offers a direct suggestion for improvement ('improve the caption to explain what the dashed lines represent'). This directly addresses a potential weakness for the authors and provides actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The suggestion to 'mention the evaluation metric' is an explicit action. However, the action lacks detail on *how* to mention it, making it somewhat vague. The reviewer proposes a specific improvement, but the implementation is not detailed.", "grounding_specificity_rationale": "The reviewer implies they are referring to 'evaluation' when suggesting 'mention the evaluation metric'. This provides some grounding as the intent is clear. However, the suggestion is not fully specific as it doesn't pinpoint a particular section or table. The example 'including ROOT arcs' is vague and could be interpreted in multiple ways, hindering precise grounding.", "verifiability_rationale": "The reviewer makes a claim: 'For clarity, it would be better if the evaluation metric is mentioned here.' This claim is verifiable as the reviewer states a reason (improves clarity) for making a suggestion. However, the claim itself doesn't provide evidence for or against it.", "helpfulness_rationale": "The reviewer suggests a specific change: 'For clarity, it would be better if the evaluation metric is mentioned here to better understand the scale of the improvement'. This is a clear and actionable suggestion aimed at improving the paper. The reviewer proposes a specific improvement, making it helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests 'studying the behaviour of the model under higher noise.' This is an explicit action that the authors can directly implement. The term 'higher noise' is also concrete, indicating that the authors should explore scenarios with increased noise levels. The reviewer does not leave room for ambiguity regarding what constitutes 'higher noise' in this context, even if the exact implementation details are not specified.", "grounding_specificity_rationale": "The reviewer refers to 'the observations in the plot compared to the true trajectories.' This is a specific part of the paper that the authors can identify. The comment clearly pinpoints a discrepancy that needs to be addressed, making the grounding explicit and precise.", "verifiability_rationale": "The reviewer states that the current noise level, based on their understanding of the plot, is 'not very high' and suggests studying the model under 'higher noise.' This constitutes a claim that the current noise is insufficient. However, the reviewer does not provide any specific evidence, examples, or references to support this claim. The justification is based on the visual observation of the plot alone, which is a reasonable inference but lacks rigorous backing.", "helpfulness_rationale": "The reviewer suggests 'studying the behaviour of the model under higher noise.' This is a clear and actionable suggestion that directly addresses the identified issue. While the reviewer does not explicitly define what constitutes 'higher noise' in terms of specific parameters or ranges, the suggestion itself is a valuable next step for the authors to explore different noise levels. The comment is directly relevant to improving the understanding of the model's behavior under varying noise conditions."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a limitation of a theoretical result but does not explicitly state how the authors should modify their bounds or what steps they should take. While it points to a direction for future work, it lacks concrete action items. For example, the reviewer mentions 'arbitrarily long inputs' but doesn't specify how to determine if their input falls into this category or what adjustments are needed.", "grounding_specificity_rationale": "The reviewer mentions 'arbitrarily long inputs' but does not specify what part of the paper or what specific detail this refers to. The comment is general about the bounds and their limitations for long inputs, lacking a precise reference point. The reviewer acknowledges the concept but doesn't pinpoint the exact location or nature of the issue.", "verifiability_rationale": "The reviewer provides a clear and logical explanation of why the bounds might be impractical for arbitrarily long inputs. They connect the theoretical bounds to realworld applicability, making the limitation understandable and verifiable through reasoning. The reviewer doesn't rely on external references but uses logical arguments to support their claim.", "helpfulness_rationale": "The review point directly informs the authors about a significant limitation of their theoretical result. It highlights a practical concern that they should be aware of and consider in their future work. This information is highly relevant and helpful for guiding their research and understanding the scope of their findings."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the performance of DVP on video with different lengths. While this could potentially lead to further investigation and modifications to the draft if the authors were to explore this, the point itself does not directly instruct the authors on what to do or how to change their current work. It is a question, not a directive action.", "grounding_specificity_rationale": "The review point asks about the performance of DVP on video with different lengths. It does not specify which part of the paper this relates to or what specific issue is being highlighted. The authors would need to infer the relevance of this question to their own work, making it not fully grounded.", "verifiability_rationale": "The review point is a question, not a declarative statement that makes a claim. It does not present a claim that can be verified through logical reasoning, common knowledge, or external references. It is not a statement that requires justification.", "helpfulness_rationale": "The review point is a relevant question for researchers working with video data and models. It prompts further investigation into the impact of video length on DVP's performance. While it can be helpful in inspiring further exploration and potentially leading to improvements in the authors' own work (if they choose to investigate), it does not directly provide actionable feedback on how to improve their current draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's statement is an implicit request for clarification regarding the type of cloze queries the paper targets. While they don't explicitly state 'Please clarify if the paper is about singletoken cloze queries,' the confusion indicates a need for explicit information. The action is implicit, making it 2. The reviewer knows they need more information about the paper's focus but doesn't know exactly *where* to look in the paper.", "grounding_specificity_rationale": "The reviewer is confused about the paper's focus on singletoken or multitoken cloze queries. They are not explicitly pointing to a specific section or table in the paper. The information they seek is general, lacking a precise reference point. Therefore, the grounding is weakly based on the information provided.", "verifiability_rationale": "The reviewer states their confusion about the paper's focus on singletoken or multitoken cloze queries. This statement itself is a claim that requires clarification. However, the reviewer does not provide any external references or logical reasoning to support their confusion. The claim is stated without any backing, making it 1 based on the provided text.", "helpfulness_rationale": "The reviewer clearly states their confusion regarding the paper's focus on singletoken or multitoken cloze queries. This indicates a genuine issue they encountered while reading the paper. While they don't explicitly state an action they want to take, the desire for clarification is a valuable piece of feedback. The reviewer is pointing out a lack of clarity, which is helpful for the authors to understand what needs to be addressed. Therefore, it is 3 in identifying a need for clarification."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue (ignoring the KLdivergence) and provides a specific direction for improvement (calculate and check if it approaches zero). This is an explicit and concrete action that the authors can directly implement.", "grounding_specificity_rationale": "The reviewer specifically mentions \"Section 3.3: The proposed training objective has ignored the KLdivergence term in equation (3).\" This is a clear and direct reference to a specific part of the paper. The reviewer also clearly states what the issue is (ignoring the KLdivergence) and what needs to be done (calculate and check if it approaches zero). This is highly specific.", "verifiability_rationale": "The reviewer makes a claim: \"Can you evaluate such approximation error, ie. calculate the actual KLdivergence and check whether it indeed approaches zero?\" This claim is verifiable through direct calculation of the KLdivergence using its definition and analyzing its behavior in the context of equation (3). The request itself provides the justification for why this evaluation is needed.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors to improve their understanding and potentially refine their method. This is highly beneficial for the authors' development by addressing a specific, potentially important detail in the method description."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a lack of clear connection between Section 2 and the methodology. This suggests a potential weakness or area for improvement. The mention of a 'simplistic\" theoretical analysis further reinforces this. While the reviewer identifies a problem, they don't explicitly state how the connection should be improved or what specific changes are needed in the theoretical analysis. The language is more evaluative than prescriptive.", "grounding_specificity_rationale": "The comment explicitly refers to \"Section 2\" and \"the methodology section,\" clearly identifying the areas of concern. It also mentions specific issues related to the connection between these sections and the theoretical analysis. The reviewer uses terms like \"limited connection\" and 'somewhat simplistic,\" which provides some level of detail about the nature of the problems. The comment is not just stating a problem but also describing the state of the connection and analysis.", "verifiability_rationale": "The reviewer states \"In my opinion, Section 2 shows limited connection with the methodology section\" and \"furthermore, the theoretical analysis is somewhat simplistic and closely related to 1.\" These statements are claims, as they express an opinion or judgment about the connection and the analysis. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims within the review point itself. The assessment is based on the reviewer's interpretation and comparison to external work 1, but the current review point lacks internal justification.", "helpfulness_rationale": "The reviewer identifies specific areas that need improvement, namely the connection between Section 2 and the methodology, and the simplicity of the theoretical analysis. However, the review point does not offer any concrete suggestions or guidance on how to address these issues. The reviewer's comments are more of a critique highlighting problems rather than providing actionable advice on how to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests focusing the analysis of the loss function on 'specular areas'. While this implies a specific area of interest, it doesn't explicitly state what action needs to be taken or how the analysis should be conducted. The suggestion is openended and doesn't provide a direct instruction on modification.", "grounding_specificity_rationale": "The reviewer mentions 'specular areas' as a specific context for further discussion. However, they do not explicitly identify which section, table, figure, or unique element of the paper these 'specular areas' refer to. The reference is broad and lacks precision.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for further analysis rather than a statement that needs to be proven or justified.", "helpfulness_rationale": "The reviewer suggests focusing the analysis of the loss function on 'specular areas'. This is a constructive suggestion that could guide the authors to a more nuanced understanding of their model's behavior in specific scenarios. It provides a direction for further investigation and potentially leads to valuable insights."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment states the problem (the paper isn't good enough for ICLR) but provides no guidance on *how* to solve it. There's no specific action to take, only a general assessment.", "grounding_specificity_rationale": "The comment is a broad statement about the paper's overall contribution. It lacks any specific reference to sections, tables, figures, or elements within the paper.", "verifiability_rationale": "The comment expresses an opinion about the paper's suitability for ICLR. It doesn't present a claim that needs to be supported by evidence or references. It's a statement of assessment, not a proposition to be proven.", "helpfulness_rationale": "The comment is a negative assessment of the paper's quality for the conference. It doesn't offer any specific, actionable advice on how to improve the paper. It's a critique, not a helpful suggestion."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a missing definition of n_t in Algorithm 2 and a lack of clarity regarding 'appropriate number' in line 225. While the reviewer doesn't explicitly state what the 'appropriate number' is, they clearly identify a gap in the information provided, making it 3. The reviewer's suggestion to look for the definition in Algorithm 2 is a concrete action the authors should take.", "grounding_specificity_rationale": "The reviewer refers to line 225, indicating they are identifying a specific part of the paper. However, they do not explicitly state what the 'appropriate number' is, nor do they provide a clear explanation of what is meant by it. This makes the grounding underspecific.", "verifiability_rationale": "The reviewer makes a claim that the definition of n_t is missing and that the term 'appropriate number' is unclear. They also claim that the reference 30 does not provide the answer. This claim can be verified by examining Algorithm 2 and 30, making it partially verifiable. The reviewer's statement about the lack of clarity is a claim that needs justification.", "helpfulness_rationale": "The reviewer provides specific information about the missing definition of n_t and the lack of clarity regarding 'appropriate number'. This information is directly helpful to the authors, as they can now search for the definition in Algorithm 2 and try to understand the context of 'appropriate number'. Therefore, the review point is helpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment asks a question about code availability but doesn't provide a specific action or suggestion if the code is not publicly available. It lacks a clear, actionable step for the authors.", "grounding_specificity_rationale": "The comment is about the general availability of code and reproducibility, not a specific part or element of the submitted paper.", "verifiability_rationale": "The comment is a question, not a declarative statement making a claim that needs verification.", "helpfulness_rationale": "The comment is a question about code availability, not a direct critique or suggestion for improving the current draft. It doesn't directly address the authors' immediate needs for revision."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out a lack of clarity and specificity regarding the claim about mixing time. It doesn't directly tell the author *what* is wrong or *how* to improve the experiments. While the reviewer identifies a potential weakness, they don't provide concrete steps or data to support or refute the claim. The suggestion to 'improve the experiments' is vague and doesn't offer specific guidance. Therefore, the review lacks actionable information for the author.", "grounding_specificity_rationale": "The reviewer makes a general statement about the experiments not being sufficiently supported. They don't explicitly point to a specific section, table, figure, or unique aspect of the paper. The comment is vague and doesn't pinpoint where the lack of support lies. They don't mention specific experimental details or results. Therefore, the reviewer's comment is 1 in specific parts of the paper.", "verifiability_rationale": "The review explicitly states a claim: 'the mixing time is even better.' However, this claim is not supported by any evidence or reasoning within the review point. The reviewer does not provide any logical arguments, references, or examples to back up their assertion. They simply state the claim without providing any basis for its validity. Therefore, the claim is not verifiable based on the information provided in the review point.", "helpfulness_rationale": "The review identifies a potential weakness in the experimental validation by stating that the mixing time is 'even better' than expected. However, the reviewer does not offer any suggestions or improvements to address this concern. They simply point out that the current evidence is insufficient. Since there are no concrete actions or recommendations provided, the feedback is not helpful for guiding the author's work. Therefore, the feedback is 2 as it lacks actionable suggestions."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a concrete action: 'extend the protected feature A to a vector form'. This indicates a clear direction for the authors to explore. The suggestion is not just a question but a specific proposal for a change.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or define a unique element. While it suggests a change related to 'protected feature A', it doesn't pinpoint where this feature is located or what aspect of it needs to be extended to a vector. The reviewer is implying a general improvement rather than addressing a specific issue in a particular section or table.", "verifiability_rationale": "The review point is a question, not a statement that requires verification. It's a suggestion for a potential change, not a claim about what's currently lacking. Therefore, it doesn't contain a claim that needs to be supported.", "helpfulness_rationale": "The review point is a direct and specific suggestion for the authors to consider a vector representation for their protected feature A. This is a concrete and actionable piece of feedback that directly addresses a potential area for improvement. It empowers the authors to explore a specific technical change."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for clarification on the notation used in the equation (x and t) and requests specific details about the implementation, such as whether the vectors are L2normalized and which similarity metric is used for nearest neighbors. This directly points to actionable steps the authors should take to understand and implement the method. While it doesn't directly tell them *what* to do, it identifies a specific area of confusion and guides them to look for specific implementation details.", "grounding_specificity_rationale": "The review point explicitly mentions 'x and t' in the equation, 'L2normalized', and 'cosine or dotproduct'. This demonstrates a clear grounding of the comment in the technical details of the paper, directly referencing specific elements within the described methodology.", "verifiability_rationale": "The review point is a question seeking information that is likely available in the paper (or at least should be). It doesn't present a subjective opinion. The information requested is factual and could be found through a careful reading of the methods section. While the paper *should* contain this information, the reviewer is highlighting a lack of clarity in the current description, implying it's not immediately obvious to the reader.", "helpfulness_rationale": "The review point is directly asking for clarification on implementation details. This is immediately useful for the authors. It addresses a specific, concrete issue they might be facing when trying to reproduce or understand the method. While it might not be a major critique, it's a specific question that can significantly improve the clarity of the method description."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review points out the need for multiple experiments, which is a valid concern. However, it doesn't explicitly state how to implement this, making it implicitly actionable rather than fully actionable.", "grounding_specificity_rationale": "The review mentions the need for multiple experiments and reporting statistics but doesn't specify which part of the paper or experiment is problematic, nor does it explain what is wrong.", "verifiability_rationale": "The reviewer makes a claim about the importance of reproducibility in deep RL and suggests a community effort to address it. This claim is verifiable as it points to a known issue in the field and proposes a potential solution.", "helpfulness_rationale": "The reviewer identifies a critical missing element in the experimental methodology (multiple runs) and suggests a way to address it. This is a helpful comment as it highlights a significant weakness and provides a direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what the author should do. While it points to specific locations (Figure 2, Line 433, Line 468), it doesn't provide concrete instructions on how to check these locations or what actions to take based on the findings. The request is for verification rather than actionable improvement.", "grounding_specificity_rationale": "The review point explicitly mentions specific parts of the paper (Figure 2, Line 433, Line 468), which can be considered full grounding. However, it does not specify what is wrong or needs to be improved in these parts. The comment is vague about the nature of the issue.", "verifiability_rationale": "The review point does not contain a claim. It is a directive to check specific locations, not a statement that requires verification or justification. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The review point is a request to check specific locations in the paper. While this can help identify potential issues, it does not provide the author with concrete steps to improve their work. The feedback is limited to verification, which is less helpful than suggestions for action."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the similarity between $kNNECD$ and $kNNMT$ and uses this to make a claim about the paper's technical contribution. This is a clear and direct action pointing out a specific aspect of the paper (the relationship between two methods) and how it impacts the contribution.", "grounding_specificity_rationale": "The review point mentions specific methods ($kNNECD$ and $kNNMT$) but does not explicitly identify a specific part of the paper (e.g., a section, table, or figure) being addressed. While the methods are unique elements, the point doesn't clearly pinpoint where this similarity is a problem within the paper's structure.", "verifiability_rationale": "The review point is a statement of opinion (a limitation) rather than a claim that requires verification. It doesn't present a deduction or inferred observation that needs justification. Therefore, it doesn't fit the criteria for verifiability.", "helpfulness_rationale": "The review point identifies a potential limitation of the paper's contribution by highlighting the similarity between two existing methods. While it provides a general assessment, it doesn't offer specific, actionable suggestions for improvement. The feedback is present but lacks the constructive detail that would make it 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question and suggests an experiment. While the suggestion is valuable, it's not explicitly stated as the *next step* you *must* take. It's implied.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 1' and clearly states the potential issue as 'artificially generated figures' and the suggestion for improvement as 'realworld experiments'. This is very specific.", "verifiability_rationale": "The reviewer suggests an experiment as a way to validate the phenomenon. This is a suggestion, not a definitive statement that *must* be true or false *based on the paper itself*. It's a recommendation for future work.", "helpfulness_rationale": "The reviewer raises a valid concern about the realism of the figures and suggests a concrete way to address it. This is valuable feedback, even if it's not perfectly actionable in its current form."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that they are 'not clear' on the numbers of parameters. This directly identifies a missing piece of information and provides a clear action for the author to take: seek clarification on the parameter counts. The statement is concrete, indicating a need for specific information.", "grounding_specificity_rationale": "The reviewer refers to 'Section B.3' and mentions the 'numbers of parameters'. The reference to a specific section and a specific detail ('numbers of parameters') demonstrates strong grounding and specificity. The reviewer is not making an educated guess but rather pointing to a concrete location and detail within the paper.", "verifiability_rationale": "The reviewer's statement about being 'not clear' on the numbers of parameters is a statement of fact about their own understanding. While it implies a potential weakness, it doesn't present a claim that requires external verification. The lack of supporting evidence makes it 1 in the sense that there's no logical reasoning or external references provided to support the claim of lack of clarity.", "helpfulness_rationale": "The reviewer's point directly addresses a potential area of confusion for the author. By pointing out the lack of clarity regarding the numbers of parameters, the reviewer is highlighting a specific weakness in the paper that the author could improve. This actionable feedback empowers the author to better understand and potentially refine their work, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The action is not explicitly stated, requiring the authors to infer how the example/figure would help.", "grounding_specificity_rationale": "The comment lacks specificity regarding the definition of uniform shattering.", "verifiability_rationale": "The review point is a suggestion, not a claim requiring verification.", "helpfulness_rationale": "The suggestion directly addresses a likely area of confusion and offers a concrete improvement, even though the exact implementation is not fully specified. It's 'somewhat\" helpful because it's a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer claims the method is not novel and connects it to selftraining. While the connection is stated, the specifics of how the method relates to selftraining are not detailed. The reviewer identifies a potential weakness (lack of novelty) and suggests a direction for improvement (emphasize the connection to selftraining if it exists). This provides a clear direction for the authors to consider, making it 3.", "grounding_specificity_rationale": "The reviewer mentions the connection to 'semisupervised methods' and specifically 'selftraining'. This indicates an attempt to ground the comment in a specific area of the paper. However, the reviewer does not explicitly identify a specific section, table, or unique aspect of the paper that is being addressed. The grounding is at a higher level (a category of methods) rather than a specific part of the paper. The comment specifies *what* might be related (selftraining) but not *where* in the paper this connection is being made. Therefore, it is 3.", "verifiability_rationale": "The reviewer makes a claim: 'I don't believe the proposed transductive method is very novel.' This is a subjective statement. While the reviewer provides a *reason* for their belief ('I believe its related to a common way to incorporate unlabeled data in semisupervised methods (see selftraining methods in semisupervised learning)') this reason is not presented as verifiable evidence within the review point itself. The claim is based on the reviewer's interpretation and connection to selftraining, but this connection is not supported by a reference or logical reasoning within the review point. Therefore, the claim is not welljustified and lacks external references or logical reasoning to support it.", "helpfulness_rationale": "The reviewer provides a clear statement of belief regarding the novelty of the method and suggests a direction for improvement (emphasize the connection to selftraining if it exists). This provides a direction for the authors to consider and act upon. Even though the specifics of the connection are missing, the reviewer's intent to highlight the similarity to selftraining is a valuable piece of feedback. This makes the review point 5 in guiding the authors towards considering the novelty aspect and potentially comparing their method to existing approaches."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the formulation or definition in the manuscript is 'somewhat trivial' but doesn't explicitly tell the author what to do about it. While the reviewer identifies a potential issue, the action is implied and not clearly defined. The reviewer suggests focusing on 'optimization and theoretical property analysis,' which hints at actionable steps, but the exact nature of these actions is not specified.", "grounding_specificity_rationale": "The reviewer refers to 'formulation or definition in this manu.' which indicates an attempt to ground the comment in a specific part of the paper. However, they do not explicitly name a section, table, figure, or unique aspect. They refer to it generally, making the grounding weak. The comment also specifies that the issue is 'somewhat trivial,' adding some level of specificity about the nature of the triviality, but it doesn't detail what is trivial.", "verifiability_rationale": "The reviewer makes a claim that the 'formulation or definition in this manu. is somewhat trivial.' However, they do not provide any evidence, examples, or references to support this claim. The statement is presented as an opinion without any logical reasoning or external references to back it up.", "helpfulness_rationale": "The reviewer's point is relevant to the author and offers a potential direction for improvement by suggesting a focus on 'optimization and theoretical property analysis.' This provides a general idea of how the formulation or definition could be improved, making the review 3. However, the exact nature of the actionable steps is not fully specified, and the reviewer doesn't provide evidence to support their claim of triviality."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point does not suggest any concrete actions or modifications the authors should make to their draft. It critiques the methodology and interpretation of the evaluation results rather than providing direct instructions for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'evaluation results reported in table 1' which can be considered a specific part of the paper. However, the criticism is about the *interpretation* of these results and the *methodology* used to obtain them, rather than a specific issue within a defined section or table. The grounding is present but focuses on the interpretation rather than a direct flaw within a specific part of the paper.", "verifiability_rationale": "The reviewer makes a claim that the evaluation results are not statistically significant and that the interpretation is incorrect. While the claim is about the interpretation of the results, the reviewer implicitly suggests that the small number of trials (3) is a factor contributing to the lack of significance. However, the reasoning provided is not entirely clear or wellsupported by explicit references or logical reasoning within the review point itself.", "helpfulness_rationale": "The review point is helpful in that it points out a potential flaw in the evaluation methodology and the interpretation of the results. This could help the authors understand the limitations of their evaluation and potentially reevaluate their approach. While the critique is about the methodology, it provides valuable information for the authors to improve their understanding of their evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the need to compare features with two relevant papers, making the action clear. However, it doesn't specify the exact features or how this comparison should be implemented, making it only 3.", "grounding_specificity_rationale": "The comment mentions 'two relevant papers' but doesn't specify which part of the paper the comparison should address or provide details on the features being compared. The grounding is weak as the authors can only make an educated guess about the referenced part.", "verifiability_rationale": "The comment presents a suggestion to compare features with prior work but doesn't provide any justification or evidence for why this comparison is necessary or what the expected outcome should be. The claim is made without sufficient support.", "helpfulness_rationale": "The review points out a relevant area for improvement (comparative analysis with prior work) but lacks specific guidance on what to compare or how to perform the comparison. The authors still need to infer the details, making the feedback less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly points out the use of the word 'equivalent' at specific line numbers (8, 56, 70, 93). This constitutes an explicit action, as the reviewer is directly identifying instances where the word is used. While the comment doesn't provide concrete actions on how to improve the draft based on this observation, it is a clear indication of a potential issue, making it 3.", "grounding_specificity_rationale": "The comment explicitly mentions the lines (8, 56, 70, 93) where the word 'equivalent' is used. This allows the authors to directly identify the specific part of the paper being addressed. Therefore, the grounding is fully grounded. The comment also points out a potential issue (lack of verification) related to the use of the word, making the specificity somewhat clear.", "verifiability_rationale": "The comment itself does not contain a claim that can be verified. It is a suggestion for the authors to be more cautious about their use of the word 'equivalent.' While the underlying intent is to encourage the authors to verify their usage, the comment itself doesn't provide any logical reasoning, common knowledge, or external references to support a claim. Therefore, it is classified as having X (X).", "helpfulness_rationale": "The comment directly points out a potential issue with the use of the word 'equivalent' in the paper. By suggesting the authors be more cautious, it provides a clear direction for improvement. This actionable feedback is directly helpful to the authors in refining their work. The comment is specific enough to guide the authors to review their use of the term and potentially verify it."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer identifies a problem (lack of understanding of the multiview clustering approach) and highlights a specific issue (the dominance of the paraphrase similarity view). While they don't explicitly state the steps to understand the approach or the usefulness of other views, they imply an action is needed. However, the reviewer doesn't provide concrete suggestions on how to understand the approach or utilize the other views, making it less actionable than '4' or '5'.", "grounding_specificity_rationale": "The reviewer mentions 'multiview clustering approach' and 'different clustering techniques' generally, but they don't explicitly name specific sections, tables, or unique elements of the paper they are referring to. While they mention 'other views', they don't specify which ones. The single empirical example of clustering paraphrases of 'slip' is also a general statement and doesn't pinpoint the exact part of the paper being discussed. Therefore, the grounding is weak. The reviewer also mentions 'differences' between views, which could be considered specific, but the lack of detail makes it underspecific.", "verifiability_rationale": "The reviewer states a fact: 'almost all across the board, the paraphrase similarity view does significantly better than other views and their combination.' However, they don't provide any logical reasoning, common knowledge, or external references to support why this is a problem or what we should learn from it. They also don't provide specific examples of how the other views are useful. The analysis is limited to a single empirical example, which is insufficient to draw general conclusions about the usefulness of different views. Therefore, the claim is not wellverified.", "helpfulness_rationale": "The reviewer clearly states a problem: 'I don't understand effectiveness of the multiview clustering approach' and provides a desire for further analysis: 'What, then, do we learn about the usefulness of the other views? There is one empirical example of how the different views help in clustering paraphrases of the word 'slip', but there is no further analysis about how the different clustering techniques differ, except on the task directly.' The reviewer does not offer any solutions or actionable insights. They simply state a problem and express a desire for more information. Therefore, the review point is not helpful in itself."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the architecture is 'not clearly explained'. This indicates an implicit action, as the reviewer understands that an explanation is needed but doesn't know exactly where or what to find it. The action is also vague because the reviewer doesn't specify what aspects of the architecture are unclear.", "grounding_specificity_rationale": "The reviewer states that the architecture is 'not clearly explained'. They do not identify a specific section, table, figure, or unique element of the paper that is unclear. The comment is highly unspecific about the location of the missing information.", "verifiability_rationale": "The reviewer claims that the architecture is 'not clearly explained'. This statement, in itself, is not verifiable or 1. The reviewer is making a claim about the lack of explanation within the paper. However, the *reason* for this claim is not provided within this review point. There is no external reference or logical reasoning presented to support the claim that the explanation is lacking. The reference to Jiang et al. (2019) is external to this paper and does not address the verifiability of the explanation within this paper.", "helpfulness_rationale": "The reviewer's comment identifies a significant weakness in the paper: the lack of a clear explanation of the architecture used for the experiments. This is a concrete piece of feedback that directly points to an area where the authors need to improve their work. While the feedback is broad and doesn't offer specific suggestions, it is still helpful in guiding the authors to seek clarification or reorganize the relevant sections of their paper. The reviewer's comment highlights a practical issue that the authors can directly address."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the *metrics* BertScore and BLEURT and suggests a *standardization* of their naming. This directly identifies an action the authors could take.", "grounding_specificity_rationale": "The comment identifies the *metrics* BertScore and BLEURT, which can be considered 'grounded' as they are specific terms used in the paper. However, it does not specify *where* in the paper the inconsistent typesetting occurs or *why* it is a problem, making it only 'weakly specific'.", "verifiability_rationale": "The comment presents a *claim* that BertScore and BLEURT are inconsistently typeset. While it suggests a solution (standardization), it doesn't provide *evidence* or *justification* for this claim within the review point itself.", "helpfulness_rationale": "The comment identifies a *minor formatting inconsistency* and suggests a *simple solution* (standardization). While valid, it is a relatively small and specific point, making it 3 but not a major breakthrough in feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem ('it sounds unreasonable...') and suggests a solution ('providing more detail'). This is an explicit action to address a perceived issue.", "grounding_specificity_rationale": "The reviewer directly mentions the discrepancy between their results and the paper by Ni et al. This is a clear reference to a specific part of the literature. They are also referencing their own 'Wikipedia experiments,' which grounds the issue in their own work. The reviewer is very specific about the nature of the discrepancy: 'increasing model size can hurt the performance' vs. 'increasing model size usually improves performance.' They are also suggesting a specific action to investigate this ('providing more detail').", "verifiability_rationale": "The reviewer makes a clear claim: 'It sounds unreasonable that increasing the model size can hurt the performance, as recent paper Ni et al. shows that the scaling law is also apply to dense retrieval model, so the preliminary experimental results on Wikipedia about model size should be provided in detail.' This is a claim that requires verification. The reviewer provides a potential explanation (the cited paper, the Wikipedia experiments) as justification. However, they don't provide specific details about their experiments or the cited paper to actually verify the claim. The reasoning is present, but lacks concrete evidence.", "helpfulness_rationale": "The reviewer is directly addressing a potential issue the authors might be facing (discrepancy between results and literature). They are suggesting a concrete action (providing more detail). While the specific action isn't fully realized (no details are given), the suggestion is clear and directly addresses a potential problem. Therefore, it is helpful in that it points to a relevant area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer provides several specific suggestions for improvement, such as 'improve the management of Fig 3 and Table 2' and 'clarify the meaning of the '*' in Table 1'. These suggestions are direct and point to concrete actions the authors can take to address the identified weaknesses.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific elements of the paper that need improvement, such as 'Figs 1&2', 'tables with a \"\" for the method', and the 'Dataset' column in the tables. They also point to specific issues within these elements, like the management of figures and the meaning of a symbol. This strong focus on specific parts of the paper makes it fully grounded. The examples provided are clear and directly refer to specific sections or data.", "verifiability_rationale": "The reviewer makes a claim about the presentation quality being a weakness for a highquality publication. This is a clear statement of opinion. While the reviewer does not provide explicit external references to support this claim, the suggestions for improvement are based on common knowledge about good academic writing practices. For example, suggesting improvements in figure management or clarifying table elements are generally understood to be beneficial. Therefore, the claim is 3 based on common sense and best practices.", "helpfulness_rationale": "The reviewer explicitly states that some aspects of the presentation quality are a weakness for a highquality publication. This implies that the suggestions are intended to enhance the paper's impact and meet the standards of such publications. The suggestions are also quite direct and actionable, indicating that the reviewer believes the authors can easily implement them. Therefore, the review point is helpful in guiding the authors towards improving their presentation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their curiosity about *related experiments* that the *information axis tool* can help with. This directly points to a need for further clarification and suggests a concrete area for improvement in the paper. The action is to ask for more details on the tool's application, and it is concrete because it specifies *experiments* and the *information axis tool*.", "grounding_specificity_rationale": "The reviewer refers to the 'conclusion' of the paper when discussing the justification for the information axis. While they are pointing out a limitation in the paper's analysis, they do not specify a particular section, table, or figure within the conclusion that lacks clarity. The issue is the general lack of detail in the conclusion regarding the tool's application, not a specific missing element within a referenced section.", "verifiability_rationale": "The reviewer makes a claim that 'the paper uses much analysis to justify that the information axis is a good tool to be applied.' This is a claim that can be verified by examining the paper's structure and the logical flow of arguments. The reasoning is that analysis typically supports conclusions, and the commonsense argument is that the information axis is a logical tool for organizing information. While the reviewer doesn't provide specific examples of the analysis, the claim is generally verifiable through the paper's content.", "helpfulness_rationale": "The reviewer's question directly addresses a potential weakness in the paper's demonstration of the information axis tool's utility. By asking about *related experiments* that the tool can help with, they are prompting the authors to provide more concrete evidence of the tool's effectiveness. The suggestion is to explore the tool's application in a practical setting, which is a valuable direction for improvement. The request is specific to *experiments* and the *information axis tool*."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment is explicit about the *possibility* of other multilingual pretraining setups struggling with Greek, but it doesn't provide a concrete action or suggestion on how to address this. While it raises a valid point, it doesn't directly guide the authors on what changes to make. The suggestion is general and doesn't offer specific steps.", "grounding_specificity_rationale": "The comment refers to 'other multilingual pretraining setups' generally, without specifying which part of the paper or model this relates to. It doesn't point to a specific section, table, figure, or unique element within the paper. Therefore, it is 1 in the specific context of the reviewed work.", "verifiability_rationale": "The comment contains a claim ('I\u2019d be interested to know if other multilingual pretraining setups also struggle with Greek'), but it lacks supporting evidence or justification. It doesn't provide any logical reasoning, common knowledge, or external references to back up the idea that other setups might struggle with Greek. Therefore, it is 1 based on the information provided.", "helpfulness_rationale": "The comment is concise and raises a relevant question about the limitations of current multilingual pretraining models in handling Greek. While it doesn't offer a solution, it prompts the authors to consider this potential issue and potentially investigate further. By highlighting a potential area for improvement or further exploration, it provides some degree of helpfulness."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem ('difficult for readers to understand and evaluate') but does not explicitly state what action the authors should take to address it. While it points to a need for clarification, it doesn't provide a concrete step like 'Rewrite the sentence' or 'Provide more context'.", "grounding_specificity_rationale": "The review point explicitly refers to 'the text in line 293295', which grounds the comment to a specific part of the paper. However, it does not specify *what* is unclear within that part. The comment states 'difficult for readers to understand and evaluate' which is a general statement about the text, not a specific issue.", "verifiability_rationale": "The review point makes a claim ('difficult for readers to understand and evaluate') but does not provide any evidence or justification for this claim. It is a statement of observation rather than a claim that requires verification.", "helpfulness_rationale": "The review point identifies a genuine issue \u2013 the lack of clarity in a specific section of the paper. This information is valuable for the authors as it highlights an area that needs improvement. While it doesn't offer a solution, pointing out a problem is a helpful first step in guiding authors towards better drafts. It is not unhelpful, but it lacks concrete suggestions."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what needs to be improved or how. It only points out that some explanations are vague. Authors are left to infer the need for improvement rather than being given a clear action.", "grounding_specificity_rationale": "The review point explicitly mentions 'the last paragraph of Section 3 (lines 207210) on the single image case', clearly identifying the specific part of the paper being addressed. This can be achieved through literal mentions of sections, tables, figures, etc.", "verifiability_rationale": "The review point is a statement of observation, not a claim requiring verification. It states something is unclear, not something that needs justification. There are no logical reasoning, common knowledge, or external references being presented as a claim.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper's explanation, making it 3 as a pointer to an area for improvement. However, it doesn't offer a concrete solution, making it less helpful. Authors are informed of a problem but not given a specific action to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of considering only one truck and one drone and suggests extending it to multiple trucks and drones. This is an explicit statement of a problem and a clear action (extension) that could be inferred. Therefore, it is 5.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'ONE truck' and 'ONE drone' when stating the limitation. This is a clear and precise identification of the specific part being addressed. The suggestion to extend to 'multiple trucks and drones' further specifies the area for improvement. Therefore, the grounding is fully specific.", "verifiability_rationale": "The reviewer makes a statement about the limitation and suggests a potential improvement. While the suggestion is relevant to the paper's topic, the reviewer does not provide any specific evidence or reasoning to support the claim that extending to multiple trucks and drones would be 'easy' or 'more interesting'. The claim is presented as a suggestion rather than a verifiable statement based on the paper's content. Therefore, it is 2.", "helpfulness_rationale": "The reviewer points out a limitation in the scope of the work (considering only one truck and one drone) and suggests a valuable direction for future work (extending to multiple trucks and drones). This is a clear and helpful comment that identifies a potential area for improvement. While it doesn't provide specific details, it highlights a relevant issue and proposes a meaningful extension. Therefore, it is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the proposed approach to pretraining has 'limited novelty' and that it 'more or less just follows the strategies used in ELECTRA.' This statement is explicit about the lack of novelty and the similarity to ELECTRA strategies. While the reviewer identifies a potential weakness, they don't specify exactly what needs to be changed or how to implement the suggested improvement. The action is stated, but the details are missing.", "grounding_specificity_rationale": "The reviewer mentions 'the strategies used in ELECTRA' when criticizing the proposed approach. This provides a specific reference point, indicating that the reviewer is grounded in a particular aspect of the ELECTRA method. However, the reviewer does not specify which part of the paper or method being criticized lacks novelty or how it relates to the ELECTRA strategies. The grounding is present but not fully detailed.", "verifiability_rationale": "The reviewer makes a claim: 'the proposed approach to pretraining has limited novelty' and 'it more or less just follows the strategies used in ELECTRA.' This constitutes a claim that requires verification. However, the reviewer only states that it follows ELECTRA strategies without providing specific examples, references, or logical reasoning to support this claim. The claim is present, but the supporting evidence is lacking.", "helpfulness_rationale": "The reviewer points out a potential weakness in the proposed approach to pretraining, specifically the lack of novelty and the similarity to ELECTRA strategies. This directly identifies an area for improvement in the paper. While the criticism is clear, it doesn't offer concrete suggestions or propose specific changes to address the identified weakness. The weakness is acknowledged, making it helpful in highlighting potential issues."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the weakness: 'The motivation/need for the Newton algorithm in section 4 was somewhat lacking I felt.' This is a clear indication of an actionable point. The reviewer also suggests a specific improvement: 'This is essentially just a 1dimensional line search on a convex function, so even something as basic as a bisecting line search will converge linearly. While of course quadratic convergence is better than linear convergence, how much of an impact does this actually make on the runtime of the algorithm? Experiments along these lines would help motivate the need for the analysis/algorithm.' This suggests a concrete action the authors should take.", "grounding_specificity_rationale": "The reviewer mentions 'section 4' when stating the perceived lack of motivation, which indicates some level of grounding. However, the reviewer does not pinpoint the exact sentence, paragraph, or unique element within section 4 that lacks motivation. The suggestion to compare with line search is general and doesn't specify where in section 4 the Newton algorithm's motivation is lacking. Therefore, while the reviewer identifies a relevant section, the specificity of the grounding is limited.", "verifiability_rationale": "The reviewer claims that the motivation for the Newton algorithm in section 4 is lacking. They then suggest an experiment comparing it to a line search as evidence. However, the reviewer does not provide specific details about the experiment, such as the functions to be used, the metrics to be analyzed, or the expected outcomes. While the suggestion points towards a way to verify the motivation, the lack of concrete details makes the claim somewhat underspecific. The reviewer is essentially stating that the paper needs to *show* the benefit of Newton's method over simpler alternatives, but doesn't fully demonstrate it.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper: the lack of motivation for the Newton algorithm. They also offer a suggestion for improvement: conducting experiments comparing the Newton algorithm to a line search. While the suggestion is somewhat general (it doesn't specify the functions or metrics to be used), it directly addresses the identified weakness and provides a clear direction for the authors to take. The reviewer is not just pointing out a problem; they are also proposing a concrete way to solve it, even if the specifics of the solution are not fully elaborated."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states an observation: 'For the majority of language and score combinations (see Figure 3), the impact that the methods have on idiomatic vs random data is similar; hence the proposed MT modelling methods seem far from idiomspecific.' This observation is then followed by a clear action: 'Therefore, the results simply appear to indicate that \"better NMT systems are also better at idiomatic translations\".' The reviewer directly tells the authors what to do next, which is to reevaluate the results with idiomspecificity in mind. The action is concrete and directly addresses the identified weakness.", "grounding_specificity_rationale": "The review point identifies the *methods* (upweighing and KNN) and their *impact* on *idiomatic vs random data*. While the reviewer highlights a potential issue with the interpretation of the results, they do not explicitly pinpoint a specific section, table, or unique aspect of the paper that this concern directly relates to. The connection to idiomatic vs random data is implied but not directly stated as a specific part of the paper. The reviewer's focus is on the *outcome* of the methods rather than a specific location within the paper where this outcome is discussed.", "verifiability_rationale": "The review point presents a claim: 'For the majority of language and score combinations (see Figure 3), the impact that the methods have on idiomatic vs random data is similar; hence the proposed MT modelling methods seem far from idiomspecific.' This is a claim that requires justification. The reviewer suggests that the similar impact indicates the methods are not idiomspecific, implying a different interpretation than the authors. While the reviewer points to a potential issue, they do not provide specific examples from the paper where this similarity is observed or external references to support their claim about the methods not being idiomspecific. The reasoning is present but lacks concrete evidence.", "helpfulness_rationale": "The review point raises a valid concern about the interpretation of the results and suggests an alternative perspective. The reviewer points out that the similar impact of the methods on idiomatic and random data might indicate that the methods are not idiomspecific. This is a constructive critique that highlights a potential area for further investigation. However, the reviewer does not offer a concrete solution or a clear path forward for the authors. The helpfulness is conditional on the authors being able to independently verify the reviewer's point and explore the alternative interpretation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the incorrect dimensions of the resulting volume (WxHx1) and identifies the bias as a scalar. It also points out the discrepancy with the observed 'C' biases in the feedforward models described in section 3.4. This provides a clear and actionable indication of what is wrong and how it should be corrected.", "grounding_specificity_rationale": "The review point explicitly mentions 'section 3.4' and refers to the 'feed forward models' within that section. It also specifically mentions the 'C biases', indicating a precise identification of the part of the paper being addressed and the specific issue within it.", "verifiability_rationale": "The review point presents a claim that the resulting volume should be WxHx1 and the bias is a scalar, which is a logical deduction based on the described model architecture (WxHx1). It also highlights the confusion arising from the observation of 'C' biases in the feedforward models, providing a clear and logical observation that can be verified by examining the model description in section 3.4.", "helpfulness_rationale": "The review point is 5 as it directly identifies a specific inconsistency in the model description. It points out the mismatch between the described volume dimensions and the observed number of biases. This allows the authors to pinpoint the exact location and nature of the problem, facilitating debugging and correction."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a concrete change to Equation 8, stating 'In addition, in Equation 8, if s contains dynamic factors, subtracting s from the dynamic information may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. Instead, it would be beneficial to include dynamic factors in Equation 8 rather than subtracting s.' This clearly indicates an action to be taken and a specific location where the change should be made. The action is to 'include dynamic factors' in Equation 8, which is a direct and actionable suggestion.", "grounding_specificity_rationale": "The review point explicitly refers to 'Equation 8' and states a specific issue related to it: 'if s contains dynamic factors, subtracting s from the dynamic information may result in the loss of some dynamic information...'. This clearly identifies the specific part of the paper being addressed. The reviewer is not making a general comment but rather focusing on a particular equation and a specific problem within it.", "verifiability_rationale": "The review point makes a claim about the potential consequence of subtracting 's' from dynamic information in Equation 8 if 's' contains dynamic factors. This claim is verifiable through logical reasoning. If 's' indeed contains dynamic information and you subtract it, that dynamic information will be lost. This is a logical deduction based on the understanding of subtraction and information content. While no external references are provided, the reasoning is based on fundamental mathematical principles.", "helpfulness_rationale": "The review point is 5 as it directly addresses a potential issue in the author's work (Equation 8) and offers a constructive suggestion for improvement. It doesn't just criticize but offers a specific and actionable remedy. The reviewer is providing guidance on how to potentially improve the handling of dynamic information in Equation 8, which is directly relevant to the identified problem."}
{"actionability_label": "2", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question about the relationship between MC samples, performance, and network structure. It doesn't explicitly state an action or provide a concrete step for the authors to take. While it implies an area for improvement, the specific action isn't defined.", "grounding_specificity_rationale": "The review point is a question about the relationship between MC samples, performance, and network structure. It doesn't explicitly identify a specific part of the paper or methodology being discussed. It's a general question about empirical findings.", "verifiability_rationale": "The review point is a question, not a claim that needs verification. It doesn't present a statement that requires supporting evidence or justification.", "helpfulness_rationale": "The review point is a question that encourages the authors to investigate the empirical relationship between MC samples, performance, and network structure. While it doesn't directly provide the answer, it points to a potential area for improvement and encourages further research. It provides a direction for the authors to take."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3 (because it identifies sections, but not specific actions within them)", "verifiability_label": "3 (because it points to a potential source, but lacks the specific verification)", "helpfulness_label": "3 (because it points to a missing verification, but the claim itself is clear)", "actionability_rationale": "The review point states 'there are no direct comparisons with it in either the language or vision tasks used to evaluate the proposed approach' and 'without a direct comparison of test accuracy it is unclear if this approach is indeed an improvement over the baseline that it directly modifies.' This points to a missing element rather than a specific, actionable suggestion. The reviewer doesn't tell the authors *what* to compare or *how* to make the comparison.", "grounding_specificity_rationale": "The review point *identifies* the *areas* where comparisons *could* be made (Sections 3.4 and 3.5) but doesn't specify *what* within those sections should be compared. While it points to specific sections, it doesn't pinpoint the exact elements within those sections that are relevant for the comparison. The lack of a direct test accuracy comparison also contributes to this.", "verifiability_rationale": "The review point makes a claim: 'there are no direct comparisons with it in either the language or vision tasks used to evaluate the proposed approach' and 'without a direct comparison of test accuracy it is unclear if this approach is indeed an improvement over the baseline that it directly modifies.' This claim is not fully supported by the provided text. While the reviewer identifies potential sources of information (Sections 3.4 and 3.5), they don't provide the *evidence* (the direct test accuracy comparison) to verify their claim.", "helpfulness_rationale": "The review point criticizes the lack of a 'direct comparison of test accuracy' and argues that this makes it 'unclear if this approach is indeed an improvement over the baseline.' This directly points to a missing piece of information that is crucial for evaluating the effectiveness of the proposed approach. Without this comparison, the authors don't have a clear metric to assess the improvement (or lack thereof) of their approach over the baseline."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggestion. It raises a question about the generalizability of the method and asks for clarification on the selection of event types. While these are relevant questions, they don't directly instruct the authors on how to improve their draft. The reviewer is asking for information or an opinion, not a direct instruction.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. The questions are about the method's applicability in general and the selection process of event types, not about a particular section or table in the paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point raises questions about the selection of event types. While it doesn't explicitly state a claim that requires verification, the reviewer is asking for justification for a methodological choice. The verifiability depends on whether the paper provides a clear rationale for the 21 event types. If the rationale is missing or unclear, the reviewer's concern is valid and verifiable by checking the paper's methodology section. However, without more information about the paper's content, it's difficult to definitively assess the verifiability of this specific point.", "helpfulness_rationale": "The review point raises valid questions about the generalizability of the method and the selection of event types. These are relevant concerns for authors who might want to apply or build upon the work. However, the questions themselves are not directly providing actionable feedback on a specific weakness in an author's draft. They are more about clarifying the methodology. While the questions are relevant, they don't immediately empower the authors to improve their specific work."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the claim about the importance of language modeling and identifies the weakness of the current experiments. They also suggest specific tasks (language modeling, machine translation, or text summarization) that would be more appropriate. The action is clearly stated, and the suggestion for improvement is concrete.", "grounding_specificity_rationale": "The reviewer identifies the specific area of the paper being criticized \u2013 the 'experiments' section, particularly the tasks in section 5.3. They also specify the *types* of tasks that would be more appropriate (language modeling, machine translation, or text summarization). This shows both grounding the issue in a specific part of the paper and specifying the desired outcome.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the current experiments in reflecting language modeling capabilities. They provide a logical argument connecting the chosen tasks (word similarity and SquAD) to the importance of language modeling. While they don't provide external references in this specific point, the reasoning is based on established understanding of language modeling.", "helpfulness_rationale": "The reviewer provides a clear criticism of the experimental setup and offers specific, actionable suggestions for improvement. They directly link the identified weakness to the need for more language modelingfocused tasks. This makes the review 5 for the authors to understand and rectify their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1. 1", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'cite and discuss'. While it doesn't specify *how* to cite or discuss, the action itself is clear. Therefore, it is considered explicit. However, the lack of detail makes it 3 rather than 5.", "grounding_specificity_rationale": "The review point refers to 'important references for domain adaptation' without specifying which section, table, figure, or unique element within the paper this pertains to. The reference is general, making the grounding weak. It is 1 at all in a specific part of the paper.", "verifiability_rationale": "The review point contains a claim: 'This paper lacks some very important references for domain adaptation'. It also provides a suggestion for improvement: 'cite and discuss'. This suggests a logical reasoning and a concrete action, making the claim verifiable.", "helpfulness_rationale": "The review point is directly relevant to the authors, identifying a clear weakness ('lack of important references') and providing a constructive suggestion ('cite and discuss'). This feedback is actionable and wellsupported, making it 5 for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks a question about a specific detail ('EMAweighting') in a specific part of the paper ('other baseline models') and a specific table ('Table 3'). This constitutes an explicit action, as the reviewer is directly asking about a specific implementation detail. The action is also concrete, as the reviewer is asking about the *presence* of EMAweighting, which is a clear and actionable piece of information for the authors.", "grounding_specificity_rationale": "The reviewer is asking about a specific aspect of the experimental setup (EMAweighting) for a specific set of models (baseline models) in a specific table (Table 3). While the *section* might be implicitly the experimental setup, it is not explicitly stated as 'Section 4.2 or 4.3 or Table 3'. The grounding is weak because the exact location isn't explicitly mentioned. However, the specificity is high as the reviewer is asking about a very specific detail.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a question posed to the authors, not a statement that needs evidence. Therefore, it does not fit into the 'Verifiability' aspect, which focuses on the presence and support of claims.", "helpfulness_rationale": "The review point identifies a potential ambiguity in the paper regarding the use of EMAweighting for baseline models in Table 3. This is a valuable piece of information for the authors to clarify. While the review point itself doesn't directly provide a solution, it highlights a potential area for improvement in the paper's presentation of the experimental details. It is 3 because it points to a specific detail that the authors should consider for a fair comparison."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the 'lucky' outcome on domain pricing is suspicious, which is an explicit action. However, the reviewer does not specify how to verify this suspicion or what steps the authors should take to investigate further. The action is identified, but the method of verification and application is vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the SCNN model' and 'domain pricing' when stating that the 'lucky' outcome is suspicious. This clearly identifies the specific part of the paper being addressed, making the grounding fully grounded. The comment also specifies the area of concern (SCNN on domain pricing and the 'lucky' outcome), making the specificity specific.", "verifiability_rationale": "The reviewer makes a claim that the 'lucky' outcome on domain pricing is suspicious. This claim is verifiable because the reviewer suggests investigating the hyperparameter tuning range and the distance to the next best model. While the reviewer provides some direction for verification, they do not offer concrete examples or a detailed methodology for how to determine if the distance is 'suspiciously large'. The claim has some justification, but it lacks key elements like specific examples or detailed methodology.", "helpfulness_rationale": "The reviewer raises a valid concern about the SCNN's performance on domain pricing. However, the comment does not provide specific guidance or suggestions for the authors to address this concern. While the issue is identified, the reviewer does not offer a clear path for the authors to investigate or resolve it, making the feedback somewhat limited in its helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment states that some aspects of the experimental setup were unclear or poorly motivated, but it does not explicitly state which aspects or how to improve them. The phrase 'see details below' indicates that the information is not immediately available. Therefore, the action is implicit and needs to be inferred.", "grounding_specificity_rationale": "The comment mentions 'the experimental setup', 'corpora', and 'datasets', which could be considered a form of grounding. However, it does not specify which particular part of the experimental setup, corpora, or datasets is unclear or poorly motivated. The information is not precisely identified.", "verifiability_rationale": "The review point states that 'some aspects of the experimental setup were unclear or poorly motivated' and refers to 'details below'. This is a statement of observation, not a claim that requires verification. There is no explicit claim being made in this review point.", "helpfulness_rationale": "The review point identifies a potential issue with the experimental setup but does not provide specific, actionable feedback or suggestions within the scope of the current review point. It sets expectations for more information to be provided later. Therefore, it does not directly help the authors improve their draft at this stage."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The statement is explicit about the lack of improvement, but it is vague about the nature of the improvement and how it could be addressed.", "grounding_specificity_rationale": "The comment refers to 'existing RL method' generally, not a specific section, table, or unique aspect of the paper. It does not specify what is lacking in the improvement.", "verifiability_rationale": "The comment contains a claim ('The improvement of the proposed method over existing RL method is not impressive') but does not provide any evidence or reasoning to support this claim.", "helpfulness_rationale": "The review points out a weakness but does not offer specific suggestions or guidance on how to improve the proposed method. It is a subjective assessment without actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the size of the hourglass modules, which implies a lack of this information in the authors' current draft. While the reviewer doesn't explicitly state what should be done with this information, the act of identifying a missing detail is a form of implicit actionability. However, the reviewer doesn't provide concrete guidance on how to obtain this information, making it less actionable than a statement that directly tells the authors where to find the data.", "grounding_specificity_rationale": "The reviewer explicitly mentions '4 hourglass modules' in the context of the model architecture. This demonstrates strong grounding specificity as the reviewer can accurately pinpoint the referenced part of the paper. The reviewer also identifies a missing detail (the size of each module) within this specific part.", "verifiability_rationale": "The reviewer states a fact: 'The authors mention that the model consists of 4 hourglass modules, but do not say how big each hourglass module is.' This constitutes a claim that there is missing information. However, the reviewer does not provide any external references or logical reasoning to support this claim within the review point itself. The claim is based on the authors' statement, making it 3 but lacking strong external support within the review.", "helpfulness_rationale": "The reviewer points out a missing detail in the authors' description of their model. While this is a valid observation, it doesn't directly tell the authors how to improve their draft. The authors would still need to go back and find the information about the size of the hourglass modules. Therefore, this review point identifies a gap in the information provided but doesn't offer a direct solution or actionable advice on how to address that gap."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a specific formula for the dimensions of the projection matrices and claims it's incorrect, suggesting it prevents projection. This is a direct statement of a potential issue.", "grounding_specificity_rationale": "The reviewer provides a specific formula for the dimensions and explains *why* they think it's wrong, making the grounding very clear.", "verifiability_rationale": "The reviewer states a claim about the matrix dimensions and provides a reasoning based on the mechanics of projection. While not backed by a citation, the reasoning is logical.", "helpfulness_rationale": "The reviewer highlights a specific, technical detail that, if correct, would be valuable information for the authors to understand the limitations of their method."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point identifies a characteristic of the proposed method (PACE) but does not explicitly instruct the authors on what to do with this information. While it states that PACE is a 'diagnostictype prediction,' it doesn't ask the authors to verify this or provide a direct action based on this finding.", "grounding_specificity_rationale": "The review point directly names 'PACE' and 'diagnostictype prediction,' providing clear and specific information about the method being discussed. It explicitly mentions the section or aspect being addressed.", "verifiability_rationale": "The review point makes a claim about PACE being a 'diagnostictype prediction' without providing any supporting evidence, references, or logical reasoning to back this assertion. It presents a statement without justification.", "helpfulness_rationale": "The review point highlights a distinction between PACE and prior work (ClimateBench, ClimateSet) regarding the 'diagnostictype prediction' aspect. While it points out this difference, it doesn't directly instruct the authors on how to incorporate this information into their work, making it less immediately actionable for them."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the paper's metric learning theory doesn't give better results than existing generalization theory and that the metric perspective isn't working. While these are direct statements about the paper's content, they are general and lack specific details about which results are not better or which aspects of the metric learning are not working. The reviewer points to the 'metric learning theory in this paper' and 'generalization theory of neural networks' but doesn't explicitly state which section or table is being referred to. Therefore, the reviewer's point is explicit but vague, making it 2.", "grounding_specificity_rationale": "The reviewer refers to 'metric learning theory' and 'generalization theory of neural networks' which are general concepts. While they mention 'metric learning' as the area of concern, they don't explicitly point to a specific section, table, or unique element within the paper that they believe lacks grounding. The reviewer's statement is about the content of the paper in general, rather than pinpointing a specific part. Therefore, the grounding is weak, although the reviewer does identify a specific area of concern, making it partially specific.", "verifiability_rationale": "The reviewer makes a claim that the paper's metric learning theory doesn't give better results and that the metric perspective isn't working. However, the reviewer does not provide any evidence, examples, or references within this review point to support these claims. The statements are presented as opinions without logical reasoning or external references. Therefore, the claim is not verifiable within this review point.", "helpfulness_rationale": "The reviewer's comment is specific to the theoretical contribution of the paper regarding metric learning. While this is valuable feedback for the authors, it is a very narrow and specific concern. The reviewer doesn't provide general suggestions or improvements for the paper as a whole, only critiques a specific aspect. The helpfulness is limited to the specific area of concern, but it lacks broader guidance. Therefore, the helpfulness is 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer's comment is explicit in stating the desired changes: 'move visual results from supplementary to the main paper' and 'condense architecture figures'. These actions are also concrete, specifying the location of the visual results and the type of figures to be condensed. Therefore, the reviewer provides clear instructions for the authors to follow.", "grounding_specificity_rationale": "The reviewer does not explicitly identify the specific part of the paper where the visual results or architecture figures are located. While they suggest improvements to the 'main paper' and the 'experiment of the paper,' this is a general statement. Therefore, the grounding is weak. The specificity of the suggestion is also low; the reviewer doesn't specify *which* visual results or *how* the architecture figures should be condensed.", "verifiability_rationale": "The reviewer's comment is not a claim that requires verification. They are suggesting improvements to the presentation of the paper, not stating that something is wrong or needs to be changed. Therefore, there is X to verify, making it 'X'.", "helpfulness_rationale": "The reviewer's comment provides a suggestion for improvement, specifically regarding the presentation of visual results and architecture figures in the paper. While it doesn't directly identify a flaw in the authors' work, it offers a concrete direction for enhancing the manuscript. Therefore, it is helpful but not a critique that would directly guide the authors in fixing a problem."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a potential source of confusion regarding the notation used for risk in minimization and minimax problems. They suggest making this distinction clearer. This is a direct and actionable suggestion, falling under the 'Explicit' category as the reviewer proposes a specific action to address the issue. The 'Concrete' aspect is also met as the reviewer suggests a specific action (clarifying the distinction) and even points to the specific terms (r and primal risk) involved.", "grounding_specificity_rationale": "The reviewer points out a potential source of confusion related to the notation for risk in minimization and minimax problems. However, they do not explicitly identify the specific section, table, or unique aspect of the paper where this confusion might arise. They are making a general comment about the notation. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The reviewer makes a claim about a potential confusion regarding the notation for risk in minimization and minimax problems. However, they do not provide any specific evidence or references to support this claim. They are stating a potential issue without demonstrating its existence or providing a solution. Therefore, the claim is not verifiable as there is no logical reasoning, common knowledge, or external references provided to support the statement.", "helpfulness_rationale": "The reviewer's suggestion to clarify the distinction between using 'r' for minimization problems and 'primal risk' for minimax problems is directly aimed at improving the clarity and reducing potential confusion for the authors. It is a constructive suggestion that directly addresses a potential area of misunderstanding. Therefore, it is 5 as it provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests using the American corpus to explain the British patient and asks if the corpus residual value can detect this. While the suggestion is an action, the reviewer does not explicitly state *how* to apply this action. The connection between identifying the potential corpus mismatch and the specific action of using the American corpus is implied but not clearly defined. Therefore, it is not fully actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the patient of Figure 8' and 'Figure 8'. This is a specific part of the paper. While the reviewer doesn't provide the exact section or table number, the reference to a specific figure is a strong indicator of grounding. The comment also specifies what needs to be addressed: 'how to potentially explain it'. This specificity goes beyond just identifying the part and details the issue within it. Therefore, it is 5.", "verifiability_rationale": "The reviewer proposes using the American corpus and corpus residual analysis to investigate the potential mismatch. This involves external references and a logical reasoning process. While the *application* of this method to this specific problem might require further justification, the *method itself* is grounded in existing concepts. Therefore, it is 4.", "helpfulness_rationale": "The reviewer directly asks a question about a potential issue (the difference in the patient's characteristics) and suggests a method to investigate it (using the American corpus and corpus residual analysis). This clearly identifies a weakness and provides a suggestion for improvement. The question itself is a strong indicator of helpfulness. Therefore, it is 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a suggestion to use a different dataset (WebQuestions) and provides a reason for this suggestion (weak supervision). While it doesn't identify a specific weakness in the current dataset, it clearly states an action (switching datasets) and provides a rationale for this action.", "grounding_specificity_rationale": "The reviewer explicitly mentions the dataset 'WebQuestions' and the reason for the suggestion 'since NSM only requires weak supervision'. This indicates strong grounding as the specific part of the paper (the dataset choice) is clearly identified, and the reason for the suggestion is also clearly stated.", "verifiability_rationale": "The review point presents a suggestion and a justification for that suggestion. While it doesn't present a claim that requires verification, it does offer a rationale for a change. The 'justification' is the reason for the suggestion (weak supervision). The suggestion itself is a claim that the authors should consider using a different dataset.", "helpfulness_rationale": "The review point suggests a change to the dataset used in the experiments. While it doesn't explicitly state why the current dataset was chosen or identify a specific weakness, it offers a concrete alternative ('WebQuestions') and a reason for considering it ('weak supervision'). This suggests a potential improvement or a point for discussion that could be helpful for the authors in refining their approach or making it more comparable to other work. The suggestion is actionable, even if it lacks a definitive justification for the current dataset's choice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2: Borderline Helpfulness", "actionability_rationale": "The reviewer raises a question about the desirability of sparsity, which is an implicit statement rather than an explicit instruction. While the reviewer clearly states their confusion, they don't directly say 'I don't understand how to apply this' or 'Do this'. The implicit nature makes it less actionable than a direct instruction. However, the reviewer does state that the connection between sparsity and better performance needs to be demonstrated, which is a concrete action the authors could take. The reviewer's statement 'I don't really see the need to make such claims' indicates a lack of clarity in the paper's motivation for introducing sparsity, making it difficult for the authors to understand the underlying reasoning.", "grounding_specificity_rationale": "The reviewer mentions 'sparsity in training' and 'training is not obvious that sparsity is desirable.' This indicates a weak grounding as the reviewer can identify the concept of sparsity in the training context, but they cannot confidently pinpoint the exact section, table, or unique aspect being addressed. The reviewer's subsequent elaboration on the potential benefits of sparsity (larger networks, reduced FLOPs) adds to the specificity of their concern, even though it's framed as a question of necessity rather than a direct critique of a specific claim. The reviewer is asking about the *motivation* behind a claim, not directly pointing to a specific element within the paper.", "verifiability_rationale": "The review point does not contain a claim that requires verification. The reviewer is raising a question about the *motivation* for introducing sparsity, not making a statement that needs to be supported by evidence. The paper presumably claims that sparsity is useful, and this review point questions that claim. Therefore, it is not '1'. It is more of a critique of a claim's justification rather than a claim itself.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper by questioning the motivation for introducing sparsity. While it highlights an area for improvement in the paper's presentation, it does not offer a concrete suggestion or critique that would directly help the authors improve their draft. The reviewer is pointing out a lack of clarity, not proposing a solution. Therefore, it is not 5 as it does not directly address how the authors should modify their work. It is also not 'unhelpful' because it does identify a potential issue."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the limitation in novelty and the use of existing techniques (attention for motion learning). While it identifies a weakness, it doesn't provide specific, actionable steps for the authors to take. The reviewer points out a gap in the contribution.", "grounding_specificity_rationale": "The review point mentions \"attention for motion learning\" as a basis for the design. This provides some level of grounding as the reviewer identifies a specific aspect of existing work that is being referenced. However, it doesn't explicitly state that the design *relies* on this specific mechanism or point to a specific part of the design that is affected by this lack of novelty.", "verifiability_rationale": "The review point makes a claim: \"Novelty is limited.\" This is a subjective assessment. While the reviewer provides a reason (\"attention for motion learning has been widely used\"), this is presented as a justification for the limited novelty, not as evidence *of* it. There's no logical reasoning, common knowledge, or external references provided to support the claim that novelty is limited. Therefore, it's not 5.", "helpfulness_rationale": "The review point identifies a significant limitation in the novelty of the work and the design. It alerts the authors to a potential gap in their contribution. While it doesn't offer specific, actionable steps, it highlights a crucial area that needs attention. This provides some level of helpfulness by informing the authors about a potential weakness."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the need to 'verify the effectiveness of the framework on ImageNet1k or even ImageNet100' and suggests 'presenting these results in the main paper'. This is a clear and direct action for the authors to take. While the action itself is somewhat vague (e.g., 'verify effectiveness'), the reviewer implicitly suggests a specific type of verification (e.g., performance metrics, ablation studies). The authors know exactly what they should do and what kind of results are needed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'ImageNet1k or even ImageNet100' as the specific datasets to analyze. This allows the authors to accurately identify the referenced part of the paper. The reviewer also suggests 'presenting these results in the main paper', which is a specific instruction about where to place the findings. The grounding is strong, and the specificity is good, as the datasets are clearly named.", "verifiability_rationale": "The reviewer suggests 'perform analysis on other datasets' and provides examples (ImageNet1k/100) and mentions 'similar to CIFAR derivatives'. This provides a clear claim that the framework's performance needs to be evaluated on more complex datasets. The reviewer also suggests 'presenting these results in the main paper', which provides a justification for why this analysis is needed. The claim is wellsupported by logical reasoning (the framework should generalize) and common knowledge (performance on standard benchmarks is important). External references are not explicitly mentioned, but the general principle of benchmarking is wellestablished in the field.", "helpfulness_rationale": "The review point directly identifies a gap in the paper's results by pointing out the lack of analysis on other datasets. It suggests a concrete and valuable next step for the authors: performing analysis on datasets like ImageNet1k/100. This is a helpful suggestion because it addresses a potential limitation of the framework and encourages the authors to validate its generalizability. The suggestion is clear, actionable, and likely to improve the paper's overall quality and impact."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem 'Unclear model design' and provides concrete suggestions for improvement by 'providing a plot of model illustration, pseudocode table, or code repository'. These suggestions are clear actions that the authors should take to address the identified issue.", "grounding_specificity_rationale": "The reviewer mentions 'model design' generally, which is a broad concept. While the suggestion to provide 'details' is implied, the initial mention of 'model design' itself is not specific to a particular part or detail within the model. The authors would need to infer which part of the model design is unclear.", "verifiability_rationale": "The review point contains a claim that 'model design is unclear' and suggests verifiable actions to address this claim by 'providing a plot of model illustration, pseudocode table, or code repository'. These actions are verifiable through visual inspection, logical analysis, and code examination.", "helpfulness_rationale": "The review point is 5 because it directly identifies a clear weakness ('unclear model design') and provides standard and verifiable solutions ('plot of model illustration, pseudocode table, or code repository'). This directly addresses the authors' need for improved clarity and reproducibility."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a discrepancy between the Abstract/Introduction and the Experiments section regarding the treatment of BigFive and MBTI. While the Abstract/Introduction suggests they are models to be extended, the Experiments section treats them as datasets. This is an implicit actionability, as the reviewer is highlighting a potential inconsistency in the paper's framing. However, the reviewer does not explicitly state how this discrepancy should be addressed or what the implications are, making it partially actionable.", "grounding_specificity_rationale": "The reviewer's comment is general and does not specify which part of the paper is affected by the discrepancy between the treatment of BigFive and MBTI in the Abstract/Introduction and Experiments sections. The reviewer is broadly pointing out a potential inconsistency. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer states a potential inconsistency or lack of justification regarding the use of BigFive and MBTI. This constitutes a claim that could be verified by examining the paper's content. The reviewer identifies the inconsistency (treatment as models vs. datasets) and suggests an explanation (lack of justification). This claim is 3 as the reasoning and common knowledge aspects are present, but the reviewer does not provide specific examples or references to external works.", "helpfulness_rationale": "The reviewer highlights a potential area for clarification and improvement in the paper's structure and justification. By pointing out the discrepancy between the models/datasets treatment in different sections, the reviewer provides a suggestion for improvement. However, the comment itself does not directly instruct the authors on how to fix the issue, making it 3 as it points to a potential problem that needs addressing."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a missing piece of information (rejection rate) but doesn't provide a direct action for the authors to take based on this observation.", "grounding_specificity_rationale": "The reviewer mentions 'experiments' without specifying which ones, making it unclear what information is missing and how to address it.", "verifiability_rationale": "The reviewer states that the rejection rate is not shown and offers a potential interpretation ('One could view a misclassification as a rejection...'). This provides some context, making the claim 3.", "helpfulness_rationale": "The reviewer identifies a missing piece of information, which could be relevant, but they don't offer actionable steps for the authors to take because this information is missing."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation in the paper's discussion of applying DIMES to the Traveling Salesman Problem (TSP) and suggests further experiments. While the reviewer doesn't provide explicit instructions on *what* to do, they identify a gap and propose a potential solution. This suggests an action towards further investigation, making it 3.", "grounding_specificity_rationale": "The reviewer mentions 'generalization to the specific TSP instances' and 'DIMES's own advantages'. While the paper likely discusses generalization, the reviewer doesn't explicitly state which specific part of the paper (e.g., a section, table, or unique aspect) is being addressed. The mention of 'DIMES's own advantages' could be interpreted as a general statement about DIMES, making the grounding less precise. Therefore, it can be considered 3.", "verifiability_rationale": "The reviewer suggests a 'comparison of DIMES with other methods on TSP100 (indistribution testing performance) with/without metalearning'. This constitutes a claim that DIMES performs well indistribution. However, the reviewer doesn't provide any logical reasoning, common knowledge, or external references to support this claim within the review point itself. The suggestion is presented as a potential experiment rather than a verified claim. Therefore, it is not 5.", "helpfulness_rationale": "The reviewer raises a valid point about the generalization gap in applying DIMES to TSP and suggests further experiments. This points to a potential area for improvement in the paper. While the reviewer doesn't provide immediate, concrete steps for the authors to take, they offer a direction for further investigation. This makes the point 3 in identifying a research gap."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks for information about the 'final thresholds' and 'hyperparameters'. This is a direct and clear request for specific details, making it 5. The reviewer can directly identify the information they are seeking and how it would be applied (to improve the draft).", "grounding_specificity_rationale": "The reviewer mentions 'thresholds' and 'hyperparameters', which are specific concepts. However, they do not explicitly point to a specific section, table, or unique aspect of the paper where these are discussed. While the concept is clear, the *specific* location or context within the paper is not identified, making the grounding somewhat weak. The issue is about the *values* of these parameters, which is specific to the experimental setup or model.", "verifiability_rationale": "The reviewer suggests that sharing information about 'thresholds' and 'hyperparameters' will improve the draft. This can be interpreted as a claim or suggestion. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion lacks justification or examples of how this information would be helpful, making it only 3.", "helpfulness_rationale": "The review point itself asks for information about 'thresholds' and 'hyperparameters'. While this information *could* be helpful for the authors in understanding their experimental setup or model, the review point itself does not directly identify a specific weakness or deficiency in the authors' work that needs to be addressed. It's a request for information rather than a critique or suggestion about the authors' current draft content or structure."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the paper's conclusion about the readability of RC datasets not directly affecting question difficulty is dependent on the method/features used for answer detection. They further provide a specific example of POS/dependency parses as a potential feature that could explain the observed results. This makes the reviewer's point very actionable for the authors, as they can directly investigate or reevaluate their analysis methods.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific claim in the paper that the readability of RC datasets does not directly affect the question difficulty. They then suggest that this might be due to the method/features used for answer detection. The reviewer can confidently pinpoint the area of the paper being discussed and provide a specific suggestion related to the method, making this comment both grounded and specific.", "verifiability_rationale": "The reviewer makes a claim that the paper's conclusion is dependent on the analysis method. However, they do not provide any evidence or references to support this claim within the review point itself. They are simply suggesting a potential factor that could explain the observed results, but without any logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer's point is valuable because it encourages the authors to critically examine their methodology and consider alternative explanations for their results. By highlighting the potential influence of the analysis method, they are prompting the authors to investigate further and potentially refine their approach. While it doesn't directly fix the issue, it is a constructive critique that promotes deeper analysis and critical thinking, which are crucial for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a direction for improvement ('use less whitespace') but does not specify the *method* or *how* to achieve this. While it points to an actionable area, the lack of concrete steps makes it less actionable than a review that provides specific instructions.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 1', clearly identifying the specific part of the paper being addressed. It also identifies the issue as 'using less whitespace', which is a specific characteristic of the figure.", "verifiability_rationale": "The review point is a suggestion for improvement, not a declarative statement. There is X being made, like 'You should try this technique' or 'Your method is flawed.' It's a suggestion for better presentation.", "helpfulness_rationale": "The review point identifies a valid area for improvement (figure optimization) and suggests a direction (using less whitespace). While it lacks specifics on *how*, it *does* point towards a concrete action the author can take. It's better than a completely vague comment."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The question is explicitly framed as a request for evidence regarding the meaningfulness of the space. It doesn't identify a specific action to be taken beyond seeking evidence. The phrasing 'Do you have any evidence' directly implies a need for verification.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or the morphfitting process. The question is about the general meaningfulness of the space, not about a particular element within it. Therefore, it lacks strong grounding.", "verifiability_rationale": "The review point clearly states a claim: 'Do you have any evidence that the geometry of the space you end with is meaningful.' It then provides a suggestion for how to verify this claim: 'It would be nice to have some analysis that suggests the morphfitting results in a more meaningful space, not just better embeddings.' This demonstrates an attempt to provide evidence.", "helpfulness_rationale": "The review point is helpful in prompting the authors to consider the interpretability of their embeddings and to seek evidence for the meaningfulness of the learned space. The suggestion to 'have some analysis' directly addresses a potential area for improvement. The phrasing 'It would be nice to have some analysis...' indicates a desire for concrete evidence."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific issue \u2013 the imbalance in space allocation between memory networks and the forward model. This suggests an explicit action: the authors should adjust the length of the corresponding sections. The reviewer also mentions a lack of detail in the related work, implying a need for specific examples or citations. Therefore, the review point has multiple explicit and concrete actionability aspects, making it 5.", "grounding_specificity_rationale": "The reviewer's comment is general ('Overall, the writing quality of the paper should be improved'). While they then mention specific areas ('the authors spend the same space on explaining basic memory networks and then the forward model' and 'The related work has missing pieces'), the initial statement does not pinpoint a specific section, table, or unique aspect of the paper. The grounding is weakly grounded as the reviewer can only make an educated guess about which parts are being referred to. The specificity is also low as the reviewer does not detail what is specifically wrong in the mentioned areas.", "verifiability_rationale": "The reviewer states a problem ('the writing quality of the paper should be improved') and suggests a solution ('adjust the length...'). This implies a claim that the current writing quality needs improvement. However, the reviewer does not provide any evidence or justification for this claim. They do not cite any specific examples of poor writing or suggest any concrete ways to measure the writing quality. Therefore, the claim is not supported by logical reasoning, common knowledge, or external references, making it 1.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as adjusting the space allocation between memory networks and the forward model and recommending more specific pieces in the related work section. These suggestions are actionable and directly address identified weaknesses. While the initial comment about writing quality is vague, the subsequent points offer concrete feedback, making the review point 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the change made to the quantum operation (replacing the first column of Qo with vo) and the consequence of this change (the first state is no longer reachable but becomes a terminating state). This constitutes an explicit action. However, the reviewer does not provide concrete details on how this change affects the overall functionality or performance of the operation, nor does it offer specific steps on how to implement this change in the code or system. The reviewer also identifies a potential issue (the possibility of an infinite loop) but does not provide actionable steps to address it or clarify which assumption (Ass.1 or Ass.2) is responsible for this issue. Therefore, while the action is explicit, the lack of concrete details on the impact and the absence of specific guidance make it partially actionable.", "grounding_specificity_rationale": "The reviewer mentions \"Ass.1 (finite length of an option)\" and \"Ass.2\" in relation to the change in the quantum operation. However, they do not explicitly state which of these assumptions is being violated or how the change impacts them. The reviewer implies that one of these assumptions is responsible for the change but does not provide a clear connection. While the reviewer specifies the change made to the quantum operation and the resulting state behavior, the link to the assumptions is vague. The reviewer also does not specify what needs to be done to ensure the assumption is met. Therefore, while the action refers to specific parts of the paper, the lack of clarity on which assumption is violated and what needs to be done to meet it makes it weakly grounded and somewhat specific.", "verifiability_rationale": "The reviewer makes a claim: \"I assume that either Ass.1 (finite length of an option) or Ass.2 is responsible.\" This is a claim that requires justification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this assumption. They suggest possibilities but do not explain why one of these assumptions is specifically responsible for the observed change. The reviewer describes the change and its consequence but does not provide evidence to back up their assumption. Therefore, the claim is made without sufficient support, making it 1.", "helpfulness_rationale": "The reviewer points out a potential issue with the theoretical construction by highlighting the change in the quantum operation and the resulting state behavior. They suggest that this could lead to an infinite loop and attribute it to either Ass.1 or Ass.2. While this raises a concern and highlights a potential flaw, the reviewer does not provide specific guidance on how to identify the violated assumption or how to modify the construction to prevent the infinite loop. The reviewer's suggestion is more of a hypothesis than a concrete solution. Therefore, the review points to a problem but lacks actionable advice, making it 3 in identifying an issue but not in providing a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point focuses on suggesting an alternative area of investigation (accuracy and specific properties) if the initial focus (FLOPs or inference time) doesn't yield improvement. While it doesn't explicitly state an action to be taken, it implies the action of investigating accuracy and properties. However, the action is somewhat implicit.", "grounding_specificity_rationale": "The review point suggests looking at accuracy and specific properties but doesn't explicitly state which part of the paper these properties relate to. The grounding is weak as it doesn't point to a specific section or table. The suggestion is general.", "verifiability_rationale": "The review point suggests an *action* (looking at accuracy and properties) but doesn't provide any *justification* or *evidence* for why this would necessarily lead to improvement. It's a suggestion, not a claim supported by reasoning or references.", "helpfulness_rationale": "The review point is helpful in that it acknowledges a potential limitation (no improvement in FLOPs or inference time) and offers a concrete suggestion for further investigation (looking at accuracy and specific properties). It guides the authors on how to potentially find improvement, even though it doesn't definitively state a problem with the current draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point directly asks a question about a core assumption made in the paper. The reviewer is asking whether the assumption that d_e are good replacements for entity embeddings has been tested or validated. This is a clear and actionable question that the authors should address to clarify the basis of their approach. The reviewer is prompting for evidence or justification for this assumption.", "grounding_specificity_rationale": "The review point explicitly refers to the assumption about the replacement of entity embeddings. The reviewer is directly asking about the validity of this specific assumption in the context of the paper's methodology. The grounding is explicit as the question directly targets a specific claim made in the paper.", "verifiability_rationale": "The review point poses a question about an assumption made in the paper. For the review to be helpful, the authors need to provide evidence or justification for this assumption. The question itself is a claim that requires support. While the paper might not explicitly state 'this assumption is tested,' the reviewer's question implies a need for verification. Therefore, it is '3' as the paper should ideally provide some form of justification or explanation, even if it's not a dedicated 'test'.", "helpfulness_rationale": "The review point directly questions a core assumption of the paper regarding the use of documentlevel entity embeddings. This is a highly relevant and specific question for the authors. If the assumption is incorrect, it could significantly impact the validity of the results. The question is directly actionable and seeks clarification on a key methodological choice. Therefore, it is 5 for the authors to address this question."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly states what is unclear about the 'scoring function' and its components (components of the function and threshold values/ranges). This directly points to an explicit action the reviewer is seeking clarification on. While the action itself isn't directly actionable for the authors, understanding the components and thresholds is crucial for them to interpret and potentially improve the scoring system. Therefore, while the action isn't directly about the authors' draft, the reviewer's request for clarification is a form of actionability.", "grounding_specificity_rationale": "The review point does not specify which part of the paper or process the 'scoring function' is applied to. It focuses on the *process* of the scoring itself and what is unclear about its components and thresholds. Therefore, the grounding is weak as the authors cannot determine the specific area being addressed by the scoring.", "verifiability_rationale": "The review point questions the *verifiability* of the scoring function. It asks how the authors arrived at the different components and threshold values/ranges, implying a lack of clear justification, logical reasoning, or external references to support these choices. The reviewer is asking for *evidence* that the scoring is sound and not arbitrary. This directly relates to the 'Verifiability' aspect, as the reviewer is questioning the basis for the scoring's design and implementation. The lack of justification makes the claim about the scoring 1.", "helpfulness_rationale": "The review point is not helpful for the authors because it doesn't specify *where* the scoring function is applied (grounding is weak) and it questions the *justification* behind the scoring's components and thresholds (verifiability is questionable). Without knowing the location and the reasoning behind the scoring, the authors cannot effectively use or interpret the feedback provided by the score. The lack of clarity and justification makes the scoring system unhelpful in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "1", "actionability_rationale": "The reviewer suggests that making factors in a table does not help convey more messages than pure text. While this could be an actionable suggestion if the authors were to redesign the table, the reviewer's statement itself is not explicitly stating what action should be taken. The suggestion is more about identifying a potential issue rather than providing a clear, actionable step. Therefore, it is 3 as it implies an action (improving the table) but lacks specific guidance on how to do it.", "grounding_specificity_rationale": "The reviewer states, 'making the factors in a table does not help convey more messages than pure text.' This statement refers to tables in general and does not specify which particular part of the table or section is lacking clarity. The reviewer is making a general claim about the ineffectiveness of tables, not pinpointing a specific element within a table that needs improvement. Therefore, the grounding is weak as the specific part being addressed is not identified.", "verifiability_rationale": "The reviewer makes a statement: 'making the factors in a table does not help convey more messages than pure text.' This statement is a claim that can be verified by comparing the information conveyed by tables with the information conveyed by the corresponding text. The reviewer is making a judgment about the effectiveness of tables, which can be supported or refuted with evidence. Therefore, the claim is verifiable.", "helpfulness_rationale": "The reviewer states, 'making the factors in a table does not help convey more messages than pure text.' This is a critique of the current approach. While it identifies a potential issue (ineffective tables), it does not offer any specific suggestions or actionable steps for the authors to take to improve their draft based on this observation. The suggestion is vague and doesn't directly address the identified problem. Therefore, the review point is not helpful in providing concrete guidance to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The question identifies a potential area of confusion for the authors regarding the term 'physical interaction' in the context of a simulation. While it doesn't explicitly state what needs to be changed, it points to a lack of clarity, which can be actionable by prompting the authors to define their terms more precisely. However, it doesn't directly tell the authors *how* to apply the change or *where* the issue lies in their draft.", "grounding_specificity_rationale": "The comment explicitly mentions 'physical interaction' and 'simulation', which are specific terms within the context of a potential model or experiment described in the authors' draft. This provides a clear target for the authors to identify and clarify the specific type of interaction being referred to.", "verifiability_rationale": "The comment itself does not contain a claim that requires verification. It's a question prompting information rather than a statement that needs to be supported by evidence.", "helpfulness_rationale": "The question highlights a potential lack of clarity for the authors regarding the terminology used in their draft, specifically regarding simulations and interactions. This can be helpful as it encourages the authors to define their terms more precisely, which is a crucial step in improving their work. However, it doesn't directly provide specific instructions on how to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies two key issues: the lack of categorical features in most datasets and the omission of onehot encoding for a specific dataset. While these are valid points, the reviewer does not explicitly state what the authors *should* do. They imply these are weaknesses that need addressing, but the specific actions are not detailed. Therefore, while the issues are valid, the explicit actions are missing, making it 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the chosen selection of datasets' and 'the omission of onehot encoding for this one dataset.' This clearly identifies the specific parts of the paper being addressed, providing strong grounding. The reviewer also states the *types* of features missing (categorical) and the *specific* missing step (onehot encoding), making the grounding very specific.", "verifiability_rationale": "The reviewer states that the omission of categorical features and onehot encoding 'affects conclusions' and provides reasoning based on the general challenges of categorical features and the standard practice of onehot encoding. While the reviewer doesn't provide specific citations, the reasoning is logical and based on common knowledge in the field, making the claim 3.", "helpfulness_rationale": "The reviewer provides suggestions for improvement, such as 'consider including datasets with categorical features' and 'ensure they use onehot encoding for all relevant features.' These suggestions are actionable and directly address the identified weaknesses. While the reviewer doesn't guarantee these suggestions will resolve the authors' issues, they are concrete and provide a clear direction for improvement, making the review 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the choice of datasets as a weakness and provides concrete reasons for this opinion: 'The two IoT datasets (FlatCam Face 26, Headpose detection 11) are unpopular, weird choices. The former is relatively recent but not substantially followed yet. The latter was published in 2004 and was no longer used much recently.' This is an explicit statement of an issue with the methodology. However, the reviewer does not suggest any concrete actions or modifications to the draft based on this choice of datasets. The suggestion is at a higher level of changing the experimental setup rather than directly improving the draft itself.", "grounding_specificity_rationale": "The review point explicitly mentions 'the two IoT datasets' and provides reasons for why they are 'unpopular' and 'weird choices'. This demonstrates a clear grounding of the comment in a specific part of the paper (the datasets). The comment also specifies what the reviewer feels is wrong with these datasets. However, the review point does not detail *how* the unpopularity of these datasets affects the benchmarking results or what specific aspects of the datasets are problematic. The grounding is present, but it lacks specific details about the issues.", "verifiability_rationale": "The review point makes a claim about the 'unpopularity' and 'weird choices' of the specific IoT datasets used in the paper. While the reviewer provides reasons for this opinion, they do not offer any external references or logical reasoning to support this claim. The statement is based on the reviewer's perception of the datasets' popularity and usage. Therefore, the claim is not wellsupported by evidence within the review point.", "helpfulness_rationale": "The review point identifies a potential weakness in the authors' choice of datasets for their IoT benchmarking. The reviewer provides specific reasons why they believe these datasets are not ideal and suggests alternative datasets. While the point does highlight a potential issue, it does not offer concrete, actionable suggestions for how the authors can improve their draft based on this criticism. The reviewer's suggestions are at a higher level of recommending different experimental setups rather than providing specific edits or improvements to the current draft."}
{"actionability_label": "Medium", "grounding_specificity_label": "High", "verifiability_label": "Low", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states the limitation of pruning with large networks and distributed training, and the need for a global top Q values metric. This is an *explicit* action pointing to a missing piece of information. However, the reviewer does not *immediately* tell the authors *how* to find this information. The action is identified, but the implementation details are missing.", "grounding_specificity_rationale": "The reviewer mentions \"distributed settings\" and \"top Q values of the metric.\" \"Distributed settings\" is a general term, but the mention of \"top Q values of the metric\" provides a specific element that the reviewer is referring to. This suggests the reviewer has made an *educated guess* about what the authors might be trying to ask. The grounding is present but could be more precise.", "verifiability_rationale": "The reviewer makes a claim: \"This will potentially break big portion of acceleration techniques, such as quantization and sparsification.\" This is a statement of a potential negative impact. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. The claim is stated, but the supporting evidence is lacking.", "helpfulness_rationale": "The reviewer points out a potential negative impact of pruning in a distributed setting, which is a relevant concern for authors. By highlighting this, the reviewer is providing valuable information that could help the authors make informed decisions about their training process. The potential negative impact is a relevant piece of information."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not provide a specific action or suggestion. It raises a suspicion about a potential error, but does not tell the authors what to do or how to fix it. Therefore, it lacks the explicitness and concreteness required for high actionability.", "grounding_specificity_rationale": "The reviewer mentions 'subfigures in Figs 1 and 2,' which is a specific part of the paper. This indicates that the reviewer can identify the relevant section. Therefore, the grounding is strong.", "verifiability_rationale": "The review point is a statement of suspicion or potential error. It does not contain a claim that requires verification or justification. Therefore, it has X and falls under the 'X' category for verifiability.", "helpfulness_rationale": "The review point points out a potential issue with the figures. While it doesn't provide a solution, it highlights a concrete area for the authors to investigate. This is a valuable piece of feedback and can be considered 3 as it guides the authors to look at specific parts of their paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the potential benefit (improving sensitivity) and the potential risk (increased false positives). They also suggest discussing the risk, which is a clear action. The action is also concrete as it specifies the potential impact of the dropout probe.", "grounding_specificity_rationale": "The reviewer mentions 'dropout probe,' 'sensitivity,' 'false positives,' and 'discussion,' which are general concepts related to the method and its potential consequences. While not explicitly pointing to a specific section or table, they are addressing the method and its potential implications. The grounding is not literal but refers to the method and its potential issues.", "verifiability_rationale": "The reviewer makes claims about the dropout probe improving sensitivity and the increased risk of false positives. However, they do not provide specific citations, examples, or logical reasoning to support these claims within the provided review point itself. The claims are presented as possibilities rather than certainties based on evidence.", "helpfulness_rationale": "The review point raises a relevant concern about the potential drawback of the dropout probe (increased risk of false positives). It suggests a concrete action (discussing the risk), which is helpful for the authors. However, the claims about sensitivity and false positives are presented without strong supporting evidence or references within the review point itself, making the overall feedback somewhat speculative."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that they did not find the regret bound for the minibatch estimator in the supplementary material. This is an explicit statement of a missing piece of information, making it actionable for the authors to check the location of the regret bound. However, the reviewer does not specify *how* they should go about finding it, making it somewhat vague on the implementation side.", "grounding_specificity_rationale": "The reviewer is asking about the location of a specific result (the regret bound) and implicitly about a specific part of the paper (the appendix). They are not asking for the details of the proof or the implications of the bound. While they don't explicitly name the section or appendix number, they are clearly referring to a specific location, making it fully grounded and asking for specific information.", "verifiability_rationale": "The reviewer makes a claim that the regret bound is in the appendix and states that they did not find it. This claim is verifiable by checking the appendix. The reviewer provides a clear statement and identifies a missing element (the location of the bound), making it 5.", "helpfulness_rationale": "The reviewer is asking a direct question about the location of a key result (the regret bound). This is a clear and actionable piece of feedback that directly addresses a potential issue the authors might be facing. The question is helpful in identifying a missing element and guiding the authors to the relevant section of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem with the formatting and provides concrete suggestions for improvement. They mention the abstract font size and bottom margins, and suggest fixing the NeurIPS style to gain space and include NLP experiments. This indicates a clear understanding of what needs to be changed and how to do it.", "grounding_specificity_rationale": "The reviewer explicitly mentions the NeurIPS formatting style and points to specific elements within that style (abstract font, bottom margins) as being problematic. This strong identification of the specific part of the paper being addressed makes the grounding very explicit.", "verifiability_rationale": "The reviewer makes a claim that the formatting is 'off' and suggests improvements based on fixing the style. They provide logical reasoning by pointing out the specific issues with the abstract font and bottom margins. They also connect the proposed solution (gaining space, including experiments) to the benefits of fixing the formatting. This demonstrates a clear justification for the claim.", "helpfulness_rationale": "The reviewer provides clear feedback on the formatting issues and suggests a specific solution (fixing the NeurIPS style). They explain *why* this solution is beneficial (gaining space, including NLP experiments). This actionable feedback directly addresses the identified problems and offers a clear path for improvement, making the review 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "Not Applicable", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the lack of discussion and comparison of specific exploration methods, which is a direct and actionable suggestion. The mention of 'countbased methods' and 'intrinsic motivations' (specifically RND and ICM) makes the suggestion concrete, indicating a clear area for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'countbased methods,' 'RND,' and 'ICM,' which clearly identifies the specific areas of the paper being addressed. However, the reviewer does not specify *how* these methods are relevant or should be discussed. The grounding is present, but the specificity of the suggestion is limited to the identification of the methods.", "verifiability_rationale": "This review point does not contain a claim that requires verification. It is a statement of fact: the paper is missing certain exploration methods. Therefore, the concept of verifiability does not apply to this specific point.", "helpfulness_rationale": "While the reviewer's point is valuable in identifying a gap in the related work, it is presented as a criticism rather than a direct, actionable suggestion for improvement. It points out a weakness in the paper's discussion of related work, but it doesn't directly tell the authors *how* to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment states \"annotations in Figure 4 can be further enlarged for visibility.\" This indicates an implicit action: the reviewer suggests the annotations should be enlarged. However, the comment lacks explicit instructions on *how* to enlarge them. The phrasing \"further enlarged\" is also vague, not providing a clear method. Therefore, while the action is implied, the lack of concrete steps makes it 3 but not fully actionable.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 4\", which is a specific part of the paper. It also clearly identifies the issue as \"can be further enlarged for visibility\", specifying what needs to be improved. This indicates that the reviewer has accurately identified the section and the problem within it.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a suggestion for improvement rather than a statement that needs to be proven. Therefore, it does not fit into the categories of 1, 2, 3, 4, or 5. It is essentially a constructive suggestion.", "helpfulness_rationale": "The comment directly points to a specific issue in Figure 4 and suggests a concrete improvement: enlarging the annotations. This is a clear and actionable suggestion that directly addresses a potential problem for the author. While it doesn't *prove* the issue exists, it provides a clear direction for improvement. Therefore, it is a helpful suggestion, though it could be slightly more definitive about the problem's existence."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the incorrect assumption about sentences and relation classification. It also points out that this is true for more complex scenarios like documents and joint entity/relation extraction, which can be interpreted as an implicit action to caution against oversimplification.", "grounding_specificity_rationale": "The comment refers to 'sentences,' 'relation classification,' 'documents,' 'entities,' and 'relation extraction.' While it doesn't have a direct link to a specific line number or table, it refers to general concepts within the field. It could be more specific, but it's not entirely lacking in identifying a part of the paper. The comment also specifies what is wrong (multiple entities in relation classification).", "verifiability_rationale": "The comment contains a claim: 'Lines 2627: Multiple entities typically exist in both sentences and documents and this is the case even for relation classification'. While the comment doesn't provide explicit reasoning or references to support this claim, the statement itself is factually correct and verifiable based on common knowledge in relation classification. Therefore, it can be considered 3 as it states a verifiable fact.", "helpfulness_rationale": "The comment is informative and correct, pointing out a factual correction. However, it doesn't offer actionable advice on how to address this understanding or improve the draft. It's more of a clarification than a suggestion for improvement. The reviewer could have framed it as a question for the authors to consider, which would have been more helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the issue with Fig. 4's color bar and suggests a concrete action: changing a label to 'worse'. This is an explicit action that is also concrete, as it clearly states what needs to be done.", "grounding_specificity_rationale": "The comment explicitly mentions 'Fig.4' and the 'color bar' of the figure, accurately pinpointing the specific part of the paper being addressed. The comment also clearly specifies what is wrong ('presumably one of the labels should say \u201cworse\u201d') and what needs to be done to fix it.", "verifiability_rationale": "The comment is a suggestion for improvement, not a claim that requires verification. It does not contain any opinions, judgments, or assertions.", "helpfulness_rationale": "The comment directly identifies a potential issue with a figure and provides a specific suggestion for improvement. This actionable feedback is highly valuable for the author."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly suggests adding the phrase 'sets' after 'validation/test'. It also identifies the location where this correction should be made, which is 'Row 757 in Supp. Page 29'. This provides a clear action for the author to take.", "grounding_specificity_rationale": "The comment explicitly mentions 'Row 757 in Supp. Page 29'. This is a very specific reference to a location within the author's document, indicating a high level of grounding. It clearly identifies the part of the paper being addressed.", "verifiability_rationale": "While the comment itself doesn't make a claim in the sense of stating something definitively true, it suggests an improvement to the draft ('...training/validation/test sets'). This can be seen as implicitly verifying that the current draft is lacking clarity or completeness regarding the use of data splits. The suggestion is directly tied to the identified location, making it verifiable by the author themselves.", "helpfulness_rationale": "The comment is clear, specific, and directly points to a location in the supplementary material where a correction should be made. It empowers the author to improve their draft by adding the missing 'sets'. The suggestion is actionable and directly addresses a potential issue."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is prompting for clarification regarding the implications of the method and questioning the tuning of hyperparameters and the clarity of writing. While they are not directly asking to perform an action, they are implicitly suggesting that the method might not be as straightforward as implied and that more attention to detail is needed. The lack of explicit instructions makes it 2.", "grounding_specificity_rationale": "The reviewer is broadly commenting on the method and the paper as a whole, without pinpointing a specific section or detail. They are asking about the implications of the method, the coefficient in line 307, and the clarity of writing, but do not explicitly state which part of the paper or method they are referring to. This lack of specific referencing makes it weakly grounded.", "verifiability_rationale": "The reviewer is making claims about the method's implications and the experimental setup, but lacks explicit references or detailed explanations in the provided text snippet. They are questioning the coefficient in line 307 and the tuning of hyperparameters, which could be considered verifiable if the paper provided more context or justification for these aspects. However, without the full paper, it's difficult to definitively assess the verifiability of these claims based solely on the provided snippet. The questions are insightful but lack the supporting evidence needed for full verifiability.", "helpfulness_rationale": "The reviewer raises several valid points regarding the method's implications, hyperparameter tuning, and writing clarity. However, the presentation is somewhat vague, and the reviewer is primarily questioning assumptions rather than providing direct suggestions for improvement. While the concerns are wellfounded, the lack of concrete recommendations makes the overall feedback somewhat unhelpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests an action to improve clarity regarding the definition of the quantile. While the reviewer identifies an area for improvement, the suggestion lacks specific details on how to achieve this improvement. The reviewer proposes adding brackets or defining the bracketed term separately, but doesn't elaborate on the exact implementation or the reasoning behind this suggestion. Therefore, while the reviewer points out a potential area for action, the lack of concrete details makes it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the definition of the quantile' as the area of confusion. This clearly identifies a specific part of the paper being addressed. Furthermore, the reviewer points out a specific element within that definition ('an extra pair of brackets'), which further specifies the issue. This demonstrates strong grounding as the reviewer can accurately pinpoint the referenced part and the specific issue within it.", "verifiability_rationale": "The review point does not contain a claim that requires verification. The reviewer is suggesting an improvement to clarity, which is a direct action rather than a claim that needs to be supported by evidence or reasoning. Therefore, this review point does not fall under the 'verifiability' aspect.", "helpfulness_rationale": "The reviewer directly addresses a potential point of confusion for the authors by suggesting a specific change ('an extra pair of brackets around the term'). This suggests a clear and actionable improvement. While the suggestion is relatively simple, it directly addresses a potential issue and empowers the authors to improve their understanding of the concept. Therefore, the review point is helpful in guiding authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests replacing a specific model (Dozat and Manning, 2016) with a more general term ('very high performing model'). While the reviewer identifies a need for improvement, the action is not explicitly stated. The suggestion to use 'very high performing model' is an implicit action, as the reviewer does not provide specific criteria or methods for finding such a model. Therefore, the action is not fully explicit or concrete, making it 2.", "grounding_specificity_rationale": "The reviewer refers to 'the model' in line 152, which is likely the intended target of the change. This demonstrates a reasonable level of grounding \u2013 the reviewer can identify the specific part of the paper being addressed. However, the specificity of the suggestion is low. The reviewer doesn't tell the authors *which* aspects of the model they should change or *how* they should go about finding a 'very high performing model'. They don't provide concrete examples or criteria. Therefore, while the grounding is present, the specificity of the suggestion is lacking, making it 3.", "verifiability_rationale": "The reviewer suggests replacing a specific model with a more general term. This review point does not contain a clear claim that can be verified. The reviewer is offering a suggestion for improvement, but without specific evidence or references, it cannot be considered verifiable. The statement is more of a suggestion or recommendation rather than a claim requiring justification.", "helpfulness_rationale": "The reviewer's suggestion to replace a potentially outdated model with a 'very high performing model' is relevant and points towards a potential area for improvement. While the suggestion is not very specific, it provides a direction for the authors to focus their efforts. The reviewer is indicating that the current model might not be optimal, which is a helpful insight. However, the lack of specificity makes the feedback less impactful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the performance difference ('worse than PQ') and the condition ('when a small code length is allowed'). However, it lacks specific details on *how* the proposed compression performs worse and the exact definition of 'small code length'. The consequence ('main weakness') is stated, but the actionable steps for improvement are not detailed.", "grounding_specificity_rationale": "The reviewer refers to 'this method' and 'PQ', which are specific terms within the field. However, the section or table where 'this method' is detailed is not explicitly mentioned. While 'PQ' is a specific comparison point, the exact section or table where the comparison is made is also not specified. The reviewer mentions 'small code length' and 'practical side' as factors, but doesn't provide specific examples or references within the paper.", "verifiability_rationale": "The review point contains a claim ('The proposed compression performs worse than PQ...') and states a consequence ('...which is the main weakness of this method...'). However, it does not provide any logical reasoning, external references, or specific examples to support the claim that the proposed compression performs worse than PQ under the specified conditions. The 'practical side' is also mentioned without any justification or evidence.", "helpfulness_rationale": "The review point identifies a potential weakness ('main weakness') and suggests it's relevant to the 'practical side'. This could be considered helpful as it points out a potential area for improvement. However, it lacks concrete suggestions or specific details on how to address this weakness. The reviewer doesn't offer any actionable steps or insights on how to improve the proposed compression based on the identified weakness."}
{"actionability_label": "3", "grounding_specificity_label": "1 and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out that some subjective statements might be inappropriate for introducing the paper. While the reviewer suggests providing proofs and references, the statement itself is vague and doesn't specify which statements are problematic. The reviewer also mentions the difficulty of multiscale architecture design, particularly the choice of fusion, and notes that skip connections implicitly use multiscale information. These suggestions are helpful but lack specific examples or references to the paper's content.", "grounding_specificity_rationale": "The reviewer's comment is 1 in the paper. They make general statements about subjective statements and the difficulty of multiscale design without pointing to specific sections, tables, figures, or unique aspects of the paper.", "verifiability_rationale": "The reviewer's claims about the appropriateness of subjective statements and the difficulty of multiscale design are not wellverified. While the reviewer suggests providing proofs and references, they don't offer specific examples or references to the paper's content. The observation about skip connections implicitly using multiscale information is partially verifiable, as it points to a valid characteristic of skip connections, but lacks specific examples within the paper.", "helpfulness_rationale": "The review point provides some suggestions for improvement, such as providing proofs and references and clarifying multiscale design. However, these suggestions are vague and lack specific examples or references to the paper's content. The reviewer's observation about skip connections implicitly using multiscale information is a valid point but lacks concrete suggestions for improvement within the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point is a question, which is not an explicit instruction to perform an action. While it implies a comparison, the specific action or suggestion is not stated. Therefore, it is 2.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. It is a general question about the comparison with prior art. Therefore, it is 1 in a specific aspect of the paper.", "verifiability_rationale": "The review point itself is not a claim. It is a request for information. The verifiability of the information provided in the review point would depend on the specific prior art being referenced, which is not part of the review point itself.", "helpfulness_rationale": "The review point is a request for information/comparison. While such requests can be helpful, the current point is vague and lacks specific direction or expected outcome. It does not actively guide the authors on what to improve or how to do so. Therefore, it is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a desire for 'more detailed' analysis, which can be interpreted as an actionable suggestion. However, the specific nature of this 'more detailed' analysis is not clearly defined, making it somewhat vague.", "grounding_specificity_rationale": "The review point mentions 'language/nationality' and provides an example of languages, indicating a level of grounding. However, it does not specify which part of the analysis or what specific issue within 'language/nationality' requires more detail. The specificity is limited to the broad area mentioned.", "verifiability_rationale": "The review point contains a claim ('some analyses can be more detailed') and provides implicit support by mentioning the existence of different languages and the potential for interesting comparisons. While the reasoning is not explicitly stated, the suggestion is grounded in the observation of different languages.", "helpfulness_rationale": "The review point suggests a valuable direction for future work by highlighting the potential for more indepth analysis of language/nationality differences. While the suggestion is not entirely lacking in meaning, it lacks specific details and concrete recommendations, making it less immediately helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question that implicitly suggests exploring alternative properties beyond the standard 'norm'. While it doesn't explicitly state a specific action or provide concrete details, the question itself is a form of action, guiding the authors to consider other feature properties. Therefore, it can be considered 3 as it points towards a direction for improvement.", "grounding_specificity_rationale": "The reviewer asks a general question about 'other property of features'. While the authors can infer that the reviewer is interested in properties beyond the standard 'norm', the question lacks specificity regarding which alternative properties are being considered. This makes it somewhat specific in its intent but weak in its grounding as the authors need to deduce the focus.", "verifiability_rationale": "The review point is a question and does not contain a claim that requires verification. Therefore, it falls under the category of 'X'.", "helpfulness_rationale": "The review point is relevant to the topic and encourages the authors to explore alternative feature properties. While it doesn't provide a direct solution, it prompts a search for potentially valuable features, making it 3 in guiding the authors towards further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises specific questions about the conservation properties of F^\u2020, suggesting an implicit action: investigating whether F^\u2020 preserves mathematical invariants similar to symplectic integrators. However, the point lacks concrete steps or suggestions on how to approach this investigation. The action is implied but not explicitly stated or detailed.", "grounding_specificity_rationale": "The review point explicitly mentions 'symplectic integrators' and 'conservation properties' in the context of physicsrelated PDEs. It also refers to 'Hamiltonian systems' and 'numerical illustrations'. This indicates a clear grounding in specific technical areas. The point identifies a specific area of interest within the paper, suggesting a targeted focus. The grounding is strong as it points to specific concepts and examples.", "verifiability_rationale": "The review point poses questions about the conservation properties of F^\u2020 without providing any references, logical reasoning, or external evidence. The point is speculative and lacks any basis in existing knowledge or established methods. The claim (if any) is not supported by any evidence within the review itself. The verifiability is low as there are no supporting arguments or references provided.", "helpfulness_rationale": "The review point raises a valid concern about the connection between F^\u2020 and established numerical methods for solving PDEs, particularly in the context of physics. It highlights a potential area for further investigation and suggests numerical validation. While the point identifies a potential issue or area for improvement, it does not provide a concrete solution or direction for addressing it. The helpfulness is limited as it primarily sets expectations or highlights a gap rather than offering immediate guidance. The point is somewhat specific and technical, which might limit its appeal to a broader audience. The lack of a clear recommendation or solution makes it less helpful than a point that offers a concrete improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "Partially Helpful", "actionability_rationale": "The reviewer explicitly states the lack of 'network changes or losses' and poses a direct question about the necessity of using two SIRENs for 'f' and 'd'. This indicates a clear and concrete action the authors should take: evaluate the necessity of the current architecture and potentially explore simpler alternatives. The action is explicit because the reviewer directly points out the absence of changes and asks a specific question about a design choice.", "grounding_specificity_rationale": "The reviewer refers to 'the method' generally but focuses on specific components like 'network changes or losses' and the specific functions 'f' and 'd'. While the initial reference is broad, the subsequent points are specific, suggesting a degree of grounding. The question about the two SIRENs pinpoints specific parts of the architecture, indicating a level of grounding.", "verifiability_rationale": "The reviewer makes a claim about the lack of 'network changes or losses' but does not provide any justification or reasoning for this assertion. There are no references to external works or logical arguments to support this claim. The lack of verifiable evidence makes the claim 1.", "helpfulness_rationale": "The reviewer suggests a potential simplification in the architecture by questioning the use of two SIRENs and proposing a single SIREN as an alternative. This is a concrete suggestion that could be helpful for the authors. However, the reviewer does not provide any justification for why the current architecture is necessary or better than the suggested alternative. Without justification, the suggestion remains a question rather than a helpful improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that RQ1 is 'redundant' and 'adds no extra information'. This implies a lack of clear action for the authors. While the reviewer offers a suggestion (alternative analysis), this is not a direct critique or actionable point regarding the specific content or methodology of RQ1 itself. The reviewer does not explicitly state what needs to be done or what is wrong with RQ1. Therefore, the actionable aspect is low as the reviewer does not provide concrete steps or modifications based on the criticism.", "grounding_specificity_rationale": "The reviewer's critique of RQ1 is not explicitly grounded in a specific part of the paper. They refer to RQ1 generally and suggest an alternative analysis based on the proportion of explicit hate speech. While the suggestion is specific to a detail within the analysis, the critique of RQ1 itself lacks a clear reference point within the paper. The reviewer does not mention a specific section, table, figure, or unique aspect being addressed regarding RQ1. Therefore, the grounding_specificity is 2 as the reviewer does not identify a precise location within the paper being criticized.", "verifiability_rationale": "The reviewer makes a claim that 'RQ1 adds no extra information' but does not provide any evidence or reasoning to support this claim. They offer a suggestion (alternative analysis) as a potential improvement, but this suggestion itself is not necessarily verifiable without further context or justification. The claim is presented without logical reasoning, common knowledge, or external references. Therefore, the verifiability is 1 as the reviewer does not provide any basis for their claim.", "helpfulness_rationale": "The reviewer's primary point is that RQ1 is redundant and lacks value. While they offer a suggestion (alternative analysis), this suggestion is not directly tied to the specific issues with RQ1. The criticism is more about the *lack of critique* of RQ1 itself. The reviewer does not provide actionable feedback or propose concrete modifications based on their assessment of RQ1. Therefore, the helpfulness is not high as the reviewer does not directly address the content or methodology of RQ1 with actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The statement explicitly mentions 'link predict' as the current task and 'a variety of tasks' as the desired outcome. This is a direct and clear indication of an action that needs to be taken.", "grounding_specificity_rationale": "The reviewer is implying a concern about the current task focus (only link predict) and suggesting a broader approach. They are not explicitly pointing to a specific section or element of the paper that needs addressing.", "verifiability_rationale": "The reviewer is stating an expectation about the tasks used in the paper (lack of variety) and suggesting a way to improve it. This is a deduction based on common practices, but there is no explicit backing within the paper itself to support this expectation.", "helpfulness_rationale": "The review point directly points out a potential limitation of the work (limited task variety) and suggests a way to improve it (include more diverse tasks). This provides a clear direction for the authors to consider."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "3 (3)", "verifiability_label": "3 (3)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point asks for elaboration on the differences between the work and other face editing methods. While it implies a need for more information, it doesn't explicitly state what needs to be done or how to achieve the desired outcome. It's a request for clarification rather than a direct instruction.", "grounding_specificity_rationale": "The reviewer refers to 'other works focusing on the semantic face editing' and their 'ability to achieve continuous control over different attributes'. This points to specific concepts within the field, indicating a degree of grounding. While it doesn't name specific papers, the concepts themselves ground the discussion to a particular area of research.", "verifiability_rationale": "The reviewer claims that 'other works focusing on the semantic face editing and they show the ability to achieve continuous control over different attributes'. This is a claim that needs to be supported. While the reviewer provides a general example '1' to illustrate this point, they don't provide specific details or references to back up the claim that these works exist and achieve continuous control. The evidence is present but lacks depth and specificity.", "helpfulness_rationale": "The reviewer asks, 'Could you elaborate the difference between your work and these papers?'. This is a valid and helpful question for the authors. It seeks to understand the novelty and contribution of their work in relation to existing research. The question is framed in a way that encourages a detailed explanation rather than being dismissive or critical."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states actions or suggestions. The phrase \"Details around parameter settings etc. can be moved into the appendix to make space\" is a direct action. The phrase \"Details around parameter settings etc. can be moved into the appendix\" is a direct action. The reviewer also implies an action by stating \"Additionally, footnotes are used FAR too extensively in this paper  it's actually very distracting. Much of the content is actually important and should be moved into the main body of the paper! Details around parameter settings etc. can be moved into the appendix to make space (e.g., L468).\" which implies the action of moving content. The reviewer also states \"it's to make space\", which is an action. The reviewer also states \"it's actually very distracting\", which implies an action to address this issue.", "grounding_specificity_rationale": "The review point explicitly mentions \"Details around parameter settings etc. can be moved into the appendix\" and \"it's actually very distracting\". The reviewer also implies the relevance of these points by stating \"it's actually very distracting\" and \"it's to make space\". The reviewer also states \"it's to make space (e.g., L468)\", which explicitly points to a specific location in the paper. The reviewer also states \"it's actually very distracting\", which implies the importance of the content in the main body. The reviewer also states \"it's actually very distracting\", which implies the importance of the content in the main body.", "verifiability_rationale": "The review point provides a claim that \"Details around parameter settings etc. can be moved into the appendix to make space\" is a suggestion for improvement. This claim is supported by the suggestion itself, which is a logical reasoning. The reviewer also provides a claim that \"it's actually very distracting\" is a judgment about the paper. This judgment is supported by the reviewer's opinion that the extensive use of footnotes is disruptive. The reviewer also provides a claim that \"it's to make space\" is a suggestion for improvement. This suggestion is supported by the practical goal of making space. The reviewer also provides a claim that \"it's actually very distracting\" is a judgment about the paper. This judgment is supported by the reviewer's opinion that the extensive use of footnotes is disruptive.", "helpfulness_rationale": "The review point provides two concrete suggestions for improvement: (1) move details around parameter settings to the appendix and (2) move important content from the appendix to the main body. These suggestions are directly actionable and address a practical concern about space. The reviewer also expresses concern about the excessive use of footnotes, which is a valid observation that could lead to actionable feedback. While the concern about footnotes is subjective, the suggestions regarding the main and appendix are concrete and directly address potential improvements to the paper's structure and clarity. The reviewer also states \"it's to make space\", which is an action. The reviewer also states \"it's actually very distracting\", which implies an action to address this issue."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests adding a discussion about fewshot demonstrations, which implies an explicit action. However, the reviewer does not specify how this discussion should be structured, what aspects of the demonstrations should be covered, or where in the paper this discussion should be placed. The action is present, but the details are missing, making it vague on how to implement it.", "grounding_specificity_rationale": "The reviewer mentions 'a discussion about this,' which could be interpreted as implicitly referring to the fewshot demonstrations. However, the reviewer does not specify the exact section, table, figure, or unique aspect of the paper that needs this discussion. The grounding is present but not precise, making it weakly grounded.", "verifiability_rationale": "The reviewer states that including zeroshot generation results 'satisfies general curiosity.' This is a subjective statement and lacks any logical reasoning, common knowledge, or external references to support the value of these results. The claim is made without sufficient justification.", "helpfulness_rationale": "The reviewer explicitly states, 'I find the inclusion of zeroshot generation results a bit strange here.' This is a clear statement of a weakness or an area for improvement. While the reviewer *could* suggest adding the fewshot demonstrations, the core of their comment is the *lack* of a discussion about the zeroshot results, which is a valuable piece of feedback for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks 'What's up with Figure 3?' and points out that 'OAA' is not referenced in the body text. This directly implies that the authors need to address Figure 3 and clarify the meaning of 'OAA'. The reviewer is prompting an action on a specific part of the paper.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 3' in their comment. This clearly identifies the specific part of the paper they are referring to. They also mention 'OAA' as something that is missing from this figure, further specifying the issue.", "verifiability_rationale": "The reviewer's comment implicitly suggests an issue with Figure 3 and the missing 'OAA'. While they do not provide a logical reasoning or external reference, the observation itself is a form of implicit verification. The reviewer is stating a fact that needs to be addressed.", "helpfulness_rationale": "The reviewer clearly identifies a potential issue with Figure 3 and points out a missing element ('OAA'). This provides the authors with a specific area to improve. The comment is direct and actionable, guiding the authors to investigate Figure 3 and understand the meaning of 'OAA'."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the authors *must* clarify their contribution and its relationship to prior work. This provides a clear direction for the authors to take, making the comment actionable. The authors know exactly what they need to do: clarify the novelty of their approach in the introduction.", "grounding_specificity_rationale": "The reviewer points to the specific lines in the introduction (2930) where the framework is first introduced. This provides a precise location for the authors to focus their clarification. The comment is grounded because it directly references a specific part of the paper.", "verifiability_rationale": "The reviewer instructs the authors *must* provide evidence to support their claim about the existing framework. This is a call for justification and provides a verifiable requirement. While it's a directive, it sets a direction for the authors to seek or provide evidence.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential lack of clarity for the authors regarding their contribution and its relation to existing work. By emphasizing the need for clarification and evidence, the comment guides the authors towards a more precise and impactful revision of their paper. It helps them understand what needs to be shown to support their claims."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer is asking a question about the impact of the GS module on the effective receptive field, rather than providing explicit instructions on how to improve it. While the question is relevant, it doesn't directly tell the authors what to do or how to apply a change.", "grounding_specificity_rationale": "The reviewer mentions the 'GS module' and 'effective receptive field,' but doesn't specify the exact location or section of the paper being referred to. The reference to '2' also adds to the lack of specific grounding.", "verifiability_rationale": "The review point is a question, not a declarative statement that requires verification. Therefore, it doesn't contain a claim that needs to be supported by evidence.", "helpfulness_rationale": "The review point is a question about a potential improvement, but it doesn't actively engage with the authors' needs for improvement or provide actionable feedback. It acknowledges the question but doesn't provide a response that would be helpful to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The suggestion is explicit in proposing adding another head to the network for computing value functions. However, it lacks specific details on how this addition would be implemented or what changes would be made to the LSTM architecture. The action is clearly stated, but the implementation details are missing, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer suggests adding another head to the network for computing value functions. While the suggestion is specific about the *what* (adding a head), it does not explicitly identify the *where* within the LSTM network or the *type* of head to be added. The grounding is present in identifying the *action* (adding a head), but the specificity of the implementation details is lacking.", "verifiability_rationale": "The reviewer states that the objective for the LSTM part would be the same for pretraining and finetuning. This is presented as a claim that needs verification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The justification for this claim is missing, making it 1.", "helpfulness_rationale": "The reviewer suggests that adding another head to the network for computing value functions is a potential improvement for the LSTM architecture in the finetuning stage. This suggestion is relevant to the authors as it offers a practical alternative to retraining from scratch. The suggestion is clear and directly addresses the need for efficient finetuning. Therefore, it provides helpful guidance to the authors."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC's regularization. This is not a direct instruction for the authors to perform an action, but rather a request for clarification on the relationship between these two methods. While the information could be actionable if provided clearly, the reviewer is not prompting the authors to implement or adapt their work based on this information.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'G4RL' and 'HRAC' and asks about their combination and the potential dependency of G4RL on HRAC. This directly identifies the specific parts of the paper (or the concepts being discussed) being addressed. The reviewer is also asking about the *relationship* between them, which is a specific detail. Therefore, the grounding is explicit and the target is clearly defined.", "verifiability_rationale": "The reviewer is posing a question about the rationale and relationship between G4RL and HRAC. This is a request for information, not a claim that needs to be verified. There is no assertion of truth or falsehood involved in the reviewer's point.", "helpfulness_rationale": "The reviewer is asking for clarification on the rationale and relationship between G4RL and HRAC. While this information could be helpful for the authors to understand the context and potentially improve their own work, the request itself is not a direct action or claim. It's a request for information that, while potentially useful, doesn't inherently improve the draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests 'it would be good to acknowledge some of the older works too.' While this implies an action (acknowledging older works), it doesn't explicitly state how to do this. The suggestion is more of a desire or a recommendation for improvement rather than a direct instruction on what needs to be done. Therefore, it's 2 as it points towards an improvement but lacks specific guidance on the implementation.", "grounding_specificity_rationale": "The reviewer mentions 'related works' generally, without specifying a particular section, table, figure, or unique aspect of the paper. The suggestion is broad and doesn't pinpoint where the older works should be acknowledged. Therefore, the grounding is weak as the specific part of the paper being addressed is not clearly identified.", "verifiability_rationale": "The reviewer states 'it would be good to acknowledge some of the older works too.' This is a suggestion or a desire for improvement, not a claim that something is missing or incorrect. There is no assertion that the current related work section is flawed or needs justification. Therefore, it contains X and is not verifiable.", "helpfulness_rationale": "The reviewer suggests 'it would be good to acknowledge some of the older works too.' This points towards a valuable improvement in the related work section, specifically suggesting a better organization or referencing of older works. While the suggestion is vague, it provides a direction for the author to take. Therefore, it is 3 as it suggests a concrete improvement, even if the exact method of implementation is not specified."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their confusion about the results in Table 2 and asks a question. This directly points to a lack of clarity in the explanation of the experimental results and how the expected outcome should be interpreted. The reviewer is directly identifying a need for further explanation.", "grounding_specificity_rationale": "The reviewer mentions 'the results in Table 2' and 'uniform sampling should lead to better performance'. This indicates a clear identification of the specific part of the paper (Table 2) being referenced. However, the reviewer doesn't explicitly state *which* part of Table 2 is causing confusion, making the grounding somewhat weak. The reviewer also states an *expected* outcome based on the authors' claims, which is a logical deduction but not a direct critique of the paper's content.", "verifiability_rationale": "The reviewer states their *belief* that 'increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling, especially when the performance of architectures in the good subregion are rather close'. This statement is based on a logical understanding of the experimental setup and the authors' claims. However, it doesn't provide a detailed explanation or justification for this belief, making the verifiability somewhat limited.", "helpfulness_rationale": "The reviewer's confusion about the experimental results and their direct question about why uniform sampling isn't clearly superior are 5. They are directly pointing out a lack of clarity in the explanation of the experimental findings and how they should be interpreted. This feedback is very helpful for improving the understanding of the results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies potential issues with the time complexity and points to specific components of the method (itemoriented autoencoder, elementwise function, and the number of hidden units) as potential sources. While the reviewer doesn't explicitly state how to address these issues, they suggest that these components might be contributing to the high complexity. This indicates an implicit suggestion for improvement, but it lacks a direct, actionable instruction. The reviewer identifies a problem and points to potential causes, but doesn't provide a clear path for the authors to fix it.", "grounding_specificity_rationale": "The reviewer refers to 'the time complexity' and 'the proposed method' as the areas needing improvement. While 'the proposed method' is a general reference, the reviewer also mentions specific components like 'itemoriented autoencoder,' 'elementwise function,' and 'number of hidden units.' This provides some level of specificity, but it's still a general reference to the overall method rather than a specific section or table. Therefore, the grounding is weak but offers some specificity by naming potential problem areas within the method.", "verifiability_rationale": "The reviewer states that 'the time complexity seems rather high' and points to specific components of the method as potential causes. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion of high time complexity. The reviewer simply states the potential issue without providing any justification. Therefore, the claim is not supported by any evidence.", "helpfulness_rationale": "The reviewer identifies a potential issue (high time complexity) and points to specific components of the method as potential causes. This is a valuable piece of feedback as it highlights a potential bottleneck or area for optimization in the proposed method. While the reviewer doesn't offer a direct solution, they do point out specific areas that might be contributing to the problem. This provides the authors with a clear direction for further investigation and potential improvements. The feedback is constructive and points to specific components for the authors to examine."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'improve the figures'. It further suggests a concrete method: 'make them clearer by specifying the type of autoencoder'. This action is directly linked to a specific aspect of the paper (the figures) and provides a clear direction for improvement. The suggestion to specify the type of autoencoder (pretrained solution encoders & solution decoders) is a concrete step that the authors can take to potentially address the clarity issues.", "grounding_specificity_rationale": "The review point explicitly mentions 'pretrained solution encoders & solution decoders' when discussing the figures. This direct mention allows the authors to accurately identify the specific aspect of the paper being addressed. The suggestion is also directly tied to this identified component, specifying how the clarity issue might be improved by referencing a specific type of autoencoder. This provides a clear and specific target for the authors to focus on.", "verifiability_rationale": "The review point makes a claim: 'Many of the figures would be more clear if they said pretrained solution encoders & solution decoders, since there are multiple types of autoencoders.' This claim is supported by a suggestion: 'make them clearer by specifying the type of autoencoder'. While the suggestion itself is verifiable (it's a concrete action the authors can take), the initial claim about clarity being improved by specifying the type of autoencoder lacks external references or specific examples within the review point itself. The suggestion acts as the verification, but the claim as stated is 3.", "helpfulness_rationale": "The review point is directly addressing a potential weakness the authors might be experiencing with their figures (lack of clarity). It offers a specific suggestion to improve this, which is to specify the type of autoencoder. This actionable feedback empowers the authors to potentially address the clarity issues. While the helpfulness is conditional on the authors understanding the difference between encoders and decoders, the suggestion itself is a valuable and direct improvement strategy. The reviewer has identified a likely problem and provided a clear path towards resolution."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the *lack* of comparison with specific NeRFbased methods (Zero1to3) and the occlusion experiment. While they don't provide explicit instructions on *how* to improve these comparisons, they clearly identify the *areas* for improvement. This indicates an implicit action, making it actionable.", "grounding_specificity_rationale": "The reviewer mentions specific methods (Zero1to3 and pointe) as missing comparisons, which grounds the comment. They also refers to the 'occlusion experiment' which is a specific part of the paper. While the reviewer doesn't explicitly state *how* the method is proposing something specific to occlusion, they clearly express a lack of relevance, which can be inferred. This makes it somewhat grounded and specific.", "verifiability_rationale": "The reviewer states that the method lacks comparison with NeRFbased methods and that the occlusion experiment is irrelevant. While they state these claims, they do not provide any logical reasoning, common knowledge, or external references to support these statements. The claims are presented as opinions without justification.", "helpfulness_rationale": "The reviewer criticizes the lack of comparison with specific methods and the perceived irrelevance of the occlusion experiment. While this feedback is valuable, it doesn't offer concrete, actionable suggestions beyond what was already implied in the review point. It primarily points out weaknesses without providing clear directions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states two actions they believe would be helpful for the authors: 'A brief explanation of \u201cmultiaspect\u201d' and 'Figure 1: Subscripts s and t should be 1 and 2?'. These are direct, actionable requests for information or clarification.", "grounding_specificity_rationale": "The reviewer does not explicitly state where the explanation of 'multiaspect' is supposed to be, nor does the reviewer directly identify the subscripts in Figure 1. The reviewer can infer that the paper is missing an explanation and that the subscripts are likely intended to represent specific elements, but they cannot precisely identify them.", "verifiability_rationale": "The reviewer makes a claim about the paper: 'A brief explanation of \u201cmultiaspect\u201d would be helpful' and 'Figure 1: Subscripts s and t should be 1 and 2?'. This claim is supported by the reviewer's observation that the paper lacks this information and the subscripts are unclear. However, the reviewer does not provide specific references or examples to support these claims.", "helpfulness_rationale": "The reviewer's comments are directly addressing potential areas of confusion or lack of clarity in the paper. Requesting a definition for 'multiaspect' and clarifying the subscripts in Figure 1 are both actionable suggestions that would likely improve the reader's understanding and the overall quality of the paper."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer asks 'how the parts of sentences and documents are extracted?' and 'Do the rules of extraction have any effect on the experiment?'. This is an implicit request for clarification on a methodological aspect. While the reviewer is interested in the process, they don't explicitly state an action they want to take based on this information. The request itself doesn't provide a concrete action or solution. The phrase 'I would like to know' indicates a desire for more information, which is characteristic of an implicit action, but without specifying what to do with this information, it's not actionable in itself.", "grounding_specificity_rationale": "The reviewer asks 'p indicates the proportion of documents, I would like to know how the parts of sentences and documents are extracted? Do the rules of extraction have any effect on the experiment? I hope to see a more detailed analysis.' The reviewer is asking about a specific calculation (proportion of documents) and a specific process (extraction of parts of sentences and documents). While they don't explicitly state which section of the paper this proportion refers to, they are asking about a specific aspect of the document. This weakly grounds the request. However, the reviewer doesn't specify *how* the extraction is done, leaving the rules unspecified and potentially impactful. The request is for information about a process, not a direct instruction on what to do. The phrase 'I hope to see a more detailed analysis' suggests a lack of clarity about the current analysis, indicating a lack of specificity in the request itself.", "verifiability_rationale": "The reviewer poses a question: 'p indicates the proportion of documents, I would like to know how the parts of sentences and documents are extracted?'. This is a request for information, not a claim or assertion. There is no statement of what the proportion is, why it's important, or how it's calculated. Therefore, there's no verifiable evidence or justification provided in this review point.", "helpfulness_rationale": "The reviewer's request is for clarification and a desire for a 'more detailed analysis'. This indicates a lack of immediate actionable insights or a clear understanding of the information being requested. The reviewer isn't providing a specific problem or question that they believe is valuable for the author. The request itself is a question, not a statement of a problem or a suggestion for improvement. The lack of a clear action or insight makes this review point less helpful."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment asks for information that the authors should be able to determine themselves, specifically the computation time, hardware, and experimental setup. While it doesn't explicitly state what to do with this information, the authors can infer that this information is relevant for understanding the practical aspects of the experiments and ensuring reproducibility. However, it doesn't directly guide them on how to implement the experiments or make specific changes to their draft.", "grounding_specificity_rationale": "The comment asks for information about the implementation process and resource requirements, which is general and doesn't specifically point to a particular part of the paper (e.g., 'Section 3.2 needs improvement'). The authors have to infer where this information is relevant. Therefore, the grounding is weak as the authors need to make an educated guess about the relevance of the information.", "verifiability_rationale": "The comment asks for factual information about the implementation and resource requirements. While it doesn't present a claim that needs verification, the information itself is verifiable through the authors' own experiments and knowledge of their hardware. The authors can logically reason about the typical time and resources required for similar experiments and can potentially verify the hardware specifications. Therefore, the claim (the existence of this information) is verifiable, but the information itself is not presented as a claim needing external justification.", "helpfulness_rationale": "The comment asks for information about the computation required to implement the experiments, including time, hardware, and experimental setup. This information is valuable for understanding the practical aspects of the experiments, ensuring reproducibility, and contextualizing the work. While the information isn't directly telling the authors *how* to implement the experiments, it provides a crucial understanding of the resources and steps involved. Therefore, it is 3 for the authors to understand the implementation details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point directly asks a question and provides a clear direction for the authors to address it: 'please provide more discussion' and 'please specify the epoch'. This indicates a clear intent to understand a specific implementation detail, making it actionable.", "grounding_specificity_rationale": "The comment explicitly mentions key components: 'meta sampler,' 'decoupled way,' 'linear classifier,' and 'epoch.' These are all specific terms within the context of the paper, allowing the authors to identify the relevant part and understand what needs to be discussed, making it fully grounded.", "verifiability_rationale": "The review point is a question rather than a declarative statement containing a claim. Therefore, it doesn't require verification in the sense of supporting evidence. However, it points to a potential area of confusion or missing detail in the paper, which could be considered a form of implicit verification that the authors need to address.", "helpfulness_rationale": "The review point directly addresses a potential ambiguity in the method description by asking about a specific implementation detail ('decoupled way' and 'epoch'). This is likely to be helpful as it encourages the authors to clarify a crucial aspect of their work, making it easier for readers to understand and potentially replicate their results."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors used their own defined 'vanilla metric' and lacks 'related fairnessaware metrics like Equality odds (EO)'. This is an explicit statement of what the authors did not do, and it implies an actionable suggestion: the authors should have used standard, fairnessaware metrics. The suggestion to conduct more experiments on more datasets is also an explicit action to take. The citation to the AAAI paper further suggests a specific area of research that the authors should have considered. Therefore, the review points to clear and actionable feedback for the authors.", "grounding_specificity_rationale": "The review point mentions 'related fairnessaware metrics like Equality odds (EO)' and suggests 'conducting more experiments on more datasets like COMPAS and Drug Comsumptionm'. This demonstrates an attempt to ground the feedback in specific concepts and potentially specific experimental setups. However, it doesn't explicitly state which fairness metric or which other dataset the authors should have used. The suggestion to follow the AAAI paper is also general and doesn't specify which part of the paper they should have followed. Therefore, while the review touches upon specific areas, it doesn't pinpoint the exact missing element, leading to a '3' assessment.", "verifiability_rationale": "The review point makes a claim about the authors' methodology (using their own defined metric) and suggests a reason (lack of fairness and the need for more comprehensive evaluation). It also recommends conducting more experiments and citing a specific paper. While the review points to a potential issue and offers a solution, it doesn't provide specific references or detailed justifications for why the authors' approach is problematic or why the suggested experiments are necessary. The suggestion to follow the AAAI paper is a general recommendation. Therefore, the verifiability is moderate, as the claim is supported but lacks key elements like examples or references.", "helpfulness_rationale": "The review point clearly identifies a problem with the authors' methodology (using a custom, potentially unfair metric) and provides actionable suggestions for improvement (using standard fairness metrics, conducting more experiments on diverse datasets, and following relevant research). The recommendation to follow the AAAI paper is a direct pointer to a specific area of research that addresses the identified issue. The suggestions are concrete and directly address the potential problems. Therefore, the review provides valuable and actionable feedback to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'remove L107114'. It also provides a concrete reason for this action: 'it seems speculative or overly opinionated'. The action is to remove a specific section, and the reason is clearly stated.", "grounding_specificity_rationale": "The comment explicitly mentions 'L107114', which is a specific section in the paper. However, it does not explain why this section is problematic or what specific issues it contains. The grounding is to the section number, but the specificity of the issue is missing.", "verifiability_rationale": "The comment contains a claim: 'L107114 seems speculative or overly opinionated'. However, it does not provide any evidence or justification to support this claim. It is purely a subjective judgment without any logical reasoning or references.", "helpfulness_rationale": "The comment is helpful because it identifies a potential area for improvement (section L107114) and suggests a concrete action (removal). While the justification for why it's speculative is missing, the suggestion itself is a valuable piece of feedback for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests considering baselines, which implies a concrete action: investigating the performance of Rope and Alibi relative positional embeddings. While not explicitly stating 'add these baselines,' the suggestion points to a clear area of further analysis and experimentation.", "grounding_specificity_rationale": "The review point mentions 'Rope and Alibi relative positional embeddings' as a specific type of baseline to consider. While it doesn't explicitly name a section, table, or figure, it clearly specifies the *type* of baseline, indicating a degree of grounding specificity.", "verifiability_rationale": "The review point presents a suggestion about considering specific baselines rather than a claim that requires verification. It doesn't state that the current method is flawed or lacking justification. Therefore, it doesn't contain a verifiable claim.", "helpfulness_rationale": "The review point suggests considering baselines as a way to verify performance improvements. This is a constructive suggestion that guides the authors towards further analysis and experimentation. It points to a potential area for improvement or further investigation, making it helpful in that context."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for information about the value of the neighborhood size h and its influence on the model's performance. While it doesn't provide concrete actions or modifications, it directly points to specific aspects of the paper that need clarification or analysis. The request for a 'constant set of parameters' implies a need for a specific action, which is to identify and document these parameters. The request for 'robustness' also suggests a desire for a specific analysis, indicating an implicit action. However, the action is not explicitly stated, making it somewhat implicit.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper it is addressing. It refers to the 'value of neighborhood size h' and the 'model's performance' in general, without pinpointing a specific section, table, figure, or unique element. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses. The comment also does not specify what needs to be addressed in this part (the value of h or the performance analysis).", "verifiability_rationale": "The review point contains a claim: 'Another important missing element from the paper is the value of neighborhood size h, as well as an analysis of its influence over the model's performance. This is the key parameter of the proposed strategy and providing readers with intuitive knowledge of the value of h to use, and the robustness of the method with respect to larger or smaller neighborhoods is essential. Similarly, different hyperparameter sets are used per dataset, which is not ideal. Can authors provide insights into how performance varies with a constant set of parameters?' This claim is not verifiable because the reviewer does not provide any evidence, reasoning, or references to support their statement about the missing information and the inconsistency in hyperparameter usage. The reviewer simply states the issues without explaining why they are important or providing any basis for the expected behavior of the model with constant parameters.", "helpfulness_rationale": "The review point is 5 as it directly points out significant gaps in the author's work. The reviewer clearly identifies the missing information regarding the neighborhood size h and its influence on performance, which is a crucial aspect of the proposed strategy. By asking for this information and insights into the use of constant parameters, the reviewer encourages the author to address a key weakness and improve the clarity and reproducibility of their work. The request for robustness also prompts the author to provide a more thorough analysis. While the review doesn't provide the information itself, it guides the author towards specific areas that need clarification and investigation, which is a valuable contribution to the peerreview process."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the model's behavior with imperfect multimodal data. It doesn't explicitly state what needs to be done. While it suggests exploring the model's robustness, it doesn't provide a specific, actionable step for the authors to take. The reviewer is prompting the authors to investigate the impact of missing data and the model's ability to leverage other modalities. This is more of a suggestion for further investigation than a direct action the authors should undertake immediately.", "grounding_specificity_rationale": "The review refers to 'the model' and 'multimodal data' without specifying a particular section, table, or unique aspect of the paper. While it identifies the problem (model behavior with imperfect data), it doesn't pinpoint the exact part of the paper where this behavior needs investigation or how to address it. The grounding is weak because the authors can only make an educated guess about where the issue lies. The specificity is also underspecific as the reviewer doesn't suggest a particular solution or location within the paper.", "verifiability_rationale": "The review presents a question about the model's behavior with imperfect multimodal data. It doesn't provide any claims, judgments, or suggestions. It's a question posed to the authors, not a statement that requires verification. There's no logical reasoning, common knowledge, or external references provided within the review point itself to support any implicit claims about the model's behavior. Therefore, it's 1 as it doesn't contain a claim that needs justification.", "helpfulness_rationale": "The review raises a relevant question about a potential limitation of the model and suggests exploring its robustness to missing data. This provides insight into the model's behavior and can guide the author in improving their model's training or architecture. While it doesn't directly provide a solution, it prompts the authors to investigate and potentially address the issue, which is a valuable contribution. The reviewer is asking a question that, if answered, could significantly improve the model."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests an analysis of the SST dataset regarding negation and intensity words, which is a suggestion for further investigation, not a direct instruction on how to improve the current draft. The reviewer is proposing a *what* (analysis) rather than a *how* (improvement).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the SST dataset' and 'negation or intensity words,' which clearly identifies the specific part of the paper and the aspect of the data being analyzed. This provides a clear grounding point.", "verifiability_rationale": "The reviewer is suggesting a *thing to do* with the dataset (perform the analysis) rather than making a claim that needs verification. The suggestion itself doesn't contain a claim that is supported by logical reasoning, common knowledge, or external references. The *content* of the suggestion could be verifiable, but the suggestion itself isn't a claim requiring verification.", "helpfulness_rationale": "The reviewer's suggestion is about a potential area for deeper analysis of the SST dataset. While it doesn't directly tell the authors what to change in their current draft, it points out a potential improvement and could be helpful for their understanding and potentially lead to better results. It's not a direct instruction, so it's not 5, but it's more than just a vague comment."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states \"Authors don\u2019t verify the stability of the OGEAug on OOD benchmarks\". This clearly identifies an action the authors should take (verify stability) and states that this action is not being done. The suggestion to use DrugOOD and validate SPE is a direct action to achieve this verification. The reviewer is pointing out a lack of implementation of a clear action.", "grounding_specificity_rationale": "The review point mentions \"OOD benchmarks\" generally. While it doesn't provide a literal section number or table title, it points to the concept of OOD benchmarks. The reviewer then specifically names \"DrugOOD\" and suggests \"validating SPE\" on it. While the initial mention of \"OOD benchmarks\" isn't a perfect \"full grounding\", the subsequent mention of \"DrugOOD\" makes it clear which specific benchmark is being referred to. The specificity of the suggested benchmark and validation method further enhances the grounding.", "verifiability_rationale": "The review point contains a clear claim: \"Authors don\u2019t verify the stability of the OGEAug on OOD benchmarks\". This claim is supported by the suggestion to use DrugOOD and validate SPE. The reviewer provides a specific method (DrugOOD and validating SPE) to verify the stability, making the claim verifiable through this suggested action.", "helpfulness_rationale": "This review point is 5 because it directly identifies a potential weakness in the authors' methodology (lack of OOD benchmark verification) and provides a concrete suggestion for improvement (using DrugOOD and validating SPE). This actionable feedback is immediately actionable and provides a clear next step for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests specific alternative methods (freezing BERT layers and LoRA) and states that these methods are 'natural to think about' and could provide a 'valuable basis for experimental comparison'. This indicates an explicit action: exploring these alternative methods. However, the review point lacks details on *how* to implement these suggestions, making it somewhat vague on the action to be taken. For example, it doesn't specify which layers to freeze or the parameters for LoRA.", "grounding_specificity_rationale": "The review point does not explicitly refer to any specific part of the paper (e.g., a particular section, table, or figure). It is a general suggestion about methods for dimensionality reduction. Therefore, it cannot be grounded to any specific aspect of the paper.", "verifiability_rationale": "The review point does not contain a claim. It is a suggestion for future work rather than a critique or assertion of something. Therefore, it does not have verifiability in the sense of supporting or refuting a statement.", "helpfulness_rationale": "The review point provides a clear direction for future experimentation by suggesting alternative methods to SVD for dimensionality reduction. It explicitly mentions specific techniques (freezing BERT layers, LoRA) and their potential benefits. The statement that these methods are 'natural to think about' and could provide a 'valuable basis for experimental comparison' suggests a helpful and insightful perspective for the authors. While it doesn't directly identify a weakness in the current approach, it offers concrete suggestions for improvement, making it 5 in guiding further research."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "6", "helpfulness_label": "3", "actionability_rationale": "The review point lacks explicitness and concreteness. It's a general suggestion without actionable steps, making it 1.", "grounding_specificity_rationale": "The review point mentions 'related work section' and 'strong baselines that use the coordinates,' which are weak groundings. It also lacks specificity in its suggestions.", "verifiability_rationale": "The review point consists of suggestions, not declarative claims, making it a 'X'.", "helpfulness_rationale": "The review point identifies areas for improvement but lacks specifics, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the action of 'training on multiple seed experiments' and provides a clear consequence of doing so ('more robust evaluation'). The suggestion is direct and actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'Single Seed Experiments' and implies the need for 'multiple seed experiments'. While it doesn't pinpoint the exact section, the reference is clear, and the reviewer can infer the specific area of concern. The comment also specifies the goal of improving 'performance differences and the true impact of the proposed cycle consistency loss on convergence'.", "verifiability_rationale": "The comment contains a claim ('Multiple seed experiments would provide a more robust evaluation') but does not provide sufficient justification or supporting evidence for this claim. It lacks specific examples or references to back up the assertion that multiple seeds would lead to a more robust evaluation.", "helpfulness_rationale": "The comment directly identifies a limitation in the experimental setup (single seed experiments) and provides a clear and actionable suggestion (training on multiple seed experiments). This directly addresses a valid concern and guides the authors towards a concrete improvement."}
{"actionability_label": "5", "grounding_specificity_label": "X", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a question about the motivation behind using VMF and the truncated normal distribution. This directly points to a lack of explanation or justification for a methodological choice, making it 5 for the authors to seek clarification.", "grounding_specificity_rationale": "The reviewer's question is about the *motivation* behind using these distributions, not about a specific part of the paper or the method itself. Therefore, it doesn't fit the definition of grounding specificity.", "verifiability_rationale": "The reviewer is not making a claim about the VMF distribution or the truncated normal distribution themselves. They are asking *why* these were chosen, implying a lack of explicit justification or reasoning provided in the original work. While the distributions are defined (verifiable), the *why* is missing, making it 3 but lacking a clear explanation.", "helpfulness_rationale": "The reviewer is asking for a justification for a methodological choice, which is a common and valuable request. It directly addresses a potential bottleneck for the authors and helps them understand the method better, making it 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies the *problem* (missing citation) and implies the *action* (adding the citation). While the action isn't explicitly stated in detail, the reviewer clearly indicates what needs to be done. However, the action is vague on *how* to identify the missing citation or *where* to find it.", "grounding_specificity_rationale": "The review point explicitly mentions 'L425', the specific line number where the issue occurs. This clearly identifies the part of the paper being addressed, making it fully grounded. The comment also clearly specifies the *issue* (missing citation), making it specific to that part.", "verifiability_rationale": "The review point does not contain a claim. It is a statement of fact: 'Missing citation for the public skipgram data set in L425'. There is no suggestion, judgment, or request for changes. Therefore, it does not fall under the 'X' category (X).", "helpfulness_rationale": "The review point identifies a valid issue (missing citation) which is helpful in pointing out a problem. However, it does not provide any suggestions or guidance on how to address the issue. The reviewer simply states the problem without offering any constructive feedback on how to fix it."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "Partially Verifiable", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the suggestion to 'compare this system, which also captures semantics.' This is an explicit action. However, the reviewer also offers 'improvement suggestions' like 'Even, Ref2 can be a strong baseline to compare the performance of the current system. Suggestions to improve:' This action is vague and lacks specific details on how to perform the comparison or what specific improvements are being suggested.", "grounding_specificity_rationale": "The reviewer mentions 'RNN based models' and 'semantics' as key aspects of the current system. While they identify some aspects, they don't pinpoint a specific weakness or area of improvement within the current system that needs to be addressed through this comparison. The suggestion to compare with Ref2 is a suggestion, not a specific problem with the current system's output or methodology.", "verifiability_rationale": "The reviewer makes a claim by stating 'It would be better to compare this system, which also captures semantics.' This claim is suggested as a beneficial step. The reviewer implicitly supports this claim by mentioning Ref2 as a 'strong baseline' and offering 'improvement suggestions.' However, the reasoning behind *why* this comparison is beneficial and *how* it would improve the system is not explicitly detailed.", "helpfulness_rationale": "The reviewer offers a suggestion for improvement by recommending a comparison with another system and providing general improvement suggestions. While this points in a helpful direction, the specific actions to take based on this suggestion are not clearly defined. The suggestion is broad and lacks concrete steps."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper does not explain how the quantitative results are obtained. They also state that the paper does not detail the data used for training, validating, and testing. This is a clear indication that the missing information is directly relevant to the action the reviewer would take, which is to seek clarification on these aspects. The reviewer understands the importance of this information and can directly identify the missing steps needed to replicate or understand the results. Therefore, the review point is 5 as the authors can directly identify the missing information they need.", "grounding_specificity_rationale": "The reviewer states that 'it is not clear how the quantitative results are obtained' and 'what data exactly is used for training, validating and testing'. While the reviewer identifies a gap in the information, they do not specify *which* part of the paper lacks this information. They are broadly stating that the details are missing. Therefore, while the information is missing, the reviewer does not pinpoint the exact location of the missing information, making the grounding weak. The information is generally lacking, but not specifically tied to a particular section or table. The reviewer could have provided more specific examples, but the lack of any specific reference makes it weakly grounded.", "verifiability_rationale": "The reviewer makes a claim that 'it is not clear how the quantitative results are obtained' and 'what data exactly is used for training, validating and testing'. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. They are simply stating that the information is missing. There is no verification provided for this statement. Therefore, the claim is 1 as no evidence or justification is given to support the reviewer's assertion about the lack of clarity.", "helpfulness_rationale": "The reviewer's point is highly relevant and addresses a fundamental concern for researchers. Understanding how quantitative results are obtained and the specifics of the data used for training, validation, and testing is crucial for reproducibility and interpreting the findings. The reviewer's comment directly points to a missing piece of information that would significantly enhance the authors' ability to understand and potentially reproduce their work. Therefore, the review point is 5 as it directly addresses a critical aspect of the research."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the reasons for the model's failure are unclear and suggests investigating assumptions, learning difficulties, or other factors. This is a direct identification of a specific area for improvement, making it actionable. The reviewer is pointing to a concrete issue that the authors can directly address.", "grounding_specificity_rationale": "The comment explicitly mentions the 'triangle dataset' and the 'model's failure to identify true sources'. This directly points to a specific part of the paper and the issue within it. The reviewer is not making a general statement but rather focusing on a particular experimental setup and its outcome. This strong identification makes it fully grounded.", "verifiability_rationale": "The comment states that the reasons for the model's failure are unclear. While it doesn't provide a specific claim that needs verification, it sets up questions that could be investigated through further analysis or experimentation. The lack of clarity itself is a verifiable state, indicating a gap in understanding. It doesn't propose a solution, but it identifies a problem that needs further exploration.", "helpfulness_rationale": "The comment identifies a gap in understanding regarding the model's failure on the triangle dataset and suggests investigating potential causes. This provides a clear direction for the authors to seek clarification or further analysis. While it doesn't offer a definitive solution, it points to a specific area where improvement is needed, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states their intention to clarify 'how' and 'why' the SE framework can help, but does not provide a concrete action or suggestion on how to implement this clarification. The action is implied but not explicitly stated, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions a specific reference (1) and a general concept (SE framework), indicating a weak grounding as they do not explicitly identify a specific section, table, or unique aspect of the paper being addressed. The specificity of the request is also low as it is a general question about how and why the framework helps.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It is a request for clarification and explanation.", "helpfulness_rationale": "The review point directly addresses a potential weakness in the authors' work by suggesting a relevant technique (SE framework) and asking for clarification on its application. This is a helpful comment as it guides the authors to improve their draft by providing a relevant context and a request for information."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their desire for the system to generalize to more views, which is a clear and actionable request.", "grounding_specificity_rationale": "The reviewer refers to 'two views' and 'more views,' explicitly identifying the aspect of the system they are concerned about. While they don't define the views themselves, the focus on 'views' makes the grounding relatively strong.", "verifiability_rationale": "The statement is about a desired feature, not a claim requiring evidence or justification. Therefore, it does not contain a claim that needs verifiability.", "helpfulness_rationale": "The request is a suggestion for improvement, not a critique of the current system. While potentially helpful, it's a specific feature request rather than a direct, actionable criticism for immediate improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: 'these metrics are not suitable for the datasets provided, but would not be applicable in a setting where either the task boundaries are not known or there are no hard task boundaries to be identified.' This is an explicit action stating a problem. The reviewer also specifies the metrics (continual learning, loss after switch, recovery time after switch) and the type of datasets (those without clear task boundaries), making the action explicit and grounded.", "grounding_specificity_rationale": "The reviewer explicitly names the metrics (continual learning, loss after switch, recovery time after switch) and the characteristics of the datasets (those without clear task boundaries or hard task boundaries). This is a strong form of grounding as the reviewer can accurately pinpoint the section, table, figure, or unique aspect being addressed (metrics and dataset type). The mention of 'one of the main selling points of the paper' further clarifies the context.", "verifiability_rationale": "The reviewer makes a claim: 'these metrics are not suitable for the datasets provided, but would not be applicable in a setting where either the task boundaries are not known or there are no hard task boundaries to be identified.' The reviewer provides a logical reasoning based on the definition of these metrics and how they are typically used in scenarios with known task boundaries. While the reviewer doesn't provide external references, the reasoning is based on common knowledge about these metrics. The claim is supported by the established purpose of these metrics.", "helpfulness_rationale": "The reviewer provides a clear and actionable criticism: 'these metrics are not suitable for the datasets provided, but would not be applicable in a setting where either the task boundaries are not known or there are no hard task boundaries to be identified.' This criticism directly points to a need for improvement in the paper's evaluation methodology. The reviewer also offers a constructive alternative: 'these metrics would not be applicable'. This suggests a desire for the authors to consider alternative evaluation strategies."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The question is explicit about the temporal information flow in a decoderdecoder model. It asks *why* the decoder at time step t only uses information up to time step t, rather than the entire history. This is a clear request for an explanation of a specific aspect of the model's architecture and operation. The reviewer is looking for a concrete action: to understand the rationale behind this design choice. The information provided in the review point directly identifies the action to be taken (explain the temporal information flow) and provides details about the components involved (decoder at time step t and information up to time step t). Therefore, this review point is 5.", "grounding_specificity_rationale": "The reviewer is asking a question about the decoder at time step t and its use of information up to time step t. This requires understanding a specific component of the model and its function. While the reviewer doesn't explicitly name a section or table, the question is directly about a specific part of the model's operation. The information provided in the review point helps to ground the question to a specific component (the decoder at time step t). However, the reviewer might not be fully clear on the exact mechanism or the specific information being used, making it somewhat underspecific. Therefore, this review point is somewhat grounded.", "verifiability_rationale": "The reviewer is making a claim about the design of the decoderdecoder model, specifically questioning why the decoder at time step t uses only information up to time step t. This is a valid claim about the model's architecture. The answer to this question would involve explaining the role of the encoder in providing contextual information and the mechanism by which the decoder uses this information. This information can be found through knowledge of sequence models. Therefore, this review point is 5.", "helpfulness_rationale": "The reviewer is asking a valid question about the design of the decoderdecoder model. The question is clear and points to a specific aspect of the model's operation. However, the helpfulness depends on whether the reviewer already understands the basic principles of sequence models. A good answer would explain the role of the encoder and the encoderdecoder architecture. While the question is valid, the answer might not be immediately clear to someone who doesn't understand the basics of sequence models. Therefore, this review point is 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to consider the hyperparameter \u03b3, but it doesn't provide any explicit or implicit guidance on how to set it, how to analyze its sensitivity, or what the implications of different values might be. The reviewer is being asked to infer these details rather than being given concrete instructions. This falls under the 'Implicit' category of actionability, as the authors need to deduce the necessary steps from the comment. The 'Concrete' category would apply if the review directly stated the procedure for setting and analyzing the hyperparameter.", "grounding_specificity_rationale": "The review point does not explicitly mention any specific part of the paper related to the hyperparameter \u03b3. It is a general comment about the discussion of the hyperparameter being missing. Therefore, it cannot be grounded to a specific section, table, figure, or unique aspect of the paper. This falls under the '1' category of grounding specificity.", "verifiability_rationale": "The review point identifies a potential weakness in the paper (the missing discussion of the hyperparameter \u03b3) and suggests that the authors should investigate it. However, it does not provide any specific examples, references, or logical reasoning to support this claim. The reviewer is being asked to make an inference about the importance of the hyperparameter based on the context of the review. While the claim is present, the lack of supporting evidence makes it somewhat underjustified.", "helpfulness_rationale": "The review point identifies a valid area for improvement in the paper \u2013 the lack of discussion regarding the hyperparameter \u03b3. It provides a clear direction for the authors to take, which is to investigate and address this hyperparameter. However, the review point does not provide any specific guidance on *how* to set the hyperparameter, *how* to analyze its sensitivity, or *why* it is important. The reviewer is being asked to infer this information rather than being given concrete instructions. This makes the review point 3 in identifying a gap but not entirely helpful in providing a complete solution."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the action of ablating heads at different locations and provides a clear reason for this suggestion: to control for a confounding factor related to head location. The action is directly stated, making it explicit. The suggestion is also concrete, indicating a specific type of controlled baseline.", "grounding_specificity_rationale": "The reviewer refers to 'induction heads' and 'FV heads' and mentions 'layers' within the model. This allows the reader to precisely identify the specific parts of the paper being addressed. The reviewer also explains the purpose of the ablation, which is to control for a confounding factor related to head location. This explanation is specific to the identified parts.", "verifiability_rationale": "The review point identifies a potential issue (induction heads and FV heads at different locations could be a confounding factor) and suggests a solution (controlled baseline). This constitutes a claim. However, the review point does not provide any specific evidence or references to support this claim or the proposed solution within its own text.", "helpfulness_rationale": "The review point raises a valid concern about a potential confounding factor in an ablation study and suggests a way to improve it by proposing a controlled baseline. This is generally helpful for researchers who are performing similar studies. However, the review point lacks specific details on how to implement this controlled baseline and does not directly address the performance difference mentioned in the context (ablating induction heads vs. FV heads). It focuses on a potential confounding factor rather than directly addressing the performance issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that a section on synonym identification is missing. This makes it an explicit action the authors should take. However, the comment doesn't specify what is missing or how it should be implemented, making it somewhat vague.", "grounding_specificity_rationale": "The comment explicitly mentions 'synonym identification section,' which allows the authors to accurately pinpoint the missing part. However, it doesn't specify the content or the approach used in that section. Therefore, it is weakly grounded but specific about the section itself.", "verifiability_rationale": "The comment itself is not a claim. It is a statement about a missing element. Therefore, it does not have verifiability as it lacks a claim to be verified.", "helpfulness_rationale": "The comment identifies a missing section that would be helpful for the authors, especially if they are implementing similarity measures. However, it lacks detail on what is missing, making it somewhat incomplete but still helpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states that an 'overview of the workflow and the model' is needed. This indicates an explicit action (providing an overview) that is not yet concretely defined. The reviewer identifies a potential area for improvement but does not specify what aspects of the workflow or model require this overview. Therefore, while the action is implied, it lacks the necessary detail to be actionable.", "grounding_specificity_rationale": "The review point refers to the 'workflow' and 'model' in general, without specifying a particular section, table, figure, or unique element of the paper. The reviewer does not identify a specific part of the paper that needs improvement. While the issue (lack of overview) is implied, the reference to the workflow and model is vague and does not ground the comment to a specific part of the paper. The specificity of the issue is also lacking.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It is a suggestion for the authors to provide more information about their workflow and model. There is no statement of opinion, judgment, or request for clarification that would necessitate supporting evidence. The comment is a request, not a claim.", "helpfulness_rationale": "The review point requests an 'overview of the workflow and the model'. While this can be helpful for the authors to understand the context and identify potential areas for improvement, it does not specifically identify a weakness or suggest a concrete change. It is a general request rather than a targeted feedback on a specific issue. Therefore, while relevant, it lacks the specificity to be 5 in guiding improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'please redefine the figure...as the expected quantities are scalars but shown as a vector.' This is a clear and actionable instruction. The authors can directly identify the action needed: redefining the figure, and understand exactly how to implement it: showing the scalars as vectors. The action is not inferred and is directly stated.", "grounding_specificity_rationale": "The review point directly mentions 'figure3' and specifies the desired change: 'as the expected quantities are scalars but shown as a vector.' This is a clear and precise reference to a specific part of the paper. The authors can easily identify the referenced element and understand the proposed modification. The grounding is explicit, and the specificity is about the *type* of figure, which is a clear and actionable detail.", "verifiability_rationale": "The review point does not contain a claim that something is wrong or needs to be changed. It is a suggestion for improvement rather than a statement requiring justification. Therefore, it does not fit into the categories of '1,' '2,' '3,' '4,' or '5'. The appropriate label is 'X'.", "helpfulness_rationale": "The review point provides a specific and targeted suggestion for improvement related to figure3. It tells the authors exactly what needs to be changed and how. This is likely to be a helpful suggestion as it directly addresses a specific issue and offers a clear direction for action. The authors can directly implement this suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the problem with 'ablations' and the desired improvement is 'better experiment setup'. This indicates an explicit action being suggested. However, the specifics of the ablations and the aspects of the experiment setup that need improvement are not detailed, making the action somewhat vague. Therefore, the comment is explicitly stated but the action is not concretely defined.", "grounding_specificity_rationale": "The reviewer refers to 'ablations' and 'experiment setup' generally. While 'ablations' is somewhat specific, the 'experiment setup' is a broader concept. The reviewer does not explicitly identify a specific section, table, figure, or unique element of the paper being addressed. The comment is 1 at a precise location within the paper. The comment specifies what needs improvement (better experiment setup) but not the exact part of the paper where this improvement is needed.", "verifiability_rationale": "The reviewer makes a claim: 'so many questions arise'. This is a subjective statement expressing a lack of clarity. While there's an implicit claim that the current setup is problematic ('The ablations seem to deserve better experiment setup'), this claim is not supported by any specific examples, references, or logical reasoning within the review point. The reviewer is suggesting improvement but not providing verifiable evidence of a flaw or a need for change. The comment expresses a desire for better setup, but it lacks the supporting evidence required for verifiability.", "helpfulness_rationale": "The reviewer's comment is a suggestion for improvement rather than a critique of a specific weakness in the paper. It does not identify a specific area where the work is lacking or provide concrete actionable steps for improvement. The comment is more of a 'call to action' than a constructive critique. Therefore, it does not provide significant value to the authors in terms of identifying areas for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'no empirical evidence is provided' and 'it would have been interesting for the authors to look deeper into this.' This indicates an implicit action of 'identifying a missing empirical evidence' but the action is not concrete as it doesn't specify how to look deeper or what kind of evidence is needed. The vagueness of 'look deeper' makes it 2.", "grounding_specificity_rationale": "The review mentions 'lowfrequency words,' 'sememes,' and 'word similarity data sets' as relevant aspects. However, it doesn't explicitly state which section, table, or figure contains this discussion. While the general areas are mentioned, the specific grounding of the discussion is not clear, making it weakly grounded. The specificity of the criticism is high as it directly relates to the proposed model and the datasets used.", "verifiability_rationale": "The review points out a lack of empirical evidence and suggests that the sememe mapping might not explain improvements due to frequent word pairs in the datasets. This doesn't present a claim that can be verified. It's a statement of a potential issue rather than a verifiable assertion. Therefore, it is not verifiable.", "helpfulness_rationale": "The review raises a valid concern about the lack of empirical support for the sememe mapping hypothesis. This is helpful for the authors as it highlights a missing piece of evidence. However, the suggestion to 'look deeper' is quite general and doesn't provide specific guidance on what experiments to conduct or how to analyze the data. While it points to a potential area for improvement, the lack of concrete suggestions makes it 3."}
{"actionability_label": "3: 4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests a comparison across different voxel resolutions, which is an explicit action. However, the other parts of the review point, such as questioning the computational cost and inquiring about the specific resolution, are implicit actions as the reviewer doesn't directly ask for the resolution or explain why the computational cost is a concern. The suggestions are concrete in terms of comparing different resolutions, but the initial questions are vague. Therefore, the actionability is mostly applicable, as the reviewer suggests a clear improvement but doesn't fully specify the current state or action needed.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'voxellike features' and '3D voxel' which grounds the discussion to a specific part of the paper. They also mention 'Sec4.2' and 'Sec4.2 by comparing with different resolutions of voxel features', further grounding the point to a specific section and the desired analysis. The observation about the 1x1x1 resolution also implicitly refers to a specific aspect of the voxel feature. Therefore, the grounding specificity is 5.", "verifiability_rationale": "The review point doesn't contain a claim that requires verification. It's a suggestion for further analysis and experimentation. There's no assertion that something is wrong or needs to be changed. Therefore, the verifiability is not applicable as there's X to be verified.", "helpfulness_rationale": "The review point raises valid questions about the methodology and suggests a concrete way to investigate a potential area of improvement. By proposing the comparison across different resolutions, the reviewer provides a clear direction for the authors to explore and potentially refine their approach. This makes the review point 5 as it directly addresses a potential limitation and offers a practical suggestion for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment identifies a potential issue in Table 3 (PM+CL behaving differently) and suggests a possible improvement (developing set trends). While the suggestion is implied, the issue is directly related to the content of Table 3, making it partially actionable.", "grounding_specificity_rationale": "The comment explicitly refers to 'Table 3' and mentions specific elements within it, such as 'PM+CL', 'PM', and 'CL'. This indicates a high level of grounding as the authors can directly identify the referenced part and the specific aspects being discussed.", "verifiability_rationale": "The comment makes a claim about the difficulty in seeing trends in Table 3 and suggests a logical next step (seeing development set trends). While it doesn't provide external references or detailed logical reasoning, the claim is based on the observed data in Table 3, making it 3.", "helpfulness_rationale": "The comment directly points out a weakness in the presentation of results in Table 3 and offers a concrete suggestion for improvement (developing set trends). This directly addresses the authors' need to understand and interpret their experimental results, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out specific issues: 'it is difficult to understand e.g. figure 5' and 'there are a lot of lines on top of each other'. These are explicit actions identifying problems. However, the reviewer does not specify *how* it is difficult to understand or *what* changes should be made. The reviewer suggests improvements ('e.g., make it easier to understand figure 5') but doesn't provide concrete details. Therefore, while the issues are clear, the suggestions are vague and lack specific implementation details, making it 2.", "grounding_specificity_rationale": "The reviewer mentions 'figure 5' and 'lines on top of each other' as specific elements within the paper. This indicates strong grounding as the paper section and the specific visual element are identified. The reviewer also points out issues with 'the main metrics reported' and suggests 'flops or model size', which are specific metrics. This indicates strong grounding as the paper content and specific metrics are referenced. Therefore, the grounding is fully grounded in both aspects.", "verifiability_rationale": "The reviewer states 'it is difficult to understand e.g. figure 5' and 'there are a lot of lines on top of each other'. These statements express a judgment or opinion about the figure's clarity. The reviewer also suggests 'the main metrics reported are performance compared to remaining weights' and 'flops or model size'. While these are suggestions, they are not supported by logical reasoning, common knowledge, or external references within the review point itself. The reviewer simply proposes these as improvements without explaining *why* they are necessary or how they would address the clarity issue or the missing metrics. Therefore, the claims are not welljustified.", "helpfulness_rationale": "The reviewer points out a clear weakness in the presentation of Figure 5 and suggests improvements. This provides a clear direction for the authors to improve their draft. The reviewer also identifies a gap in the reported metrics and offers concrete suggestions for improvement. Both points are actionable and directly address specific issues in the paper. Therefore, the review point is 5 as it identifies concrete areas for improvement and suggests specific changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point states, 'Some details of the proposed method are missing...'. This points to a lack of information but doesn't explicitly state what is missing or where to find it. The reviewer implies the missing details are relevant, but doesn't directly instruct the author on what to identify. Therefore, while it identifies a problem, the action to address it is not explicitly stated.", "grounding_specificity_rationale": "The review point states, 'Some details of the proposed method are missing...'. This points to a general area of missing information (the proposed method) but doesn't specify which part of that method is lacking details. The reviewer can make an educated guess, but cannot precisely identify the referenced part. Therefore, the grounding is weak.", "verifiability_rationale": "The review point states, 'Some details of the proposed method are missing...'. This is a statement of a problem, not a claim that requires verification. There is no suggestion to do something or justify something. Therefore, there is X to be verified.", "helpfulness_rationale": "The review point identifies a missing element in the proposed method. While this highlights a potential weakness, it doesn't offer specific guidance on what information is missing or how the author should proceed. The feedback is identifying a problem but lacks actionable steps. Therefore, it is not 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to improve the paper by simplifying and clarifying certain aspects. They point to specific sections and lines, indicating a clear action they believe should be taken. The reviewer suggests concrete actions like 'simplifying the description' and 'explaining the architecture and computations better'. These are direct and actionable steps that the authors can take to improve their draft.", "grounding_specificity_rationale": "The reviewer provides multiple ways to identify the specific parts of the paper they are referring to. They mention specific sections (Figure 7, Section 8) and a range of lines (3964). They also use general terms like 'simplification and better explanation' and 'architecture and computations' to pinpoint the areas needing improvement. This strong identification of the specific part of the paper, combined with the general areas of concern, demonstrates high grounding specificity.", "verifiability_rationale": "The reviewer identifies a problem ('Paper is too dense...not very easy to follow') and offers solutions ('simplifying the description and explaining the architecture and computations better'). This constitutes a claim that the paper is difficult to follow. While the reviewer doesn't provide specific examples of where the density hinders understanding or cite external literature to support their claim about clarity, the *solutions* offered are generally accepted practices in academic writing. The problem itself is generally verifiable through reading, and the solutions point towards common areas for improvement in clarity. Therefore, it can be considered 3 as it points to a generally verifiable issue with potential solutions.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improving the paper. They directly address the reader's experience of the paper being too dense and not easy to follow. They offer specific areas for improvement, such as 'simplifying the description' and 'explaining the architecture and computations better'. This feedback is directly aimed at enhancing the reader's understanding and experience with the paper, making it 5 for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer's suggestion is not explicitly stating what needs to be done, but rather suggesting an *action* (comparing EIGNN with GCNII on realworld datasets). The suggestion lacks specific details on how to perform this comparison or what metrics to use, making it implicit. The action itself (comparing models) is concrete, but the lack of detail makes the overall suggestion 1.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the evaluation on oversmoothing' and 'variants focusing on dealing with oversmoothing,' indicating a clear grounding in the specific area of evaluation. While the suggestion to use 'realworld datasets' is not fully specific (as many realworld datasets exist), it points to a relevant and concrete aspect of the evaluation. Therefore, the grounding is strong but could be more specific about the datasets and metrics. The suggestion directly addresses a potential improvement in the evaluation, making it somewhat specific.", "verifiability_rationale": "The reviewer's statement is not a claim that something is wrong with the current evaluation. It's a suggestion for an *additional experiment or comparison*. Therefore, it contains X and should be classified as 'X'.", "helpfulness_rationale": "The reviewer's suggestion is relevant to the topic of evaluation and could be valuable for the authors. However, as noted, it's a highlevel suggestion without specific details on which datasets to use or how to compare the performance. While it has the potential to be helpful, the lack of specificity limits its immediate usefulness. Therefore, it's '3' as it points to a valuable direction for future work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of a 'separate part or subsection' and the 'how to use the multiple prompts in the test stage'. This directly points out a missing element and the procedure for its implementation, making it explicit. The 'how to use' part, while vague on the *specific* method, is concrete in identifying the need for a clear explanation. The reviewer is directly identifying a deficiency and suggesting a solution.", "grounding_specificity_rationale": "The review point directly refers to 'the approach method', making the grounding explicit. It also specifies what is missing ('inference strategy') and where it should be introduced ('in the test stage'), making the specificity high. The reviewer is not making an educated guess but rather directly pointing out a specific area and its deficiency.", "verifiability_rationale": "The review point is a critique of a deficiency rather than a claim requiring verification. It doesn't present a statement that needs to be supported by evidence. However, the lack of information can be seen as implicitly suggesting a problem that needs addressing, which could be argued as having a form of implicit justification. The reviewer is highlighting a missing piece of information.", "helpfulness_rationale": "The review point is highly constructive and actionable. It directly tells the authors what is missing in their description of the approach and where it should be included. This is a very helpful suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'Figure 4 is confusing' and 'it's not clear what the columns mean.' This directly points to a specific area needing improvement. The reviewer also implies a solution by suggesting 'clarify the columns,' making the action explicit. The impact is clear: the authors need to understand the columns to interpret Figure 4 correctly. The reviewer's statement is a direct identification of a weakness and a suggestion for improvement, making it concrete.", "grounding_specificity_rationale": "The reviewer directly refers to 'Figure 4' and then specifically points out the issue with the 'columns'. This is a clear and precise identification of the part of the paper being addressed. The reviewer does not need to make any inferences to pinpoint the columns; they are explicitly mentioned. This demonstrates strong grounding as the specific element is directly identified.", "verifiability_rationale": "The reviewer makes a claim by stating 'Figure 4 is confusing' and 'it's not clear what the columns mean.' This claim is verifiable because the lack of clarity about the columns is a demonstrable issue. While the reviewer doesn't provide a specific solution or justification for why the columns are unclear, the *fact* that they are unclear is verifiable. The reviewer's statement points to a concrete problem within the figure.", "helpfulness_rationale": "The reviewer directly points out a weakness in the paper (confusion about Figure 4) and suggests a concrete improvement (clarify the columns). This is a clear and actionable feedback for the authors. The reviewer's comment directly identifies an area where the authors need to make changes or improvements. The suggestion to clarify the columns is a specific and helpful piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests discussing the experiment results. While this is a valid suggestion for improvement, it is an implicit action. The reviewer does not explicitly state what should be discussed or how the results should be interpreted. The action is not concrete, leaving the author to guess the intended improvement.", "grounding_specificity_rationale": "The reviewer mentions 'experiment results' generally. While the reviewer later refers to 'Algorithm 4' and 'computational complexity,' the initial mention of 'experiment results' is vague and does not pinpoint a specific section, table, or unique aspect of the paper. The grounding is weak until the reviewer provides more specific information.", "verifiability_rationale": "The reviewer does not make a claim or assertion about the paper. They are simply suggesting areas for improvement and clarification. There is X being made that requires verification or evidence. The comment is classified as 'X'.", "helpfulness_rationale": "The reviewer suggests discussing experiment results and clarifying realworld applications and computational complexity. These are valid points that could help the authors improve their work. While the suggestions are general, they point towards specific areas where the authors could benefit from further analysis and explanation. The feedback is relevant and addresses potential weaknesses."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer is asking for an explanation, which implies an action: 'I want to understand why the ablation study results are so low compared to other methods.' This action is explicit and directly addresses a potential issue. The request for 'explanations' is a clear instruction for specific information.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the ablation experiments' and compares the results to 'fCLSWGAN 4' and 'fVAEGAND2 5'. This clearly identifies the specific part of the paper being addressed, making the grounding fully specific.", "verifiability_rationale": "The reviewer states a fact: 'The results are even lower than some simple early methods...'. This is a claim that can be supported by comparing the reported results of the ablation study with the cited methods. Therefore, it is 5.", "helpfulness_rationale": "The reviewer's request to understand why the ablation results are low directly addresses a potential weakness in the authors' work. This is a clear and actionable feedback that can help them improve their methodology. The request for 'explanations' is a specific and helpful suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem ('lack of ablation analysis') and proposes a solution ('it makes it easier to pinpoint the source of performance gain'). This is an explicit action with clear and concrete details on how to implement it.", "grounding_specificity_rationale": "The reviewer mentions 'lack of ablation analysis' but doesn't specify which part of the paper is lacking it or what specific aspect is missing. The grounding is weak as the authors can only make an educated guess about the referenced part.", "verifiability_rationale": "The review point contains a claim ('lack of ablation analysis makes it difficult to pinpoint performance gain') but doesn't provide any logical reasoning, common knowledge, or external references to support this claim. It's presented as an observation rather than a justified statement.", "helpfulness_rationale": "The review point directly addresses a common challenge in machine learning research \u2013 the difficulty in attributing performance gains to specific components. The suggestion to include ablation analysis is a clear and actionable step that would benefit the authors by providing valuable insights."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The review explicitly states the finding of experiment 2 and its implication regarding noise rates. However, it doesn't tell the authors what specific changes they should make based on this finding. The actionable step is missing.", "grounding_specificity_rationale": "The review refers to \"experiment 2\" and \"Theorem\". While it specifies the condition (\"number of classes > 8\"), it doesn't clearly link experiment 2 to a specific section, table, or figure in the paper. The reference to \"Theorem\" is also vague without knowing which theorem is being referred to.", "verifiability_rationale": "The review states the finding of experiment 2. However, it doesn't provide any reasoning or justification for why this result might be true. It simply reports the outcome.", "helpfulness_rationale": "The review points out a specific experimental finding and its potential implication. It suggests looking at \"Th.\", which is a helpful step for the authors to explore further. While it doesn't provide a solution, it does highlight a potentially important observation and a direction for investigation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action of comparing the model trained on the original dataset with that trained on the mixture. This is a clear and direct action that the authors can readily implement.", "grounding_specificity_rationale": "The reviewer identifies the specific issue being addressed as the experimental setup in Section 3.1 and the comparison being made between models trained on different datasets. While not explicitly naming a section, the focus on the comparison itself grounds the comment to a specific part of the paper and specifies what needs to be addressed.", "verifiability_rationale": "The reviewer presents a claim about the importance of comparing models trained on different datasets. This claim could be verified by suggesting experiments to compare the performance of these models, thus providing logical reasoning and a potential verification method.", "helpfulness_rationale": "The reviewer provides a concrete suggestion for improving the experimental design by comparing models trained on the original and mixed datasets. This directly addresses a potential flaw and offers a clear improvement for the authors, making it 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement 'The CNN experiments are not fully convincing' is a subjective opinion and does not explicitly state what needs to be done or how to improve the CNN experiments. It lacks the explicit and concrete nature required for high actionability. The reviewer expresses a concern but does not provide specific, actionable steps for the authors to follow.", "grounding_specificity_rationale": "The comment refers to 'the CNN experiments' generally, without specifying which particular experiments or aspects of the CNN are being discussed. This lack of specificity means the authors cannot pinpoint the exact area that needs improvement. The grounding is weak because the authors cannot confidently determine the referenced part of the paper.", "verifiability_rationale": "The comment 'The CNN experiments are not fully convincing' is a claim that lacks supporting evidence or justification. The reviewer expresses an opinion but does not provide any logical reasoning, common knowledge, or external references to back up their statement. Therefore, the claim is not verifiable based on the information provided.", "helpfulness_rationale": "While the reviewer expresses a concern about the CNN experiments, the comment itself does not provide specific, actionable feedback or suggestions for improvement. The statement is a subjective opinion, and while it might prompt the authors to reevaluate their approach, it lacks the concrete guidance necessary for 5 feedback. The feedback is somewhat aimed at guiding the authors, but it lacks the specificity and actionable steps needed for them to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly identifies the discrepancy in results for model (3) (Chung et al. 2016) for CsEn. While it doesn't directly state the action of checking the source, it implies that the authors should verify the source of these results, as they likely computed them themselves. This makes the action somewhat implicit but still actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'model (3) (Chung et al. 2016)' and 'CsEn'. It also refers to 'Table 1', which is a specific location within the paper. This indicates a high level of grounding specificity as the authors can easily identify the referenced part of the paper and the specific elements within it.", "verifiability_rationale": "The comment makes a claim that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the papers. While it doesn't provide a direct justification, it strongly implies that the authors should be able to find this information in the cited works. This makes the claim somewhat inferential but still verifiable through logical reasoning and common knowledge.", "helpfulness_rationale": "The comment is clear and directly points out a potential issue with the results presented in the paper. It suggests a concrete action for the authors to take, which is to verify the source of these results. This makes the review point 5 in guiding the authors to identify and potentially resolve the problem."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests a general area for improvement (prompt design) rather than a specific action. It doesn't point to a specific part of the paper or how to do something. While the topic is concrete, the 'how' is vague. The reviewer doesn't provide a specific method or guideline. Therefore, it's not explicitly stating an action, and the action it mentions is vague.", "grounding_specificity_rationale": "The review doesn't specify which section of the paper the authors should focus on regarding prompt design. It's a general suggestion. The authors cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part (improving prompt design).", "verifiability_rationale": "The review states a desire for a discussion on prompt design. This is a suggestion, not a claim requiring verification. The reviewer doesn't provide any specific information, data, or references to support their suggestion. They simply state it as a desired addition.", "helpfulness_rationale": "The review suggests adding a section on prompt design. While relevant to the paper's scope, it doesn't directly critique or identify specific weaknesses in the existing work. It's a suggestion for improvement rather than a critique. The authors would likely find the topic relevant, but the review itself doesn't provide specific guidance on how to design better prompts. It's a broad suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests comparing with 'SoTA approaches' but does not specify which approaches, how to compare them, or what aspects to focus on. It lacks explicit instructions on how the authors should act.", "grounding_specificity_rationale": "The review point refers to 'SoTA approaches' generally without identifying a specific section, table, figure, or unique element of the paper being discussed. It does not ground the feedback in a concrete part of the work.", "verifiability_rationale": "The review point contains a suggestion (a claim) to compare with 'SoTA approaches' but does not provide any logical reasoning, examples, or references to support this suggestion within the review point itself.", "helpfulness_rationale": "The review point is a general suggestion without specific, actionable steps for the authors. It does not provide concrete guidance on how to compare with 'SoTA approaches' or what benefits this comparison might offer."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of clarity regarding the use of freezing in MLS selection and suggests an alternative method (adaptive). While the questions are about *why* and *why not*, they don't explicitly state an action the authors should take. The reviewer's suggestion is more of a question prompting clarification rather than a direct instruction.", "grounding_specificity_rationale": "The reviewer refers to 'MLS selection' and 'adaptive method' without explicitly stating which specific part of the paper or table this relates to. While the general area is mentioned, the specific element needing clarification is not pinpointed.", "verifiability_rationale": "The reviewer's comment does not contain a claim that requires verification. It's a statement of uncertainty and a suggestion for further thought.", "helpfulness_rationale": "The reviewer identifies a potential area of confusion in the paper (MLS selection) and suggests an alternative method. This points to a concrete area for improvement and encourages the authors to consider different approaches, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential area for improvement in the authors' future work by suggesting they provide a 'more detailed plan' to address the mentioned limitations. However, the suggestion lacks specific action or concrete details. While it implies an action (providing a plan), the specifics of what constitutes 'more detailed' are not specified, making it difficult to apply directly to the current draft. Therefore, the review point is 2 as it points to a potential action but doesn't provide explicit or concrete steps on how to achieve it.", "grounding_specificity_rationale": "The review point does not specify which limitations are being referred to or which part of the paper these limitations are discussed in. The suggestion to provide a 'more detailed plan' is general and does not target a specific aspect of the paper that needs improvement. Therefore, the review point is 1 as it does not identify a specific area within the paper being addressed.", "verifiability_rationale": "The review point does not contain a claim or suggestion that requires verification. It is a statement about what the authors *should* do in their future work, not a critique of their current work that needs evidence. Therefore, the review point does not contain a claim that needs to be supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point suggests that the authors should provide a 'more detailed plan' to address the mentioned limitations. While this is a helpful suggestion for guiding future work, it does not directly address the current draft or provide specific actionable steps for improvement within it. It is a suggestion for future improvement rather than immediate feedback on the current work. Therefore, the review point is 3 as it points towards a positive direction for the authors' development, but it lacks immediate applicability to the current draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly asks a question about the model's capabilities and suggests a concrete analysis involving image, text, and KGs. This makes the action clear: evaluate the model on the suggested analysis.", "grounding_specificity_rationale": "The reviewer refers to the proposed model by name ('the proposed knowledgeCLIP model') and then specifies the analysis involving image, text, and KGs, and further details the analysis techniques (negations/ changing entities). This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer does not make any claims or assertions. They are suggesting a potential experiment, which does not involve making a claim that needs verification.", "helpfulness_rationale": "The reviewer suggests a potential experiment, which could be helpful, but it doesn't provide immediate actionable feedback to the authors. The authors haven't presented any issues or areas for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides specific suggestions for improvement and points out a potential issue with notation. While the reviewer doesn't explicitly state what action needs to be taken, the suggestions are clear and actionable. For example, the reviewer suggests clarifying the notation in Eq. 3, inferencing that the authors might be confused by the inconsistency, and that adding variance in Alg. 2 could improve the fusion prototype. These suggestions directly address potential areas of confusion or improvement for the authors.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Eq. 3' and 'Alg. 2', which are specific parts of the paper. The reviewer also suggests using '\u03bc_f' instead of '\u03bc_g', which directly points to a specific element in Algorithm 2. This clear referencing demonstrates a strong grounding in the specific parts of the paper being discussed.", "verifiability_rationale": "The reviewer's claims are based on logical reasoning and the potential benefits of the suggested improvements. For example, the reviewer suggests that clarifying the notation in Eq. 3 would resolve confusion for the authors, which is a logical inference. Similarly, suggesting the inclusion of variance in Alg. 2 is based on the potential benefit of capturing more information in the fusion prototype. While the reviewer doesn't provide specific examples or external references, the suggestions are based on common practices in machine learning and the logical implications of the proposed changes. The reviewer's claim to be 'consistent with Eq.' is also based on logical consistency in notation.", "helpfulness_rationale": "The reviewer provides clear and actionable feedback on potential issues and suggests concrete improvements. The suggestions to clarify notation, add variance, and use consistent notation are all likely to be helpful for the authors in understanding and refining their work. The reviewer is directly addressing potential points of confusion and proposing practical solutions. The suggestions are welldefined and directly address potential areas for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for a more comprehensive discussion on computational cost and complexity. They are not inferring this need but directly pointing out a potential area for improvement. The action is explicit, and the details of what needs to be discussed are clear.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific aspect of the paper related to computational cost and complexity. They also mention the impact on computation time, further specifying the area of concern. The grounding is strong as the topic is directly related to the paper's content.", "verifiability_rationale": "The reviewer claims that the paper lacks a discussion on computational cost. This is a claim that needs to be supported. While the reviewer identifies the topic, they do not provide any evidence or reasoning to back up their claim that the paper specifically omits this discussion. The evidence is circumstantial and lacks directness.", "helpfulness_rationale": "The reviewer's request for more information on computational cost is generally helpful as it could provide valuable insights for the authors. However, the request lacks a strong justification for why this information is crucial or specific to the authors' needs. The helpfulness is moderate as it's a general suggestion without a clear connection to the authors' current work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the issue: 'how novel values in the test set are handled.' It also implies the need for an explanation: 'explain how'. This is an explicit action, as the reviewer clearly identifies what is missing and what needs to be done. The concreteness comes from the fact that the reviewer points to a specific aspect of the test set (novel values).", "grounding_specificity_rationale": "The review point explicitly refers to 'novel values in the test set.' This is a specific part of the paper and a specific characteristic being discussed. The reviewer does not need to make any inferences to identify this part. Therefore, the grounding is fully grounded. The specificity comes from the fact that the reviewer clearly states what is missing in this specific part \u2013 an explanation of how novel values are handled.", "verifiability_rationale": "The review point itself does not contain a claim. It is a request for information rather than a statement of what is or is not the case. Therefore, it does not have verifiability in the sense of supporting a claim. However, the request itself implies a potential gap in understanding, suggesting that the authors should be aware of how novel values in the test set are typically handled. This could be considered 3 in the sense that the authors should have this information, even if it's not explicitly stated in the review.", "helpfulness_rationale": "The review point directly identifies a clear weakness: the lack of explanation regarding how novel values in the test set are handled. This provides the authors with a concrete direction for improvement \u2013 to provide this explanation. The request is specific and directly related to a potential area of confusion. Therefore, it is 5 as it points to a specific and actionable improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that 'Similar methods have already been proposed...'. This directly points to a potential area for improvement. However, the reviewer does not specify *which* similar methods or *how* they relate to the current paper's approach. The action is identified, but the details are vague.", "grounding_specificity_rationale": "The reviewer mentions 'multitask learning' as a related concept. This provides a specific area within the broader field that the reviewer believes is relevant. The paper does not explicitly discuss multitask learning. The reviewer's comment is specific to a subfield, but the paper's content is not. The grounding is present (mention of a subfield), but the connection to the specific paper's content is not explicitly made.", "verifiability_rationale": "The reviewer's point about similar methods not being discussed is a claim that needs to be verified. However, the reviewer does not provide any specific examples, citations, or logical reasoning to support this claim. The claim is stated, but there is no evidence provided to back it up.", "helpfulness_rationale": "The reviewer's comment identifies a potential gap in the related work discussion. This is a valuable piece of feedback that can help the authors position their work more effectively. However, the reviewer does not offer specific suggestions for how to address this gap or improve the related work section. The feedback is identified, but the suggestions are lacking."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment implicitly suggests comparing the computational cost, but it doesn't provide explicit steps on how to do this. The reviewer is asking a question about a potential implementation detail, which is not a direct action but points towards a relevant area for improvement.", "grounding_specificity_rationale": "The comment does not specify which part of the paper it is referring to. It is a general question about the computational cost of FedMITR compared to other methods, without pointing to a specific section, table, or figure.", "verifiability_rationale": "The comment is a question, not a claim that needs verification. It's asking for information rather than making a statement that requires supporting evidence.", "helpfulness_rationale": "The question directly addresses a potential area for improvement in the authors' understanding or implementation of FedMITR, particularly regarding computational costs. It highlights a potential gap in the paper's clarity and encourages the authors to seek clarification or further details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point does not explicitly state what action the authors should take. While it implies a need for clarity, it doesn't specify how to achieve it or what changes are necessary. The suggestion to use a 'generic external knowledge base' is an implication rather than an explicit action. Therefore, the review point lacks explicit and actionable steps.", "grounding_specificity_rationale": "The review point does not clearly identify which part of the paper it is referring to. It makes a general statement about the writing being 'too confusing' without specifying which section, table, figure, or unique element is causing the confusion. The suggestion about the 'generic external knowledge base' is about the process, not a specific part of the paper. Therefore, the review point is 1 in a specific aspect of the paper.", "verifiability_rationale": "The review point makes a claim: 'However the writing is too confusing I cannot be sure if that is the case or not.' This claim is not supported by any logical reasoning, common knowledge, or external references. The reviewer expresses uncertainty about the confusion without providing evidence or a solution. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The review point is somewhat vague and lacks specific details. While the reviewer suggests a potential improvement to the review process (using a generic external knowledge base), the *how* and *why* are not clearly explained. The reviewer also expresses a negative sentiment about the writing ('too confusing') but doesn't specify what is confusing or how the suggestion would be implemented. Therefore, the review point is not 5 as it lacks concrete suggestions and lacks grounding in the paper's specific aspects."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for a justification for a specific hyperparameter value (0.6) related to Glove embedding similarity. While the reviewer is asking for information, the action is implicit  they *should* have stated the value explicitly if it was obvious. The lack of clarity in the original paper makes this an 1 request.", "grounding_specificity_rationale": "The reviewer is asking about a specific hyperparameter (0.6) within the context of Glove embeddings and similarity. The paper *should* mention Glove and embedding similarity. The reviewer is asking about a *specific* value, making the grounding quite strong, although not explicitly pointing to a specific section or table. The specificity is high as the request is very focused on a particular detail.", "verifiability_rationale": "The reviewer is making a request for information about a hyperparameter and potentially about the experimental setup (kcrossvalidation). There is no explicit claim, judgment, or suggestion being made. The reviewer is asking a question, not making a statement that needs verification.", "helpfulness_rationale": "The reviewer is asking for details about a hyperparameter and potentially about the experimental setup (kcrossvalidation). This could be helpful for the authors to understand the model's behavior and potentially improve their draft. The questions about potential impact and alternative losses are also valuable for understanding the method's robustness and exploring alternatives. However, the questions are somewhat openended and require further clarification from the authors."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a weakness: 'Missing indepth analysis on experimental results.' This indicates a clear action the authors should take: 'Perform a more detailed analysis of the experimental results.' While the reviewer doesn't specify *how* to perform this analysis, they identify the *area* of improvement, making it actionable.", "grounding_specificity_rationale": "The reviewer mentions 'experimental results' generally. While they provide an *example* of the * nature* of the results (limited improvement on one dataset, significant on another), they don't explicitly point to a specific section, table, or figure in the paper where this discrepancy is discussed or needs addressing. The suggestion is *general* \u2013 a need for 'indepth analysis' rather than pinpointing a specific part of the paper that requires it.", "verifiability_rationale": "The reviewer makes a claim: 'Missing indepth analysis on experimental results.' They also provide justification for this claim by stating *why* it's a problem: 'For example, why the improvements of models are limited on offense detection dataset and are significant on coarse stereotype set?' This demonstrates an attempt to justify the identified weakness with logical reasoning and a specific example of the inconsistency.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper's analysis and provides a specific example. This points to a genuine area where the authors could improve their understanding and presentation of the experimental findings. The reviewer's comment is not just a criticism but also a constructive suggestion for improvement, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'Use modern backbone baselines (say, Resnet50 or DenseNet121)' and explains why '3 conv layers is definitely too small for anything nonsynthetic'. Both the action and the reason are concrete.", "grounding_specificity_rationale": "The comment explicitly mentions 'Resnet50' and 'DenseNet121' as examples of 'modern backbone baselines'. It also specifies '3 conv layers' as a size that is 'too small for anything nonsynthetic'. This provides clear grounding in specific model architectures and architectural details.", "verifiability_rationale": "The claim 'I have to say that even given this version of the idea, I am skeptical this would work (lots of such robustness/domain invariance interventions have been proposed and have failed)' is supported by the reviewer's statement that 'lots of such robustness/domain invariance interventions have been proposed and have failed'. This provides a basis for understanding the reviewer's skepticism.", "helpfulness_rationale": "The comment provides concrete suggestions for improving the feature extraction layer, such as using Resnet50 or DenseNet121. While the reviewer expresses skepticism based on past experiences, the suggestions themselves are actionable and directly address the proposed method. The helpfulness is moderate as the reviewer's skepticism, while not directly providing a solution, sets the stage for further discussion and consideration."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests tuning the baseline, which is an explicit action. However, the method of tuning, 'similar resources,' is not explicitly defined, making it somewhat vague.", "grounding_specificity_rationale": "The review point refers to 'the baseline,' which is a specific part of the paper. However, the suggestion to tune it with 'similar resources' is not explicitly defined, making the grounding somewhat weak. While the hyperparameters are mentioned, the resource is vague.", "verifiability_rationale": "The review point suggests tuning the baseline as a solution. While this can be considered a claim, the reasoning behind 'similar resources' is not provided, making the verifiability 1.", "helpfulness_rationale": "The review point suggests tuning the baseline, which is a practical and often beneficial suggestion for researchers who have extensively tuned hyperparameters. While the specifics are lacking, the suggestion is relevant and addresses a common issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides two explicit statements about the definition of perplexity and the nature of Eq1. The first statement directly identifies a potential error in the stated definition of perplexity. The second statement explicitly compares the equation to crossentropy, indicating a lack of clarity in the reviewer's understanding or the paper's explanation. The reviewer clearly states what they believe is incorrect and what they believe the equation represents.", "grounding_specificity_rationale": "The reviewer's comment is grounded in the specific concept of perplexity being discussed. While the paper isn't explicitly mentioned, the context implies the reviewer is referring to the definition being presented. The reviewer also specifies Eq1, indicating a clear reference to a specific equation. The reviewer's comment is specific about the potential error in the stated definition of perplexity and the nature of Eq1.", "verifiability_rationale": "The reviewer makes a claim about the content of the paper, specifically stating that the definition of perplexity is incorrect and that Eq1 is more akin to crossentropy. This constitutes a 'Claim' as it is a statement that needs to be verified. The reviewer provides logical reasoning by stating their understanding of perplexity and the common understanding of crossentropy and likelihood to support their claim.", "helpfulness_rationale": "This review point is 5 for the authors. By directly pointing out a potential error in the definition of perplexity and the nature of Eq1, the reviewer provides concrete feedback that can help the authors correct their understanding or the paper's explanation. The specific nature of the criticism makes it actionable for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the concern about the condition \u03b7 \u2265 C\u2080 in Proposition 6.1 and suggests a comparison with Section 4. The action is clearly defined: 'further clarify this condition and compare it with that in Section 4 (correct model case)'. The reviewer also implies that this condition is problematic because \u03b7 is typically a small value, which is a direct action to identify an issue.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Proposition 6.1' and the condition '\u03b7 \u2265 C\u2080' as the specific part of the paper being addressed. This provides strong grounding. However, the reviewer does not explicitly state *why* this condition is problematic or how it differs from the conditions in Section 4. The implications are there, but the explicit identification of the problematic aspect within the proposition itself is clear.", "verifiability_rationale": "The reviewer makes a claim that '\u03b7 is typically a small value'. This is a claim that needs to be supported. While the reviewer doesn't provide external references or detailed explanations within this review point, the statement itself is a clear assertion. The lack of immediate verification makes it 3.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors to improve their draft. They want the authors to clarify the condition in Proposition 6.1 and compare it with the content in Section 4. This directly addresses a potential issue and guides the authors on where to focus their attention. The feedback is directly relevant to a specific part of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the compared baseline is 'not sufficient' and provides specific examples of missing baselines (MVGRL and gptgnn). They also suggest 'adding more baselines of graph contrastive learning and test them on some common datasets'. These are concrete actions or suggestions that are direct or apparent. The authors can directly identify modifications they should apply to their draft by adding more baselines and testing on common datasets. The reviewer's point is clear and directly actionable.", "grounding_specificity_rationale": "The reviewer not only identifies that the baselines are 'not sufficient' but also specifies 'such as MVGRL4, gptgnn5 are missing'. They also mention the 'graph classification task'. This indicates a high level of specificity in identifying the issue. The authors can accurately pinpoint the section, table, figure, or unique aspect being addressed by knowing the specific missing baselines and the task being evaluated. The grounding is explicit and directly related to the experimental setup.", "verifiability_rationale": "The reviewer states a fact: 'In the graph classification task, the compared baseline is not sufficient...'. This claim is verifiable as the authors can assess the performance of the existing baselines and compare it to established benchmarks in graph contrastive learning for graph classification. The reviewer's suggestions, while not providing new methods, are based on the verifiability of the identified weakness. The claim is thoroughly supported by the reasoning that the current baselines are insufficient for a comprehensive evaluation of graph classification performance in graph contrastive learning.", "helpfulness_rationale": "The reviewer's comment directly addresses a clear weakness in the experimental evaluation: the lack of sufficient baselines for graph classification. They provide a clear direction for the authors to improve their evaluation by 'adding more baselines of graph contrastive learning and test them on some common datasets'. This is a valuable and helpful comment as it guides the authors towards a more robust and comprehensive experimental setup, which is crucial for a fair evaluation of the proposed method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer provides a general critique of the authors' defense strategy and suggests an alternative evaluation scenario. While the core idea is clear, the specific action the authors should take is not explicitly stated. The reviewer points out a potential weakness in the authors' approach by suggesting an 'adaptive attack' that causes 'minimal structural alterations' to edge maps, but the authors are not directed to a specific flaw or improvement based on this. The suggestion is more about exploring a different type of attack.", "grounding_specificity_rationale": "The reviewer's comment is not strongly grounded in a specific section or figure of the paper. They refer to 'the authors' method' and 'edge map based defense strategies' generally. While the suggestion about edge maps is specific to the authors' work, the overall comment lacks a clear reference to a particular part of the paper being addressed. The reviewer doesn't explicitly name a section, table, or figure, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer makes a claim about the importance of evaluating the defense against an 'adaptive attack' that causes 'minimal structural alterations' to edge maps. However, they do not provide any specific evidence, references, or logical reasoning to support this claim. The suggestion is presented as a constructive idea for improvement rather than a claim that needs verification. The reasoning is more about the potential of the suggested attack than providing concrete evidence for a flaw or the need for a different evaluation approach.", "helpfulness_rationale": "The reviewer's comment is 3 in that it encourages the authors to consider a broader range of attacks and to think about the limitations of their current evaluation. The suggestion to evaluate against an attack that causes 'minimal structural alterations' to edge maps is a valuable point for discussion and future work. However, the comment lacks a direct and specific critique of a potential weakness in the authors' current method. It doesn't pinpoint a specific flaw or provide actionable steps for the authors to take based on this suggestion. The feedback is more about prompting a different perspective than directly addressing a specific issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue with the table legends and provides a clear action: 'clarify the legends'. They also specify *what* needs clarification: 'longer and clarify whether the numbers are % errors, or % correct (MNIST and CIFAR respectively presumably)'. This action is both explicit and concrete, leaving no ambiguity about what the authors should do.", "grounding_specificity_rationale": "The reviewer directly refers to 'Table 1, 2, 3' and explicitly states that the legends should be longer and clarify the meaning of the numbers. This is a clear and unambiguous identification of the specific parts of the paper being addressed, and the issue within those parts is also clearly defined.", "verifiability_rationale": "The reviewer makes a statement about the current state of the table legends: 'Table 1, 2, 3 the legends should be longer and clarify whether the numbers are % errors, or % correct (MNIST and CIFAR respectively presumably)'. This constitutes a claim that needs to be addressed. The reviewer also provides a suggestion for improvement, which is a form of logical reasoning and is directly verifiable by the authors upon examining the tables.", "helpfulness_rationale": "The reviewer directly points out a clear issue with the table legends (lack of clarity about the meaning of the numbers and the need for longer legends) and provides a specific and actionable suggestion: 'clarify the legends'. This is immediately helpful for the authors as they would likely benefit from a clearer representation of their results in the tables."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that 'the experimental results do not contain standard deviations' and 'therefore it is hard to judge the significance of the results'. This is an explicit action the authors should take, and it is also concrete as it tells them exactly what is missing and how to potentially address it (by looking for standard deviations in tables, figures, or analysis sections).", "grounding_specificity_rationale": "The review point refers to 'the experimental results' as the part of the paper being addressed. While this is a general reference, it is not specific enough to pinpoint a particular section, table, figure, or unique element. The reviewer does not provide any further detail to ground the reference. Therefore, it is not fully grounded.", "verifiability_rationale": "The review point does not contain a claim. It is a factual statement about the missing information in the experimental results. Since there is X, there is no verifiability to evaluate.", "helpfulness_rationale": "The review point is 5 because it identifies a specific, actionable issue (missing standard deviations) that directly impacts the authors' ability to assess the significance of their results. It clearly points the authors to where they should look to find this missing information. While it doesn't provide a solution, it highlights a concrete step they need to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing theoretical aspects: 'the existence and smoothness of the solution of SDE (2a)(2d), and any guarantees of the discretization (in time and space)'. This directly points to areas where action is needed, making it 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the existence and smoothness of the solution of SDE (2a)(2d), and any guarantees of the discretization (in time and space)'. This directly identifies the specific part of the paper (the analysis of SDE (2a)(2d) and its discretization) where the issue lies, providing strong grounding. Furthermore, the reviewer clearly specifies what is missing in this part.", "verifiability_rationale": "The reviewer's claim that the analysis 'seems somewhat weak' because 'the existence and smoothness of the solution of SDE (2a)(2d), and any guarantees of the discretization (in time and space)' are not provided is a clear and verifiable statement. The reasoning is based on established theoretical knowledge in the field of SDE discretization, making it 5.", "helpfulness_rationale": "The reviewer provides specific and actionable feedback by pointing out the missing theoretical aspects related to SDE (2a)(2d) and its discretization. This directly guides the authors on what needs to be addressed, making the review 5 in improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem with the quality of generated images, specifically mentioning 'limited realism'. However, the reviewer does not explicitly state what aspects of the realism are limited (e.g., blurry details, lack of diversity). While the suggestion to 'improve realism' is a clear direction, it lacks specific details on how to achieve this improvement.", "grounding_specificity_rationale": "The reviewer refers to 'generated images by proposed method' and 'realism of generated results', indicating a specific area of concern. However, the reviewer does not pinpoint the exact location or aspect within the generated images that is lacking in realism. The suggestion to 'improve realism' is a general improvement, making it underspecific.", "verifiability_rationale": "The reviewer states a problem with the 'realism of generated results' and suggests improvement. This can be considered a claim that needs justification. The evidence provided is the observation of 'limited realism' in the generated images. While the reviewer points out the discrepancy between 'good continuous control' and 'limited realism', they do not provide specific examples or references to support their claim about the limited realism.", "helpfulness_rationale": "The review point identifies a weakness in the generated images and suggests improvement by 'improving realism'. This provides some guidance for the authors. However, the suggestion is quite general and lacks specific details on how to achieve this improvement. The feedback is present and constructive, but it could be more detailed to be fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the missing information about how G is built, the size and elements of G, and the dimensions of G, X, and W. This indicates a clear action the authors should take.", "grounding_specificity_rationale": "The reviewer directly refers to 'Section 3.3' (even though it's not explicitly stated) and asks for specific details about the graph G and the dimensions of other variables. This implies a clear understanding of the relevant section and the specific elements needed.", "verifiability_rationale": "The reviewer points out a deficiency in the paper's description of how G is built and requests specific information. This can be considered a claim that the paper lacks sufficient detail. The reviewer's requests provide some justification for this claim.", "helpfulness_rationale": "The reviewer identifies a specific area of confusion in the paper and provides concrete suggestions for what information is missing. This directly helps the authors understand and potentially improve their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a specific detail about the backpropagation process in the Cycle Consistency loss, stating that it involves two separate standard backpropagation processes. This is a concrete action the authors should take: identify the specific implementation of backpropagation in their Cycle Consistency loss and ensure it aligns with the described twophase process. The reviewer also implies a potential discrepancy between the authors' description and the actual implementation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Cycle Consistency loss' and details the specific backpropagation process involving 'ABA and BAB' reconstructions and 'two separate standard backpropagation processes'. This allows the authors to precisely identify the relevant part of the paper and understand the specific issue.", "verifiability_rationale": "The reviewer makes a claim that the authors' statement is 'not entirely true' and provides a specific technical detail about the backpropagation process in the Cycle Consistency loss to support this claim. This claim is verifiable through the provided technical detail.", "helpfulness_rationale": "The reviewer directly points out a factual error in the authors' description of the Cycle Consistency loss implementation. This is a clear and actionable feedback that will help the authors correct their understanding and potentially their implementation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the issue: \"calling 'hyperspectral' is confusing.\" This directly points to a lack of clarity or understanding regarding the use of the term \"hyperspectral\". Therefore, the action is identified as explicit. However, the reviewer does not provide a specific action or suggestion on how to improve the clarity. The action is to understand the confusion, which is vague. Therefore, the action is vague. Based on the definitions, an explicit action is one that is directly identified, and a vague action is one that needs to be inferred. The reviewer states the problem explicitly but doesn't offer a concrete solution.", "grounding_specificity_rationale": "The reviewer mentions \"hyperspectral\" without specifying which part of the paper or figure this refers to. They could have mentioned a specific section, table, or even a concept within the text. The lack of specificity makes it difficult to pinpoint the exact issue. Therefore, the grounding is weak. The reviewer states that calling \"hyperspectral\" is confusing, which implies that the term is either not welldefined or its usage is unclear. However, the reviewer does not specify *what* is wrong with the term's usage or where the confusion lies. For example, they might not be clear on whether the confusion is about the definition, the application, or the terminology itself. The lack of specificity in identifying the problematic aspect makes the specificity low. Based on the definitions, grounding is how well the authors can identify the specific part of the paper being addressed, and specificity is how clearly it details what is wrong or missing in the referenced part.", "verifiability_rationale": "The review point itself is not a claim that requires verification. It's an observation or suggestion. Therefore, verifiability does not apply to this point.", "helpfulness_rationale": "The review point identifies a valid concern: the potential confusion surrounding the term \"hyperspectral\". This is a legitimate issue that could hinder understanding for readers. However, the review point does not offer any specific suggestions or context to help the authors improve their writing. It's a valid observation, but it lacks the constructive feedback needed to be 5. Therefore, the helpfulness is low. Based on the definitions, helpfulness is determined by the value of the review comment to the authors. A helpful comment identifies weaknesses or suggests improvements, though it could be expanded or refined to be fully comprehensive and impactful."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides two explicit actions: suggesting how 'energy' should be interpreted in Section 5.2 and asking for clarification on the 'peak' in Figure 5. While the suggestions are clear, they require the authors to interpret the concept in the context of the paper, making them somewhat vague on how to directly implement these actions. The suggestion about Section 5.2 is explicit, but the interpretation of 'energy' within that section needs to be deduced. The suggestion about the 'peak' is implicit, requiring the authors to understand what constitutes a 'peak' in the context of the energy diagram.", "grounding_specificity_rationale": "The reviewer explicitly mentions Section 5.2 when suggesting how 'energy' should be interpreted, providing strong grounding. Similarly, the reference to Figure 5 when asking for clarification on the 'peak' also grounds the comment to a specific part of the paper. The reviewer clearly identifies the sections and figures where the issue lies.", "verifiability_rationale": "The reviewer is making suggestions and requests for clarification, not making claims that require verification. The suggestion about interpreting 'energy' in Section 5.2 is based on common understanding of the concept, but it doesn't provide a definitive reference or external evidence. The request for clarification on the 'peak' in Figure 5 is a request for information rather than a claim that needs verification. Therefore, the verifiability is low as there's no explicit claim being made or supported.", "helpfulness_rationale": "The reviewer provides concrete suggestions for improving the clarity of the paper by explaining the concept of 'energy' and asking for clarification on a specific element in a figure. These suggestions are directly aimed at helping the authors understand and improve their work. The reviewer is not making a claim that requires verification but is instead providing guidance and assistance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desire for a breakdown of contributions, which can be interpreted as an action to provide this information. However, the action itself is vague, lacking specific details on *which* components and *how* they contribute.", "grounding_specificity_rationale": "The reviewer mentions specific components like 'Linformer', 'window attention', and 'contrition', indicating a degree of grounding. However, they do not specify *how* these components contribute to performance improvements, making the grounding somewhat specific but lacking detail.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity in how components contribute to performance improvements. While the claim is present, the reviewer does not provide specific examples or references to support this claim within the review point itself, making the verifiability 3 but lacking concrete evidence.", "helpfulness_rationale": "The reviewer clearly states the value they believe this information would bring to the authors, indicating a high level of helpfulness. The information directly addresses a potential need for understanding model improvements."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states what is missing ('grammar over kernels is not explained in any detail') and what should be done ('understand how this approach is applied in practice'). This directly points to an actionable item for the authors. The phrase 'presumably there are also probabilities associated with the grammar that define a hypothesis space of kernels?' further clarifies the expected information and how it should be presented. The suggestion 'How is inference performed?' is a concrete action the authors can take to understand the missing details.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific part of the paper being addressed ('grammar over kernels') and specifies what is missing ('not explained in any detail') and how it should be present ('detailed explanation'). This indicates strong grounding and specificity.", "verifiability_rationale": "The reviewer does not present a claim in the traditional sense of stating an opinion or judgment. Instead, they are pointing out a potential issue ('some of the details of the models are missing') and suggesting improvements ('how this approach is applied in practice'). While there's an implicit assumption that the lack of detail makes the paper unclear, there's no explicit justification for this claim or reference to external evidence. The suggestion 'How is inference performed?' is a request for clarification rather than a claim requiring verification.", "helpfulness_rationale": "The reviewer provides specific examples of what is missing ('grammar over kernels is not explained in any detail') and suggests concrete improvements ('understand how this approach is applied in practice'). This directly addresses the authors' needs and provides actionable feedback. The reviewer's suggestions are clear and directly related to improving the understanding and application of the model."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a gap in the ablation study and raises questions about the implementation of the 'w/o perception' module. While the reviewer identifies a problem (the lack of verification of the perception module's effectiveness), they don't explicitly state how to implement the ablation or what changes to make. The reviewer suggests the ablation is '1' because it's not clear how to apply the suggested changes. The reviewer also states the similar performance is '1' because they don't know how to improve the ablation to get better results. The reviewer's point about the unknown implementation details is also '1' as they don't provide specific details. The reviewer's point about the sample size is also '1' as they don't suggest how to address the sample size issue. Therefore, the reviewer's point is implicitly actionable but lacks specific details on how to apply the suggestions.", "grounding_specificity_rationale": "The reviewer mentions 'ablation study' and 'w/o perception module' and 'w perception' but doesn't specify which part of the paper or table these refer to. The reviewer doesn't provide a clear location or unique element to identify the issue. The reviewer mentions 'w/o perception module' and 'w perception' but doesn't specify the exact location within the paper. Therefore, the reviewer's comment is 1 at all.", "verifiability_rationale": "The reviewer states that the ablation study doesn't explicitly verify the effectiveness of the visual information and that the performance of 'w/o perception' and 'w perception' is similar. The reviewer provides some evidence (similar performance) but doesn't explain *why* this is a problem or suggest specific improvements to the experimental design. The reviewer's point about the unknown implementation details is also underspecific as they don't provide examples or references. The reviewer's point about the sample size is also underspecific as they don't suggest how to address the sample size issue. Therefore, the reviewer's claim is somewhat supported but lacks key elements (e.g., examples, references).", "helpfulness_rationale": "The reviewer raises several valid points: the lack of clarity on the ablation of the perception module, the inconclusive results due to similar performance, and the lack of detail about the ablation setup. These are all actionable suggestions for the authors. The reviewer identifies a gap in the experimental analysis and raises concerns about the statistical significance of the results. These are all valuable insights that can help the authors improve their draft. While the reviewer doesn't provide specific solutions, they clearly identify areas for improvement and highlight important questions that need to be addressed. Therefore, the reviewer's point is 3 as it points out areas for further investigation and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that 'previous works on Lasso screening are not cited or compared' and points to a specific location in the paper ('the end of Sec. 4.2') where this issue is observed. This provides a clear and actionable suggestion for the authors to improve their work.", "grounding_specificity_rationale": "The review point explicitly mentions 'Transfer Lasso' and 'Lasso screening' and points to the 'end of Sec. 4.2' where the lack of citations is observed. This allows the authors to precisely identify the specific part of the paper being addressed and the specific issue.", "verifiability_rationale": "The review point contains a claim ('previous works on Lasso screening are not cited or compared') and provides a justification for why this is a problem ('it lacks proper context and fails to acknowledge relevant prior work'). This justification, while not a citation itself, explains the reasoning behind the claim.", "helpfulness_rationale": "The review point directly identifies a weakness in the paper ('Transfer Lasso showed the best accuracy in feature screening') and provides a clear suggestion for improvement ('cited relevant prior work'). This is a highly constructive criticism that directly guides the authors to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states \"the model has many components whose hyper parameters are not fully provided.\" This is an explicit action that the authors can directly address by searching for information about these hyperparameters within the model's code or documentation. The comment is clear and identifies a specific area of the model where information is lacking. Therefore, it is concrete.", "grounding_specificity_rationale": "The review point mentions \"components\" and \"hyper parameters\" generally. While it points towards the *model*, it doesn't specify a *unique* section, table, figure, or a specific aspect of the model where this lack of information is explicitly mentioned. The authors would still need to search broadly to find this information. Therefore, it is weakly grounded. While it identifies the *what* (hyperparameters) and the *where* (within the model components), it lacks the precision of pointing to a specific element.", "verifiability_rationale": "The review point contains a claim (\"the model has many components whose hyper parameters are not fully provided\") that indicates a potential issue or area for improvement. However, it does not provide any justification or evidence for why this is a problem. It simply states the observation without referencing external sources or logical reasoning. Therefore, it is 1.", "helpfulness_rationale": "The review point identifies a concrete issue: the lack of complete information about the hyperparameters of the model's components. This is a valuable piece of feedback for the authors as it highlights a specific area they need to investigate and potentially address. While it doesn't offer specific suggestions on *how* to find the missing information, it points to a significant gap in their understanding or documentation. This makes it a helpful comment."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states '3%p' as the improvement for CIFAR10. This makes the action somewhat explicit. However, the reviewer does not specify what 'p' stands for, making the action not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions 'CIFAR10', which grounds the comment to a specific dataset. However, the reviewer does not specify *where* in the CIFAR10 results the '3%p' improvement is located, making the specificity somewhat lacking.", "verifiability_rationale": "The reviewer makes a claim about the unclear notation for results and the ambiguity of '3%p'. However, the reviewer does not provide any evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the notation is unclear or that the 3%p improvement is valid. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer clearly identifies a problem with the reported results, specifically the lack of clarity in the '3%p' improvement. This is a valuable piece of feedback as it directly points to a missing detail that would be helpful for the authors to understand and potentially reproduce the results. While the action and grounding are somewhat lacking, the feedback itself is actionable in prompting the authors to clarify their metrics."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point asks the authors to consider 'qualitative results' and 'failure cases'. While this implies a specific type of analysis, it doesn't explicitly state the *method* for obtaining these qualitative results or how to analyze the failure cases. The action is implied but not fully detailed, making it 3 but not fully actionable.", "grounding_specificity_rationale": "The review point is general and does not specify which part of the previous method or the authors' work the qualitative results or failure cases relate to. It refers to them broadly as 'qualitative results' and 'failure cases' without pinpointing a specific section, table, figure, or unique element. Therefore, it is 1 at all.", "verifiability_rationale": "The review point makes a claim about the value of showing 'qualitative results' and analyzing 'failure cases' to improve the method. It suggests that previous methods might 'fail' in these cases. While it doesn't provide explicit examples or references to support this claim, it presents a judgment about the previous method's limitations. Therefore, the claim is 3 as it makes a statement about the previous method's potential shortcomings, even if the evidence is not fully developed.", "helpfulness_rationale": "The review point explicitly states the desire to show 'qualitative results' and analyze 'failure cases' as a way to improve the method. This directly addresses a potential weakness and provides a clear direction for improvement. The reviewer explicitly states this as a helpful outcome. Therefore, the review point is 5 as it directly suggests concrete actions for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the authors' claim and directly points out the errors in the statement. The phrase 'this statement makes multiple incorrect assertions' indicates a clear action the authors should take: reevaluate the statement and understand the limitations of the CLT. The specific errors mentioned ('nonasymptotic regime' and 'finite linear combination of arbitrary random variables') provide concrete details for the authors to apply the necessary changes.", "grounding_specificity_rationale": "The review point explicitly references 'line 238' in the authors' paper, providing precise grounding. Furthermore, the reviewer goes beyond just pointing to the line and explains *why* the authors' statement is incorrect, detailing the limitations of the CLT in the nonasymptotic regime and for arbitrary random variables. This level of specificity demonstrates a clear understanding of the relevant part of the paper and the issues with the statement.", "verifiability_rationale": "The review point clearly identifies a claim made by the authors regarding their use of the CLT. The reviewer then provides a logical explanation of why this claim is incorrect, referencing the conditions under which the CLT holds. This logical reasoning and explanation serve as sufficient evidence to verify the claim, making it 5.", "helpfulness_rationale": "The review point is 5 because it directly identifies a specific error in the authors' understanding of the CLT. By pinpointing the limitations of the theorem in the nonasymptotic regime and for arbitrary random variables, the reviewer provides concrete guidance for the authors to correct their statement. The specific reference to line 238 makes the feedback actionable and easily verifiable by the authors."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the request to 'Analyze the time complexity of the proposed policies mentioned in Section 4.' This is a clear and direct instruction, making it actionable. The reviewer is directly telling the authors what to do and how to go about it.", "grounding_specificity_rationale": "The reviewer points to 'Section 4' where the policies are mentioned. While the reviewer doesn't explicitly name the policies, they clearly identify the location where the policies are discussed. This provides strong grounding as the authors can easily locate the relevant section. The reviewer's reference to Section 4 is a clear and specific instruction.", "verifiability_rationale": "The reviewer requests an 'analysis of time complexity.' While not a claim in the strict sense of stating something is wrong, it's a request that implies a need for understanding the computational cost. The reviewer doesn't provide specific examples or references, but the request itself is based on common knowledge and practices in algorithm analysis. The request is verifiable by examining the algorithms or pseudocode in Section 4 and applying standard time complexity analysis techniques.", "helpfulness_rationale": "The request to 'Analyze the time complexity of the proposed policies' is a valuable piece of feedback for the authors. Understanding the time complexity is crucial for evaluating the efficiency and scalability of the proposed solutions. This analysis can help identify potential bottlenecks and areas for optimization. It provides a clear direction for the authors to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer criticizes the justification for using an automatic metric instead of a humanbased one. While they don't demand a specific action, they imply that the current justification is insufficient, which could be seen as a call for a more actionable solution. However, the criticism is more about the *reasoning* behind the choice rather than a direct demand for a specific action on the part of the authors.", "grounding_specificity_rationale": "The reviewer mentions 'style control' and 'TSS metric' as the areas of concern, which provides some grounding. However, they don't specify *how* the TSS metric relates to style control or why it's inadequate. This lack of specificity makes it only somewhat grounded.", "verifiability_rationale": "The reviewer states a belief about the weakness of the justification for using the TSS metric. However, they don't provide any concrete evidence or examples to support this claim. The statement is based on their understanding and interpretation, making it 3 but lacking strong justification.", "helpfulness_rationale": "The reviewer's point is a critique of the evaluation methodology. While it could be helpful in identifying potential flaws in the current process, it doesn't directly provide the authors with a specific action to take to improve their draft. It's more of a constructive suggestion for improvement rather than a direct helpful suggestion."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the issue: 'lack of confidence intervals for their results' and suggests a solution: 'including confidence intervals'. It also mentions another issue: 'unclear whether performance gains are statistically significant' and suggests a solution: 'evaluating on more datasets'. These are direct and actionable suggestions for the authors.", "grounding_specificity_rationale": "The comment mentions 'confidence intervals' generally but doesn't specify which part of the paper or metric is lacking them. It also doesn't explicitly state which confidence intervals are missing (e.g., for a specific metric or across the entire distribution). While it implies a problem, the authors would need to infer the exact location of the missing information.", "verifiability_rationale": "The comment makes a claim: 'the lack of confidence intervals makes the performance gains \"unclearly\" significant'. While the reviewers likely understand the importance of confidence intervals, the comment doesn't provide specific references to external works or datasets where this is a known issue. The reasoning is somewhat implicit, relying on the reviewers' general knowledge of statistical significance.", "helpfulness_rationale": "The comment identifies a valid concern regarding the statistical significance of the results and suggests a relevant improvement: evaluating on more datasets and including confidence intervals. While it doesn't provide a detailed methodology for these improvements, it points to concrete actions the authors can take to strengthen their evaluation. The suggestion is directly related to the identified problem."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action (identifying a missing evaluation) but lacks concrete details on how to implement this action or what the specific evaluation should entail. The action is implied rather than explicitly stated with steps.", "grounding_specificity_rationale": "The comment explicitly mentions the 'magnitude of interpretability tax' and points to a 'specific part of the paper' (the evaluation section) where this is missing. This indicates strong grounding as the section is clearly identified. The specificity is moderate as the comment identifies a specific area but doesn't detail what constitutes an 'interpretability tax'.", "verifiability_rationale": "The comment presents a claim (the paper lacks an evaluation of the interpretability tax) and provides a suggestion (the authors should perform this evaluation). The claim is supported by the statement 'The paper does not evaluate the magnitude of interpretability tax associated with the method.' The reasoning is clear and directly addresses the identified issue. External references are not explicitly mentioned, but the suggestion is logically sound and directly addresses a potential area for improvement. The claim is supported by logical reasoning and the suggestion is a direct request for action.", "helpfulness_rationale": "The comment identifies a clear weakness in the paper (lack of evaluation of interpretability tax) and provides a direct suggestion for improvement. While it doesn't offer specific steps on *how* to perform this evaluation, it points to a concrete area for the authors to focus their efforts. This provides some actionable guidance, making it helpful, but not fully constructive as it lacks specific implementation details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out a *potential* area for improvement in the LUQ design process (focusing on a clear goal) but does not explicitly state how the authors should apply this suggestion. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The review mentions the 'LUQ design process' generally, without specifying a particular section, table, figure, or unique aspect of the paper. Therefore, the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review makes a claim about the paper's contribution ('I'd say the main contribution...'), but it does not provide any specific evidence or justification for this claim within the review point itself. The reasoning is based on interpretation rather than direct verification.", "helpfulness_rationale": "The review offers a suggestion ('focusing on a clear goal'), but it lacks concrete steps on how the authors should implement this suggestion. While the idea is potentially helpful, the lack of actionable steps makes it only '2'. The reviewer's opinion about the paper's contribution is subjective and not directly helpful in improving the draft itself."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their *wish* to see training losses, which is a clear action. However, the request lacks specificity regarding the type of loss or how they should be calculated, making it less actionable in practice.", "grounding_specificity_rationale": "The reviewer mentions 'a deep localization network' and 'differentiable Sinkhorn' which are specific terms. While they don't explicitly name a section or table, the mention of these terms strongly implies a specific part of the paper or implementation. Therefore, the grounding is present but not fully explicit.", "verifiability_rationale": "The reviewer is asking for *information* (training losses) that isn't inherently verifiable *within the review point itself*. The review point is a question, not a statement of fact, and doesn't provide any evidence or references to support the request for training losses.", "helpfulness_rationale": "The reviewer explicitly states their *wish* to see training losses. This is a clear and actionable request that would directly benefit their work by providing empirical evidence. The request is specific enough to indicate a genuine need for information."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "Not Verifiable", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer states 'The paper overclaims the strength of the proposed BC loss in theoretical analysis.' This is an implicit statement, not an explicit instruction on what the authors should do. While the reviewer identifies potential issues with the authors' claims, they do not explicitly state what needs to be changed or how the overclaiming should be addressed. The reviewer offers examples of what they think is the same concept, but these are suggestions, not direct instructions.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific part of the paper when making their claim. They are making a general statement about the BC loss's properties. There is no mention of a specific section, table, figure, or unique element of the paper that they are referring to.", "verifiability_rationale": "The reviewer claims that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are the same thing. This claim lacks specific evidence or references to support this assertion. The reviewer does not provide logical reasoning, common knowledge, or external references to back up their claim that these are equivalent. The justification is based on the reviewer's interpretation that they are all forms of constraining samples with higher popularity, but this is not explicitly stated or supported within the paper itself.", "helpfulness_rationale": "The reviewer's comment is more of a critique of the authors' analysis and claims rather than a direct suggestion for improvement. They are questioning the authors' interpretation of the BC loss's properties and suggesting that these properties might be overlapping concepts. While they identify a potential issue, they do not provide actionable steps or concrete advice on how the authors should revise their work based on this observation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The reviewer's point suggests a lack of actionable feedback. They are criticizing the *effectiveness* of the scores. While the *review* is actionable (identifying a problem with current evaluation), the *proposed solution* (criticizing automated scores) isn't very actionable for the authors in terms of improving their draft. The reviewer doesn't offer a concrete alternative or specific steps authors should take based on this criticism.", "grounding_specificity_rationale": "The reviewer's criticism is quite general. They don't specify *why* automated scores are ineffective or *how* arenabased evaluations are unsuitable. The criticism is directed broadly at the *type* of evaluation. While the *general* criticism could be considered grounded (they mention specific types of evaluations), the *specificity* of *why* they are ineffective isn't detailed.", "verifiability_rationale": "The reviewer doesn't provide a strong justification for their criticism. They state a claim ('these arenabased evaluation systems may not solve the problems of current scorebased evaluation systems') but don't offer substantial evidence or reasoning to support it. The reasoning is presented as a statement of opinion rather than a wellsupported argument.", "helpfulness_rationale": "The reviewer's criticism is negative and doesn't offer any constructive feedback or suggestions. It's a critique without a proposed solution. The review is a statement of opinion rather than a helpful suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the training method (2x samples per iteration) and its consequence (1.5x slower running speed). It also raises a valid concern about the fairness of comparing RegMixup's performance when it sees twice as many samples as other methods. The reviewer clearly identifies a concrete action the authors should take: investigating the impact of the increased sample size on the training process and ensuring a fair comparison with other methods. The information provided is sufficient for the authors to understand the issue and potentially address it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'RegMixup' and '2x samples per iteration' as the context for the training method. While the comparison to 'other methods' is not a specific section or table reference, it is a clear implication of the training procedure. The reviewer identifies the specific aspect of the paper being addressed (the training method and its sample usage) and provides details about what needs to be addressed (the impact on speed and the potential for unfair comparison).", "verifiability_rationale": "The reviewer makes a claim: 'RegMixup seeing 2x samples may lead to unfair comparison.' The reviewer provides supporting information by stating the training method (2x samples) and the observed slower speed (1.5x slower). While the reviewer does not provide specific external references, the logic is generally verifiable: an increased number of samples during training would logically lead to a longer training time. The claim is supported by the described method and its observed effect, making it 3.", "helpfulness_rationale": "The review point raises a specific concern about the training procedure of RegMixup and its potential impact on the fairness of comparisons. This is a relevant and actionable feedback for the authors. The reviewer points out a concrete implementation detail that could affect the results and raises a valid question about the comparability of RegMixup with other methods. While the review doesn't propose a solution, it identifies a clear area for further investigation and discussion, which is helpful for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly points out a potential ambiguity in the notation `t_R^m` within an unnumbered equation. They suggest a concrete action: defining `t_R^m`. This is an explicit and concrete action, making it 5 for the author.", "grounding_specificity_rationale": "The reviewer directly refers to `t_R^m` in the context of the equation mentioned in the review. They are not just asking a general question about the equation's clarity but specifically about the notation used. This strong reference to a specific part of the paper makes the grounding highly specific. The reviewer also suggests a concrete action: defining `t_R^m`, which further enhances the grounding specificity.", "verifiability_rationale": "The reviewer does not make a claim in the sense of asserting something is wrong or needs improvement. They are asking a question and making a suggestion. Therefore, there is X to verify. The suggestion to define `t_R^m` could be considered a form of implicit verification if the author can provide a definition or justification for the notation, but the reviewer does not present any evidence to support this suggestion within the review point itself.", "helpfulness_rationale": "The reviewer is directly addressing a potential point of confusion for the author regarding the notation `t_R^m`. By asking a specific question and suggesting a concrete action (defining the notation), the reviewer is providing a clear and actionable direction for the author to improve their draft. While the helpfulness is not perfect, it is certainly in the '4' range as it directly addresses a likely area of uncertainty."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the potential issue with using focal loss for regression (inaccurate gradients) and suggests the authors might be taking a unified approach without considering the differences between classification and regression tasks. This provides a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'focal loss is used in regression tasks' and then focuses on the specific application of 'IoU regression'. This clearly identifies the part of the paper being addressed. The reviewer also provides a reason for the criticism ('focal loss is famous for doing class imbalance problem. It has lower gradients on easy samples, which is a good property for classification. But for regressing the IoU, lower weight for easy samples may cause inaccurate problem'). This specifies the issue within the identified part.", "verifiability_rationale": "The reviewer provides a claim that focal loss might be problematic for regression due to inaccurate gradients. They support this claim by stating 'focal loss is famous for doing class imbalance problem. It has lower gradients on easy samples, which is a good property for classification. But for regressing the IoU, lower weight for easy samples may cause inaccurate problem'. While they don't provide external references, their reasoning is based on the known properties of focal loss and the nature of regression tasks. The reasoning is logical and provides a basis for understanding the potential issue.", "helpfulness_rationale": "The reviewer raises a valid concern about the potential mismatch between the design of focal loss for classification and its application for regression. This is a relevant point for the authors to consider and potentially address. While the reviewer doesn't offer a specific solution, they highlight a potential area for improvement in the paper, suggesting a unified approach might not be optimal for all tasks."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point is a question about the method's scaling behavior, which can be interpreted as an implicit action. However, the question is vague, asking about scaling with 'corpus size' and 'hidden dimension size' without specifying how these factors are increased or what aspects of scaling are being considered. While it encourages the authors to think about this, it doesn't provide concrete steps or identify a specific problem to address.", "grounding_specificity_rationale": "The review point asks about the method's scaling behavior in general, without referencing a specific part of the paper or the method. The reference is broad, encompassing the entire method. Therefore, the authors cannot confidently determine which part the comment addresses. However, the comment does specify what needs to be addressed in this part, which is the method's scaling behavior.", "verifiability_rationale": "The review point is a question posed to the authors, not a statement containing a claim or assertion. There is no evidence or reasoning provided to support or justify the question itself. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The review point is a question that, while relevant, doesn't directly provide actionable feedback to the authors. It encourages them to think about a specific aspect of their method but doesn't give them a clear next step or solution. Therefore, it is not immediately helpful for improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their desire to verify the statistical significance of the improvement, indicating an action. However, they do not specify the method or criteria for this verification, making it less concrete.", "grounding_specificity_rationale": "The reviewer refers to 'improvements of the proposed model over the RL without feedback model' and specifically points to 'row3 vs. row4 in table 6'. This clearly identifies a specific part of the paper and a comparison within it, demonstrating strong grounding. The request is also specific about the type of improvement being questioned.", "verifiability_rationale": "The reviewer makes a claim about the improvement being 'not so high'. However, they do not provide any logical reasoning, examples, or external references to support this claim within the review point itself. The request for verification implies a belief in the claim's verifiability, but the evidence is missing in this review point.", "helpfulness_rationale": "The reviewer identifies a valid concern regarding the statistical significance of the improvement. This is a relevant and actionable feedback for the authors. However, the request is vague and lacks specific instructions on how to verify the significance, making it less helpful in its current form."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their desire to relax the requirement of visiting all ballaction pairs and asks about the implications of partial coverage. This indicates an action or suggestion. However, the reviewer does not provide specific details on how this relaxation could be achieved or what concrete steps would be involved in partially covering the pairs. The suggestions are vague, such as 'Perhaps you can use some heuristics' or 'Maybe you can use some approximation algorithms'.", "grounding_specificity_rationale": "The reviewer asks a question related to a specific aspect of an algorithm (ballaction pairs). While they are referencing a previous remark, the current review point itself doesn't pinpoint a specific ballaction pair or algorithm detail. The reference is general. The reviewer is asking for a general strategy rather than addressing a specific issue.", "verifiability_rationale": "The reviewer is asking a question, not making a claim. They are seeking information or guidance. Therefore, there is X to verify.", "helpfulness_rationale": "The reviewer asks a question related to a previous remark about reducing the need to visit all ballaction pairs. While the question is relevant and seeks clarification, the review point itself does not offer any concrete solutions or propose a specific approach to achieve the relaxation. The suggestions are vague and lack detail. The reviewer is asking *what can be done* but does not provide *how* or *what* specific steps could be taken. The helpfulness is limited as it does not directly address the issue raised in the previous remark with actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about the potential impact of using a different encoder. While the question is direct, it doesn't specify *how* the authors should go about investigating this further. The action is implied but not stated explicitly. Therefore, it is not fully actionable as it lacks concrete steps for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'BERT' and 'RoBERTabase', which are specific models. This demonstrates strong grounding as the authors can easily identify the referenced parts of the paper. The comment clearly specifies what is being asked about (potential improvement with a different encoder).", "verifiability_rationale": "This review point does not contain a claim. It is a question posed to the authors. Therefore, it does not have verifiability as it is not making a statement that can be verified.", "helpfulness_rationale": "The reviewer directly asks a question that, if answered, could provide valuable information for the authors regarding the potential benefits of a different encoder. This is a relevant and potentially helpful suggestion for improving their draft by exploring alternative models."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests the action of 'collecting more data' on 'traditional multilingual tasks' like XNLI and XTREME. This is a clear and direct instruction for the authors, making it an explicit and concrete action to improve their draft.", "grounding_specificity_rationale": "The reviewer mentions 'traditional multilingual tasks' and specifically names 'XNLI' and 'XTREME'. This allows the authors to identify the specific area of the paper being addressed. While the reviewer doesn't ask for a *unique* element, naming specific datasets implies a clear focus on these resources, making it grounded. The comment also specifies the *purpose* of using these datasets (showing generalization to tasks with different reasoning requirements), adding to its specificity.", "verifiability_rationale": "The review point contains a claim that 'more datasets on traditional multilingual tasks like XNLI, XTREME, can show the proposed technique can generalize to tasks with different levels of reasoning requirements'. While the reviewer doesn't provide direct evidence or references to support this claim, it clearly states a hypothesis and a direction for investigation. The suggestion to use these datasets provides a basis for the authors to verify the technique's generalization ability. However, without specific examples or external references, the verifiability is limited.", "helpfulness_rationale": "The review point directly suggests a concrete action for the authors: 'collect more data' on 'traditional multilingual tasks' like XNLI and XTREME. This is a clear and actionable suggestion that directly addresses a potential weakness in the authors' current evaluation setup. It provides a specific direction for the authors to take, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action (improving baseline methods) but is vague on how to execute it. The reviewer suggests comparing to other existing methods but doesn't provide specific guidance on how to perform this comparison or what aspects to focus on.", "grounding_specificity_rationale": "The comment explicitly mentions specific existing methods (RefNeRF and MipNerf) as baselines, and it implies they should be used for specific areas (appearance decomposition and larger outdoor scenes). This provides clear grounding as the specific methods and areas are mentioned. The comment also suggests replacing the current baselines, which implies a clear action to be taken.", "verifiability_rationale": "The comment contains a claim (improving baseline methods) and provides some justification by naming specific existing methods and their relevance to the mentioned areas. However, it lacks explicit references or logical reasoning to support why these methods are superior or how they will improve the results. The justification is based on implication rather than concrete evidence.", "helpfulness_rationale": "The comment provides a suggestion (improving baseline methods) and names specific existing methods (RefNeRF and MipNerf) as replacements. This suggests a clear direction for the authors to take. However, it lacks explicit reasoning or justification for why these specific baselines are better or how they will lead to improved results. The suggestion is present, making it 3, but lacks the depth needed for full impact."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states an action: 'show how to achieve fair policy learning to achieve fair policy learning'. This is a clear and direct instruction on what needs to be done.", "grounding_specificity_rationale": "The reviewer explicitly states a goal: 'how to achieve fair policy learning' and grounds this goal in a practical constraint: 'without severely damaging the performance of predictive model'. This grounds the goal in a specific aspect of the paper and provides a clear direction for the action.", "verifiability_rationale": "The reviewer's point is more of a practical guideline or suggestion rather than a claim requiring verification. While it's a useful suggestion, it doesn't contain a claim that can be supported by logical reasoning, common knowledge, or external references within the review point itself. Therefore, it's borderline 1 as it doesn't present a definitive statement that needs to be justified.", "helpfulness_rationale": "The reviewer's point directly addresses a practical concern for researchers working in this area: balancing fairness with predictive performance. This is a highly relevant and actionable suggestion that can help researchers improve their work. It provides a concrete direction for further investigation and experimentation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a weakness ('lack of implementation details') and suggests a concrete action (including them in Section 4.1). While the action is implied, the reviewer clearly states the problem and the desired outcome, making it 3. However, the lack of specificity about *what* is missing makes it only 3.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 4.1', allowing the authors to accurately pinpoint the section being addressed. This constitutes full grounding. However, the point does not specify *what* information is missing within that section, making it underspecific.", "verifiability_rationale": "The review point identifies a weakness ('lack of implementation details') and suggests a solution (including them in Section 4.1). This constitutes a claim. However, the claim is not supported by logical reasoning, common knowledge, or external references. It is presented as a suggestion rather than a verifiable statement. Therefore, it is X (X).", "helpfulness_rationale": "The review point clearly identifies a specific area needing improvement ('lack of implementation details') and provides a concrete suggestion for improvement (including them in Section 4.1). This directly addresses a potential bottleneck for the authors trying to understand and build upon the work. While the suggestion is broad, it is a clear direction for the authors to take. Therefore, it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states 'no empirical evaluation whatsoever is provided' and 'no comparison (except for on an abstract level) with other methods.' While the reviewer doesn't directly identify the *specific* part of the paper lacking this, the suggestion to 'improve their draft' implies a desire for these elements. The lack of explicit instructions on *how* to perform these evaluations or comparisons makes the action implicit.", "grounding_specificity_rationale": "The reviewer mentions 'empirical evaluation' and 'comparison with other methods' as missing elements. However, they do not explicitly identify the specific part of the paper or method where these are lacking. The reviewer implies these are areas for improvement but doesn't pinpoint the exact location within the paper.", "verifiability_rationale": "The reviewer makes the claim 'It is completely unclear what the practical value of the contribution even could be.' This is a claim requiring justification. The support for this claim is the lack of empirical evaluation and comparisons. However, this lack of evidence makes the justification weak. There's no external reference or logical reasoning provided to *prove* the unclear practical value. It's an assertion based on the absence of information.", "helpfulness_rationale": "The reviewer's overall assessment is that 'the submission is not suitable for a publication at NeurIPS' due to the lack of empirical evaluation and practical value. This directly translates to the review point being unhelpful in identifying ways to improve the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a clear notational inconsistency where 'P' is used for both probability and the cumulative distribution function. While the reviewer doesn't explicitly state the action to take (e.g., 'Check the definition of P in those equations'), the ambiguity makes it difficult for the authors to proceed confidently. The action is implicit but not fully explicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific locations in the appendix (Eq. (3) and (4) and L44) where the notational inconsistency occurs. This provides strong grounding as the authors can directly identify the problematic parts of the paper. The issue is also specific, detailing the dual use of 'P'.", "verifiability_rationale": "The reviewer makes a clear claim that 'P' is used inconsistently for probability and CDF, citing specific equations and a line number. This claim is wellsupported by the provided references and the explanation of the confusion. The reasoning is logical and the evidence is direct.", "helpfulness_rationale": "The reviewer's point is 5. They are identifying a clear notational inconsistency that could lead to confusion or errors. The authors can directly address this by checking the definitions of probability and CDF in standard statistical literature or software documentation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the potential issue ('are all feature spaces wellsuited for 1NN?') and suggests a solution ('If a feature space is not close to a spherical Gaussian, it may perform poorly. If feature dimensions are individually standardized, it would avoid this issue.')", "grounding_specificity_rationale": "The reviewer directly mentions 'line 213', providing a very specific location in the paper. They then elaborate on the issue by mentioning 'feature spaces', '1NN', 'spherical Gaussian', and 'individually standardized'.", "verifiability_rationale": "The reviewer makes a claim ('are all feature spaces wellsuited for 1NN?') and provides a reason ('If a feature space is not close to a spherical Gaussian, it may perform poorly.') and a potential solution ('If feature dimensions are individually standardized, it would avoid this issue.')", "helpfulness_rationale": "The reviewer's point directly addresses a potential technical limitation of using 1NN, which could lead to improved understanding and potential modifications in the authors' implementation. The suggestion to standardize features is also a practical piece of advice."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the 'contrastive gap' is unclear. This is a direct and actionable criticism. The reviewer suggests a concrete action: 'a clear, formal definition'. This action is directly implied and directly addresses the identified weakness.", "grounding_specificity_rationale": "The reviewer identifies the 'proposed *contrastive gap*' as the area needing clarification. This provides some level of grounding by specifying the location of the issue within the paper. However, the reviewer does not specify *exactly* what aspect of the 'contrastive gap' is unclear or what constitutes a 'formal definition'. The specificity of the grounding is limited.", "verifiability_rationale": "The reviewer makes a claim that the 'contrastive gap' has 'never been defined clearly'. This is a claim that requires justification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The verifiability of this statement is low as the reasoning is missing.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement: 'a clear, formal definition'. This directly addresses the identified weakness and provides a concrete path for the authors to improve their draft. The suggestion is directly related to the identified lack of clarity."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two explicit suggestions: 'Correct the inaccurate statement on line 143' and 'Clarify the action space definition on line 154'. These are direct actions that the authors can readily implement.", "grounding_specificity_rationale": "The reviewer points to specific lines (143 and 154) indicating where the issues are. However, for line 154, the reviewer states 'unclear if each action is a single feature or the power set', which is a lack of specific information about the action space definition itself, rather than a direct identification of the referenced part.", "verifiability_rationale": "For line 143, the reviewer claims 'This is not true of standard MDP formulations' without providing specific examples or references to support this claim. For line 154, the reviewer states 'it's not clear if each action is a single feature or the power set', which is a claim that needs further clarification and justification.", "helpfulness_rationale": "The reviewer's suggestion to correct the inaccurate statement on line 143 is a direct and actionable improvement that would help the authors understand the paper better. The suggestion to clarify the action space definition on line 154 is also a helpful and actionable piece of feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a weakness in the paper (lack of comparison to other works) and suggests improvements (mentioning baselines, explaining the chosen baseline's relevance, adding questions). While the reviewer doesn't explicitly state 'I want you to compare to these papers,' the action of comparing is implied. The reviewer also suggests specific baselines (29, 5, 6 and general concepts like 'other works discussed in related work') which makes the action relatively concrete, although the exact nature of the comparison isn't fully specified.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'other baselines' and provides specific examples of related works (29, 5, 6) and even suggests specific aspects of those works (detailed experimental setup, theoretical foundations). The reviewer also suggests adding questions, which targets a specific area. This indicates a strong grounding as the authors can identify the specific part of the paper being addressed (the lack of comparison to other works) and the issue within that part (the missing baselines and questions).", "verifiability_rationale": "The reviewer states a preference for including 'Ideal other baselines would also be included' and provides specific examples of related works (29, 5, 6) and even suggests specific aspects of those works (detailed experimental setup, theoretical foundations). However, the reviewer does not provide any external references or logical reasoning to *support* the claim that including these baselines would improve the paper. The statement is presented as a suggestion rather than a claim that can be verified.", "helpfulness_rationale": "The reviewer identifies a valid point (the lack of comparison to other works) and offers suggestions for improvement (mentioning baselines, explaining the chosen baseline's relevance, adding questions). However, the suggestions are somewhat general and lack a clear connection to a specific weakness in the authors' draft. The reviewer suggests baselines but doesn't explicitly state what specific aspects of the authors' work these baselines are meant to address. The suggestion to explain the chosen baseline's relevance is also vague. The reviewer also suggests adding questions, which is helpful but doesn't specify what kind of questions or how they should be framed."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies the phrase 'a response candidate can meet each utterace' as unclear. While the reviewer points to the need for clarification, the specific action to be taken (e.g., to ask for clarification, to rephrase) is not explicitly stated. The reviewer's suggestion of 'asking for clarification' is a general suggestion, making the action somewhat implicit. The reviewer identifies the need for clarification, but the specific steps to achieve this are not detailed.", "grounding_specificity_rationale": "The reviewer explicitly mentions the line number (280) where the phrase 'a response candidate can meet each utterace' is located. This indicates a strong grounding as the comment accurately identifies the specific part of the paper being addressed. The comment clearly pinpoints the section where the issue lies.", "verifiability_rationale": "The reviewer points out that the phrase 'a response candidate can meet each utterace' is difficult to understand. This constitutes a claim that something is lacking in the paper. However, the reviewer does not provide any external references or logical reasoning to support this claim. The suggestion is to 'ask for clarification', which is a request rather than a verifiable claim. The comment identifies a problem but doesn't provide evidence to support the claim of unclear writing.", "helpfulness_rationale": "The reviewer identifies a specific instance of unclear writing in the paper. While identifying a problem is helpful, the reviewer does not provide a concrete suggestion for improvement beyond 'asking for clarification'. The comment is grounded in the specific line number where the issue is located. However, the lack of a specific, actionable suggestion limits the overall helpfulness of the comment."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the inconsistency in naming conventions between L_task and L_class. This constitutes an explicit action, as the reviewer directly points out a discrepancy. While the point doesn't provide concrete guidance on what to do with this information, it identifies a specific area where clarification is needed. Therefore, the action is identified, making it 3.", "grounding_specificity_rationale": "The review point directly references 'L_task' in the text and 'L_class' in Figure 1. This clearly identifies the specific notations being discussed, indicating strong grounding. The reviewer does not mention any other parts of the paper or figure, further emphasizing the specificity of the reference.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a factual observation about the inconsistency in naming conventions. There is no logical reasoning, external references, or examples provided to support the observation itself. Therefore, it does not meet the criteria for a verifiable claim.", "helpfulness_rationale": "The review point identifies a potential source of confusion for the authors regarding the naming of the task loss. While it points out the discrepancy, it doesn't explicitly suggest a specific action or improvement the authors should take. It serves as a headsup about a potential issue rather than a direct solution. Therefore, it is 3 in highlighting a potential problem."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question prompting the authors to consider limitations and specifically the 'shallow network\" issue. While not a direct instruction, it's a form of actionable feedback by encouraging the authors to reflect on their method's limitations. The question implicitly asks the authors to identify potential weaknesses.", "grounding_specificity_rationale": "The review point mentions \"other limitations of the method\" and specifically \"the network was pretty shallow.\" While it points to a general area of concern, it doesn't explicitly name a specific part of the paper or methodology being addressed. The mention of the \"network\" is somewhat vague, making it difficult to pinpoint the exact issue.", "verifiability_rationale": "The review point is a question, not a declarative statement containing a claim. Therefore, it doesn't have verifiability aspects.", "helpfulness_rationale": "The review point is a question prompting the authors to consider limitations. While it encourages critical thinking, it doesn't directly identify a specific weakness or provide a clear path for improvement. It's more of a suggestion for further selfreflection than a direct critique with actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests evaluating the proposed method in machine translation, which is a specific task within the broader domain of natural language processing. While this could be an actionable suggestion, the reviewer does not explicitly state how the authors should go about implementing this evaluation. They don't provide concrete steps or tools. The suggestion is more of a direction than a specific action.", "grounding_specificity_rationale": "The reviewer suggests evaluating the proposed method in machine translation. While they could be interpreted as implicitly referring to a 'specific part' of the field (the 'close domain' aspect), the connection between their suggestion and the specific part of the paper being evaluated is not explicitly stated. The reviewer doesn't pinpoint a specific section or table in the paper that would benefit from this evaluation approach. The grounding is implied but not clearly defined.", "verifiability_rationale": "The reviewer's statement that 'This work only uses answer generation and summarization to evaluate the proposed method' is a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. They simply state it as a fact. There is no evidence presented to verify this statement. The claim is presented without any backing.", "helpfulness_rationale": "The reviewer's comment primarily focuses on the evaluation methodology and suggests machine translation as a more suitable 'close domain' task. While this is a valuable suggestion, the comment itself does not provide specific, actionable feedback on how the authors should improve their current evaluation framework. The reviewer does not offer concrete steps or tools for implementing the suggested evaluation in machine translation. The comment is more of a suggestion for improvement rather than a direct critique of the authors' work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of the current evaluation and suggests specific improvements. The statement 'Only showing the performance drop on fusion models is not enough' directly identifies an implicit action: the need to evaluate on a broader range of models. Similarly, the suggestion 'Comparisons with other singlestage attacks are also needed' is an explicit action pointing to a specific area for improvement. The reviewer provides clear guidance on how to make the evaluation more robust.", "grounding_specificity_rationale": "The reviewer refers to 'the twostage optimization approach' and 'the performance drop on fusion models,' which are specific parts of the paper. The reviewer also explicitly states the need for 'comparisons with other singlestage attacks' as a specific improvement. The grounding is clear, and the specific elements being addressed are welldefined.", "verifiability_rationale": "The reviewer makes a claim: 'Without proper benchmarks and comparisons with other SOTA algorithms, it is hard to justify the effectiveness of the technical contributions.' This claim is supported by logical reasoning. The reviewer explains *why* these elements are important: 'Only showing the performance drop on fusion models is not enough' and 'Comparisons with other singlestage attacks are also needed.' The reviewer provides a clear justification for their claim, outlining the specific shortcomings of the current evaluation.", "helpfulness_rationale": "The reviewer provides concrete suggestions for improvement, directly addressing a potential weakness in the paper's evaluation methodology. The reviewer's points are actionable and directly address the need for more comprehensive benchmarks. The suggestion to 'compare with other singlestage attacks' is a specific and valuable contribution to the paper. The reviewer's feedback is not just critical but also offers a clear path forward for strengthening the evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment states a fact about missing information (GPU type and inference time) but does not explicitly instruct the authors on how to address this or what specific changes are needed. The implications are implied (the authors will likely need to provide this information), but the actionable step isn't stated directly.", "grounding_specificity_rationale": "The comment refers to 'this paper' generally, mentioning 'GPUs' and 'inference time' without specifying a particular section, table, figure, or unique aspect of the paper. The authors would need to search the paper to find where this information might be relevant.", "verifiability_rationale": "The comment makes a claim: 'This paper does not provide the type of GPUs, and inference time when testing.' This claim is based on the information provided in the paper (or the reviewer's assessment of the paper's content). While the reviewer might be inferring that this missing information is important, the statement itself is verifiable based on the paper's content.", "helpfulness_rationale": "The review point highlights a missing piece of information crucial for reproducibility and understanding the experimental setup. While it doesn't *teach* the authors how to conduct this analysis, it points to a significant gap that would be valuable for the authors to address or clarify."}
{"actionability_label": "3", "grounding_specificity_label": "Fully Grounding Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "Part 1 of the review point is not actionable as it's a question about the significance of sections. However, parts 2 and 3 are actionable as they point out specific missing notations and elements in equations, providing clear directions for improvement.", "grounding_specificity_rationale": "Part 1 of the review point is weakly grounded as the reviewer is questioning the importance of sections without explicitly identifying a specific section. However, parts 2 and 3 are fully grounded as they specifically point out the missing variables and elements in equations.", "verifiability_rationale": "Part 1 of the review point is not verifiable as it's a question about interpretation, not a claim requiring verification. However, parts 2 and 3 are verifiable as they point out specific issues in the equations that can be checked against the paper's content or external knowledge.", "helpfulness_rationale": "Part 1 of the review point is not very helpful as it's a question about significance, not a suggestion for improvement. However, parts 2 and 3 are helpful as they directly point out actionable steps the authors can take to understand and potentially improve their implementation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the connections in Figure 2 are incorrect and specifies *which* connections are wrong and *why* they should be wrong. They suggest that the Perceptual Metric should connect the Second Inpainted Images with the Inpainted Image, but not the Images Masked by Second Masks. This indicates a clear and direct action the author should take to correct the figure.", "grounding_specificity_rationale": "The reviewer directly refers to specific elements of Figure 2, namely 'The Perceptual Metric,' 'Second Inpainted Images,' 'Inpainted Image,' and 'Images Masked by Second Masks.' They accurately identify the intended connections based on their understanding of the method. This demonstrates a strong grounding of the comment in the specific part of the paper being discussed.", "verifiability_rationale": "The reviewer makes a claim about the intended connections in Figure 2. While they don't explicitly state the *reasoning* behind this claim, it's a reasonable assumption based on standard practices for visualizing connections between outputs of different stages. The claim is supported by the visual representation and the implied workflow of the method.", "helpfulness_rationale": "The reviewer directly points out a visual error in Figure 2 that could confuse the reader. They provide a clear suggestion for correction, which is a concrete action the author should take. This directly impacts the author's ability to understand the method and potentially replicate it."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states the sentence is confusing and provides a specific line number. This suggests a potential lack of clarity or explicitness. While the sentence is grammatically correct and conveys a meaning, the mechanism of 'memorizing each newly added filter by the shape of every layer' is vague. It doesn't explicitly tell the author how this memorization happens. Therefore, while the reviewer identifies a problem, the action to be taken is not explicitly stated within the review itself.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'the sentence 9395' by providing the line number. This clearly identifies the specific part of the paper being addressed. Furthermore, the reviewer asks 'how to implement the inferred action' regarding this sentence, which directly specifies the issue within that part. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer states the sentence is 'confusing' and suggests they 'believe I understood it after rereading it and the subsequent sentences but it is not immediately obvious what is meant.' This statement expresses an opinion about the sentence's clarity. While the reviewer provides a reason for their belief ('it is not immediately obvious what is meant'), this is not a definitive claim that requires external verification or logical reasoning. Therefore, the claim is somewhat justified but lacks key elements like examples or references.", "helpfulness_rationale": "The review points out a potential point of confusion for the author, which could hinder their progress. While identifying a confusing sentence is valuable feedback, the review does not offer a concrete solution or actionable steps for the author to take. The reviewer's belief that they eventually understood the sentence after rereading suggests the issue was not immediately clear, which could be a barrier for other authors. Therefore, the review highlights a potential area needing clarification, making it 3 in pointing out a potential issue, but it doesn't directly address the problem with a solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit suggestions for improvement, such as 'yes, but you need a citation there' and 'we can always sample more efficiently using different samplers from the literature that trade off sample quality.' These suggestions are clear and point to specific areas that require attention. However, the suggestion in 'This improves the reliability and efficiency, because diffusion models are more compute efficient a training smaller dimensional latent variables and input tokens inherently have different lengths' lacks concrete details on how to implement this improvement.", "grounding_specificity_rationale": "The review point explicitly mentions specific sections and techniques. For example, it refers to 'diffusion models' and 'generative adversarial networks' in the first point, 'previous work' in the second, 'section 3' in the third, and 'section 4' in the fourth. This indicates a strong grounding of the criticism within the paper.", "verifiability_rationale": "The review point makes claims that require verification. For instance, the statement 'Previous work has tried to tackle... but with limited success' implies a need for citations to support this claim. Similarly, the suggestion 'we can always sample more efficiently using different samplers from the literature that trade off sample quality' also implies the need for references to back up this assertion. The claim 'diffusion models have been able to outperform generative adversarial networks on image generation benchmarks' also requires evidence to validate the comparison.", "helpfulness_rationale": "The review point provides clear and actionable feedback that directly addresses potential weaknesses in the paper. It suggests specific improvements such as adding citations, providing evidence, and modifying the text. These suggestions are directly aimed at helping the authors improve their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that Fig 1 is not consistent with Fig 2. They also point out a specific detail: Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows a single encoderdecoder per auxiliary task. This is an explicit action, and the reviewer provides a concrete detail about the discrepancy.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Fig 1' and 'Fig 2', which are specific parts of the paper. They also clearly states what is wrong with these figures: 'a single shared encoderdecoder for multiple tasks' vs 'a single encoderdecoder per auxiliary task'. This strong identification of the specific part and the issue within it demonstrates full grounding and specificity.", "verifiability_rationale": "The comment contains a claim: 'Fig 1 is not consistent with Fig 2'. However, the reviewer does not provide any evidence, reasoning, or external references to support this claim. While the claim is identified, there is no verification provided to justify the inconsistency. Therefore, it is not 5.", "helpfulness_rationale": "The comment identifies a potential issue with the figure descriptions. However, it does not provide any actionable suggestions or guidance on how to resolve the inconsistency. While the reviewer points out a factual error, they do not take the next step of suggesting a debugging process or a correction. Therefore, it is 3 in identifying the problem, but lacks concrete suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "3: 1", "actionability_rationale": "The reviewer raises a valid point about the clarity of the attention mechanism. While the paper describes the attention mechanism, it doesn't explicitly state whether 'N_l^(s)' refers to immediate neighbors or a broader range of nodes. This ambiguity makes it difficult for the authors to understand the exact scope of the attention and how it applies to different nodes in the graph. The lack of clarity hinders their ability to implement the method correctly and understand its implications. Therefore, the reviewer's point is actionable as it directly impacts the authors' ability to use the method effectively.", "grounding_specificity_rationale": "The reviewer's concern about the grounding of the attention mechanism is wellfounded. The paper describes the attention mechanism but doesn't clearly define what constitutes a 'neighboring node' in the context of the graph. The description of 'N_l^(s)' is vague and doesn't specify whether it refers to immediate neighbors, nodes within a certain distance, or nodes in the same layer. This lack of specificity makes it difficult for the authors to understand the exact nodes that are being attended to and how the attention weights are being calculated. The reviewer's question about equation 2 highlights this ambiguity, as it's unclear if the attention is truly limited to immediate neighbors or if there's a possibility of attending to nonneighboring nodes. This weak grounding hinders the authors' ability to understand the method's behavior and limitations.", "verifiability_rationale": "The reviewer's question about the scope of the attention mechanism and the definition of 'neighboring nodes' raises concerns about the verifiability of the review point. The paper describes the attention mechanism but doesn't provide sufficient detail to fully understand its implementation. It's unclear whether the attention is truly limited to immediate neighbors or if there's a possibility of attending to nonneighboring nodes. The lack of clarity makes it difficult for the authors to verify the exact behavior of the method and understand its implications. The reviewer's confusion about equation 2 further highlights this issue, as it's not clear if the interpretation of 'N_l^(s)' is accurate or if there are nuances that are being missed. This lack of verifiability could lead to misunderstandings and misinterpretations of the method.", "helpfulness_rationale": "The reviewer's point about the clarity of the attention mechanism is highly relevant to the helpfulness of the review. The lack of clarity regarding the scope of the attention and the definition of 'neighboring nodes' could hinder the authors' understanding of the method and their ability to implement it correctly. The reviewer's confusion about equation 2 suggests that the description is not sufficiently detailed to fully understand the method's behavior. This lack of clarity makes it difficult for the authors to grasp the implications of the attention mechanism and how it relates to their own work. Therefore, the reviewer's concern significantly reduces the helpfulness of the review point."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer is directly asking for a clarification on how a specific inequality follows from a previous result (Lemma 7). This is an explicit request for a connection between two parts of the paper, making it actionable for the authors. The reviewer is indicating they understand the components involved but need a clearer explanation of the logical jump.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Lemma 7' and the inequality after line 433. This demonstrates a clear understanding of the relevant section of the paper and a specific focus on a particular element, indicating high grounding specificity.", "verifiability_rationale": "The reviewer is asking for a clearer explanation of how the inequality follows from Lemma 7. This implies that the connection is not immediately obvious and requires justification. While the reviewer isn't making a claim about the correctness of the inequality itself, they are claiming that the connection to Lemma 7 needs to be better justified, making it partially verifiable.", "helpfulness_rationale": "The reviewer is directly addressing a potential point of confusion for the authors by asking for clarification on a specific mathematical step. This is a valuable contribution to the review process, as it directly addresses a potential weakness in the authors' understanding and provides a clear path for improvement. The reviewer is not making a subjective judgment about the correctness of the inequality, but rather pointing out a lack of clarity in the logical connection."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issues: 'unclear,' 'overstated,' 'not wellsupported,' 'not clear,' 'unclear.' This directly points to areas needing action. While the reviewer doesn't specify *what* is unclear or how it is unclear, the identification of the areas needing improvement makes the action somewhat explicit. The reviewer identifies the *area* of the paper being discussed (main contribution, proposed method, multitasking, automation) but doesn't detail *where* the lack of clarity is. Therefore, the action is somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'the main contribution,' 'the proposed method,' 'dynamic largescale multitasking,' and 'automation.' While they don't pinpoint a *section* or *figure*, they do identify the *area* of the paper being discussed. This can be considered weak grounding as the authors can make an educated guess about where the issues lie. However, the reviewer does not specify *what* needs to be addressed in these areas. Therefore, the grounding is somewhat underspecific.", "verifiability_rationale": "The reviewer makes claims: 'the main contribution of this paper is unclear,' 'they either somewhat overstated the ability or applicability of the proposed method or were not wellsupported,' 'the main idea of how the proposed method copes with dynamic largescale multitasking is not clear,' and 'How the automation is achieved is also unclear.' These are clear statements of opinion or judgment. However, the reviewer does not provide *reasons* or *examples* to support these claims. The claims are presented without sufficient justification or evidence. Therefore, the verifiability is somewhat 1.", "helpfulness_rationale": "The reviewer identifies specific problems with the paper's main contribution, novelty claims, and the explanation of the method and automation. While they don't offer direct solutions, they clearly point out areas where the authors need to improve. The reviewer's comments highlight concrete weaknesses that the authors can directly address. Therefore, the review point is 3 in guiding the authors towards selfimprovement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "Both suggestions in the review point are implicitly suggesting an action. The first suggests including results, and the second suggests evaluating performance. However, the actions are not explicitly stated, and the details on how to implement them are missing, making them only 2.", "grounding_specificity_rationale": "The review point explicitly mentions specific components: 'the bottomup method 9', 'crowdpose dataset', 'Table 4', 'MS coco dataset', and 'easy (non occluded) settings'. This indicates a clear identification of specific parts of the paper or experiments being referred to.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It presents suggestions for future experiments or evaluations without making any judgments or assertions about the current work or the expected outcomes of those experiments.", "helpfulness_rationale": "The review point offers suggestions for improving the authors' work by including results from a specific method on a specific dataset and evaluating performance on another dataset. While these suggestions are relevant and could be helpful, they lack concrete steps or specific guidance on how to achieve these improvements, making them 3 but not fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the claim of using 'annotation guideline' may be an overstatement. While this points out a potential issue, the reviewer does not explicitly state what needs to be done to verify or address this overstatement. The suggestion is present, but the action is not fully specified.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'label name', 'label description', and 'fewshot examples' as the aspects of their analysis. This clearly identifies specific parts of the paper being discussed, indicating strong grounding. The comment also specifies what the reviewer is considering when they say 'this paper only considered...'", "verifiability_rationale": "The reviewer makes a claim that the paper 'may be an overstatement' regarding the use of annotation guidelines. However, the reviewer does not provide any specific evidence, examples, or references to support this claim. The statement is presented as a potential issue without a clear path to verification or justification.", "helpfulness_rationale": "The reviewer identifies a potential overstatement regarding the use of annotation guidelines. While this points out a limitation, the reviewer does not offer any concrete suggestions or actions for the author to take. The feedback is present but lacks actionable steps, making it less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "Partially Verifiable", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the weakness: 'the author only compare their method to the BERTbaseline.' This is a clear and direct statement of the missing comparisons. Furthermore, the review point concretely identifies the *missing* baselines: 'token pruning and token combination baselines.' This provides a specific direction for improvement. The authors are directly informed to compare their method to these specific baselines.", "grounding_specificity_rationale": "The review point explicitly states the weakness: 'the author only compare their method to the BERTbaseline.' This directly points to the comparison as the area needing improvement. While it doesn't pinpoint a *specific* part of the experimental setup (e.g., a particular layer of the BERT model), it clearly identifies the *comparison* itself as the issue. Therefore, it is grounded in the context of the comparison.", "verifiability_rationale": "The review point contains a claim: 'the author only compare their method to the BERTbaseline.' This claim could be verified by examining the results of the BERT baseline and the missing baselines (if those results were available). However, the review point itself does not provide the evidence to support this claim. The suggestion to compare to token pruning and token combination baselines is a recommendation, not a claim requiring external verification to be considered valid.", "helpfulness_rationale": "The review point clearly identifies a weakness in the experimental setup (the limited baseline comparison) and provides a concrete suggestion for improvement (comparing to token pruning and token combination baselines). This directly helps the authors address the identified weakness and improve their draft. The suggestion is actionable and provides a clear direction for further experimentation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of 'Compare to coordinateaware methods, such as TFN or SchNet' and suggests this comparison as a solution to the identified limitation. This is a clear and direct instruction for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions 'the experimental section' and then names specific methods (TFN and SchNet) and a comparison type ('coordinateaware'). This clearly identifies the specific part of the paper and the relevant methods being addressed.", "verifiability_rationale": "The claim to compare to coordinateaware methods is supported by the common understanding of method categories and the relevance of methods like TFN and SchNet for point cloud data. While not explicitly citing a paper, the reasoning is generally accepted within the field.", "helpfulness_rationale": "The review point directly identifies a weakness in the experimental section (lack of comparison to coordinateaware methods) and offers a clear and specific suggestion for improvement (comparing to TFN or SchNet). This directly addresses a need for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The comment identifies a potential weakness but does not specify how the authors should go about finding or addressing it. It lacks concrete steps or actions for the authors to take.", "grounding_specificity_rationale": "The comment is too general and does not specify which part of the paper or model the weaknesses might be in. It lacks precision in identifying the relevant section, table, figure, or unique aspect.", "verifiability_rationale": "The comment points out a potential weakness but does not provide any evidence or reasoning to support it as a claim. It lacks logical reasoning, common knowledge, or external references to back up the assertion.", "helpfulness_rationale": "The comment identifies a valid concern but does not offer any solutions or directions for the authors to address it. It is a critique without any constructive feedback or actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point asks a question ('What does the system offer...') and suggests a comparison ('over the previous extractthengenerate methodologies'). This hints at being *implicit* as the reviewer doesn't explicitly state how to achieve this. The reviewer needs to *infer* the need to understand the related work and the system's contribution. Therefore, it's **2**.", "grounding_specificity_rationale": "The review point asks about 'what the others have done' and 'what the system offers.' It doesn't explicitly state which part of the paper these relate to, making it **Weakly Grounded**. However, the reviewer clearly specifies what they are asking about ('improvement', 'comparison', 'troublesome'), making it **Specific**. Therefore, it's **3**.", "verifiability_rationale": "The review point contains a claim: 'This is troublesome considering that the paper does not have any Related Work section, nor experimenting other extractthengenerate with their proposed model.' This claim is supported by the explicit statement 'the paper does not have any Related Work section, nor experimenting other extractthengenerate with their proposed model.' Therefore, it's **5**.", "helpfulness_rationale": "The review point raises a valid concern about the lack of context and comparison, which could hinder the reader's understanding of the paper's contribution. However, it doesn't offer *specific suggestions* on how to address this issue. It's more of a *detection* of a potential problem than a constructive suggestion. Therefore, it's **3**."}
{"actionability_label": "2", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an alternative approach to dealing with churn but does not explicitly state how this approach should be implemented or what steps the authors should take. While it implies a potential improvement, the lack of concrete action makes it difficult to assess its actionable potential.", "grounding_specificity_rationale": "The review point discusses the limitations of the proposed approach (training 3040 models) and suggests an alternative using unlabeled data and constraints. However, it does not specify which models are being referred to, what '3040 models' means in this context, or what 'burn in' implies. It lacks a clear reference to a specific part of the paper or analysis being discussed, making it 1.", "verifiability_rationale": "The review point proposes an alternative approach to handling churn without providing any evidence, logical reasoning, or external references to support its validity or potential benefits. It presents a speculative idea without any basis for verification.", "helpfulness_rationale": "The review point raises a valid concern about the computational cost of training numerous models and offers a potentially valuable alternative direction for research. While it doesn't provide immediate solutions or concrete steps, it encourages the authors to consider different approaches and think critically about their methodology, making it 3 in prompting further consideration and exploration."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of detail in the related work. While the reviewer identifies a problem (insufficient related work), the suggested action is to 'give more work on GLN' and 'reflect the advantages or difference of the proposed method, such as the difference from BGLN'. This is an explicit statement of what should be done, but the reviewer doesn't specify how to identify the missing work or how to compare the proposed method to BGLN. The action is broad and lacks concrete steps for the authors to take immediately.", "grounding_specificity_rationale": "The reviewer criticizes the 'introduction of related work' as being insufficient. While they pinpoint the area of concern, they do not identify a specific section, table, figure, or unique aspect within the introduction where the related work is lacking. The criticism is general to the section as a whole, lacking specificity about *what* is missing.", "verifiability_rationale": "The reviewer suggests 'more work on GLN' and 'reflect the advantages or difference of the proposed method, such as the difference from BGLN'. This statement itself is not a claim that can be verified using logical reasoning, common knowledge, or external references. It's a suggestion for improvement, presented as a request rather than a verifiable assertion.", "helpfulness_rationale": "The reviewer's comment identifies a clear area for improvement in the related work section. They suggest 'more work on GLN' and 'reflect the advantages or difference of the proposed method, such as the difference from BGLN'. While the suggestion is broad and doesn't provide specific guidance on *how* to identify the missing work or *how* to compare the proposed method, it does point towards a valuable direction for the authors to expand upon. The comment provides a direction for improvement, even if it's not entirely concrete."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the difference in the number of dropout rates used for Moon's approach and Variational dropout. It points out that the original paper uses a single dropout rate for Moon's approach while Variational dropout uses inputoutput and recurrent dropout parameters. This directly identifies a potential inconsistency or area for improvement, making it actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'Moon's approach' and 'Variational dropout', identifying the specific methods being discussed. It also specifies the type of dropout rates being used ('dropout rate' and 'inputoutput and recurrent dropout parameters'). This precise identification of the parts of the paper being addressed makes it 5.", "verifiability_rationale": "The review point makes a claim that the original paper should have used multiple dropout rates for Moon's approach, similar to Variational dropout. While this is a valid suggestion based on common practices in deep learning, the review point itself does not provide a specific justification or cite any external references to support this claim. Therefore, it is not 5, as it lacks strong supporting evidence.", "helpfulness_rationale": "The review point identifies a potential improvement to the original paper's methodology by highlighting the difference in hyperparameter settings for dropout. It points out a design choice that could be explored further. While it doesn't explicitly tell the authors *how* to fix it, it clearly identifies a gap or an area where the original paper could have been more comprehensive. This makes it a helpful comment, as it points out a concrete issue that can be addressed."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer does not explicitly state what action the authors should take to address the lack of largerscale experiments or the scalability concerns. While they point out a missing element, they don't demand its inclusion or provide a specific path forward. The reviewer suggests improvements but doesn't force the authors to implement them immediately.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'largerscale experiments' and provides specific examples like 'gridworlds with walls' and 'simple videogame domains'. They also suggest 'simulators for such experiments' and 'comparison against other approaches'. This clearly identifies the specific part of the paper (the experimental setup) being addressed and provides concrete suggestions for improvement. The reviewer uses literal mentions of specific types of experiments and suggests concrete actions.", "verifiability_rationale": "The reviewer makes a claim: 'Currently it is hard to judge whether this was simply due to a lack of time or because the method has severe scalability issues.' They then provide evidence for this claim by stating 'why were there no experiments with larger stateaction spaces and nontrivial dynamics included (at least gridworlds with walls, and other nontrivial tiles)?' This claim is supported by logical reasoning (the absence of evidence suggests a potential issue) and specific examples of what constitutes 'largerscale experiments'. The reviewer also suggests 'simulators for such experiments' which provides a reference point. The claim is thoroughly supported by the reasoning and examples provided.", "helpfulness_rationale": "The reviewer provides multiple suggestions for the authors to improve their draft. They suggest 'largerscale experiments', specifically mention 'gridworlds with walls' and 'simple videogame domains' as examples, and recommend 'simulators for such experiments'. They also suggest 'comparison against other approaches' to better understand the method's performance. These suggestions are concrete and directly address the identified weakness of the experimental setup. The reviewer also poses a question ('Why were there no experiments...') which is a helpful inquiry for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "Not Applicable", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a deficiency in the authors' work and suggests adding a quantitative measurement. While this implies a concrete action (adding a measurement), the suggestion itself is not explicitly stated. The reviewer does not specify *what* measurement to add or *how* to compare to real distributions, making the suggestion vague.", "grounding_specificity_rationale": "The review point is a general critique of the authors' methodology regarding the measurement of occupation bias and its comparison to real distributions. It does not explicitly identify a specific part of the paper being addressed, nor does it detail what is wrong or missing in that part.", "verifiability_rationale": "The review point is not a claim that needs verification. It is a critique of the authors' methodology.", "helpfulness_rationale": "The reviewer suggests a potential improvement to the authors' work by pointing out a lack of quantitative measurement. This critique is generally helpful as it guides the authors towards a more comprehensive analysis. However, the lack of specifics in the suggestion makes it less helpful overall."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer poses a question about the potential impact of adaptive gradient methods on hard features, but does not explicitly state what action the authors should take based on this question. The question is about the *potential* effect rather than a direct request for a change or analysis.", "grounding_specificity_rationale": "The reviewer mentions 'hard features' in the context of potential impact, but does not explicitly point to a specific section or element of the paper where these hard features are discussed. The connection is implied but not direct.", "verifiability_rationale": "The reviewer presents a question about the impact of adaptive methods on hard features, not a definitive statement that requires verification. There is X being made.", "helpfulness_rationale": "The reviewer asks a question that is relevant to understanding the implications of using adaptive gradient methods. While not a direct critique, it prompts a specific type of analysis that could be actionable for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing element (no information from 2hop neighbors) and suggests a concrete action (include this information). The use of 'again' implies the reviewer is drawing attention to a previous consideration, further indicating an actionable suggestion.", "grounding_specificity_rationale": "The review point directly mentions '2hop neighbors,' which is a specific technical term within the context of graphbased methods. This clearly identifies the specific part of the paper or concept being addressed.", "verifiability_rationale": "The review point makes a claim about the method being 'highly unclear' and 'unclear why it is effective.' While it doesn't provide specific evidence *within this point*, the claims themselves are verifiable. A reviewer could point to the complexity of 2hop relationships or the lack of clear justification for this specific choice.", "helpfulness_rationale": "The review point is highly specific, identifying a missing detail in a method description and suggesting its inclusion. This directly addresses a potential point of confusion for the authors and would likely improve their understanding and implementation of the method."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the preference for using DICOM images over PNG and recommends the FastMRI challenge dataset. They also suggest comparing inference speeds. These are all direct and actionable suggestions for the authors to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'DICOM image' and 'PNG image' and recommends the 'FastMRI challenge dataset'. This clearly identifies the specific parts of the paper being addressed and provides specific details about what needs improvement.", "verifiability_rationale": "The reviewer makes a claim by stating that DICOM is better than PNG for the experiment. They provide a suggestion (using the FastMRI dataset) and a justification (comparing inference speed), which is a logical and commonsense argument in the field. While there are no explicit external references, the reasoning is sound and verifiable through common practices.", "helpfulness_rationale": "The reviewer provides clear and actionable feedback on the type of image data and the dataset to use, along with a metric for comparison (inference speed). This directly addresses potential limitations or areas for improvement in the authors' work and guides them towards better experimental practices."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment states 'ProtPainter just provides an empirical conformation estimation.' This is a statement of observation about ProtPainter's behavior, not a request for improvement. It lacks explicit and concrete instructions on how to optimize or validate the conformation estimation. Therefore, it is 1.", "grounding_specificity_rationale": "The comment refers to 'ProtPainter' and 'binder design' generally, without pinpointing a specific section, table, figure, or unique aspect of ProtPainter related to conformation estimation. The grounding is weak as the authors cannot confidently determine the referenced part. The comment specifies what it is observing about ProtPainter, but not a specific part of their own work. Therefore, it is 2.", "verifiability_rationale": "The comment states 'ProtPainter just provides an empirical conformation estimation.' This is a statement of observation or limitation about ProtPainter. It does not present a claim that requires verification or justification. It describes the current behavior of ProtPainter, not a suggestion that needs to be proven. Therefore, there is X.", "helpfulness_rationale": "The comment identifies a limitation of ProtPainter. However, it does not provide specific, actionable feedback or suggestions that would directly help the authors improve their own draft. The focus is on a different tool and its general behavior, not on specific weaknesses or improvements in the authors' work. Therefore, it is not helpful for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks for clarification on the training procedure of the model in Figure 7 and suggests that the information is missing. The request is clear and directly points to a specific aspect of the paper that needs more detail. The reviewer also asks about the relationship between the stimulus cycle duration and the adaptation time scale, indicating a desire for a deeper understanding of the model's behavior.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'fig. 7' and asks specific questions about the model's training in that figure. This indicates a clear identification of the relevant section and a desire for detailed information about its content. The questions about the training procedure and the relationship to adaptation time scale are specific and directly address potential weaknesses in the paper's description.", "verifiability_rationale": "The reviewer's comment contains a claim: that the authors should clarify the training procedure of the model in Figure 7 and explore the relationship between stimulus cycle duration and adaptation time scale. The reviewer also provides a justification for this claim by stating that this information is missing and that it is important for understanding the model's behavior. The logical reasoning and the specific questions asked support the claim.", "helpfulness_rationale": "The reviewer's comment is helpful because it directly points to areas where the authors could improve their clarity and provide more context. The request for clarification on the training procedure and the exploration of the relationship between stimulus cycle duration and adaptation time scale are concrete suggestions that could lead to a better understanding of the model. The reviewer is asking the authors to provide specific details that are currently missing."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point directly asks a question about a specific scenario ('what happens if the original CAD model is already associated with spatiallyvarying (SV) BRDF maps?'). This implies an action needs to be taken or considered in this situation. The reviewer is pointing out a potential constraint or requirement that the authors might not be immediately aware of. The action is to understand the implications of this association.", "grounding_specificity_rationale": "The review point explicitly mentions 'CAD model' and 'spatiallyvarying (SV) BRDF maps.' This directly identifies the specific parts of the paper being referred to. The reviewer is not making any general statements or educated guesses about which part of the paper they are referring to. The specificity of the question is also clear \u2013 it asks about the implications of this specific association.", "verifiability_rationale": "While the review point is a question, it implicitly suggests a need for clarification or understanding regarding how this specific association affects the rendering process. The underlying 'claim' is that this scenario might require special handling or has specific implications. While the answer might not be immediately obvious to all readers, the question implies a desire for information or guidance. The reasoning would involve understanding the data structures and how they are stored and accessed in the rendering software.", "helpfulness_rationale": "This review point raises a valid question about a specific scenario that could be relevant for authors working with spatially varying BRDFs and CAD models. It highlights a potential point of confusion or a less common use case that might require further explanation in tutorials or documentation. The authors would likely need to look up how the data is stored and accessed in their specific software to understand the implications."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a desire for 'more evaluation,' which can be interpreted as an actionable suggestion to increase the rigor of the assessment. However, the specific actions or methods for this additional evaluation are not detailed, making it somewhat vague.", "grounding_specificity_rationale": "The comment explicitly mentions 'CIFAR10' and 'lower label scenarios,' indicating a strong grounding by identifying specific parts of the paper being addressed. However, it does not specify what aspects of these areas require more evaluation.", "verifiability_rationale": "The comment is a suggestion ('More evaluation would have been welcome') rather than a claim that can be verified. It doesn't provide a basis for logical reasoning, common knowledge, or external references to support the need for more evaluation.", "helpfulness_rationale": "The comment directly addresses a specific concern (the need for more evaluation on CIFAR10 with different label scenarios), making it 3 in identifying an area for improvement. However, the lack of specific suggestions limits its overall helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the concern about comparing experiments with different amounts of data and names the specific comparisons (H>N vs. H>N+B and H>N>H vs. H>N+B>H). This directly identifies the issue and provides clear actions to investigate the potential flaw.", "grounding_specificity_rationale": "The reviewer explicitly names the specific experimental setups being compared (H>N, H>N+B, H>N>H). This precise identification of the parts of the paper being discussed makes the grounding very specific.", "verifiability_rationale": "The reviewer makes a claim about the potential flaw in the experimental comparisons and provides specific examples of the experiment names (H>N, H>N+B, H>N>H) to support their claim. This claim is directly verifiable based on the provided information.", "helpfulness_rationale": "The reviewer's point, if valid, would directly address a potential issue in the authors' experimental design and data usage. This is a valuable and actionable piece of feedback that would help the authors improve their methodology."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer's questions directly address the paper's content and methodology. They clearly indicate intended actions: understanding the placement of the comment, investigating the behavior of Algorithm 1 with more iterations, finding the missing citation, and locating the figure. This is 5 as the reviewer can directly identify modifications they should apply to their draft.", "grounding_specificity_rationale": "The reviewer explicitly states where they expect to find information (end of the paper, T > 2, introduction, Figure 1). This clearly grounds their expectations in the paper's structure and content. The reviewer can accurately pinpoint the sections, table, figure, or unique aspect being addressed.", "verifiability_rationale": "The reviewer's questions are logical and based on standard practices in academic writing (citing methods, explaining algorithm parameters). While the *reviewer* might not have checked the *actual* content of the paper to confirm these points, the *review point itself* presents a claim (that these things should be there) with a *method* for verification (check those sections). This is highly verifiable.", "helpfulness_rationale": "The reviewer's questions are directly relevant to understanding and using the paper. They highlight potential areas of confusion or missing information that could hinder the reader's experience. The questions are clear and directly address potential points of ambiguity in the paper's presentation and methodology. This is 5 as the reviewer can gain a deeper understanding of the paper's content and improve their own work by addressing these points."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "Partially Grounded and UnderSpecific", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what the author should do. It points out a lack of clarity and asks a question about the expected outcome of a matrix multiplication.", "grounding_specificity_rationale": "The review point refers to the matrix resulting from the multiplication in equation (1), allowing the reader to infer the specific part being addressed. However, it does not explicitly state what is wrong with the matrix.", "verifiability_rationale": "The review point is a question, not a claim that requires verification.", "helpfulness_rationale": "The review point is relevant and points to a potential issue with the matrix multiplication. However, it does not provide a clear, actionable solution for the author."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests a concrete action for the authors: \"plot a figure about the decline in accuracy of a predictor over time in different settings to support their claim.\" This is a clear and actionable suggestion that directly addresses the identified problem of the lack of direct evidence for the motivation. The reviewer provides a specific method for demonstrating the issue.", "grounding_specificity_rationale": "The reviewer identifies the problem as \"a predictor suffers from the accuracy decline due to longterm and continuous usage\". While the *general* problem is implied, the reviewer doesn't explicitly point to a specific section, table, or unique aspect of the paper where this decline is occurring. The suggestion is general and doesn't pinpoint the exact location of the issue within the paper's content. The *specificity* of the suggestion is about the *concept* of accuracy decline, not a specific instance within the paper.", "verifiability_rationale": "The reviewer's comment is not a claim in itself. They are pointing out a gap in the paper's presentation and suggesting a way to address it, rather than making a definitive statement about the current state of the work. The focus is on *improvement*, not *assertion*. There is X that needs to be verified.", "helpfulness_rationale": "The reviewer's comment is 5 for the authors. They are providing a clear and actionable suggestion for improving the paper by demonstrating the accuracy decline. This empowers the authors to address the identified issue and strengthen their motivation section. It's a constructive suggestion rather than a critique of the current work, but rather a suggestion for improvement."}
{"actionability_label": "None", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "3", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "The review point raises several valid questions and concerns about the concept of 'excessive risk,' which could be helpful for the authors. The request for clarification on the definition and calculation of excessive risk is a fundamental need for understanding a key metric. The reviewer's observation about the potential for negative values, despite the context of the optimal solution, highlights a potential inconsistency or lack of clarity in the explanation. This raises a question about the practical interpretation and application of the metric. The reviewer's question about the comparability of excessive risk values across different groups is also important for understanding the scope and limitations of the metric as a fairness measure. Finally, the request for justification of why excessive risk is a good representation for fairness is crucial for accepting and applying the metric. While the review point doesn't directly pinpoint a specific weakness in the paper's methodology or results, it prompts the authors to critically examine the theoretical underpinnings and practical implications of the fairness metric they are using or developing."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the relationship between NGD and NGF ('NGD is a discretization of NGF') and concludes that initialization should play a role in the context of initial value problems ('Thus, initialization should play a role such as pretraining.'). This constitutes an explicit action. However, the reviewer does not provide specific details on *how* initialization should be pretrained, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to concepts like 'NGD,' 'NGF,' 'initial value problem (IVP),' and 'initialization.' While these terms are mentioned, the reviewer does not explicitly point to a specific section or element in the paper they are referring to. The connection is implied but not explicitly made. The reviewer also mentions 'pretraining' as a potential action, which is a general concept rather than a specific detail.", "verifiability_rationale": "The reviewer makes a claim about the relationship between NGD, NGF, discretization, IVP, and initialization. The reviewer then provides a reference to support their statement, indicating that the claim is supported by logical reasoning (the reference) and external references. The claim is also specific in identifying the relationship between these concepts.", "helpfulness_rationale": "The reviewer points out a potential area for clarification in the original paper by suggesting a connection to pretraining. While this is a valuable suggestion, the lack of specific details on *how* initialization should be pretrained might limit its immediate helpfulness for the authors. The reviewer identifies a specific point that needs further explanation, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point implicitly suggests an action related to named entity extraction by pointing out a lack of clarity. However, it doesn't explicitly state what needs to be done or how to achieve it. The suggestion regarding English proofreading is more explicit, stating that the author should proofread. While it doesn't specify *how* to proofread, it implies a concrete action. Therefore, the review point provides some actionable feedback but lacks the specificity needed for full actionability.", "grounding_specificity_rationale": "The review point mentions named entity extraction and English proofreading but doesn't specify *which* part of the paper or dataset it refers to, nor does it detail *what* is wrong with the named entity extraction or *where* the English proofreading should be conducted. This lack of specificity makes the grounding weak. The grounding is also not specific because it doesn't detail the issues with the named entity extraction or the specific aspects of the English proofreading to be done.", "verifiability_rationale": "The review point states that named entity extraction is unclear and suggests English proofreading. However, it doesn't provide any evidence or justification for why this is a problem or how it should be addressed. It also doesn't cite any external references or common knowledge to support these claims. The lack of verifiable evidence makes the claims 1.", "helpfulness_rationale": "The review point identifies a potential issue with the clarity of named entity extraction but doesn't offer a solution. While it suggests English proofreading, it doesn't explain *why* the current proofreading is insufficient or what specific issues it should address. Therefore, while the suggestion for proofreading is a form of actionable feedback, the overall review point lacks specific and constructive suggestions for improvement, making it 3 but not 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly points out the ambiguity in the phrase \"for every arm a\" and suggests a specific interpretation. They also propose a concrete alternative initialization strategy and quantify its improvement. Both points are direct and suggest a specific action to be taken.", "grounding_specificity_rationale": "The reviewer does not explicitly name the section or table where the definition of the optimistic parameter is. They rely on the reader understanding the context. However, they clearly specify what needs to be addressed (the dependence on the context or arm). This can be considered partially specific as the location is not pinpointed, but the issue is clear.", "verifiability_rationale": "The reviewer explains why the \"for every arm a\" wording is ambiguous and proposes a clarification. They also propose a specific alternative initialization and derive the improved condition. Both points are logically reasoned and supported by common knowledge or derivations.", "helpfulness_rationale": "The reviewer clearly identifies a lack of clarity and suggests a specific interpretation, which is directly actionable for the author. They also propose a concrete alternative initialization and quantify its improvement, providing a clear path for the author to implement a better strategy."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the inconsistency in the formatting of 'L' and 'E' in the immediate vicinity (lines 296 and 302). The reviewer clearly identifies the *difference* in formatting (italicized vs. nonitalicized) and suggests that this inconsistency should be addressed by defining 'L' and 'E'. This is an **explicit** action and this action is **concrete** as the reviewer directly suggests a solution.", "grounding_specificity_rationale": "The review point directly references specific line numbers (296 and 302) where the inconsistency is observed. This clearly grounds the comment to the specific part of the paper being discussed. Furthermore, the reviewer specifies the *type* of inconsistency (italicized vs. nonitalicized formatting). This adds further specificity to the grounding.", "verifiability_rationale": "The review point identifies a potential inconsistency in the formatting of variables within the paper. While the reviewer doesn't explicitly state *what* the inconsistency is, the *implication* is that the formatting should be consistent. This can be verified by examining the specified lines. The reviewer's suggestion to define 'L' and 'E' implies a lack of clarity or potential error in the current usage. Therefore, this is **3** as the *implication* of a problem exists, but the reviewer isn't providing a definitive solution or external reference within the review point itself.", "helpfulness_rationale": "The review point directly points out a potential issue (inconsistent formatting) and suggests a concrete solution (defining 'L' and 'E'). This is a clear and actionable feedback that directly addresses a potential point of confusion or error for the authors. The reviewer is taking a proactive stance in suggesting a resolution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment states 'More experiments are required.' This is a general suggestion and does not specify how to conduct these additional experiments or what specific improvements are needed. The authors are left with the task of interpreting the broad suggestion, making it 1.", "grounding_specificity_rationale": "The comment refers to the 'experimental section' generally and does not identify a specific part of the paper (e.g., a table, figure, or method description) that is weak. It also does not specify what is wrong with this section. Therefore, the comment lacks grounding specificity.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for more experiments, which could be considered a claim, but the point itself doesn't provide evidence to support this suggestion. Therefore, it has X.", "helpfulness_rationale": "The comment identifies a weakness in the experimental section ('it is a little weak') and suggests improvement ('More experiments are required'). While it lacks specific details on *how* to improve, it does point to a clear area for enhancement, making it 3. It is better than no feedback, but could be more specific to be 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests *comparing* with other models and techniques *beyond* LoRA and SPP. While the action of comparing is implied, the reviewer doesn't explicitly state *what* comparisons should be made. The suggestion is broad and lacks specific details on which models or techniques to consider. Therefore, while the action is somewhat implied, the lack of concrete suggestions makes it 3 but not fully actionable.", "grounding_specificity_rationale": "The review point doesn't explicitly mention a specific part of the paper that it is addressing. It's a general suggestion for improvement. The reviewer doesn't pinpoint a section, table, figure, or unique aspect of the paper that requires these comparisons. Therefore, the review point is 1 at all.", "verifiability_rationale": "The review point itself is a suggestion, not a claim that *something is wrong with the paper*. It proposes a *change* to the manuscript by suggesting more comparisons. There is no explicit claim being made, nor is there any evidence provided to support why these comparisons are necessary or beneficial. The review point is a suggestion, not a critique needing verification. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point suggests exploring a broader range of parameterefficient finetuning techniques beyond LoRA and SPP. This is a valid and constructive suggestion that could guide the authors in further research and potentially lead to improvements in their model. While it doesn't pinpoint specific issues in the current manuscript, it offers a clear direction for future exploration, which can be helpful for the authors. Therefore, the review point offers a 3 direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides four explicit suggestions for improvement, each targeting a specific line number. The first three suggestions are concrete, directly indicating the type of change needed (adding 'ing', changing 'of' to 'to', and changing 'to' to 'to'). The fourth suggestion, while slightly less specific ('Effect of the modelling mixed temporalmodality features.' > I'm not sure what this means, it's not grammatically correct'), still points to a specific area of the text that needs clarification. All suggestions are actionable, directly indicating what the author should do.", "grounding_specificity_rationale": "The reviewer explicitly states the line numbers (2, 56, 158, 265) where the issues are located. This indicates a high level of grounding specificity. The suggestions directly relate to the content on these lines, further emphasizing the grounding. For example, on line 2, the suggestion is to add 'ing' to 'compact', directly addressing the content. On line 56, the suggestion is to change 'of' to 'to', again directly referencing the line. Similarly, the suggestions for lines 158 and 265 are directly tied to the content on those lines.", "verifiability_rationale": "The review point identifies specific issues on particular lines, which can be considered claims that the content on those lines is incorrect or needs improvement. While the reasoning for these claims isn't extensively elaborated, the suggestions provided are practical fixes that are generally verifiable. For instance, the typo or grammatical error on line 2 is likely verifiable. The suggestion on line 265, while needing rephrasing, is a clear indication of an area that requires attention. Therefore, the claims are verifiable, but the justification for them is not deeply explored.", "helpfulness_rationale": "The review point provides clear and actionable suggestions for improvement. Each suggestion directly addresses a specific issue identified on a particular line. The suggestions are specific enough for the author to understand what needs to be changed. For example, the suggestion to 'add 'ing'' to 'compact' is a clear instruction. The suggestion to 'change 'of' to 'to'' is also very specific. While the suggestion on line 265 is slightly less specific ('Effect of the modelling mixed temporalmodality features.' > I'm not sure what this means, it's not grammatically correct'), it still points to a specific area of the text that needs clarification. The overall feedback is likely to be helpful for the author in improving their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states 'Mistakes in Eqs.' which clearly identifies a problem in the equations. The reviewer is asking for clarification on a specific issue, making the action clear. While the action is to clarify, the reviewer is pointing to a concrete issue within the equations.", "grounding_specificity_rationale": "The reviewer refers to 'W4 \u2013 Mistakes in Eqs.' which is a specific section and equation number within the paper. This clearly identifies the part of the paper being addressed. The specificity is high as the reviewer is asking a question directly related to the content of these equations.", "verifiability_rationale": "The comment is not a claim but rather a question asking for clarification. Therefore, it does not contain a claim that needs to be verified. The 'X' category applies here as the comment is a request for more information rather than a statement of fact or opinion.", "helpfulness_rationale": "The comment points out a potential error in the equations and asks a relevant question. While identifying a mistake is helpful, the comment itself does not actively guide the author on how to fix the issue or improve the work. It's more of a diagnostic question than a direct prescription for change."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment is vague and does not explicitly state what is wrong with the paper or how the model is an extension of GANs for static images. It lacks concrete details on the specific improvements needed.", "grounding_specificity_rationale": "The comment is 1 in a specific part of the paper. It makes a general assessment about the paper being somewhat incremental and a straightforward extension of GANs for static images without pinpointing a particular section, table, figure, or unique aspect.", "verifiability_rationale": "The comment is an opinion ('somewhat incremental') and does not present a claim that requires verification or support. There is no logical reasoning, common knowledge, or external references provided to back up this statement.", "helpfulness_rationale": "The comment is general and lacks specific, actionable feedback. It acknowledges the paper's limitations but does not provide concrete suggestions or identify specific areas for improvement that would help the authors enhance their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks a question: \"Does the proposed method perform better in pure combinational logic (without register)?\". This constitutes an explicit action, as the reviewer directly poses a question that the authors should address. Furthermore, the reviewer suggests a concrete action: \"it seems it may be much easier to model without state related registers, it would be interesting to see a comparison between sequential design and combinational design.\" This action is concrete in the sense that it proposes a specific comparison to be made. The reviewer also implies an action by suggesting a potential area for improvement: \"it would be interesting to see a comparison between sequential design and combinational design.\"", "grounding_specificity_rationale": "The review point explicitly mentions \"the proposed method\" and \"pure combinational logic (without register)\". This clearly grounds the comment to a specific part of the paper being discussed. The reviewer also uses phrases like \"it would be interesting to see a comparison between sequential design and combinational design,\" which, while not a direct statement of a problem, implies a focus on a specific aspect of the proposed method (modeling complexity). The grounding is strong because the specific elements are mentioned. The reviewer also uses the phrase \"without register,\" which further pinpoints the scope.", "verifiability_rationale": "The review point contains a claim: \"it would be interesting to see a comparison between sequential design and combinational design.\" This claim suggests a direction for future work or further analysis. However, the verifiability of this claim is somewhat limited. While the suggestion points towards a valuable area of exploration, it doesn't provide a clear methodology or specific examples for how this comparison should be conducted. The claim is presented as a suggestion rather than a definitive statement requiring immediate verification. There are no explicit references to external works or logical reasoning provided to support this claim.", "helpfulness_rationale": "The review point raises a valid question about the impact of register usage on modeling difficulty and suggests a relevant comparison. It provides a clear direction for further investigation and offers a constructive suggestion for future work. While it doesn't provide a definitive answer, it points towards a valuable area of exploration and offers a constructive suggestion for future work. The reviewer's comment is actionable and directly relates to the design aspects of the proposed method. It encourages the authors to consider the tradeoffs between combinational and sequential logic in their design choices."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This is a direct request for information that, if present, would be a clear action for the authors to take. The request is not ambiguous and directly targets a specific aspect of the baseline's performance.", "grounding_specificity_rationale": "The reviewer's request is highly specific, directly asking for the 'topic switch percent metric' for the 'LDA+LSTM' baseline. This demonstrates a clear understanding of the model and the specific metric relevant to evaluating its performance. The comment directly identifies the relevant part of the paper and the specific issue.", "verifiability_rationale": "The reviewer is making a claim about the performance of the LDA+LSTM baseline. This claim can be verified by checking the experimental results section of the paper, where the topic switch percent metric is likely reported. While the paper isn't provided, the request itself is a claim that can be supported if the information exists in the paper.", "helpfulness_rationale": "The reviewer's request is highly relevant to the authors. If the paper includes the experimental results and reports the topic switch percent metric for the LDA+LSTM baseline, this information would directly help the authors understand the performance of their proposed method compared to this baseline. It provides a concrete piece of information for comparison and analysis."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the motivation is 'unclear' and that the quality of annotations cannot be guaranteed due to 'uncertainty'. While the reviewer identifies a potential issue, they do not offer any suggestions or guidance on how to address this lack of clarity or how to improve the annotation process. The reviewer essentially points out a problem without providing any actionable feedback.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'when an object is totally occluded' as the specific scenario and then lists 'position, size and motion' as the attributes being difficult to predict. This provides a clear grounding of the problem and specifies the aspects of the object that are hard to determine. The reviewer also mentions 'uncertainty' in the annotations, further grounding the issue.", "verifiability_rationale": "The reviewer poses questions about the motivation and the handling of uncertainty, indicating a lack of clear justification for the task and the predictions. While the reviewer identifies a potential issue (uncertainty), they do not provide any external references or examples to support their claims. The reasoning is present but lacks external validation.", "helpfulness_rationale": "The reviewer's comments are relevant to the task of amodal tracking, particularly regarding the motivation and the challenges of uncertainty. However, the reviewer does not offer any concrete suggestions or improvements based on their observations. The feedback is pertinent but lacks direct actionable recommendations, making it 3 in identifying areas for improvement rather than directly suggesting solutions."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests including experiments with GPT3.5, which is a direct action. However, the reviewer does not specify how to implement this action, such as what data to use, what metrics to evaluate, or what analysis to perform. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer mentions GPT4 and GPT3.5, but does not specify which part of their work or which experiment they are referring to. The suggestion is general and does not target a specific aspect of their research or methodology.", "verifiability_rationale": "The reviewer does not make a claim about the quality, efficiency, or costeffectiveness of GPT4. They suggest an alternative but do not present it as a definitive statement that requires justification or evidence. The suggestion is presented as a helpful idea, not a claim to be verified.", "helpfulness_rationale": "The reviewer offers a relevant suggestion by proposing an alternative model. However, the suggestion is highlevel and lacks specific guidance on how to proceed. The reviewer does not provide any steps on how to compare GPT4 and GPT3.5, what metrics to use, or what analysis to perform. While the suggestion is relevant, it lacks concrete steps, making it less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a problem with the presentation of results in Table 4, specifically mentioning the missing bold numbers for baselines. They also point out that the best WMT17WIKIT result is not in the baselines according to their paper. This constitutes an explicit action to identify and correct the issue. The action is also concrete as the reviewer clearly states the location of the problem (Table 4) and the nature of the missing information (bold numbers for baselines).", "grounding_specificity_rationale": "The reviewer specifically identifies 'Table 4' as the location of the issue. They further pinpoint the problem to 'bold numbers for the baselines of previous work' and specifically mention 'WMT17WIKT'. This demonstrates a high level of grounding as the reviewer accurately identifies the section, table, and specific baseline being addressed. They also clearly specify what is missing \u2013 the absence of bold numbers for these baselines.", "verifiability_rationale": "The reviewer makes a claim that 'the best result in the baselines for WMT17WIKT is actually in the baselines'. This is a claim that can be verified by examining the results presented in the paper. While the reviewer doesn't explicitly state the numbers, the claim itself is verifiable by comparing the presented results with the information in their paper. The claim is supported by the potential for external verification (reading their paper).", "helpfulness_rationale": "The reviewer's comment is highly constructive and directly addresses a specific issue in the presentation of results. They identify a factual error (the location of the best baseline result) and suggest a concrete improvement (adding bold numbers). This type of feedback is 5 for the authors as it points out a specific, actionable step they can take to improve the clarity and accuracy of their results section."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment 'unreliable neighbors' is implicit, as it doesn't explicitly state what constitutes an unreliable neighbor. It's also vague, as it doesn't provide guidance on how to identify or address them. While it points to a potential area for improvement, the reviewer doesn't offer concrete steps or criteria.", "grounding_specificity_rationale": "The comment 'unreliable neighbors' is 1 at all. It doesn't specify a particular part of the paper or the nature of the unreliability. The reference is broad and lacks specificity.", "verifiability_rationale": "The comment itself doesn't contain a clear claim. While it implies a need for clarification regarding 'unreliable neighbors,' there's no logical reasoning, common knowledge, or external references provided to support this implied need. The comment is more of a request for information than a statement requiring verification.", "helpfulness_rationale": "The comment is 3 in that it identifies a potential area for improvement (understanding 'unreliable neighbors'). However, it lacks concrete guidance and specific examples, making it vague and less directly actionable for the author. It's more of a request for clarification than a direct suggestion of improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states the claim is 'insufficiently backedup,' which implies a lack of explicit information. While the reviewer doesn't pinpoint a specific missing piece of information, the suggestion to 'include more information' indicates a clear action the paper should take. Therefore, it's 3 as the paper should explicitly state the missing information or provide a clear path for the authors to find it. However, the vagueness of the suggestion makes it not fully actionable.", "grounding_specificity_rationale": "The reviewer explicitly states 'the main paper does not even mention the TD3GA algorithm.' This clearly indicates a lack of explicit identification of the relevant part of the paper. While they mention the 'study of combining DQD with TD3,' they don't explicitly name TD3 or TD3GA as the algorithms being discussed in the main paper. This makes the grounding weak. The reviewer also mentions 'the synergy between DQD and PPO,' which, if present, would be more specific than just mentioning 'TD3GA'. However, the core issue is the lack of explicit mention of the algorithms, making it weakly grounded. The specificity is also lacking as the paper doesn't clearly identify the specific algorithms being discussed.", "verifiability_rationale": "The reviewer states the claim about the synergy between DQD and PPO is 'insufficiently backedup.' This directly points to a lack of justification or evidence for the claim. The paper does not provide any logical reasoning, common knowledge, or external references to support this claim. Therefore, it is 1.", "helpfulness_rationale": "The reviewer concludes by saying the claim about the synergies 'should be central.' This implies the lack of information is a significant impediment to understanding and improving the work. The paper should provide more details about the algorithms and their interactions to be helpful for the authors. Therefore, it is 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about why a surprising result occurred, which does not directly identify an action or improvement to be made. The comment is about understanding the outcome, not suggesting a change.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Sections 6.1 and 6.2', providing strong evidence of grounding. However, the comment focuses on the *reason* for the result being surprising, which is not a specific detail about the content within those sections.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are asking a question about the results, not making a statement that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer's question about the surprising result is valuable for the authors' understanding and potentially for improving the method. While it doesn't directly provide a solution, it seeks clarification on a key aspect of the findings, which can be helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the confusion caused by the word 'confident' and asks for clarification. This indicates a clear action that the authors should take: clarifying the meaning of 'confident'. The action is also concrete, as the reviewer identifies the specific word causing the issue. Therefore, the review point provides a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions the word 'confident' in the text, indicating a clear identification of the specific part of the paper being addressed. Furthermore, the reviewer directly states their desire to understand the meaning of this word, providing a clear specification of what needs to be addressed. This makes the grounding both explicit and specific.", "verifiability_rationale": "The review point is a statement of opinion about the clarity of the text, not a claim that something is wrong or needs verification. While it encourages clarification, it doesn't present a statement that requires logical reasoning, common knowledge, or external references to be considered valid. Therefore, it doesn't fit into the 'verifiable' categories. The 'helpfulness' of this point lies in its prompting for clarification, which can lead to a more informative explanation.", "helpfulness_rationale": "The reviewer directly points out a lack of clarity and asks for clarification. This is a very direct and helpful suggestion for the authors. While it doesn't provide a specific solution, it clearly identifies an area where improvement is needed. The request for clarification is a constructive step towards addressing the identified issue."}
{"actionability_label": "High", "grounding_specificity_label": "Partially Grounded", "verifiability_label": "High", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states a concern about the practicality of using prior knowledge, which can be directly acted upon by the authors. They suggest considering alternative approaches or acknowledging the limitations of their method. This constitutes an explicit action with concrete details.", "grounding_specificity_rationale": "The reviewer mentions 'prior knowledge about causal relationships' as the specific area of concern. While they don't pinpoint the exact section, this provides a clear indication of what needs to be addressed. The grounding is strong in identifying the general area, but it could be more specific.", "verifiability_rationale": "The reviewer provides reasons for their concern, such as 'prior knowledge is not always available' and 'might be inaccurate to a specific subpopulation.' These are logical explanations supported by common knowledge, making the claim verifiable.", "helpfulness_rationale": "The reviewer raises a valid and actionable concern about the limitations of relying on prior knowledge. This provides the authors with a clear direction for improvement, such as exploring datadriven methods or acknowledging the limitations of their approach. The suggestion is specific and helpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review points out a potential issue with the novelty of the work but does not explicitly state how the authors should address this issue or the expected behavior of the confidence intervals. The suggestions are indirect and lack concrete steps.", "grounding_specificity_rationale": "The reviewer's comment is general and does not specify which part of the paper or unique aspect of the work is being discussed. The issue is framed broadly without pinpointing a specific element.", "verifiability_rationale": "The reviewer makes a claim about the expected behavior of confidence intervals with finetuning. While this claim is generally verifiable based on statistical principles, it lacks specific examples or references to external work.", "helpfulness_rationale": "The review raises a valid concern about the novelty of the work and provides a plausible explanation. However, it does not offer specific, actionable steps for the authors to take, making it less directly helpful in terms of providing immediate solutions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the desired action: 'It would make for a stronger case if the paper reports the numbers observed when the label noise experiment is performed on imagenet with 1000 classes as well'. The action is also concrete, as it clearly identifies the specific experiment and its parameters (label noise, ImageNet, 1000 classes).", "grounding_specificity_rationale": "The comment explicitly mentions 'label noise experiment', 'ImageNet', and '1000 classes', clearly identifying the specific aspect of the paper being addressed. While it doesn't explicitly state the *purpose* of this experiment (e.g., to strengthen the case), it clearly pinpoints the section or part being referred to.", "verifiability_rationale": "The review point itself does not contain a claim in the sense of a statement requiring justification or proof. It's a suggestion for an additional experiment. However, the *implied value* is that reporting these results would strengthen the paper's case, which could be considered a form of implicit justification. Therefore, it leans towards '1' as the review point itself isn't a claim, but it's grounded in the suggestion.", "helpfulness_rationale": "The review point directly suggests a concrete and actionable improvement: including results from a label noise experiment on ImageNet with 1000 classes. This is a clear and valuable suggestion for strengthening the paper's empirical evaluation. While it doesn't provide a detailed methodology, it's a specific direction for future work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests an alternative metric (number of weight updates) to the existing one (number of network updates) and provides a reason for this suggestion (parallel processing). It also directly asks the authors to consider this change and provides a request for additional feedback to improve the paper. This constitutes an explicit action and concrete details on how to implement it, making it 5.", "grounding_specificity_rationale": "The review point explicitly mentions the 'number of weight updates' as the alternative metric and asks the authors to consider this change. It also requests 'additional feedback with the aim to improve the paper', which clearly identifies the specific aspect being addressed and the desired outcome. This indicates strong grounding specificity as the authors can easily identify the referenced part and the issue.", "verifiability_rationale": "The review point presents a claim that 'number of weight updates is better' and provides a reason based on 'parallel processing'. While the reasoning is conceptual, it is a clear statement that could be supported by further explanation or examples if needed. Therefore, it is 3 as the claim is stated and a justification is provided, though it might benefit from more concrete evidence.", "helpfulness_rationale": "The review point directly addresses a methodological choice and asks for improvement. It provides a reason for the proposed change and requests additional feedback, which is highly beneficial for the authors in understanding and potentially improving their work. The request for improvement itself is a strong indicator of helpfulness."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point is a question about the objective of adversarial prediction accuracy, rather than a direct instruction on how to improve the draft. While it implies scenarios where this accuracy is important, it doesn't explicitly state what needs to be done or how to achieve it. Therefore, it lacks explicit and concrete actionable information.", "grounding_specificity_rationale": "The review point is about the objective of a specific type of accuracy, not a particular part of the paper or experiment. It doesn't identify a specific section, table, figure, or unique element of the paper. The question is about the *purpose* of the accuracy, not the *content* of a specific part. Therefore, it doesn't ground the discussion in a specific aspect of the work.", "verifiability_rationale": "The review point is a question about the objective of a specific type of accuracy, not a claim or statement that needs verification. It doesn't present a statement that requires logical reasoning, common knowledge, or external references to be considered valid. It's a question seeking information, not a critique or assertion. Therefore, it doesn't contain a claim that needs to be supported.", "helpfulness_rationale": "The review point is a question seeking information about the objective of adversarial prediction accuracy. While relevant to understanding a specific evaluation metric, it doesn't provide actionable feedback or suggestions on how to improve the draft. It doesn't identify weaknesses or propose solutions. Therefore, it doesn't offer any helpful insights or guidance for the author."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement implies a potential issue with the contrastive learning framework's similarity to SimCLR, suggesting the need for further investigation. However, it doesn't explicitly state what needs to be done next, making it 3 but lacking explicitness and concreteness.", "grounding_specificity_rationale": "The statement explicitly mentions 'SimCLR', a specific method, clearly identifying the area of comparison. This demonstrates strong grounding as the specific method is named.", "verifiability_rationale": "The statement is a factual claim about the relationship between the contrastive learning framework and SimCLR. It doesn't present a suggestion for change or improvement, so it doesn't fall under the 'verifiability' aspect which focuses on claims requiring justification.", "helpfulness_rationale": "The statement raises a potential concern about the novelty of the contrastive learning framework by pointing out its similarity to SimCLR. However, it doesn't offer any concrete steps or suggestions for the author to take to address this concern, making it unhelpful on its own."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the 'lack of comparative experiments' in Section 4.3 and suggests 'including comparative experiments with these specific block types'. This is an explicit statement that implies an action: 'The authors should have included comparative experiments with these specific block types in Section 4.3'. Therefore, it is actionable. The reviewer also specifies the *type* of blocks, making it concrete.", "grounding_specificity_rationale": "The review point explicitly refers to 'Section 4.3' and specifically mentions 'bottleneck in ResNet' and 'linear bottleneck in MobileNetV2'. This allows the authors to directly identify the relevant part of the paper and the specific issue. Therefore, it is 5.", "verifiability_rationale": "The review point contains a claim, which is the suggestion 'In Section 4.3, there lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2, which could have showcased the unique advantages or potential shortcomings of the proposed method in a broader context'. While the reviewer doesn't provide direct evidence for *this specific claim*, they are offering a logical suggestion for improvement. They are implying that including these comparisons would provide a broader context. Therefore, it is verifiable but lacks direct supporting evidence, making it partially verifiable.", "helpfulness_rationale": "The review point directly identifies a weakness in the experimental section (lack of comparative experiments with specific block types) and suggests a concrete improvement (including these comparisons). This actionable feedback is likely to be very useful for the authors to understand the limitations of their method and how it compares to other architectures. The suggestion is specific and targets a clear area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point suggests improving the submission by adding more attention to related work. However, it does not specify how to achieve this. The suggestion is general and lacks concrete steps for the authors to follow.", "grounding_specificity_rationale": "The review point mentions 'related work (such as 1,2,3)'. While it identifies the area of improvement, it does not specify which particular part of the submission needs attention. The examples provided are placeholders and do not ground the comment to a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion to improve the submission by adding more related work, but it does not make a declarative statement that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The review point suggests adding more related work to the submission. While this is generally a helpful suggestion for providing context and improving completeness, it is vague and does not offer specific guidance on how to achieve this. The authors are left with a general direction but no concrete steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a *lack* of comparison against text GANs, which is an implicit action. They suggest comparing, but don't explicitly state the steps. The reviewer also mentions SeqGAN but doesn't detail how to test it, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'text GANs' and 'SeqGAN,' showing some grounding. However, they don't specify *which* section, table, or unique aspect of the paper they are referring to. The issue is presented generally.", "verifiability_rationale": "The reviewer makes claims about the absence of comparison and the state of SeqGAN testing. They state these facts without providing specific examples or references to external works. The reasoning is present but lacks depth and justification.", "helpfulness_rationale": "The reviewer identifies a missing element (comparison against GANs) which could hinder the assessment of the paper. They suggest adding this comparison, which is a clear direction for improvement. While the suggestion is present, it lacks specific details on how to perform the comparison."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review suggests the paper should have focused more on the algorithmic aspects, but it doesn't explicitly state how the authors should modify their work or provide concrete steps. The suggestion is more of a recommendation for future work rather than actionable feedback for the current draft.", "grounding_specificity_rationale": "The reviewer mentions 'the algorithmic aspects of the solution' and 'the Blackwell winner concept' but doesn't explicitly identify a specific section, table, figure, or unique element of the paper being addressed. The reference is more general and doesn't pinpoint a concrete part of the work.", "verifiability_rationale": "The reviewer states 'I believe the paper should have also focused on the algorithmic aspects of the solution' and 'the novelty of the paper seems limited' without providing any evidence or justification for these claims. These are statements of opinion without supporting reasoning or references.", "helpfulness_rationale": "The review offers a suggestion for improvement ('I believe the paper should have also focused...') but lacks specific, actionable steps on how to make the solution algorithmic or how to demonstrate its algorithmic aspects. It doesn't provide concrete guidance on how the authors can address the perceived lack of novelty."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the suggestion to split the tables and move specific columns. This action is directly identified and actionable. The reviewer also provides details on *how* to implement the suggestion by specifying which columns to move and where to place them. This makes the action concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 4' and 'Table 5' and further specifies the columns to be moved ('8 SFII columns' and '8 SPDI columns'). This allows the authors to precisely identify the referenced parts and the specific issues being addressed. The information is provided in a literal manner, without needing to infer the relevance of the tables or columns.", "verifiability_rationale": "The reviewer presents a suggestion about improving the readability of the tables. This can be considered a claim that this change will be beneficial. However, the reviewer does not provide any explicit justification or evidence to support this claim within the review point itself. The suggestion is presented as a recommendation rather than a proven statement.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion aimed at improving the clarity and accessibility of the presented data. This is a direct and actionable feedback that is likely to be helpful for the authors. The suggestion is specific about *which* tables and *which* columns to move, making it 5 and specific to the identified issue. The potential benefit of improved readability is a reasonable expectation for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly names the elements of Figure 5 that are causing confusion ('valid' and 'orig') and encourages the authors to understand their difference. This makes the action clear: understand the distinction between these two terms.", "grounding_specificity_rationale": "The comment directly refers to 'Fig. 5', which is a specific part of the paper. It also asks for the difference between 'valid' and 'orig' within that figure, which are specific elements. This strong grounding helps the authors identify the relevant section and the specific issue.", "verifiability_rationale": "The comment encourages the authors to infer the difference between 'valid' and 'orig' based on the context of Figure 5. While it doesn't explicitly state the definitions or provide examples, it implies a need for understanding these terms within the figure's context. The reasoning is based on standard practices or the surrounding text, making it somewhat inferable.", "helpfulness_rationale": "The comment is directly helpful because it points out a potential area of confusion for the authors regarding Figure 5 and encourages them to understand the difference between 'valid' and 'orig'. It's a clear indication that something is unclear and asks for clarification."}
{"actionability_label": "5", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper 'could be improved' by making comparisons more systematic and suggests 'systematically compare the best performance of each method'. This provides a clear direction for the authors to follow, indicating a direct action to be taken. The reviewer identifies the area for improvement (comparison of methods) and the type of action (systematic performance analysis).", "grounding_specificity_rationale": "The reviewer mentions 'the most closely related work of Zemel et al. (2013)' and refers to 'the present paper'. This indicates an attempt to ground the comment in existing work. However, the specific section, table, figure, or unique aspect of the paper being addressed is not explicitly identified. The reviewer mentions the *area* of improvement (originality) and the *method* of improvement (systematic comparison), but not the precise location within the paper.", "verifiability_rationale": "The reviewer makes a claim that 'the most closely related work of Zemel et al. (2013) is referenced, the present paper explains how it is different, and gives comparisons in simulations. It could be improved by making these comparisons more systematic with respect to the tuning of each methodi.e. compare the best performance of each.' This claim is supported by the suggestion to 'systematically compare the best performance of each method'. The reviewer provides a logical reasoning for why this improvement could be made, suggesting a concrete action to be taken.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement. They identify a valid area for enhancement (systematic comparison of methods) and propose a concrete action (comparing the best performance). This directly addresses a potential weakness in the paper and offers a clear path for the authors to follow to improve their work. The suggestion is specific enough to be helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The comment implicitly suggests an action: 'Compare your method to methods mentioned in the computer vision setting.' While it doesn't explicitly state 'do this,' the suggestion implies a concrete next step for the authors to take. The reviewer also provides a reason for this suggestion ('...that these are not always applicable...'), which further clarifies the intended action.", "grounding_specificity_rationale": "The comment explicitly states the part of the paper being addressed: 'computer vision setting.' This provides clear grounding. The comment also specifies what needs to be done: 'a comparison to methods mentioned in the computer vision setting.' This provides clear specificity regarding the comparison.", "verifiability_rationale": "The comment contains a claim: '...that these are not always applicable and typically require a supervised setup, but some of them can probably be adapted to language tasks relatively easily.' This claim is supported by the reviewer's understanding of the limitations and potential of CV methods. The reasoning is logical, explaining the context and the potential for adaptation.", "helpfulness_rationale": "The comment is helpful because it points out a potential improvement for the authors: comparing their method to relevant methods from a different field (computer vision). This suggests a more comprehensive related work section and potentially highlights a gap in their awareness of relevant techniques. While it doesn't provide a direct solution, it guides the authors towards a valuable direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The comment identifies the importance of time complexity estimation for scalability but does not explicitly state how the authors should go about estimating it or implementing this suggestion. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The comment refers to 'the learning algorithm' generally, without specifying a particular part of the paper or a unique element. It does not clearly identify which aspect of the algorithm or the paper needs improvement related to time complexity. The grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The comment presents a suggestion (estimating time complexity) but lacks a clear justification or reasoning for why this is important for scalability. It does not provide external references or examples to support this claim. The claim is present but not wellsupported.", "helpfulness_rationale": "The comment identifies a missing element (time complexity estimation) and suggests its importance for scalability. However, it lacks explicit instructions, specific references to parts of the paper, and a clear justification for the suggestion. The feedback is present but lacks the necessary details to be fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the *type* of connection they are suggesting (connection to universal kernels and their shattering ability). This is an explicit action. However, the *specific* nature of the connection and how this relates to the *specific work* is not clearly defined. The reviewer is prompting for more information, which is a form of action, but it's not a concrete action on how to improve the draft itself.", "grounding_specificity_rationale": "The reviewer provides the specific book and chapter (Steinwart and Christmann, Chapter 4) as context for their suggestion. This is strong grounding. The reviewer also specifies the *property* of universal kernels they are referring to (ability to shatter any finite dataset). This is high specificity as they are pointing to a specific theoretical concept.", "verifiability_rationale": "The reviewer is making a claim about a potential connection between their work and universal kernels. They provide a *specific property* of universal kernels as supporting evidence. This claim is 3 because the specific property of universal kernels is mentioned. However, the *relevance* of this connection to the *specific work* being reviewed is not explicitly verified or supported within the review point itself.", "helpfulness_rationale": "The reviewer is asking a question about a potential connection. While this can be helpful for guiding the authors' thinking and suggesting potential research directions, it is not a direct criticism or suggestion for improvement within the current draft. It's more of a *prompt* or *direction* than a *criticism* or *suggestion*."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X (X)", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a problem ('terse and not very clearly explained') but does not explicitly state what the author should do to address it. While the reviewer implies the author should expand the discussion, this is an inference rather than a direct action. The action of making the discussion more detailed and clear is not explicitly stated.", "grounding_specificity_rationale": "The review point explicitly mentions 'equation (10)', which grounds the comment to a specific part of the paper. However, it does not specify *what* is wrong with the discussion around that equation. The grounding is present, but the specificity is lacking.", "verifiability_rationale": "The review point states a critique ('terse and not very clearly explained') without making a claim that requires verification. It's a statement of observation, not a proposition that needs to be proven. There is X being made.", "helpfulness_rationale": "The review point identifies a valid area for improvement (the discussion around equation 10) by pointing out its lack of detail and clarity. This is helpful in that it highlights a problem that the author might be struggling with. However, it does not provide specific, actionable guidance on *how* the author should improve the discussion. The reviewer doesn't tell the author what to add, how to rephrase, or what specific aspects to focus on."}
