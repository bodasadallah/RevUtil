{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their question: 'any reason you did not consider the and operator or elementwise max? They seem to correspond to the ideas of union and intersection from the or operator and elementwise min, and it wasn\u2019t clear to me why the ones you chose were better options.' This is a direct request for clarification and justification, making it explicit. The reviewer also provides specific examples of alternative methods ('and operator' and 'elementwise max'), making the action concrete.", "grounding_specificity_rationale": "The reviewer clearly identifies the section of the paper where the question relates ('results' section and the calculation of the overall score). They also specify the aspect being questioned ('any reason you did not consider...'). This explicit identification of the paper section and the specific aspect makes the grounding very strong. The reviewer is not just making a general comment but directly pointing to a specific part of the methodology.", "verifiability_rationale": "The reviewer poses a question about the methodology used for calculating the overall score. This constitutes a claim that the chosen methods ('or operator' and 'elementwise min') are the appropriate way to calculate the score. However, the reviewer does not provide any evidence, reasoning, or references to support why these methods were chosen over the alternatives ('and operator' and 'elementwise max'). The justification is missing, making the claim 1.", "helpfulness_rationale": "The reviewer's request for justification is directly aimed at helping the authors understand the reasoning behind the chosen methodology. While the review itself doesn't directly suggest improvements to the score calculation, it seeks a clear explanation of *why* the current method was selected. This is helpful in the sense that it encourages the authors to articulate their decisionmaking process and potentially provide insights that could be valuable for the authors. However, it doesn't directly improve the authors' ability to perform the calculation itself."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states the comment is 'implicit' and 'lacks detail on how to apply it'. This means the authors would not know exactly what needs to be done after reading the comment, making it 1.", "grounding_specificity_rationale": "The reviewer points out the ambiguity in the description of the data selection process. While the general source is mentioned, the specific subset and the criteria for selection are not clearly defined. The reviewer's suggestion to mention Li et al. earlier and provide a clearer description of the data selection process highlights this lack of precision. The comment does not specify what needs to be addressed in this part, making it 1 and not specific.", "verifiability_rationale": "The reviewer argues that the claim, 'the data selected is a subset of Li et al. (2019a)\u2019s dataset,' is not wellsupported by explicit reasoning, common knowledge, or external references. While the *fact* might be true, the *explanation* of why it's a subset and the *justification* for this approach are lacking. The reviewer's suggestion to explicitly mention Li et al. earlier and provide a clearer description of the data selection process does not inherently make the claim verifiable. The reasoning and commonsense arguments are missing, making it 1.", "helpfulness_rationale": "The reviewer's concerns about the grounding specificity and verifiability of the comment directly impact its helpfulness. Since the authors cannot easily understand the feedback and the reasoning behind it is unclear, the comment is unlikely to provide meaningful guidance. The lack of clarity makes it difficult for the authors to act on the suggestion, reducing its helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "1", "actionability_rationale": "The reviewer asks a question about the average duration in Table 1, implying a lack of clarity or purpose. While they don't explicitly state an action, the question itself is a form of actionable feedback, prompting the authors to understand the table better. The lack of a direct instruction makes it borderline.", "grounding_specificity_rationale": "The reviewer asks about the purpose of the average duration in Table 1. They can infer that it's related to the table, but they cannot precisely identify the specific cell or column containing the duration. The reviewer can also specify the information they are looking for (purpose and whether it includes waiting time), making it somewhat specific but not fully grounded.", "verifiability_rationale": "The reviewer makes a claim that there is 'no supporting explanation about it' regarding the average duration in Table 1. They provide a reason for this claim ('There is no supporting explanation about it') and ask a specific question ('Does it include time spent by the user waiting for the model to generate a response?') to try and verify it. This provides some justification, making it 3.", "helpfulness_rationale": "The reviewer's point is about clarifying the information in Table 1. While this can be helpful for the authors to understand the data better, it doesn't directly identify a weakness in the paper or provide a suggestion for improvement. It's more of a request for information than a critique that prompts action."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point asks a question about interpreting results in Table 3 and makes comparative statements about different models. While it implies an action (interpreting the results), it doesn't explicitly state what needs to be done or how to proceed with the interpretation. The action is implicit rather than explicit.", "grounding_specificity_rationale": "The review point refers to 'Table 3' as the source of information, which grounds the discussion. However, it doesn't specify which rows or columns of the table are relevant to the comparison being made. The grounding is weak because the reviewer doesn't point to the exact data points being referenced.", "verifiability_rationale": "The review point makes a claim about the interpretation of the results in Table 3. However, it doesn't provide any justification or explanation for its interpretation. It simply states the observations (comparability, overlap) without explaining what these observations mean in a statistical or practical context. The claim is made without sufficient support.", "helpfulness_rationale": "The review point asks a question about interpreting results in Table 3 and makes comparative statements about different models. While it identifies a weakness (the lack of clear interpretation of statistical similarities), it doesn't provide any guidance or explanation on how to interpret the overlapping confidence intervals or what the implications are for model selection. The reviewer identifies a problem but doesn't offer a solution or actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer identifies the issue of inconsistent spacing between 'accuracy' and 'standard deviation' in Tables 2 and 3. While the reviewer points out the *problem*, the review point itself doesn't explicitly * tell the authors how to fix it. The authors would still need to determine if the spacing is indeed incorrect and how to correct it. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 2 and Table 3' as the location of the issue. This clearly identifies the specific part of the paper being addressed, demonstrating strong grounding. The reference is explicit and literal.", "verifiability_rationale": "The reviewer observes an inconsistency in the formatting of tables. This can be considered a deduction or an observation about the current state. The suggestion to 'remove the space' is a potential action, but the review point itself doesn't provide strong external references or logical reasoning to *prove* the space exists. The issue is identified, but the justification for the claim is weak.", "helpfulness_rationale": "The reviewer points out a formatting issue in the tables. While this is a valid observation, it doesn't directly contribute to improving the core content, methodology, or analysis of the paper. The suggestion to 'remove the space' is a minor improvement that doesn't fundamentally change the research findings. The helpfulness is limited as it doesn't directly address the authors' primary goals."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The phrase 'antecedent missing' is explicit in indicating a problem with the phrase 'both tasks'. However, it does not specify what is missing, leaving the author to infer the nature of the issue. This makes the action implicit.", "grounding_specificity_rationale": "The comment explicitly refers to 'both tasks', which is a specific section. However, it does not specify what is wrong within that section, making the grounding underspecific.", "verifiability_rationale": "The comment implies a problem with referencing but does not provide specific evidence or justification for this claim. It is a deduction rather than a direct statement. Therefore, the claim is undersupported.", "helpfulness_rationale": "The comment identifies a potential issue with referencing, which is generally helpful for clarity and professionalism. However, it does not specify what is missing or how to fix it, making it only partially helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'The explanations for features in Section 3.2 are somewhat intertwined and thus confusing.' They then provide a clear and actionable suggestion: 'The section would be more coherently organized with more separate paragraphs dedicated to each of lexical features and sentencelevel features, by:'. This indicates a direct identification of an issue and a specific, stepbystep solution. The reviewer clearly understands the nature of the confusion and proposes a concrete improvement.", "grounding_specificity_rationale": "The reviewer refers to 'Section 3.2' and specifically mentions 'lexical features' and 'sentencelevel features' when describing the problem. They also suggest a solution that targets these specific aspects: 'by:'. This demonstrates a strong understanding of the section and the specific elements within it that are causing confusion. The reviewer not only identifies the area of confusion but also specifies the nature of the confusion and the targeted solution.", "verifiability_rationale": "This review point does not contain a claim that requires verification. It is a suggestion for improvement in the organization of a section. Therefore, it does not fit the defined categories for verifiability.", "helpfulness_rationale": "This review point directly addresses a potential reader confusion regarding the organization of explanations in Section 3.2. By suggesting a clear separation of lexical and sentencelevel features, the reviewer is providing a concrete and actionable improvement that could significantly enhance the reader's understanding. This type of suggestion is highly valuable and directly addresses a potential weakness in the presentation of the work."}
{"actionability_label": "partially actionable", "grounding_specificity_label": "partially grounded", "verifiability_label": "partially verifiable", "helpfulness_label": "partially helpful", "actionability_rationale": "The review point contains two parts. The first part, 'The abstract is written well and invokes intriguing early', is a statement of opinion and does not provide an explicit action or suggestion for improvement. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', suggests an action to improve the abstract by addressing the inconsistency in evaluation. Therefore, the review point has one actionable part and one nonactionable part.", "grounding_specificity_rationale": "The first part of the review point, 'The abstract is written well and invokes intriguing early', is a general comment about the abstract and does not specify which part of the paper it is referring to. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', refers to a specific issue related to the evaluation process but does not explicitly point to a specific section, table, or figure in the paper. Therefore, the review point is not fully grounded but has some grounding.", "verifiability_rationale": "The first part of the review point, 'The abstract is written well and invokes intriguing early', is a subjective statement and does not contain a claim that can be verified. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', is a claim that can be verified by citing examples of the inconsistency between gold and human evaluation. Therefore, the review point contains one claim that is verifiable.", "helpfulness_rationale": "The first part of the review point, 'The abstract is written well and invokes intriguing early', is a positive comment and does not provide any actionable feedback for the author. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', directly suggests an improvement to the abstract by addressing the identified issue. Therefore, the review point has one unhelpful part and one helpful part."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states actions or suggestions. For the first part, it directly instructs the authors to 'discuss the results' for a specific task and 'include results for model (B)'. For the second part, it directly asks a question about why 'objects here' are not mentioned in the context of 'latent in verbs'. These are explicit statements that guide the authors on what to do or why something is missing.", "grounding_specificity_rationale": "The review point explicitly refers to 'the task of inferring knowledge on objects' and 'model (B)'. This clearly identifies the specific aspect of the work being referred to. Similarly, the second part refers to 'objects here' in the context of 'latent in verbs', which also grounds the criticism to a specific type of information within that task. The reviewer is not just talking about the task in general, but about specific elements within it.", "verifiability_rationale": "The first part of the review point is a suggestion ('include results for model (B)') rather than a claim that needs verification. However, it clearly states what the reviewer believes is missing. The second part is a question ('why don't you mention objects here?') which implies a potential issue or area for clarification. While not a direct claim, it points to a potential area that requires further consideration or explanation.", "helpfulness_rationale": "The review point is 5. The first part directly points out missing information and suggests a specific action ('include results for model (B)') that the authors can take. The second part raises a question about a design choice ('why don't you mention objects here?') which can guide the authors in understanding the rationale behind the current approach or potentially identify a limitation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential discrepancy between the text description and the figure caption. The core of the issue is the description of the GRU's output. While the reviewer's interpretation of the GRU as a *single* vector output is clear and actionable, the text description focuses on the *encoding process*. The reviewer's statement is explicit about the intended output. However, the reviewer's claim that this is vague is debatable as they clearly state the expected output. The reviewer's suggestion to check the text for a single vector output is a concrete action the authors can take.", "grounding_specificity_rationale": "The reviewer connects the description to Figure 2. While the text *could* be more precise, the reviewer *does* identify a specific part of the paper (Figure 2) that seems relevant. This provides a *weak* grounding \u2013 the reviewer has an *impression* that something in the figure relates to the text description. The reviewer's point is about the *output* of the GRU. The text description focuses on the *encoding process*. The figure caption suggests a set of vectors. This is a specific point of detail.", "verifiability_rationale": "The reviewer states a claim: \"The sentence in line 212... is not strictly correct.\" This is a clear claim. The reviewer's claim that this claim is not wellverified is debatable. They are pointing to Figure 2 as evidence. Whether the figure *actually* shows a set of vectors is the key. The reviewer's *claim* is that the figure supports their interpretation of the discrepancy. The verification methods are not explicitly detailed, but the reviewer is suggesting a comparison between the text description and the figure caption.", "helpfulness_rationale": "The reviewer is trying to improve the clarity and accuracy of the description. The reviewer's comment directly addresses a potential point of confusion for the authors and provides a clear direction for them to seek clarification. Authors would likely benefit from knowing if the GRU is indeed producing a single vector or a set of vectors. This directly impacts their understanding and implementation of the model."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the weakness: 'The adopted baseline models are weak' and provides specific suggestions: 'First of all, the author does not compare to Campos et al. (2020), which also uses feedback in QA tasks. Second, they also do no comparison with other domain adaptation methods, such as those work cited in Section 8.' The suggestions are clear and point to specific areas for improvement.", "grounding_specificity_rationale": "The comment identifies the weakness in the *type* of baseline models (weak models) and then specifies the *nature* of the missing baselines (Campos et al. (2020) and domain adaptation methods). This specificity allows the authors to understand exactly what is missing. The comment also implicitly refers to the *area* of the work (QA tasks) when mentioning feedback in QA tasks, although it doesn't explicitly name a section, table, figure, or unique aspect.", "verifiability_rationale": "The comment contains claims about the weakness of the baselines ('The adopted baseline models are weak') and suggests improvements ('First of all, the author does not compare to Campos et al. (2020)...'). However, the claim about the weakness lacks strong justification. The suggestion to add citations is helpful but doesn't require external verification. The suggestion to rephrase the sentence is also helpful but lacks a clear reasoning process.", "helpfulness_rationale": "The review point identifies specific weaknesses in the baseline selection and the lack of comparison to relevant methods. It provides concrete suggestions for improvement, such as adding citations to relevant works and rephrasing a specific sentence. These suggestions directly address areas where the authors could enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a potential issue with the yaxis label of figure 5 and suggests using 'Exact Match ratio' directly. This is a clear and concrete action the authors can take to address the identified weakness.", "grounding_specificity_rationale": "The comment explicitly mentions 'figure 5' and clearly identifies the issue as the 'yaxis label'. This allows the authors to precisely pinpoint the section being addressed, and the comment specifies the nature of the problem, making it highly grounded. The suggestion to use 'Exact Match ratio' directly also provides a clear direction for improvement.", "verifiability_rationale": "While the comment itself doesn't contain a claim that requires verification, the suggestion to 'use \"Exact Match ratio\" directly' implies a need for the authors to verify the current yaxis label and confirm if 'Exact Match ratio' is indeed the appropriate measure. The act of examining the yaxis label is a form of verification, even if the comment doesn't explicitly state it.", "helpfulness_rationale": "The review point is 5 as it directly identifies a potential issue with a specific element of the paper (the yaxis label of figure 5) and provides a clear and actionable suggestion for improvement ('use \"Exact Match ratio\" directly'). This empowers the authors to quickly understand the problem and take a concrete step towards resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer implicitly suggests that the paper should include more strong baselines for the MCNC component in Table 3. While the reviewer doesn't explicitly state an action to add baselines, the request implies a lack of explicit actionability in the current presentation. The reviewer points to the absence of these baselines as a potential area for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 3, MCNC' as the area where strong baselines are missing. This clearly identifies the specific part of the paper being addressed, making the grounding fully grounded. The comment specifies what is missing (strong baselines) in this part.", "verifiability_rationale": "The reviewer states that 'Table 3: MCNC should have many strong baselines that are not compared here, such as the baselines in 1'. This is a claim that requires justification. The reviewer explains *why* these baselines are important (to demonstrate the effectiveness of the proposed method and provide a fair comparison). The reasoning and the identification of the missing baselines are clear, making the claim 3.", "helpfulness_rationale": "The reviewer points out a significant omission in the paper (missing strong baselines in Table 3) and requests a justification for its absence. This directly highlights a potential weakness in the paper's presentation or completeness and provides a clear direction for improvement. The request for justification makes this comment 5 for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides two explicit suggestions. The first suggests adding the use of word embeddings, which is a clear action the authors should take. The second suggests clarifying the meaning of 'KNs' in Figure 3, which is also a clear action. Both suggestions are directly stated, making them actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 2.3' and the 'BiLSTMCRF model' in their first suggestion, providing strong grounding. For the second suggestion, while they mention 'Figure 3', they don't explicitly link 'KNs' back to a specific part of section 2.3 or explain its connection to the text, making the grounding slightly weaker.", "verifiability_rationale": "Both suggestions are verifiable. The first suggests a potential improvement in clarity and completeness by mentioning word embeddings. The second highlights a potential source of confusion in the figure, which can be verified by checking the figure and the text.", "helpfulness_rationale": "Both suggestions are helpful. The first directly points out a missing detail that would improve the clarity and completeness of the paper. The second helps the authors understand a potential issue with Figure 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a problem ('misleading') but doesn't specify how the lines are misleading or what changes the authors should make. The action is implied but not explicit.", "grounding_specificity_rationale": "The review point refers to 'Lines 102106,' which is specific. However, the issue 'such distribution' within those lines is not clearly defined, making the grounding not fully specific.", "verifiability_rationale": "The review point claims 'Lines 102106 is misleading' but provides no evidence or reasoning to support this claim. They don't explain why those lines are misleading or what evidence supports that assertion.", "helpfulness_rationale": "The review points out that lines 102106 are 'misleading' but offers no specific guidance on how to make them less misleading or improve the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action (more indepth analysis) but lacks detail on how to achieve it. It suggests exploring different methods or levels of scrutiny but doesn't provide concrete steps. This fits the definition of '3' where the action is vague on how to execute it.", "grounding_specificity_rationale": "The comment doesn't mention any specific claim, section, table, figure, or unique aspect of the paper. It's a general statement about the *claims* in the paper. Therefore, it doesn't identify a specific part of the paper, making it '1'.", "verifiability_rationale": "The comment itself is not a claim. It's a suggestion for improvement. While the *implied* claim is that the identified claims *do* benefit from more indepth analysis, the *explicit* statement isn't a claim that requires verification. Therefore, it's 'X (X)'.", "helpfulness_rationale": "The comment identifies a valid area for improvement (more indepth analysis of claims) and provides a general direction. It encourages the authors to think critically about their own work. While it lacks specific details, it's not entirely without value. It prompts the authors to engage more deeply with their claims."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks two questions: 'What is the pooling method?' and 'What is E_i?' These are direct requests for specific information, making the reviewer's point actionable. The reviewer clearly identifies the areas where they need more information.", "grounding_specificity_rationale": "The reviewer directly points to 'line 397' for the pooling method and 'equation (7) in line 472' for the definition of E_i. This precise location and the specific issue being raised indicate strong grounding specificity. The reviewer is not making an educated guess but rather pointing to a specific part of the paper.", "verifiability_rationale": "The reviewer is not making a claim that something is wrong with the paper. Instead, they are asking for clarification on specific aspects. While they are implicitly suggesting that the current information might be insufficient, they are not providing a logical reasoning or external reference to support this claim. Therefore, it is not 5. However, the reviewer is clearly indicating a need for more information, which could be considered partially verifiable as it points to a lack of clarity.", "helpfulness_rationale": "The reviewer's questions directly address key aspects of the paper and the equation, which are crucial for understanding and potentially improving the work. By asking for the pooling method and the definition of E_i, the reviewer is directly informing the authors of specific areas that need attention. This level of direct feedback is 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out that the paper raises hypotheses but does not study them. While the reviewer doesn't explicitly state an action, the implication is that the authors should conduct further analysis. The action is implicit in the suggestion to 'go deeper'. However, the reviewer doesn't specify *how* to go deeper, making it less concrete. The reviewer implies the need for more investigation, but the exact methodology or analysis is not provided, making it somewhat vague on how to apply it.", "grounding_specificity_rationale": "The reviewer refers to the hypotheses in lines 078086. They do not explicitly point to a specific section, table, figure, or unique aspect of the paper. The reference is general to the hypotheses as a whole. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer makes a claim that the paper 'actually does not really study these hypotheses'. This is a clear statement requiring justification. The reviewer implies that the logical next step is to study these hypotheses, suggesting a lack of external references to support the claim that the hypotheses are not studied. While the claim is verifiable by examining the paper's content, the justification for this claim is implied rather than explicitly provided in the review point itself.", "helpfulness_rationale": "The reviewer clearly identifies a problem: the paper raises valuable hypotheses but fails to investigate them. They also suggest a solution: the authors should go deeper into the respective topics. This is a direct and actionable feedback. The reviewer provides a clear problem and a clear suggestion for improvement, making it 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the steps to create a baseline PCFG with a smaller state size and directly parameterized matrices. The reviewer clearly indicates the size of the new PCFG (state size r) and the dimensions of the parameter matrices (e.g., H: r x r, I: r x o). This provides a clear and actionable direction for the authors to implement this baseline. The action is explicit, and the details are concrete, making it 5.", "grounding_specificity_rationale": "The review point explicitly states the size of the smaller PCFG (state size r) and the dimensions of the parameter matrices (e.g., H: r x r, I: r x o). This clearly identifies the specific part of the PCFG being addressed. The grounding is explicit, and the details provided make it easy for the authors to understand and implement this baseline. The authors can directly apply this information to create the smaller model.", "verifiability_rationale": "The review point proposes a specific experimental setup: creating a smaller PCFG with direct parameterization and comparing its perplexity to the original. While it doesn't provide a detailed justification for *why* this comparison is valuable, it clearly states a claim and suggests a concrete experiment. The claim is that this baseline can be used for comparison, and the method is to create the smaller model and measure perplexity. The reasoning is present in the form of stating the experiment.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the authors: create a smaller PCFG with direct parameterization and compare its perplexity. This directly addresses a common need for authors to understand the impact of model size on performance. The suggestion is specific enough for the authors to implement and evaluate. This provides a concrete experiment that can help the authors understand their model better."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the action the authors should take (state the maximum number of tasks done by any annotator) and provides concrete guidance on how to do it (by including this information in their paper).", "grounding_specificity_rationale": "The comment does not specify which part of the paper it is referring to. It is a general suggestion about the paper as a whole.", "verifiability_rationale": "The review point is a suggestion, not a claim that needs to be verified or supported. There is X made in this review point.", "helpfulness_rationale": "The comment provides a clear and actionable suggestion for the authors (state the maximum number of tasks) and guides them on how to implement it (by including that information in their paper). This directly addresses a potential area for improvement and is very helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The suggestion to include a 'hard prompt baseline' in Table 1 is explicit and provides concrete guidance on what to add. It is also vague on how to execute it, making it 2.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Table 1' and suggests a very specific type of analysis ('hard prompt baseline'). This can be achieved through literal mention of sections, tables, figures, etc., making it fully grounded. The comment specifies what needs to be addressed in this part, which is the inclusion of a hard prompt baseline in Table 1.", "verifiability_rationale": "The reviewer suggests adding a specific type of analysis to a specific table, which is logically connected to the goal of understanding performance. However, it doesn't provide external justification. It is 3 as it points to a concrete next step for the authors.", "helpfulness_rationale": "The suggestion to include a 'hard prompt baseline' in Table 1 directly addresses the need to understand the performance of different methods and is a clear, actionable recommendation. It provides a concrete next step for the authors to take. While it doesn't provide a justification for why this is beneficial, it does point to a specific area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the 'lack of numerical results' as a problem and suggests 'applying it to some popular algorithms and their performance compared with existing DP algorithms' as a way to address it. This indicates an explicit action and a concrete suggestion.", "grounding_specificity_rationale": "The reviewer mentions 'numerical results,' 'popular algorithms,' and 'existing DP algorithms,' which provides some grounding. However, the specifics of the numerical results, the choice of popular algorithms, and the method of comparison are not detailed, making it only partially grounded and specific.", "verifiability_rationale": "The reviewer identifies a 'lack of numerical results' as a problem and suggests 'applying it to popular algorithms and comparing their performance with existing DP algorithms' as a way to verify it. This is a clear claim with a suggested method of verification, making it 3.", "helpfulness_rationale": "The reviewer clearly states the 'lack of numerical results' as a problem and offers 'applying it to some popular algorithms and their performance compared with existing DP algorithms' as a solution. This directly addresses the stated issue, making it helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the absence of experiments for InvP with wider backbones, which is an implicit action. While the reviewer doesn't directly say 'Please include these experiments', the suggestion implies a desired action. The action is vague in the sense that it doesn't specify *why* these experiments are needed, making it less concrete than a direct instruction.", "grounding_specificity_rationale": "The reviewer mentions 'some methods like MoCo and SimCLR' and their 'wider backbones (ResNet50 2\u00d7) and (ResNet50 4\u00d7)'. This clearly identifies the specific aspect of the paper being addressed (InvP's performance with these backbones) and provides a basis for comparison. The grounding is strong as the specific elements are mentioned. The specificity is high as the reviewer directly asks for results for a particular configuration.", "verifiability_rationale": "The reviewer makes a claim about the need for these additional experiments and provides a logical reasoning by drawing a parallel to the experiments conducted on MoCo and SimCLR. The claim is supported by logical reasoning and the suggestion is directly relevant to the field. The evidence is present and logical.", "helpfulness_rationale": "The reviewer directly asks for 'results of proposed InvP with these wider backbones'. This is a clear and actionable suggestion that directly addresses a gap in the current evaluation. The request is specific and directly relevant to improving the understanding of the proposed method. The suggestion is directly helpful for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the callout to Table 5 should be in Table 3 and points out that the callout for Figure 6 is not directing properly. This provides a clear action for the authors to take: move the callout for Table 5 to Table 3 and fix the callout for Figure 6. The reviewer directly identifies the location of the callout and the issue with the callout's direction, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly identifies the callout belonging to Table 5 and Figure 6. They state 'the callout to table 5' and 'figure 6 callout', clearly pinpointing the specific elements in the paper being addressed. This is a literal mention of the sections and figures, providing full grounding.", "verifiability_rationale": "The reviewer makes a claim by stating that the callout to Table 5 is incorrect and should be in Table 3, and that the callout for Figure 6 is not directing properly. While the *effect* of the callout being wrong is verifiable by examining the figures, the reviewer's *claim* itself isn't being supported by external evidence or logical reasoning within the review point. The suggestion is constructive feedback, not a claim requiring verification.", "helpfulness_rationale": "The reviewer provides specific, actionable feedback by pointing out the incorrect placement of a callout and the malfunctioning callout for a figure. This directly addresses potential issues the authors might be facing when interpreting the paper. The suggestion to move the callout and fix the direction is a clear and constructive improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a specific action: 'comparisons with SketchRNN'. This is a clear instruction on what the authors should do to improve their draft. The action is not just implied but directly stated, making it easily actionable.", "grounding_specificity_rationale": "The review point refers to 'the experiments' as the area needing improvement. While the suggestion to compare with SketchRNN is valuable, the point does not specify *which* part of the experiments (e.g., a specific dataset, a model implementation, an evaluation metric) is lacking. The reference is general, making the grounding somewhat weak.", "verifiability_rationale": "The review point makes a claim about the experiments: 'The paper reports only self comparisons' and 'The paper also doesn't explain why this is so, which adds to the poor motivation problem.' These are statements that can be verified by examining the paper's content and the reasons provided for the experiments. While the reviewer doesn't provide specific examples or references to external work, the claim is based on observable information within the paper itself.", "helpfulness_rationale": "The review point is clear, concise, and directly addresses a relevant issue for the authors. It suggests a specific improvement by proposing comparisons with SketchRNN, which is a concrete and actionable suggestion. The feedback is directly linked to the experimental section, making it highly relevant and helpful for the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that 'Both CNNs and ViTs seem to benefit similarly from increased model capacity' and then provides a detailed analysis comparing the performance of different sized CNNs and DeiT models in Figure 3. The reviewer identifies a specific trend and suggests a comparison, which are both direct actions the authors could take. The reviewer also states 'I disagree with authors' viewpoint that \"Both CNNs and ViTs seem to benefit similarly from increased model capacity\"', which is a direct challenge to the authors' claim.", "grounding_specificity_rationale": "The reviewer mentions 'Figure 3' when discussing the performance of different sized models. While they also mention 'DeiTB', 'DeiTT', 'DeiTS', 'APTOS2019', 'ISIC2019', and 'CheXpert', the exact models and datasets being compared are not explicitly stated in the review point itself. The reviewer implies a comparison between different sized DeiT models and different datasets, but the specific combinations are not clearly identified. The reviewer also mentions 'increasing model capacity' which is a general concept.", "verifiability_rationale": "The reviewer makes the claim that 'DeiT models do not consistently outperform smaller DeiT models and smaller CNN models in the provided figures' and 'the performance gains of DeiT with increased capacity are less consistent than CNNs'. This is a claim that requires verification. The reviewer implies that the figures provide evidence for this claim, although the specific evidence is not detailed in the review point itself.", "helpfulness_rationale": "The reviewer provides a clear statement of a potential issue and a comparison between CNNs and ViTs. They highlight a discrepancy in performance trends and suggest further analysis. While they don't offer a direct solution, they point out a specific area that needs investigation, which can be helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the distinction between updating a frozen model and hard prompt tuning. While they don't provide specific steps on how to implement this distinction, the action of identifying the difference is clear and direct. The mention of 'Schick and Sch\u00fctez, etc' provides a concrete example of the type of work being referred to, further grounding the suggestion.", "grounding_specificity_rationale": "The reviewer suggests a distinction in terminology but does not explicitly point to a specific section, table, or figure in the paper where this distinction is lacking. The comment is general and about improving clarity in the authors' understanding or communication, rather than pinpointing a specific element of the paper.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It is a suggestion for improvement in terminology and clarity. Therefore, it falls under the 'X' category, indicating X.", "helpfulness_rationale": "The reviewer's suggestion to make a distinction between hard prompt work updates the frozen model (Schick and Sch\u00fctez, etc) from ones that don't is relevant and could be helpful for authors trying to understand the nuances of prompt tuning. However, the suggestion is quite general and lacks specific examples or actionable steps for the authors. It provides a potential improvement but requires further elaboration to be fully helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the request to conduct an ablation study on the visDial dataset and specifically asks for the performance of ATT(+H) without the attention retrieval mechanism. This is a clear and direct instruction, making the action explicit. Furthermore, the reviewer specifies which ablation study (ATT(+H)) and which metric to evaluate (performance without attention retrieval), making the action concrete.", "grounding_specificity_rationale": "While the reviewer doesn't explicitly name a section or table, the phrase 'To further backup the proposed visual reference resolution model works in real dataset' strongly implies they are referring to the visDial experiments presented in the paper. This can be considered weak grounding as the authors can make an educated guess about the relevant part. However, the reviewer does clearly specify what needs to be addressed: 'the performance of ATT(+H) (in figure 4 left). What is the result if the proposed model didn't consider the relevant attention retrieval from the attention memory.' This specificity allows the authors to understand the exact experiment to be conducted.", "verifiability_rationale": "The reviewer makes a request for a specific experiment: conducting an ablation study on the visDial dataset and evaluating the performance of ATT(+H) without the attention retrieval mechanism. This can be considered a claim in the sense that the reviewer is asking for a particular analysis to be performed. While not a definitive statement of agreement or disagreement, the request itself is a form of claim that needs to be supported. The support comes from the request itself, asking for a specific analysis to be performed. The logical reasoning is that this ablation study would help understand the contribution of the attention mechanism. The claim is 3 as the authors can infer the need for this analysis based on the model's architecture and the reviewer's interest.", "helpfulness_rationale": "The reviewer's request is highly relevant and directly addresses a potential weakness in the paper \u2013 the lack of a thorough evaluation of the proposed model on the visDial dataset. By specifically asking for an ablation study on ATT(+H) without attention retrieval, the reviewer is directly prompting the authors to investigate the contribution of this particular component. This is a valuable and actionable suggestion that would significantly enhance the paper's evaluation and understanding of the model's behavior. The request is clear, specific, and directly contributes to improving the model's assessment."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question ('what is the model predicting with `np.ones` input?') which directly prompts the authors to perform an analysis. While it doesn't explicitly state the action, the question itself is a clear instruction. However, the subsequent statement ('Figure 2 seems to suggest that Gaussian noise input does not work as well as WPA.') infers an action: 'Analyze Figure 2 and compare the performance of WPA and Gaussian noise inputs.' This lack of explicit action makes it borderline.", "grounding_specificity_rationale": "The review point starts with a general statement ('It would be interesting to try...') and then asks a question ('what is the model predicting with `np.ones` input?'). While `np.ones` is a specific input, the question itself is general and doesn't explicitly refer to a specific section, table, or figure in the paper. The statement about Figure 2 also lacks a direct reference to that figure or section. The critique about the authors' work ('but fails to provide useful insights on how WPA works...') is a general statement about the authors' analysis, not a specific request related to a particular part of the paper. Therefore, the grounding is weak as it doesn't explicitly point to a specific area of the paper being discussed.", "verifiability_rationale": "The review point makes a claim by stating ('Figure 2 seems to suggest that Gaussian noise input does not work as well as WPA.') and ('Authors spend lot of time showing WPA improves the test performance of the original model, but fails to provide useful insights on how WPA works...'). These statements are claims that require some level of interpretation and inference from the paper's content. However, the review point itself doesn't provide explicit logical reasoning, common knowledge, or external references to support these claims. The claims are based on the interpretation of Figure 2 and the authors' analysis, which are external to the review point itself. Therefore, it is '3' as it points to potential weaknesses in the authors' work but lacks direct evidence within the review point.", "helpfulness_rationale": "The review point raises a valid concern about the lack of mechanistic understanding of WPA and suggests a potential experiment (`np.ones` input) to investigate this. It points out a limitation in the authors' current analysis. While it doesn't directly tell the authors *how* to improve their current draft, it highlights a valuable area for future research and suggests a concrete experiment. Therefore, it is '3' as it identifies a potential area for improvement and suggests a way to explore it, even if it doesn't directly address the current draft's shortcomings."}
{"actionability_label": "Partially Actionable (3)", "grounding_specificity_label": "5 (5)", "verifiability_label": "Not Verifiable (1)", "helpfulness_label": "4 (4)", "actionability_rationale": "The reviewer identifies the missing information about parameter settings and sensitivity analysis in the experimental section. While they don't explicitly state how to set the parameters or what range to use, they clearly point out the *lack* of this information. This can be considered a form of actionable feedback, as it highlights a crucial missing piece of information that the authors would need to replicate the results. However, the action is not fully carried out, as no specific values or ranges are suggested.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the experimental section (Sec. 3)' and the specific parameters 'minimum cluster size' and 'conductance threshold'. This clearly identifies the specific part of the paper being addressed and the exact issues. This is a strong form of grounding, as the reviewer provides a direct reference point within the paper.", "verifiability_rationale": "The reviewer *claims* that the experimental section does not mention or discuss how the parameters are set and how sensitive the performance is with respect to these parameters. However, the reviewer does not provide any evidence or reasoning to support this claim within the provided text. The text describes the experimental section but does not contain the missing information the reviewer is criticizing.", "helpfulness_rationale": "The reviewer clearly states that the lack of information about parameter settings and sensitivity analysis is a problem. They highlight that this information is crucial for reproducibility and understanding the robustness of the results. This is a direct and helpful critique, pointing out a significant gap that the authors need to address to properly evaluate their method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a potential weakness related to reinforcement learning, which is an explicit action (identifying a weakness). However, they don't provide specific steps on how to address it, making it implicit. The weakness is about the method and its implications, which is concrete.", "grounding_specificity_rationale": "The reviewer mentions \"reinforcement learning for a static VQA task\" but doesn't specify which part of their paper this refers to. The issue is about the approach's potential weakness, which is a general statement about the method.", "verifiability_rationale": "The reviewer states their belief about the weakness of reinforcement learning but doesn't provide external references or logical reasoning to support this claim within the review point itself. The consequences are logical, but the initial statement is an opinion.", "helpfulness_rationale": "The reviewer identifies a potential limitation of the approach, which is a relevant point for the authors to consider. While not a direct solution, it encourages them to think critically about their method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer is asking for clarification on a specific implementation detail (the bilinear layer) and its relationship to other methods. While the reviewer identifies the area of confusion (bilinear layer implementation), they do not explicitly state what action the authors should take to understand this implementation. The request is more about seeking information than directly instructing on the next steps.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'bilinear layer' and 'other approaches' in their review point. This indicates a clear identification of the specific part of the paper being referred to. However, the reviewer does not specify *what* is wrong with the implementation or *how* it differs from other approaches. The grounding is present, but the specifics are lacking.", "verifiability_rationale": "The reviewer is asking questions about the differences between the bilinear layer and other approaches, and the role of Equation (3). These are questions that require further explanation and justification from the authors, rather than stating a verifiable claim. The reviewer is not making a statement that can be directly supported or refuted.", "helpfulness_rationale": "The reviewer is asking questions rather than providing suggestions or pointing out specific weaknesses in the paper. While the questions are relevant, they do not directly guide the authors on how to improve their draft. The review point itself is not immediately helpful for the authors without further clarification from the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the reason for the high cosine similarity (preactivation values being the same) and directly asks a question about an alternative visualization (the latter loss term of Eqn 13). This provides a clear action for the authors to take, making it 5. The reviewer is not just pointing out a problem but suggesting a specific solution.", "grounding_specificity_rationale": "The reviewer directly references 'Fig. 3 e.' and mentions the specific relationship between preactivation values and cosine similarity. They also explicitly state their suggestion related to 'Eqn 13'. This shows a strong grounding in the paper's content and a clear understanding of the specific section being discussed.", "verifiability_rationale": "The reviewer's point is based on a logical understanding of cosine similarity. They are not making a subjective claim about the *quality* of the figure itself, but rather about the *interpretation* of the existing data. The suggestion to show the loss term is a logical next step based on their understanding. This is verifiable because it's based on a known mathematical property.", "helpfulness_rationale": "The reviewer is suggesting an alternative visualization to potentially gain a *deeper understanding* of the results. While it doesn't directly fix a *bug* or error, it's a valuable suggestion for improving the analysis and interpretation of the data. It empowers the authors to explore the results in a different and potentially more insightful way. Therefore, it's '5' because it directly addresses a potential area for improvement in the analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer's point about the lack of comparison with TTA methods is implicitly actionable. While the reviewer doesn't explicitly state 'I need to compare X with Y', the implication is clear: the paper should address this gap. However, the action is vague. The reviewer doesn't specify *how* to prove data processing is superior to model parameter adjustment. Is it through a specific experiment, a theoretical argument, or a comparison of performance on a specific dataset? This vagueness makes the action implicit and not fully actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'testtime adaptation (TTA) methods, such as AB' and the general goal of adapting to outofdistribution data. This clearly grounds the comparison in a specific area of the literature and a defined problem. Furthermore, the reviewer specifies the *nature* of TTA methods (updating model parameters) and how they differ from the paper's focus (adjusting input data). This makes the grounding both **Weakly Grounded** (as the reviewer doesn't provide the full details of AB) and **Specific** (as the reviewer highlights the difference in approach).", "verifiability_rationale": "The reviewer makes a clear claim: 'how to prove that data processing is superior to model parameter adjustment?'. This claim requires evidence. The reviewer suggests an experimental approach as the way to verify this claim. While the suggestion itself isn't a fully detailed experiment, the intent to provide *experimental results* is a valid and generally accepted method for verification in this context. Therefore, the claim is **Partially Verifiable** as it has some justification (experimental results) but lacks the specifics of the experiment itself.", "helpfulness_rationale": "The reviewer provides a clear and actionable point for improvement: 'how to prove that data processing is superior to model parameter adjustment?'. This directly addresses a gap in the paper. The reviewer also suggests a way to achieve this, namely 'by conducting experimental results'. This makes the comment both **Explicit** in its request for a solution and **Concrete** in suggesting an experimental approach. The reviewer's intent is to help the authors improve their draft by providing a clear direction for further investigation. This makes the comment **5**."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'the first expression for J (\u03b8) is incorrect' and provides the correct expression 'Q (s<sup>t0</sup>, \u03c0<sub>\u03b8</sub>(s<sup>t0</sup>))'. This directly identifies an error and suggests a concrete fix, making the action explicit and the action itself concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3.2.1' and provides the exact expression 'Q (s<sup>t0</sup>, \u03c0<sub>\u03b8</sub>(s<sup>t0</sup>))' as the correct alternative. This allows the authors to precisely locate the issue and understand the desired correction, making the grounding fully explicit and the grounding itself fully explicit.", "verifiability_rationale": "The reviewer states a fact ('the first expression for J(\u03b8) is incorrect') and provides a specific alternative ('Q (s<sup>t0</sup>, \u03c0<sub>\u03b8</sub>(s<sup>t0</sup>))'). This claim is directly verifiable by understanding the standard notation for the actionvalue function in reinforcement learning. The reviewer is not making a subjective judgment but rather pointing out a factual error and providing the correct alternative.", "helpfulness_rationale": "This review point is 5 because it directly identifies a technical error in a key mathematical expression and provides the correct alternative. Authors would likely benefit from this direct correction rather than having to discover the error themselves. The suggestion is concrete and actionable."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states actions to take, and these actions are clearly defined. They mention 'improving the paper' and list specific actions like 'capitalization errors in references'. This is a clear indication of actionable feedback.", "grounding_specificity_rationale": "The reviewer mentions 'references' generally. It's not pinpointing a *specific* section, table, figure, or unique aspect of the paper. The comment specifies what needs to be addressed in this part (capitalization), but the part itself is not clearly identified. While they mention specific paper sections (p.8 and p. 13), they don't explicitly state which *part* of the paper they are referring to.", "verifiability_rationale": "The reviewer states a claim about the paper needing proofreading but doesn't provide any evidence or references to support this claim. There is no logical reasoning or external references given to justify the need for proofreading.", "helpfulness_rationale": "The feedback is about proofreading, which is generally helpful. However, it lacks specific details about *why* these errors are problematic and doesn't connect them to the content of the paper. The reviewer doesn't explain the impact of these capitalization errors on the paper's understanding or presentation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a question about the performance of a specific configuration (Table 2 with CBN on layer 2) compared to another configuration (Table 2 with CBN on layers 3 and 4). While the reviewer identifies a discrepancy, they do not explicitly state what action the authors should take to address this issue. The reviewer is implicitly suggesting that the current configuration might be problematic, but they do not provide concrete steps or guidance on how to improve the performance. The reviewer's question is the core of the point, but it lacks the explicit action required for high actionability.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 2' and the specific layers (2, 3, and 4) in their review point. This clearly identifies the specific part of the paper and the experimental setup being discussed. The reviewer is not making a general comment about the paper but rather focusing on a specific table and layer configuration. This demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer states that 'deteriorates performance for GuessWhat?! compared to when CBN is applied to layers 4 and 3 only.' This is a claim that requires verification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim within the review point itself. The reviewer presents the observation as a fact without explaining *why* this might be happening. Therefore, the claim is not verifiable based solely on the information provided in this review point.", "helpfulness_rationale": "The reviewer points out a performance issue with a specific configuration (Table 2 with CBN on layer 2) compared to another configuration (Table 2 with CBN on layers 3 and 4). This observation is helpful because it highlights a potential problem that the authors should investigate. By identifying this discrepancy, the reviewer guides the authors to focus on a specific experimental setup and its impact on performance. While the reviewer does not provide a solution, they do identify a meaningful issue that requires attention, making the review point 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue (similarity to backdoor triggers) and suggests an investigation. While they don't explicitly state what the authors should do, they identify a problem that needs attention. This makes it 3 as the authors can infer the need for further analysis.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Section 3.1 and 3.2,' which clearly identifies the specific part of the paper being addressed. This is a strong example of full grounding as the section number is mentioned.", "verifiability_rationale": "The reviewer makes a claim about the impact of spurious examples, stating, 'It is wellknown that a few training examples with such triggers (rare spurious examples in this paper) would have a large impact on the trained model.' However, this claim is not supported by any specific references or logical reasoning within this review point. The reviewer is stating a generally accepted truth but doesn't provide evidence for their specific context.", "helpfulness_rationale": "The reviewer identifies a potential issue (similarity to backdoor triggers) and suggests an investigation. This is a helpful pointer for the authors to consider, as it highlights a potential problem that could affect their model. While it doesn't directly tell them what to do, it points to an area for further examination, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a lack of clarity regarding the distinction between weak supervision and semisupervised training. While the reviewer acknowledges the existence of these training regimes, they highlight that the paper does not explicitly state when each is used. The reviewer suggests renaming a column in Table 1 and adding new columns to clarify the training data for different parts of the model. This is a valid point as the current presentation does not clearly delineate these distinct training approaches, potentially leading to confusion about the experimental setup and results.", "grounding_specificity_rationale": "The reviewer provides a clear and specific suggestion for improving the clarity of the paper. They propose renaming a column in Table 1 and adding new columns to explicitly show the mixture training data and single source data used for each part of the model. This directly addresses the reviewer's request and provides a precise location for the requested information. The reviewer's understanding of where the information should be located is evident.", "verifiability_rationale": "The reviewer's request is very concrete and directly addresses a potential ambiguity in the paper. They suggest renaming a column in Table 1 and adding new columns to explicitly show the mixture training data and single source data used for each part of the model. This request is based on a clear understanding of the information needed to understand the training process and is presented in a way that is easy to verify and act upon.", "helpfulness_rationale": "The reviewer's suggestion directly addresses a potential ambiguity in the paper and would improve its clarity and reproducibility. The reviewer is proposing a specific change to Table 1 that would make it easier for readers to understand the training process and the data used for different parts of the model. This is a valuable suggestion that would benefit the authors and readers."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the finding: 'in the ablation experiment, the performance without reinforcement learning dropped lower than without dependency tree'. This clearly indicates an action the authors should take. The reviewer also suggests a specific improvement: 'The two tables do not list the cases where dependency tree and RL are not used'. This is a concrete action the authors can take to improve their draft by including these cases. The reviewer's statement is direct and identifies a clear area for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'ablation experiment', 'performance', 'reinforcement learning', and 'dependency tree'. While they don't explicitly state the 'section' or 'table' number, the context strongly implies they are referring to specific sections or tables in the paper where these results are typically presented. This can be considered 'Full Grounding' as the information is implied and highly contextdependent, but not explicitly stated. The reviewer also specifies the 'type' of ablation ('without reinforcement learning') and the 'metric' affected ('performance'). They also identify the 'missing element' ('cases where dependency tree and RL are not used'). This contributes to the specificity of the comment.", "verifiability_rationale": "The reviewer makes a claim: 'in the ablation experiment, the performance without reinforcement learning dropped lower than without dependency tree'. This is a statement that requires verification. The reviewer also points out a lack of supporting information: 'The two tables do not list the cases where dependency tree and RL are not used'. This lack of specific data makes the claim less verifiable. While the claim itself might be verifiable through the tables if they were present, the reviewer's point about the missing cases is a valid concern that hinders the verification of the performance difference.", "helpfulness_rationale": "The reviewer provides a clear critique of the experimental setup and points out a specific missing piece of information. This is helpful for the authors as it highlights a potential issue with their ablation study and suggests a necessary improvement. The criticism is specific and actionable, suggesting a concrete step the authors should take to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the 'experiments section' as the main weakness. They further specify the datasets (CIFAR10, LEAF, FedProx, FedMAX) that are missing. This indicates a clear and direct identification of an actionable area for improvement. The reviewer doesn't leave room for ambiguity about what needs to be addressed.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'experiments section' as the area of concern. They then provide specific examples of missing information within that section, such as 'LEAF https://leaf.cmu.edu/', 'FedProx https://arxiv.org/abs/1812.06127' and 'FedMAX, https://arxiv.org/abs/2004.03657 (ECML 2020)'. This demonstrates a high level of grounding specificity by accurately pinpointing the section and providing concrete examples of missing elements.", "verifiability_rationale": "The reviewer makes a claim that the 'experiments section' is a weakness due to the limited dataset usage and missing relevant benchmarks and papers. However, they do not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a statement of fact rather than a welljustified assertion. Therefore, while the claim is identified, the verifiability is low as there is no supporting evidence provided.", "helpfulness_rationale": "The reviewer identifies a clear area for improvement in the paper \u2013 the limited scope of the experimental evaluation. However, the review stops at pointing out the missing datasets and papers. While this highlights a potential weakness, it does not offer specific suggestions for how the authors should address this issue or explain *why* this is a critical flaw. The feedback is primarily diagnostic rather than constructive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a contradiction in the paper's description of how clean exemplar manifolds are constructed, specifically for nonstochastic networks like ResNet50 and ATResNet50. While the paper mentions both adversarial perturbations and stochasticity as methods for creating exemplar manifolds, it doesn't explicitly detail how the 'clean' manifold is generated for the nonstochastic networks. This creates an implicit gap in the information provided, making the reviewer's question actionable in identifying a missing piece of the methodology. The action isn't explicitly stated as 'I'm confused about how to create a clean manifold for ResNet50', but the lack of clarity implies it.", "grounding_specificity_rationale": "The reviewer's question directly targets a specific aspect of the methodology: how the clean exemplar manifold is constructed for the ResNet50 and ATResNet50 networks. They explicitly mention 'clean exemplar manifold' and 'ResNet50 & ATResNet50' in their question. This demonstrates strong grounding as the reviewer can accurately pinpoint the section of the paper being addressed, or at least know exactly where the information would be found (the method description). The specificity is high because the question is very focused on a particular implementation detail.", "verifiability_rationale": "The reviewer's point is not a claim but rather a request for clarification on how a clean exemplar manifold is constructed for specific networks. Therefore, the 'verifiability' aspect is not directly applicable as there is X to be verified. However, the *lack* of this information in the paper makes the reviewer's point 3 in the sense that the paper doesn't provide the necessary information to answer their question. The paper states the construction methods but doesn't specify the method for the clean manifold for ResNet50 and ATResNet50, creating a logical gap.", "helpfulness_rationale": "The reviewer's question is highly specific and directly addresses a potential point of confusion for the authors regarding the construction of clean exemplar manifolds for specific networks. By asking how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50, the reviewer is seeking a crucial implementation detail that is missing from the paper. This question is likely to be very helpful for the authors to understand and potentially reproduce the experiments. The specificity of the question makes it a valuable point of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the confusion and provides a specific example of where the lack of clarity occurs ('what is S and Xt'). This is an explicit action the reviewer is requesting.", "grounding_specificity_rationale": "The reviewer *identifies* a gap in the paper's content \u2013 the lack of definition for 'S' and 'Xt'. This demonstrates a clear understanding of where the information is missing. The reviewer *specifically* points out the confusion arising from the missing definitions. This specificity is high.", "verifiability_rationale": "The reviewer *states* that the paper is confusing. This is a claim (or a suggestion for improvement) that can be supported by examining the paper. While the paper *could* potentially address this by including definitions, the reviewer's statement itself is a verifiable claim.", "helpfulness_rationale": "The reviewer explicitly states they found the comment helpful in identifying an area for improvement. The comment directly addresses a potential weakness and provides a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of clarity in the motivation for a specific mathematical choice (\u03b8 = \u03c0/2(1h)) within a theorem. While they identify a potential weakness in the explanation, they do not explicitly state what action the authors should take to address this. The authors are left to infer the need for clarification. The reviewer does not provide concrete steps or examples of how the authors should proceed beyond 'understanding the lack of clarity'.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Theorem 3' and the specific equation '\u03b8 = \u03c0/2(1h)' within it. They clearly identify the issue as a lack of 'clarity' regarding the motivation for this choice. The reviewer directly points to a specific part of the paper and explains what they believe is missing. The grounding is explicit, and the issue is clearly defined within the referenced section.", "verifiability_rationale": "The reviewer makes a claim that the motivation for the choice of \u03b8 = \u03c0/2(1h) is not very straightforward and clear. They state that the paper states this choice is 'empirical' but provides 'very little' motivation for this exact form. While the reviewer identifies a gap in the explanation, they do not provide external references or logical reasoning to support their claim. The justification is based on the paper's own statement of the choice being 'empirical' without further elaboration. The evidence for the lack of clarity is based on the reviewer's interpretation of the paper's content.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the paper by pointing out the lack of clarity in the motivation for a specific mathematical choice. This highlights an area where the authors could benefit from further explanation or justification. While the reviewer does not provide a solution or a replacement for the current explanation, they do point out a specific point of confusion that the authors might encounter. This makes the review point 3 in identifying an area needing improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential issue with the statement 'Finally, INRs operate on a perdatainstance basis, meaning that one timeseries instance is required to train an INR'. While the statement itself is explicit, the reviewer's suggestion to clarify that this applies to *each instance* within a batch is an actionable point that would improve understanding. The reviewer identifies a potential misinterpretation, which is a valuable actionable insight. However, the initial statement is explicit about the perdatainstance nature. The reviewer's actionable point is a clarification of the *implication* of the statement, not a correction of the statement itself.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly pointing to a specific section or table in the paper. They are commenting on a general statement about how INRs operate. While the reviewer does provide some context by mentioning 'timeseries instance' and 'train an INR,' this is inferred from the statement itself rather than explicitly stated in the paper. The comment is about the implications of the statement, not a direct reference to a specific part of the paper.", "verifiability_rationale": "The reviewer makes a factual claim about how INRs operate. The claim that 'INRs operate on a perdatainstance basis' can be verified by the definition of INRs. The reviewer's addition that 'one timeseries instance is required to train an INR' is also verifiable. However, the reviewer doesn't provide specific examples or external references to support this claim within the review point itself. The claim is verifiable based on the definition of INRs, but lacks specific examples or citations within the provided text.", "helpfulness_rationale": "The reviewer's point is 5. They are identifying a potential misunderstanding of INRs and clarifying the practical limitations of this approach. By highlighting that a model trained on INRs would struggle with a single time series, the reviewer provides valuable context for readers trying to understand the method's applicability. This directly addresses a potential practical concern and guides the reader's understanding of the method's limitations."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a limitation in the experiments section, identifying 'most of the experiments (excluding Section 4.1.1) are limited to RoBERTabase only' as an actionable issue. It further suggests concrete actions like 'investigating whether the results can be generalized to differences in model size, objective function, and architecture' and 'including more analysis and discussion for GPT2'.", "grounding_specificity_rationale": "The review point is grounded in the specific sections of the paper mentioned, 'most of the experiments' and 'RoBERTabase only.' It also focuses on a specific aspect of the models, 'learnable APEs.' The suggestion to 'include more analysis and discussion for GPT2' further grounds the criticism in a concrete example.", "verifiability_rationale": "The review point makes a claim about the generalizability of results to different model types. While it doesn't provide immediate evidence *within the review point*, it clearly states the intent to investigate this further, particularly with the example of GPT2. This suggests a logical reasoning to explore the claim.", "helpfulness_rationale": "The review point is helpful by identifying a clear limitation in the experimental setup. It provides a direction for improvement by suggesting exploring a wider range of models and architectures. The specific mention of GPT2 as an example makes the suggestion concrete and actionable for the authors. The language used, such as 'It is important to investigate' and 'It is worthwhile to include,' encourages the authors to take further steps to address the identified limitation."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitations of the method in terms of the model architecture (ViT) and data type (image data). They also suggest alternative approaches (NLP and CNNs). This is a clear and direct identification of a problem, making it actionable for the authors to consider these alternatives.", "grounding_specificity_rationale": "The reviewer refers to 'Table 1' and mentions 'model,' 'experiments,' 'NLP,' and 'CNNs.' These are specific elements within the authors' work and the proposed improvements. The reviewer clearly identifies the areas where the method might not be applicable and suggests specific research directions, making the feedback grounded.", "verifiability_rationale": "The reviewer states that the parameters seem to be only good for ViT and image data. While this is a valid observation, the reviewer does not provide any specific evidence or methodology to *verify* this limitation. The suggestions for improvement (NLP and CNNs) are general and lack specific references or justifications. Therefore, the claim is not fully supported by verifiable evidence.", "helpfulness_rationale": "The reviewer points out a limitation of the method and suggests exploring alternative areas and model types. This is a constructive feedback point that encourages the authors to consider the broader applicability of their work. While it doesn't provide a definitive solution, it guides them towards further research and potentially expanding the scope of their method. This type of feedback is helpful for guiding future work and improving the overall contribution."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a problem (nonstandard benchmarks breaking TTA methods) but does not provide explicit or implicit instructions on how to address it or improve the draft. The authors are left to infer the necessary changes.", "grounding_specificity_rationale": "The review point mentions 'TTA methods' and 'natural distribution shift, like WILDS 9'. While it mentions WILDS, it does not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed in relation to these TTA methods. The grounding is weak because the reviewer is suggesting evaluating on a new benchmark but doesn't specify which part of their current paper this relates to.", "verifiability_rationale": "The review point makes a claim ('This is an interesting observation') and suggests a potential problem ('using nonstandard benchmarks breaks a lot of popular TTA methods'). While the observation itself is verifiable, the claim about TTA methods breaking down is an inference based on experience rather than a direct statement supported by evidence within this specific review point. The reasoning is present but could be more explicit and detailed.", "helpfulness_rationale": "The review point raises a valid concern about the experimental setup and suggests evaluating on WILDS. However, it does not provide concrete, actionable steps for the authors to take to address this issue or improve their draft. The suggestion is more of a potential area for future work rather than direct guidance on how to modify the current submission."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'The unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version) is perfectly balanced...'. This clearly identifies an action the authors should take: consider using a more realistic, imbalanced unlabeled dataset. The reviewer also provides a specific reference to a relevant paper, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version)' and 'perfectly balanced'. This directly identifies the specific part of the paper the reviewer is referring to, making the grounding explicit. They also name a specific paper, further specifying the issue.", "verifiability_rationale": "The reviewer's claim is that using a perfectly balanced dataset for unlabeled data is 'impractical in realworld applications' and that the authors should use a setting similar to He et al., EMNLP 2018. This claim is supported by the reviewer's statement and the logical argument that realworld data is often imbalanced. The reviewer also provides a reference to a relevant paper, making the claim verifiable.", "helpfulness_rationale": "The reviewer's point is directly relevant to the authors. They are highlighting a practical limitation of the authors' experimental setup (using a perfectly balanced dataset) and suggesting a more realistic alternative. This is a valuable suggestion that can help the authors improve their draft by making their experiments more aligned with realworld scenarios. The reviewer is not suggesting a flaw in the method itself, but rather in the experimental setup, making it 5 for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem with Equation 3, saying 'Equation 3 directly removes the modal subset of all instances.' They also ask 'How to deal with the problem mentioned above.' This indicates a clear and direct action the authors should take. The reviewer provides a concrete description of the issue, specifying that instances with good performance in modality A and B are potentially stronger, and Equation 3 removes all instances of a modality. This action is directly linked to Equation 3 and the identified issue.", "grounding_specificity_rationale": "The reviewer refers to 'instances' and 'modalities' in the context of Equation 3. While they don't explicitly state which instance or modality they are referring to, the context strongly implies they are pointing to the data being processed by Equation 3. The reviewer also specifies 'instances with good performance of modality A' and 'instances with good performance of modality B,' which adds a degree of specificity. However, the reviewer doesn't provide a precise section or table number where Equation 3 is located, making the grounding somewhat implicit.", "verifiability_rationale": "The reviewer makes a claim about Equation 3: 'Equation 3 directly removes the modal subset of all instances.' This claim is verifiable by examining Equation 3 (if provided in the paper). The reviewer also offers a potential solution: 'How to deal with the problem mentioned above.' While the solution itself isn't a citation, the claim about Equation 3 is verifiable. The reviewer's explanation of the problem is reasonably clear, but it doesn't provide a specific citation or example to support the claim about Equation 3.", "helpfulness_rationale": "The reviewer provides a clear and actionable feedback regarding a potential issue with Equation 3. They identify the problem ('Equation 3 directly removes the modal subset of all instances') and offer a constructive suggestion ('How to deal with the problem mentioned above'). The reviewer's feedback is directly related to a specific part of the paper (Equation 3) and provides a clear direction for improvement. The feedback is not just a general comment but a specific critique of a methodological aspect."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "X", "actionability_rationale": "The reviewer clearly states the confusion and points out specific inconsistencies ('sparse labels', unlabeled target domain notation). This directly indicates an explicit action that needs to be taken to clarify the method description. The reviewer identifies specific areas of confusion (use of source domain data, discrepancy with original paper). This directly indicates an explicit action that needs to be taken to clarify the method description. The reviewer provides clear information on what they found unclear, making this 5.", "grounding_specificity_rationale": "The reviewer struggles to understand the notation and the handling of source domain data. They don't explicitly state they cannot identify the referenced part, but the confusion indicates a lack of clear identification of the specific aspect being addressed. The reviewer doesn't point to a specific error in the method description, but the overall confusion about the problem setting makes it difficult to pinpoint a concrete issue within the method itself. While the reviewer *knows* there's a problem, they can't pinpoint exactly what's wrong.", "verifiability_rationale": "The reviewer's confusion about the discrepancy with the original paper makes it difficult to assess the verifiability of the information presented in the submitted paper. The reviewer is expressing uncertainty about the accuracy or completeness of the information. The reviewer's confusion about the discrepancy with the original paper makes it difficult to assess the verifiability of the information presented in the submitted paper. The reviewer is expressing uncertainty about the accuracy or completeness of the information. The reviewer's confusion about the discrepancy with the original paper makes it difficult to assess the verifiability of the information presented in the submitted paper. The reviewer is expressing uncertainty about the accuracy or completeness of the information.", "helpfulness_rationale": "The reviewer's confusion and lack of clarity about the method's description will likely hinder the authors' ability to understand and implement the method. This reduces the helpfulness of the review. The reviewer's confusion and lack of clarity about the method's description will likely hinder the authors' ability to understand and implement the method. This reduces the helpfulness of the review. The reviewer's confusion and lack of clarity about the method's description will likely hinder the authors' ability to understand and implement the method. This reduces the helpfulness of the review."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a *type* of analysis (epochwise) and *specific investigations* (batch size, sampling, deterministic/stochastic comparison). It doesn't explicitly tell the author *what* to do next. While it implies the value of such an analysis, it lacks specific instructions on how to implement it or what specific data to look for. Therefore, it's a 2 comment.", "grounding_specificity_rationale": "The review point is very general. It suggests *a type* of analysis but doesn't specify *which* part of the paper or analysis this should relate to. There's no mention of a specific section, table, figure, or unique element. The reviewer can't confidently identify the 'specific part\" they are referring to. Therefore, it's 1 at all.", "verifiability_rationale": "The review point clearly states a *position* or *suggestion*. It begins with \"I think...\" which indicates an opinion or judgment about the potential benefits of epochwise analysis. It also lists specific *investigations* which are suggestions. However, these suggestions are not supported by concrete evidence or logical reasoning within the review itself. They are more like hypotheses or directions for future work rather than verifiable claims. Therefore, it's not 5.", "helpfulness_rationale": "The review point offers a general direction for improvement and suggests investigating specific aspects of training, such as batch size and sampling strategies. It also proposes comparing deterministic and stochastic methods. These are all relevant and potentially helpful suggestions for the author to consider. While it doesn't pinpoint a specific error, it provides valuable insights and potential areas for further exploration. Therefore, it's 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a problem (difficulty distinguishing between two types of extreme speech) but does not explicitly state how to address it or provide concrete steps. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer states that the distinction between the two types of extreme speech is unclear but does not explicitly identify which part of the paper or specific section this refers to. The grounding is implied but not precise.", "verifiability_rationale": "The reviewer claims the distinction is unclear and provides an example, but they do not explicitly state *why* it is unclear or provide external references or logical reasoning to support this claim. The verifiability is weak as the reasoning is missing.", "helpfulness_rationale": "The reviewer raises a valid point about the clarity of distinguishing between the two types of extreme speech and provides a specific example. However, the comment is primarily a question and does not offer a concrete, actionable suggestion for improvement. It is helpful in identifying a need for clarification but not for providing a solution."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitation of sequential ensembling in the context of homomorphic encryption, identifying 'noise accumulation' as the issue. This directly points to a problem and its cause, making it actionable.", "grounding_specificity_rationale": "The reviewer mentions 'sequential ensembling' generally. While they identify a limitation, they do not explicitly pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. The issue of 'noise accumulation' is mentioned, but not the specific part of the sequential ensembling process that causes it. Therefore, the grounding is weak, and while the issue is specific, the reference is not precise enough to be fully specific.", "verifiability_rationale": "The reviewer states a limitation ('this limitation prevents the use of even single deep neural networks on homomorphically encrypted data') but does not provide any specific examples, references, or logical reasoning to support this claim. The statement is presented as a statement of fact without further justification or evidence.", "helpfulness_rationale": "The reviewer identifies a concrete limitation of sequential ensembling in the context of homomorphic encryption, specifically the problem of noise accumulation. This information is directly relevant to the authors and highlights a significant bottleneck in their potential approach. While it doesn't offer specific solutions, it clearly points to a major issue that needs addressing."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "3", "helpfulness_label": "High", "actionability_rationale": "The comment explicitly states the desired action: 'It would be good to include...'. This clearly indicates an intention to add a specific element to the graph. The phrasing is direct and prescriptive, indicating a clear action to be taken.", "grounding_specificity_rationale": "The comment explicitly refers to a specific part of the paper: 'the left graph in fig 3'. This is a clear and accurate identification of the location where the additional element should be included. The comment also specifies what should be included: 'the learning curve for a model without any mean teacher or pi regularization for comparison'. This clearly defines the desired visualization and its purpose.", "verifiability_rationale": "The comment presents a suggestion ('It would be good to include...') which can be interpreted as a claim that this addition would be beneficial. While the comment itself doesn't provide explicit justification for *why* this comparison would be helpful, the request implies a clear intention and a direct action. The benefit of including this comparison (to isolate the effect of mean teacher learning) is a logical inference, making it 3.", "helpfulness_rationale": "The comment directly suggests a concrete and actionable improvement for the authors: including a specific baseline in their graph. This is a clear and helpful suggestion that directly addresses a potential need for understanding the impact of different training strategies. The request is straightforward and provides a clear direction for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer directly asks a question about the relationship between equations, which is an explicit action. They are prompting the authors to clarify a specific aspect of their method.", "grounding_specificity_rationale": "The reviewer points out a lack of significant improvement in the results on the OfficeHome dataset. While they mention a specific dataset, the *reason* for the lack of significance is not explicitly stated. They are prompting the authors to explain this observation.", "verifiability_rationale": "The reviewer makes a claim about the lack of significant improvement in the results. However, they do not provide any evidence or justification to support this claim. The claim is stated without further explanation or reference to external sources.", "helpfulness_rationale": "The reviewer is trying to help the authors by pointing out a potential issue with their results and suggesting a clarification. They are asking a question and highlighting a lack of significant improvement. This is generally helpful, even if it might lead to further investigation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'some stateofthe art references are missing' and provides a specific example of a missing work, 'Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding'. This is an explicit action and concrete details on what is missing and how to apply the action by including the references.", "grounding_specificity_rationale": "The reviewer implicitly refers to the 'experiment of face recognition' but clearly specifies the type of missing information as 'stateofthe art references' and provides a concrete example of such a reference. While not explicitly pointing to a section or table, the context strongly implies a specific part of the paper is being addressed, making the grounding somewhat explicit. The specificity is high as the reviewer details the nature of the missing information and provides a specific example.", "verifiability_rationale": "The reviewer makes a claim that the missing references are relevant by stating that the cited work achieved a better result on a related benchmark (LFW). This claim is supported by the logical reasoning that better performing models on the same benchmark are generally considered stateoftheart. The external reference to the LFW results and the comparison to the paper's reported results provides sufficient evidence to support the claim.", "helpfulness_rationale": "The review point is 5 as it directly points out a clear weakness in the paper (missing relevant references) and provides a concrete suggestion for improvement (including these references). The reviewer also hints at a potential improvement in the results, which is valuable information for the authors. The suggestion is clear and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out two main issues. First, they state that the range of ID and OOD doesn't change much after sparsification (a potential action, but not explicitly stated as an action to be taken). Second, they highlight that Lemma 2's assumption is not well discussed and its implications for DICE are unclear (another potential action, but not explicitly stated as an action to be taken). While the reviewer identifies problems, they don't provide concrete steps on how to address them or implement the suggestions.", "grounding_specificity_rationale": "The reviewer refers to 'Lemma 2' and 'DICE' generally, but doesn't explicitly point to a specific section, table, or figure within the paper where these are discussed. While the context suggests they are referring to specific parts, the connection isn't immediately obvious or explicitly stated by the reviewer.", "verifiability_rationale": "The reviewer makes two claims: (1) the range of ID and OOD doesn't change much after sparsification, and (2) Lemma 2's assumption is not well discussed and its implications for DICE are unclear. Neither of these claims is explicitly supported by logical reasoning, common knowledge, or external references within the review point itself. The reviewer states observations that require further investigation or explanation, but doesn't provide any evidence to back up their claims.", "helpfulness_rationale": "The reviewer identifies potential issues with the method's robustness (the range not changing) and the lack of discussion around a key assumption (Lemma 2). These points could be helpful for the authors to understand limitations or areas for improvement. However, the reviewer doesn't offer concrete solutions or actionable steps, making the feedback somewhat vague and less directly helpful for immediate implementation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer is asking a question and making a suggestion, but does not propose a concrete action or improvement based on the identified issue. The suggestion is implied but not explicitly stated as an action to be taken.", "grounding_specificity_rationale": "The reviewer identifies the specific part of the paper being discussed as 'the update' and 'the formatting of bolded sections on page 6. This demonstrates a degree of grounding as the section is identified. However, the reviewer does not explicitly state that the update needs to cover all possible environments, making the grounding not fully specific to the environment issue.", "verifiability_rationale": "The reviewer makes a claim about the update likely needing to integrate over all possible environments. However, this claim is presented as a question and a suggestion for improvement, without providing any logical reasoning, common knowledge, or external references to support this assertion. The reasoning is based on the practical consideration of space, but lacks justification.", "helpfulness_rationale": "The review point primarily raises a question and suggests a formatting improvement. While the suggestion is valid, the review point itself does not directly critique the work being reviewed or identify a specific weakness that needs addressing. It is more of a suggestion for improvement rather than a critique of the work itself."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer provides a list of suggestions for improvement, which are direct and actionable. They suggest using default settings, including missing baselines, and addressing limitations. These are clear steps the authors can take to enhance their work.", "grounding_specificity_rationale": "The reviewer mentions 'position kernels' and 'BO baselines' as potential issues. While they identify specific terms, they do not explicitly state which part of the paper or experiment these issues relate to. For example, they don't specify which experiment or section is affected by the use of position kernels.", "verifiability_rationale": "The reviewer identifies areas where the paper lacks information or justification. They state that the experiments seem weak and suggest specific improvements. However, they do not provide specific evidence or references to support their claims about the experimental setup or missing baselines. They also do not explain why these are limitations.", "helpfulness_rationale": "The reviewer clearly identifies weaknesses in the paper's methodology and presentation. They suggest improvements like using default settings and including missing baselines. While these suggestions are valuable, the reviewer does not provide specific guidance on how the authors should implement these changes or what the expected outcomes would be. For example, they suggest using default settings but do not explain why the current settings are problematic or what the benefits of using defaults are."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states 'The derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4'. This directly identifies the missing element and the specific step in the derivation that needs attention. The action is clear: the authors should check their derivation and ensure the temperature dependence is correctly handled.", "grounding_specificity_rationale": "The comment explicitly refers to 'Eqn. 3 to Eqn. 4', which is a specific part of the paper. It also specifies the missing element as 'temperature \u03c4'. This demonstrates high grounding specificity as the authors can easily identify the referenced part and the specific issue within it.", "verifiability_rationale": "The comment contains a claim: 'The derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4'. However, within the review point itself, there is no explicit logical reasoning, external references, or examples provided to support this claim. The reviewer is stating their belief about the derivation based on their understanding of the context, but the evidence for this specific claim is not contained within this review point.", "helpfulness_rationale": "The review points out a specific potential error in the derivation (missing temperature parameter). This is a concrete piece of feedback that directly relates to the correctness of a physical model or calculation. Authors would likely find this helpful as they would need to investigate the derivation and ensure the temperature dependence is correctly handled. The feedback is specific and actionable."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "1 (1 and Not Specific)", "verifiability_label": "X (X)", "helpfulness_label": "4 (4)", "actionability_rationale": "The review point explicitly suggests an action (adding a citation) and provides a method (using an example like 2). While it doesn't pinpoint the exact location of the citation, it strongly implies it relates to the discussion of differential privacy.", "grounding_specificity_rationale": "The review point mentions 'differential privacy' and 'add a citation' without explicitly referring to a specific section, table, figure, or unique aspect of the paper. The suggestion is general and doesn't detail what needs to be added.", "verifiability_rationale": "The review point is a suggestion or recommendation ('It'd be useful to the reader to add a citation...') rather than a claim that something is incorrect or needs improvement. It doesn't make a statement that requires verification.", "helpfulness_rationale": "The review point provides a relevant and helpful suggestion by recommending the addition of a citation to the topic of differential privacy. This directly addresses a potential area for improving the paper's clarity and referencing."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two specific points of feedback. First, they critique the claim about 'significant additional assumptions' as being too extreme. While the reviewer identifies an action (critiquing the claim), the feedback itself doesn't explicitly state how to apply this critique or what the authors should do with this information. Second, the reviewer points out an error in the inequality on line 310. This is an explicit action (identifying an error) and the reviewer provides a specific location, making it 5.", "grounding_specificity_rationale": "The reviewer identifies the claim as being in 'Section 3.2' and specifically the 'first para of Section 3.2'. This is a clear and precise identification of the referenced part of the paper. The reviewer also identifies the specific error in the inequality on line 310, which further grounds the feedback.", "verifiability_rationale": "The reviewer critiques the claim about 'significant additional assumptions' as being too extreme. This implies a lack of justification for the claim, making it 1. The reviewer also identifies an error in the inequality on line 310, which is a clear and verifiable factual error. The critique of the claim, however, doesn't have a clear verification method.", "helpfulness_rationale": "The reviewer provides two specific points of feedback. First, they critique the claim about 'significant additional assumptions' as being too extreme. This is a valuable piece of feedback for the authors as it helps them understand the limitations of the methodology. Second, the reviewer points out an error in the inequality on line 310. This is a concrete error that the authors can easily correct. Both points are actionable and provide specific guidance to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies the presence of writing issues but lacks specific details on how to address them. It mentions 'grammatical errors' and 'abuses of mathematical symbols' as symptoms rather than problems to be solved. While it can be considered explicit in pointing out the issues, it lacks concrete steps for improvement, making it 2.", "grounding_specificity_rationale": "The review point makes a general statement about the paper's writing issues without specifying which part of the paper or which type of writing issue is being referred to. It doesn't identify a specific section, table, figure, or unique element of the paper as being affected.", "verifiability_rationale": "The review point makes a claim about the paper's writing issues but does not provide any evidence or justification for these claims. It states that the paper contains 'severe writing issues' without pointing to specific examples, external references, or logical reasoning to support this assertion.", "helpfulness_rationale": "The review point identifies the presence of writing issues but offers no specific suggestions or guidance on how to improve the paper. It lacks concrete actions or insights that would empower the authors to address the identified problems."}
{"actionability_label": "5", "grounding_specificity_label": "Fully Grounded and Specifically", "verifiability_label": "Partially Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states what they want (add untrained network results, clarify dotted lines, clarify normalization) and suggests a specific action (show random data examples). This is very explicit and the request to run experiments is concrete.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figures 3c and 3,' 'Table 1,' 'untrained networks,' and 'random data'. This demonstrates strong grounding. They also provides specific questions about the experimental setup, including whether the networks were trained on random data or if the dotted lines represent networks trained on unaltered data evaluated with random data. They also ask about the normalization process and suggest showing examples of the random data. This shows a high level of specificity in identifying the missing information.", "verifiability_rationale": "The reviewer is pointing out a lack of information in the current presentation of the results. They are not making a claim that *something is wrong* but rather highlighting a gap in the explanation of the presented data. Therefore, it's not 5 in the sense of identifying a flaw and providing evidence for it. However, it's more verifiable than a request for a completely new experiment.", "helpfulness_rationale": "This review point is extremely helpful as it directly addresses potential gaps in the experimental evaluation and encourages the authors to clarify crucial aspects of their methodology. The request to add untrained network results is a concrete action that can significantly improve the paper's completeness. The clarifications requested are essential for the authors to ensure the accuracy and clarity of their presentation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer's point is somewhat implicit. While they are asking a question about the meaning of '100 steps', the action they are pointing out is the lack of clarity in this definition. The reviewer could have explicitly stated that '100 steps' is unclear and what they *expect* it to mean (e.g., sampled strategies). The current phrasing focuses on the ambiguity itself.", "grounding_specificity_rationale": "The reviewer provides a section reference ('Search models comparison 5.1'), indicating they can identify the specific part of the paper where the ambiguity likely exists. However, they do not specify *what* is meant by '100 steps' within that context. The grounding is present, but the specificity regarding the meaning of '100 steps' is lacking.", "verifiability_rationale": "The reviewer is not making a claim that needs verification. They are asking a question about the meaning of a term within a specific section. Therefore, there is X to be supported or verified.", "helpfulness_rationale": "The reviewer is directly asking for clarification on a potentially important implementation detail of a search model comparison. This is a very specific and actionable request that would help the authors understand and potentially reproduce the results. The fact that they are seeking to understand *how* '100 steps' is defined makes this review 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests repeating experiments and conducting statistical significance analysis, which implies an action. However, the specifics of how to improve are vague. Actions are considered actionable if they are direct or apparent. While the reviewer suggests an action, it is not explicitly stated how to achieve this or what the specific limitations are. The action is implicit.", "grounding_specificity_rationale": "The reviewer mentions \"previous methods,\" \"Table 1 and Fig.5,\" and 'statistical significance,\" which can be interpreted as identifying specific parts of the paper. The reviewer also points out the *absence* of mean, standard deviation, and statistical significance analysis in the reported results. This indicates a clear identification of the specific issue within those parts. Grounding is considered full if the authors can accurately pinpoint the referenced part. The reviewer's mention of specific elements and the lack of statistical significance demonstrates a clear understanding of the relevant parts and the issues within them.", "verifiability_rationale": "The reviewer makes a claim about the results not reporting mean, standard deviation, and statistical significance. While the reviewer states this as a fact, there is no logical reasoning, common knowledge, or external references provided within the review point to *justify* why this is a valid concern. The claim is presented as an observation without further explanation or evidence. Verifiability is considered 5 if a claim is supported by logical reasoning, common knowledge, or external references. The reviewer's claim lacks these supporting elements within the review point itself.", "helpfulness_rationale": "The reviewer suggests repeating experiments and conducting statistical significance analysis, which is a clear and actionable suggestion. The reviewer also evaluates the impact of this suggestion, stating that the improvement is small and the lack of statistical significance makes it hard to know if the improvement is real. The reviewer provides a clear recommendation (reject the paper). Helpfulness is considered 5 if the review thoroughly identifies weaknesses and offers detailed, actionable, and constructive suggestions that empower the authors to significantly improve their draft. The reviewer provides a concrete suggestion and evaluates its potential impact, making the review quite helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the 'approach section' is missing. This is an explicit indication of where the method description should be. While the reviewer doesn't specify what is missing, the absence of this section is a concrete piece of information that authors need to address.", "grounding_specificity_rationale": "The reviewer implies that the 'approach section' should be in a specific part of the paper, likely where methods are typically described. While they don't explicitly name a section, the implication is that this section exists and is identifiable. This can be considered 'fully grounded' as the location is implied. However, the reviewer doesn't specify what is missing within that section, making it 'somewhat specific'.", "verifiability_rationale": "The reviewer's comment is a statement of fact: 'The approach section is missing in the main paper.' There is X being made or judgment being offered. Therefore, it's a normal statement. This means the verifiability score is 'X'.", "helpfulness_rationale": "The reviewer points out a significant structural issue: the absence of an 'approach section'. This is a crucial piece of information for understanding the methodology. Authors need to know where to find the details of how the work was done. This makes the review 5 as it directly addresses a fundamental aspect of the paper's presentation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the weakness in the introduction regarding the biological plausibility of backpropagation. They point out that the current statement is too general and lacks specific details. The reviewer suggests making the statement more concrete by specifying the exact nature of the biological implausibility. This provides a clear direction for the authors to improve their draft by addressing this specific point.", "grounding_specificity_rationale": "The reviewer not only identifies that the biological plausibility of backpropagation is discussed in the introduction but also specifies the exact location: 'While the backpropagation ..., its biological plausibility remains a subject of debate.' They further clarify that they understand the *content* being addressed, making it more than just '3'.", "verifiability_rationale": "The reviewer identifies a claim in the introduction: 'its biological plausibility remains a subject of debate.' They argue that this claim is verifiable because it is widely accepted that backpropagation is biologically implausible. While they don't provide a direct citation in this review point, the reasoning based on common knowledge makes it 'Partially Verifiable'.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the introduction and provides a specific suggestion for improvement. They point out that the statement about biological plausibility is too weak and suggest making it more specific. This is a direct and actionable feedback that helps the authors improve their draft by addressing this specific point."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a gap in the paper's argument regarding the connection between overparameterization, memorization, and generalization. While they don't explicitly state what action should be taken, their question implies a need for the authors to either strengthen their discussion on generalization or connect their findings to existing theoretical work on generalization bounds. The action is implied but not directly stated, making it partially actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'generalization bounds' and the 'constructions of ReLU networks for robust memorization' as areas where the paper's argument is unclear. They directly identify the specific part of the paper being addressed (generalization bounds and ReLU network constructions). This demonstrates high grounding specificity as the authors can accurately pinpoint the referenced concepts. The reviewer also implies a potential reason for the lack of connection, making it even more specific.", "verifiability_rationale": "The reviewer makes a claim about the paper's lack of connection between overparameterization, memorization, and generalization, specifically regarding generalization bounds. They also suggest a potential reason (the constructions of ReLU networks). This claim is verifiable as the paper does not explicitly address this connection or provide justification for why memorization in overparameterized networks wouldn't lead to better generalization. The reasoning, while present, is not explicitly stated as a justification for the lack of connection, making it 3.", "helpfulness_rationale": "The reviewer's comment is 5 because it directly points out a significant weakness in the paper's argument regarding generalization. They provide a specific area of concern (generalization bounds) and suggest a potential reason (constructions of ReLU networks for memorization). This is a very actionable and constructive suggestion for the authors to consider and address. The comment provides a clear direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the weakness of the OOD experiments and suggests a specific action: comparing the current method with untrained neural networks used for inverse problems. The reviewer also mentions 'Ideally, also compare', which further indicates a clear action to be taken. The action of comparing is directly tied to the identified weakness, making it actionable. The reviewer clearly states the desired improvement, which is a direct action.", "grounding_specificity_rationale": "The reviewer mentions 'OOD experiments' and 'inverse problems', which are specific concepts within the paper. While they don't explicitly name a section, table, or figure, they point to areas within the paper that are relevant. The reviewer also specifies the type of comparison they suggest ('untrained neural networks used for inverse problems'), which adds to the specificity of the feedback. The reviewer's comment is focused on specific areas and types of comparisons, indicating a degree of grounding and specificity.", "verifiability_rationale": "The review point clearly states a claim: 'It maybe good to mention this in the paper and place the current method in context and Ideally, also compare with those class of methods.' This is a subjective statement that suggests a comparison with untrained neural networks for inverse problems. However, the reviewer does not provide any specific examples, references, or logical reasoning to support this claim. The suggestion is presented as a suggestion, not a verifiable statement. The reviewer identifies a gap in the paper but doesn't provide evidence to fill that gap.", "helpfulness_rationale": "The review point identifies a relevant area for improvement (OOD generalization) and suggests a meaningful comparison with untrained neural networks. The reviewer provides a clear direction for the authors to take, which is helpful in guiding their work. The suggestion to compare is a concrete and actionable feedback, making the review point helpful in improving the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their belief that the proxlinear subproblem can be reformulated using the conjugate function and claims this alternative is more general, making the motivation of Algorithm 1 unclear. This is a direct and specific suggestion for improvement.", "grounding_specificity_rationale": "The reviewer directly refers to 'Eq.(1)', the 'proxlinear subproblem', and 'Algorithm 1', precisely identifying the parts of the paper they are commenting on. They also specify the nature of their criticism ('I believe that the proxlinear subproblem can be reformulated using the conjugate function...'). This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim about a potential reformulation of the proxlinear subproblem using the conjugate function. While the review point itself doesn't contain immediate mathematical proofs, the suggestion is specific enough that its verifiability could be assessed by examining the mathematical relationship between the proxlinear subproblem and the conjugate function in the context of stochastic optimization. The reviewer's claim about the alternative being 'more general' and 'making the motivation of Algorithm 1 unclear' are specific statements that can be verified through mathematical analysis or by examining the implications of the proposed reformulation.", "helpfulness_rationale": "The reviewer's point is not about fixing a bug or implementing a feature, but rather offering a constructive suggestion for improvement and clarification. They are pointing out a potential simplification and its implications for the motivation of an existing algorithm. This offers valuable insight for the authors and can help them understand the problem better and potentially improve their approach. While it might not be a direct solution, it's a valuable contribution to the discussion and can enhance the authors' understanding of the problem."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'can authors please throw light on why the performance degrades when using the additional information about missing/wrong/redundant?' This is an explicit request for explanation, making it actionable for the authors. The reviewer identifies the area of concern (FBN results, table 5) and the specific elements of the additional information (missing/wrong/redundant), adding detail to the request.", "grounding_specificity_rationale": "The reviewer refers to 'FBN results (table 5)' and asks about the impact of 'missing/wrong/redundant' information. This provides a specific reference point and identifies the elements being discussed, indicating strong grounding. The reviewer is directly addressing a part of the presented results.", "verifiability_rationale": "The reviewer states 'can authors please throw light on why the performance degrades when using the additional information about missing/wrong/redundant?'. This is a claim that needs verification. The reviewer provides the context ('FBN results (table 5)') and the specific elements of the additional information ('missing/wrong/redundant'), making the claim verifiable. However, the review point itself does not provide the evidence to verify this claim.", "helpfulness_rationale": "The reviewer's request to 'throw light on why the performance degrades' is a valuable piece of feedback for the authors. It directly addresses a potential issue or area for improvement identified in the results. While the request itself isn't a statement of fact, it clearly indicates a need for further explanation and is therefore helpful in guiding the authors' work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states two distinct issues: (1) the lack of clarity in the first two sections and (2) the unclear explanations of specific concepts (LSTM conversion and the phrase about hierarchical layers). This indicates a direct identification of problems and requests for clarification, making it actionable for the authors. While the actions are not fully concrete, the reviewer points to specific areas needing attention.", "grounding_specificity_rationale": "The reviewer directly refers to 'the first two sections,' 'line 43,' and 'line 96.' This explicit referencing clearly identifies the specific parts of the paper being addressed, indicating strong grounding. The reviewer also points to specific unclear concepts within these sections, further enhancing specificity.", "verifiability_rationale": "The reviewer doesn't present a claim that requires external verification. Instead, they are pointing out areas where the paper lacks clarity and explanation. While the 'impact' of these points on the authors' work is a form of implicit verification, the core of the comment is about identifying weaknesses in the presentation, not making assertions that need justification.", "helpfulness_rationale": "The reviewer provides specific examples of where the paper is unclear and asks targeted questions. This directly helps the authors understand and improve their work. The suggestions for clarification and further explanation are actionable and directly address potential weaknesses in the paper's presentation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'minimizing the averaged loss might not ensure the flatness of the minima.' This is a clear and direct criticism. The reviewer also provides a concrete next step for the authors: 'To claim that the minima found by minimizing the loss in Eq (3), the analysis on the losses of the noiseinjected models after training is required.' This indicates a clear action the authors should take. While the reviewer doesn't provide a *specific* method for minimizing the averaged loss, the implication is that the current method is insufficient for guaranteeing flatness. Therefore, the comment is actionable and points to a concrete area for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the loss used for training base model' and 'the noiseinjected models' when critiquing the claim about flat minima. They even refer to 'Eq (3)', which is a very specific reference. This clearly identifies the specific part of the paper being addressed. The reviewer also specifies what is missing: 'the analysis on the losses of the noiseinjected models after training is required.' This demonstrates a high level of grounding as the authors can easily identify the relevant section and the specific issue. The comment is not just general; it pinpoints the exact area where further analysis is needed.", "verifiability_rationale": "The reviewer makes a clear claim: 'minimizing the averaged loss across the noise injected models does not ensure the flatness of the minima.' This is a statement that can be verified. The reviewer also provides a potential verification method: 'To claim that the minima found by minimizing the loss in Eq (3), the analysis on the losses of the noiseinjected models after training is required.' This suggests a way to validate the claim by looking at specific results. The reviewer doesn't just state a problem; they also offer a concrete suggestion for how the authors could address it. This makes the claim verifiable through logical reasoning and a suggested experiment.", "helpfulness_rationale": "The reviewer's point is very clear and directly addresses a potential flaw in the paper's claims. They identify a specific area where the analysis is lacking and suggest a concrete next step for the authors. The reviewer doesn't just point out a problem; they also offer a clear and actionable solution. This makes the comment 5 for the authors in improving their draft. The suggestion is specific and directly related to the identified issue."}
{"actionability_label": "5", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states actions the authors should take, such as 'improve this presentation' and 'add breakout diagrams showing the attention mechanisms'. These are direct instructions on how to modify the draft.", "grounding_specificity_rationale": "The reviewer refers to 'section 4' and 'attention mechanisms' within that section, providing a general area for improvement. However, they don't specify *exactly* which sentence or paragraph in section 4 needs improvement, nor do they pinpoint *which specific* attention mechanism within that section is problematic. The suggestion is for *what* to add (diagrams) rather than *where* in the existing text.", "verifiability_rationale": "The reviewer does not make any claims or judgments about the model. They are suggesting improvements in presentation and adding visualizations. There is X that something is '1 at all', '2', '3', or '4' or '5'. The suggestion is about how to present the model better, not about verifying something about the model itself.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, including concrete examples like adding notation and diagrams. These suggestions are directly actionable and likely to be beneficial for the authors in understanding and improving their model description."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states they don't understand the red line, which is an action. However, the specifics of what they don't understand are not provided, making it somewhat vague. Therefore, it's an explicit but somewhat vague action.", "grounding_specificity_rationale": "The reviewer directly mentions 'Figure 3', indicating they can identify the specific part of the paper being addressed. They then ask a question about the content of this figure, further specifying what they need to understand. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim by stating they don't understand the red line. The paper, as presented, does not provide any evidence or explanation to support this claim. Therefore, the claim is 1 within the provided text.", "helpfulness_rationale": "The reviewer's comment is a direct request for clarification on a specific element of the paper. This highlights a potential weakness in the paper's presentation and is very relevant to the reader's understanding. While it doesn't directly suggest improvements, it points out a lack of clarity, which is a valid weakness. Therefore, it is 3 in identifying a need for better explanation."}
{"actionability_label": "4", "grounding_specificity_label": "3: 4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing comparison to existing DAS earthquake detectors and suggests clarifying the claim about the foundation model. These are direct and actionable suggestions for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'existing DAS earthquake detection models' and suggests clarifying the claim about a foundation model. This points to specific areas within the paper that need attention, making the grounding specific.", "verifiability_rationale": "The reviewer provides specific suggestions for what the authors should do, such as 'comparing your method to PhaseNetDAS and other relevant DAS models' and 'clarifying whether the goal is to develop a foundation model or a specific earthquake detector'. These suggestions are logical and verifiable.", "helpfulness_rationale": "The reviewer provides concrete suggestions for improvement, including comparing to existing methods, clarifying the goal, and demonstrating future applications. These suggestions are directly actionable and address potential weaknesses in the paper's framing or evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification on discrepancies between tables and requests ablation studies. While it doesn't explicitly state an action to be taken, it points to a potential issue in the results and asks for further analysis of a specific component. The reviewer is seeking to understand the cause of the discrepancy and the impact of removing adaptive metrics. This is somewhat implicit actionability as the reviewer is prompting the authors to investigate these aspects.", "grounding_specificity_rationale": "The review point explicitly mentions 'Table 6' and 'Table 1' and 'MCTpair' and 'MCT without the adaptive metrics'. This indicates strong grounding as the reviewer is directly referring to specific parts of the paper and a specific method. The request is very specific about the location of the information needed.", "verifiability_rationale": "The review point is a request for information rather than a claim that needs verification. It doesn't present a statement that requires justification or evidence. The request is for the authors to provide data or analysis, not for the reviewer to evaluate the validity of a claim. Therefore, it doesn't fit the criteria for verifiability.", "helpfulness_rationale": "The review point is asking for clarification on a discrepancy between tables and for specific ablation studies. While it doesn't directly provide a solution, it highlights potential issues in the results and requests further analysis of a specific component. This can be helpful for the authors as it encourages them to investigate these aspects and potentially identify errors or areas for improvement. The request is clear and directly related to the authors' work, making it 3 in identifying areas needing attention."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests adding AccNet as part of a larger predictor. This is a direct and actionable suggestion, providing a clear direction for improvement. The reviewer proposes a specific experiment (including AccNet in a larger predictor for semantic segmentation) and mentions 'similar operators,' indicating a concrete implementation idea. This falls under explicit and concrete suggestions.", "grounding_specificity_rationale": "The review point uses specific terminology to refer to the proposed improvement. The reviewer mentions 'AccNet,' 'larger predictor,' 'semantic segmentation,' and 'similar operators.' These terms are directly relevant to the paper's focus and the suggested modification. The reviewer does not need to infer which part of the paper is being addressed; the terms themselves point to the specific area of improvement. This indicates strong grounding as all key elements are explicitly mentioned.", "verifiability_rationale": "The review point suggests an experiment (including AccNet in a larger predictor) and provides a reason for this suggestion ('similar operators'). While the suggestion itself is a hypothesis and not a definitive statement, the reasoning behind it is clear and based on a specific detail ('similar operators'). This makes the suggestion 3, as it proposes a testable idea based on a connection to existing work. The reviewer is not just stating a possibility but offering a concrete direction for future research.", "helpfulness_rationale": "The review point is 5 as it directly addresses a potential area for improvement by suggesting a specific experiment (including AccNet in a larger predictor for semantic segmentation). The reviewer provides a clear context ('semantic segmentation') and a reason for the suggestion ('similar operators'), indicating a relevant and actionable direction. This feedback is likely to be valuable for the authors in exploring new model architectures and potentially improving performance in the semantic segmentation task. The suggestion is not vague or general but rather concrete and focused."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out specific instances where the paper lacks clarity and provides actionable suggestions. For example, they suggest defining the abbreviation 'NE' and clarifying the superscript notation in Equation 6. These are concrete actions the authors can take to improve their work.", "grounding_specificity_rationale": "The reviewer explicitly mentions the location of the undefined abbreviation 'NE' (line 73) and the equation with unclear notation (Equation 6). This precise identification of the problematic section demonstrates strong grounding specificity, as the reviewer clearly identifies the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer makes claims about the paper, such as stating that 'Some abbreviations are not defined' and 'Superscript notation in Eq 6 is not defined until much later'. These claims can be verified by examining the paper itself. The lack of definition for 'NE' and the unclear superscript notation are verifiable issues within the paper.", "helpfulness_rationale": "The reviewer provides specific criticisms and suggests a concrete improvement ('improve clarity'). By pointing out these specific issues, the reviewer guides the authors on what needs to be addressed. The suggestion to improve clarity is a helpful direction for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit information about the Walkman algorithm's relation to ADMM and critiques the paper's generalization about SGDbased algorithms. It also suggests improving clarity in a specific section, which is an explicit action. While the suggestion is general, the identification of the issue is concrete.", "grounding_specificity_rationale": "The review point explicitly mentions the 'Walkman algorithm (Mao et al., 2020)' and details its relation to ADMM. It also refers to 'the SGDbased Algorithm 1' in the context of Section 3. This provides strong grounding to specific parts of the paper and the concepts being discussed.", "verifiability_rationale": "The review point contains claims that can be supported. For the Walkman part, the reviewer provides specific details about ADMM versions, which can be verified. For the Section 3 part, the reviewer points out a lack of clarity, which can be verified by examining the referenced section. However, the suggestion to improve clarity is not verifiable with external evidence.", "helpfulness_rationale": "The review point provides specific information that directly addresses a potential misunderstanding regarding the Walkman algorithm and its relation to ADMM. This is a 5 comment as it points to a concrete issue. The suggestion to improve clarity in Section 3 is also helpful, as it identifies a necessary improvement, although it lacks specific details."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem with the dev set usage and suggests a specific improvement (presenting average results on the test set with error bars). This indicates a clear action the authors should take.", "grounding_specificity_rationale": "The reviewer refers to 'Tables 1 and 2', 'dev set', 'test set', and 'random seeds'. While they don't explicitly name sections or figures, they clearly identify the parts of the paper and the experimental procedure. However, they don't specify the exact format of the error bars or the specific random seeds, making the grounding somewhat implicit.", "verifiability_rationale": "The reviewer makes a claim about the inadequacy of dev set evaluation and suggests a standard improvement in experimental reporting. This claim is supported by logical reasoning and common knowledge in machine learning, making it 5.", "helpfulness_rationale": "The reviewer provides a clear and actionable critique of the experimental setup and suggests a concrete improvement. This directly benefits the authors by guiding them towards better evaluation practices."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer asks for the number of topics used, which is a direct question about a parameter. While the paper should specify this, the reviewer is looking for explicit information on how this number was determined or if it was a hyperparameter. The request for 'how did you get topicword parameters' is more about the methodology than a direct action. The request for the dataset size is about specific numbers, which is more actionable. The reviewer is looking for information on how the parameters were obtained and the size of the dataset, which are all actionable and grounded. The helpfulness comes from the fact that this information is crucial for understanding and reproducing the experiments.", "grounding_specificity_rationale": "The reviewer asks 'How did you get topicword parameters for this \"real\" dataset?'. This is a request for a process and explanation. The paper should explain *how* these parameters were derived, including the specific method used and any justifications. The request for the dataset size is about specific numbers, which is more grounded. The helpfulness comes from the need for clear and detailed explanations of parameter derivation and dataset specifics for reproducibility.", "verifiability_rationale": "The reviewer asks 'How many topics were used? How did you get topicword parameters for this \"real\" dataset? How big is the AG news dataset?'. These questions all ask for information that should be verifiable from the paper. The number of topics, the method for obtaining parameters, and the dataset size should all be explicitly stated or derivable from the paper's content. The helpfulness comes from the need for verifiable information to understand and reproduce the experiments.", "helpfulness_rationale": "The reviewer asks 'How many topics were used? How did you get topicword parameters for this \"real\" dataset? How big is the AG news dataset?'. These are all direct requests for information that is crucial for understanding the experimental setup and methodology. The number of topics is a key parameter. The method for obtaining parameters is important for understanding the model. The dataset size is essential for understanding the scale of the experiment. The helpfulness comes from the fact that this information is directly requested and is essential for understanding and reproducing the experiments."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need to 'train a discriminator on generations from the learned model' to confirm the claim of reducing exposure bias, mimicking the approach in Figure 1. This is a clear and direct action to be taken.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'training a discriminator' and compares it to the approach in Figure 1. They also highlight the difference from Figure 4. This clearly identifies the specific part of the paper being addressed and provides specific details on what needs to be done.", "verifiability_rationale": "The reviewer proposes a method for evaluation ('train a discriminator') and points out a potential issue ('it might get stuck at a local optimum' during coadaptation). While the suggestion is a claim, the justification for the coadaptation concern is not explicitly supported by evidence or references within this review point itself. The reasoning is based on general knowledge of training dynamics rather than specific analysis within the paper.", "helpfulness_rationale": "The reviewer suggests a specific evaluation method ('train a discriminator') which directly relates to validating the paper's claim about reducing exposure bias. This provides a clear direction for the authors. However, the reviewer also raises a potential issue ('it might get stuck at a local optimum') which could hinder the effectiveness of the proposed method. While the suggestion is helpful, the awareness of a potential limitation makes it slightly less impactful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the problem and its location (Tables 6, 7), making the action somewhat explicit. However, the specific action needed to address the disorganization is not clearly defined, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly names 'Table 6, 7,' indicating strong grounding. They also describes the issue within these tables ('not wellorganized' and 'sentences squeeze together'), which is quite specific.", "verifiability_rationale": "The review point describes a factual observation ('the prompts are not wellorganized') and does not make a claim that requires external verification or logical reasoning. It's more of a statement of fact than a claim that needs justification.", "helpfulness_rationale": "The review point identifies a valid issue (disorganized prompts) but does not offer any specific suggestions or actions to improve it. It is more of a critique than a helpful suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the figures are 'not clear' and provides a specific example ('figure 2, it\u2019s confused for the relation of 3 subfigures'). This is an explicit statement of a problem. Furthermore, the reviewer points out the missing elements ('labeled modules'), which are concrete actions the authors should take. The reviewer's suggestions are direct and actionable, indicating a clear understanding of what needs to be improved.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'figure 2' and further specifies the issue by referring to the 'relation of 3 subfigures' and the 'labeled modules'. This demonstrates a strong grounding of the issue in a specific part of the paper and a clear identification of the problematic elements within that part. The reviewer provides concrete information about the exact location and nature of the problem.", "verifiability_rationale": "The reviewer states a problem ('figures are not clear') and offers suggestions ('try to understand the relationship between the subfigures and identify and label the missing modules'). While the reviewer does not provide external references to support the claim of figures being unclear, the suggestions are directly actionable and provide a clear direction for improvement. The reviewer implies that better labeling and understanding of the subfigures will improve the clarity of the figures, making the claim somewhat inferable but still verifiable through practical application.", "helpfulness_rationale": "The reviewer clearly identifies a problem with the figures ('not clear') and provides specific suggestions for improvement ('try to understand the relationship between the subfigures and identify and label the missing modules'). These suggestions are directly actionable and immediately helpful to the authors in addressing the identified issue. The reviewer's feedback is focused and provides a clear path for the authors to rectify the problem, making the review 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'Some questionable design choices' and then lists specific concepts ('perplexity,' 'catastrophic forgetting,' 'domain drift'). This is an explicit statement of issues. However, the reviewer doesn't specify *which* design choices are questionable or how they are questionable. The action of identifying issues is clear, but the lack of specificity makes it less actionable. The reviewer also suggests 'How are such factors controlled?' but doesn't provide specific methods or actions to take. The action is present, but the lack of detail makes it somewhat vague.", "grounding_specificity_rationale": "The reviewer states 'Some questionable design choices' and then lists specific concepts ('perplexity,' 'catastrophic forgetting,' 'domain drift'). While the reviewer mentions these concepts, they don't explicitly identify the *specific* part of the paper or model where these issues arise. The reviewer doesn't mention a specific section, table, figure, or unique element of the paper being addressed. The criticism is general and doesn't pinpoint the exact location of the problem. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim: 'How are such factors controlled?' This claim is not verifiable because the reviewer doesn't provide any specific information or references on how to control for domain drift or address the other mentioned factors. The criticism is about the methodology and interpretation of perplexity, but it doesn't offer any concrete solutions or alternative approaches. The claim is present, but the lack of supporting evidence or solutions makes it less verifiable.", "helpfulness_rationale": "The reviewer raises valid concerns about the methodology and the interpretation of perplexity as a sole indicator of semantic retention. They point out the possibility of domain drift. However, the review stops short of providing concrete solutions or specific recommendations for improvement. The criticism is more about identifying potential flaws in the analysis approach rather than directly suggesting actionable steps to fix the model or the analysis. While the criticism is relevant, it doesn't offer direct guidance to the authors on how to improve their draft. Therefore, it is 3 in identifying areas for improvement in the analysis but less directly helpful for providing concrete improvement suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the 'lack of details' in the Related Work section and provides concrete examples of what those details should include, such as 'sparseattention mechanisms 1, 2' and 'segmentationbased approaches 3, 4, 5'. This clearly indicates an expectation for the authors to address these specific methods and their limitations. The reviewer is not merely pointing out a general deficiency but specifying the nature of the missing information.", "grounding_specificity_rationale": "The reviewer mentions specific methods and their limitations by name (1, 2, 3, 4, 5, 6, 7). This indicates a strong grounding of the feedback in the potential content of the Related Work section. Furthermore, the reviewer specifies the *types* of methods and *what to discuss* (limitations of longcontext models, details of sparse attention, etc.). This level of specificity is quite high.", "verifiability_rationale": "The reviewer makes a claim that the Related Work section is 'lacking details' and provides specific examples of what those details should be. While the reviewer doesn't explicitly cite specific papers within the review itself to support this claim, the examples provided (sparse attention, segmentation) are wellestablished concepts in the field. The claim is somewhat supported by common knowledge and the examples provided, making it 3.", "helpfulness_rationale": "The reviewer provides a clear and actionable feedback on the Related Work section. They identify a specific area (lack of details) and suggest concrete improvements (discuss specific methods and their limitations). The reviewer's tone is constructive and directly points the authors in a specific direction for improvement. The suggestions are directly tied to the identified problem."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment is a general statement about the need for improvement rather than specific instructions on what to do. It lacks the 'how' and 'what to do' components required for actionability.", "grounding_specificity_rationale": "The comment doesn't pinpoint a specific section or element of the paper as being unclear. The phrase 'some points' is too broad and lacks specificity.", "verifiability_rationale": "There is no explicit claim being made. It's a suggestion, not a statement that requires verification.", "helpfulness_rationale": "The comment is a positive statement but lacks concrete details. It doesn't tell the author *which* parts are unclear or *how* to improve them, thus offering no actionable value."}
{"actionability_label": "2", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a potential issue ('poor writing and annotations') but does not explicitly state what needs to be done to address it. It implies the writing and annotations are unclear, but lacks a direct action for the author.", "grounding_specificity_rationale": "The comment is very general and does not specify which part of the paper is experiencing the issue ('poor writing and annotations are a little hard to follow'). It lacks a clear reference to a specific section, table, figure, or unique element of the paper.", "verifiability_rationale": "The comment is a statement of observation ('Poor writing and annotations are a little hard to follow') rather than a claim that requires justification or evidence. It does not present a judgment or suggestion that needs backing.", "helpfulness_rationale": "The comment identifies a potential problem (poor writing/annotations) but does not offer a solution or guide the author on how to address it. It points out an issue without providing actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a weakness in the literature (that only 8/14 evaluation metrics achieve SOTA) and asks a question about the discrepancy in F1 scores. While the weakness is valid, the question itself doesn't directly suggest an actionable improvement for the authors' work. The reviewer doesn't explicitly state an action or suggest how the authors should address the observed performance differences. The weakness is more of a contextual observation than a direct call for action.", "grounding_specificity_rationale": "The reviewer mentions the 'Twitter2017 $\rightarrow$ Twitter2015' setting and the discrepancy between 'best overall F1' and 'not best F1 in all single types'. This clearly identifies a specific part of the paper (the evaluation setting and the F1 scores) and specifies the issue. The reviewer provides the context of the specific setting and the observed performance difference, making it grounded and specific.", "verifiability_rationale": "The reviewer presents a claim about the discrepancy in F1 scores. This claim could potentially be supported by examining the confusion matrix or detailed performance breakdowns, which are common methods for verifying claims about performance metrics. However, the reviewer doesn't provide the specific data or reasoning to verify this claim within the provided text. The claim is stated, but the supporting evidence is missing from the review point itself.", "helpfulness_rationale": "The reviewer's point is partially helpful. The question about the discrepancy in F1 scores directly addresses a potential area of concern for the authors and encourages them to investigate further. While the first part of the comment is a statement about the field, the second part is a question that prompts action and analysis. The reviewer identifies a specific issue (the discrepancy in F1 scores) and asks why it exists, which is a valuable piece of feedback for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The statement is somewhat explicit as it directly relates the proposed solution to Guzman et. al.'s work. However, it lacks concrete details on how the solution is 'incremental' or what the 'minor suggestions' entail. The action of acknowledging the work is clear, but the subsequent actions are vague.", "grounding_specificity_rationale": "The comment mentions 'Guzman et. al.' which can be considered a weak grounding as it identifies the author of the work being referenced but doesn't pinpoint a specific section, table, figure, or unique aspect. The comment also refers to 'the proposed solution' which is a general reference and doesn't specify a particular part of the paper being addressed. Therefore, it is 2.", "verifiability_rationale": "The comment does not contain a claim. It is a statement of observation or critique. Therefore, it is not verifiable as it lacks a statement that requires evidence or justification.", "helpfulness_rationale": "The comment is not helpful because it does not provide actionable feedback or suggest concrete improvements. It simply states that the proposed solution is an incremental step, which is a negative observation rather than a constructive suggestion. The lack of specific details makes it unhelpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests improvements in the presentation of results, but does not explicitly state what specific action the authors should take. While the suggestions are helpful, they lack a clear, direct action for the authors to follow.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 2 and 3', which is a specific reference to the paper. They also point out issues with the yaxis label ('performance' is ambiguous) and the missing runtime in these figures. This provides clear grounding to the specific parts of the paper and the issues being addressed.", "verifiability_rationale": "The reviewer makes specific claims about the results presentation. They state that the yaxis label is 'ambiguous' and that 'runtime is not represented' in the figures. These claims are verifiable by examining the figures themselves.", "helpfulness_rationale": "The reviewer offers suggestions for improving the clarity and effectiveness of the results presentation. While the suggestions are valuable, they are somewhat general and could benefit from more specific guidance on what changes the authors should make. Therefore, the helpfulness is somewhat high."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the concern about the Unsupervised Online Adaptation setting and clearly identifies the issue: the requirement of a training set with documents, quires and labels, which implies annotations. The reviewer also offers a potential explanation, indicating a desire for clarity. This is a direct and constructive attempt to improve the draft by pointing out a potential issue with the experimental setup.", "grounding_specificity_rationale": "The reviewer refers to 'Sec 3.1' to explain the training data, indicating an attempt to ground the comment in the paper's structure. However, the explanation itself is not explicit. The reviewer implies that Sec 3.1 describes the training data containing documents, quires, and labels, but they do not explicitly state 'Section 3.1 describes the training data'. This makes the grounding implicit.", "verifiability_rationale": "The reviewer makes a claim that the Unsupervised Online Adaptation setting is 'not unsupervised' because the training set requires annotations. This is a claim that needs to be supported. However, the reviewer does not provide any external references or logical reasoning to back up this claim within the provided text. The explanation is based on the reviewer's interpretation of the training data description in Sec 3.1, not a direct quote or logical deduction from the text itself.", "helpfulness_rationale": "The reviewer raises a valid point about the potential supervised nature of the Unsupervised Online Adaptation setting. They identify the key issue: the requirement of a training set with annotations. While the reviewer attempts to provide context by referencing Sec 3.1, they do not explicitly state that Sec 3.1 describes the training data. Furthermore, the reviewer does not provide any evidence or logical reasoning to support their claim that the process is 'not unsupervised'. This lack of verifiability makes the comment less impactful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies the presentation of results as 'convoluted' and states that 'safety violations of the agent in the first 1000 episodes were disregarded.' While the comment points to specific information, the assessment of 'convoluted' is subjective. The disregarded safety violations are actionable, but the degree of 'convolutedness' is not. The comment identifies an issue and suggests an improvement (making the presentation clearer), but the suggestion is vague.", "grounding_specificity_rationale": "The comment explicitly mentions 'safety violations of the agent in the first 1000 episodes' within the results section. This clearly grounds the criticism to a specific part of the paper. However, the comment does not specify what is meant by 'convoluted' or why the safety violations were disregarded. The criticism is specific about the location of the issue but underspecified regarding the nature of the problem and the proposed solution.", "verifiability_rationale": "The comment contains a claim that 'safety violations of the agent in the first 1000 episodes were disregarded.' However, it does not provide any justification or evidence for this claim. The comment also states that the results are presented in a 'convoluted way,' which lacks verifiable support. The claim about disregarded safety violations is supported by the comment itself, but the claim about the convoluted presentation is not.", "helpfulness_rationale": "The comment identifies a potential issue with the presentation of results and suggests making it clearer. However, it does not explain why the safety violations in the first 1000 episodes were disregarded or what the implications of this omission are. The comment lacks a clear explanation of the problem and how the suggested change will address it. The lack of justification for the claim about disregarded safety violations makes the comment unhelpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that there are 'writing errors' and provides specific examples like 'informative informative' and 'performance' lacking a title. While the reviewer identifies the *type* of error, they don't explicitly state *how* to correct them or *where* in the document these errors are located (e.g., on a specific line or paragraph). The action of identifying the errors is clear, but the lack of concrete steps for correction makes it partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'page 5' and 'page 1' when pointing out the writing errors. This clearly identifies the specific sections of the paper where the issues are located. However, the reviewer does not specify the exact words or sentences that need correction, nor does they point to any particular tables or figures. Therefore, the grounding is weakly specific, as it identifies the page but not the exact element within the page.", "verifiability_rationale": "The reviewer makes a claim that there are 'writing errors' in the paper and provides specific examples like 'informative informative' and 'performance' lacking a title. These examples serve as evidence to support the claim about the quality of the writing. The claim is based on observable issues and the provided examples are concrete evidence. Therefore, the claim is verifiable.", "helpfulness_rationale": "The reviewer points out specific writing errors and suggests that the authors should correct them. Identifying and correcting writing errors is a common and generally helpful form of feedback for authors, as it directly addresses issues that can affect the clarity, professionalism, and readability of the paper. The reviewer's comment is actionable and directly addresses a common concern in academic writing. Therefore, the review point is 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the difference between the standard sigmoid and the one used in URNNs, which can be considered an explicit action. However, it doesn't provide concrete steps on how to implement or apply this difference. The suggestion to elaborate on Theorem 4.1 is implicit, as it doesn't directly state 'You should elaborate on Theorem 4.1'.", "grounding_specificity_rationale": "The comment explicitly mentions the 'standard sigmoid' formula and refers to 'Theorem 4.1'. It also names the components being compared ('RNN' vs. 'URNN') and the relevant concept ('maximum slope'). This indicates a strong grounding of the parts being addressed.", "verifiability_rationale": "The comment makes a claim: 'Theorem 4.1: Would be useful to elaborate a bit more in the main text why this holds (intuitively, since the RNN unlike the URNN will converge to the nearest FP)'. It provides a reason (convergence) for why elaborating might be useful. It also suggests how it might be elaborated (intuitively). This makes it 4.", "helpfulness_rationale": "The comment points out a specific detail that could be important for understanding the behavior of URNNs. It highlights a potential point of confusion for someone not deeply familiar with the nuances of sigmoid functions in RNNs. While it doesn't provide a direct solution, it prompts the author to consider an important aspect of their model. This makes it 3 as it identifies a potential area for clarification."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point describes the process of planbased methods but does not provide a direct action or suggestion for the authors to take. It highlights a limitation of the method rather than offering a solution.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 2' when discussing the planbased method, indicating a clear reference to a specific part of the paper. They also point out a specific issue ('may be difficult to generalize...') related to this grounding.", "verifiability_rationale": "The review point states a limitation ('The proposed method may be difficult to generalize...') but does not provide any logical reasoning, examples, or references within the review point to support this claim. It is presented as a statement of a problem rather than a verifiable claim.", "helpfulness_rationale": "The review point identifies a potential limitation for the authors regarding the method's reliance on ground truth for plan design. However, it does not offer any concrete solutions or alternative approaches to address this limitation. It presents a problem without providing constructive feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a discrepancy: 'It appears that in nearly all experiments, the results are reported for a single heldout test set.' It also suggests an alternative: 'Standard practice in most papers on GPs involves using a number of train/test splits or folds which give a more accurate illustration of the method\u00e2\u0080\u0099s performance.' This clearly identifies a potential improvement and provides a suggestion.", "grounding_specificity_rationale": "The review point is a general statement about experimental practices in the field of Gaussian Processes. It does not specify which part of the paper the authors are referring to or what specific issue within the paper this relates to. The comment is about a general practice, not a specific element within the paper.", "verifiability_rationale": "The review point contains a claim: 'Standard practice in most papers on GPs involves using a number of train/test splits or folds which give a more accurate illustration of the method\u00e2\u0080\u0099s performance.' This claim is based on common knowledge within the field of Gaussian Processes. While it doesn't provide specific citations, it is a generally accepted practice. The reviewer is making a statement about what is typically done, which can be considered verifiable through common knowledge in the field.", "helpfulness_rationale": "The review point points out a deviation from standard practice in the field of Gaussian Processes. While it might not be definitively wrong for *this specific paper*, it highlights a common practice and suggests a more robust evaluation approach. It guides the authors towards a more common and potentially more robust evaluation approach, which can be helpful for improving their draft by aligning with broader standards."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point is a question and a suspicion, not a direct statement of an action to be taken. While the suspicion hints at a potential improvement, it's not explicitly stated how to address it.", "grounding_specificity_rationale": "The review refers to the 'method' in general, without specifying which part or aspect of the method is being discussed. There is no clear identification of a specific section, table, figure, or unique element of the paper being addressed.", "verifiability_rationale": "The review contains a claim: 'One would suspect that there is an underlying, simpler, principle that is propulsing the quality gains.' This is a statement of opinion and a potential explanation. However, it lacks specific justification or examples to support this suspicion.", "helpfulness_rationale": "The review raises a relevant point about potential overcomplexity and suggests a simpler underlying principle. However, it does so through a question and a suspicion rather than a direct, actionable suggestion. The authors are left to interpret the implications rather than being given clear guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3: Partially Grounded", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly points out a potential issue with the algorithm's implementation (using s_t instead of s_n) and raises two questions about the method's theoretical properties and empirical evaluation. While it doesn't directly state what to do, it identifies areas for improvement. The questions about asymptotic performance and average return with more environment steps are implicit suggestions for improvement, guiding the authors to investigate further.", "grounding_specificity_rationale": "The reviewer refers to 'Algorithm 1 Line 8' which grounds the initial part of the comment. However, the subsequent questions about asymptotic performance and average return with more environment steps are not directly tied to a specific section or element of the paper. The questions are more general inquiries about the method's properties and experimental setup.", "verifiability_rationale": "The comment contains claims regarding the potential error in the algorithm's implementation and requests for information about asymptotic performance and experimental results. The potential error is a claim that could be verified by checking the algorithm's implementation. The requests for asymptotic performance and average return with more environment steps are valid questions that can be addressed by referencing the paper's theoretical analysis and experimental setup, respectively.", "helpfulness_rationale": "The review points out a potential implementation detail and asks for information that is standard practice in academic research. The questions about asymptotic performance and average return with more environment steps are valuable requests that can guide the authors to further investigate and validate their method. While it doesn't directly provide a solution, it identifies areas where the authors can improve their understanding and reporting."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point contains an explicit action ('force the neural network to memorize them'), but the reviewer does not specify how this should be achieved or what the implications are. The action is somewhat vague, making it partially actionable but not fully concrete. The grammatical error suggestion is actionable, but the 'memorize' part is vague.", "grounding_specificity_rationale": "The reviewer refers to 'a critical point' in TopoNet 24, but the specific part of the paper being addressed is not explicitly identified. The reference to the paper is present, but the exact location or nature of the issue is not clearly pinpointed. The grammatical error suggestion is specific, but the 'memorize' part is not. The wordiness comment is general.", "verifiability_rationale": "The reviewer makes a claim ('neural network does not memorize an exact \"critical point\" as such in TopoNet 24'). This claim could potentially be supported by external references or logical reasoning. However, the reviewer does not provide any specific examples, references, or logical justifications within the review point itself. The grammatical error suggestion is verifiable as a factual statement. The wordiness comment is a general observation.", "helpfulness_rationale": "The review point offers some suggestions, such as 'force the neural network to memorize them' and 'tone down this statement'. However, the 'memorize' part is vague and lacks specific guidance. The grammatical error suggestion is helpful and specific. The wordiness comment is a general suggestion. Overall, the feedback is 3 but lacks specific actionable details in some parts."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential point of confusion for the authors regarding the definition of uncertainty. While the reviewer identifies a lack of clarity, the action is somewhat explicit in stating 'The uncertainty is defined based on the posterior distribution.' However, the reviewer doesn't specify *exactly* where this ambiguity lies within the paper's description of the posterior distribution. For example, is the issue with the mathematical definition, the interpretation, or the connection to model parameters? Without pinpointing the exact location, the action is not as concrete as it could be.", "grounding_specificity_rationale": "The reviewer explicitly states 'The uncertainty is defined based on the posterior distribution.' This directly identifies the section or concept being referenced, indicating a degree of grounding. However, the reviewer does not specify *which* part of the paper this refers to (e.g., a specific section, table, or figure). While the concept of the posterior distribution is welldefined, the lack of a precise reference point makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer provides a detailed explanation of how uncertainty is often understood in Bayesian contexts, linking it to the prior, likelihood, and posterior distributions. This explanation logically supports the conventional understanding of posteriorbased uncertainty. The reviewer is not introducing a new concept or requiring external references to understand their point. The reasoning is clear and aligns with established statistical principles. Therefore, the claim is wellsupported.", "helpfulness_rationale": "The reviewer offers a clear and detailed explanation of a concept that is likely to be confusing for the authors. They provide a Bayesian perspective on uncertainty, explaining the role of the prior, likelihood, and posterior. This explanation is logically sound and aligns with standard statistical understanding. The reviewer is not criticizing anything but rather clarifying a potential point of confusion. This type of clarification is highly beneficial for improving the authors' understanding and the quality of their work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a fact ('the performance of Megatron and COCOLM is a little overrated') but does not explicitly suggest a concrete action or improvement for the authors. While the reviewer raises a question, it is not a direct, actionable suggestion. The action is implied but not stated clearly.", "grounding_specificity_rationale": "The reviewer mentions 'Megatron' and 'COCOLM' but does not explicitly identify the specific section, table, figure, or unique aspect of the paper being addressed. The mention is general, making the grounding weak.", "verifiability_rationale": "The reviewer makes a claim ('the performance of Megatron and COCOLM is a little overrated') and implicitly suggests that this overstatement is problematic. While the reviewer provides context by mentioning other models, the connection to the specific comparison being made is not explicitly stated or supported by a reference. The reasoning is present but lacks explicit external references or detailed explanations.", "helpfulness_rationale": "The reviewer points out a potential overstatement of performance, which could be helpful for the authors to consider. However, the review lacks specific suggestions or actionable steps based on this observation. The question about BPE is a good addition, making the review 3 overall."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the analysis is 'not convincing enough' and points out a logical flaw in the interpretation of the results. While the reviewer identifies a problem with the analysis, they don't explicitly state what action the authors should take to improve their analysis. The critique is present, but the call for action is missing.", "grounding_specificity_rationale": "The reviewer refers to 'lines 128 to 149' and 'Fig 3' to support their critique. This indicates that the reviewer has identified the specific part of the paper being discussed and has access to the visual evidence. Therefore, the grounding is explicit.", "verifiability_rationale": "The reviewer claims that the observation about class selectivity scores doesn't support the hypothesis. This is a claim that needs to be verified. However, the reviewer does not provide any evidence or reasoning to support this claim. The reasoning provided is a logical deduction, not a verification based on external references or logical reasoning within the context of the paper itself. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer criticizes the analysis and provides a reason for why it's not convincing. While the reviewer identifies a problem, they do not offer any specific suggestions or actions for the authors to take to improve their analysis. The critique is present, but the call for improvement is missing."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a potential weakness in the paper's claim about the detrimental effects of continuous learning with unlabeled data on representation quality. They suggest that the limited exploration of combination methods might be a contributing factor. While the reviewer doesn't explicitly state how to *action* on this, they provide *specific* examples of relevant works (R1, R2, R3) that could be used to explore alternative combination methods. This makes the suggestion more actionable than a vague statement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'continuous learning with unlabeled data' and 'representation quality,' which are specific aspects of the paper. They also name specific papers (R1, R2, R3) that are relevant to the discussion of feature replay and continual learning. This strong grounding makes it clear what part of the paper the reviewer is referring to.", "verifiability_rationale": "The reviewer makes a claim about the paper's assertion regarding the detrimental effects of continuous learning with unlabeled data on representation quality. They then provide external references (R1, R3) to support the potential effectiveness of feature replay methods, which directly challenges the paper's claim. While the reviewer doesn't provide *direct evidence* within the paper itself to disprove the claim, they offer alternative explanations and supporting evidence from other works, making the claim partially verifiable.", "helpfulness_rationale": "This review point is 5. It directly addresses a weakness in the paper's claim about the impact of continuous learning with unlabeled data. The reviewer provides concrete suggestions, such as exploring combination methods and considering feature replay, and even names specific relevant papers (R1, R2, R3). The suggestions are actionable and provide a clear path for the authors to improve their work. The reviewer also identifies a potential alternative to the paper's claim, which is valuable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Weakly Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point contains multiple suggestions and observations. '11 is wonderful, how about other bit operations?' is a direct question suggesting an extension. 'Fig. 5 a seems strange' is an observation that could be considered an implicit suggestion for improvement. 'When the input is aer format, how did you deal with DVS input?' is a question seeking clarification. 'If you can analyze the energy consumption as reference15 did, this paper would be more solid' is a suggestion for improvement. While there are elements of actionability, they are often implicit or suggestions for improvement rather than direct instructions. The lack of explicitness and concrete details makes it 3 but not fully so.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper. 'Fig. 5 a seems strange' is a general observation about the figure, not a specific element within it. The question about Aer format and DVS input does not directly point to a specific section or table. The lack of explicit references makes the grounding weak. While the points raise concerns, they lack specificity about which part of the paper they are addressing.", "verifiability_rationale": "The review point contains a claim: 'Fig. 5 a seems strange'. This is an opinion or judgment about the figure. However, the comment does not provide any specific evidence, references, or logical reasoning to support why Fig. 5a is 'strange'. It is a subjective statement without verifiable backing. The lack of supporting evidence makes the claim 1.", "helpfulness_rationale": "The review point raises valid concerns and suggests improvements. '11 is wonderful, how about other bit operations?' is a suggestion for future work. 'Fig. 5 a seems strange' points out a potential area for clarification. 'When the input is aer format, how did you deal with DVS input?' seeks to understand the methodology. 'If you can analyze the energy consumption as reference15 did, this paper would be more solid' suggests an improvement by adding a more thorough analysis. While the suggestions are relevant, they are often vague and lack specific details on how to implement them. The lack of concrete actions makes the feedback 3 but not entirely so."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'can be combined together'. It also provides concrete details on how to implement this action by referring to 'the first two bullets about contributions (at the end of the intro)'. This makes the action clear and actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'the first two bullets about contributions (at the end of the intro)'. This is a very specific reference to a particular section of the paper, making it fully grounded. The use of parentheses and the phrase 'at the end of the intro' further emphasizes the specificity.", "verifiability_rationale": "The review point is a suggestion, not a claim requiring evidence. Therefore, it does not contain a claim that needs to be verified. The score should be 'X'.", "helpfulness_rationale": "The suggestion to combine the first two bullets about contributions is a logical and helpful comment. It directly addresses a potential organizational issue and could improve the clarity of the introduction. While it doesn't solve *every* potential problem, it's a valuable suggestion that the authors can easily implement."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The request is explicit and concrete. The authors need to find the definition of the dashed lines in the specified figures. This action is directly actionable for the authors.", "grounding_specificity_rationale": "The request is very specific about the figure numbers (fig. 2AB and 4B). This suggests the authors can accurately pinpoint the referenced parts of the paper. While the request doesn't explicitly state what needs to be defined, the specificity of the references indicates strong grounding. The request is welldefined and points to specific elements in the paper.", "verifiability_rationale": "The request itself does not contain a claim. It is a request for information. However, the information about the dashed lines *does* exist within the paper (or is likely intended to be found within it). Therefore, the request is 3 in that the information it seeks is present. The request points to existing information, making it 3.", "helpfulness_rationale": "The request is directly relevant to understanding the figures and their elements. The authors would likely benefit from this clarification. While the request itself isn't a critique or suggestion for improvement, it's a question that, if answered, would be helpful for the authors to understand the paper better. The request addresses a specific need of the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the importance of unsupervised pretraining and suggests its emphasis in the main paper. The suggestions are direct and actionable for the authors. The reviewer clearly indicates what needs to be improved.", "grounding_specificity_rationale": "The review point mentions \"unsupervised pretraining\" and connects it to \"performance gain\" and the \"ablation study.\" While it doesn't provide the exact section number where the detailed discussion is missing, it strongly implies the relevance of the pretraining section. The grounding is present but not as precise as it could be.", "verifiability_rationale": "The review point makes a claim: \"there is no detailed discussion on the unsupervised pretraining in the main paper, which might be a problem.\" The reviewer provides supporting evidence by referencing the experimental results (Table 4) showing its importance and the ablation study (Table 5) highlighting its impact. While it doesn't provide specific examples of what is missing, the connection between the lack of detail and the observed performance is implied and logical.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper (lack of detailed discussion on unsupervised pretraining) and provides a constructive suggestion (emphasize it). The reviewer directly points to the consequences of this lack of detail (performance gain and ablation study) and suggests a concrete improvement. This is a valuable piece of feedback for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment suggests improving the writing style by making it 'simpler' but does not specify which aspects of the writing need simplification or how to achieve this. It lacks concrete actions and specific details on implementation.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper (e.g., a section, table, figure) that needs improvement. It is a general statement about the writing style.", "verifiability_rationale": "The comment is a suggestion for improvement, not a claim that requires verification. It does not present a statement that can be logically reasoned, supported by common knowledge, or backed by external references.", "helpfulness_rationale": "The comment identifies a weakness ('writing is difficult to follow') and suggests an improvement ('simplify'). While it points to an area for improvement, the lack of specificity about *what* needs simplification and *how* to do it makes it less helpful than it could be."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for clarification on the intuition of Theorem 1, explores the impact of different distributions on the invertible function f*, and provides guidance on how to choose a fixed P*. These are all direct requests for information and suggestions that are actionable for the authors. While the reviewer doesn't provide a specific action, the questions clearly point to areas where the authors' understanding could be improved and where they could apply changes to their work.", "grounding_specificity_rationale": "The reviewer refers to 'Theorem 1' and the 'invertible function f*'. While they don't explicitly name the section or table containing Theorem 1, the context strongly implies they are referring to a specific part of the paper. This can be considered 'Full Grounding' as the reference is clear, even if not literal. However, the reviewer doesn't specify *what* is missing in the explanation of the theorem or the function, making the specificity somewhat weak. They are pointing to a general area needing more explanation rather than a specific detail.", "verifiability_rationale": "The reviewer does not explicitly state a claim or opinion. They are asking questions and exploring the implications of a specific function. Therefore, this review point does not contain a claim and falls under the 'X' category. There is no evidence to assess its verifiability.", "helpfulness_rationale": "The reviewer is directly asking for clarification and exploring the implications of a specific function. This is clearly intended to improve the authors' understanding and potentially their work. Therefore, this review point is 5 as it directly addresses a need for better understanding and provides avenues for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a question about the difference between two specific terms in equations (7) and (10). While this points to a potential area of confusion, the reviewer does not explicitly state what action the authors should take. They are asking a question, which can be interpreted as an implicit request for clarification, but not a direct instruction. Therefore, it is not fully actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions the equations (7) and (10) and the terms X and H^(1). This provides clear grounding as they directly identify the specific part of the paper being addressed. The language is precise and literal, indicating a strong understanding of where the confusion might lie.", "verifiability_rationale": "The reviewer is not making a claim in the sense of stating an opinion or assertion. They are posing a question. Therefore, there is X to verify. The 'X' notation is appropriate here as the comment is a question and not a statement of opinion or suggestion.", "helpfulness_rationale": "The reviewer is asking a question to clarify a specific point of confusion regarding the equations. This directly addresses a potential weakness the authors might have in understanding the equations. While it doesn't offer a constructive solution, it is targeted and seeks to improve understanding. Therefore, it is 3 as it identifies an area needing attention."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential conflict between two definitions. The definition of minimal conditional dependence refers to a *set* of variables Z', while Eq. (7) seems to imply a condition on a *single variable* (or a set treated as a single entity) without explicitly considering the role of Z'. This makes the reviewer's statement an explicit action suggesting that X and Y are independent given W, but the reviewer argues that Eq. (7) contradicts this. The reviewer identifies the discrepancy and proposes a specific scenario (Z' being the empty set) to illustrate the conflict. The reviewer clearly states the action and its expected outcome.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"Lemma 2,\" \"Eq (7),\" and \"the definition of minimal conditional dependence.\" They clearly identify the specific part of the paper being discussed and how the conflicting statements relate to this part. The reviewer's statement directly addresses a specific aspect of the paper, making it highly grounded. The reviewer states the specific elements being addressed (Lemma 2, Eq. (7), definition of minimal conditional dependence) and how the issue relates to them.", "verifiability_rationale": "The reviewer makes a claim: \"Second rule in Lemma 2, i.e., Eq (7) and the definition of minimal conditional dependence seem to be conflicting.\" The reviewer then provides a justification by explaining how the definition of minimal conditional dependence, when considering the case where Z' is the empty set, implies that X and Y are independent given W. The reviewer argues that Eq. (7) contradicts this implication. The reviewer provides a logical reasoning to support their claim, making it highly verifiable. The reviewer states a claim and provides a clear reasoning to support it.", "helpfulness_rationale": "The reviewer identifies a potential conflict in a theoretical definition, which could lead to confusion and misinterpretations for readers. By pointing out this specific inconsistency, the reviewer is providing a constructive suggestion for improvement. The reviewer's comment directly addresses a potential flaw in the theoretical framework, offering a clear direction for the authors to clarify their definitions. This is a 5 comment as it directly addresses a potential source of confusion and suggests a concrete improvement for the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for a comment on how the archetype positions are updated after initialization. This constitutes an explicit request for action. However, the paper only mentions the initialization method (FurthestSum) and does not provide any details on the update process. Therefore, while the reviewer clearly identifies the action that needs to be taken (describing the update), the means to achieve this are not provided, making it somewhat implicit.", "grounding_specificity_rationale": "The reviewer mentions Algorithm 2, the coreset C, the query Q, and the archetypes z_1 to z_k. This demonstrates that the reviewer can identify the specific part of the paper being addressed, indicating strong grounding. However, the reviewer does not specify *what* is wrong with the current archetype positions or *how* the update is supposed to work. The request is about identifying the *specific* issue and the *specific* solution, which are not detailed in the provided text. Therefore, while the section is identified, the specific details are missing, making the grounding somewhat underspecific.", "verifiability_rationale": "The reviewer states that the paper does not provide a clear explanation of how the archetype positions are updated after initialization. This constitutes a claim that needs to be supported. While the *reason* for choosing FurthestSum or the *benefits* of the update might be present elsewhere, the *lack of explanation* within the algorithm description itself is the core point. The claim is supported by the absence of a detailed explanation within the provided text, making it 3.", "helpfulness_rationale": "The reviewer's question directly targets a core component of the algorithm. Understanding how archetypes are updated is crucial for implementing and interpreting the method. The lack of this information makes the review point 5 (the action being to explain the update) and somewhat underspecific (as it doesn't specify the method). A helpful response would clearly explain the update process, making this review point very helpful in improving the clarity of the algorithm description. The reviewer's question highlights a significant omission that would directly benefit the reader's understanding."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that important information about the empirical study is missing, which directly points to a lack of actionable feedback for the authors. They are indicating a need for the authors to include details like recording parameters, preprocessing steps, resting state conditions, harmonization techniques, and the number of regions.", "grounding_specificity_rationale": "The reviewer requests specific details about the empirical study, such as the resting state condition and a brief explanation of the harmonization technique. While the general area of methodological details is mentioned, the specific implementation and parameters are not identified, making the grounding only partially specific.", "verifiability_rationale": "The reviewer asks for clarification on the recording parameters for the MRI, preprocessing steps, and the resting state condition. This is a request for justification or evidence within the paper itself, indicating that the information is not readily verifiable from the text alone.", "helpfulness_rationale": "The reviewer provides concrete suggestions for the authors to improve their paper, such as including the requested information about the empirical study. These suggestions are directly aimed at helping the authors address the identified weaknesses."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of datasetspecific relationships between action units and provides a clear, concrete suggestion: 'perform crossdataset experiments.' This action is directly identified and recommended by the reviewer, indicating high actionability.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'crossdataset experiments' and connects it to the problem of 'datasetspecific relationships.' This directly identifies the relevant part of the paper and the type of data being used, indicating full grounding. The reviewer also specifies what needs to be done (perform these experiments), indicating high specificity.", "verifiability_rationale": "The reviewer makes a claim that the paper is 'lacking' crossdataset experiments. This claim is supported by the reasoning that 'this limitation can already be seen in Figure 1 with quite different cooccurences of AU1 and AU12.' This provides evidence supporting the reviewer's claim, indicating high verifiability.", "helpfulness_rationale": "The reviewer's comment is highly valuable as it identifies a significant limitation in the paper's methodology (lack of crossdataset experiments) and provides a concrete suggestion for improvement. This directly helps the authors understand a potential gap in their work and how to address it, making the comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly criticizes the statement about overparametrization and provides a direct counterpoint ('overparametrization seems to be very helpful...'). It also offers a reason for this alternative viewpoint ('...results in worse performance') and provides supporting evidence ('I have seen a number of theoretical work...'). This makes the criticism both explicit and concrete.", "grounding_specificity_rationale": "The reviewer criticizes a general statement about overparametrization without explicitly identifying a specific section, table, figure, or unique aspect of the paper. While the reviewer mentions 'supervised learning of deep neural networks' as a context, this doesn't pinpoint a specific element being addressed. Therefore, the initial criticism is weakly grounded. However, the reviewer *does* provide specific information about the *benefits* of overparametrization in this context, making the subsequent explanation somewhat specific.", "verifiability_rationale": "The reviewer provides an alternative viewpoint ('overparametrization seems to be very helpful...') and offers supporting evidence ('I have seen a number of theoretical work...'). This makes the criticism 3, as it is supported by logical reasoning and examples, though it doesn't definitively prove the original statement is incorrect.", "helpfulness_rationale": "The review point directly challenges the original statement and offers a clear counterpoint ('overparametrization seems to be very helpful...'). It provides a reason for this alternative viewpoint ('...results in worse performance') and offers supporting evidence ('I have seen a number of theoretical work...'). This makes the review point 5 as it provides actionable feedback and relevant information to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer's request to add more detail about the experimental setting is somewhat explicit, but lacks specific guidance on *how* to add the detail. While the reviewer mentions 'continual learning,' they don't specify which aspects of the setting need clarification. The request is implicit in the statement, 'Add a few more sentences explaining the experimental setting for continual learning,' which the authors can infer but don't know exactly what to add.", "grounding_specificity_rationale": "The reviewer mentions 'the experimental setting for continual learning' in the first part of the review point, which provides some grounding. However, the authors would still need to infer which specific part of the paper or which specific details are being referred to. The second part of the review point, asking about the correspondence between learning curves and MPHATE, directly refers to 'Figure 3' and 'MPHATE,' providing strong grounding.", "verifiability_rationale": "The reviewer's questions about Figure 3 do not present a claim that needs verification. They are asking for clarification and interpretation of existing information. Therefore, the verifiability is not applicable in the same way as for a critique that makes a claim about missing elements. The questions are requests for information rather than statements that require justification.", "helpfulness_rationale": "The reviewer's request to add more sentences explaining the experimental setting is 3, as it points to an area where the authors can improve their draft. However, it lacks specific direction on *how* to add the detail. The questions about Figure 3 and the accuracy numbers are 5 as they directly address specific uncertainties and requests for information from the authors. The reviewer is asking the authors to clarify and interpret existing results, which is a valuable feedback point."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue with the experimental setup by suggesting that the compared methods might not have been initialized with the same pretrained model as the proposed method. This is an explicit action that the reviewer proposes investigating. The reviewer also implies that this discrepancy could explain the performance difference, making the action somewhat concrete, though the exact details of the compared methods' pretraining are not provided.", "grounding_specificity_rationale": "The reviewer mentions 'other methods' and 'compared methods' generally, without specifying which exact methods or providing details about their pretraining. While the reviewer refers to Table 1, they do not explicitly state the pretraining details of any specific method. Therefore, the grounding is weak as the authors cannot confidently determine which part of the paper the comment addresses.", "verifiability_rationale": "The reviewer claims that the experimental comparison is unfair due to potential differences in pretraining. To verify this claim, the reviewer would need to see the experimental setup details, specifically the pretraining procedures of all compared methods. Without this information, the claim is not supported by the provided review point, making it 1.", "helpfulness_rationale": "The reviewer raises a valid concern about the fairness of the experimental comparison. By pointing out the potential discrepancy in pretraining, the reviewer provides a potential explanation for the performance difference. This could be helpful for the authors to investigate further. However, the reviewer does not explicitly state what the authors should do next or provide a clear justification for why the comparison is unfair in a prescriptive way."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly criticizes the use of \"attribute\" metadata and suggests exploring better metadata embeddings. Both of these points are direct and specific actions the authors could take. The criticism of the current metadata is clear, and the suggestion to use Reed et al.'s embeddings is a concrete action to improve the method. The reviewer provides a clear direction for the authors to follow.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"zeroshot learning on CUB dataset\" and the \"metadata used here are \u00e2\u0080\u009cattribute\u00e2\u0080\u009d\". This clearly identifies the specific part of the paper being addressed. The criticism is directly tied to the \"attribute\" metadata used in this context. While the suggestion to explore Reed et al. is more general, the initial criticism is grounded. The grounding is strong as the reviewer refers to specific elements of the paper.", "verifiability_rationale": "The reviewer makes two claims. First, they state that \"this is good for fair comparison,\" which is a factual statement and verifiable. Second, they suggest exploring Reed et al.'s embeddings, which implies a logical connection to prior work and suggests a direction for future research, making it verifiable through logical reasoning and referencing external knowledge. Both statements are verifiable and provide a basis for the authors to explore further.", "helpfulness_rationale": "The review point provides a clear criticism of the current metadata and suggests a relevant improvement by referencing a specific paper. This is a helpful comment as it directly points out a potential limitation and offers a concrete direction for the authors to consider. The suggestions are actionable and could lead to improvements in the method."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a contrasting viewpoint regarding SGC's applicability compared to PEFT methods, suggesting that PEFT methods are more suitable for computeconstrained scenarios. While the reviewer identifies a potential improvement by suggesting a plot, the action of creating the plot itself is not explicitly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'LoRA' as a specific PEFT method for comparison, grounding the discussion in a concrete example. Furthermore, the reviewer suggests a specific visualization with defined axes (sparsity and performance), providing further detail on the comparison.", "verifiability_rationale": "The reviewer presents a claim about PEFT methods being typically used in computeconstrained scenarios. While the reviewer does not provide a direct logical reasoning or external reference within the review point itself, the suggestion of a plot to *verify* this claim introduces an element of verifiability by implying a method to test the claim.", "helpfulness_rationale": "The reviewer's point directly challenges a claim made in the paper regarding SGC's applicability. The suggestion to include a plot with specific axes (sparsity and performance) is a concrete and actionable suggestion that would likely improve the authors' understanding and potentially lead to better decisions regarding the use of SGC. This addresses a specific concern and offers a clear path for investigation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly asks a question about the rationale behind the experimental setup and suggests a concrete action (code publication) to address a potential issue. The action is directly tied to the question posed, indicating a clear intent to improve understanding and potentially facilitate further work. The reviewer identifies the specific components of the experiment (datasets, tasks) and the potential problem (training time difference), making the action quite explicit.", "grounding_specificity_rationale": "The reviewer refers to several components of the paper (Experiments, German and Law school dataset, Gerrymandering, Independent, ERM, plugin, Kearns et al., code publication) but does not explicitly point to a specific section, table, or figure in the paper under review. The reviewer is discussing the experimental setup and suggesting a practical action (code publication) related to another paper. While the terms are relevant, the reviewer does not directly identify a specific part of the *reviewed paper* that is problematic or needs clarification. The mention of external concepts and experiments from another paper does not ground the review to the specific work of the authors being evaluated.", "verifiability_rationale": "The reviewer presents a claim about the training time difference between datasets in the Gerrymandering and Independent experiments. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim within the review point itself. The suggestion to publish the code is a potential solution *if* the training time is different, but the reviewer does not explain *why* they believe the training time should be different or why code publication is the appropriate remedy. The claim is presented without sufficient justification, making it 1 based on the information provided in this review point.", "helpfulness_rationale": "The reviewer's comment primarily focuses on the *rationale* behind the experimental setup in another paper and suggests a *practical action* (code publication) related to that experiment. While the suggestion to publish code is valuable, it is a suggestion for an external work and does not directly address any perceived weaknesses or ambiguities in the *reviewed paper*. The reviewer does not provide any specific feedback or suggestions directly applicable to the authors' work. The comment is more about the design of an experiment and a suggestion for a practical action rather than directly improving the reviewed paper."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the difference in followup time between the human and model baselines and how this impacts the interpretation of the results. It also clearly identifies the CER and BLEU scores mentioned in the abstract and points out that the comparison might be misleading due to the different followup times. The actions suggested are explicit and concrete: 'Please consider the followup time when interpreting the human baseline performance' and 'It would be beneficial to rephrase the comparison in the abstract to avoid confusion'. The grounding is implicit as the reviewer refers to the abstract without explicitly naming a section or table, but the context implies they are referring to the experimental results. The specificity is implicit as the reviewer doesn't detail *how* the comparison is misleading, just that it is.", "grounding_specificity_rationale": "The reviewer explicitly mentions the followup time in the abstract as a key aspect being addressed, making the grounding fully explicit. The specificity is also fully explicit as the reviewer clearly states the CER and BLEU scores and the misleading nature of the comparison.", "verifiability_rationale": "The reviewer makes a clear claim: 'In the abstract, the authors mention \"already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources\" which is a bit misleading given the 1 hour vs.' This claim is verifiable because the reviewer provides specific evidence (the CER, BLEU scores, and the followup time difference) to support their statement. The logical reasoning is clear: the short followup time for the human baseline likely underestimates their potential performance, making the comparison in the abstract misleading.", "helpfulness_rationale": "The reviewer's point is highly relevant and directly addresses a potential source of confusion for readers interpreting the results. By highlighting the discrepancy between the reported human baseline and the potential for a human with a longer followup time to achieve better performance, the reviewer is providing actionable feedback that helps authors understand the limitations of the human baseline as presented in the abstract. This feedback is specific and directly addresses a point of ambiguity in the original text."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states actions or suggestions that are direct or apparent. The reviewer asks for an example of data, clarifies terminology, and requests explicit model details. These are all direct actions the author can take.", "grounding_specificity_rationale": "The authors can accurately pinpoint the section, table, figure, or unique aspect being addressed. The reviewer explicitly refers to Figure 1 and asks about specific data within that figure ('support data' and 'predicted training count data'). They also ask for the model used, which is a specific detail within the methodology.", "verifiability_rationale": "The claim is wellsupported but has minor gaps in explanation or references. The reviewer's requests are logical and directly related to the presented information. For example, asking for clarification of terminology is a natural next step in understanding the data. Asking for the model used is a standard request in methodology sections. While not explicitly labeled as a claim, the guidance is clear and builds upon the presented content.", "helpfulness_rationale": "The comment thoroughly identifies weaknesses and offers detailed, actionable, and constructive suggestions that empower the authors to significantly improve their draft. The reviewer's requests for clarification, model details, and an example are all very specific and directly address potential areas for improvement. While the request for an 'example' is somewhat openended, the other two are quite specific and actionable. This review provides a good starting point for the author to refine their understanding and potentially improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the purpose of Figure 3 and provides concrete suggestions for improvement. They identify the need to 'elucidate this procedure in greater detail' and 'understand whether the spatial arrangement of the EEG sensors played any role in this process'. These are direct actions the authors can take.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 3' by name, clearly identifying the specific part of the paper being addressed. They also specify what they find ambiguous ('interpretation') and what they want to know ('the role of spatial arrangement'), adding detail to the grounding.", "verifiability_rationale": "The reviewer identifies a potential issue ('ambiguity in interpretation') and suggests a way to address it ('elucidate this procedure in greater detail'). While they don't provide external references to verify the ambiguity, their suggestion is a logical and actionable step for the authors to take. The claim is that the interpretation is ambiguous, and the suggestion is to make the procedure clearer.", "helpfulness_rationale": "The reviewer directly points out a potential area for improvement ('ambiguity in interpretation') and offers a concrete suggestion ('elucidate this procedure in greater detail'). This is a very direct and actionable piece of feedback that empowers the authors to address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly mentions a specific detail about the Witness oracle's complexity and identifies a potential issue with how it's being used. However, it doesn't provide explicit instructions or concrete steps for the authors to take. The reviewer expresses a suspicion rather than a direct instruction.", "grounding_specificity_rationale": "The reviewer refers to 'checking on the Witness oracle' and 'polynomial time' without explicitly linking these terms to a specific section, table, or figure in the paper. The grounding is weak because the authors can't confidently pinpoint the referenced part. The reviewer also expresses a feeling of the approach not being 'direct,' further reducing specificity.", "verifiability_rationale": "The review point is a statement of opinion ('feels like...') rather than a claim that requires verification. There's no logical reasoning, common knowledge, or external references provided to support or refute the reviewer's statement.", "helpfulness_rationale": "The reviewer identifies a potential issue with the approach and expresses a concern about it being 'not direct.' This indicates a desire for the authors to improve their work. However, the reviewer doesn't provide specific, actionable steps for the authors to take. They express a suspicion or a potential flaw in the methodology, which is valuable feedback but lacks concrete suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing literature on moment matching and provides a clear reason for its relevance (alternative to quantile regression for Distributional RL). The suggestion to discuss this is a direct action the authors can take to improve their draft.", "grounding_specificity_rationale": "The reviewer not only identifies the missing literature but also specifically names a relevant paper (NguyenTang et al., AAAAI'21) and connects it directly to the topic being discussed (Distributional RL). This provides strong grounding as the authors can directly refer to this paper.", "verifiability_rationale": "The reviewer provides a specific paper and a clear reason why it's relevant (moment matching as an alternative to quantile regression for Distributional RL). This provides a basis for verification, as the authors can consult this paper to understand moment matching.", "helpfulness_rationale": "The reviewer's suggestion is directly relevant to improving the related work section by acknowledging alternative approaches to Distributional RL. This is a valuable and actionable piece of feedback for the authors."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "5 (5)", "verifiability_label": "3 (3)", "helpfulness_label": "3 (3)", "actionability_rationale": "The comment points out a lack of clarity in the introduction's second paragraph. It doesn't explicitly state what needs to be improved or how to do it. The action is implied rather than stated.", "grounding_specificity_rationale": "The comment explicitly mentions the 'second paragraph' of the introduction, clearly identifying the specific part of the paper being addressed. It also clearly states the issue: 'it is not immediately obvious what is being modelled'. This indicates strong grounding and specificity.", "verifiability_rationale": "The comment states a fact: 'the second paragraph talks about modelling curves...'. It does not make a claim that requires verification or justification. Therefore, it fits the 'X' category (X).", "helpfulness_rationale": "The comment identifies a potential issue (lack of clarity) in a specific part of the paper. While it doesn't provide a complete solution, it encourages the authors to look at the second paragraph and understand what's being modeled. This points the authors in the right direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem: 'As I just mentioned, the paper only analyzed, under which cases will the Algorithm 1 converges to permutations as local minima.' This indicates an awareness of a limitation. They also suggest a solution: 'However, it will be better if the quality of this kind of local minima could be analyzed (e.g. the approximation ratio of these local minima, under certain assumptions).' This suggests an action, albeit a general one. While the reviewer identifies a need for analysis, they don't provide specific implementation details. Therefore, the action is somewhat explicit but could be more concrete.", "grounding_specificity_rationale": "The reviewer refers to 'Algorithm 1' and 'permutations as local minima,' which are specific elements within the paper. They also mention 'approximation ratio,' a specific concept. This indicates a strong grounding of the comment in the paper's content. The reviewer not only identifies the area of the paper being discussed but also pinpoints the specific aspect within that area.", "verifiability_rationale": "The reviewer makes a claim: 'it will be better if the quality of this kind of local minima could be analyzed...'. This is a statement that requires justification. The reviewer argues for the importance of this analysis by stating that it would provide a better understanding of the solutions found by the algorithm. While the reviewer provides a logical argument for why this analysis is beneficial, they do not provide specific examples or citations to support this claim. Therefore, the claim is somewhat justified.", "helpfulness_rationale": "The reviewer clearly identifies a limitation in the paper's analysis of Algorithm 1, specifically the lack of analysis regarding the quality of the local minima. They propose a concrete direction for improvement: analyzing the approximation ratio. This comment is directly aimed at helping the authors improve their draft by highlighting a specific area for further investigation. The reviewer's suggestion is actionable and directly addresses a potential weakness."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly mentions the 'Fill, Propagate, Decode algorithms' and the 'weight pool' as components involved in implementing information redundancy. However, it lacks specific details on how the redundancy is achieved within these components. For example, it doesn't specify the exact operations or data transformations that create the redundancy in the 'Fill' algorithm or how the 'weight pool' ensures this redundancy is maintained throughout the process. The description is highlevel and lacks concrete implementation details.", "grounding_specificity_rationale": "The comment explicitly mentions the 'Fill, Propagate, Decode algorithms' and the 'weight pool', directly referring to specific parts of the method. It states that the robustness comes from the 'information redundancy implemented in our design of the weight pool'. This provides a clear grounding of the issue being addressed. However, while it identifies the 'weight pool' as the specific part, it doesn't explicitly detail *how* the information redundancy is built into this pool. It mentions the 'learned weights' but doesn't explain the mechanism of learning or how the redundancy is enforced within the pool.", "verifiability_rationale": "The comment makes a claim that 'Finally, by comparing the performance of the secret model with or without fusion, we conclude that the robustness of Cans largely comes from the information redundancy implemented in our design of the weight pool.' While it states a conclusion based on a comparison, it doesn't explicitly provide the reasoning or the results of that comparison within the sentence itself. The verifiability relies on the reader understanding the overall experimental setup and the role of the 'weight pool' in the model. The claim is stated, but the supporting evidence or logical reasoning directly within this sentence is lacking.", "helpfulness_rationale": "The review point is highly relevant as it directly addresses a core question about the implementation of a key mechanism (information redundancy) in the proposed method. The reviewer is seeking a detailed explanation of how this redundancy is built into the algorithms. While the paper claims the redundancy is in the 'weight pool', it doesn't provide sufficient detail for the reviewer to understand or replicate this mechanism. The information provided is highlevel and lacks the specific technical details needed for a thorough understanding or improvement of the method."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'there should be experimental results of excluding such mixup technique.' This is a clear and direct identification of a missing piece of information. The reviewer also suggests a concrete action: 'conduct an ablation study.' This action is to *exclude* the mixup technique from the experiments, which is a clear and actionable step. While the suggestion is highlevel, it is directly tied to the identified problem and provides a clear path for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'Sec. 4.2', 'mixup technique', and 'LUMP'. While they don't provide a literal mention of a specific section, they clearly identify the *content* of the experiment that is lacking. The reviewer's suggestion to 'exclude such mixup technique from the proposed method' is a specific action related to the experimental setup. Therefore, while the grounding is not perfect, it is still somewhat grounded by identifying the area of concern (mixup technique in experiments). The specificity is in the suggestion to *exclude* the mixup technique, which is a clear indication of the desired change.", "verifiability_rationale": "The reviewer makes a claim: 'there should be experimental results of excluding such mixup technique.' This is a clear statement of what is missing. The reviewer then suggests 'conducted an ablation study' as a way to verify this claim. This ablation study would logically demonstrate the impact of removing the mixup technique. The reasoning is clear and directly addresses the claim. The suggestion provides a logical and verifiable way to support the claim.", "helpfulness_rationale": "The reviewer clearly states a desire for more experimental evidence to support a claim about the mixup technique. Their suggestion to 'conduct an ablation study' is a direct and actionable step that directly addresses this need. The request is specific and targets the identified weakness in the experimental validation. This is a 5 suggestion as it directly contributes to improving the understanding of the proposed method's contribution."}
{"actionability_label": "Low", "grounding_specificity_label": "High", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point does not explicitly state an action or suggestion. It poses a question about a potential issue and suggests a potential citation. Therefore, it is not actionable as it does not directly tell the authors what to do or what to change in their work.", "grounding_specificity_rationale": "The reviewer mentions the 'RVC paper' and refers to 'steps 1 & 2' of the algorithm. This provides a specific reference point and grounds the comment in a concrete piece of related work and a specific part of the algorithm being discussed. Therefore, the grounding is high.", "verifiability_rationale": "The reviewer suggests that an error in the initial calibration steps (steps 1 & 2) of the RVC algorithm might explain the speed disparities observed between the RSPs and FDs. This is a suggestion that requires further investigation and could be supported by external references. However, it lacks specific examples or direct evidence within the review point itself. Therefore, the verifiability is somewhat supported but not definitively proven.", "helpfulness_rationale": "The review point raises a valid question about a potential cause for the observed speed disparities and suggests a relevant piece of work (the RVC paper) as a potential source of information. This is a helpful point as it points the authors towards a potential area of investigation and a relevant piece of related research. It doesn't directly solve the problem, but it provides a direction for further inquiry."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for clarification on the labels in the datasets from Section 4.1. While it doesn't state the exact method of labeling, it implies a direct association between the generated data and the labels. The reviewer is seeking a clear understanding of how these labels are derived and applied, which is a direct request for action. Therefore, it can be considered actionable as the reviewer can directly use this information to understand the dataset.", "grounding_specificity_rationale": "The reviewer is asking about the *source* of the labels within the dataset. While the paper mentions that the labels are generated, it doesn't explicitly state where within the dataset these labels are located or how they are structured. The reviewer needs to infer this information from the paper's description of the label generation process. Therefore, it can be considered grounded but not fully specific as the exact location or structure isn't directly stated.", "verifiability_rationale": "The paper states that the labels are generated using a 'combination of rulebased and machine learning approaches'. This provides some justification for the labeling process. However, it doesn't explicitly mention any external references or examples used in this generation. The reviewer has to infer that the information is contained within the paper itself. Therefore, it can be considered 3 as there is some explanation provided, but it lacks external references or detailed examples.", "helpfulness_rationale": "The review point directly addresses a clear need for clarification regarding the labels in the datasets. By asking for this information, the reviewer is empowered to better understand the experimental setup and the nature of the generated data. This directly contributes to improving their understanding and potentially their own work in similar areas. Therefore, it is 5."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "3 (Weakly Grounded and UnderSpecific)", "verifiability_label": "1 (1)", "helpfulness_label": "2 (2)", "actionability_rationale": "The reviewer explicitly states the sensitivity to \u03bb parameters and asks how the process of calculating \u03bb is done. This is an implicit action. While the reviewer understands the *consequence* of \u03bb sensitivity, the *how* is missing. The reviewer also states that ELLA does not increase sample efficiency in a COMBO environment, which is an explicit action. The reviewer doesn't understand what it means, indicating a lack of clarity in the explanation.", "grounding_specificity_rationale": "The reviewer doesn't explicitly state *where* the calculation of \u03bb happens within the paper. They imply it's in the context of the ELLA method. The reviewer doesn't explicitly state *where* the discussion about ELLA and sample efficiency in COMBO occurs. They imply it's in the section describing the ELLA method. The reviewer doesn't explicitly state *where* the missing citations are located. They imply they are related to the exploration methods discussed.", "verifiability_rationale": "The reviewer states the sensitivity to \u03bb parameters without providing a justification or reasoning for why this sensitivity exists. The reviewer states that ELLA does not increase sample efficiency in a COMBO environment without providing a justification or reasoning for this claim. The reviewer points out missing citations related to exploration, which is a claim (the lack of citations is a weakness) without explicit justification within the review point itself.", "helpfulness_rationale": "The reviewer explicitly states they don't understand how the process of calculating \u03bb is done. This makes the feedback not helpful. The reviewer explicitly states they don't understand what it means ELLA does not increase sample efficiency in a COMBO environment. This makes the feedback not helpful. The reviewer points out missing citations, which hinders their understanding and ability to improve, making the feedback not helpful."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out potential issues with the lower bound double qlearning algorithm, such as doubt about its effectiveness, a slight performance decrease in MsPacman, similar convergence with other algorithms, and the potential for overestimation. While these are valid observations, the reviewer does not explicitly state what actions the authors should take. They suggest investigating these issues, which is an implicit suggestion rather than a direct instruction. Therefore, the actionable aspect is somewhat limited.", "grounding_specificity_rationale": "The reviewer mentions 'double qlearning' generally and then focuses on specific environments (MsPacman, WizardOfWor, Zaxxon RoadRunner, BattleZone) in Figure 2. While the environments are clearly identified, the *specific implementation* of the double qlearning algorithm within the paper is not explicitly pinpointed. The reviewer infers that the issues might be related to the algorithm's implementation in these environments. This makes the grounding somewhat weak as the authors need to make an inference to find the relevant part.", "verifiability_rationale": "The reviewer makes claims about the effectiveness of the lower bound double qlearning algorithm, the performance decrease in MsPacman, the similar convergence with other algorithms, and the potential for overestimation. However, within the provided review point itself, there is no direct evidence or citation to support these claims. The reviewer is making inferences based on their general knowledge of reinforcement learning and the experimental results they observe. Therefore, the verifiability is limited as the claims are not directly supported by the information within this specific review point.", "helpfulness_rationale": "The reviewer's review point raises several concerns about the lower bound double qlearning algorithm. They point out a potential doubt about its effectiveness, a performance decrease in a specific environment, similar convergence with other algorithms, and the possibility of overestimation. These are all valid points that could encourage the authors to reexamine their experimental setup and consider alternative approaches. While the reviewer doesn't provide direct solutions, they offer a direction for further investigation. Therefore, the review point is helpful in identifying potential issues but doesn't offer immediate solutions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the observation that DNN+MMA's performance is worse than vanilla DNN when lambda is small and also states the expected outcome (approaching from above) but observes it approaching from below. This is an explicit statement of an action (identifying a performance issue) and how it should be expected to behave. While the reviewer doesn't propose a solution, they clearly point out a discrepancy that needs attention.", "grounding_specificity_rationale": "The reviewer refers to 'DNN+MMA,' 'vanilla DNN,' and 'lambda' within the review point. While they don't explicitly mention 'fig.34,' the context strongly links the performance difference to the figures. This can be considered weak grounding as the connection is inferable but not direct. The reviewer also specifies the *nature* of the discrepancy (worse performance, approaching from below, expectation of above), which adds to the specificity.", "verifiability_rationale": "The reviewer makes a claim about the performance discrepancy between DNN+MMA and vanilla DNN when lambda is small. However, within the review point itself, there is no evidence, reasoning, or external references provided to support this claim. The reviewer is simply stating their observation. Therefore, it is not verifiable based on information within this review point.", "helpfulness_rationale": "The reviewer points out a clear issue (performance discrepancy) and provides a reasonable expectation. While they don't offer a solution, highlighting this discrepancy is valuable information for the authors. They are asking a question, which can be helpful in guiding further investigation. However, the lack of a figure reference within the review point itself makes it less helpful than it could be."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the conditions for Hoeffding's inequality (independent samples) and points out that the paper might be overlooking this requirement. They also highlight the impact of stochastic algorithms on the inequality's applicability. This is an explicit statement of a potential issue and a clear suggestion for improvement, making it actionable. The reviewer identifies the specific area where the paper needs to be more precise.", "grounding_specificity_rationale": "The reviewer mentions 'Hoeffding's bound' and 'samples are drawn independently' as conditions for the inequality. While they implicitly refer to the concept of Hoeffding's inequality within the paper's context, they don't explicitly point to a specific section, table, or figure within the paper where this condition is not met or needs clarification. The grounding is based on the concept rather than a specific part of the paper. The specificity is also implicit as the reviewer is not providing a concrete example of where the condition is violated within the paper's content.", "verifiability_rationale": "The reviewer makes a claim about the conditions for Hoeffding's inequality and suggests the paper needs to address the independence requirement and the impact of stochasticity. The claim is supported by the general knowledge of Hoeffding's inequality, which states that the samples must be independent and identically distributed. However, the reviewer doesn't provide specific examples from the paper where these conditions are violated or how stochasticity affects the inequality in their specific context. The reasoning is based on general statistical principles rather than specific evidence from the paper.", "helpfulness_rationale": "The reviewer provides a clear and actionable feedback to the authors. They point out a potential misunderstanding or misapplication of Hoeffding's inequality in the paper's analysis and suggest that the paper needs to be more precise about the conditions under which the inequality holds. This feedback is directly helpful for the authors to improve their draft by addressing the potential gap in their analysis. The reviewer is not asking a question but rather highlighting a specific issue that needs to be addressed."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests comparing with 'other representative panoptic segmentation models' and provides specific examples like 'PanopticFPN' and 'Mask2Former'. This constitutes an explicit action, and the reviewer directly states the desired outcome: including these models in the comparison. The action is also concrete as it names specific models to be included.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'other representative panoptic segmentation models' and provides specific examples like 'PanopticFPN' and 'Mask2Former'. This clearly identifies the specific aspect of the paper (the comparison with other models) and provides concrete details about the models being referred to. The grounding is strong as the reviewer names specific models, and the specificity is high as the reviewer directly states the need for comparison.", "verifiability_rationale": "The review point contains a claim: 'Some other representative panoptic segmentation models are not compared, like PanopticFPN, Mask2Former, etc.' The reviewer provides examples and suggests a comparison. This claim is verifiable as it points to a specific area of the paper (the comparison section) and provides examples of models that are relevant. The reasoning is clear and directly addresses a potential omission in the current comparison.", "helpfulness_rationale": "The review point directly suggests comparing with specific panoptic segmentation models and provides examples. This is a clear and actionable feedback for the authors, indicating a potential gap in the related work or experimental evaluation. The suggestion is specific and points to concrete areas for improvement. While it doesn't provide the 'why' or 'how' of the comparison, it is a very direct and actionable suggestion for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer identifies areas for improvement in the paper, such as 'sensitivity to other hyperparameters' and 'language usage'. While these are valid points, the suggestions provided are quite general and lack specific actionable steps. For example, the reviewer suggests 'improving language usage' but doesn't specify *how* to do this. The suggestions are at a high level and don't provide concrete modifications to the text. Therefore, while the reviewer points out issues, the lack of specific guidance makes the feedback 3 but not 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific instances in the paper where improvements are needed. For example, they point out 'we typically considers' in the context of (7), 'two permutation' in Theorem 1, 'until converge' in (14), and other similar instances. The reviewer clearly identifies the specific parts of the paper and provides examples of problems within those parts. This demonstrates a strong grounding in the text and a clear understanding of where the issues lie.", "verifiability_rationale": "The reviewer makes claims about the language usage and grammatical errors in the paper. For example, they state that certain phrases like 'we typically considers' are problematic. However, the reviewer does not provide any logical reasoning, examples, or external references to support these claims. The statements are presented as opinions without any backing. While the reviewer identifies issues, they do not explain *why* these are issues or *how* they should be addressed. Therefore, the claims are made without sufficient justification, making the feedback 3 but not 5.", "helpfulness_rationale": "The reviewer points out several language issues and suggests improvements in 'language usage'. While these are valid observations, the feedback provided is quite general and lacks specific actionable steps. The reviewer identifies problems but doesn't offer concrete solutions. For example, they suggest 'improving language usage' but don't specify *how* this should be done. The suggestions are broad and don't provide a clear path for the authors to follow. Therefore, while the reviewer identifies problems, the feedback is 3 but not 5 due to the lack of specific guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point is a statement of opinion about the limited scope of the evaluative framework. It does not explicitly state any actions or suggest improvements. Therefore, it is not actionable. The reviewer mentions 'considerations restricted to merely three QuestionAnswering tasks and two language models' but does not specify what needs to be done to address this limitation or how to apply it to their own work.", "grounding_specificity_rationale": "The review point mentions 'three QuestionAnswering tasks' and 'two language models' but does not specify which parts of the paper or methodology these tasks or models are evaluating. The reviewer's statement is about the scope of the evaluation framework rather than a specific issue within a defined part of the paper. While the referenced parts exist, the reviewer does not clearly identify the specific section, table, figure, or unique aspect being addressed in relation to these tasks and models.", "verifiability_rationale": "The review point contains a claim: 'the evaluative framework appears somewhat limited in scope.' This claim is supported by the reviewer's reasoning: 'With considerations restricted to merely three QuestionAnswering tasks and two language models, there are reservations about the method's broader applicability. Its potential to generalize to other reasoning or generation tasks or more advanced models, such as vicunna or alpaca, remains a subject of inquiry.' The reasoning provides examples and elaborates on the limitations, making the claim verifiable.", "helpfulness_rationale": "The review point identifies a limitation in the scope of an evaluation framework. While this is a valid observation about the methodology, it does not directly suggest specific improvements or actionable steps for the authors to take in their own work. The feedback is about the limitations of a different framework, not about specific weaknesses in the paper being evaluated. Therefore, it is not 5 for improving the authors' draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a statement of opinion and does not contain explicit or implicit instructions for the authors. Therefore, it is 1.", "grounding_specificity_rationale": "The review point refers to 'the experiments' in general, lacking specificity about which experiments are insufficient. Therefore, it is weakly grounded.", "verifiability_rationale": "The review point contains the claim 'The experiments are not sufficient' but provides no evidence or reasoning to support this claim. Therefore, it is 1.", "helpfulness_rationale": "The review point criticizes the experiments without offering any concrete suggestions for improvement, making it unhelpful to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests a *specific experiment* to evaluate the sensitivity of the method to initialization. They propose varying the distance 'c' between the initial matrix M^0 and the ground truth M^*, and then reporting the performance accordingly. This is a clear and actionable suggestion that authors can directly implement to investigate a potential weakness or area for improvement. The reviewer is not just pointing out a problem, but proposing a concrete way to test it.", "grounding_specificity_rationale": "The reviewer provides a very specific definition of how the initialization should be varied. They mention 'the distance of initialization M^0 to the groundtruth M^*', 'varying distance c', and even provide a formula for sampling matrices M^0 such that the Frobenius norm of M^0  M^* is less than 'c'. This level of detail ensures that the authors can precisely replicate the experiment and understand exactly what aspect of the initialization is being tested. The grounding is explicit and welldefined.", "verifiability_rationale": "The reviewer's suggestion is not only specific but also logically sound and verifiable. They propose a clear methodology: varying the distance 'c', randomly sampling matrices according to the specified condition, and then reporting the performance. This provides a verifiable claim about how the initialization affects the performance. The reasoning is explicit, and the suggestion is testable with a welldefined experimental setup. There are no ambiguities in the proposed method or the claims being made.", "helpfulness_rationale": "The reviewer's suggestion is 5. Exploring the sensitivity of the method to initialization is a relevant and potentially valuable analysis. It can reveal important insights about the robustness and reliability of the method. By understanding how the method behaves with different initializations, the authors can gain a better understanding of its limitations and potential areas for improvement. This is a concrete and actionable piece of feedback that directly addresses a potential weakness or area for further investigation."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a potential simplification in the Frobenius norm definition by removing the absolute value. It also points to a specific location in the paper (line 77), making the action clear and the grounding explicit. While the action itself is about suggesting a change, the reviewer is implicitly suggesting the author should remove the absolute value, which is a concrete action.", "grounding_specificity_rationale": "The comment explicitly mentions 'line 77' in the paper, providing a precise location where the Frobenius norm definition is located. This demonstrates strong grounding as the author can directly identify the referenced part. The comment also explains *why* the absolute value might be unnecessary (tensor entries are real numbers), adding clarity to the grounding by specifying the reason behind the suggestion.", "verifiability_rationale": "The comment contains a claim: 'The absolute value operation in the definition of the Frobenius norm in line 77 is not needed because tensor entries are real numbers.' This claim is 3. While it doesn't provide external references, the reasoning is based on a fundamental property of real numbers, making it logically sound. The reviewer is suggesting a simplification based on a wellunderstood mathematical concept, which can be verified by the author.", "helpfulness_rationale": "The comment is 5. It points out a minor but potentially useful simplification in a definition, which can save the author time and effort. The suggestion is clear and actionable \u2013 the author can simply remove the absolute value. The reviewer's comment is directly aimed at improving the clarity and conciseness of the paper for the author."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the 'clear flaws associated with them' (FIDs and the 'simplistic Inception network') and recommends using 'DinoV2 Frechet Distances'. While the weakness and recommendation are clear, the specific nature of the flaws and the details of DinoV2 are not provided, making it somewhat vague on the implementation level. The reviewer also uses the phrase 'simplify' which is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper and does not identify the issue within that part. The reference to 'C' is a citation but does not specify what aspect of the paper or methodology it relates to in the context of the flaws or the recommendation.", "verifiability_rationale": "The comment contains a claim: 'there have been clear flaws associated with them and the simplistic Inception network C'. The reviewer also provides a suggestion: 'Please use DinoV2 Frechet Distances for the comparisons from C'. The suggestion acts as supporting evidence for the claim. The claim is supported by the recommendation to use DinoV2, but lacks specific details about the flaws of FID and the advantages of DinoV2.", "helpfulness_rationale": "The comment identifies a potential issue (limitations of FID) and provides a concrete alternative (DinoV2). While the specific nature of the FID flaws and the details of DinoV2 are not elaborated upon, the reviewer provides a clear direction for improvement. The recommendation to use DinoV2 Frechet Distances is a helpful suggestion, even if it lacks specific implementation details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue with figure 6C ('it implies negative rates, which is not the case') and provides a concrete solution ('use a second yaxis or another visualization'). This indicates a clear understanding of a problem and a direct suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The reviewer specifically refers to 'figure 6C' and explains the problem within it ('it implies negative rates, which is not the case'). This clear identification of the specific part of the paper demonstrates full grounding. The reviewer also suggests a concrete solution ('use a second yaxis or another visualization'), which is specific to the identified issue.", "verifiability_rationale": "The review point does not contain a claim. It is a suggestion for improvement, not a statement of opinion or judgment. Therefore, it falls under the 'X' category.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion ('use a second yaxis or another visualization') to improve the clarity of figure 6C. While the suggestion is good, it could potentially be expanded upon (e.g., mentioning other visualization types in more detail), making it '4'."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their experience with LSTMs and provides a specific reference (Zaremba et al. 2014) to support their claim that smaller architectures are not necessarily needed for LMs to avoid overfitting. They also ask a direct question about the application of dropout to hidden states, which can be interpreted as an implicit suggestion for clarification. The reviewer provides a clear action (identifying a potential issue) and a concrete detail (the missing information about hidden state dropout).", "grounding_specificity_rationale": "The reviewer explicitly mentions section D.4 of the supplemental material as the source of the questionable statement. This directly identifies the specific part of the paper being addressed, indicating full grounding. They also clearly specify the issue (smaller architectures not needed for LMs to avoid overfitting) and the missing detail (dropout on hidden states), showing high specificity.", "verifiability_rationale": "The reviewer makes a claim by stating that the statement in D.4 is 'questionable' and provides a counterexample (Zaremba et al. 2014). They also pose a clear question about the implementation details of dropout. The claim is supported by the counterexample and the request for clarification points to good verifiability. The reviewer provides a logical reasoning (overfitting isn't the only reason for smaller architectures) and a specific reference (Zaremba et al. 2014).", "helpfulness_rationale": "The reviewer directly addresses a potential misunderstanding the authors might have regarding the regularization of their baseline models. They provide a counterexample to support their claim and ask a specific question about the implementation of dropout. This directly points to a potential issue and provides a clear direction for the authors to investigate. The reviewer's comment is directly related to the specific concern raised in the supplemental section D.4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point presents a comparative statement about the multilingual chainofthought and villa chainofthought without explicitly suggesting a concrete action for the authors. While it raises a question about the contribution of one over the other, it doesn't provide a direct instruction on how to improve their draft based on this comparison. The action is implied but not stated directly.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'multilingual chainofthought' and 'villa chainofthought' when discussing the incremental contribution. This demonstrates a clear grounding of the comment within specific technical terms related to the paper being reviewed. The specificity is high as the comparison is directly between these two concepts.", "verifiability_rationale": "The statement 'The contribution of multilingual chainofthought is incremental compared to the villa chainofthought' is a claim that requires verification. However, the review point itself does not provide any specific evidence, citations, or logical reasoning to support or refute this claim. The verifiability is low as the evidence for 'incremental' is not explicitly presented within this review point.", "helpfulness_rationale": "The review point raises a question about the relative contribution of two approaches but does not provide actionable feedback or suggestions on how the authors should proceed. While it prompts the authors to consider the tradeoffs, it doesn't directly guide them on what to do with their multilingual chainofthought implementation. Therefore, its helpfulness is limited as it doesn't offer concrete steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem of comparing Geffects of isolated unlearning objectives and highlights its potential impact on the comparability of Geffect values across different unlearning objectives and approaches. This is a clear and direct identification of a problem and a suggestion for authors to consider the interaction effects when interpreting the results. The action is 'comparing Geffects of isolated unlearning objectives' and the consequence is 'potential issues with comparability'. This is a concrete and actionable comment.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 4' and focuses on the 'Geffect of each learning objective in isolation'. This precise identification of the section and the specific aspect being addressed makes the grounding very specific. The reviewer clearly pinpoints the area where the concern lies, indicating a strong grounding.", "verifiability_rationale": "The reviewer states a concern about the comparability of Geffect values when unlearning objectives are studied in isolation. However, the reviewer does not provide any evidence, examples, or references to support this claim. The statement is presented as a potential issue without any verification. Therefore, the claim is not fully supported by the provided text. The action is 'studying Geffects of each learning objective in isolation' and the consequence is 'potential comparability issues'. This is a claim without sufficient justification.", "helpfulness_rationale": "The reviewer raises a concern about the comparability of Geffect values when unlearning objectives are studied in isolation. While this raises a valid point about the potential limitations of the methodology, the reviewer does not offer any specific solutions or directions for improvement. The comment is more of a diagnostic or diagnosticlike comment, pointing out a potential issue without providing actionable steps to address it. The action is 'identifying a problem with comparing Geffects in isolation' and the consequence is 'potential impact on comparability'. This is a comment that identifies a potential problem but lacks solutions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a discrepancy in the experimental results (UNIFORM not consistently better in the 1shot setting) and directly asks a question ('Do the authors have a theory...?') to understand this observation. This is a clear and direct action for the authors to take. The reviewer is prompting them to investigate a specific finding.", "grounding_specificity_rationale": "The review point explicitly refers to 'the 1shot setting' and 'UNIFORM' in the context of the experimental results. This clearly grounds the comment in a specific part of the paper being discussed. The reviewer is not leaving any ambiguity about which aspect of the results they are referring to.", "verifiability_rationale": "The reviewer makes an observation ('the tables show that UNIFORM does not always offer a clear advantage...') based on the experimental results. This observation is verifiable. They then pose a question ('Do the authors have a theory...?') to seek further explanation or justification for this observation. While the question itself isn't a claim requiring immediate verification, the preceding statement is a verifiable observation.", "helpfulness_rationale": "The review point identifies a specific inconsistency in the experimental results and asks for an explanation. This is a valuable piece of feedback for the authors. It highlights a potential area where their method or understanding might be lacking. By pointing out this discrepancy, the reviewer is guiding the authors to focus their attention on a specific experimental condition and its implications. This is a significant contribution to their understanding and potential improvement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a 'reason why' for information value being a stronger predictor of dialogue, linking it to 'complementarity' and referencing specific sections (page 7 or 8). This provides a clear direction for the authors to investigate. The action is to explore the role of information value in dialogue prediction and examine the relevant sections of the paper.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'complementarity in page 7 or discussion in page 8'. This is a very specific reference to a part of the paper, allowing the authors to identify the relevant section. The grounding is strong as the section is clearly identified. The specificity is high as the reviewer clearly identifies the concept of information value as a stronger predictor of dialogue and points to the specific sections where this discussion takes place.", "verifiability_rationale": "The reviewer presents a claim about the relationship between information value and dialogue prediction. However, they do not provide any specific examples, references, or logical reasoning to support this claim within the review point itself. The claim is presented as a suggestion for further investigation rather than a verifiable statement. Therefore, it is not 5 based on the information provided in this review point.", "helpfulness_rationale": "The reviewer suggests that the authors should consider the role of information value in dialogue prediction and look at the sections on 'complementarity' and 'discussion'. While this points to a potential area for improvement in the paper's analysis, it does not provide a concrete solution or specific steps to take. It is more of a suggestion for further research or discussion rather than a direct improvement. Therefore, it is 3 in guiding the authors towards a potential area of focus."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that T_a(t) is used in Section 3.1, making the action explicit. However, the reviewer does not specify *how* T_a(t) is used in that section, making the action implicit.", "grounding_specificity_rationale": "The reviewer mentions 'Section 3.1' but does not explicitly identify the specific part of the paper being addressed. However, the reviewer does specify what is missing: the definition of T_a(t).", "verifiability_rationale": "The reviewer makes a claim that T_a(t) is used in Section 3.1 but only defined in Section 4. However, the reviewer does not provide any evidence or justification to support this claim.", "helpfulness_rationale": "The reviewer points out a potential issue in the paper's structure or clarity by highlighting the discrepancy regarding T_a(t). While it might not directly tell the authors what to change, it raises a valid point that could help them understand the paper better."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The action of providing clarification and explanation is implied but not explicitly stated. The reviewer wants the authors to understand and justify the amplitude adjustments, which is a clear action, but it's not directly requested in the text.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 3' and 'Frequency Stability score' without explicitly stating which part of the paper Figure 3 refers to or providing a clear definition of 'Frequency Stability' within the review itself. The authors need to identify the specific section or element in Figure 3 that is being discussed and explain the concept of Frequency Stability.", "verifiability_rationale": "The reviewer asks 'why' these adjustments are effective, but does not claim that the adjustments are effective or require justification. The reviewer is seeking information, not making a claim that needs verification.", "helpfulness_rationale": "The reviewer asks for clarification and an explanation, which is a valuable piece of feedback for the authors. While not explicitly stating what they hope to achieve by receiving this information, the request itself is a positive contribution to the authors' understanding. The formatting issue is also a helpful suggestion for improving the paper's presentation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of comparison with CoCoOp and suggests its necessity. The action of 'comparing' is directly implied and can be clearly identified. The reviewer is pointing out a concrete action to be taken.", "grounding_specificity_rationale": "The review point explicitly mentions 'CoCoOp' by name. This provides a clear and specific reference point within the paper. Furthermore, the reviewer explains why this comparison is necessary, detailing the relevance of the extended version of CoOp. This explanation directly specifies what needs to be addressed.", "verifiability_rationale": "The review point contains a claim: 'It is necessary to compare with CoCoOp'. This claim suggests a specific action (comparison) and provides a reason for it (the relevance of the extended version of CoOp). While the reviewer doesn't provide external references to support this claim, the logical reasoning behind it is clear.", "helpfulness_rationale": "The review point is highly constructive and directly points out a clear omission in the experimental evaluation. It provides a clear rationale for why the comparison is necessary, highlighting the relevance of the extended version of CoOp. This guidance is actionable and directly addresses a potential weakness in the authors' understanding or evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states \"Fig. 1 can also be drawn better\". This indicates an intention to improve the figure. However, the reviewer does not specify *how* the figure should be drawn better. The suggestion is present, but the details are missing, making it only implicitly actionable.", "grounding_specificity_rationale": "The reviewer states \"Fig. 1 can also be drawn better\". While the reviewer implicitly refers to Figure 1, they do not explicitly identify a specific part of the paper, table, figure, or unique aspect where the improvement should be made. The suggestion is general and does not pinpoint the exact location within the paper that needs improvement.", "verifiability_rationale": "The reviewer states \"Fig. 1 can also be drawn better\". This is a claim that the figure can be drawn better. However, the reviewer does not provide any justification or reasoning for why this should be the case. There are no external references or logical arguments presented to support this claim.", "helpfulness_rationale": "The reviewer suggests that Figure 1 should be drawn better. While this points to a potential area for improvement, the suggestion is vague and lacks specific details on *how* the figure should be redrawn. Without more information, the authors cannot readily understand the nature of the improvement or how to achieve it. Therefore, the feedback is 3 but lacks the necessary specificity to be fully beneficial."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: \"Section header (136) should not contain abbreviations that might confuse readers.\" This is a clear and direct instruction for the author.", "grounding_specificity_rationale": "The review point explicitly refers to \"Section header (136)\", clearly identifying the specific part of the paper being addressed. However, the suggestion is general and doesn't specify *which* abbreviations should be removed or why they are confusing.", "verifiability_rationale": "The review point contains a claim: \"Section headers should not contain abbreviations that might confuse readers.\" This is a generally accepted guideline in academic writing. While it's not a strict rule that *must* be followed by *every* section header, it's a valid point that can be helpful for readers. It lacks specific examples or citations to back it up.", "helpfulness_rationale": "This review point is 5. It identifies a potential practical issue (confusion for readers) and suggests a straightforward improvement (removing abbreviations). It directly addresses a concern that an author might have."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The statement 'The technical contribution is unclear' is explicit, as the reviewer directly points out a lack of clarity. However, the reviewer does not specify *what* is unclear, making the action vague. Similarly, 'Most of the analysis are quite standard' is an explicit statement, but it lacks specific details on what constitutes 'standard' analysis, making the action vague overall. The reviewer identifies a problem but doesn't provide concrete steps for improvement.", "grounding_specificity_rationale": "The reviewer makes a general statement about the 'technical contribution' and 'analysis' without specifying a particular section, table, figure, or unique aspect of the paper. They are referring broadly to the work, indicating a lack of specific grounding. The reviewer does not identify a specific part of the paper or method that needs improvement, making the specificity low.", "verifiability_rationale": "The reviewer makes claims about the 'technical contribution being unclear' and 'most of the analysis being quite standard'. However, they do not provide any evidence, reasoning, or references to support these claims. The statements are presented as facts without justification, making the verifiability low. The reviewer does not offer any logical reasoning, common knowledge, or external references to back up their assertions.", "helpfulness_rationale": "The review point primarily criticizes the paper's technical contribution and analysis as being unclear and standard, respectively. While it identifies a potential weakness, it does not offer any suggestions or constructive feedback on how to improve these aspects. The feedback is primarily negative and lacks actionable steps, making it not very helpful for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states the paper's contribution is \"an incremental advancement in efficiency over the TACTiS approach.\" While it identifies the *type* of improvement, it doesn't explicitly recommend an action or explain how to achieve this efficiency. The reviewer points out the lack of concrete steps or details on how to make it efficient. Therefore, it's 2 as it identifies the *what* (efficiency) but not the *how*.", "grounding_specificity_rationale": "The review mentions \"the paper's primary contribution\" and \"TACTiS approach.\" It doesn't explicitly name a specific section, table, figure, or unique aspect of the paper being addressed. The focus is on the *contribution* itself rather than a specific element within the paper. The reviewer is making a general comment about the paper's *contribution* and comparing it to *another approach*. They don't pinpoint a specific part of their own work that needs improvement based on this. Therefore, it's 1.", "verifiability_rationale": "The review states \"The paper's primary contribution seems to be an incremental advancement in efficiency over the TACTiS approach.\" This is a statement of opinion or judgment about the paper's contribution. It also implies a lack of *substantial evidence* for this claim. The reviewer expresses a *suspicion* or *doubt* about the significance of the contribution. They don't provide any concrete evidence or logical reasoning to *support* this claim. The phrase \"more substantial evidence or arguments are needed\" indicates a lack of current justification. Therefore, it's 1 as it presents a claim without providing supporting evidence or justification.", "helpfulness_rationale": "The review points out a potential weakness in the paper's contribution but doesn't offer any concrete suggestions or actionable steps for the authors. It's a critique without a clear path forward. The reviewer states the contribution is \"an incremental advancement\" and suggests \"more substantial evidence or arguments are needed.\" This is a critique of the paper's *impact* or *justification*. It doesn't offer any specific *howto* advice to the authors. Therefore, it's not helpful as it doesn't provide any actionable feedback or guidance to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their agreement with the efficiency argument regarding FLOPs but highlights a potential inconsistency in the description of the S2D structure concerning the number of parameters. They suggest that if the kernel height and width remain the same, the depth would increase, leading to more parameters. This directly points out a lack of clarity and requires the authors to clarify their S2D implementation. The reviewer is asking for a specific clarification, which is a direct action the authors can take.", "grounding_specificity_rationale": "The reviewer refers to 'S2D structure' and the 'number of parameters' as the specific part of the paper being addressed. While they don't provide a specific section number, the concept of S2D structure and the parameter count are clearly defined within that context. The reviewer's request for more details directly targets a specific aspect of the method description. The grounding is explicit in the concepts discussed.", "verifiability_rationale": "The reviewer makes a claim: 'In S2D structure, it is not clear why the number of parameters does not change.' They then provide a logical argument: 'If the kernel height/width stay the same, then its depth will increase, resulting in more parameters.' This logical reasoning and the implication of a discrepancy between the description and the expected behavior of parameters make the claim verifiable. The reviewer also suggests a solution ('more details are expected'), indicating a clear direction for the authors to follow.", "helpfulness_rationale": "The reviewer identifies a potential point of confusion regarding the S2D structure and the number of parameters. They explicitly state their agreement with the efficiency argument but highlight the lack of clarity in the parameter count. This points out a specific area where the authors need to improve their explanation. The reviewer's request for more details is a concrete and actionable suggestion that directly benefits the authors in understanding and implementing their method. The overall impact is significant for the authors' ability to communicate and reproduce the work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'Specifically, the authors do not really comment on why the GPC (benchmark) is performing better than BPC (their method).' They also offer a potential explanation: 'It would be worth reiterating that this is b/c of the bandit feedback and not using information about the form of the cost function.' This shows a direct identification of a problem and a suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the presentation of the simulation study' and then focuses on the specific issue of 'why the GPC (benchmark) is performing better than BPC (their method)'. They even suggest a reason for this, indicating a clear understanding of the relevant part of the paper. This demonstrates high grounding specificity.", "verifiability_rationale": "The reviewer makes a claim: 'the authors do not really comment on why the GPC (benchmark) is performing better than BPC (their method).' They also provide a justification for this claim by stating: 'It would be worth reiterating that this is b/c of the bandit feedback and not using information about the form of the cost function.' This claim is supported by logical reasoning and a specific explanation, making it 5.", "helpfulness_rationale": "The reviewer points out a clear weakness for the authors: the lack of explanation for GPC outperformance. They also offer a potential solution by suggesting the authors reiterate the reason for this, which is directly related to the method and feedback mechanism. This is a clear and actionable suggestion that directly addresses a potential area of confusion for the authors, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests 'I might be helpful to quantify and clarify the claim...'. This is an explicit suggestion for improvement, indicating an actionable point. However, the reviewer does not specify *how* to quantify or clarify the claim, making it only implicitly actionable.", "grounding_specificity_rationale": "The reviewer states 'ReLU does not work very well in very deep or in convolutional networks.' This comment identifies a specific aspect of ReLU's limitations and mentions 'ReLU,' 'deep,' and 'convolutional networks.' While it doesn't pinpoint a specific section or table, it clearly specifies the type of networks where the limitation is being discussed, making it somewhat grounded. The specificity is in the *type* of network rather than a specific element within the network description.", "verifiability_rationale": "The reviewer makes a claim: 'ReLU does not work very well in very deep or in convolutional networks.' This claim is supported by providing a counterexample: 'ReLU was used in the AlexNet paper which, at the time, was considered deep and makes use of convolution.' This provides external evidence to challenge the generality of the claim, making it 3.", "helpfulness_rationale": "The reviewer suggests 'I might be helpful to quantify and clarify the claim...'. While this offers a direction for improvement, it does not provide concrete, actionable steps for the authors to take. The authors would still need to decide *how* to quantify and *how* to clarify the claim. Therefore, while the suggestion is relevant, it lacks the concrete action items that would make it fully helpful."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that the perplexities are over 30 and points to Figure 1 as the location of this information. This is an explicit action pointing to a specific metric. While the reviewer doesn't immediately suggest a concrete action to fix this, identifying the high perplexity is a clear action they can take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 1' and the metric 'perplexities' as the location and type of information. This is a clear and accurate grounding of the reference. The specificity is high as the reviewer is pointing to a specific metric within a specific figure.", "verifiability_rationale": "The reviewer states a fact: 'In Figure 1, the reported perplexities are over 30, which looks pretty high.' This constitutes a claim. However, the reviewer does not provide any evidence or reasoning within this review point to support why these perplexities are high or how they contradict the better BLEU scores. The reviewer asks a question ('How did you calculate perplexity?') which is a request for information, not a verification of their claim.", "helpfulness_rationale": "The reviewer points out a potential issue with the perplexity scores in Figure 1 and notes a discrepancy with the BLEU scores. While this highlights a potential area for investigation, the reviewer does not offer any concrete suggestions or explanations for why this discrepancy might exist. The reviewer's request for clarification on the perplexity calculation is a step towards understanding, but it's not a direct solution or resolution of the issue."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the weakness ('that the consistency between training and inference can be easily satisfied') and suggests an improvement ('I would suggest giving more explanations on this'). This indicates a degree of actionability. However, the suggestion is broad and lacks specific details, making it only partially actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions the lines where the issue is discussed ('Line 9597' and 'Line 308310'). This demonstrates strong grounding. However, the specific nature of the problem within those lines is not identified, making it underspecific.", "verifiability_rationale": "The review point makes a claim about the smoothness of neural models leading to easily satisfied consistency. However, it does not provide any supporting evidence or logical reasoning to back this claim. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point identifies a potential area for improvement (the explanation of the consistency issue) and suggests a concrete action (giving more explanations). This suggests a degree of helpfulness. However, the suggestion is broad and lacks specific details, limiting its potential impact and making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests discussing 'failure cases,' which is a relevant improvement. However, it lacks explicit instructions on how to implement this suggestion. The action is implied but not clearly stated as a concrete action to be taken by the authors.", "grounding_specificity_rationale": "The review point is very general and does not specify which part of the paper or which aspect of the work the authors should consider when discussing 'failure cases.' There is no mention of a specific section, table, figure, or unique element of the paper. The grounding is weak because the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a suggestion for improvement rather than a statement that needs to be justified or supported by evidence. Therefore, it does not fit into the 'Claim Extraction' and 'Verifiability Verification' categories.", "helpfulness_rationale": "The review point suggests adding a discussion of 'failure cases.' While this is a relevant and potentially helpful suggestion for improving the paper, it lacks specific details on how to approach this discussion. The suggestion is general and doesn't provide actionable steps for the authors. Therefore, while the intent is helpful, the lack of specifics makes it only '2'."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment suggests a potential improvement in clarity by introducing epsilon earlier. While the suggestion is directly related to the identified issue, it doesn't explicitly state how to implement this change or what specific action the authors should take. The suggestion is somewhat vague, requiring the authors to infer the next step.", "grounding_specificity_rationale": "The comment explicitly mentions 'Section 4.1' and refers to 'equations (10)' and '(11)', clearly identifying the specific part of the paper being addressed. The comment also specifies the issue as the 'inconsistent use of epsilon'. This provides strong grounding and clearly identifies the area for improvement.", "verifiability_rationale": "The comment points out a potential issue regarding the inconsistent use of epsilon. While it's plausible that this inconsistency exists, the comment doesn't provide a clear explanation or justification for why epsilon is inconsistently used. It also doesn't cite any external references to support this claim. The verifiability is limited as the reasoning is not explicitly stated.", "helpfulness_rationale": "The comment clearly identifies a potential area for improvement in the paper's clarity by highlighting the inconsistent use of epsilon. It directly suggests a concrete action, which is to introduce epsilon earlier. This actionable feedback is directly aimed at improving the authors' draft and is therefore 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem of the lack of discussion on computational complexity and provides concrete suggestions for improvement, such as 'Explicitly stating the upper bounds' and 'Elaborating on empirical runtimes'. These actions are directly identifiable and actionable for the authors.", "grounding_specificity_rationale": "The reviewer refers to 'computational complexity' and specifically mentions 'homomorphism counts,' directly relating to the core topic of the review point. They also reference a specific line (145), indicating they've located the relevant area in the paper. This precise identification of the area and the specific concept demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the lack of discussion on computational complexity and provides a suggestion for improvement. While they don't provide explicit proof that the current discussion is lacking or that their suggestion is superior, the suggestion itself is a verifiable action. The claim is that the paper 'does not adequately discuss the computational complexity...'. The suggestion is a concrete next step for the authors.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improving the paper by explicitly stating the upper bounds of homomorphism counts and elaborating on empirical runtimes. This directly addresses the identified weakness and provides a concrete next step for the authors to take."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "High", "helpfulness_label": "High", "actionability_rationale": "The suggestions are directly stated and do not require inference. For the typo, the reviewer explicitly points out the error ('the form of ..'). For the MCL question, the reviewer clearly states the concern about convergence. The suggestions are also concrete, providing specific actions like correcting the typo and asking a question about the training process.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'line 108' and the specific phrase 'the form of ..'. This strong grounding clearly identifies the location and nature of the issue. The MCL question is also grounded by mentioning the 'training of the baseline MCL with deep learning'. The specificity is high as the reviewer clearly states the problem and asks a direct question about a specific aspect of the training process.", "verifiability_rationale": "The reviewer makes clear claims about the typo and the importance of MCL training convergence. For the typo, the evidence is the presence of 'f' in the text. For the MCL, the reviewer provides a logical reasoning that convergence is crucial for ensemble performance. The evidence is sufficient and the claims are wellsupported.", "helpfulness_rationale": "The review is 5. The reviewer directly points out the error and asks a relevant question about the MCL training. The suggestions are actionable and provide clear guidance for the authors. The question about convergence is particularly valuable as it directly addresses a potential weakness in the baseline method."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out two specific errors in the mathematical formulation and provides a clear explanation of why the sum of squares should be 1/d and not d. The reviewer also directly addresses the potential misunderstanding of the input's dimensionality. This provides clear actions for the authors to take: check the proof, verify the input's dimensionality, and reevaluate the sum of squares calculation.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"Theorem A.3 proof\" and points to the specific equations in their review point. This clearly identifies the section of the paper being addressed, making the grounding fully explicit and precise.", "verifiability_rationale": "The reviewer makes claims about the input x having two indices and the sum of squares calculation. These claims are verifiable by the authors by directly examining the proof in Theorem A.3. The reviewer provides specific examples (the equations) that can be used to verify the correctness of the mathematical steps.", "helpfulness_rationale": "This review point is 5 because it directly identifies specific technical errors in a mathematical proof. The reviewer not only points out a potential misunderstanding of the input's dimensionality but also highlights a concrete calculation error. This actionable feedback is extremely valuable for the authors to understand and correct the issues in their work."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "3 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer explicitly states the concern about the use of vague terms like 'somewhat' and 'good generative ability' in the description. They also suggest that the lack of a clear metric (77%) makes it difficult to assess the correctness of the pluggedin entities/relationships. While the concern is clear, the suggestion about the 77% metric is vague and lacks a clear connection to the proposed solution.", "grounding_specificity_rationale": "The reviewer mentions sections 4.3 and 4.4, indicating a weak grounding as they do not explicitly identify the specific part of the paper being addressed. However, the reviewer clearly identifies the issue (vague terms, lack of grounding) but does not specify *which* parts are problematic, leading to weak specificity.", "verifiability_rationale": "The reviewer makes a claim about the lack of grounding and the difficulty of ensuring correctness. However, the reviewer themselves does not provide evidence to support this claim about the 77% metric or the lack of a mechanism for ensuring correctness. The verifiability of this part of the review is low.", "helpfulness_rationale": "The reviewer's overall point is that the paper needs to address the issue of grounding vague terms and the lack of a robust grounding mechanism. While the concern is valid, the review point itself doesn't offer a solution or a clear next step. It's a critique pointing to a problem."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states the limitation of FedPCL's reliance on pretrained models and suggests exploring lightweight frameworks and prototypebased aggregation. However, it does not explicitly tell the authors what specific changes or modifications they should make to their model architecture or training procedure to address this limitation. The suggestions are general directions rather than concrete steps.", "grounding_specificity_rationale": "The review point generally refers to the 'performance of FedPCL' and its 'sensitivity to pretrained models'. While it mentions 'model accuracy' and 'pretrained models', it does not pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. The reference to 'Table 4' is general and doesn't specify which part of the table or figure is relevant.", "verifiability_rationale": "The review point makes a claim that 'This work adequately addressed the limitations'. While it mentions 'sensitivity to pretrained models' and refers to 'Table 4', the connection between the claim and the proposed solutions (lightweight framework, prototypebased aggregation) is not explicitly and clearly justified within the review point. The link is implied but not rigorously proven.", "helpfulness_rationale": "The review point identifies a limitation of the existing method (FedPCL's dependence on pretrained models) and suggests a potential improvement direction (lightweight framework, prototypebased aggregation). However, it does not provide concrete steps or specific recommendations on how to implement these solutions. The connection between the identified limitation and the proposed solutions is not explicitly detailed, making it less immediately helpful for implementation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states suggestions for improvement, such as moving sections and creating a separate section. These suggestions are concrete and directly address potential organizational issues. The reviewer also suggests referencing common techniques, which are actionable steps for the authors.", "grounding_specificity_rationale": "The reviewer explicitly mentions sections 2.3 and 2.4 where the attention mechanisms are described. This is a clear and accurate grounding of the relevant information. They also suggest referencing normalization and feature scaling, which are specific examples of common techniques.", "verifiability_rationale": "The reviewer makes a claim about the potential benefits of reorganizing the paper and referencing common techniques. This claim is supported by the suggestion that the current structure might be confusing and that separating the attention mechanisms would improve clarity. The reviewer provides a logical reasoning for their suggestion.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as moving sections and creating a separate section. These suggestions are directly aimed at helping the authors understand and implement the proposed changes. The reviewer also suggests referencing common techniques, which are practical steps for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer's comment is explicit and directly points out a potential issue with the mathematical notation used to describe graphs. They suggest that the notation should be changed to use multisets instead of sets to accurately represent graphs with repeated vertex or edge labels. This is a clear indication that the reviewer has identified a specific action that needs to be taken to improve the notation.", "grounding_specificity_rationale": "The reviewer's comment is wellgrounded as they specifically point out a potential improvement to the mathematical notation used in section 4. They identify the section number and the specific issue (using sets instead of multisets for graphs with repeated labels). This shows a clear understanding of the context and the specific detail being addressed.", "verifiability_rationale": "The reviewer's suggestion to use multisets is a specific and verifiable claim. They propose a concrete change to the notation that would make it more accurate in representing graphs with repeated labels. This claim is supported by the logical reasoning that multisets are necessary to capture the multiplicity of labels in such graphs.", "helpfulness_rationale": "The reviewer's comment could be helpful depending on the context. If the authors are working with collections of graphs and need to represent the frequency of different graph structures, their suggestion to use multisets would be 5. However, if they are only dealing with single graphs, the suggestion might be less immediately useful. The comment is specific about the potential improvement in section 4."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point offers two main suggestions:\n1. Drawing a table to compare CoT methods: This is an explicit action with concrete details (drawing a table).\n2. Questions about assumptions and selection criteria: These are explicit actions (asking questions) and implicitly suggest an action of examining the rationale and criteria.\nThe reviewer also poses questions, which can be interpreted as actions to seek clarification.\nThe level of actionability is somewhat vague as the reviewer doesn't specify *how* to draw the table or *what specific dimensions* to compare.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'section 4.2' and 'Table' in their suggestions. This demonstrates a clear understanding of the paper's structure and a desire to engage with specific content. The questions are directly related to the content of the paper.", "verifiability_rationale": "The reviewer is not making a claim that *something is wrong*. They are asking questions and suggesting a way to improve the presentation. While the suggestions could be verified by examining the paper, the reviewer isn't presenting a definitive statement that requires external evidence. The questions themselves are verifiable as requests for information.", "helpfulness_rationale": "The reviewer provides two main suggestions:\n1. Drawing a table to compare CoT methods: This is a concrete suggestion that directly addresses the need for better clarity and comparison. It is likely to be helpful for the authors.\n2. Questions about assumptions and selection criteria: These are valid inquiries about the methodology, seeking clarification and understanding of design choices. These are also likely to be helpful.\nThe reviewer's suggestions are specific and actionable, directly addressing potential areas for improvement. The questions are also valuable for understanding the rationale behind the experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is an implicit action, as the reviewer identifies the missing information. The reviewer also implies the need to go back and check the methods section for clarification, making it 3.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'title', 'abstract', 'introduction', and 'discussion' as the sections lacking explanation. This is strong grounding as the specific parts of the paper are identified. The reviewer also specifies the *type* of information needed ('explanation that the results are for unsupervised random forests').", "verifiability_rationale": "The reviewer states that the title, abstract, introduction, and discussion 'do not explain that the results are for unsupervised random forests'. This is a claim that can be verified by examining those sections of the paper. The reviewer also states that this omission is 'a fairly serious omission' and that 'casual readers would remember the wrong conclusions', indicating that the reasoning behind the claim is clear and the consequences are wellunderstood. While the reviewer doesn't provide a specific reference, the logical reasoning and the impact on interpretation are evident.", "helpfulness_rationale": "The reviewer highlights the potential for 'casual readers to remember the wrong conclusions' and the concern about 'publishing results without sufficient peer review' due to the lack of clarity about the experimental setup. This is a direct and impactful statement about the consequences of the missing information, making it 5 for the authors to understand the importance of this clarification."}
{"actionability_label": "4", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'no significance testing is done' and provides specific examples (line 486 and the dBLEU scores). This clearly identifies an actionable gap. The reviewer also suggests a concrete action: 'including checking the distribution and accounting for multiple comparisons'. This demonstrates a clear understanding of what needs to be done to address the identified weakness.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'specific methods' and names examples like 'ChatGPT', 'GPT4', 'FeedME2', and 'PPO'. They also refer to specific metrics like 'dBLEU' and 'humeval'. This demonstrates strong grounding as the reviewer can accurately pinpoint the parts of the paper being discussed. The reviewer further specifies the *issue* by pointing out the 'minimal difference' in scores, indicating a clear understanding of what needs to be addressed.", "verifiability_rationale": "The reviewer makes a claim: 'The conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness'. This is a statement that could be argued. The reviewer also provides supporting evidence for their assessment of verifiability. They state that 'the difference between zh>en ChatGPT (17.4 dBLEU; 2.8/2.9 humeval) and GPT4 (18.8 dBLEU; 2.6/2.8 humeval) and the scores for FeedME2 (16.1 dBLEU; 2.2/2.3 humeval) and PPO (17.2 dBLEU; 2.6/2.7 humeval) is minimal and it's hard to say whether it is significant without proper testing'. This provides specific reasons why the claim is not wellsupported and suggests *how* testing should be done (checking the distribution and accounting for multiple comparisons).", "helpfulness_rationale": "The reviewer's comment is clear, concise, and directly points out a specific weakness in the paper (the lack of significance testing). They also provide a concrete suggestion for improvement ('including checking the distribution and accounting for multiple comparisons'). This makes the comment actionable and constructive for the authors. The reviewer's comment is also specific, focusing on the comparison between different models and the dBLEU scores mentioned in the paper."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests providing more details about the baselines in Figure 5 and extending CATER to other languages. While the reviewer doesn't explicitly state an action is missing, the suggestion to add details implies a desire for a more concrete understanding of the experimental setup. The language extension is a forwardlooking comment, not a direct request for improvement in the current draft. Therefore, while the reviewer's suggestion is not entirely actionable, it points towards a need for more specific information.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 5' in their review point. This indicates a clear identification of the specific part of the paper being addressed. However, the reviewer does not specify *what* is wrong or missing in Figure 5, nor does they identify the baselines specifically. The issue is presented generally as 'the two baselines presented in Figure 5'.", "verifiability_rationale": "The reviewer states their desire to 'see more details about the two baselines presented in Figure 5'. This is a claim that requires justification. However, the review point does not provide any evidence or reasoning to support this claim. The reviewer is stating their preference for more information, not providing a logical argument or reference for why the baselines are lacking or why Figure 5 is 1.", "helpfulness_rationale": "The reviewer's comment is a direct suggestion for improvement: 'I would like to see more details about the two baselines presented in Figure 5'. This is a clear and actionable feedback aimed at enhancing the clarity and completeness of the paper. The reviewer is not critiquing existing content but rather proposing a concrete change to improve it. The suggestion to extend CATER to other languages, while valuable, is a forwardlooking comment and not a direct request for improvement in the current draft. The focus of the helpfulness score will be on the request for more baseline details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2: 3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem: 'unclear Literature Review' and suggests a solution: 'provide a more explicit and comparative analysis of related work'. This directly translates to an actionable suggestion for the authors. While the reviewer doesn't specify *how* to make the analysis explicit, the *act* of providing a more explicit analysis is clear. The reviewer also mentions 'GFlowNet for sequence generation' as a specific example, indicating a concrete area of focus.", "grounding_specificity_rationale": "The reviewer mentions 'GFlowNet for sequence generation' as a specific example within the context of the 'unclear Literature Review'. While the paper itself might not explicitly label GFlowNet as such, the reviewer's mention strongly implies a specific area of the paper they are referring to. The reviewer could have been more explicit about which part of the paper they are referring to as 'unclear', making the grounding less clear.", "verifiability_rationale": "The reviewer states a problem ('unclear Literature Review') and suggests a solution ('more explicit and comparative analysis'). This constitutes a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support why a clearer literature review is needed or how GFlowNet would specifically address the identified lack of clarity. The suggestion is presented as a general improvement without specific justification.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by pointing out the need for a clearer literature review and offering a concrete solution: 'provide a more explicit and comparative analysis of related work'. This directly addresses a potential weakness in the authors' work. While the reviewer doesn't elaborate on the *why* behind the need for clarity or the *impact* of GFlowNet, they do offer a specific action the authors can take to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that section 3.2 can be eliminated. However, they do not provide any specific reasons or details about what might be wrong with section 3.2. The action is stated, but the implementation is vague.", "grounding_specificity_rationale": "The reviewer refers to 'section 3.2', which is a specific part of the paper. However, they do not explain *why* they believe this section can be eliminated. The grounding is explicit, but the specificity is lacking.", "verifiability_rationale": "The reviewer makes a claim that 'section 3.2 can be eliminated'. However, they do not provide any justification or reasoning for this claim. There is no logical reasoning, common knowledge, or external references supporting this suggestion.", "helpfulness_rationale": "The reviewer suggests removing section 3.2. While they identify a specific section, they do not provide a reason *why* this section should be removed. This makes the suggestion less actionable and less helpful for the authors to understand the specific issues."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "Both suggestions directly propose changes to the paper. The first suggests adding an explanation, and the second suggests adding labels to figures. Both are clear actions the authors can take.", "grounding_specificity_rationale": "The suggestion about including labels for subfigures in Figs 3 and 4 is fully grounded as it explicitly mentions 'Figs 3 and 4'. However, the suggestion about explaining the link between IP and terms/equations is less grounded as it refers to a conceptual link rather than a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "Neither suggestion makes a claim that requires verification. They are requests for improvement or observations about current practice. Therefore, they are not verifiable in the sense of providing evidence for a statement.", "helpfulness_rationale": "Both suggestions are valuable and directly address potential weaknesses or areas for improvement in the paper. The suggestion to explain the link between IP and terms/equations is helpful for improving understanding. The suggestion to include labels for subfigures in Figs 3 and 4 is helpful for improving the clarity and readability of the figures."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'it would be better to provide some ablation experiments' and implies the ablation should be conducted on the 'tricks' mentioned in Section 3.4. The action is clearly defined, and the expected outcome (validating model performance) is also stated. The reviewer is directly addressing a potential improvement to the experimental design.", "grounding_specificity_rationale": "The comment explicitly refers to 'Section 3.4' as the location of the 'tricks'. This is a clear and precise identification of the specific part of the paper being addressed. The grounding is literal and accurate.", "verifiability_rationale": "The comment presents a suggestion ('it would be better to provide some ablation experiments') as a claim that the current evaluation might be lacking in thoroughness regarding the impact of the 'tricks'. The comment also provides a direction for verification ('validate the model performance further'). While it doesn't provide a concrete example of the ablation experiments, it clearly suggests a method for validation, making it 3.", "helpfulness_rationale": "The comment provides a constructive suggestion to improve the evaluation of the model's performance by conducting ablation studies on the 'tricks' from Section 3.4. This is helpful for the authors as it directly addresses a potential area for improvement in their experimental design and provides a clear direction for further investigation. The suggestion is specific and actionable, although it doesn't provide a complete solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the issues with Appendix A and Proposition B.1. The reviewer clearly identifies that Appendix A is left blank and that the purpose of Proposition B.1 is unclear. The phrasing 'Furthermore, the authors\u2019 socalled \u201cproof\u201d is missing' indicates a direct action the authors should take \u2013 provide a proper proof. The reviewer also points out that the partitioning principle is wellknown, suggesting a lack of novelty or contribution, which is a concrete action the authors should consider.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Appendix A' and 'Proposition B.1' in the review point. This precise identification of the location and the specific element within the paper demonstrates strong grounding. The reviewer not only points to the location but also explains the nature of the issue with Proposition B.1 \u2013 it's 'unclear' and potentially unnecessary. This specificity goes beyond just saying 'Appendix B is unclear'.", "verifiability_rationale": "The review point contains a claim: 'This is a wellknown concept in machine learning, and furthermore, the authors\u2019 socalled \u201cproof\u201d is missing.' This is a statement of opinion and a factual claim about the missing proof. The reviewer provides reasoning for this claim by stating the concept is 'wellknown' and the 'proof is missing'. While the reviewer doesn't provide specific examples of the missing proof, the claim itself is verifiable based on the reviewer's assertion. The reviewer also points out the 'unclear purpose' of Proposition B.1, which could be further clarified with references or examples, but the claim itself is verifiable.", "helpfulness_rationale": "The review point is 5 as it directly points out specific issues in the paper. The reviewer clearly identifies that Appendix A is blank and Proposition B.1's purpose is unclear. The reviewer also highlights the lack of a 'proof' and the wellknown nature of the concept, all of which are concrete feedback that the authors can use to improve their work. The suggestions, while not actively proposing changes, are pointing towards specific areas for improvement, making the review point very actionable and helpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion about the paper's contribution and the model's approach but does not explicitly state an action or provide guidance on how to improve the paper. While it identifies a potential weakness, it lacks concrete steps for the authors to take.", "grounding_specificity_rationale": "The reviewer refers to the 'contribution of this paper' and the 'proposed model' but does not specify which particular section, table, figure, or unique element within those areas is limited or incremental. The grounding is present in identifying the broad areas, but the specificity is lacking.", "verifiability_rationale": "The review point contains a claim ('In my opinion, the contribution of this paper appears somewhat limited' and 'the proposed model seems incremental in its approach') but does not provide any external references, logical reasoning, or examples to support these claims. The verifiability is low as there is no justification for the stated opinions.", "helpfulness_rationale": "The review point is a statement of opinion about the paper's contribution and the model's approach. While it identifies a potential weakness, it does not offer specific, actionable feedback or suggestions on how to improve the paper. The helpfulness is limited as there are no concrete steps or guidance provided for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a discrepancy in the experimental setup, specifically mentioning the different benchmarks used for evaluating different OPE methods in Figure 4 and Figure 5. This directly identifies an actionable issue: the inconsistency in the experimental design. The reviewer is asking the authors to reflect on why the benchmarks differ, which is a clear indication of a lack of explicitness in the review point.", "grounding_specificity_rationale": "The reviewer explicitly asks the authors to comment on the differences between the two sets of evaluation methods used in the experiments. This directly addresses the aspect of grounding specificity. The reviewer is asking the authors to identify the specific parts of the paper being addressed (the evaluation methods and their corresponding benchmarks) and explain what needs to be improved regarding these methods. This shows a clear attempt to ground the feedback in the specific experimental choices.", "verifiability_rationale": "The reviewer points out a potential lack of justification for the inconsistent benchmarks used in the experiments. While the reviewer doesn't explicitly state that the claim about the differences in benchmarks is not supported by evidence, the act of asking for clarification on the differences implies a need for justification. This suggests that the reasoning or common knowledge supporting the experimental choices is lacking, making the claim 3.", "helpfulness_rationale": "The reviewer's comment is direct and constructive. They are not criticizing the authors' work but rather suggesting improvements to the experimental design. The reviewer is asking the authors to reflect on their choices and provide explanations for the differences in benchmarks. This is a helpful comment as it directly points to areas where the authors can improve their work, making it 5 and helpful."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point implicitly suggests the need to discuss iteration cost but doesn't explicitly state the action or provide concrete details on how to do it. The action of discussing iteration cost is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the proposed method' and 'related methods including baseline methods', indicating a clear identification of the specific parts of the paper being addressed.", "verifiability_rationale": "The review point is a suggestion to include information about iteration cost, which is a recommendation rather than a claim that requires verification. It doesn't provide logical reasoning, common knowledge, or external references to support the suggestion.", "helpfulness_rationale": "The review point identifies a valid gap in the discussion \u2013 the lack of iteration cost analysis \u2013 and suggests adding this analysis. While it points out a weakness, it doesn't provide specific guidance on how to analyze or implement the iteration cost. The suggestion is relevant but lacks detailed instructions."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a discrepancy between the authors' statement about the center correlation and its use in the figure. While the authors *state* something about the center correlation not being insightful, the *action* of using it in the figure requires the reader to infer the reason for this action. The connection between the statement and the action is not explicitly stated, making the action somewhat implicit.", "grounding_specificity_rationale": "The reviewer's comment highlights a lack of clarity in the authors' statement about the center correlation. The authors mention the metric but do not explicitly identify the *specific* part of their method or analysis where the center correlation was used in Figure 4. This makes the grounding of the comment somewhat weak, as the reviewer is left to infer the connection. Furthermore, while the authors *imply* the center correlation is used for comparison, they don't explicitly state *why* it's useful in this context, making the grounding not fully specific.", "verifiability_rationale": "The reviewer's question about the authors' statement constitutes a claim that the center correlation was not insightful for discriminating model defenses. The verifiability of this claim depends on how the authors *support* this statement. If the authors provide a brief explanation or justification for why the center correlation is not insightful, the claim would be 3. However, if they simply state the claim without further explanation, it would be 1. Based on the provided text, it appears the authors do not provide any explicit justification, making the claim somewhat 1.", "helpfulness_rationale": "The review point is not very helpful because the authors do not clearly explain the reasoning behind using the center correlation in Figure 4, despite stating that it was not insightful for discriminating model defenses. The reviewer is left to infer the connection and the purpose of the metric in the figure, which reduces the value of the comment for the authors. A clearer explanation would have been beneficial."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point directly identifies specific weaknesses in the paper's experimental evaluation. It points out the absence of an ablation study for the 'picking' step, which is a specific action the authors could have taken to isolate the impact of this component. This makes the review point actionable as it suggests a concrete experiment to be conducted.", "grounding_specificity_rationale": "The review point explicitly mentions '2.2. Experiments on CIFAR' and then further breaks it down into '2.2.1. The continual learning literature has extensive experiments on this dataset and the paper only compares to one approach (DEN)' and '2.2.2. It is unclear if DEN is correctly used/evaluated. It would have been more convincing if the authors used the same setup as in the DEN paper to make sure the comparison is fair/correct.' The reviewer not only identifies the area of concern but also specifies the baseline (DEN) and even suggests a way to improve the evaluation (using the same setup as the baseline paper). This demonstrates strong grounding as the reviewer can accurately pinpoint the section and the specific issue within that section.", "verifiability_rationale": "The review point does not contain any claims that require verification. It is a statement of observation about the paper's content and methodology. There are no statements that require logical reasoning, common knowledge, or external references to be considered verifiable.", "helpfulness_rationale": "The review point provides specific feedback on the paper's experimental evaluation. It points out missing elements (ablation study) and limitations in the conducted experiments (limited baselines, potential incorrect implementation). This feedback is directly aimed at helping the authors improve their work by guiding them to conduct more comprehensive experiments and ensure the validity of their comparisons. The suggestions are concrete and actionable."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests removing the 45degree line and adding a thin gray diagonal line to the plot. This is a clear and concrete action that can be directly implemented. The reviewer also specifies the area where the change should be made ('above/below diagonal') and the type of line to add. This makes the action both explicit and concrete.", "grounding_specificity_rationale": "The reviewer refers to 'above/below diagonal' in the context of a plot. While the reviewer specifies the *area* of the plot where the change is suggested, they do not explicitly identify whether they mean the diagonal above or below the main diagonal. Therefore, the grounding is weak. However, the reviewer does specify the *type* of line they suggest ('a thin gray diagonal'), making the specificity somewhat clear regarding the line itself, but not the exact diagonal location.", "verifiability_rationale": "The reviewer presents a claim that 'nitpicking: I find \"above/below diagonal\" (add a thin gray diagonal to the plot) easier to interpret than \"above/below 45 degree\", which sounds like a local property (e.g., not the case where the red line saturates and has \"0 degrees\").' This claim is supported by reasoning. The reviewer argues that 'above/below diagonal' is more intuitive for visualizing relationships, especially when the red line saturates. While the reviewer does not provide external references, the reasoning is logical and based on common sense about visual clarity. Therefore, the claim is 3.", "helpfulness_rationale": "The reviewer's suggestion is directly actionable and addresses a potential improvement in the clarity of a visual element (the plot). The reviewer clearly states what change they propose ('add a thin gray diagonal line') and where they suggest it be placed ('above/below diagonal'). This makes the review point 5 for the authors as it provides a clear next step to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states what is unclear and what is not shown. While the reviewer points to a specific section (2.3), the *content* of that section and its relation to the RNNs isn't detailed. The reviewer *identifies a gap* but doesn't explain *how* the model in section 2.3 relates to the RNNs. This makes it 3 in the sense that it highlights a need for clarification, but the action isn't taken for the author.", "grounding_specificity_rationale": "The reviewer explicitly mentions Section 2.3 as the location of the model in question, achieving full grounding. The reviewer also specifically mentions 'nonlinear RNN models' and 'taskoptimized approaches' as the context being compared to the proposed model, further strengthening the grounding. The reviewer *specifically identifies the gap* as the lack of demonstration of the model's relation to the RNNs and the lack of explanation of how it provides 'further explanation.' This shows the grounding specificity of identifying the issue and why it needs to be addressed.", "verifiability_rationale": "The reviewer makes a claim that the scientific insight is unclear and that the model is not shown to be a prototype approximation to the RNNs. The reviewer provides a reason for why the insight is unclear (lack of demonstration and lack of explanation of the explanation). The reviewer references specific elements of the paper (Section 2.3, RNNs) to support their claim. This provides verifiability through logical reasoning, common knowledge (understanding of model comparisons), and external references (knowledge of emergent behavior).", "helpfulness_rationale": "The reviewer states the comment is unclear and not shown to address the gap. This indicates a lack of actionable feedback. While the reviewer identifies a need for more explanation, they don't offer specific suggestions on how to improve the model or the comparison. The feedback is more about identifying the problem than providing a solution. The comment is also a direct criticism of the clarity and completeness of the paper, which is a valid point but doesn't immediately offer concrete steps for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point directly asks for clarification on how groundtruths are built and how the network predicts all keypoints despite the localized prediction approach. This directly points to areas needing clarification or correction in the paper, making it 5. The reviewer is explicitly asking for information that is not immediately clear, which is a clear indication of a need for action.", "grounding_specificity_rationale": "The reviewer is asking about the construction of groundtruths, which requires the authors to infer the process from the description. This makes the grounding weakly grounded. The reviewer is also asking how the network predicts all keypoints despite the localized approach, which requires the authors to infer how the network handles keypoints outside the defined radius. This makes the specificity underspecific. While the questions are clear, the lack of explicit detail in the paper makes them difficult to pinpoint, contributing to the '3' category.", "verifiability_rationale": "The reviewer raises a question about the consistency between the training objective (Eq. 2) and the groundtruth construction. This requires the authors to understand the training process and the groundtruth generation process and verify if they align. This makes it 3. The lack of explicit details about the network architecture and groundtruth generation makes it difficult to definitively verify the reviewer's concern, contributing to the '3' label. The reviewer is not presenting a claim that is definitively true or false, but rather a potential inconsistency that needs investigation.", "helpfulness_rationale": "The review point raises a valid concern about the consistency between the network's prediction scope and the groundtruth generation. If this is a genuine issue, addressing it could clarify a key aspect of the method and potentially resolve a potential inconsistency. Therefore, it is 3. The impact on the overall understanding and usability of the method depends on the validity of the concern, which requires further investigation. It's not a critique of fundamental flaws, but a clarification needed."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit feedback on several key areas. It directly points out the issue with figure readability, the missing connection between equations, the introduction of a new variable without context, and the undefined parameters. Each of these points is clear and directly identifies a problem that needs to be addressed. While the reviewer doesn't explicitly state *how* to improve these aspects, the feedback is clear and actionable.", "grounding_specificity_rationale": "The review point is 1 in a specific section or table. While the reviewer mentions 'equation 5', 'equation 4', and 'theta^(t+1/2)', they don't explicitly state *which* figure or table is being referred to. The parameters S* and S~ are mentioned, but without specific references to their location in the text. The criticism is general and points to missing definitions rather than specific instances.", "verifiability_rationale": "The review point makes claims about the paper's content. It states that the figures are small and unreadable, that equation 5 doesn't follow from equation 4, that theta^(t+1/2) is introduced without explanation, and that S* and S~ are undefined. These are all claims that could potentially be supported by evidence or references within the paper. However, the reviewer doesn't provide any specific examples or references to support these claims. Therefore, the verifiability is low as the claims are presented without justification.", "helpfulness_rationale": "The review point is 5 as it directly identifies several areas where the paper could be improved. It points out a clear issue with figure readability, highlights a missing explanation in the mathematical formulation, and points out missing definitions of crucial parameters. These are all actionable suggestions that would significantly enhance the clarity and completeness of the paper. The reviewer provides specific examples of what is missing, making the suggestions concrete and directly useful to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states actions that authors should take, such as 'increase the font size' and 'correct the formatting'. These are direct and concrete actions that can be easily implemented. The reviewer also points out specific locations (legends, axis labels, figure captions) where improvements are needed, further enhancing the actionability.", "grounding_specificity_rationale": "The review point explicitly identifies the specific parts of the paper being addressed. It mentions 'texts in legends and axis labels', 'proposition number', 'confusion between numbered propositions and equations', and 'texts in captions'. These are literal mentions of specific sections and elements, demonstrating strong grounding specificity.", "verifiability_rationale": "The review point makes claims about the current state of the document, such as 'texts in legends and axis labels should be larger' and 'Captions and legend's font should be larger'. However, it does not provide any logical reasoning, external references, or examples to support these claims. Therefore, it is not 5, although the claims themselves are clear and actionable.", "helpfulness_rationale": "The review point directly addresses concrete issues that authors are likely to encounter, such as small text in legends and axis labels, incorrect formatting of proposition numbers, and confusion between numbered propositions and equations. The suggestions are clear and actionable, making the review point 5 for guiding improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their desire to add Journey TRAK as a baseline and provides a reason for this suggestion (comparing effect sizes). The reviewer also infers the need to specify the 'step of the sampling trajectory' implicitly by referencing Figure 2 of the Journey TRAK paper, which shows a specific comparison relevant to their point. While the need for specification isn't fully explicit, the intent is clear.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'counterfactual experiments' and implicitly refers to the methodology within that section. They also clearly specify the suggestion: 'I would have liked to see a comparison against Journey TRAK 1 used at a particular step of the the sampling trajectory.' and further specifies what they believe is missing and why: 'In particular, 1, Figure 2 shows a much larger effect of removing highscoring images according to Journey TRAK, in comparison with CLIP cosine similarity.' This indicates a high level of grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim: 'For the counterfactual experiments, I would have liked to see a comparison against Journey TRAK 1 used at a particular step of the the sampling trajectory.' They then provide supporting evidence by stating: 'In particular, 1, Figure 2 shows a much larger effect of removing highscoring images according to Journey TRAK, in comparison with CLIP cosine similarity.' This provides a logical reasoning and a reference to external work, making the claim verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: adding Journey TRAK as a baseline for comparison in the counterfactual experiments. They also provide a reason for this suggestion, linking it to a potential discrepancy observed in another paper (Journey TRAK Figure 2). This directly addresses a potential limitation in the current methodology and offers a concrete improvement. The suggestion is specific and directly relevant to the identified area."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests an analysis of the placement of adaptive convolutions based on the experimental results. While the reviewer identifies a potential issue (ACNNv3 performing worse than ACNNv2), the specific action to take isn't explicitly stated. The reviewer implies that further investigation into where adaptive convolutions are most effective is needed, but doesn't provide concrete steps on how to perform this analysis. Therefore, the action is implicit rather than explicit.", "grounding_specificity_rationale": "The reviewer mentions 'adaptive convolutions' and 'Table3', indicating some level of grounding. However, they don't explicitly state which specific parts of the table or the exact layers were analyzed. The reviewer refers to the general concept of 'placement' without pinpointing the precise elements being discussed. This makes the grounding somewhat weak as the authors need to infer the specific parts being addressed.", "verifiability_rationale": "The reviewer makes a claim that the placement of adaptive convolutions is important based on the experimental results presented in Table 3. They compare the performance of ACNNv2 and ACNNv3, which have different placements of adaptive convolutions. The reviewer provides the experimental results as evidence to support their claim. However, the reasoning behind why the specific placement differences lead to performance variations is not explicitly detailed. The claim is supported by the results, but the logical connection between the placement and the results could be clearer.", "helpfulness_rationale": "The reviewer provides a suggestion for improvement by pointing out a potential issue with the experimental setup and suggesting further analysis of the placement of adaptive convolutions. While this is a valuable suggestion and could help the authors improve their draft, it doesn't directly tell them *what* to change or *how* to implement the analysis. The reviewer is offering a higherlevel suggestion rather than a direct, actionable fix. Therefore, it's 3 but not the most actionable form of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer is making a statement about the information content of a method's output, suggesting a consequence (information loss). While they are implicitly suggesting an action (further analysis), the review point itself doesn't explicitly ask for this. The reviewer is critiquing an existing method rather than providing a direct feedback point for the authors of the paper being reviewed. Therefore, the actionability is somewhat implicit and not directly actionable within the context of improving the reviewed paper. The reviewer is pointing out a potential issue and suggesting a direction for further investigation, but the review point itself doesn't directly propose a solution or clarification for the authors of the paper being reviewed.", "grounding_specificity_rationale": "The reviewer is discussing the relationship between ancestral graphs and DAGs and making a claim about the information loss. However, they are not explicitly pointing to a specific section, table, or unique aspect of the paper they are reviewing where this discussion would be most relevant. The reviewer is making a general comment about the methods themselves. Therefore, the grounding specificity is not explicitly identified within the context of the paper being reviewed. The reviewer is making a comment about the methods, not a specific issue within the paper.", "verifiability_rationale": "The reviewer makes a claim about the information content of ancestral graphs compared to DAGs and provides a reason ('This is the price that has been paid to gain a better performance'). This provides a basis for logical reasoning and justification, making the claim verifiable. The reviewer is providing a rationale for their statement, which supports the claim.", "helpfulness_rationale": "The reviewer is criticizing a method and suggesting an analysis of the information loss. While they are providing a suggestion, it is not a direct, actionable feedback point for the authors of the paper being reviewed. The reviewer is pointing out a potential limitation of an existing method, but they are not proposing a specific improvement or clarification for the authors of the paper they are reviewing. The helpfulness is limited to the context of improving the existing method, not the reviewed paper itself."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the motivation for a timevarying Q ^ t and S t , which does not directly instruct the author on what changes to make. While it prompts the author to consider the implications of this change, it does not provide explicit steps or actions to take. The reviewer is asking 'what is the effect' rather than 'how should we change'.", "grounding_specificity_rationale": "The review point discusses the motivation and potential effects of timevarying Q ^ t and S t but does not explicitly refer to a specific section, table, figure, or unique element of the paper. The focus is on the *concept* of timevarying parameters rather than a specific location within the paper.", "verifiability_rationale": "The review point does not make a claim or assertion that requires verification. It is a question posed to the author, asking them to consider the implications of a design choice. There is no statement that needs to be proven or justified within the review point itself.", "helpfulness_rationale": "The review point is 3 in that it prompts the author to consider the motivation and potential effects of a timevarying parameter. This encourages the author to think critically about their model and its assumptions. However, it does not provide a direct solution or suggestion, making it less impactful than a review that offers concrete improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer attempts to clarify the difference between RepPoints and other regression methods in object detection, specifically mentioning anchorbased regression, RepPoints' regression to feature map locations, and the findings of RetinaNet and ATSS. They express uncertainty about the novelty of RepPoints. While the reviewer doesn't explicitly state an action they want the authors to take, they are asking for clarification on a key aspect of the method, which can be considered actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'RepPoints' and 'regression in RepPoints' and compares it to 'anchorbased regression' and the regression in 'RepPoints' to the 'location of feature maps'. They also mentions 'RetinaNet' and 'ATSS' in the context of regression. The reviewer clearly identifies the specific methods being discussed and their confusion about the differences. This indicates strong grounding specificity.", "verifiability_rationale": "The reviewer states their 'doubts about the definitions in Table 1' and asks for clarification on the difference between 'anchorbased regression' and 'the regression in RepPoints'. They express uncertainty about the 'different between anchorbased regression and the regression in RepPoints in RetinaNet' and the 'regression methods do not influence a lot' in 'ATSS'. While the reviewer doesn't present a specific claim that requires verification, their expressed uncertainty about the definitions and the lack of clarity in the paper suggest a lack of verifiability in the reviewer's understanding of the methods.", "helpfulness_rationale": "The reviewer explicitly states 'I have some doubts about the definitions in Table1' and asks for clarification on the 'different between anchorbased regression and the regression in RepPoints'. They express uncertainty about the 'motivations here is not solid enough'. This directly questions the significance and justification of the proposed method and the paper's contribution. The reviewer's lack of clarity about the differences and the influence of regression methods on performance raises concerns about the perceived value and impact of the work. This is a 5 review point as it directly challenges the core contribution."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the issue: 'The caption for Figure 7 is incorrect, and should be corrected to \"Edge Dynamics\" from \"Node Dynamics\"'. The action is clear: correct the caption. The method is also explicit: change the label from \"Node Dynamics\" to \"Edge Dynamics\". The information provided is sufficient for the authors to understand the problem and the desired change.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 7', which is a specific part of the paper. It also clearly identifies the issue with the caption and specifies the correct label ('Edge Dynamics') and the incorrect label ('Node Dynamics'). This demonstrates a high level of grounding as the specific figure and the nature of the error are clearly identified.", "verifiability_rationale": "The review point contains a claim: 'The caption for Figure 7 is incorrect, and should be corrected to \"Edge Dynamics\" from \"Node Dynamics\"'. However, the review point itself does not provide any evidence or justification to support the claim that the 'Node Dynamics' label is indeed incorrect. The suggestion is presented as a proposed change rather than a verifiable statement based on information within the review point.", "helpfulness_rationale": "The review point directly points out a potential issue (an incorrect caption) and offers a concrete solution (changing the label). This directly addresses a practical concern an author might have when working with the paper and provides a clear direction for improvement. The suggestion is actionable and directly related to the identified problem."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing information 'standard deviation after multiple experiments' and suggests a concrete action: 'clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method'. This directly addresses a deficiency and provides a clear path for improvement, making it 5.", "grounding_specificity_rationale": "The review point explicitly mentions 'standard deviation after multiple experiments' and suggests focusing on 'which effects are within the range of standard deviation fluctuations'. This directly identifies the specific part of the paper being addressed and clearly specifies the issue, making it 5.", "verifiability_rationale": "The review point contains a claim: 'The standard deviation after multiple experiments is not provided.' It also provides verification by stating the 'improvement brought by SoRA compared with the baseline is quite limited, which may be due to random fluctuations.' This connects the missing information to a specific problem (limited improvement) and suggests a solution (focusing on standard deviation). The reasoning is logical and directly relevant to the identified issue.", "helpfulness_rationale": "The review point is 5 as it directly identifies a missing piece of information (standard deviation) that is crucial for understanding the experimental results. It provides a clear suggestion for improvement by focusing the analysis on the variability of the results, which is directly relevant to the stated problem of limited improvement due to potential random fluctuations. The language is clear and the suggestion is actionable."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point implicitly asks for clarification on the meaning of 'upper faces' and the definitions of 'dual subdivision and projection \u03c0'. While it encourages the authors to explain these concepts better, it doesn't explicitly state what action the authors should take. The reviewer is prompting for more information rather than directly instructing on how to improve the current draft. Therefore, it's 2 as it requires the authors to infer the next step.", "grounding_specificity_rationale": "The review point refers to specific mathematical concepts like 'upper faces of the convex hull' and 'dual subdivision and projection \u03c0'. However, it doesn't explicitly point to a specific section, table, or figure where these concepts are discussed. The authors would need to search the paper to find where these terms are likely to be mentioned. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point identifies a potential issue: the variable 'p' is not explicitly defined. This constitutes a claim that there is a lack of clarity or precision in the paper. However, the reviewer does not provide any specific examples or references to support this claim. The support is vague and insufficient. Therefore, the claim is underverifiable as the reasoning and examples are missing.", "helpfulness_rationale": "The review point asks for clarification on specific terms and concepts. While this can be helpful for the authors to understand the paper better, it doesn't directly suggest concrete improvements to the draft. It's a request for information rather than a direct suggestion on how to enhance the work. Therefore, it's 3 as it seeks to improve understanding, but it doesn't directly address potential weaknesses or suggest concrete changes."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the uncertainty regarding the contribution of each component and proposes a concrete action: evaluating the method on baseline detection or parsing techniques. The action is directly tied to the identified weakness, making it a clear and actionable suggestion.", "grounding_specificity_rationale": "The review point mentions 'the proposed method,' 'generative shape model,' and 'word parsing model,' which are specific components. However, it also refers to 'baseline detection or parsing techniques' without specifying which baselines, making the grounding partially specific. The reviewer can identify the components of the proposed method but not the exact nature of the baselines being suggested for comparison.", "verifiability_rationale": "The review point contains a claim: 'It is unclear which component contributes to the performance gain.' While the reviewer suggests an action (evaluating on baselines), this action itself is not yet verifiable within the current review point. The claim is stated, but the suggestion for future work doesn't provide immediate evidence. The grounding specificity issue also contributes to the lack of verifiability as the baselines are not clearly defined.", "helpfulness_rationale": "The review point identifies a weakness (unclear contribution of components) and suggests a way to address it (evaluating on baselines). While the suggestion is valuable, it is not yet a fully comprehensive or actionable solution within the current review point itself. Therefore, it is 3 as it points towards a direction for improvement, but it lacks immediate practical assistance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks 'what are the main rationals for (a) Having a separate timbre encoder module (b) SADTW takes outputs of content encoder (and not timbre encoder) as input?'. This directly addresses the action of identifying the reasons behind specific design choices. The reviewer is asking for explanations of *why* these architectural decisions were made. While the *action* is clear, the *how* these choices interact and the specific rationale for each part could be more explicit.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 1' and specifically mentions 'content encoder' and 'timbre encoder' within that figure. This demonstrates a clear attempt to identify the specific parts of the paper being addressed. The reviewer is asking for the *reasons* *within this paper* for the existence of these modules and their specific connections. The grounding is present, but the reviewer is also asking for the *specifics* of the rationales, which could be more detailed.", "verifiability_rationale": "The reviewer is not making a claim about the paper's content or suggesting improvements. Instead, they are asking for *rationales* for specific architectural choices. This falls under the 'X' category. While the request is relevant to understanding the work, it doesn't involve verifying existing claims or identifying errors within the paper itself.", "helpfulness_rationale": "The reviewer is asking clarifying questions about the model architecture. While this is relevant to understanding the paper, it doesn't directly point out weaknesses or provide actionable suggestions for improvement *in the paper itself*. The request is for information, not a critique or assertion of something within the paper. Therefore, it's 3 in terms of improving understanding but doesn't directly address the paper's content."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that 'Table 4 is incomplete' and suggests 'it should include the results for all four datasets'. This is a clear and direct action that the authors can readily follow to improve their draft by completing the missing table.", "grounding_specificity_rationale": "The review point directly refers to 'Table 4', which is a specific part of the paper. It also clearly specifies the desired content for Table 4, which is 'the results for all four datasets'. This demonstrates both grounding and specificity.", "verifiability_rationale": "The review point contains a claim: 'Table 4 is incomplete'. While the authors would need to check Table 4 themselves to verify this claim, the suggestion to include 'all four datasets' is a clear and actionable recommendation. The reviewer is directly pointing out a missing element and providing a specific direction for improvement.", "helpfulness_rationale": "The review point is 5 because it directly identifies a missing element (Table 4) and provides a clear and specific suggestion for improvement (including results for all four datasets). This actionable feedback empowers the authors to directly address the identified weakness."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem ('jumbled writing/presentation') but doesn't specify how to address it. It's implicit what needs to be done (organize, clarify, improve the flow).", "grounding_specificity_rationale": "The reviewer refers to 'writing / presentation' generally, not a specific part of the paper. The comment doesn't pinpoint a section, table, figure, or element that's jumbled.", "verifiability_rationale": "The comment is a subjective opinion ('I found the writing / presentation a bit jumbled at times') and does not contain a claim that can be verified.", "helpfulness_rationale": "The comment points to a problem but lacks specific, actionable advice. The author still needs to figure out how to make the writing clearer."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "", "verifiability_label": "", "helpfulness_label": "5", "actionability_rationale": "This review point is actionable because it explicitly identifies a factual error in the authors' description of the IOI circuit and provides a clear alternative explanation based on external knowledge (Wang et al., 2023). The action is to revise the authors' description, which is a direct and verifiable change. The reviewer also specifies *which* part of the paper and *what* is incorrect, making it highly specific.", "grounding_specificity_rationale": "", "verifiability_rationale": "", "helpfulness_rationale": "This review point is 5 because it directly identifies a factual error in the authors' description of the IOI circuit and provides a clear alternative explanation based on external knowledge. This empowers the authors to correct their description and align with the established understanding in the field. The reviewer's specific references to the IOI circuit components and the S2 token make the feedback highly targeted and actionable."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out the *perceived* limitations of the work but doesn't offer concrete steps for improvement. It's implicit that the authors should make their work more novel, but this isn't stated directly. Therefore, it's 1. While the reviewer criticizes the work, they don't explicitly state what the authors should do to improve their draft based on this criticism. The criticism is more of a statement of opinion about the work's incremental nature rather than a direct instruction on how to make it better.", "grounding_specificity_rationale": "The review doesn't mention any specific section, table, figure, or unique aspect of the paper. It's a general critique of the work's perceived incremental nature and novelty. Therefore, it's 1. The reviewer is making a broad statement about the overall work, not about a specific detail within it.", "verifiability_rationale": "The review expresses an opinion about the work's novelty without providing any verifiable evidence or specific details. It doesn't state a claim that can be supported by logical reasoning, common knowledge, or external references. Therefore, it's 1. The statement is an opinion without supporting evidence. The reviewer is stating what they think is wrong, not what they know is wrong and needs to be addressed.", "helpfulness_rationale": "The review is critical and doesn't offer any actionable advice to the authors. It focuses on what they *don't* like about the work rather than providing specific suggestions for improvement. Therefore, it's not helpful. The review is critical and lacks actionable suggestions. It focuses on what the reviewer *doesn't* like."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "Both parts of the review point explicitly state the weaknesses and provide clear actions for improvement. The first part identifies the vagueness of 'too vague' and suggests looking into specific RNN research and a resource (SNLI). The second part criticizes the reinforcement learningagent analogy and suggests improvements are found in later examples. These actions are direct and lead to concrete changes.", "grounding_specificity_rationale": "Both parts of the review point clearly identify the specific aspects of the paper being discussed. The first part refers to 'certain RNNs work well for certain natural language reasoning tasks,' grounding the criticism in specific research areas. The second part refers to 'the reinforcement learning / agent analogy' and 'examples you give later in the paper,' grounding the criticism and suggestions in specific sections of the paper.", "verifiability_rationale": "Both parts of the review point make claims and provide justifications for them. The first part claims 'again, too vague' and provides a suggestion and a reference (SNLI). The second part claims 'the reinforcement learning / agent analogy seems a bit outofplace' and suggests improvements are found in later examples. These claims are supported by logical reasoning and external references (or references to later sections of the paper).", "helpfulness_rationale": "Both parts of the review point offer specific and actionable feedback. The first part highlights the need to clarify the vagueness by pointing to relevant research and a resource. The second part criticizes the analogy and suggests improvements are found in later examples. These suggestions are directly relevant to improving the paper and provide clear directions for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two issues: a lack of significant difference in performance and a lack of justification for Algorithm 1. While it points out these gaps, it doesn't explicitly state what the authors should do next. The suggestions are implied but not directly actionable.", "grounding_specificity_rationale": "The reviewer mentions 'Fig.5' and 'StableDiffusion', indicating some level of grounding. However, they don't specify which part of Fig. 5 they are referring to or what exactly the issue is with StableDiffusion. The reference to 'Algorithm 1' is also missing, making the grounding less precise.", "verifiability_rationale": "The review point makes a claim about the lack of significant difference in performance and the lack of justification for Algorithm 1. However, it doesn't provide any specific evidence or reasoning to support these claims. It's a statement of observation rather than a definitive claim requiring proof.", "helpfulness_rationale": "The review point identifies two areas for improvement: the performance of the proposed method and the justification of Algorithm 1. While it highlights these issues, it doesn't offer concrete suggestions or guidance on how to address them. The feedback is somewhat general and lacks specific direction."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: \"change the notation in line 122 from sets to tuples.\" This is a clear and direct instruction for the authors to make a modification. The suggestion is also concrete, specifying the exact change they should make. Therefore, the review point provides a clear and actionable step for the authors to improve their draft.", "grounding_specificity_rationale": "The review point explicitly refers to \"line 122\" and the \"triples\" within that line. This clearly identifies the specific part of the paper being addressed. The comment is not making a general statement about triples but rather about a specific implementation detail in line 122. Therefore, the review point is fully grounded in the specific part of the paper it addresses, and it also specifies what needs to be addressed in this part.", "verifiability_rationale": "The review point does not contain a claim in the sense of a definitive statement about the correctness of the paper. It is more of a suggestion for improvement. However, it does imply that the current notation (using sets) might be less clear or standard than the tuplelike structure. While it doesn't provide external references or logical reasoning to support this implication, it suggests a potential area for clarification. Therefore, while not a 5 claim, it is 3 in the sense that it points to a potential area needing justification or improvement.", "helpfulness_rationale": "The review point is a clear and specific suggestion for improvement. It directly addresses a potential area of confusion (notation) and proposes a concrete change (using tuples). This type of suggestion is 5 for the authors as it directly points them towards a actionable step to enhance their work. While it doesn't provide a definitive proof of a flaw, it offers a constructive suggestion that can significantly improve the clarity of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the claim 'every kernel can be described by a feature space parameterized by a neural network' is not true. They further elaborate by providing a specific example of Radial Basis Function (RBF) kernels, explaining that their Reproducing Kernel Hilbert Space (RKHS) is famously infinitedimensional, which would require an infinitely wide neural network to represent. This clearly indicates an actionable limitation that the authors should consider.", "grounding_specificity_rationale": "The reviewer not only identifies the limitation but also explicitly points to a specific location in the paper ('l.') where this issue is discussed. They further specify the type of kernel ('RBF kernels') and the nature of the limitation ('infinitedimensional RKHSs'). This strong indication of a specific location and type of kernel demonstrates high grounding specificity.", "verifiability_rationale": "The reviewer provides a clear explanation of why the claim is not true, linking it to the concept of RKHS dimensionality. They state that for RBF kernels, the RKHS is infinitedimensional, and finitewidth neural networks cannot represent this. This explanation is logical and based on established knowledge in kernel methods, making the claim verifiable.", "helpfulness_rationale": "The reviewer's point is 5 and directly addresses a potential flaw in the paper's premise. By highlighting the limitations of representing infinitedimensional RKHSs with finitewidth neural networks, the reviewer provides the authors with a concrete direction to improve their understanding of neural network capabilities in kernel representation. This is a valuable and specific piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1: Not Verifiable", "helpfulness_label": "4", "actionability_rationale": "The review point presents several questions and suggestions. The first two questions, 'In Fig. 4, is it possible that GPI with noise added could reproduce the data similarly well or are there other measures to show that GPI cannot have as good fit with behavioural data (e.g. behavioural trajectories? time to goal?)', are implicitly suggesting actions. The authors are prompted to investigate and explore alternative measures. The last two sentences, 'Finally this approach seems to be suitable for modelling pattern separation tasks, for which there is also behavioural data available  it would be nice to have some discussion on this', are explicitly suggesting actions. However, the actions are not always clearly defined, making the point partially actionable.", "grounding_specificity_rationale": "The review point refers to 'GPI with noise added' and 'behavioural data' generally. While it mentions specific aspects like 'behavioural trajectories?' and 'time to goal?', it doesn't explicitly point to a specific section, table, or unique element in the paper where this investigation should focus. The suggestion to discuss pattern separation tasks is also general and doesn't specify a particular section or table. Therefore, the grounding is somewhat weak.", "verifiability_rationale": "The review point does not make a claim that requires verification. It presents questions and suggestions for further exploration and analysis. There is no assertion that something is incorrect or needs justification. Therefore, it is not verifiable in the sense of stating something that needs evidence.", "helpfulness_rationale": "The review point offers several suggestions for improvement and further analysis. The questions about exploring alternative measures and considering pattern separation tasks are valuable insights that can guide the authors in refining their methodology and understanding their data better. While it doesn't provide a direct solution, it encourages a more thorough investigation, which can be helpful. Therefore, it is 3 in prompting further exploration and rigor."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the performance difference between the baseline and the best approach is less than 1%. This is a concrete action, as it identifies a specific outcome. However, it doesn't directly suggest how the authors should modify their draft to achieve this level of improvement. The action is to acknowledge the small gains, but the suggestion is implicit in the observation that the gains are small, rather than a direct instruction on how to improve.", "grounding_specificity_rationale": "The comment is a general statement about the overall performance gains and doesn't specify which part of the paper or experiment this refers to. There is no mention of a specific section, table, figure, or unique aspect of the paper being addressed. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The comment contains a claim: 'the performance gains are not very high'. This claim is supported by the reviewer's own experiments, making it 5. The reasoning is based on the observed results, and there are no missing external references in this case as the evidence is derived from the reviewer's own work.", "helpfulness_rationale": "The comment identifies a potential issue (limited performance gains) but does not provide specific guidance or actionable steps for the authors to address this issue. It's a critique of the current approach rather than a direct instruction on how to improve the draft. While it highlights a problem, it doesn't offer a solution or a clear path forward for the authors."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point asks a question about the value of specific feedback for a feedback network. While it implies an action (considering the feedback), it doesn't explicitly state how to act upon it or provide concrete steps. The action is implicit.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or the type of mistake being referred to. It is a general question about the feedback process, not about a particular element of the submitted work. Therefore, it is 1 at all.", "verifiability_rationale": "The review point is a question, not a claim. It does not make a statement that can be verified as true or false. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point raises a valid question about the utility of specific feedback for a feedback network. While it is relevant to the authors' understanding of the review process, it does not directly provide actionable feedback on how to improve their draft. It is more of a metacomment than a direct critique or suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a question ('if we use a betterUnary baseline, is there still a performance boost?'). This question directly relates to the experimental setup and results presented in the tables. While the question itself doesn't explicitly state what action to take, it encourages further investigation and analysis of the model behavior. The reviewer is prompting the authors to consider a potential improvement or further experimentation. Therefore, while the question is directly related to the results, it doesn't provide explicit instructions on how to modify the draft based on this observation. The action is implied rather than stated.", "grounding_specificity_rationale": "The reviewer refers to 'Tab 1,2,3' and 'LinearTop', 'NLTop', and 'Unary'. While they mention these terms, they don't explicitly state which specific table or figure within those sections they are referring to. The reviewer is discussing the general trends observed across these tables. Without knowing the exact table or section being pointed to, the authors would need to search through the paper to find the relevant information. This makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer states a potential inconsistency: 'LinearTop and NLTop adds additional parameters, whileUnary performs much worse comparing to the numbers reported e.g. in 14, where they used a different and probably better neural network. This raises a question: if we use a betterUnary baseline, is there still a performance boost?' The reviewer is making a claim based on their interpretation of the experimental setup and results. However, the paper itself, as presented in the review point, doesn't provide the specific evidence (e.g., direct quotes from the 14 paper, detailed architectural differences) to fully support this claim. The claim is based on an inference and a comparison to external information. Therefore, the claim is present, but the supporting evidence within the provided text is limited.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential area for improvement in the experimental setup and results interpretation. They are prompting the authors to consider a better baseline and its impact on performance. This question is relevant to the authors and encourages them to think critically about their model choices and experimental design. While it doesn't provide a definitive answer, it highlights a potential avenue for further investigation and improvement. Therefore, the comment is relevant and raises a valuable point for consideration."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks for the final learning rates used in the experiments, particularly for CIFAR10 and CIFAR100. This is a direct request for information, making the action clear. While the reviewer doesn't state the *action* of looking for this information, the request itself is the action. The information is specific, but the reviewer doesn't provide it, making the action itself somewhat incomplete.", "grounding_specificity_rationale": "The reviewer asks for the final learning rates for specific datasets (CIFAR10 and CIFAR100). This directly targets specific parts of the paper (the experimental setup and results sections where these datasets are mentioned). The reviewer doesn't explicitly name a section or table, but the context implies they are referring to the experimental details of the paper they are reviewing. The request is very specific about the datasets involved. Therefore, the grounding is quite clear, although not as explicit as 'Full Grounding' which would involve a direct literal mention.", "verifiability_rationale": "The reviewer presents a claim: 'Because the authors only searched 4 different learning rates, and if the optimal learning rate for the baseline was outside the tested interval that could spoil the results.' This is a claim that requires verification. The reviewer provides a logical argument (the potential impact of the search interval) and refers to external knowledge (the typical range of learning rates). While the claim is plausible, the reviewer doesn't provide direct evidence or citations to support it. Therefore, the claim is partially supported by logical reasoning and common knowledge.", "helpfulness_rationale": "The reviewer provides a constructive suggestion: 'Another remark:'. They are pointing out a potential flaw in the experimental design (the limited learning rate search) and suggesting it could affect the results. This is a helpful comment because it identifies a potential issue and suggests a way to improve the experimental setup. The reviewer's suggestion is actionable and directly related to the identified limitation. The comment is also logically sound and based on common knowledge about learning rate tuning."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the proposed approaches outperform baselines in only 1 out of 3 setups. This provides a clear, actionable feedback to the authors regarding the performance of their proposed methods compared to existing techniques. The reviewer also points out the lack of a consistent trend, which suggests areas for potential improvement or further investigation. The explicit comparison between proposed and baseline methods allows the authors to directly address where their methods fall short or where further development is needed.", "grounding_specificity_rationale": "The reviewer's comment is highly grounded as they explicitly refer to 'Table 2' and mention specific details about the experimental setups, such as '1 setup (out of 3)' and the performance of 'proposed methods (+w2w) or (+FA)'. This allows the authors to precisely identify the section and table being discussed. The reviewer's focus on the inconsistency in performance across different methods and setups further adds to the specificity of the feedback.", "verifiability_rationale": "The reviewer's claim that the results are 'insufficient to prove the benefits of the proposed methods' is not supported by any logical reasoning, common knowledge, or external references within the review point itself. The reviewer states the issue but doesn't provide evidence or justification for why the results are insufficient. Therefore, based solely on the information provided in this review point, the claim is 1.", "helpfulness_rationale": "The reviewer's comment is primarily critical, pointing out the limitations of the experimental evaluation. While the comment identifies a problem, it does not offer any specific suggestions or improvements for the authors. The reviewer's statement is more of a diagnosis than a prescription, which limits its helpfulness in guiding the authors towards better results."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a need for clarification ('clarify') and points to specific lines in Figure 4 that are overlapping ('the line of No adapt or Finetune are covered by other lines'). This indicates a clear action the authors should take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 4' and then specifies the 'line of No adapt or Finetune' as the issue. This demonstrates a high level of specificity in identifying the problematic part of the paper.", "verifiability_rationale": "The reviewer identifies a problem ('Some figures are not selfexplanatory') and provides a specific example ('For instance, in Figure 4, the line of No adapt or Finetune are covered by other lines, without additional explanation.') that can be verified by examining the figure itself. While no external references are provided, the visual overlap is a clear point of contention.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion ('For instance, in Figure 4, the line of No adapt or Finetune are covered by other lines, without additional explanation. Please add a legend or explanation to clarify these lines.') that directly addresses a concrete issue identified in the paper. This is a valuable piece of feedback for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The point identifies a potential weakness in the experimental setup regarding the 'careful evaluation of sampling'. However, it does not explicitly state what needs to be done to address this weakness. The reviewer points out a gap in the experiments but doesn't recommend a specific action or improvement strategy.", "grounding_specificity_rationale": "The reviewer criticizes the 'convergence to optimum' of the sampling method but does not specify which sampling method or which part of the optimization process is being referred to. The reference to 'supplementary where it is compared to sampling from uniform distribution' is a general pointer rather than a specific identification of a part of the paper being addressed.", "verifiability_rationale": "The point makes claims such as 'This is not experimentally evaluated carefully' and 'compared to sampling from uniform distribution'. These claims could potentially be supported by further investigation or references, making them partially verifiable. The comparison to uniform sampling provides a basis for verification, but the lack of statistical significance or other supporting evidence is not explicitly stated.", "helpfulness_rationale": "The point identifies a potential area for improvement in the experimental design by highlighting the importance of sampling and suggesting a comparison to a simpler method. However, it does not offer a concrete, actionable suggestion for the authors to make based on this feedback. The point points to a potential issue but lacks a specific recommendation for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises several questions about the rationale behind the comparisons and the computational cost. While the questions themselves are explicit, the lack of clear answers or justifications within the paper makes it difficult to pinpoint the specific actions the authors should take. The reviewer's questions are framed as requests for clarification rather than explicit instructions or solutions, indicating a lack of actionable feedback in this area.", "grounding_specificity_rationale": "The reviewer explicitly mentions the works 9 and 16 in the context of the comparisons, indicating a clear grounding in these specific papers. However, the reviewer also states *why* these specific papers were chosen and the specific comparisons were made, further strengthening the grounding. The explicit mention of the rationale behind the comparisons adds to the grounding specificity.", "verifiability_rationale": "The reviewer identifies a gap in the paper regarding the discussion of computational cost. The paper compares computational cost with 9 but doesn't provide a similar comparison with 16. The reviewer questions the significance of this computational cost in a practical scenario, indicating a lack of justification or explanation for this aspect. The reviewer's statement about the lack of discussion is a clear claim that requires justification.", "helpfulness_rationale": "The reviewer clearly states their concerns and questions regarding the rationale behind the comparisons and the computational cost. These are not just general comments but specific requests for information or clarification. The reviewer's questions are actionable in the sense that they point to specific areas where the paper is lacking. The reviewer's statement about the lack of discussion on computational cost is a clear claim that needs to be addressed."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for a comparison between the PL condition and a specific paper. While it doesn't explicitly state an action or suggest a concrete change, it directly requests information that could be used to understand the relationship between the two. The reviewer is implicitly suggesting that this comparison could be useful for the authors. The action could be to perform the comparison and provide feedback based on the findings.", "grounding_specificity_rationale": "The review point explicitly mentions 'the PL condition' and 'a specific paper'. This clearly identifies the specific part of the paper being addressed. The reviewer is asking about a direct comparison, which is a specific request. The grounding is strong because the elements are literally mentioned.", "verifiability_rationale": "The review point asks a question about a comparison. There is X being made or supported. It's a request for information, not a statement that something is wrong or needs to be improved. Therefore, it doesn't fit the criteria for verifiability, which requires a claim and supporting evidence.", "helpfulness_rationale": "The review point asks a direct question about a comparison. This is a clear request for information that could be relevant to the authors. The specificity of the request is high, as it targets a specific paper and the PL condition. However, the request itself doesn't inherently suggest a concrete action or improvement for the authors. It's a request for clarification or further understanding. The helpfulness is moderate because it points to a potential area for improvement (understanding the relationship with other PL conditions) but doesn't directly offer a solution."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point states a lack of discussion, implying an action (discussing the impact), but doesn't provide concrete steps on how to implement it.", "grounding_specificity_rationale": "The review point explicitly mentions 'adding additional parameters and additional computational effort' in the context of the multistage training and discriminators, clearly identifying the specific part of the paper being addressed.", "verifiability_rationale": "The review point makes a claim ('there is a complete lack of discussing the impact...') but doesn't provide any supporting evidence or justification for it.", "helpfulness_rationale": "The review point informs the authors of a potential weakness in their own analysis by highlighting the lack of discussion regarding the impact of additional parameters and computational effort, which can be valuable information for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the limitations of the analysis, suggesting a concrete next step: investigating different model architectures and seeking theoretical explanations. The reviewer directly points out what needs to be done, making it actionable.", "grounding_specificity_rationale": "The reviewer refers to 'the analysis of the correlation between dataset size and the Frobenius norm and the singular values,' which clearly identifies a specific aspect of the paper being discussed. The reference is explicit and points to a defined analysis.", "verifiability_rationale": "The review point makes a claim about the lack of theoretical evidence, stating 'no theoretical evidence is advanced for this correlation.' However, it doesn't provide specific examples of missing literature or logically explain why this evidence is absent. The claim is presented as a belief rather than a rigorously proven gap.", "helpfulness_rationale": "The review point is actionable and grounded, providing a clear direction for the authors to take. However, the lack of specific evidence or a clear justification weakens its overall impact. While it prompts further investigation, it doesn't offer immediate, definitive guidance, making it 3 rather than 5."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer raises two questions. The first question directly asks for a logical consequence of a statement in the paper, which is a clear and explicit action. The second question also asks for a logical consequence, which is again an explicit action. While the questions are insightful, they don't provide concrete steps on how to improve the draft, making them somewhat implicit in terms of actionability.", "grounding_specificity_rationale": "The reviewer's questions directly address a conclusion in the paper (L114) and a subsequent statement about combining datasets. The questions are posed in a way that implies the reviewer can identify the specific parts of the paper being referenced (L114 and the general concept of combining datasets). Therefore, the grounding is full. The questions also specify what needs to be considered (the implications for SSL and generic representations). Thus, the specificity is high.", "verifiability_rationale": "The reviewer's questions are logical deductions based on the paper's statements. They don't require external references or complex reasoning to understand the underlying concepts. While the questions are logically sound, they don't provide concrete examples or citations to support the claims being questioned. Therefore, the verifiability is somewhat lacking.", "helpfulness_rationale": "The reviewer's questions directly address potential weaknesses or ambiguities in the paper's methodology and conclusions. They offer logical extensions and suggest further investigations. This provides the authors with concrete feedback and directions for improvement. The questions are not just critiques but also potential avenues for further research or clarification. Therefore, the helpfulness is high."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The suggestion is directly stated, making it explicit. Furthermore, the reviewer clearly indicates the specific aspect of the paper (the empirical version of the objective (3)) that needs adjustment and recommends a concrete action: moving it to the supplementary materials. This action is welldefined and specific.", "grounding_specificity_rationale": "The comment is 1 as it does not explicitly identify a specific part of the paper being addressed. While it refers to 'the empirical version of the objective (3)', it does not point to a specific section, table, figure, or unique element within the paper. Therefore, the grounding is weak. The comment is also not specific as it does not detail *how* the empirical version of the objective (3) should be moved to the supplementary materials. It only suggests moving it there without providing further guidance on the process.", "verifiability_rationale": "The comment does not contain a claim. It is a suggestion or recommendation. Therefore, it falls under the 'X' category, indicating X. There is no need to assess verifiability as there is X to verify.", "helpfulness_rationale": "The suggestion is directly helpful. It provides a clear direction for the authors to improve their draft by reorganizing supplementary information. It is actionable and directly addresses a potential organizational issue."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their point about Corollary 10 and asks a question, which is a clear action. The action is also concrete as they are pointing out a specific logical gap in the interpretation of the corollary.", "grounding_specificity_rationale": "The reviewer directly references 'Corollar 10' and explains why it is relevant to their point. This shows strong grounding. They also specify the nature of the issue (relationship between 01 loss and convex surrogate).", "verifiability_rationale": "The reviewer makes a claim about the interpretation of Corollary 10. This claim can be verified by examining the definitions of the expected 01 loss and the expected convex surrogate, and understanding the implications of descent directions. While the reviewer doesn't provide a detailed proof, the claim is logically supported by standard definitions.", "helpfulness_rationale": "The reviewer's point directly addresses a potential misunderstanding or misinterpretation of a key theoretical result. This is 5 for the authors trying to understand the implications of Corollary 10 and the relationship between the 01 loss and its convex surrogate. It challenges a potentially misleading conclusion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point mentions a \"performance improvement\" and a specific number (0.02). It also suggests an alternative way to present the data (tables). While it points to a *potential* improvement, the *action* isn't explicit. The authors aren't told what to change or how to achieve the improvement.", "grounding_specificity_rationale": "The review mentions \"figure 3\" and \"the bank dataset.\" This is a clear grounding element \u2013 it specifies *where* the performance improvement is being measured. The reviewer also mentions \"the biggest improvement in the bank dataset was ~0.02.\" This specifies *what* is being measured and provides a *specific* value.", "verifiability_rationale": "The review states \"As shown in figure 3, the performance improvement of proposed methods seems not so significant, the biggest improvement in the bank dataset was ~0.02.\" This is a statement of observation or judgment about the significance of the improvement. The reviewer provides some support by referencing Figure 3 and providing a specific numerical value. However, they don't explicitly explain *why* this improvement is significant or provide external references to support the claim of \"not so significant.\"", "helpfulness_rationale": "The review is relevant and identifies a potential issue with the reported results. While the reviewer points out a potential improvement and suggests using tables, they don't offer concrete *suggestions* for improvement. They don't specify what needs to be changed in the method or the experiments to achieve the improvement. The feedback is valuable but lacks specific actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two potential areas for improvement in the experimental validation: considering deeper networks and providing details on the optimization strategy, including the grid search for hyperparameters. While the optimization strategy is vague, the suggestion to consider deeper networks is a concrete action. However, the lack of detail makes it somewhat vague overall.", "grounding_specificity_rationale": "The review point explicitly mentions 'shallow networks' and 'optimization strategy, including the grid search strategy for hyperparameters selection' as areas for improvement. This clearly identifies specific aspects of the paper being addressed, making it fully grounded. The minor point about layer redundancy is a more general observation but the main criticisms target specific parts.", "verifiability_rationale": "The review point makes claims about the experimental validation being 'not convincing' and the consideration of only 'shallow networks'. It also states that the 'optimization strategy, including the grid search strategy for hyperparameters selection, is not described'. While these claims could potentially be supported by evidence, the review point itself does not provide any references or logical reasoning to back these claims. The minor point about layer redundancy is a suggestion for improvement, not a claim requiring verification.", "helpfulness_rationale": "The review point raises concerns about the experimental validation, which could be helpful for the authors to identify potential weaknesses. However, the criticism about the optimization strategy and the limited consideration of shallow networks are somewhat vague and lack specific suggestions for improvement. The minor point about layer redundancy is a general observation and less helpful without a concrete suggestion."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The statement 'The technical contribution is limited' is a declarative statement that identifies a potential weakness but does not explicitly state what is limited or what needs to be improved. While it implies a lack of novelty, it lacks a direct action or suggestion.", "grounding_specificity_rationale": "The statement 'The technical contribution is limited' does not specify which part of the paper or model is lacking. It is a general statement about the overall technical contribution without pinpointing a specific area.", "verifiability_rationale": "The statement 'The technical contribution is limited' is an opinion or judgment about the paper's novelty and impact. It lacks supporting evidence or logical reasoning to back up this claim.", "helpfulness_rationale": "The statement 'The technical contribution is limited' is a critical assessment of the paper's originality and value. While it identifies a weakness, it does not offer any suggestions or constructive feedback to address the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of 'Adding fullysupervised baselines for small models in table 1' and provides a clear explanation of *how* this addition would be beneficial for understanding the gap between full supervision and SSL. The action is not just implied but directly stated, and the methodology for implementation is also provided.", "grounding_specificity_rationale": "The review point explicitly refers to 'table 1' and explains *why* adding the baselines would be useful in the context of understanding the gap between full supervision and SSL. The referenced part of the paper is clearly identified, and the implications for that specific part are discussed.", "verifiability_rationale": "The review point contains a claim that 'Adding fullysupervised baselines for small models in table 1 will be useful in understanding the gap between full supervision and SSL for these models.' This claim is supported by the reasoning that these baselines will help in understanding the performance differences between supervised and selfsupervised learning, which is a logical and inferable justification.", "helpfulness_rationale": "The review point is 5 as it directly addresses a potential area for improvement (adding baselines) and provides a clear rationale for why this addition would be beneficial for understanding the performance differences between supervised and selfsupervised learning. The suggestion is actionable and directly addresses a potential weakness in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the lack of novelty in the approach, the use of specific algorithms (MLP, Regression Tree, Random Forest), and the similarity of the sampling strategy to existing methods (epsilongreedy, BRPNAS). While the reviewer identifies areas of concern, they do not provide explicit instructions on how to address these issues. For example, they point out the use of 'MLP, Regression Tree or Random Forest' but don't specify how these should be replaced. Similarly, they mention the similarity to 'epsilongreedy and exactly the same as that in BRPNAS' but don't suggest how to modify their approach. The lack of specific actions makes the criticism less actionable.", "grounding_specificity_rationale": "The reviewer mentions 'the specific components of the approach,' 'the algorithms used,' and 'the sampling strategy.' While they identify these aspects, they do not explicitly pinpoint the exact section, table, figure, or unique element within the paper they are referring to. They use general terms like 'components,' 'algorithms,' and 'sampling strategy.' Furthermore, while they name the algorithms (MLP, Regression Tree, Random Forest) and the sampling strategy (epsilongreedy, BRPNAS), they do not provide specific details *within* these categories. For example, they don't say 'The 'X' component is the 'attention mechanism' in the MLP' or 'The sampling strategy uses a fixed exploration rate.' The grounding is present at the *type* level, but not the *exact instance*.", "verifiability_rationale": "The reviewer makes claims about the nonnovelty of the algorithms used (MLP, Regression Tree, Random Forest) and the similarity of the sampling strategy to existing methods (epsilongreedy, BRPNAS). However, the reviewer does not provide any evidence or justification to support these claims. They state that 'the weak predictor used are MLP, Regression Tree or Random Forest, all of which have been used for NAS performance prediction before' and 'the sampling strategy is similar to epsilongreedy and exactly the same as that in BRPNAS'. Without citing other papers or providing a detailed analysis, these claims remain 1.", "helpfulness_rationale": "The reviewer's comment is critical and points out significant shortcomings of the work, specifically the lack of novelty in the algorithms and methods, and the similarity of the sampling strategy to existing approaches. While the criticism is valid, it does not offer any specific, actionable suggestions or evidence to support their claims. The reviewer states that 'If we look at the specific components of the approach, they are not novel as well' and 'the weak predictor used are MLP, Regression Tree or Random Forest, all of which have been used for NAS performance prediction before' and 'the sampling strategy is similar to epsilongreedy and exactly the same as that in BRPNAS'. However, they do not suggest any alternative algorithms or modifications to the sampling strategy. The comment raises concerns but does not provide clear guidance on how to address them, making it less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks for clarification on the iterative nature of the OT sample selection process and its relationship with the training steps. While the reviewer doesn't explicitly state that the actions are implicit, the questions imply a need for more detail on how these processes are implemented and interact. The reviewer also asks for concrete details on how to apply the actions, such as the runtime for solving the OT problem and sample selection. This suggests that the actions, while present, are not immediately clear or easily actionable without further explanation.", "grounding_specificity_rationale": "The reviewer asks specific questions about the iterative nature of the OT sample selection process and its relationship with the training steps. They also ask for runtime information. While the questions are about specific parts of the method, the reviewer doesn't explicitly point to a specific section or table in the paper. The request for a flowchart to understand the process is a suggestion for improvement rather than a direct request for information about the current paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer asks for details and a flowchart to understand the OT sample selection process. This implies a need for logical reasoning to understand how the processes work. The request for runtime information is a request for external references (runtime measurements). The reviewer also asks 'why' solving the OT problem is important, which requires common knowledge or external references to understand the typical use of OT in this context. The request for a flowchart is a request for a visual aid to understand the process, which is not directly verifiable from the paper itself.", "helpfulness_rationale": "The reviewer asks for clarification on a crucial aspect of the method (the OT sample selection process) and wants to understand the computational cost. This is a request for information that would improve the reader's understanding and potentially the paper's clarity. The reviewer is directly asking for details about the implementation and performance of the method, making it 5 for readers trying to understand or implement the approach. The request for a flowchart, while not directly verifiable, is a suggestion for improving the paper's clarity and is therefore helpful in a broader sense."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to consider experiments with continuous tasks and entropy methods, which are implicit actions. However, it doesn't provide concrete details on how to implement these actions, making it somewhat vague. The request to compare performance is also implicit.", "grounding_specificity_rationale": "The review point doesn't explicitly mention the specific part of the paper being discussed (e.g., 'Section 7', 'Appendix'). It refers to the discussion of continuous tasks and entropy methods generally. Therefore, the grounding is weak. The questions are about specific methods and comparisons, but the initial statement lacks specificity about the location in the paper.", "verifiability_rationale": "The review point raises questions about the derivation of entropy methods and the performance comparison with ConBO. While it points to specific elements (entropy methods, ConBO), it doesn't provide any justification or references for these claims. The questions themselves are requests for information rather than statements that can be verified.", "helpfulness_rationale": "The review point provides clear and actionable feedback by highlighting missing experiments with continuous tasks and the absence of a comparison with entropy methods. It directly prompts the authors to address these gaps. The questions are specific and directly related to the discussed methods. This review point effectively guides the authors towards important improvements in their experimental setup and analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the calculation method (precision/recall/F1score) for a 4class classification of breast density. This directly addresses a potential point of confusion for the authors who might not be familiar with the specific implementation. The request is clear and directly actionable for the authors to understand the calculation process.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'how did you calculate precision/recall/F1score for 4class classification of breast density' and 'researchers usually report AUC with sensitivity and specificity at different operating points to compare model performance'. These are specific and clear questions that directly address the authors' potential confusion and suggest improvements. The reviewer accurately identifies the context (breast density classification) and the relevant metrics (AUC, sensitivity, specificity).", "verifiability_rationale": "The reviewer is stating their intention to report certain metrics, not making a claim that requires verification. While the suggestion to use AUC is valid, the statement itself doesn't require external evidence or justification to be considered verifiable in the defined sense.", "helpfulness_rationale": "The reviewer provides a clear and specific question that directly addresses a likely point of confusion for the authors regarding the calculation of a classification metric. By suggesting alternative metrics, they also offer a concrete improvement in evaluation methodology. This information is directly actionable and helpful for the authors to understand and implement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests that the use of Transformer is not novel and criticizes the limited improvement from selfcross attention. While the reviewer points out potential issues, the suggestions are not explicit actions the authors should take, nor are they concrete steps to implement. The reviewer's comments are more about raising concerns and suggesting areas for improvement rather than directly instructing the authors on what to do.", "grounding_specificity_rationale": "The reviewer mentions 'Transformer has been adopted for lots of NLP and vision tasks' and refers to 'ablation study (table4 and 5)'. This indicates a lack of specific grounding. The reviewer is making general statements about the Transformer's adoption and refers to the ablation study without explicitly identifying the specific aspect of the ablation study being criticized.", "verifiability_rationale": "The reviewer claims that 'selfcross attention brings limited improvement (<1%)'. This is a claim that needs verification. While the reviewer states a fact about the improvement, they do not provide specific examples, references, or logical reasoning to support this claim within the provided text. The claim is presented as a statement without further justification.", "helpfulness_rationale": "The reviewer offers a critique of the work and suggests that the main improvements come from using a 'na\u00efve transformer' instead of the proposed modification. While this provides some insight for the authors, it is a somewhat general and subjective statement. The reviewer doesn't provide specific, actionable advice on how to improve the work based on their critique."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment implicitly suggests adding sentence inference tasks by mentioning the limitations of the current experiments and proposing MNLI and RTE as examples. While not explicitly stating 'add MNLI and RTE', the suggestion is clear and points to a concrete action. The reviewer also mentions 'other tasks that involve sentence pairs', which implies a need for more specific guidance on what those tasks might be.", "grounding_specificity_rationale": "The comment explicitly names specific tasks that are relevant to sentence pair analysis: 'sentence similarity tasks', 'open domain QA tasks', 'MNLI' and 'RTE'. This strong naming of specific tasks indicates high grounding specificity.", "verifiability_rationale": "The comment provides specific examples of relevant tasks (MNLI, RTE) which serve as implicit justification for the suggestion. While it doesn't cite external literature, the mention of these wellknown tasks provides a basis for verification. The reasoning is that if these are standard tasks, the authors might also benefit from evaluating on them.", "helpfulness_rationale": "The review point clearly identifies a limitation in the experimental scope and provides specific, relevant suggestions for improvement. By mentioning specific tasks like MNLI and RTE, the reviewer guides the authors towards a concrete area for expanding their evaluation. This directly addresses a potential weakness for the authors and offers actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the prompt should be in the appendix or supplement, which is an explicit action. It also provides a concrete location (appendix or supplement). Therefore, it is a concrete action that the authors can directly apply.", "grounding_specificity_rationale": "The comment identifies the missing prompt and suggests the appendix or supplement as potential locations. However, the reviewer explicitly states they cannot access supplements, making the grounding somewhat weak as the authors cannot confidently determine the exact location. The specificity is also somewhat lacking as the prompt could be in either the appendix or the supplement, and the reviewer's inability to access the supplement adds to the uncertainty.", "verifiability_rationale": "The comment contains a claim ('It's important to have the prompt included in the appendix or supplement') but does not provide any specific evidence or justification for this claim. It is a statement of importance and a suggestion, but it lacks logical reasoning, common knowledge, or external references to support it. Therefore, it has X and is not verifiable.", "helpfulness_rationale": "The comment points out a potential issue (the prompt being missing) and suggests a location (appendix or supplement). While it doesn't guarantee the prompt is there, it provides a potential area to check. This can be helpful in identifying a problem, but it's not a definitive solution or a strong recommendation. The uncertainty about the reviewer's access to the supplement makes the advice less actionable, thus it's 3 but not highly so."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'You should consider the choice of constraint as a hyperparameter.' It also concretely identifies the specific types of constraints: 'convex or concave constraint, and an increasing/decreasing constraint.'", "grounding_specificity_rationale": "The comment explicitly mentions the 'choice' of constraints and then specifies the types as 'convex/concave' and 'increasing/decreasing'. This allows the authors to accurately pinpoint the relevant aspect being addressed.", "verifiability_rationale": "The comment presents a judgment about the practical implications of the original statement ('while technically true, the *choice* of employing a convex or concave constraint... can be seen as a hyperparameter that needs to be chosen or tuned'). It does not make a claim that requires verification or evidence.", "helpfulness_rationale": "The comment is a valid observation that the choice of constraint can be seen as a hyperparameter. It provides a clear direction for the authors to consider this. However, it lacks specific guidance on *how* to tune these constraints, *what data* to use for tuning, or *what criteria* to use for making the choice. The comment identifies a weakness in the original statement's brevity but doesn't fully address the practical implications."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly identifies the issue with the convergence proof by pointing out the contradiction between the claim about Z being noni.i.d. and Assumption 4.1 stating X is i.i.d. They also clearly state that this leads to a 'clear covariance matrix' for Z and that 'straightforward modifications' can be made. This provides a clear path for the authors to address the perceived weakness, making the action explicit and concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Assumption 4.1' and 'Modification 1 in Appendix C', directly pinpointing the relevant section of the paper. They also clearly explain the implications of the i.i.d. assumption for the covariance of Z. This strong grounding makes it easy for the authors to understand the specific area being criticized and the nature of the problem.", "verifiability_rationale": "The reviewer makes a clear claim that the convergence proof lacks 'substantial novelty and rigor'. They support this claim by explaining the i.i.d. assumption, the resulting 'clear covariance matrix', and the possibility of 'straightforward modifications'. While not providing external references, the logical reasoning and specific examples (Modification 1) make the claim verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable critique of the convergence proof. They identify the specific issue (i.i.d. assumption) and suggest concrete steps the authors can take (investigating the implications and exploring modifications). This constructive feedback empowers the authors to improve their work and is presented in a way that is easy to understand and follow."}
{"actionability_label": "1", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or provide guidance on how to address the identified issue. The authors are left to interpret the conflicting statements themselves.", "grounding_specificity_rationale": "The review point identifies a potential issue (the conflicting statements) but does not specify which part of the paper or results this issue refers to. It is a highlevel observation rather than a precise grounding.", "verifiability_rationale": "The review point is not a claim that requires verification. It's a question about the interpretation of existing results.", "helpfulness_rationale": "The review point highlights a potential source of confusion for the authors regarding their results. By pointing out the apparent contradiction, it encourages the authors to critically examine their interpretation of the multi vs. singleenvironment model performance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the lack of motivation for the problem and the use of static datasets. This is a clear indication of an actionable point. The reviewer directly points out what is missing and how it impacts the paper's contribution.", "grounding_specificity_rationale": "The reviewer mentions the 'objective of designing fast label aggregation algorithms for a streaming setting' and the 'static datasets used in the empirical analysis'. While the reviewer identifies these aspects, they don't accurately pinpoint the exact section, table, or figure where the motivation is detailed (it's in the introduction, but not explicitly labeled as a 'section'). The mention of 'static datasets' is accurate. Therefore, the grounding is somewhat specific but not fully precise.", "verifiability_rationale": "The reviewer makes a claim that the paper lacks motivation and uses static datasets. They also provide a justification for why this is a problem, stating that 'the problem is not well motivated'. This demonstrates that the reviewer has identified a claim and provided logical reasoning to support it.", "helpfulness_rationale": "The reviewer's comment is highly valuable and directly addresses significant weaknesses in the paper. They clearly articulate the lack of motivation and the use of static datasets, which are crucial for the paper's relevance and impact. The reviewer's argument is wellreasoned and constructive, highlighting the importance of motivating the problem and using appropriate data types for streaming algorithms."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an implicitly stated action: 'the scope of the study is underspecified.' It also identifies a specific area of the paper being discussed: 'the work focuses on injecting CoT based approach to smallscale Language Models.' While the action itself is vague, the reviewer points to a missing element: 'additional relevant CoT baselines for incontext learning of Large Language Models (for text003 and ChatGPT) are missing in Table 2 and 3 (See Question A).' This suggests a concrete improvement. Therefore, the comment is implicitly stating an action and is somewhat concrete in identifying the area of concern, making it actionable.", "grounding_specificity_rationale": "The reviewer attempts to ground the comment by mentioning 'the work focuses on injecting CoT based approach to smallscale Language Models.' This provides a specific area of the paper being discussed. Furthermore, the reviewer specifies what is missing: 'If that is not the case, additional relevant CoT baselines for incontext learning of Large Language Models (for text003 and ChatGPT) are missing in Table 2 and 3...' This clearly identifies the specific type of information the reviewer believes is lacking. Therefore, the comment explicitly mentions which part of the paper it addresses and specifies what needs to be addressed in this part, making it 5.", "verifiability_rationale": "The reviewer makes a claim: 'The scope of the study is underspecified.' However, they do not provide any specific evidence or reasoning to support this claim within the review point itself. While they suggest 'additional relevant CoT baselines for incontext learning of Large Language Models (for text003 and ChatGPT) are missing in Table 2 and 3' as a potential improvement, this is presented as a suggestion rather than a verified claim requiring evidence. Therefore, the comment contains a claim without any supporting evidence or justification, making it 1.", "helpfulness_rationale": "The reviewer points out a potential issue with the paper's scope and highlights missing baselines. This provides the authors with some direction for their work and helps them understand what might be missing in their approach. While the review doesn't explicitly state how the scope is underspecified or how the missing baselines would address it, it raises important questions and points towards relevant areas of research. The suggestions, though not fully substantiated, offer a sense of value and direction for the authors. Therefore, the comment provides some actionable feedback and raises important questions, making it 3, but it lacks concrete evidence to support its claims, making it not fully helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks 'How is this connected?' which clearly states an action: to explain the relationship between the general difficulty of symmetric tensor decomposition and the specific finding about the 'nice' landscape. This action is explicit and directly addresses the connection.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the fact that tensor decomposition is in general harder in the symmetric than in the nonsymmetric case' and 'the recent findings about the `nice' landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors.' This clearly identifies the specific parts of the paper being referenced, making the grounding strong. The reviewer also asks 'how is this connected', which specifies what needs to be explained in this part.", "verifiability_rationale": "The reviewer presents a claim: 'In the introduction the authors mention the fact that tensor decomposition is in general harder in the symmetric than in the nonsymmetric case. How is this connected with recent findings about the `nice' landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors 1?' This claim is about a connection that could be supported by literature on optimization landscapes and tensor decomposition. While the reviewer doesn't provide specific evidence, the claim itself is verifiable by referencing relevant literature.", "helpfulness_rationale": "The reviewer's question is very specific and directly addresses a potential gap in the authors' understanding of the connection between general difficulty and specific landscape properties. This question is likely to be very helpful for the authors to clarify their work and potentially identify areas for improvement. It seeks to bridge a potential gap in their understanding of the implications of the 'nice' landscape."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem of performance degradation with increasing identities and suggests a potential solution of presetting a small capacity. This indicates an explicit action to identify a weakness and propose a direction for improvement. While the suggestion to preset a small number is concrete, the initial observation of the trend is more of an implicit action than a fully explicit one, leading to '4' rather than 'Explicitly Actionable'.", "grounding_specificity_rationale": "The reviewer refers to 'Table 3 (a)' and discusses the 'maximum number of identities.' This directly points to a specific part of the paper and its characteristics. The reviewer is not making an educated guess about where the issue lies, thus demonstrating strong grounding. The reviewer is also specific about the *impact* of increasing identities on performance. The suggestion to preset a capacity to '10' further reinforces this specificity by identifying a concrete aspect of the model's configuration.", "verifiability_rationale": "The reviewer makes a claim that 'the performance is getting worse with growth of the maximum number of identities.' They also suggest a solution by proposing 'presetting the capacity to some small number (e.g., 10).' The reviewer implies a logical connection between the number of identities and the model's performance. While the suggestion to preset a capacity is concrete, the initial claim about performance degradation is not fully supported by external references or specific examples within the review point itself, making it somewhat '3'.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the model's performance with increasing identities and offers a potential improvement by suggesting a preset capacity. The language is direct and actionable, providing the authors with a clear understanding of the issue and a starting point for investigation. The reviewer's suggestion is directly aimed at addressing the identified problem, making the feedback 5 for the authors' debugging and potential model adjustments."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Specific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement 'I don't see anything NLPspecific in their approach' is an explicit action, as the reviewer directly states what is lacking. However, the action is vague because it doesn't specify *where* the NLPspecificity is missing or what should be NLPspecific. The reviewer identifies a potential weakness but doesn't provide concrete steps for improvement.", "grounding_specificity_rationale": "The comment 'The authors claim it to be one of the preliminary works discussing the application of LLP to NLP tasks. However, I don't see anything NLPspecific in their approach' does not explicitly identify a specific part of the paper being addressed. The reviewer refers to 'their approach' generally, without pointing to a specific section, table, figure, or unique element. Therefore, the grounding is weak.", "verifiability_rationale": "The comment contains a claim ('the authors claim it to be one of the preliminary works discussing the application of LLP to NLP tasks. However, I don't see anything NLPspecific in their approach') that requires verification. However, the comment does not provide any evidence, examples, or references to support this claim. The reasoning is missing, making it 1.", "helpfulness_rationale": "The review point is not particularly helpful because it criticizes the authors' claim without providing any concrete suggestions or explanations. The reviewer states 'I don't see anything NLPspecific' but doesn't offer any alternatives or further details about what should be NLPspecific. The feedback is negative and lacks actionable value."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing justification and the lack of discussion regarding the need for a new curriculum learning method. They point out that the paper doesn't explain why existing methods are insufficient for text graphs. This is a clear and direct action the reviewer takes, identifying a specific gap in the paper's discussion.", "grounding_specificity_rationale": "The reviewer refers to 'Section 1' and the concept of 'curriculum learning methods' in the paper. While not a unique element, it is a specific part of the paper. The reviewer also specifies the *type* of gap they are pointing out: 'the need for designing a new curriculum learning method' and 'why existing methods can\u2019t be applied'. This shows a degree of grounding and specificity in identifying the issue.", "verifiability_rationale": "The reviewer makes a claim that the paper 'doesn't discuss' or 'doesn't justify' the need for a new method and the limitations of existing ones. However, the reviewer does not provide any specific evidence or reasoning to support this claim within the review point itself. The claim is based on an observation, not a logical deduction or citation of external work.", "helpfulness_rationale": "The reviewer clearly identifies a missing justification and a lack of discussion regarding the need for a new curriculum learning method. They suggest that the paper should 'design a new curriculum learning method' and 'discuss the limitations of existing methods'. These are concrete suggestions that directly address the identified gap. The reviewer's action is to point out a weakness and propose a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification on a definition, which can be seen as an implicit action to improve understanding. However, the specific action of 'improving understanding' isn't explicitly stated or actionable in terms of concrete steps for the authors to take. The reviewer is essentially prompting for more information.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'definition 2.1' and 'auxiliary model weights', indicating they are identifying a specific part of the paper. However, they also state that the definition is 'a bit difficult for me to interpret', indicating the explanation within that definition is not clear or specific. Therefore, while a specific section is mentioned, the explanation lacks clarity.", "verifiability_rationale": "The reviewer is making a claim about the clarity of a definition. While they don't provide external references or logical reasoning to support this claim, the claim itself is verifiable by examining the actual definition in the paper. Therefore, the claim is verifiable but lacks external support.", "helpfulness_rationale": "The reviewer is pointing out a potential area of confusion for the authors. While the comment itself isn't a direct instruction on how to fix the issue, it identifies a potential problem, making it 3 in highlighting a need for clarification. The helpfulness is limited because the reviewer doesn't offer a solution."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests examining the final outputs and figures but doesn't explicitly state how to improve the model or the evaluation process. It identifies a potential area for improvement (analyzing final outputs) but lacks specific guidance on the actions to take.", "grounding_specificity_rationale": "The review point refers to 'Figure 3,' 'Figure 4,' 'middle outputs,' and 'final outputs' but doesn't specify which part of the paper these relate to or what specific issues they are critiquing. The criticism is about the content of the figures rather than a direct critique of a specific section or element.", "verifiability_rationale": "The review point makes a claim about the ineffectiveness of current evaluations but provides no evidence or reasoning to support this claim. It's a statement of concern without backing.", "helpfulness_rationale": "The review point criticizes the evaluation process and suggests an alternative, but it doesn't offer specific, actionable feedback on how to improve the model or the evaluation methodology. It's more of a critique than a helpful suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides explicit suggestions for improvement, such as 'add details to the experimental procedures,' 'add error bars and pvalues to statistical inferences,' and 'include supplementary information for clarification.' These suggestions directly address specific shortcomings in the paper, making the feedback actionable for the authors.", "grounding_specificity_rationale": "The reviewer explicitly points out specific areas where improvements are needed, such as 'the explanations,' 'the procedures,' and 'Figure 2.' This direct identification of the problematic sections grounds the feedback in the paper, allowing the authors to focus their edits.", "verifiability_rationale": "The reviewer makes claims about the paper's limitations, such as 'the explanations are very qualitative,' 'the procedures are described very minimally,' and 'some figures are confusing.' These claims are supported by the lack of detail in the paper, the absence of statistical rigor, and the ambiguity in Figure 2. The reviewer also suggests specific improvements (error bars, pvalues, supplementary info) that would address these limitations, making the feedback verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable list of suggestions for improvement, directly addressing the identified weaknesses. The suggestions are specific and point to concrete areas where the authors can make changes. This makes the feedback 5 for the authors to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'This paper could be improved by explicitly showing the settings for the various knobs of this algorithm to mimic prior work: Dagger, searn, etc...'. This action is concrete, telling the authors exactly what they should do.", "grounding_specificity_rationale": "The review point mentions 'various knobs of this algorithm' and 'prior work: Dagger, searn, etc...'. While it doesn't pinpoint a specific section or table, it does mention specific examples of prior work, providing some grounding. The general references to 'knobs' and 'prior work' indicate an attempt to refer to specific parts of the paper or relevant concepts.", "verifiability_rationale": "The review point makes a claim: 'This paper could be improved by explicitly showing the settings...to mimic prior work.' This claim is somewhat supported by the suggestion to 'mimic prior work', which implies a need for clarity and consistency with existing literature. However, the specific 'knobs' and the exact 'settings' are not detailed, making the claim somewhat vague.", "helpfulness_rationale": "The review point provides a clear direction for improvement by suggesting 'showing the settings for the various knobs of this algorithm' to 'mimic prior work'. This directly addresses a practical concern and offers a specific area for the authors to focus. While it lacks specific details on *how* to show the settings, it is a concrete suggestion related to a relevant issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out a lack of clarity regarding the *generalizability* of the discussed biases and prediction shifts. While they understand the *existence* of these issues (implying an explicit action of identifying a problem), they are unclear on how *common* or *widespread* these situations are. The action is identified, but the specifics of how to apply it are vague. The reviewer is asking 'how general these situations are' rather than providing a direct action on how to address it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 3.2' and 'Theorem 1' in their review point, indicating a clear identification of the specific part of the paper being addressed. They are also asking about the generality of the issues within this section, which can be seen as a specific aspect of the paper. Therefore, the grounding is strong. However, the reviewer is not specifying *how* the generality relates to section 3.2 and Theorem 1, making the specificity weak.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question about the generality of the observed phenomena. There is no assertion of something being correct or incorrect, so there is X to be verifiable.", "helpfulness_rationale": "The reviewer is asking a question about the generality of the discussed biases and prediction shifts. While this is a valid point for clarification and understanding, it does not directly provide actionable feedback or critique that would help the authors improve their draft. The question is about understanding, not about guiding improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states their belief that the method in Section 3.1 follows the previous work, Luciddreamer, but does not explicitly identify the action or improvement they are suggesting. The statement is a general observation rather than a specific instruction on how to improve the method.", "grounding_specificity_rationale": "The reviewer mentions 'Sec. 3.1' and 'Luciddreamer' but does not explicitly point to a specific part within Section 3.1 that they are criticizing. The grounding is weak because the authors cannot confidently determine which part of the paper the reviewer is referring to.", "verifiability_rationale": "The reviewer makes a claim ('the Sec. 3.1 for 3D Gaussians generation seems to just follow the previous work, Luciddreamer') but does not provide any evidence or reasoning to support this claim within the review point itself. The verifiability is low because the reasoning, common knowledge, or external references are not present to justify the statement.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the novelty of the method in Section 3.1. However, they do not provide any specific suggestions or improvements. The helpfulness is limited because the reviewer does not offer actionable feedback on how to enhance the method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the drawbacks of MMD DRO, such as the lack of an exact reformulation, the looseness of the upper bound, and the restrictive assumption about the loss function. However, the reviewer does not provide concrete steps or modifications that authors should implement to address these issues. The suggestions are implicit, requiring the authors to infer the necessary actions.", "grounding_specificity_rationale": "The reviewer refers to 'MMD DRO' and 'Theorem 3.1', indicating a clear identification of the specific area being discussed. However, the reviewer does not specify *where* within the method or theorem these issues arise or *how* they manifest. The critique is general to the method rather than pinpointing a specific element within it.", "verifiability_rationale": "The reviewer presents several claims about the limitations of MMD DRO. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The statements are presented as observations or critiques without justification.", "helpfulness_rationale": "The reviewer points out specific limitations of MMD DRO, which could be valuable information for authors considering this method. However, the reviewer does not offer any concrete suggestions or guidance on how authors should address these limitations. The feedback is primarily a critique without actionable improvements."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the desired action: 'it should be reorganized'. This is a clear and direct instruction for the authors. While the specifics of the reorganization are not provided, the action itself is explicit. Therefore, it is actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'Appendix H', which is a specific part of the paper. This demonstrates strong grounding as the authors can easily identify the referenced section. The comment also clearly identifies the issue as 'difficult to follow', which is a specific description of the problem within that section. Therefore, it is 5.", "verifiability_rationale": "The comment contains a claim: 'Appendix H section should be reorganized which is difficult to follow'. This claim is supported by the suggestion to reorganize, which can be interpreted as a recommendation or justification for addressing the difficulty in following the section. While it lacks specific examples or references, the suggestion itself provides some level of verifiability. Therefore, it is 4.", "helpfulness_rationale": "The comment provides a clear and actionable suggestion: 'reorganize Appendix H'. This is a direct and helpful piece of feedback for the authors. The suggestion is specific enough to guide them in improving the draft, even though the exact nature of the reorganization is not detailed. Therefore, it is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The reviewer identifies the problem of the paper not being reproducible despite the pseudocode and supplementary material. They suggest that more details are needed. While the reviewer doesn't explicitly state 'Add a section on RNN implementation details', they point out specific missing technical details like 'RNN implementation (number of units etc), and many other technical details'. This implies an action, but the specific action isn't directly stated.", "grounding_specificity_rationale": "The reviewer points out the need for more technical details to reproduce the work. They specifically mention missing information like 'RNN implementation (number of units etc), and many other technical details'. While the reviewer doesn't explicitly state 'Look at Section 3 and add RNN implementation details', they name concrete missing information. This indicates weak grounding but specific examples of what is missing.", "verifiability_rationale": "The reviewer makes a claim: 'even with the pseudocode given in the supplementary material I don't get the feeling the paper is written to be reproduced'. They then provide evidence for this claim by stating 'It is written to provide an intuitive understanding of the work, but to actually reproduce it, more details are required that are neither provided in the paper nor in the supplementary material'. This provides logical reasoning supporting the claim.", "helpfulness_rationale": "The reviewer clearly identifies a problem: 'the paper is not written to be reproduced'. They then offer a solution: 'more details are required that are neither provided in the paper nor in the supplementary material'. This directly addresses the identified problem and suggests a concrete improvement. The reviewer's suggestion is actionable and directly relevant to the authors' goal of reproduction."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'Figure 1 would be much stronger if there were error bars...' and 'more random trials...'. These are explicit statements that direct the authors to take specific actions: add error bars to Figure 1 and increase the number of random trials. The actions are concrete and directly address the identified issue.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 1' as the area for improvement. This is a clear and unambiguous identification of the specific part of the paper being addressed. The suggestion directly relates to the visual representation within Figure 1.", "verifiability_rationale": "The review point is a suggestion for improvement, not a claim that requires verification. It proposes adding error bars and more trials to enhance the strength of Figure 1, but it doesn't make a statement about what Figure 1 *is* or *isn't*.", "helpfulness_rationale": "The review point directly identifies a potential weakness in Figure 1 (lack of error bars and potential random fluctuations) and provides clear, actionable suggestions to improve it. This is a very constructive and helpful comment for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides two distinct suggestions. The first, to add a brief introduction to energy models in the related work section, is an explicit action suggesting an improvement. The second, regarding Figure 1, implicitly suggests an action by pointing out the missing labels for different learning rates and steps. While both are helpful, only the first is a fully explicit action with concrete details. The second requires the authors to infer the missing information.", "grounding_specificity_rationale": "The review point offers two suggestions. The first, to add an introduction to energy models in the related work, is 1 as the authors do not specify which section or table this refers to. The second, regarding Figure 1, explicitly points out the missing labels for different learning rates and steps, making this suggestion fully grounded. However, the first suggestion is not specific enough to be considered grounded.", "verifiability_rationale": "The review point does not contain any claims or opinions. It is a suggestion for improvement and a request for clarification. Therefore, it does not have verifiability as it is not a claim that can be supported or unsupported.", "helpfulness_rationale": "The review point offers two suggestions. The first, to add a brief introduction to energy models in the related work section, is generally helpful as it provides context and background for the work. The second, regarding Figure 1, is also helpful as it directly addresses a missing element that would improve the reader's understanding of the results. Both suggestions are directly aimed at improving the authors' understanding and the paper's clarity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states 'Figure 2 right.' and provides a concrete action to improve the figure: 'make use of styles (e.g. dashed lines) or add color.' This directly addresses the identified part of the paper and offers a clear, actionable improvement.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 2 right,' which is a precise and accurate identification of the specific part of the paper being addressed. The suggestions to 'make use of styles (e.g. dashed lines) or add color' are concrete and directly relate to the identified figure. This demonstrates full grounding and specificity.", "verifiability_rationale": "While the initial statement 'I found it difficult to distinguish between the different curves' is not a direct claim about the paper's quality, it implies a judgment about the figure's clarity. The comment then provides specific suggestions ('make use of styles (e.g. dashed lines) or add color') that directly address the identified issue and offer verifiable solutions. The suggestions are logical and provide concrete examples of how to improve the visualization. Therefore, while the initial observation is somewhat underspecific, the subsequent suggestions are fully specific and verifiable.", "helpfulness_rationale": "The comment is very direct in identifying the problem (difficulty distinguishing curves) and provides a clear and actionable solution (using styles or adding color). This directly addresses a clear issue and offers a concrete improvement, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Weakly Specific", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer's comment is **implicitly** stated, requiring the authors to infer the mismatch between the claimed language learning aspect and the actual question answering task. This makes it less actionable as the authors need to deduce the issue.", "grounding_specificity_rationale": "The reviewer's comment is 1 in the paper's content. While the reviewer implies a mismatch, the authors cannot pinpoint the specific section or element in the introduction that is inaccurate or misaligned with the task.", "verifiability_rationale": "This aspect is not applicable as the review point is a suggestion, not a claim requiring verification.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion to improve the introduction and the framing of the work, directly addressing the authors' needs for clarity and accuracy."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the performance gap between the submitted model and two specific recent models, GLaMM and UNINEXT. It also suggests comparing the results in Table 4 with the performance of these models on the mentioned datasets and metrics. This provides clear, actionable feedback for the authors to investigate and potentially improve their model's performance.", "grounding_specificity_rationale": "The review point explicitly refers to 'Table 4' as the location of the performance comparison. Furthermore, it provides specific details about the models (GLaMM, UNINEXT) and metrics (RES cIoU, REC accuracy, IoU>0.5) being compared. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The review point contains a claim that the performance on REC and RES in the submitted work is 'clearly behind more recent models'. It then provides specific performance numbers from external references ref1 and ref2 to support this claim. The reasoning is logical, and the evidence is clear, making the claim verifiable.", "helpfulness_rationale": "The review point is 5 as it directly points out the performance gap and provides concrete suggestions for the authors to compare their results with those of specific recent models. The inclusion of references makes the feedback actionable and verifiable, empowering the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a fact ('shows evidence') about the order of learning, which is an explicit action. However, they don't provide concrete steps or modifications the authors should take based on this observation. The action is stated, but the implementation is vague.", "grounding_specificity_rationale": "The reviewer refers to 'evidence' generally and 'concepts' broadly, without specifying which section, table, figure, or unique element of the paper is being discussed. The grounding is weak because the referenced part is not precisely identified. The specificity is also weak as the reviewer doesn't detail what the 'evidence' looks like or which specific concepts are involved.", "verifiability_rationale": "The reviewer makes a claim ('some information is learned before the model is able to use the concepts'). However, they do not provide any logical reasoning, common knowledge, or external references to support this claim. The claim is stated, but the verification is lacking.", "helpfulness_rationale": "The reviewer points out a potential issue (the order of learning) that could be relevant to the authors' work. However, they don't provide specific suggestions or guidance on how the authors should address this. The comment identifies a potential problem but doesn't offer concrete improvement steps."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states that the kernels are implemented with OpenAI's Triton, not CUDA, and suggests that a fullpage explanation is unnecessary. This is a direct and concrete action that the authors can take to understand the implementation details more efficiently.", "grounding_specificity_rationale": "The comment identifies the specific aspect of the paper being discussed: the implementation of kernels with OpenAI's Triton. While it doesn't pinpoint a specific section, table, or figure, it clearly refers to a specific part of the implementation. The grounding is present but could be more precise.", "verifiability_rationale": "The comment provides a justification for why a fullpage explanation might be unnecessary, stating that 'due to wellknown engineering improvements.' This provides a logical reasoning that supports the suggestion for conciseness.", "helpfulness_rationale": "The review point is 5. It directly identifies a factual discrepancy in the implementation details (Triton vs. CUDA) and provides a practical suggestion for improving the paper's clarity by recommending a more concise explanation. The justification for the suggestion ('due to wellknown engineering improvements') adds further value by explaining the reasoning behind the recommendation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The statement explicitly states that the extension from linear models to wide fullyconnected neural networks is trivial and that the work only considers the easy wide fullyconnected neural networks. This directly points out a lack of significant contribution in this area, providing a clear action for the authors to address this limitation.", "grounding_specificity_rationale": "The reviewer mentions 'Section 3.2, 3.3' and 'wide fullyconnected neural networks' which indicates a partial grounding. However, they do not specify a particular element within these sections or the networks themselves that needs addressing. The reviewer is making a general statement about the type of neural networks considered, rather than pinpointing a specific part of the paper.", "verifiability_rationale": "The statement contains claims: 'With the existing NTK theorem, the extension from linear models to wide fullyconnected neural networks is trivial' and 'The work bypasses the core problem of overparametrized neural networks and only considers the easy wide fullyconnected neural networks'. These claims are supported by the mention of 'Section 3.2, 3.3' and the focus on 'easy wide fullyconnected neural networks', providing logical reasoning and specific examples.", "helpfulness_rationale": "The review point is 5 as it directly criticizes a key aspect of the paper (the analysis of neural networks) and suggests a clear direction for improvement. It highlights the limitations of the work in this area and provides a concrete suggestion for the authors to focus on more complex networks."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and Somewhat Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the weakness (no results for larger models), but it does not directly instruct the authors on the next steps to take.", "grounding_specificity_rationale": "The paper sections and model names are mentioned, providing some grounding. However, the specific aspect of the paper being addressed (e.g., performance analysis, efficiency comparison) is not clearly defined.", "verifiability_rationale": "The review point is a factual statement about the absence of results, not a claim that requires verification or justification.", "helpfulness_rationale": "The review point identifies a missing piece of information (results for larger models), which is relevant for a comprehensive evaluation of the models. While it doesn't provide explicit instructions on how to address this, it highlights a gap in the presented results."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a potential inconsistency in terminology ('inexpensive' vs. 'expensive') but does not explicitly state what the authors should do to resolve this. While the inconsistency is implied, the reviewer does not provide concrete steps or actions for the authors to take. The authors are left to interpret the potential contradiction themselves.", "grounding_specificity_rationale": "The reviewer identifies a potential issue in the abstract and the introduction, which are broad sections. While the reviewer points out a potential inconsistency, they do not explicitly state which part of the paper is confusing or what specific aspect of the terms ('inexpensive' and 'expensive') needs clarification. The authors would still need to infer the specific area of concern.", "verifiability_rationale": "The reviewer makes a claim about a potential inconsistency in the terminology used in the abstract and introduction. They provide examples of the terms ('inexpensive' and 'expensive') but do not explicitly state that there is a contradiction or provide evidence to support this claim. The reasoning is implied but not clearly articulated or supported by external references.", "helpfulness_rationale": "The reviewer's comment raises a potential issue regarding the terminology used in the abstract and introduction. While this could be valuable feedback for the authors to ensure clarity, the comment does not offer a solution or a clear direction for the authors to follow. The feedback is more of a *warning* or *potential problem* than a helpful suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desired change: 'the paper compares to related work only on some not official test set or dev set, however the final results should be compared on the official COOC leader board on the blind test set'. This clearly indicates an action the authors should take. The reviewer also implicitly suggests the consequence of not doing so: 'lack of proper benchmarking'. The reviewer further elaborates on the *how* by providing the link to the COOC leaderboard and mentioning specific strong results (5,17). This provides concrete details on how the authors can implement the suggested change.", "grounding_specificity_rationale": "The reviewer points out a discrepancy in the evaluation method used in the paper. They state that the comparison is done on 'some not official test set or dev set' while the 'official COOC leader board on the blind test set' should be used. This indicates a lack of clear grounding in the evaluation protocol. While the reviewer mentions the *what* (official leaderboard) and the *how* (blind test set), they don't explicitly state *which specific part* of the paper's results or comparisons is lacking. The grounding is implicit in the criticism of the comparison method.", "verifiability_rationale": "The reviewer makes a claim: 'the paper compares to related work only on related work only on some not official test set or dev set, however the final results should be compared on the official COOC leader board on the blind test set'. This claim is supported by logical reasoning: the standard evaluation protocol for this task is the official COOC leaderboard. The reviewer also provides external references (the link to the COOC leaderboard and mentions of strong results from 5,17), which serve as evidence to support their claim. The claim is further strengthened by the logical argument that using the official leaderboard is the correct way to benchmark performance in this context.", "helpfulness_rationale": "The reviewer's point is 5 for the authors. By highlighting the discrepancy in the evaluation method, they are directly addressing a crucial aspect of research rigor: proper benchmarking and comparison. The reviewer provides a clear direction for the authors to take, specifically suggesting the use of the official COOC leaderboard and blind test set. This is a concrete and actionable piece of feedback that directly improves the authors' ability to validate their work and compare it to existing stateoftheart methods. The reviewer also provides evidence (the link and mention of strong results) to support their claim, making the feedback more robust."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review points out a discrepancy in the results (MSE < MAE) and links it to the reliability of the experimental results. This suggests a potential issue with the methodology or implementation. It's explicit enough to indicate a problem, but it doesn *not* explicitly state *what* needs to be changed. It doesn't say \"You should rerun the experiments with...\" or \"Check your MAE calculation\".", "grounding_specificity_rationale": "The reviewer mentions \"Table 1\" and specific metrics (\"MSE\" and \"MAE\"). It also points to a *discrepancy* in the results (MSE < MAE) which is a clear indication of a potential issue. They also link this discrepancy to \"reliability\".", "verifiability_rationale": "The review states a *judgment* about the experimental results: \"experimental results are unreliable\" and \"MSE is significantly smaller than the MAE, which raises concerns about their validity\". This is a claim. However, the reviewer *does not* provide any specific evidence or references to support this claim. They state the observation but don't explain *why* it's concerning or suggest any specific literature.", "helpfulness_rationale": "The reviewer points out a *potential error in the evaluation metrics or implementation*. This is a valuable piece of feedback. However, they *don't* suggest specific steps to *fix* the issue. They don't say \"Check your MAE calculation\" or \"Rerun the experiments\". While the reviewer identifies a problem, the lack of concrete suggestions limits its ability to help the authors improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment identifies the lack of novelty but does not specify how to improve the methodology or provide concrete steps. It's unclear what the author should do next.", "grounding_specificity_rationale": "The comment is general and does not specify which part of the paper it is addressing. It criticizes the methodology as a whole without pointing to a specific section or aspect.", "verifiability_rationale": "The comment is an opinion about the lack of novelty, not a claim that requires verification or justification based on the paper's content.", "helpfulness_rationale": "The comment identifies a valid concern but offers no actionable steps or specific suggestions for improvement. It's a negative comment without constructive feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests improving the clarity of an explanation at L248. While they don't provide a specific 'how', they identify a actionable area for improvement by pointing to the 'nuance' at L255 as the specific area needing attention. This indicates an explicit suggestion to make the explanation better. However, the action is not fully concrete, as the reviewer doesn't specify the exact changes needed. The grounding is strong as they refer to a specific line number (255).", "grounding_specificity_rationale": "The reviewer refers to 'the nuance' at L255, which strongly suggests they are identifying a specific part of the paper. While not a perfect literal match, it's a very specific reference to a unique aspect of that section. The reviewer also explicitly states that the explanation at L248 is unclear and needs improvement, which clearly specifies what needs to be addressed in that part. This combination of strong grounding and clear specificity leads to a high grounding specificity score.", "verifiability_rationale": "The reviewer makes a claim at L248 that the explanation is 'wrong' and that the paper gets into some of the nuance of this position at L255. This constitutes a claim that requires verification. However, the reviewer does not provide any specific examples, references, or logical reasoning to support their claim. The justification is vague, and the common knowledge or external references are missing. This makes the claim 3 as it is stated, but lacks sufficient support.", "helpfulness_rationale": "The reviewer's comment at L248 identifies a specific area of the paper (the explanation at L248) as needing improvement. They point out a lack of 'nuance' and suggest that the paper's explanation is unclear. This is a helpful comment as it highlights a weakness in the paper. However, the reviewer does not offer any concrete suggestions or solutions for how to improve the clarity. They are essentially pointing out an issue rather than providing a constructive suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors have not covered more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This provides a clear action for the authors to take, which is to include this information in their paper. The reviewer directly points out a missing element and suggests where it should be placed, making the action quite explicit and concrete.", "grounding_specificity_rationale": "The reviewer refers to 'datasets' and then narrows it down to 'types of activities' and their 'importance for occupant comfort and energy efficiency'. While the reviewer doesn't explicitly name a section or table, they clearly identify the specific aspect of the dataset they are referring to. This allows the authors to identify the relevant part of the paper where this information might be missing. The specificity comes from the reviewer pinpointing the exact elements (activity types and their impact) that are relevant. They also provide a reason (improving occupant experience) for why this information is important, making it more than just a vague reference.", "verifiability_rationale": "The reviewer states that the authors have not covered more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This statement is a claim that the authors are missing information. However, the reviewer is not providing any logical reasoning, common knowledge, or external references to support this claim within the review point itself. The claim is based on their assessment of the paper's content, but there's no evidence presented to verify it. Therefore, the claim is not verifiable based solely on the information within this review point.", "helpfulness_rationale": "The review point directly points out a gap in the authors' discussion regarding the types of activities in their datasets and their relevance to occupant comfort and energy efficiency. This is a clear and actionable suggestion for the authors. They are being informed about a missing piece of information that could significantly improve the paper's contribution and relevance. The reviewer provides a clear direction for the authors to take, making this review point 5 in guiding the authors towards a more complete and impactful paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a performance difference between two specific configurations (RGCN discriminator vs. proposed module) in Section 5.3 and asks for an explanation of why the proposed module prevents collapse. While it points to a discrepancy, it doesn't explicitly state what action the authors should take based on this observation. The reviewer is seeking clarification and understanding, which can be seen as an implicit call for action, but it's not a direct instruction on how to modify the method.", "grounding_specificity_rationale": "The review point explicitly mentions 'Sec 5.3' and compares 'a generator equipped with a standard RGCN as discriminator' with 'the proposed module'. This clearly identifies the specific part of the paper and the components being discussed. The reviewer also states that the RGCN discriminator 'tends to collapse' and the proposed module 'will not', specifying what is being addressed within the referenced part. Therefore, the grounding is strong, and the specificity is also present as the reviewer identifies a specific behavior (collapse vs. no collapse).", "verifiability_rationale": "The review point contains a claim: 'the reason behind this fact can be essential to show the mechanism how the proposed method differs from previous one'. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The reviewer asks for an explanation, implying they believe a reason exists, but it's not explicitly stated or justified. Therefore, it is 2 as it contains a claim but lacks supporting evidence.", "helpfulness_rationale": "The review point raises a valid concern about the stability of the generator with the RGCN discriminator and asks for an explanation of the proposed module's behavior. This directly relates to understanding and potentially improving the method described in the submission. While it doesn't provide a direct solution, it points to a crucial experimental detail that needs clarification, making it 5 for the authors to understand the method's inner workings and potential limitations. The reviewer's question is directly relevant to understanding a core component of the proposed method and its experimental validation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment points out a lack of clarity regarding theoretical comparisons to adaptive learning of GPRGNN. While it doesn't explicitly state what is unclear, it implies that the authors should understand this comparison. This is an actionable call for the authors to investigate this gap.", "grounding_specificity_rationale": "The comment explicitly mentions 'adaptive learning of GPRGNN,' which is a specific aspect of the paper. However, it doesn't specify *why* the comparison is unclear or what needs to be done to make it clearer. The grounding is present, but the specificity of the issue is missing.", "verifiability_rationale": "The comment states that 'theoretical comparisons to adaptive learning of GPRGNN is not clear' without providing any justification or evidence. There is X being made, so the verifiability scale does not apply in this case.", "helpfulness_rationale": "The comment encourages the authors to understand a missing element in their work. This is a helpful suggestion that prompts further investigation and analysis."}
{"actionability_label": "4", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the missing components (spatial, temporal, summary queries) and suggests experiments to investigate them. This is a clear and direct action that authors can follow.", "grounding_specificity_rationale": "The comment explicitly mentions the specific queries (spatial, temporal, summary) and their relevance to understanding the model's behavior compared to other works. The grounding is strong as it points to the specific aspect of the method being discussed.", "verifiability_rationale": "The comment identifies a potential weakness in the ablation study (missing experiments for different query types) and suggests a way to address it (providing experiments and explanations). While it doesn't *prove* the missingness in this review point, the implication is clear and the suggestion is verifiable if the authors implement it. The reasoning is logical and the potential benefit is clear.", "helpfulness_rationale": "The comment directly points out a gap in the ablation study and suggests a concrete way to improve it by including experiments for different query types. This directly addresses a potential area of confusion or lack of understanding for the authors regarding their model's behavior and its differentiation from other models like VideoChatGPT. The suggestions are actionable and would likely improve the clarity and completeness of the ablation study."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the authors' perspective on the lack of negative social impacts. However, it doesn't provide concrete actions or suggestions for how to address this point. The reviewer acknowledges the authors' statement but offers potential areas for improvement rather than direct actionable feedback.", "grounding_specificity_rationale": "The comment identifies the 'social impact' of the work as a relevant area, thus grounding the feedback in a specific aspect of the paper. However, it doesn't specify *which* part of the paper or *what specific* elements of social impact are being addressed. The reviewer is general in their critique of the authors' statement.", "verifiability_rationale": "The comment contains a claim: 'the authors state that they foresee no negative social impacts of their work'. The reviewer expresses doubt about this claim and suggests potential areas for negative impact (increased automation, dual use) as potential evidence. While the authors haven't explicitly discussed these points, the reviewer provides examples that could be used to verify the authors' statement.", "helpfulness_rationale": "The comment raises a valid concern about the lack of discussion on social impact. It acknowledges the authors' perspective and suggests potential areas for improvement. However, it doesn't directly provide the authors with specific, actionable steps to take based on this observation. It's more of a suggestion for improvement rather than a direct critique or recommendation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states that information is missing but does not specify what information is missing or how to obtain it. The action is implicit (inferring the need for information) rather than explicit (stating a need for a specific action).", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper or a specific model function where the information is missing. It is a general statement about a lack of information. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The comment states a fact (information is missing) but does not provide any justification or evidence for why this information is expected to be available or reliable. There is no logical reasoning, common knowledge, or external references provided to support the claim that the model function is reliable. The verifiability is low because the claim is presented without any supporting evidence.", "helpfulness_rationale": "The comment identifies a gap in the information provided but does not offer any solutions or directions for how to address the missing information. It highlights a potential issue but does not empower the authors to improve their draft. The helpfulness is limited because the comment only points out a problem without providing any actionable steps to fix it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points out a discrepancy between the current text and the intended meaning, implying a need for a more precise description. While the action is not explicitly stated as 'change thousands to millions and add on the subword level', the reviewer clearly suggests this. Therefore, the action is implied but not fully specified.", "grounding_specificity_rationale": "The review explicitly refers to 'L006' and mentions 'the main text', clearly identifying the specific part of the paper being addressed. Furthermore, the reviewer provides a specific suggestion ('maybe add \"on the subword level\"') regarding how the issue might be resolved. This demonstrates a high level of specificity in identifying both the location and the nature of the problem.", "verifiability_rationale": "The review contains a claim ('\"thousands\" is not accurate here') and a suggestion ('maybe add \"on the subword level\"'). However, it does not provide any logical reasoning, common knowledge, or external references to support why 'thousands' is inaccurate or why 'on the subword level' is the appropriate fix. The claim is presented without sufficient justification.", "helpfulness_rationale": "The review points out a potential inaccuracy and offers a concrete suggestion for improvement. While the suggestion is specific, the lack of justification for why the original paper made the error and why the suggested fix is optimal makes the review less helpful than it could be. The reviewer is directly informing the authors of a potential issue and a possible solution, which is generally helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions the absence of hyperparameters, which is a clear and actionable piece of feedback. The reviewer also points out the behavior of a specific figure (y=0 at x=0), which is an implicit action requiring the authors to investigate and potentially address this issue. The suggestion to explore further analysis is also an implicit action, indicating a desire for improvement but lacking specific guidance. Therefore, while some aspects are explicit, the overall feedback is 3.", "grounding_specificity_rationale": "The reviewer mentions 'regularization' as an example of missing hyperparameters, indicating a degree of specificity. They also explicitly refer to 'latent path figures (eg Fig 3)', which grounds the discussion to a specific part of the paper. However, the suggestion to explore further analysis is more general, lacking a specific reference to a particular aspect or component of the model. Thus, the grounding is good but not fully specific.", "verifiability_rationale": "The reviewer claims that the absence of hyperparameters and the behavior of the latent path figures are issues that require justification. While the absence of hyperparameters is a reasonable suggestion, its verifiability depends on the authors' ability to find and understand the missing information. The behavior of the latent path figures (y=0 at x=0) is also presented as a problem, and its verifiability depends on the authors' ability to confirm or deny this observation. The suggestion to explore further analysis is also presented as a beneficial step, but its verifiability depends on the authors' ability to assess the value of this analysis. Therefore, the claims are 3.", "helpfulness_rationale": "The reviewer points out missing hyperparameters, which are crucial for model performance, making this feedback 5. The observation about the latent path figures, while potentially concerning, is a reasonable suggestion for improvement, making it 3. The suggestion to explore further analysis is also a valuable and potentially impactful piece of feedback, making it 5. The overall feedback is focused on identifying areas for improvement and suggesting further investigation, which is generally beneficial for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks questions about the effect of rounding on the full tensor error and the existence of an error bound related to epsilon. While the questions are clear, they are broad and don't provide specific, actionable steps for the authors. The reviewer is seeking information, which can be considered an implicit action.", "grounding_specificity_rationale": "The reviewer refers to the paper where the rounding method is mentioned, providing a clear reference point. However, the reviewer's questions are specific to the theoretical impact on the full tensor error and the existence of an error bound in terms of epsilon, which is not explicitly stated or detailed in the paper. The grounding is present, but the specificity of the request is limited.", "verifiability_rationale": "The reviewer is asking a question rather than making a declarative statement. Therefore, there is no explicit claim. The underlying intent is to seek information about a specific aspect of the method. While the reviewer is engaging with the paper's content, the request itself doesn't contain a claim that can be verified.", "helpfulness_rationale": "The reviewer is asking a specific question about a technical detail related to the method's implementation. While this is a valid inquiry, it doesn't directly provide actionable feedback or guidance for improving the draft. The request is focused on understanding a specific aspect rather than suggesting concrete changes."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing information: \"it's known that discriminative setting can not apply on real applications, what is the result on generative setting?\". The action is to identify the generative setting results. This is a clear and direct request, making it explicit. The reviewer also implies the need for concrete results for this setting.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"the generative setting\" as the missing information. This is a clear identification of the specific part of the paper being addressed. The comment also specifies what is missing: \"the result on generative setting\". This makes the grounding both strong and specific.", "verifiability_rationale": "The reviewer is asking a question about a known aspect of the experimental setup (the two test settings). While it's not a direct claim of opinion, it's a logical request for information related to the generative setting. The reviewer implies a desire for more comprehensive results. The request itself doesn't have explicit justification or references, but it's a clear deduction about what information is missing based on the context of the paper.", "helpfulness_rationale": "The reviewer is directly pointing out a clear gap in the presented results: the absence of results for the generative setting. This is a very actionable and specific feedback for the authors. It directly tells them where their evaluation is lacking and what they need to see. This is likely to be very helpful in improving their draft by providing a concrete area for further analysis."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point does not explicitly state an action or provide concrete steps for the authors to take. It raises a potential area for improvement but does not direct the authors on how to achieve it.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or element. It is a general suggestion about the type of scenario, making it 1.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for future work, not a statement that needs to be proven.", "helpfulness_rationale": "The review point identifies a potential area for improvement but does not provide concrete steps or guidance for the authors. It is a suggestion rather than a directive action."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the form of 'p' should be described. However, it does not provide any guidance on how to achieve this. The suggestion is present, but the action of describing 'p' is not explicitly directed or actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'line 135', allowing the authors to identify the specific part of the paper being referred to. However, the comment does not specify *what* aspect of the form of 'p' needs to be described. The grounding is present, but the specificity of the request is lacking.", "verifiability_rationale": "The comment is a request for information ('describe the form of p'). It does not contain a claim that needs to be verified. Therefore, it does not fit the criteria for verifiability.", "helpfulness_rationale": "The comment is a direct request for information. While it points to a potential issue, it does not offer any suggestions or explanations to address the problem. It is a symptom, not a diagnosis or remedy, and therefore not particularly helpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests improvements by pointing out the lack of detail and recommending specific actions like redrawing the figure and connecting text and figure. While the actions are present, the level of detail in the *action* itself could be improved, making it potentially 'Implicit'.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'details of the forwardprediction model' and points to Figure 2(b). This clearly identifies the specific part of the paper being referred to, indicating 'Full Grounding' and 'Specificity'.", "verifiability_rationale": "The reviewer makes a claim about Figure 2(b) not being a schematic and the lack of connection between text, figure, and equations. This claim, if true, lacks the supporting evidence or justification needed to be considered 'Verifiable'. Therefore, it's 'Partially Verifiable' until the figure and its connection are clarified.", "helpfulness_rationale": "The reviewer provides concrete suggestions like 'redrawing Figure 2(b)' and 'connecting the text with the figure and equations'. These are direct and actionable improvements the authors can implement, making the review 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies areas for improvement in baseline methods and suggests a conclusion direction related to reinforcement learning. While it points out weaknesses, it doesn't explicitly state the *specific steps* or *detailed actions* the authors should take to address these weaknesses. The suggestion to discuss the similarity and difference with RL is a general direction rather than a concrete action. Therefore, the action is implied but not explicitly stated, and the actions are not concrete.", "grounding_specificity_rationale": "The review point generally criticizes baseline methods as 'weak' and suggests a conclusion related to 'reinforcement learning.' It does not specify *which* baseline methods are weak or point to a particular section, table, or unique aspect of the paper. The suggestion about RL is a general direction without a clear link to the current work. The authors would need to infer the specific areas of weakness and the relevance to RL, making the grounding weak.", "verifiability_rationale": "The review point makes claims about the weakness of baseline methods and suggests a conclusion direction related to reinforcement learning. However, it does not provide any evidence, reasoning, or references to support these claims within the review itself. It presents opinions without backing, making the claims 1 within the review point.", "helpfulness_rationale": "The review point raises valid concerns about the limitations of the presented work and suggests a relevant direction for future research (i.e., exploring the connection to reinforcement learning). It provides context and highlights areas where the authors' work could be improved. While it doesn't offer specific implementation details, it points out important issues and suggests a meaningful connection to a broader field. Therefore, it provides some context and highlights important areas for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides two suggestions, both of which are concrete and actionable. They directly propose a methodological change (try a specific model with a specific prior) and imply the *how* of the action (try it and see the results).", "grounding_specificity_rationale": "The reviewer mentions relevant terms like 'VGAE' and 'vamp prior,' but doesn't explicitly point to a specific section, table, or unique element in the paper. The suggestions are about the *method* of an experiment, not a specific flaw in a section.", "verifiability_rationale": "The reviewer doesn't present a claim that requires verification. They are suggesting experiments or asking questions, not identifying a specific problem or defect that needs justification.", "helpfulness_rationale": "The reviewer offers two concrete suggestions for improving the work. They propose specific experiments that could help disentangle the effects of the generative model and inference. While not a direct critique, the suggestions are relevant and offer a clear path for future research or analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need for a discussion regarding the balance between longrange dependencies and locality. This constitutes an explicit action. However, the reviewer does not specify the *type* of longrange dependencies or the *specific* aspects of locality they are concerned about, nor does they propose any concrete steps to achieve this discussion. Therefore, while the action is clear, the lack of detail makes it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions '2D image space locality' as a potential issue related to the importance of longrange dependencies. This directly identifies a specific part of the paper (or a concept within it) that is being addressed, making the grounding fully grounded. The comment specifies what needs to be addressed \u2013 the absence of 2D locality \u2013 making it also specific.", "verifiability_rationale": "The reviewer expresses a 'suspicion' that the absence of 2D locality might lead to predictions depending on image size. This is a claim that could be verified by designing experiments to test the model's behavior with and without explicit locality constraints. While the claim is based on a potential consequence rather than a direct observation, the *potential area of investigation* is clear, making it 3. There is no external reference provided to support this suspicion.", "helpfulness_rationale": "The reviewer desires a discussion about the balance between longrange dependencies and locality. This is a clear and actionable suggestion that directly addresses a potential area for improvement in the paper. The reviewer is asking the authors to consider a specific aspect of their model or method, which is a valuable contribution. Therefore, this comment is 5 as it directly prompts the authors to engage with a specific aspect of their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for the definition of $e_l$ in Eq. (3), which is a direct and actionable request. It also points out a potential weakness in the theoretical results (exponential dependence on the diameter $M$) and asks clarifying questions about the implications. The reviewer suggests investigating the cause of the weakness, indicating a clear direction for improvement.", "grounding_specificity_rationale": "The review point mentions the diameter $M$ and its impact on the results, indicating some understanding of the issue. However, it doesn't explicitly state the section or subsection where the definition of $e_l$ is (or isn't) present. It also doesn't directly pinpoint the exact location of the corollaries and theorems. While it implies the relevance of $M$ to the corollaries and theorems, it doesn't explicitly state that it's referring to those specific sections. Therefore, while the reviewer identifies the *type* of issue, the grounding of the specific section is weak.", "verifiability_rationale": "The review point contains claims about the missing definition of $e_l$ and the exponential dependence on $M$. It also provides a clear explanation of the potential negative consequences of this dependence. While it doesn't provide a specific example of how this affects performance in *that* instance, it clearly states the *general* impact (performance getting worse, constant factor). The reviewer also suggests a potential cause (weakness of the theoretical results). This level of explanation supports the claim, making it 3.", "helpfulness_rationale": "The review point is 5. It directly points out a missing definition, which is a concrete action the authors can take. It also highlights a significant theoretical limitation with potentially negative consequences for the performance. The reviewer's suggestion to investigate the cause of the weakness is also a valuable direction for improvement. The information provided is actionable and addresses specific areas for the authors to focus."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a question about a phenomenon they observed or encountered, which implies an implicit action: 'Did you observe this?' However, the review does not provide any guidance on what the authors should do next or how to address this potential issue. The action is implied but not explicitly stated or concrete.", "grounding_specificity_rationale": "The reviewer refers to 'your model' and 'line 159' in their review point. This indicates some level of grounding as they are referencing a specific aspect of the authors' work. However, the question is general and asks about the possibility of model collapse in general, rather than specifically addressing a particular part of the model or a specific issue detailed in line 159. The grounding is present but not fully specific to a particular element of the authors' work.", "verifiability_rationale": "The reviewer poses a question about a phenomenon they observed or encountered, which can be considered a claim: 'Did you observe this phenomenon?' This claim is supported by the mention of line 159 and the experimental nature of the work. The connection to the authors' work is clear, and the context suggests it's a relevant observation. The claim is not explicitly stated as a fact but is implied through the reviewer's question and the context of the paper.", "helpfulness_rationale": "The reviewer's review point raises a relevant question about a potential issue (model collapse) and asks about its frequency and observation. This is helpful as it seeks to understand a potential limitation or behavior of the model. While it doesn't directly suggest a solution, it contributes to a better understanding of the model's performance and potential areas for improvement. The questions are pertinent to the authors' work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests including a specific method (linear scalarization + Concorde) in the comparison of solvers. This provides a clear action for the authors to take to improve their work. The suggestion is direct and actionable, indicating a clear understanding of how to address the observed performance differences between learningbased and heuristicbased solvers.", "grounding_specificity_rationale": "The reviewer identifies the issue with the current heuristicbased solver comparison by specifically mentioning the 'SOTA heuristicsolver (e.g., Concorde)' and its typically strong performance on singleobjective TSP. This clearly pinpoints the area of concern and the specific example of a strong heuristic solver. The reviewer also refers to the 'single objective TSP' which helps in localizing the problem.", "verifiability_rationale": "The reviewer makes a claim about the performance of Concorde, a wellknown heuristic solver, for singleobjective TSP. While the paper itself might not explicitly state this, it is a generally accepted piece of knowledge within the optimization community. The reviewer provides a clear statement of what is expected (Concorde's strong performance) and suggests a way to address a potential weakness in the current comparison (including it in the evaluation).", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improving the comparison of solvers. By recommending the inclusion of linear scalarization + Concorde, the reviewer directly points the authors towards a specific and relevant baseline to consider. This suggestion is constructive and addresses a potential gap in the current evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "2: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point states 'It would be helpful if you provided glosses in Figure 2.' This indicates an explicit action: adding glosses. However, it does not specify the method or steps to achieve this. The action is implied but not fully detailed.", "grounding_specificity_rationale": "The review point explicitly refers to 'Figure 2', which is a specific part of the paper. This allows the authors to accurately identify the section being addressed.", "verifiability_rationale": "The review point is a suggestion, not a claim that something is wrong or needs fixing. It does not present any logical reasoning, common knowledge, or external references. It's a helpful suggestion, but not a claim requiring verification.", "helpfulness_rationale": "The review point directly points to a specific area for improvement (Figure 2) and suggests a concrete action (adding glosses). While it doesn't provide detailed steps on how to add the glosses, it clearly identifies a actionable area for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment poses a question about a design choice (finer grouping vs. pertensor/perchannel) but does not explicitly state what the authors should do next. It lacks a clear action or instruction.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper or the current draft that it is addressing. It is a general question about a design choice.", "verifiability_rationale": "The comment does not make a claim that requires verification. It is a question, not a statement of what needs to be proven.", "helpfulness_rationale": "The comment raises a valid point about a potential improvement in quantization strategy but does not provide any justification or suggestions for why the authors should consider finer grouping. It is a question without a clear answer or recommendation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking for a definition of 'active vertices,' which is not present in the sentence. While the sentence implies the concept is relevant to sparsity, it doesn't explicitly state what 'active vertices' means. The reviewer is inferring the need for this information, making it implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'line 135,' indicating they have located the relevant context. This provides a strong grounding for their request. They are asking for a definition of a specific term within that context.", "verifiability_rationale": "The original text does not contain a claim about 'active vertices.' It simply states that the network initially has a few of them due to sparsity. The reviewer's request for a definition is a request for information, not a claim that needs verification.", "helpfulness_rationale": "The reviewer is asking for a definition to understand a specific sentence in the paper. This is a direct request for clarification that is directly relevant to the content. Providing the definition would directly address the reviewer's need and improve their understanding of the initial network state described in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out two main issues: the lack of acknowledgment of the theory's inapplicability to the model and the underestimation of GNNs' societal impact. While the reviewer doesn't explicitly tell the authors what to do, they clearly identify areas where the authors should improve. The reviewer suggests the authors acknowledge the limitation and discuss societal impact, which are actionable suggestions. However, the reviewer doesn't specify *how* the authors should go about this, making it somewhat implicit.", "grounding_specificity_rationale": "The reviewer makes general comments about the paper's limitations and the broader societal impact of GNNs. They do not explicitly refer to a specific section, table, figure, or unique element of the paper. The reviewer's comments are about the general content and implications, not a specific detail within the paper.", "verifiability_rationale": "The reviewer makes claims about the paper's content, specifically stating that the limitation of the theory is not mentioned and that the assumptions are vague. These claims are verifiable by examining the paper's limitations section and the appendix. However, the reviewer also expresses an opinion about the underestimation of GNNs' use in industry, which is not directly verifiable. The suggestions for improvement, like elaborating on societal impact, are not specific claims but rather recommendations.", "helpfulness_rationale": "The reviewer's comments highlight significant shortcomings in the paper's presentation and omissions. They point out missing acknowledgments and lack of detail in the appendix, as well as the underestimation of GNNs' societal impact. These are not direct instructions for the authors on what to do, but rather criticisms of the paper's content and structure that could hinder its reception and impact. The reviewer's point is about improving the paper, which is helpful for the authors in understanding where the paper is lacking."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their opinion that the discussion section needs more clarity. This is a clear indication of an actionable point, as it directly points to an area where improvement is needed. However, the criticism lacks specificity about *which* part of the discussion requires clarification.", "grounding_specificity_rationale": "The reviewer mentions the 'discussion' section as the relevant part of the paper where the weakness lies. This provides a clear grounding of the issue. Furthermore, the reviewer specifies the nature of the weakness: 'which part is vital for using CLIP to guide weakly supervised learning' and 'the discussion is necessary (but I didn\u2019t find clear answer in the discussion)'. This level of detail indicates a high degree of specificity about the problem.", "verifiability_rationale": "The reviewer makes a claim that the discussion section needs more clarity. This claim is supported by the logical reasoning that improved clarity would help distinguish this work from related work. While the reviewer doesn't provide specific examples or external references to support this claim, the logical connection between clarity and differentiation is evident.", "helpfulness_rationale": "The reviewer clearly states the importance of the discussion section for distinguishing their work from related work. This highlights the value of the feedback. However, the review point itself does not offer any specific suggestions or actions for the authors to take based on this criticism. It identifies a gap but doesn't provide concrete steps to address it."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the weakness of the analogy between the paper's approach and HOI analysis and Harmonic analysis. They identify specific areas where the analogy is weak, such as the limited number of 'basis' in the paper's context and the disconnect between the decomposition/integration steps and Fourier analysis. This indicates a clear and actionable critique.", "grounding_specificity_rationale": "The reviewer refers to 'HOI analysis' and 'Harmonic analysis,' which are established concepts. However, they do not explicitly identify a specific part of the paper being reviewed where this analogy is discussed. While the reviewer implies familiarity with these concepts, the connection to a specific section, table, or unique aspect of the *reviewed paper* is not made. Therefore, the grounding is weak. The reviewer clearly specifies what they are criticizing, but the connection to the *reviewed paper* itself is not explicit.", "verifiability_rationale": "The reviewer makes claims about the weakness of the analogy to HOI and Harmonic analysis. However, they do not provide specific examples or references from the *reviewed paper* to support these claims. The reviewer's statements are based on their interpretation of the paper's content and the established concepts of HOI and Harmonic analysis. While the claims are stated, they are not verifiably supported by evidence *within the reviewed paper*.", "helpfulness_rationale": "The reviewer's point is that the analogy between the paper's approach and HOI analysis and Harmonic analysis is 'weak.' While this is a valid critique, the reviewer does not offer specific suggestions or improvements for the paper being reviewed. The feedback is primarily a diagnosis of a flaw rather than a prescription for improvement. Therefore, the feedback is not particularly helpful for the authors in terms of actionable steps."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue with Figure 8 and asks a direct question about a specific aspect (generalization to unseen focusing distances). This makes it **Explicit**. The reviewer clearly identifies the *specific* issue with Figure 8 and asks a direct question about a specific aspect (generalization to unseen focusing distances). This makes it **Explicit**. Once the action is identified (examine Figure 8), the authors know exactly what needs to be done and how to apply the action (consider the limitations of the shown focusing distances and the generalization to unseen distances). This makes it **Concrete**. The reviewer is directing the authors to take action by pointing out a limitation in the figure and asking a specific question about a potential improvement. This is **Actionable**.", "grounding_specificity_rationale": "The reviewer *mentions* Figure 8. However, they don't explicitly *identify* the specific part of the paper being addressed. They are referring to a figure in the appendix (implied by \"fig 8\"). Therefore, the grounding is **Weak**. The reviewer *mentions* Figure 8. However, they don't explicitly *identify* the specific part of the paper being addressed. They are referring to a figure in the appendix (implied by \"fig 8\"). Therefore, the grounding is **Weak**. The reviewer *mentions* Figure 8. However, they don't explicitly *identify* the specific part of the paper being addressed. They are referring to a figure in the appendix (implied by \"fig 8\"). Therefore, the grounding is **Weak**.", "verifiability_rationale": "The reviewer makes a statement and asks a question. The statement \"fig 8 shows images with different focusing distance, but it only shows 1m and 5m, which both exist in the training data\" can be considered a claim about a discrepancy. The question \"How about focusing distance other than those appeared in training? does it generalize well?\" also points to a claim (that the model *should* generalize). However, the reviewer doesn't provide any external references or logical reasoning to *support* their claim about the content of Figure 8. They are stating an observation based on their understanding of the figure. Therefore, the verifiability is **Low**. The reviewer makes a statement and asks a question. The statement \"fig 8 shows images with different focusing distance, but it only shows 1m and 5m, which both exist in the training data\" can be considered a claim about a discrepancy. The question \"How about focusing distance other than those appeared in training? does it generalize well?\" also points to a claim (that the model *should* generalize). However, the reviewer doesn't provide any external references or logical reasoning to *support* their claim about the content of Figure 8. They are stating an observation based on their understanding of the figure. Therefore, the verifiability is **Low**. The reviewer makes a statement and asks a question. The statement \"fig 8 shows images with different focusing distance, but it only shows 1m and 5m, which both exist in the training data\" can be considered a discrepancy. The question \"How about focusing distance other than those appeared in training? does it generalize well?\" also points to a claim (that the model *should* generalize). However, the reviewer doesn't provide any external references or logical reasoning to *support* their claim about the content of Figure 8. They are stating an observation based on their understanding of the figure. Therefore, the verifiability is **Low**.", "helpfulness_rationale": "The reviewer is pointing out a limitation in the experimental setup (Figure 8) and raising a valid question about the model's generalization capabilities. This highlights a potential area for improvement in the paper's presentation and discussion. While it doesn't directly tell the authors *how* to fix the issue, it encourages them to consider the limitations of their experiments and the generalizability of their findings. This is relevant to the authors who likely created or reviewed the paper. It encourages them to think critically about the experimental design and the generalizability of their findings. This is relevant to the authors who likely created or reviewed the paper. It encourages them to think critically about the experimental design and the generalizability of their findings. This is relevant to the authors who likely created or reviewed the paper. It encourages them to think critically about the experimental design and the generalizability of their findings. This is relevant to the authors who likely created or reviewed the paper. It encourages them to think critically about the experimental design and the generalizability of their findings."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification and suggesting a different perspective on the authors' framing of 'content' and 'style'. While this doesn't directly tell the authors what to do, it prompts them to consider a broader conceptual question. The action is implicit in the reviewer's suggestion, but it's not explicitly stated as an action to be taken by the authors. Therefore, it's not fully actionable.", "grounding_specificity_rationale": "The reviewer is broadening the discussion to include 'content' and 'style' in a more general sense, relating it to a specific neural application. They are not pinpointing a specific section, table, or unique element within the paper that they believe needs addressing. The grounding is at a higher level of abstraction, not a specific part of the paper. Therefore, it's 1 at all.", "verifiability_rationale": "The reviewer is raising a conceptual point about the authors' framing of 'content' and 'style' and suggesting an alternative perspective. They are not explicitly stating a claim that requires verification. The suggestion is more of an encouragement for the authors to think differently rather than a statement that needs to be proven. Therefore, it's not verifiable.", "helpfulness_rationale": "The reviewer is offering a different perspective and suggesting a way to improve the authors' understanding of 'style' in their specific neural application. This is a valuable suggestion that could help the authors refine their conceptual framework. While it doesn't directly tell them what to do, it provides a direction for their thinking. Therefore, it is 3 as it encourages them to consider a different approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues with the paper's claims regarding the variance difference in MHSA quantization and the precision loss, and they identify specific areas within the paper where these issues are discussed (e.g., Line 45, Fig1(b), Fig5(b), Block.3, MHSA, ViT model). The reviewer also suggests improvements by highlighting these weaknesses, making the action clear and direct.", "grounding_specificity_rationale": "The reviewer accurately identifies the specific parts of the paper being discussed, such as 'vit quantification,' 'Line 45,' 'Fig1(b),' 'Fig5(b),' 'Block.3,' 'MHSA,' and 'ViT model.' This demonstrates a high level of grounding specificity as the reviewer can confidently pinpoint the referenced sections and elements.", "verifiability_rationale": "The reviewer provides specific references to figures and numerical values (e.g., '1.2268 in Fig1(b) vs. 1.3672 in Fig5(b) for Block.3') to support their claims about the variance difference and the precision loss. While they don't explicitly cite external literature, their mention of other quantization papers (QBERT, Q8BERT, etc.) suggests an awareness of the broader context. The reviewer's statements are logical and based on observable data, making the claim fully supported.", "helpfulness_rationale": "The reviewer provides a clear and actionable feedback, highlighting specific areas where the paper's claims and proposed method are potentially flawed. They provide numerical evidence to support their criticisms, making the feedback concrete and verifiable. The reviewer's suggestions for improvement are directly linked to the identified weaknesses, making the feedback 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the similarity of the proposed method to STNs and the lack of comparison. It also mentions specific existing works that use STNs locally (neighborhood STNs, PointNet). This provides a clear direction for the authors to investigate the relationship between their method and existing STN approaches. The reviewer identifies a potential weakness and suggests a necessary step for improvement (adding comparisons).", "grounding_specificity_rationale": "The reviewer explicitly mentions the similarity to STNs and the lack of comparison, which are concrete actions or suggestions that can be directly identified by the authors. They also provide examples of related work (neighborhood STNs, PointNet), which helps the authors understand the context and identify the potential overlap. The reviewer clearly specifies the issue (lack of novelty and comparisons) and provides examples of related work, making the grounding and specificity high.", "verifiability_rationale": "The comment contains a claim (the limitation in technical novelty and the absence of comparisons) but does not provide specific evidence or justification within this review point to support this claim. While the reviewer identifies a potential weakness and suggests a necessary improvement, they do not logically reason, provide examples, or cite external references to back up their assertion about the similarity to STNs and the missing comparisons. The claim is stated, but the supporting evidence is missing within this review point.", "helpfulness_rationale": "The comment provides a clear criticism of the technical novelty and points out a specific area for improvement (the lack of comparison to STNs). It suggests that the authors should consider adding comparisons to existing STN methods. While the reviewer does not provide specific evidence *within this review point* to *support* their claim about the similarity and missing comparisons, the suggestion to add comparisons is a constructive and actionable feedback for the authors. The reviewer identifies a potential weakness and guides the authors towards a necessary improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks two questions: 'Where does the reward come from at each trial?' and 'Is one of the r_i taken from Eq. 11?'. These are direct requests for clarification and specify the exact location of the potential issue (Eq. 12 and 11). The suggestion to explain the network model with equations is also a direct instruction for improvement. The reviewer is pointing out a lack of clarity and requesting specific details, making the action explicit and concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Eq. 12' and 'Eq. 11' as the source of confusion. They also refer to 'the network model in Sec. 4.2'. These are precise references to specific parts of the paper, indicating a strong grounding. The reviewer is not just stating a general problem but pinpointing the exact equations and sections where clarification is needed. The request to explain the network model with equations further emphasizes the specific nature of the concern.", "verifiability_rationale": "The reviewer is making a suggestion for improvement by asking for clarification on the origin of the reward and the details of the network model. While not a definitive statement requiring proof, the reviewer is prompting the authors to provide more information and justification for their choices. The request to explain the network model with equations implies a belief in the value of their work and encourages them to provide supporting details. Therefore, while not 5, it is verifiable in the sense that it encourages the authors to provide evidence or justification.", "helpfulness_rationale": "The review point directly addresses potential points of confusion for the authors by asking specific questions about the origin of the reward and the implementation of the network model. The suggestions are actionable and directly aim to improve the authors' understanding and the clarity of their work. The reviewer is likely to be helpful in guiding the authors to provide more detailed explanations and justifications, which can lead to significant improvements in their work. The request to explain the network model with equations is particularly likely to be helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the incorrect figure number (Fig.7 instead of Fig.12) and suggests a specific improvement (linking proofs to theorems/corollaries). This is a clear indication of an actionable point. The reviewer directly tells the authors what needs to be fixed and how. The suggestion about proofs is also explicit, stating that each theorem/corollary should have a linked proof. This provides a clear direction for the authors to follow.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'each theorem and corollary appearing in the main paper.' This clearly identifies the specific elements in the paper that need attention. The reviewer is not making a general comment but rather focusing on a specific type of element. The reviewer then further specifies the desired action: 'attach its corresponding proof link'. This adds further specificity to the grounding by detailing the required action.", "verifiability_rationale": "The reviewer points out a factual error ('Fig.7' should be 'Fig.12'). This claim is likely verifiable by the authors through direct inspection of the paper. The reviewer also makes a suggestion ('each theorem and corollary appearing in the main paper should be attached to its corresponding proof link'). While this is a suggestion and not a claim requiring verification in the same way as the figure error, the *factuality* of the error is verifiable. The reviewer's statement is clear and directly points to an issue that can be confirmed or refuted.", "helpfulness_rationale": "The reviewer provides two specific pieces of feedback: correcting a factual error and suggesting a way to improve the paper's structure by linking proofs. Both of these are actionable and directly address potential weaknesses in the paper. The suggestion to link proofs is particularly helpful as it improves the accessibility and clarity of the theoretical contributions. The reviewer's comments are clear, concise, and immediately actionable for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies specific areas (Section 3 and 3.306ff) where the authors are making choices that could be improved. It points out that the selection of action verbs lacks a determiner and that the choice of 'action frames' is unclear. While it highlights potential issues, it doesn't explicitly state what the authors *should* do to address these. The action is implied (improve verb selection, clarify action frames), but the guidance on *how* is missing.", "grounding_specificity_rationale": "The review point explicitly refers to 'Section 3' and 'Section 3.306ff', which are specific parts of the paper. It then further specifies the issues within these sections: 'determiner missing', 'Section 3 \"Action verbs\"', 'which 50 classes do you pick', and 'Are the verbs that you pick all explicitly tagged as action verbs by Levin?'. This precise identification of the location and the specific problem within it demonstrates strong grounding specificity.", "verifiability_rationale": "The review point makes a claim about the authors' current approach to selecting action verbs and action frames, stating that it lacks a determiner and is unclear. It references specific sections of the paper (3 and 3.306ff) to support this claim. However, it does not provide specific examples of *what* is missing or *how* the authors should improve their selection process. The claim is present, but the supporting evidence is somewhat vague.", "helpfulness_rationale": "The review point critiques the authors' methodology for selecting action verbs and action frames, pointing out potential issues. While it identifies areas for improvement, it does not offer concrete, actionable steps for the authors to take. It's a critique of their process rather than a direct prescription for improvement. The reviewer identifies a problem but doesn't provide a solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the issue ('Ln 32 on Page 1, \u2018Empiically\u2019 should be \u2018Empirically\u2019') and provides a clear action: correcting the spelling. The action is concrete, specifying the line number and the correct spelling.", "grounding_specificity_rationale": "The reviewer accurately identifies the specific line number ('Ln 32 on Page 1') and provides clear instructions on what to do ('\u2018Empiically\u2019 should be \u2018Empirically\u2019'). This demonstrates full grounding as the section and table are accurately identified, and full specificity as the issue and the solution are clearly stated.", "verifiability_rationale": "The comment does not contain a claim. It is a factual correction. Therefore, it does not have verifiability as it lacks a statement that needs to be supported.", "helpfulness_rationale": "While the reviewer points out a specific error, the helpfulness is limited. The suggestion is very narrow and doesn't address broader issues or offer significant guidance. It's a very specific fix and doesn't provide much value for the authors beyond this minor correction."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation or a lack of clarity regarding Figure 3 of INs. While they identify a potential issue, they do not explicitly state what needs to be done or how to address it. The reviewer is pointing out a *potential* area for improvement, but doesn't offer a concrete solution.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 3 of INs' in their review point. This indicates a clear identification of a specific part of the paper (or external work) being addressed. However, the reviewer does not specify *what* is unclear or problematic about this figure. The grounding is present, but it's not fully specific to the referenced part of their own paper.", "verifiability_rationale": "The reviewer states that 'the number of entities is fixed and it's not clear how to generalize a model to different numbers of entities (e.g., as shown in figure 3 of INs)'. This constitutes a claim (the statement about generalization clarity). However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The justification for why the generalization is unclear is missing.", "helpfulness_rationale": "The reviewer points out a limitation or a lack of clarity regarding Figure 3 of INs. While this is relevant to the author's work, it doesn't directly provide actionable feedback on how to improve their draft. The reviewer is highlighting a *potential* issue, but not a concrete solution or improvement strategy."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a problem (lack of novelty) but does not provide specific instructions on how to address it. It's a diagnosis, not a prescription for improvement. The authors are left to figure out what changes are needed based on this feedback alone.", "grounding_specificity_rationale": "The comment is about the 'novelty of the idea' and the 'new metric and method' in general, not a specific section, table, figure, or element. It lacks specificity about where the issue lies within the paper.", "verifiability_rationale": "The comment is a subjective judgment ('The novelty of the idea is not enough') and does not contain a claim that requires verification or justification. It's an opinion about the overall contribution, not a factual statement needing support.", "helpfulness_rationale": "The comment identifies a potential weakness (lack of novelty) but offers no concrete steps or actionable advice for the authors to improve their work. It's a critique without constructive suggestions or guidance on how to address the identified issue."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment states the issue (framing oversells the method) but does not provide explicit instructions on how to address it. It is a general observation rather than a directive action.", "grounding_specificity_rationale": "The comment refers to the 'framing of the paper' and the 'method' in a general way, without specifying a particular section, table, figure, or detail that is problematic. It lacks specific references to parts of the paper.", "verifiability_rationale": "The review point is more of an opinion or suggestion rather than a claim that can be directly verified. It does not present a definitive statement that can be proven or disproven with evidence.", "helpfulness_rationale": "The review point identifies a potential issue (overselling the method) but does not offer specific, actionable steps or examples to address it. It is a valuable observation but lacks the detailed guidance needed for constructive improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review points out two main areas for improvement: the generative process and the notation. While the suggestions are relevant, they are not explicit or concrete. For the generative process, the reviewer suggests presenting it in 'separate steps,' but doesn't specify which steps are missing or how they should be presented. For the notation, the reviewer suggests 'too many symbols and a notation table could be better,' but doesn't specify which symbols are problematic or why the current table is insufficient. The authors still need to infer the necessary actions and details from the reviewer's suggestions.", "grounding_specificity_rationale": "The review does not specify which part of the model description is unclear. The reviewer offers general suggestions, such as 'presenting such process in separate steps' and 'too many symbols and a notation table could be better.' Without identifying a specific section, table, figure, or unique aspect, the grounding is weak. The suggestions are also not specific, making it difficult for the authors to understand what needs to be improved.", "verifiability_rationale": "The review makes two claims: 1) the generative process is 'in detail' but 'presenting such process in separate steps should be better for understanding,' and 2) 'too many symbols and a notation table could be better.' While the reviewer claims the original description was unclear, they do not provide specific examples or references to support these claims. The suggestions are based on a general assessment of clarity and organization, lacking concrete evidence or logical reasoning to back them up.", "helpfulness_rationale": "The review suggests improvements to the clarity and organization of the model description. Specifically, the reviewer suggests presenting the generative process in 'separate steps' and improving the 'notation' by potentially using a 'notation table.' These suggestions are directly relevant to the model description and are likely to be helpful for the authors in understanding and improving their work. While the suggestions are not perfectly specific, they point towards actionable improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests 'improving the paper' and provides specific examples like 'identifying rationales is not a simple problem.' This indicates an explicit intention to guide the authors towards better work. However, the suggestions are general and lack specific guidance on *how* to achieve these improvements. The reviewer doesn't specify concrete steps or actions the authors should take. While the intent is clear, the lack of actionable steps makes it less actionable.", "grounding_specificity_rationale": "The reviewer mentions 'rationales' as an example of a difficult problem, which can be considered an explicit statement. However, the reviewer does not specify *which* rationales are being referred to, nor does the comment pinpoint the exact location (e.g., specific sections, tables, figures) where these rationales are discussed. The mention is general, and the comment doesn't detail what needs to be addressed within this part. Therefore, while the action (identifying rationales) is implied, the grounding (identifying the specific part) is not explicit.", "verifiability_rationale": "The reviewer makes a statement about the difficulty of identifying rationales in machine translation, which can be considered a claim. They also point out that 'Figure 2 is a bit cluttered and the \"bold\" text is hard to see.' This provides some justification for the claim. However, the reviewer does not provide a citation or external reference to support this observation about the difficulty of identifying rationales in machine translation. The support is present but not strong enough to be considered 5.", "helpfulness_rationale": "The reviewer provides a critique of a specific NLP task (rationale identification in machine translation) and points out a potential issue with Figure 2. While this offers some insight and identifies a problem, it does not directly suggest concrete, actionable improvements for the authors' current draft. The reviewer's comment is more of a general observation and a suggestion for improvement in the visualization rather than specific guidance on how to improve the authors' paper. Therefore, it is not 5 in terms of directly addressing the authors' specific needs."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "X", "actionability_rationale": "The reviewer explicitly states the potential issue (FlippedQA is general but only applied to LLMs) and suggests an action (verify on nonLLMs). However, the action lacks specific details on how to perform the verification.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'FlippedQA framework' and 'LLMs' and suggests testing on 'nonLLMbased models like HiTeA and InternVideo'. This is very specific.", "verifiability_rationale": "The reviewer states 'I believe the FlippedQA is a general framework for various generative VideoQA models. However, the authors only apply this framework to LLMbased models. It would be better to further verify the effectiveness and universality to nonLLMbased models like HiTeA and InternVideo.' This is a claim without supporting evidence or examples.", "helpfulness_rationale": "The reviewer's comment is about a potential improvement to the authors' work (broader evaluation) but doesn't explicitly state whether this comment is helpful or not."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states a weakness ('it doesn't present significant theoretical novelty') but doesn't provide specific actionable steps on how to address it. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer explicitly names the specific methods and provides citations, clearly pinpointing the relevant aspects of the proposed method.", "verifiability_rationale": "The reviewer makes a claim about the method being a combination of existing methods and lacking theoretical novelty, but provides no evidence or reasoning to support these claims.", "helpfulness_rationale": "The reviewer expresses a desire for improvement but doesn't provide specific feedback or actionable steps for the authors. The comment is about the authors' future work, not the current review's value."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment raises a question about a potential issue with text input but does not explicitly state the problem or provide concrete steps for the authors to take. While it implies a concern, it lacks the explicitness and concreteness required for high actionability.", "grounding_specificity_rationale": "The comment is 1 in a specific part of the paper or code. It refers to 'text input' generally, without specifying which text elements, object, or potential problem is being discussed. Therefore, it cannot be considered grounded at all.", "verifiability_rationale": "The comment does not contain a clear claim or assertion that can be verified. It's a question posed to the authors, implying a potential issue but not stating it explicitly or providing any justification or references. Therefore, it is 1.", "helpfulness_rationale": "The comment raises a valid point about a potential issue with text input, which could be helpful for the authors to be aware of. However, it lacks specific details and justification, making it only 3. It encourages the authors to doublecheck their code or documentation but doesn't provide concrete guidance on what to do."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the suggestion to clarify the sentence and provides a clear method for achieving this. The action is explicitly stated and concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'lines 1217' in the abstract, providing a clear and accurate grounding. The specificity is high as the exact location and the nature of the issue are described.", "verifiability_rationale": "The reviewer identifies a weakness ('cumbersome and can be made clearer') in the sentence. However, the reviewer does not provide specific evidence or references to support this claim. The suggestion to 'clarify' is a general instruction without further details on how to do so.", "helpfulness_rationale": "The reviewer provides a suggestion for improvement ('clarify'). While the suggestion is general, it directly addresses a weakness identified in the abstract and empowers the authors to take action to improve their draft. The suggestion is directly related to the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the proposed approach does not outperform or is even worse than Decouple Kang et al. for the overall performance. This is a clear indication of an explicit action or suggestion. However, the reviewer does not specify *how* the proposed approach is worse or *where* the improvement could be made. Therefore, while the action is explicit, the lack of detail makes it vague.", "grounding_specificity_rationale": "The reviewer mentions 'Decouple Kang et al.' and 'hyperparameters' as potential areas for improvement. While they mention a specific baseline, they do not explicitly identify the unique section, table, figure, or aspect of their proposed method that is being compared to Decouple. The mention of 'hyperparameters' is also general and doesn't pinpoint a specific part. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer states that 'Also, Table 5 shows the tradeoff between head and tail categories. But similar tradeoff has not been fully investigated for the baselines; for example, by changing the hyperparameters in Decouple Kang et al., Decouple Kang et al. could also significantly improve the tail accuracy while slightly decreasing the head accuracy.' This statement presents a claim about the potential of Decouple. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as an assertion without evidence. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer points out a limitation of the proposed approach (not outperforming Decouple) and suggests a potential improvement for the baselines. While these points are relevant and highlight areas for future work, they do not directly provide actionable feedback on how to improve the *current* proposed approach. Therefore, the helpfulness is somewhat limited to pointing out future directions rather than offering immediate improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking for explanations and justifications for specific choices made in the E2W algorithm. These are direct requests for clarification, which are explicit actions. The reviewer is also asking for concrete examples or further details to understand these choices, making the actions somewhat concrete. The reviewer is not inferring actions but directly stating their need for clarification.", "grounding_specificity_rationale": "The reviewer is asking about specific components of the E2W algorithm (lambda_t, epsilon, and the exploration parameter in Equation 7). While they don't explicitly state 'Section 3.2' or 'Algorithm 1', they are referring to specific parts of the algorithm's description. This can be considered weak grounding because the information is implicitly present in the text, but not explicitly labeled or pointed to. The questions are about specific parameters within the description, not about a general section or table.", "verifiability_rationale": "The reviewer is making claims about the algorithm's design choices (e.g., the intuition behind lambda_t, the necessity of epsilon, and the use of the sum in Equation 7). These claims are not supported by explicit references to external works or logical reasoning within the review point itself. The reviewer is stating their lack of understanding, which can be considered a verifiable claim as it points to a gap in the explanation. However, the verifiability is limited as the reviewer is not providing evidence to support their claims, but rather asking for clarification.", "helpfulness_rationale": "The reviewer is asking questions that, if answered, would significantly improve the authors' understanding of the E2W algorithm. These are direct requests for information that would directly address a potential weakness or area of confusion for the authors. The questions are actionable and would provide valuable insights into the algorithm's design choices. The reviewer is not making a judgment about the algorithm's overall quality, but rather asking for specific details to clarify certain aspects."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'relying on 4 OCR QA datasets' and 'more scenarios like the LLaVA benchmark.' These are direct suggestions for improvement, making them concrete actions. The reviewer also implies a desire to explore alternative evaluation methods, which is a clear action to take.", "grounding_specificity_rationale": "The reviewer mentions '4 OCR QA datasets' and 'LLaVA benchmark.' While they don't explicitly state 'the section discussing evaluation methods,' the mention of specific datasets strongly implies they are referring to that section. The reviewer also specifies 'datasets' and 'benchmarks,' adding to the specificity within the likely context. However, the lack of a direct reference point makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer makes a claim: 'The evaluation is limited...'. This claim is supported by logical reasoning: 'mostly relying on 4 OCR QA datasets... this evaluation may be unreliable... More scenarios like the LLaVA benchmark would be expected...'. These statements provide evidence and suggest a connection to external knowledge (benchmark availability).", "helpfulness_rationale": "The reviewer identifies a potential limitation in the evaluation methodology ('The evaluation is limited...'). They offer a specific suggestion for improvement by mentioning 'more scenarios like the LLaVA benchmark.' This suggests a desire to explore alternative evaluation methods, which is a constructive and actionable suggestion for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two explicit suggestions for improvement. First, they suggest a specific notation for the policy function, which is a clear and actionable change. Second, they point out a potential issue with the dimensions in equation (2) due to the removal of the noop action and suggest a concrete solution. Both suggestions are directly tied to the identified problem and provide a clear path for the authors to follow.", "grounding_specificity_rationale": "The reviewer explicitly identifies the location of the issue in 'equation (2)' and provides a specific suggestion for how to address it by modifying the notation of the policy function. This demonstrates strong grounding specificity as the reviewer not only locates the problem but also proposes a concrete solution based on the identified part of the paper.", "verifiability_rationale": "The reviewer makes a claim about a potential issue with the objective function formulation and the dimensions in equation (2). They provide a logical reasoning for this claim by explaining the dimensional mismatch resulting from the removal of the noop action. While they don't provide external references, the mathematical reasoning is sound and verifiable within the context of the paper. The reviewer's suggestion to assume the first column of X_t is always 0 is a proposed solution based on their analysis.", "helpfulness_rationale": "The reviewer's comments are 5. They directly address a potential ambiguity in the notation and a potential error in the objective function formulation. The suggestions are concrete and actionable, providing the authors with a clear direction for improvement. The reviewer's focus on resolving a potential issue and offering a solution makes their feedback constructive and valuable."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states concrete actions: \"Weak supervision could be better evaluated\" and \"The generation of authors is also not realistic\". These are clear suggestions for improvement. The reviewer also implies a lack of clarity in the current methods, which is actionable.", "grounding_specificity_rationale": "The review point mentions \"weak supervision\" and \"weakly supervised learning\" interchangeably, and refers to \"the generation of authors\" and \"author embeddings\". While the reviewer understands the concepts, the connection between these terms and the specific issues isn't explicitly stated. The reviewer is generally pointing towards these areas but doesn't pinpoint a specific section, table, or unique element being addressed. The general comments about realism and the specific example of averaging embeddings are mentioned, but the exact location of this issue isn't clearly identified.", "verifiability_rationale": "The review point contains claims: \"Weak supervision could be better evaluated\" and \"The generation of authors is also not realistic\". While these are suggestions for improvement, they don't directly verify or refute the current methods. The reviewer is offering alternative approaches and constructive feedback rather than providing a critique or a clear justification for the current state. The suggestions are relevant but don't inherently 'prove' or 'disprove' the existing techniques.", "helpfulness_rationale": "The review point directly points out two specific areas for improvement in the paper's methodology: the evaluation of weak supervision and the generation of authors. The suggestions are actionable and provide clear directions for the authors to enhance their work. The reviewer's comments are directly linked to the methodology described in the paper, making them highly relevant. The suggestions are concrete and provide clear improvement paths."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a comparison with a specific existing model, which constitutes an explicit action. The reviewer also implies that this comparison will be helpful given the importance of ternary potential, providing a clear direction for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific paper 'Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16)' as a point of comparison, providing a clear and accurate reference point. The reviewer also mentions 'ternary potential' as a key factor, which is a specific aspect of the proposed model.", "verifiability_rationale": "The reviewer suggests a comparison with a specific model, which can be considered a claim. While the reviewer doesn't provide explicit justification for *why* this comparison will be informative, the suggestion itself is a verifiable action. The grounding is explicit, and the specificity is in the model and the ternary potential.", "helpfulness_rationale": "The review point directly suggests a concrete action for the authors \u2013 comparing their model with a specific existing model. This directly addresses a potential weakness (the importance of ternary potential) and provides a clear direction for improvement. The suggestion is specific and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The reviewer is posing a question about the number of discourse relations, which implies an expectation of a certain type of labeling. While the reviewer doesn't explicitly state an action to be taken, the question itself can be interpreted as a request for clarification on how the authors labeled the relations. Therefore, it has a degree of actionability, but it's not very concrete. The reviewer is asking what the authors did, rather than what they should do based on a specific issue.", "grounding_specificity_rationale": "The reviewer is asking about the relationship between the authors' discourse labels and other languages in UD. While they are pointing to a specific aspect of the authors' work (the labeling), they are not explicitly identifying a specific part of the paper or table where this issue manifests. The question is about the *justification* of the authors' choices, not the information itself. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer is making a claim about the number of discourse relations in the authors' treebank. This claim requires justification. The reviewer is asking *why* there are so many `dobj` relations and whether this is an artifact of colloquial language or a labeling issue. This claim needs to be supported by evidence or reasoning. Therefore, it is verifiable.", "helpfulness_rationale": "The reviewer is expressing a desire for clearer and more justifiable feedback. The review point itself is not directly providing actionable suggestions. The helpfulness of the review depends on the authors' response to this point. Currently, the point is not explicitly asking for an action or providing a claim that can be verified. Therefore, it is not currently 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer mentions 'subpar hyperparameters' and expresses a concern, but does not explicitly state what action the authors should take or how to diagnose the issue. The concern is presented as a statement of doubt rather than a clear, actionable suggestion.", "grounding_specificity_rationale": "The reviewer mentions 'soft labels', 'CRM', 'Crossentropy', 'iNaturalist19', and 'beta value', which grounds the comment to some extent. However, they do not specify *which* part of the code or experimental setup is problematic, nor do they explain what is wrong with the beta value or how it relates to the metrics. The mention is general and lacks specific details about the implementation or data.", "verifiability_rationale": "The reviewer expresses a concern about the hyperparameters used, stating 'I am concerned that the authors are using subpar hyperparameters, similarly to'. This concern is presented without any supporting evidence, reasoning, or references. There is X being made, and the statement is purely a question of potential issues.", "helpfulness_rationale": "The reviewer clearly states their concern and suggests an alternative approach ('These results, at first blush, seem fairly impressive. For the leftmost plots, I am concerned that the authors are using subpar hyperparameters, similarly to'). This indicates a desire for clarification and guidance, making the comment 3 in identifying a potential issue."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly names the issues: 'text in table 1 is too small' and 'Algorithm 1: gradient symbol is missing in line 4'. This is explicit because the specific location and the missing element are directly stated. It is also concrete because the authors know exactly what needs to be changed in each case. Therefore, the actionability is 5.", "grounding_specificity_rationale": "The reviewer refers to 'table 1' and 'Algorithm 1', specifically naming the sections where the issues are located. This indicates strong grounding as the authors can easily identify the referenced parts. Furthermore, the reviewer specifies the *text size* issue in Table 1 and the *missing gradient symbol* in Algorithm 1, providing clear details about what needs to be addressed within these parts. Therefore, the grounding specificity is 5.", "verifiability_rationale": "The review point identifies issues with the paper, specifically stating that the text in Table 1 is too small and that the gradient symbol is missing in Algorithm 1. While these are valid observations, the justification provided is limited. The reviewer mentions the location of the issues but does not provide external references or logical reasoning beyond common knowledge about readability and the importance of mathematical notation. The claims are present, but the supporting evidence is lacking, making the verifiability 3.", "helpfulness_rationale": "The review point provides specific and actionable feedback to the authors. By pointing out the exact location of the small text in Table 1 and the missing gradient symbol in Algorithm 1, the reviewer guides the authors on what needs to be improved. This level of detail is 5 as it directly addresses specific issues and provides clear directions for action. The feedback is not vague or general, making it very useful for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue with the practical applicability of the proposed methods in highdimensional settings. They highlight that the algorithm requires solving several LPs in high dimensions, each involving a parameter that is not easily calculable. This suggests a lack of clarity on how to implement the algorithm in practice, which could be considered an implicit action. However, the reviewer does not explicitly state what needs to be done to address this issue, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'high dimensions' and 'parameter' as potential areas of concern. These are relevant technical terms related to the paper's content. However, the reviewer does not explicitly state which section, table, or unique aspect of the paper they are referring to. While the terms are relevant, the lack of a precise reference makes the grounding somewhat weak. The connection to the appendix, mentioned implicitly, further contributes to the lack of specificity.", "verifiability_rationale": "The reviewer provides a specific technical detail: 'solving several LPs in high dimensions, each involving a parameter that is not easily calculable.' This detail, while not a direct quote, is a clear statement of a claim that requires verification. The reviewer also links this issue to the experimental setup, mentioning 'small scale datasets'. This provides some evidence towards the verifiability of the claim, suggesting that the authors might have encountered this problem in their experiments. However, the lack of explicit examples or references weakens the verifiability score.", "helpfulness_rationale": "The reviewer raises a significant concern about the practical limitations of the proposed methods, particularly in highdimensional settings. They highlight a potential gap between the theoretical framework and the practical implementation, which could be highly valuable for the authors. The reviewer's point about the difficulty of calculating a parameter in high dimensions and the use of smallscale datasets in experiments directly addresses a practical issue. While the point could be more specific, it identifies a clear and actionable area for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "Highly Grounded Specificity", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point directly asks a question about a specific implementation detail (parameter sharing) in a particular section of the paper and suggests a concrete experiment. This is a 5 comment.", "grounding_specificity_rationale": "The reviewer explicitly references 'ResNet in the experiments in section 7.1' and asks about a specific implementation detail ('parameter sharing'). They also suggest a specific baseline experiment and connect it to a concept from a related field ('ODE net'). This is highly specific.", "verifiability_rationale": "While the reviewer isn't making a direct claim that the current ResNet is *incorrect*, their suggestion of a baseline experiment and the connection to ODEs provide implicit justification for exploring parameter sharing. This is verifiable through experimentation.", "helpfulness_rationale": "This review point is incredibly helpful. It directly addresses a technical detail, suggests a concrete improvement, and connects the work to a relevant area of research. It empowers the authors to understand the implications of their architectural choices and potentially explore alternative designs."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that trimming questions after the first 10 is an 'odd design choice'. While they don't provide a specific action to *how* to fix it, they clearly indicate that this is a point the authors should consider, making it 3.", "grounding_specificity_rationale": "The reviewer refers to 'L254,' which indicates they are pointing to a specific location in the paper. This provides some grounding. However, they are also referring to 'questions' in a general sense, criticizing the *number* of questions, which is less specific than pointing to a particular figure or table.", "verifiability_rationale": "The reviewer expresses an opinion about the design choice without providing any supporting evidence or logical reasoning. There is X that is backed by facts, external references, or clear reasoning.", "helpfulness_rationale": "The reviewer's point is about a specific implementation detail. While it is likely to be a valid observation, it doesn't directly point to a major flaw in the authors' work or offer a concrete solution. The impact is likely limited, making it 3 but not a highimpact critique."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer correctly identifies that the paper does not explicitly detail the process by which the proposed method produces the explanation about the NO2 group in Figure 1. The phrase 'additional adhoc postanalysis' suggests that the method might not inherently generate this explanation directly. The lack of a clear, stepbystep explanation makes it difficult for the authors to replicate or understand the underlying mechanism.", "grounding_specificity_rationale": "The reviewer's comment demonstrates a clear attempt to ground the discussion in a specific part of the paper, namely Figure 1 and the NO2 group. However, the paper does not explicitly state which part of the paper is being addressed, making the grounding somewhat weak. The reviewer's interpretation of the method's explanation as requiring 'additional adhoc postanalysis' is a deduction based on the paper's content, not a direct statement within the paper itself.", "verifiability_rationale": "The reviewer's statement that 'Figure 1: It's unclear how the proposed method produces this type of explanation (which says \"mutagens contain the NO2 group\")' forms a claim that the paper does not fully justify. While the paper presents the method as identifying potential motifs, the specific mechanism for generating the NO2 group explanation is not explicitly detailed. The reviewer's suggestion of 'additional adhoc postanalysis' is a deduction, not a direct statement supported by the paper.", "helpfulness_rationale": "The reviewer's comment is 5 in identifying a lack of clarity in the paper regarding the explanation of the NO2 group. It points out a potential missing step or ambiguity in the method's application, which could hinder the authors' understanding and ability to implement the method effectively. The comment highlights a specific area where the paper falls short in providing a complete and transparent explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment implicitly suggests that the nonconvexity of the loss function Z might be a problem for SGD convergence. While it doesn't explicitly state 'do something about the nonconvexity,' the suggestion to consider 'good properties' implies a concrete action: investigate the characteristics of Z that might mitigate this issue. This inferable action makes it actionable.", "grounding_specificity_rationale": "The comment explicitly refers to 'ln. 182184,' indicating a specific section of the paper being addressed. It also mentions the 'loss function Z,' which is a specific element within that section. This explicit reference to a specific part of the paper and a specific element makes it fully grounded.", "verifiability_rationale": "The comment contains a claim: 'Nonconvexity may not be an issue for the SGD to converge, if the function Z has some good properties.' However, it lacks specific evidence or references to support this claim. The term 'good properties' is vague and doesn't point to any specific existing literature or established principles. Therefore, while the claim is present, it is not wellsupported by logical reasoning, common knowledge, or external references, making it 1.", "helpfulness_rationale": "The comment raises a valid point about the potential impact of nonconvexity on SGD and offers a general suggestion: considering the 'good properties' of the loss function Z. This points to a potential area for improvement and provides a direction for the authors to investigate. However, it lacks specific details about what constitutes 'good properties' or how to identify them. Without concrete guidance, the feedback is somewhat general and might require further elaboration from the reviewer to be fully helpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer is explicitly asking for the meaning of the colon in the equation. This is a direct and clear request for clarification, making it 5 for the authors to understand the equation's meaning.", "grounding_specificity_rationale": "The reviewer is asking for the meaning of a symbol within a specific equation. While the equation is mentioned, the reviewer is not explicitly pointing to a specific part of the paper (like a section or table). The grounding is implied by the context of the equation. The specificity is reasonable as it targets a specific symbol within a specific equation.", "verifiability_rationale": "The review point is a question seeking information, not a claim being made. Therefore, the concept of verifiability doesn't directly apply. However, the reviewer is implicitly asking for justification (the explanation of the colon). Since no justification is provided, it could be considered 2 as it lacks the explicit reasoning.", "helpfulness_rationale": "The reviewer is asking for clarification on a mathematical notation within an equation. While this can be helpful for the authors to understand the paper, it is not directly addressing a problem or suggesting a solution. It is more of a request for information to improve understanding, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the errors in the SuppMat references (L502, L507, L509) and provides clear corrections. The specific line numbers and the intended references (SuppMat, z\u03b8, Table 4, Algorithm 1) are concrete and actionable for the authors.", "grounding_specificity_rationale": "While the reviewer doesn't explicitly state \"Check the SuppMat section,\" the line numbers (L502, L507, L509) implicitly point to the specific parts of the supplementary material where the errors occur. The reviewer then clearly specifies the *errors* (incorrect references) and the *corrected references* (SuppMat, z\u03b8, Table 4, Algorithm 1), making the grounding quite specific.", "verifiability_rationale": "The reviewer identifies specific errors in the SuppMat references and provides clear suggestions for correction. While the reasoning for the correction isn't explicitly stated as a chain of logic, it's implied that the original references are incorrect and the proposed ones are the standard or intended ones. This provides sufficient justification for the suggested changes.", "helpfulness_rationale": "The reviewer provides very specific and actionable feedback on the incorrect SuppMat references and clearly suggests the correct references. This information is immediately useful for the authors to fix the errors and improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing information (justification for excluding online learning and RL) and asks a direct question about it. This clearly identifies an actionable gap in the paper's explanation. The reviewer points to the need for the authors to understand *why* these methods are excluded, which is a direct action the authors can take to improve their evaluation.", "grounding_specificity_rationale": "The reviewer directly names the specific areas where the paper lacks explanation (retraining costs, comparison, challenges). They also point to the *type* of information needed (justification). This is grounded as the reviewer is pointing to specific details that are missing. The reviewer isn't just saying 'the paper is missing details'; they are specifying *what* details are needed.", "verifiability_rationale": "The reviewer makes claims about what the paper *should* explain. They are not making up information. This is verifiable based on the stated goal of understanding the limitations of the chosen approach. The claims are about *what* information is missing, not *why* it's missing (though the *why* is implied by the stated goal). The reviewer is providing a clear expectation of what information should be present.", "helpfulness_rationale": "Will this review point help authors improve their draft? Yes, significantly. By asking why online learning and RL are excluded, the reviewer is directly addressing a potential gap in the authors' understanding of their chosen methodology. This clarifies the limitations of their evaluation and guides them in understanding the scope of their work. It helps them understand the rationale behind their choices and what aspects of these methods are relevant to their study. This is a very helpful point as it directly addresses a potential area of confusion for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'Important references are missing' and names specific relevant works, Gated Fully Fusion for Semantic Segmentation (GFF) and EfficientFCN. It also suggests a 'comprehensive comparison' with these works. These are concrete actions and details on how to implement the inferred action.", "grounding_specificity_rationale": "The review point mentions 'the GFF1 and EfficientFCN2' and 'the encodedecoder architecture' generally. While it doesn't explicitly point to a specific section, table, or figure in the authors' paper, it clearly identifies the *type* of missing information and the relevant architectural context. This implies a grounding in the concepts and methods, even if not a direct reference to a specific part of the paper.", "verifiability_rationale": "The review point contains claims, specifically suggestions for improvement: 'I encourage the authors to have a comprehensive comparison with these work.' While it suggests a comparison, it doesn't provide specific examples or references within the review point itself to verify the importance of these specific references. It relies on the reviewer's knowledge of the field.", "helpfulness_rationale": "The review point is 5, explicitly stating the missing references and suggesting a concrete improvement ('holisticallyguided decoding'). It is also 3 in pointing to the general area of missing literature in encodedecoder architectures for semantic segmentation. The suggestion to have a 'comprehensive comparison' is positive and encourages further research. While it doesn't provide direct evidence within the review point to verify the importance of the specific references, it clearly identifies a relevant gap and suggests a concrete improvement, making it 5 for guiding the authors to address this gap."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a lack of support for the claim but doesn't explicitly state what is missing or how to improve the prompts, making it partially actionable.", "grounding_specificity_rationale": "The reviewer points out that the claim about effectiveness across various language pairs and domains is not fully supported by evidence from only two tables, indicating weak grounding and lack of specificity.", "verifiability_rationale": "The reviewer's statement that the slight improvement doesn't support the broad claim is verifiable based on the data in Tables 6 and 7, making it 5.", "helpfulness_rationale": "The reviewer's point is clear and directly addresses a potential issue with the claim made in the paper, making it 5 for the authors to understand the limitations of their claims."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the current method of aligning features and suggests exploring different designs. While it doesn't provide explicit instructions on how to implement these designs, the suggestions are concrete in terms of the types of experiments to conduct (varying sampling intervals and sample size). The reviewer is pointing out a potential area for improvement and offering a direction for the authors to explore.", "grounding_specificity_rationale": "The review point refers to a specific mechanism within the model ('Cycle FC align features at different spatial locations to the same channel'). However, it doesn't explicitly name a specific section, table, or unique aspect of the paper. The reviewer is making a comment about the inner workings of the model rather than a direct reference to a specific part of the data or results. While the reviewer then provides specific suggestions for improvement (sampling intervals and sample size), the initial grounding of the problem is weak.", "verifiability_rationale": "The review point contains a claim: 'analysis is slightly insufficient.' However, the subsequent suggestions for improvement (experiments with different sampling intervals and sample size) are not welljustified or supported by any logical reasoning or external references within the review point itself. The reviewer proposes these experiments as a solution but doesn't explain *why* these specific experiments would address the identified insufficiency. The connection between the claim and the suggested actions is not clearly established.", "helpfulness_rationale": "The review point identifies a potential area for improvement in the 'Cycle FC' mechanism and suggests exploring different experimental setups. While the general idea of exploring different designs is relevant and could be helpful for the authors, the lack of specific justification for the suggested experiments makes the review less impactful. The reviewer doesn't explain *why* these specific experiments (sampling intervals and sample size) would address the potential 'slight insufficiency' in the analysis. Without this justification, the suggestions are somewhat vague and less actionable for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the absence of standard deviations and directly infers the uncertainty about the 'best method'. This is an explicit and concrete action.", "grounding_specificity_rationale": "The comment explicitly mentions the 'absence of standard deviations' and logically implies the 'uncertainty about the best method'. The information is directly identified without needing inference. This is 5.", "verifiability_rationale": "The comment contains a claim ('No standard deviations are displayed') and a deduction ('Thus, we are not sure if the best method is really the best...'). However, it does not provide explicit reasoning, examples, or external references to support this deduction. Therefore, it is 1.", "helpfulness_rationale": "The comment identifies a limitation in the presented information (lack of standard deviations) and suggests an alternative interpretation ('Thus, we are not sure if the best method is really the best...'). While it doesn't directly tell the authors how to improve, it highlights a potential issue with the analysis, which is helpful for guiding further investigation or discussion. This is 3 as it points out a potential flaw in the presented results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for an explanation of how the value p < 0.4 was determined. This is an explicit request for clarification on how to *action* \u2013 understand the basis of this threshold. While the request is clear and identifies a need for action, it doesn't provide concrete steps or examples of how this decision was made within the paper. The authors need to understand the reasoning behind this specific value to proceed.", "grounding_specificity_rationale": "The reviewer is asking about the *choice* of the value 0.4. This is a specific request about a particular element of the paper. However, the paper does not explicitly state the *reason* for choosing this specific value. The weakness is that the paper does not *ground* the choice of 0.4 in a clear and precise manner. The specificity is limited to the value itself, but the lack of justification makes it less grounded.", "verifiability_rationale": "The reviewer is making a request for an explanation of a methodological choice. This constitutes a claim that *something* is the reason for choosing p < 0.4. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim within their review point. The verifiability is low because the claim is presented without sufficient evidence or justification.", "helpfulness_rationale": "The reviewer is asking for an explanation of a methodological choice. While this is valuable information for the authors and can help them understand and potentially improve their work, it is not a direct suggestion for improvement. The helpfulness is limited to providing information that can aid in diagnosis or troubleshooting, rather than directly addressing a weakness in the current draft. The authors need to *understand* the choice, not just *apply* a change."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the actions needed: 'explain why there are negative numbers in Figure 1' and 'analyze the implications of Figure 2 and Figure 3'. These are direct and concrete actions for the authors to take.", "grounding_specificity_rationale": "The reviewer directly references 'Figure 1', 'Figure 2', and 'Figure 3' by name. This indicates a high level of grounding specificity as the reviewer can easily identify the parts of the paper being addressed. Furthermore, the reviewer asks for specific actions ('explain' and 'analyze'), adding to the specificity.", "verifiability_rationale": "The reviewer makes a claim by stating that the figures 'fail to provide explanations or analysis'. This is a verifiable statement as it points out a clear deficiency. The reviewer also suggests 'clarifying' and 'analyzing', which are verifiable actions that can be supported by external references or common knowledge in data interpretation.", "helpfulness_rationale": "The review point is 5 as it directly points out missing elements (explanation and analysis) and provides specific, actionable suggestions ('explain' and 'analyze'). The reviewer is not just critical but constructive in suggesting concrete improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The comment explicitly states a trend (implicitly suggesting a need for further investigation) but lacks concrete steps for the authors.", "grounding_specificity_rationale": "The comment explicitly mentions the models, sizes, and the table (Tab. 2), making it 5.", "verifiability_rationale": "The claim is based on the observation of a trend in a table, providing some justification but lacking external references or indepth analysis.", "helpfulness_rationale": "The comment provides context and raises a relevant question, offering some value but not a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a problem (scalability) and suggests a question as a way to address it. While the suggestion is relevant, it doesn't explicitly state how the method is learned or how it can be applied to large datasets. The action is implied but not fully stated, making it less actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the whole training and test datasets as input' and then provides an example of a large dataset (ImageNet). This clearly identifies the specific aspect of the method being addressed and provides a concrete example, making the grounding very specific. The comment also implies a lack of solution for this specific grounding, further emphasizing the specificity of the identified issue.", "verifiability_rationale": "The reviewer makes a claim about the method's limitations regarding scalability and provides supporting evidence by stating the difficulty of applying it to large datasets and the potential reduction in practical contribution. This claim is wellsupported by logical reasoning and examples, making it 5.", "helpfulness_rationale": "The reviewer's comment is critical and constructive. They identify a significant limitation of the proposed method and suggest a potential improvement (addressing scalability). This type of feedback is 5 and valuable for the authors, making the review 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a question about the contribution of the UNet component and suggests a specific experiment (comparison to standard UNets). This is a clear and direct request for clarification and a concrete action for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'UNet part' and 'fractional transform' and suggests a comparison to 'standard UNets'. This demonstrates a clear understanding of the model's architecture and the specific area of interest. The grounding is explicit and points to a specific part of the model.", "verifiability_rationale": "The reviewer is not making a claim about the truth of anything. They are suggesting an experiment. Therefore, there is X to verify.", "helpfulness_rationale": "The reviewer is directly asking a question about a specific component of the model and suggesting a concrete experiment to investigate it. This is highly relevant information for the authors to understand the contribution of the UNet and the effectiveness of the CoNO model. The suggestion for comparison is a standard and useful debugging technique in machine learning."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the potential issue of higher computational cost for the proposed PSA method compared to baselines. They also point to a specific detail in Algorithm 1, mentioning the calculation involving 'flipped previous layer output,' which makes the action concrete. The reviewer implicitly suggests an experiment to compare computation complexity, indicating an intended action.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed PSA method' and 'baselines,' which are specific to the paper. They also mention 'Algorithm 1' and a specific operation within it ('flipped previous layer output'), indicating a clear reference to a specific part of the paper. The reviewer explicitly states the need for a 'computation complexity comparison' in the experiment part, making the grounding explicit.", "verifiability_rationale": "The reviewer presents a claim: 'The proposed PSA method requires more computation than baselines.' However, within this review point, there is no supporting evidence or justification for this claim. The reviewer suggests an experiment but doesn't provide any logical reasoning, common knowledge, or external references to back up the assertion that PSA requires more computation. The claim is stated without sufficient support within this review point.", "helpfulness_rationale": "The reviewer identifies a potential issue with the computational cost of the proposed method and suggests an experiment to address it. While the suggestion is concrete and actionable, the lack of verifiable evidence within this review point makes it less helpful for the authors. The authors are aware of a potential problem but lack confirmation of its existence and impact."}
{"actionability_label": "3. 3", "grounding_specificity_label": "4. 4", "verifiability_label": "2. 2", "helpfulness_label": "3. 3", "actionability_rationale": "The reviewer suggests improvements to figure clarity (font size, color) and the comparison table. While the suggestions are specific to certain parts of the paper, the reviewer doesn't explicitly state how to implement these changes. For example, they don't say \"Change the font size of the labels in Figure 1 to 12pt\" or \"Add a color scale to the grey box.\"", "grounding_specificity_rationale": "The reviewer points out specific issues with figures (font size, grey box) and suggests a table for comparison. They explicitly mention \"Fig 1. The words in grey box may be larger\" and \"V_mem, Th_i, U_i^t too small.\" They also mention \"Conv5 +BN\" in the context of the comparison table. This demonstrates an attempt to identify specific paper elements. However, the reviewer doesn't specify the exact axes or data points within the figures that need improvement, nor does they explicitly state which table in the appendix would be most relevant for the comparison.", "verifiability_rationale": "The reviewer states that the fonts in figures are too small and suggests a comparison table with epochs and parameters. However, they do not provide any justification or reasoning for these claims. For example, they don't explain *why* the font size is an issue or *why* comparing epochs and parameters is necessary to justify the improved accuracy. The reviewer simply states these as observations.", "helpfulness_rationale": "The reviewer provides some suggestions for improvement, such as increasing font sizes and adding a comparison table. However, the suggestions are somewhat vague and lack specific details. For instance, they don't specify the exact font size to use, the type of color scale for the grey box, or the exact structure of the comparison table (e.g., number of rows, columns, data format). Additionally, the reviewer doesn't explain the *purpose* of these improvements or *why* they are necessary. The lack of justification makes it difficult for the authors to understand the value of these suggestions."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "5 (5)", "verifiability_label": "X (X)", "helpfulness_label": "2 (2)", "actionability_rationale": "The reviewer explicitly states they don't understand the sentence, which implies a need for clarification and a request for a rewrite. This is a direct action the authors can take to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly points to a specific sentence (l. 3, p. 5) and a specific section (P. 5) where the lack of understanding is occurring. This indicates strong grounding specificity. They are directly referencing the location of the problem.", "verifiability_rationale": "The reviewer states they \"can't understand the meaning of the sentence.\" This is a statement of difficulty, not a claim requiring verification. There is no logical reasoning, common knowledge, or external references involved in this statement.", "helpfulness_rationale": "The reviewer clearly states their difficulty and requests a rewrite. While the request is actionable, the initial statement of confusion is the primary issue. The helpfulness is limited by the initial lack of clarity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that 'the performance gain is mostly from PBSD' and asks 'any other motivations for PBSD?'. While the motivation is implied by the paper being 'mostly motivated by supervised contrastive learning' and focusing on 'the DSCL part', the reviewer does not provide a concrete, actionable suggestion beyond asking for clarification. The action is implicit (inferring the motivation and asking for more information), and the details are lacking.", "grounding_specificity_rationale": "The reviewer mentions 'the main contribution is somehow a little bit unclear', 'the ablation study', 'this paper is mostly motivated by supervised contrastive learning', and 'the DSCL part'. While these points touch upon specific aspects of the paper, the reviewer does not explicitly and precisely point to a specific section, table, or unique element. The grounding is implicit, referring to general concepts rather than concrete locations.", "verifiability_rationale": "The reviewer presents statements like 'the main contribution is somehow a little bit unclear' and poses a question 'any other motivations for PBSD?'. These can be considered claims. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The claims are presented without justification or evidence.", "helpfulness_rationale": "The reviewer's comment is diagnostic in nature, pointing out a lack of clarity in the contribution and asking a question to seek further understanding. While this feedback is valuable for the authors, it does not directly offer concrete, actionable suggestions for improvement. The comment identifies a weakness but doesn't provide a clear path forward beyond asking clarifying questions."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Partially Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer states a fact (''2 gives a tester for the spread parameter...') but doesn't explicitly state the action or implication related to (\u03f5, \u03b4)identity testing. The concern about (\u03c0, \u03d5) pairs highlights a lack of clarity on the practical application or limitations of the mentioned tester.", "grounding_specificity_rationale": "The reviewer refers to \"item 2\" which could be interpreted as a section or a general idea. However, the initial part of the review doesn't explicitly point to a specific section, table, figure, or unique aspect of the paper. The later part about (\u03c0, \u03d5) pairs is more specific but comes after the initial potentially weakly grounded statement.", "verifiability_rationale": "The reviewer states a fact (\"2 gives a tester...\") but doesn't provide external references or logical reasoning to support their claim about the tester's behavior with specific (\u03c0, \u03d5) pairs, leaving the question unanswered.", "helpfulness_rationale": "The reviewer identifies a potential area for improvement in the paper (how item 2 relates to identity testing and its behavior with specific (\u03c0, \u03d5) pairs) but doesn't offer a concrete solution or clarification, limiting its direct helpfulness in addressing the immediate issue."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question to clarify the 'active learning pipeline' method, directly addressing the authors' claim. This is a clear and actionable request for information. The reviewer is not inferring the need for clarification but is directly stating the potential misunderstanding.", "grounding_specificity_rationale": "The reviewer's statement is a question and does not explicitly identify a specific part of the paper being addressed. They are not pointing to a particular section, table, or figure. They are also not providing a unique identifier for the 'active learning pipeline' method. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question to seek clarification on a potential misunderstanding. Therefore, verifiability is not the primary aspect of this review point.", "helpfulness_rationale": "The reviewer's comment is helpful because it attempts to correct a potential misinterpretation of the authors' work. By asking if the 'active learning pipeline' is the same as traditional active learning, they are seeking to ensure the authors have a clear understanding of the method. This is a valuable contribution to the review process, even though it is not a direct suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that 'annotated labels are needed' for the proposed method, which is an actionable point. However, the reviewer does not specify *how* these labels are used or what they represent, making the action implicit rather than explicit. The lack of detail makes it somewhat vague on how to apply it.", "grounding_specificity_rationale": "The reviewer mentions 'annotated labels' and 'supervised training' without explicitly stating which part of the model or process these labels are for. This makes the grounding weak. Furthermore, the reviewer does not specify what is incorrect or how the labels are used to identify the issue, making the specificity low.", "verifiability_rationale": "The reviewer presents a statement of fact: 'A selfsupervised pretraining approach without annotations could be more appealing.' This is a claim. However, the reviewer does not provide any justification or reasoning to support this claim. There are no references to external works or logical arguments presented to back up the assertion that such an approach would be more appealing.", "helpfulness_rationale": "The reviewer suggests an alternative approach ('A selfsupervised pretraining approach without annotations could be more appealing') to the proposed method. While this points to a potential limitation of the current method (the need for annotated labels), it does not directly improve or clarify the current method's weaknesses. It is more of a suggestion for improvement rather than a critique of the current method's flaws."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer provides two suggestions: 1) to add a citation and a more specific measure of expressivity to the abstract, and 2) to include learning curves for all experiments. While the suggestions are relevant, they are not fully explicit or concrete. The reviewer implicitly suggests where these changes should be made but does not explicitly state the exact actions to be taken (e.g., insert after a specific sentence, create a new section). The reviewer also does not specify the exact nature of the 'more specific measure of expressivity' or why learning curves are necessary for all experiments. Therefore, the review point is partially actionable as it points towards concrete improvements but lacks precise implementation details.", "grounding_specificity_rationale": "The reviewer's comment is 1 at all. They do not explicitly identify a specific part of the paper or section where the suggested changes should be made. The reviewer mentions the abstract and 'all experiments' generally, without specifying the exact location or nature of the changes. There is no clear reference to a unique element of the paper. The comment is highly unspecific.", "verifiability_rationale": "The reviewer makes a claim by suggesting specific improvements to the paper, such as adding a citation and learning curves. However, the reviewer does not provide any justification or support for these claims. There is no logical reasoning, common knowledge, or external references cited to back up the suggestions. The claims are presented without sufficient evidence or explanation. Therefore, the review point is 1 as it lacks supporting evidence or justification.", "helpfulness_rationale": "The reviewer's comment provides suggestions for improvement, such as adding a citation and learning curves. While these suggestions are relevant to the paper's content and presentation, the comment lacks specific details on how these improvements should be implemented. The reviewer does not specify where the citation should be added, what the 'more specific measure of expressivity' should be, or why learning curves are necessary for all experiments. This lack of specificity makes the suggestions less actionable and therefore less helpful for the authors. The reviewer's comment is more of a direction than a concrete guide."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of clarity regarding the motivation and application of the proposed method. While they don't provide specific steps on how to address this, the need for clarification is clear. The suggestion to demonstrate use on actual domain adaptation tasks is a potential action, but the current point itself is vague on the specific action to be taken.", "grounding_specificity_rationale": "The reviewer broadly questions the motivation of the paper and doesn't pinpoint a specific section, table, figure, or unique aspect of the paper. They are referring to the general concept of domain adaptation and the applicability of the method. While they mention 'this paper's motivation,' it's not tied to a specific element within the paper.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity in the paper's motivation and application. However, they do not provide any evidence or reasoning to support this claim. They suggest improvements but don't explain *why* the motivation is unclear or *how* the proposed method lacks application. The claim is stated but not justified.", "helpfulness_rationale": "The reviewer identifies a significant weakness in the paper \u2013 the lack of clear motivation and application. They also offer a relevant suggestion for improvement \u2013 demonstrating the method on actual domain adaptation tasks. However, the reviewer does not explicitly state how they would go about identifying the motivation or providing the necessary examples to demonstrate the application. The point highlights a problem and suggests a solution, but it doesn't provide concrete steps for the authors to take."}
{"actionability_label": "1", "grounding_specificity_label": "1: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggestion for the authors. While it identifies a potential issue with the experimental setup, it doesn't directly tell the authors what to do or how to address it.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. It focuses on the lack of clarity in the experimental comparison and the omission of key details like ranks and model parameters, rather than pinpointing a specific section or table.", "verifiability_rationale": "The review point does not contain a claim that can be verified. It identifies a potential flaw in the experimental reporting but doesn't present a new finding or hypothesis that can be supported by evidence.", "helpfulness_rationale": "The review point provides valuable information about the lack of clarity in the experimental comparison and the omission of key details like ranks and model parameters. This information is helpful for the authors as it highlights a potential issue with their experimental setup and provides a direction for improvement. However, it does not directly provide a solution or actionable steps for the authors to take based on this information."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the missing comparison in Table 2 ('In Table 2, under the leave one out setting the proposed method only be compared to \u201c+LFP\u201d') and suggests a concrete action by including ATA, which is mentioned as a potentially better alternative in the results of Table 1. The reviewer clearly identifies the specific part of the paper where the information is lacking and proposes a specific method to include.", "grounding_specificity_rationale": "The comment explicitly refers to 'Table 2' and mentions the 'leave one out setting'. This clearly identifies the specific part of the paper where the information is missing. The reviewer provides a clear target for improvement by suggesting the inclusion of ATA.", "verifiability_rationale": "The comment contains a suggestion (an action) to include ATA in Table 2, which could be considered a claim in the sense that it proposes a change to the presented results. This claim is supported by the reviewer's observation of ATA's performance in Table 1, providing a basis for verification. However, the primary impact of the comment is highlighting the missing information in Table 2, making it fully grounded but the specific action of including ATA is not directly stated in the comment itself, though suggested.", "helpfulness_rationale": "The comment is 5 as it directly points out a missing comparison in Table 2 that, based on the results in Table 1, would significantly improve the understanding of the proposed method's performance under the leave one out setting. The reviewer provides a clear and actionable suggestion for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out 'differences' and 'need for standardization' in the normalization module. While this suggests a potential area for improvement, the review doesn't explicitly state what action needs to be taken or how the current state is hindering the reader's understanding. The reviewer implies an action (standardization), but the lack of explicit detail makes it 2.", "grounding_specificity_rationale": "The reviewer mentions 'normalization module' and 'pictograms' but doesn't explicitly state which specific part of the paper or element within the module they are referring to. The reviewer also points out a potential issue in Figure 4 but doesn't clearly identify the specific section, table, figure, or unique aspect being addressed. The lack of explicit identification makes it difficult to ground the feedback precisely.", "verifiability_rationale": "The reviewer states 'a standardization of the pictograms is needed' and points out issues in Figure 4. While the reviewer identifies a problem, they don't provide any logical reasoning, common knowledge, or external references to support their claim. The reviewer's statement is an opinion about what is needed, not a justified claim based on evidence.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as 'standardization of the pictograms' and pointing out 'minor problems about the text'. These suggestions are actionable and directly address potential issues in the paper. The reviewer also highlights 'minor problems about the text', which are also actionable. The reviewer's suggestions are clear and directly related to the identified issues."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for 'detailed explanation' of the algorithm and 'computational cost analysis'. These are concrete actions that the authors should take to improve their draft. The request is clear and directly addresses the need for more information about the proposed method.", "grounding_specificity_rationale": "The reviewer explicitly refers to the 'theoretical part' and the 'proposed algorithm' when stating their concerns. This demonstrates strong grounding specificity, as the reviewer clearly identifies the section and concept where the issue lies. The request is also specific, asking for details about the algorithm's steps and its computational implications.", "verifiability_rationale": "The reviewer makes a claim about the missing details in the theoretical part and the lack of clarity regarding computational cost. While the claim itself isn't directly verifiable within the review point, the request for information to *verify* this claim is a valid and helpful suggestion for the authors. The reviewer is pointing out a gap in the provided information, which is a form of implicit verification request.", "helpfulness_rationale": "The reviewer's request is 5 because it directly addresses a lack of clarity and provides concrete information needed to understand and implement the algorithm. It helps the author improve their work by providing specific details about the algorithm's steps and its computational implications, which are crucial for the reader to understand and evaluate the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises several questions and points out a lack of clarity regarding the benefits of outputside layers and the workings of Pixelshuffle and upsampling. While the questions are not direct instructions, they clearly indicate areas where the paper's explanation is lacking. The reviewer asks 'why' these aspects are not clear, implying a need for more explicit and actionable feedback for the authors.", "grounding_specificity_rationale": "The reviewer asks for more details about the Pixelshuffle operation and the upsampling process, specifically questioning why the dimensionality remains the same after upsampling. While the paper doesn't explicitly point to a specific section of the paper when making this general comment, the reviewer's questions directly relate to the model description and its implementation. Therefore, the grounding is weak because the authors need to infer the specific parts being addressed.", "verifiability_rationale": "The reviewer questions the clarity and completeness of the explanation regarding the Pixelshuffle and upsampling. They ask 'why the dimensionality remains the same after upsampling in Figure 2. (b)?' This suggests that the paper's explanation is not sufficiently detailed or logical to justify the observed behavior. The reviewer is asking for a justification that is not explicitly provided in the paper, making the claim 1.", "helpfulness_rationale": "The reviewer's request for more information about the limitations and societal impact of their work directly addresses the authors' need for a more complete understanding of their contribution. By asking for these details, the reviewer is providing actionable feedback that could significantly improve the authors' work and its context. The request for more information is a valuable and direct suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a problem: a contradiction in the paper's description regarding the use of 300WLP. This is a direct and clear identification of an issue. While the reviewer doesn't provide a specific action beyond asking for clarification, the identification of the problem itself is a concrete action that the authors should take to understand the experimental setup better. The reviewer also clearly states the implication of this potential unfair advantage, making the action somewhat explicit.", "grounding_specificity_rationale": "The reviewer points out a discrepancy in the methodology. While they don't explicitly name a section or table where this inconsistency is claimed, they refer to the general methodology. This weakens the grounding specificity as the authors can't confidently pinpoint the referenced part. However, the reviewer clearly specifies the *what* (300WLP training) and the *why* (potential unfair advantage) of the issue, making the specificity of the identified problem clear.", "verifiability_rationale": "The reviewer presents a claim: a potential inconsistency in the paper's description. The reviewer doesn't provide external references or logical reasoning to verify this claim within the review point itself. The claim is based on the reviewer's interpretation of the paper's potentially contradictory statements. Therefore, the verifiability is low as there's no direct evidence within the review point to support or refute the claim.", "helpfulness_rationale": "The reviewer raises a valid concern about the consistency of the experimental setup. While the reviewer doesn't directly suggest a specific fix, pointing out this potential flaw is helpful for the authors as it encourages them to doublecheck their methodology and the description of the baselines. However, the reviewer's point is more about highlighting a potential issue rather than providing a clear, actionable suggestion for improvement. Therefore, the helpfulness is moderate."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential limitation in the model's assumption about how observations are aggregated (averaging) and suggests alternative methods (summation, populationweighted average). While the reviewer doesn't provide a specific formula or detailed explanation of why these alternatives are better, they clearly point out a discrepancy between the model's assumption and the nature of disease incident data (counts or rates). This highlights a potential area for improvement and provides a direction for the authors to consider. The reviewer explicitly states the model's assumption, which is an action the authors can take to understand a potential issue.", "grounding_specificity_rationale": "The reviewer refers to 'Equation (1)' and mentions 'bag observation model' or 'spatial aggregation process' in the context of that equation. This indicates that the reviewer has located the relevant information within the paper. However, the reviewer does not explicitly state the exact section, table, or figure where these concepts are discussed. They also do not provide a unique element of the paper that they believe is being referenced. The reviewer's comment is general and points to a potential issue with the model's formulation but doesn't pinpoint the exact location or specific detail within the paper.", "verifiability_rationale": "The reviewer makes a claim that the authors assume the observations are obtained by averaging over the corresponding support $v$. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim about the authors' assumption. While the reviewer suggests alternative aggregation methods, they don't provide specific examples or references to back up these suggestions. The claim is made without sufficient justification or evidence, making it difficult to verify the reviewer's assertion about the authors' assumption.", "helpfulness_rationale": "The reviewer points out a potential simplification in the model (averaging) and suggests alternative aggregation methods (summation, populationweighted average) that might be more appropriate for disease incident data (counts or rates). While the reviewer identifies a potential area for improvement and offers a direction for the authors to consider, the suggestions are quite general and lack specific details or references. The reviewer doesn't explain *why* averaging is a problem in this specific context or *how* the suggested alternatives would solve the issue. Therefore, while the reviewer's point is potentially helpful, it lacks the specificity and detail needed to be fully actionable for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issues with the architectural details (lack of mathematical definition of multihead attention) and suggests improvements (providing definitions). They also point out a specific element in Figure 2 (the split arrow) and ask a question about the input vectors, indicating an implicit action to clarify. The suggestions are directly aimed at addressing the identified issues.", "grounding_specificity_rationale": "The reviewer directly points to Figure 2 and asks very specific questions about a particular element (the split arrow) and the nature of the input vectors. This indicates a strong attempt to identify the specific part of the paper being addressed and understand the details.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity in the architectural details and the assumption about Figure 2. While the paper doesn't explicitly state that the authors are using the same vectors for keys and values, the reviewer's point highlights a potential gap in the clarity and completeness of the explanation provided in the paper. The reviewer is not providing external references to support their claim about the missing information.", "helpfulness_rationale": "The reviewer's suggestions are directly aimed at improving the reader's understanding of the architectural details, which is a significant benefit for the authors. Providing mathematical definitions and clarifying Figure 2 would directly address the identified weaknesses and make the paper more accessible."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer clearly states their criticism and provides a reason (the IID assumption) and its consequence (the sqrt(m) argument and Theorem 6/7). This is a direct and constructive criticism. Therefore, it's actionable.", "grounding_specificity_rationale": "The reviewer explicitly names the \"IID assumption\" and explains *why* it's a problem. They also connect it to the specific argument about the sqrt(m) term. This is very specific. Therefore, it's 5.", "verifiability_rationale": "The reviewer provides a clear explanation of how the IID assumption impacts the mathematical argument. They point to the specific parts of the argument (sqrt(m) and Theorems 6/7) that are affected. This is 5. The reviewer's reasoning is logical and directly addresses the stated issue.", "helpfulness_rationale": "The reviewer's criticism is directly relevant to the paper's core methodology and is wellexplained. It highlights a significant limitation. This is a 5 comment as it points out a crucial flaw in the assumptions that underpin the paper's theoretical results."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the concern about fixed policies in reinforcement learning. It uses terms like 'fixed policy' and 'tasks get more complicated' which are direct actions or suggestions. However, it doesn't specify *how* the policy is fixed or *what* specific aspect of the policy is being addressed, making the action somewhat vague.", "grounding_specificity_rationale": "The comment refers to the general concept of a 'fixed policy' in reinforcement learning. While it implies a potential issue, it doesn't explicitly point to a specific section, table, figure, or unique aspect of the paper being addressed. The grounding is implicit, as it's a general observation about the nature of RL policies.", "verifiability_rationale": "The comment presents a claim about the potential limitations of fixed policies in reinforcement learning. It suggests that tasks can become complex enough to require a nonfixed policy. This claim is supported by the general understanding of RL, but it doesn't provide specific examples or references to back up this assertion.", "helpfulness_rationale": "The comment raises a valid concern about the limitations of fixed policies in reinforcement learning. It challenges the authors to consider more dynamic approaches. This could be helpful in prompting authors to explore more sophisticated RL techniques and potentially improve their work. However, it doesn't offer concrete, actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests improving the analyses of the method and experimental outcomes. While this is a clear direction for improvement, the reviewer does not specify *how* these analyses should be improved. The suggestion is broad and lacks concrete details. Therefore, while the reviewer identifies an actionable area, the lack of specific guidance makes it somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'the method' and 'the experimental outcomes' generally, without specifying a particular section, table, figure, or unique element within the paper that needs improvement. While the reviewer implies a need for more analysis in these areas, the lack of specificity means the authors cannot pinpoint exactly what is missing. Therefore, the grounding of this comment is weak as the authors cannot confidently determine the exact area of concern.", "verifiability_rationale": "The reviewer states that 'A majority of the experiments focus on the presentation of results. The analyses of the method itself and the experimental outcomes are not comprehensive enough.' This statement clearly presents a claim about the current state of the analyses. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the analyses are 'not comprehensive enough.' Therefore, the claim is not verifiable based on the information provided.", "helpfulness_rationale": "The reviewer points out a potential weakness in the paper's analysis and suggests a direction for improvement by recommending a different pretraining level. While this is a relevant observation and a constructive suggestion, the reviewer does not provide specific details on *what* aspects of the analysis are lacking or *how* the suggested pretraining level would lead to better results. The feedback is general and lacks concrete details, making it less impactful in guiding the authors' work. Therefore, the helpfulness of this comment is somewhat limited due to the lack of specific guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly mentions the missing papers 1 and 2 and suggests including them. This indicates an explicit action. However, the reviewer does not explicitly state the *specific steps* the authors should take to incorporate these papers, such as removing the current literature, adding the new papers, or discussing the differences. The action is implied but not fully detailed.", "grounding_specificity_rationale": "The reviewer explicitly names the specific papers 1 and 2, which clearly identifies the specific part of the paper being addressed. The reviewer also states that these papers satisfy Assumption 2 and have a better rate than QSGD, providing specific information about these papers. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim by stating that the literature review ignores relevant papers and suggests that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the reviewer does not provide any evidence or references to support these claims within the review point itself. The claims are presented as assertions without logical reasoning or external references.", "helpfulness_rationale": "The review point identifies a valuable weakness in the literature review by pointing out missing relevant papers and suggesting their inclusion. The reviewer also makes a claim about the performance of specific algorithms. While the point is generally helpful in improving the literature review, it lacks explicit guidance on *how* the authors should implement the suggestions and verify the claims. The helpfulness is limited by the lack of concrete action steps and supporting evidence."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem with the paper's presentation but lacks specific details on what is difficult to follow and how the authors should address it. It implies an issue but doesn't provide concrete actions.", "grounding_specificity_rationale": "The comment is a general statement about the paper's presentation and does not specify which section, table, figure, or element is causing the difficulty.", "verifiability_rationale": "The comment is a factual statement about the presentation being hard to follow and does not contain any claims, suggestions, or judgments.", "helpfulness_rationale": "The comment identifies a weakness in the presentation but does not offer any specific, actionable suggestions for improvement, making it less helpful for guiding the authors to a solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for 'more detail' about the compared models and their 'computational requirements'. This is a direct request for information, making it actionable. The request is also quite specific, asking for details about the models and their computational cost, which reduces vagueness.", "grounding_specificity_rationale": "The reviewer explicitly names the models (DMM, DVBF, KVAE) and asks about their 'computational requirements in comparison'. This clearly identifies the specific part of the paper being addressed, making the grounding fully grounded. The request also specifies what needs to be addressed \u2013 the computational requirements of the models in comparison.", "verifiability_rationale": "The reviewer is making a claim that the paper should provide information about the 'computational requirements of the 3 methods compared in Table 1'. This claim is verifiable because the request is logical and the information, if present, would directly address the reviewer's need. The reviewer is essentially asking for justification (the information) to support their expectation (the paper should provide it).", "helpfulness_rationale": "The reviewer's request is directly relevant to improving the paper by providing missing information about the computational requirements of the compared models. This is a clear and actionable feedback that directly addresses a potential weakness in the paper's description of the methods. The request is wellstructured and easy to understand."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for 'more experiments on different famous LLMs like LLaMA, Falcon, etc'. This indicates an intention to suggest a change. However, the reviewer does not specify how these experiments should be conducted. The action is the 'need' for more experiments, but the 'how' is missing.", "grounding_specificity_rationale": "The reviewer mentions 'LLaMA' and 'Falcon' as examples of LLMs. This demonstrates that the reviewer can identify specific models. However, the reviewer does not specify *why* these models are relevant or *what aspects* of these models should be benchmarked. The grounding is present (mentioning specific model names), but the specificity regarding the *rationale* and *scope* of the suggested experiments is lacking.", "verifiability_rationale": "The reviewer makes a claim that 'experiments on L5, PaLM and GPT series LLMs and show the influence of parameter size on benchmark score. However, I think more experiments on different famous LLMs like LLaMA, Falcon, etc are needed as benchmark baselines.' This is a statement of a desired change. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support why these additional experiments are needed. The claim is stated without sufficient backing.", "helpfulness_rationale": "The reviewer's comment directly addresses a relevant aspect of the work (benchmarking on different LLMs). This is a positive sign for helpfulness. However, the comment is vague and doesn't provide specific guidance on *how* these experiments should be conducted or what benchmarks should be used. Without more detail, the authors may find it difficult to directly implement the reviewer's suggestion. While the intent is helpful, the lack of concrete information reduces its immediate helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action they want to take and the details of that action. They state \"it would be better to compare the real search cost (e.g. in terms of GPU days)\" and explicitly mentions \"Table 3\" as the location for this information. This is explicit and concrete.", "grounding_specificity_rationale": "The reviewer explicitly identifies the part of the paper being addressed as Table 3 and specifies the exact information to be added as \"real search cost (e.g. in terms of GPU days). This is both grounded and specific.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are simply suggesting an addition to a table. Therefore, there is no verifiability aspect to this review point.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for improving Table 3 by adding a relevant metric (real search cost in GPU days). This directly addresses a potential area for improvement in the paper and provides a concrete direction for the authors to take. The suggestion is actionable and would likely be valuable for the authors to understand the computational effort involved in their search process."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the error: 'In the phrase \"for 'inbetween' uncertainty\", the first quotation mark on 'inbetween' needs to be the forward mark rather than the backward mark (i.e., \u2018 i n \u2212 b e t w e e n \u2019 ). p.', and provides the correct notation. The action is to replace the backward quote with a forward quote, which is a clear and direct action.", "grounding_specificity_rationale": "The reviewer explicitly mentions the phrase 'for 'inbetween' uncertainty' and clearly identifies the issue within that specific phrase. The grounding is strong as the exact location and the specific character issue are pointed out. The specificity is high as the problem is localized and the desired change is clear.", "verifiability_rationale": "The reviewer makes a claim about the incorrect quotation mark usage and provides a clear justification for the correction by stating the desired notation (i.e., \u2018 i n \u2212 b e e n \u2019 ). The reasoning is logical and the reference is direct. External references are not needed for this specific point, but the explanation is sufficient.", "helpfulness_rationale": "The reviewer provides a very specific and actionable suggestion for correcting a clear typographical error. This directly improves the readability and presentation of the text, making it 5 for the author."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a desire for a clearer definition of \"Omega,\" indicating an action the authors should take. However, the action isn't fully explicit (e.g., \"Find the definition of Omega in Section X\"). The reviewer also points out that OMD is a family of algorithms, implying a need for more specificity in the paper's description of OMD. While the action is present, it's not fully explicit or concrete.", "grounding_specificity_rationale": "The reviewer asks for a definition of \"Omega,\" implying they need to find it. However, they don't specify *where* the definition can be found, making the grounding weak. The reviewer also mentions OMD and a link function, but doesn't explicitly point to a specific section, table, or figure where this information is lacking. The grounding is implied by the concept being discussed, but not explicitly stated.", "verifiability_rationale": "The reviewer makes a judgment about the paper's clarity regarding Omega and OMD, which constitutes a claim. However, the evidence for this claim within the review point is weak. The reviewer doesn't provide specific examples or references to support their claim about the lack of clarity. The suggestion about OMD being a family of algorithms is a general point about algorithmic understanding, not a specific critique of a flaw in the paper's content.", "helpfulness_rationale": "The reviewer's point primarily highlights a lack of clarity and raises specific questions. While it prompts clarification, it doesn't directly instruct the authors on what to do. The reviewer's suggestions, such as \"What link function?\" and \"Which theorem in 32 are you referring to for this regret guarantee?\", are more of questions prompting further investigation rather than direct actionable suggestions. The point itself is more of a pointer than a direct critique of a flaw."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "Low", "helpfulness_label": "Moderate", "actionability_rationale": "The reviewer explicitly states their intention to seek clarification and provide references regarding the use of Hamming distance as a loss function in the context of CRF. This indicates a clear and direct action to be taken on their part. The reviewer also points to a specific example (Example 2) when mentioning the 'common' practice, which further clarifies the intended action.", "grounding_specificity_rationale": "The reviewer refers to a specific part of the paper (Example 2) when mentioning the 'common' practice of using Hamming distance as a loss function in CRF. This demonstrates a clear grounding of the comment in a specific section of the paper. Furthermore, the reviewer specifies the type of Hamming distance being referred to (over the entire parts of the sequence), which adds to the specificity of the grounding.", "verifiability_rationale": "The reviewer makes a claim that the use of Hamming distance as a loss function in CRF is a 'common' practice. However, the reviewer does not provide any evidence or references to support this claim within the review point itself. The lack of supporting evidence makes the claim 1 based on the provided text.", "helpfulness_rationale": "The reviewer's primary goal is to provide references to clarify the use of Hamming distance as a loss function in CRF. While this is a valuable suggestion, it does not directly improve the technical content of the paper itself. The helpfulness is moderate as it addresses a potential point of confusion but doesn't offer concrete improvements to the methodology or experiments."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the suggestion to change the name of the 'Evaluation' element to 'Metrics'. This is a direct and clear action. Furthermore, the reviewer specifies the sections that should be removed and suggests a particular phrasing for the feedback. This demonstrates a concrete understanding of where the change is needed and how to implement it.", "grounding_specificity_rationale": "The reviewer identifies the specific sections that need to be removed ('Evaluation' section) and provides concrete suggestions for how the feedback should be presented (briefly mention the datasets or include them in the captions). This demonstrates a strong grounding in the specific parts of the paper being discussed. The reviewer also explicitly states the desired change, indicating a clear understanding of what needs to be addressed.", "verifiability_rationale": "The reviewer makes a clear claim: suggesting a change in terminology from 'Evaluation' to 'Metrics'. This claim is supported by logical reasoning. The reviewer explains that 'Metrics' is a more precise and widely understood term, which provides a justification for the suggestion. While the reviewer doesn't provide external references, the reasoning is based on common practice and understanding of terminology. The suggestion is a direct and actionable improvement to the paper.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for improvement by recommending the change in terminology and the removal of specific sections. The suggestion is directly aimed at making the paper clearer and more precise. The reviewer's comment is easy for the authors to understand and implement, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests using more objective terms than 'remarkable' and questions the use of that term. While the reviewer doesn't explicitly state an action, the suggestion implies that the authors should change their language. The action of using more objective terms is somewhat vague, but the reviewer does provide a concrete target ('remarkable') which helps the authors understand the desired change. The reviewer also points out the squished axes, which is a specific visual element, further clarifying the intended action for the authors.", "grounding_specificity_rationale": "The reviewer's comment, 'Looking at the axes, which are rather squished, the improvement is definitely there but it would be difficult to characterize it as remarkable,' does not explicitly identify a specific part of the paper being addressed. While the reviewer mentions 'the axes,' this is a general reference and could refer to multiple axes in the paper. The authors cannot confidently determine which part the comment addresses based on this information alone.", "verifiability_rationale": "The reviewer makes a claim by stating, 'Looking at the axes, which are rather squished, the improvement is definitely there but it would be difficult to characterize it as remarkable.' This claim is about the visual presentation of the results (the axes) and the perceived magnitude of the improvement. However, the reviewer does not provide any external references or logical reasoning to support this claim. The claim itself is subjective and lacks verifiable evidence.", "helpfulness_rationale": "The reviewer's comment is helpful because it points out a potential lack of objectivity in the presentation of the results and suggests a way to improve clarity. The reviewer's suggestion to use more objective terms than 'remarkable' is a constructive feedback aimed at guiding the authors to use more precise language. While the comment doesn't explicitly ask the authors to change something, it provides a clear direction for improvement, empowering them to address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the length of the video sequences as an example (e.g., 16 frames), which makes the action somewhat explicit. They point out a limitation without suggesting a complete change.", "grounding_specificity_rationale": "The reviewer mentions the UCF101 dataset and describes the types of inconsistencies observed in the synthesized results (inconsistent motion, changing color, or object disappearing over time). This provides strong grounding as the reviewer identifies the specific dataset and the nature of the problems. However, the reviewer does not delve into the specific details of the inconsistencies within the dataset itself, making it underspecific.", "verifiability_rationale": "The reviewer makes a claim about the observed inconsistencies in the synthesized results for UCF101. This claim is based on their direct observation of the results, making it 3. While the reviewer does not provide a citation or a detailed explanation of why these inconsistencies occur, the claim is based on their direct experience with the results.", "helpfulness_rationale": "The reviewer provides specific observations about limitations in the current implementation and suggests a potential improvement (videos with a longer duration). They also offer a positive comment about the paper's idea and extensive experiments. While the suggestion about longer video sequences is not explicitly detailed, it is a relevant and helpful feedback for future work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer's point is quite explicit about the limitations of the evaluation method. While the point itself is actionable in identifying the problem, the lack of specific details about *how* the evaluation is flawed makes it less actionable in terms of providing concrete steps for improvement. The reviewer's statement directly identifies a problem, making it 3 in pointing out the limitations.", "grounding_specificity_rationale": "The reviewer mentions 'synthetic data' as a limitation. This suggests the feedback isn't directly tied to the actual experimental setup or results, indicating a lack of grounding in specific details. While the *review point* is about the evaluation in general, the specific mention of 'synthetic data' makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer's statement about the evaluation being 'not fully convincing' and based on 'synthetic data' raises questions about the validity and verifiability of the results. The reviewer's statement about the evaluation's limitations isn't wellsupported by specific evidence or strong reasoning, making the claim about the evaluation's limitations 1. The reviewer's statement about the comparison with 5 highlights a difference in assumptions or problem complexity, making the direct comparison less convincing.", "helpfulness_rationale": "The reviewer's statement directly criticizes the evaluation method, indicating a lack of meaningful feedback. The reviewer's statement about the evaluation being 'not fully convincing' and 'not completely fair' strongly suggests a lack of actionable and convincing feedback. The comparison with 5 further weakens the justification for the evaluation method used in the paper."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a question about the impact of bit precision on robustness and suggests an experiment to investigate this. This constitutes an explicit and concrete action that the authors can readily follow. The suggestion to ask about the existing experiment and propose a new one directly points to specific areas for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'numbers of bits in logits' and 'PGD attack,' which are specific technical terms within the field. While not a direct reference to a section or table, these terms strongly imply a specific part of the paper. The reviewer also suggests a specific experiment, adding further grounding. However, the connection could be made more explicit by directly referencing a figure or table related to logit values.", "verifiability_rationale": "The reviewer presents a claim based on intuition: 'intuition suggests that having a 32 bit logit should improve robustness against a more powerful adversary.' This claim is not immediately verifiable with existing data. However, the reviewer also suggests an experiment ('Because intuition suggests that having a 32 bit logit should improve robustness against a larger epsilon in the PGD attack? Because intuition suggests that having a 32 bit logit should improve robustness against a larger epsilon in the PGD attack?'), which provides a pathway for verification. The suggestion to study the effect of bit precision on a PGD attack makes the claim more actionable and verifiable.", "helpfulness_rationale": "The reviewer's comment is 5. It points out a potential area for further investigation (the impact of bit precision on robustness) and suggests a concrete experiment (studying the effect of bit precision on a PGD attack). This directly addresses a potential gap in the authors' understanding and provides a clear direction for future work. It also subtly encourages the authors to consider the practical implications of their model's internal representations."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment states 'modest' and 'further refinement,' which are vague directions. It doesn't tell the author *how* to improve. The action is implied but not explicitly stated or concrete.", "grounding_specificity_rationale": "The comment is general, referring to 'the observed performance enhancements' without specifying *which* enhancements or *where* they were observed. The suggestion to 'further refine' is also general. It doesn't pinpoint a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The comment is a statement of observation ('somewhat modest') and a suggestion ('further refinement'). It doesn't make a claim that needs verification or support. There's no assertion that something is wrong or needs a specific action beyond a general direction.", "helpfulness_rationale": "The comment is relevant in that it points towards improvement, but it lacks specific actionable advice. It's a general statement and a suggestion, not a detailed critique or concrete steps. While it provides some insight, it doesn't empower the author to significantly improve their draft with specific guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer implicitly suggests adding references for the statements about sequencetosequence MT and the application of the framework to summarization. This is an actionable suggestion, though not explicitly stated.", "grounding_specificity_rationale": "The reviewer points out a gap in the paper's content (missing citations) but doesn't specify where these references should be. They are not asking the authors to infer something.", "verifiability_rationale": "The reviewer states the lack of references for the mentioned statements but doesn't provide any justification for why these references are needed. They are not making a claim that requires verification.", "helpfulness_rationale": "The reviewer directly points out missing information (references) that would be beneficial for the authors. They are essentially telling the authors what they need to add, making this feedback 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a discrepancy between equation 9 and Figure 1, suggesting that the output patches described in the equation might not be as described in the figure. This raises a concrete action: to investigate whether the patches are indeed masked versions or if there's a misunderstanding of the equation's implications. The reviewer provides a specific suggestion (bilinear sampling) which indicates a clear direction for the authors to consider. The action is explicitly stated, and the reviewer provides a concrete suggestion, making it actionable.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'eq. 9' and 'Figure 1' when pointing out the discrepancy. This demonstrates a clear identification of the specific parts of the paper being addressed, indicating strong grounding. The reviewer also specifies what they think might be wrong with the patches, adding to the specificity of the feedback.", "verifiability_rationale": "The reviewer identifies a potential issue: the nature of the output patches in equation 9 and its consistency with Figure 1. While the reviewer doesn't explicitly state a claim with supporting evidence like a missing citation, the act of pointing out a discrepancy and asking a question about the implications can be seen as a form of 'verifying' the lack of clarity or consistency in the presentation. The reviewer's suggestion about bilinear sampling implies a potential area for improvement that is worth clarifying.", "helpfulness_rationale": "The reviewer raises a valid point about the potential nature of the output patches in equation 9 and its impact on understanding Figure 1. This information is directly relevant to the authors and could help them implement the method correctly or understand the limitations of the visualization. The reviewer's suggestion about bilinear sampling further enhances the potential helpfulness by highlighting a specific area where clarification might be needed. The feedback is directly applicable to improving the authors' understanding and implementation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action: 'This seems not to have been revisited in the Discussion (which is fine, just delete \u201cDiscussion\u201d).' The reviewer clearly identifies the need to revisit a specific part of the discussion. This is a concrete and actionable suggestion.", "grounding_specificity_rationale": "The review point explicitly identifies the location of the information being referred to: 'Pg.5: \u201cThe training time reduction is less drastic than the parameter reduction because most gradients are still computed for early downsampling layers (Discussion).\u201d'. The reviewer not only knows where the original statement is located but also points out a specific missing step in that section (the discussion of this statement). This demonstrates strong grounding and specificity.", "verifiability_rationale": "The review point makes a judgment about the discussion section: 'This seems not to have been revisited...'. This is a claim about the state of the discussion. While it's verifiable in the sense that you could look at the discussion section to confirm if it was revisited, the review itself doesn't present a claim that requires external evidence or logical reasoning to be considered valid. It's a statement about the current state.", "helpfulness_rationale": "The review point is 5 because it directly points the authors to a specific area of the discussion that needs improvement. It's clear, actionable, and directly addresses a potential improvement to the discussion. The reviewer provides a specific target for improvement, which is a valuable piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment identifies a problem ('the font size is a little bit small') but does not explicitly state what action the author should take to address it. While the specific part of the paper (Figure 6) is mentioned, the action to be taken is not clearly defined. The reviewer points out the issue but doesn't provide a concrete stepbystep guide on how to fix it.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 6' as the specific part of the paper being referred to. It also clearly states the issue as 'the font size is a little bit small' within that figure. This indicates that the reviewer has identified the specific section and the nature of the problem.", "verifiability_rationale": "The comment states a factual observation ('the font size is a little bit small') without providing any external references or logical reasoning to support it. It's a direct statement of a fact, not a claim that requires verification. Therefore, it doesn't fall into the '1' or '1' categories, but the lack of any supporting evidence makes it not fully 'verifiable'.", "helpfulness_rationale": "The comment identifies a valid issue ('the font size is a little bit small') but fails to provide any actionable feedback. It doesn't suggest any improvements or changes to the author's work. The feedback is limited to pointing out a problem without offering a solution, making it less helpful compared to a comment that provides concrete suggestions."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides clear suggestions and questions regarding the introduction and the examples used to illustrate the paper's claims. They suggest focusing on problems with nondecomposable loss functions and recommend specific algorithms like Hogwild. These are concrete actions the authors can take to improve their work. The reviewer also asks for clarification on the goal of the paper, which is a direct action the authors should undertake.", "grounding_specificity_rationale": "The reviewer's suggestions are broad and focus on alternative problem areas rather than pinpointing specific issues within the paper itself. They don't identify a specific section, table, figure, or unique element of the paper that needs improvement. While they mention the second paragraph, they don't specify which part of that paragraph is problematic. The suggestions are general and lack specific references to the paper's content.", "verifiability_rationale": "The reviewer expresses doubt about the paper's claims regarding the importance of interprocess communication (IPC) based on the examples in the second paragraph. They suggest alternative problem areas and recommend specific algorithms. While the reviewer identifies a claim (the relevance of IPC), they express uncertainty about its veracity based on the provided examples. The paper's introduction could be stronger in establishing the motivation and the specific problems it addresses. There's no direct quote from the paper that the reviewer is questioning, but the lack of clarity and the examples provided make it difficult to verify the claims made in the introduction. The reviewer's suggestions are more about guiding future research directions rather than directly pointing to a verifiable flaw in the current work.", "helpfulness_rationale": "The reviewer's comments are valuable and directly address potential weaknesses or areas for improvement in the paper's introduction and the examples used. They suggest focusing on problems with nondecomposable loss functions and recommend specific algorithms like Hogwild. These suggestions are actionable and provide clear directions for the authors to follow. The reviewer's questions about the goal of the paper also highlight areas where the authors can improve their communication and clarity. The suggestions are specific and directly relevant to the content of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem of an unfair comparison between CPEF and PMEF (line 529lin534) and provides a concrete suggestion for improvement by comparing CPEF with another pretrained model, ExpertBert. The reviewer clearly identifies the issue: PMEF lacks a pretrained module, while CPEF does, and suggests a specific comparison to highlight CPEF's innovation. This is an explicit and concrete action that the authors can readily implement.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 3,' 'CPEF,' 'PMEF,' and the concept of 'pretrained module' when explaining the unfair comparison. This demonstrates a clear and accurate grounding of the discussion in the specific elements of the paper being compared. The reviewer not only identifies the models but also highlights a specific feature (pretrained module) that differentiates them.", "verifiability_rationale": "The reviewer makes a claim about the unfairness of the comparison between CPEF and PMEF due to the lack of a pretrained module in PMEF. While the paper doesn't explicitly state that the comparison is 'unfair' in a definitive sense, the reviewer's reasoning is based on the established differences between the models. The suggestion to compare with ExpertBert is a logical next step based on the described characteristics of CPEF and the reviewer's understanding of pretraining. The claim is supported by the logical comparison of the described models, making it 3.", "helpfulness_rationale": "The reviewer's point directly addresses a valid concern regarding the fairness of the comparison between CPEF and PMEF. By suggesting a comparison with another pretrained model, ExpertBert, the reviewer provides a concrete and actionable suggestion for the authors to consider. This directly helps the authors understand the potential advantages of CPEF's pretraining approach and guides them in further evaluation. The suggestion is directly related to the identified problem and offers a clear path for improvement, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "3. Fully Grounded and Not Specific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point does not provide an explicit instruction on how to fix the broken hyperlink. It only states the problem, making it 1.", "grounding_specificity_rationale": "The review point explicitly mentions 'footnote 3 and 4', clearly identifying the specific part of the paper being referred to, making it fully grounded.", "verifiability_rationale": "The review point is a factual statement about the hyperlink not working, not a claim requiring verification. Therefore, it is a normal statement ('X').", "helpfulness_rationale": "The review point identifies a problem but does not offer any suggestions or guidance on how to resolve it. It is therefore 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need to revise the modeling section and provides specific examples like 'better formalization' and 'external parameters'. This indicates a clear and actionable suggestion for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'the modeling section' and specifically mentions 'Label Embeddings'. This demonstrates a clear identification of the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer states a position about the modeling section's clarity ('I suggest to revise a bit the discussion...') but does not provide specific evidence or references to support this claim. The suggestions are recommendations for improvement rather than verifiable facts.", "helpfulness_rationale": "The reviewer provides concrete suggestions for improving the clarity of the modeling section and the role of Label Embeddings. These suggestions are directly aimed at helping the authors understand and implement the proposed changes."}
{"actionability_label": "4", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point directly asks a question about the order of operations regarding temperature and uncertainty calibration, and it also raises a question about the effect of the regularization term H. Both of these are explicit and point to a lack of clarity in the paper's explanation of these concepts. The reviewer is asking for specific details about how these techniques are integrated and applied, which is a clear indication of an actionable point.", "grounding_specificity_rationale": "The review point explicitly refers to specific parts of the paper, namely lines 155160 and 133136, to explain its confusion about the relationship between the regularization term H, temperature calibration, and uncertainty calibration. The reviewer is pointing to specific elements mentioned in the paper, making it fully grounded.", "verifiability_rationale": "The review point makes specific claims about the paper's methodology. It states that the regularization term H 'appears that they are both are required to do uncertainty calibration' and then asks a question about the effect of H on confidence. The reviewer provides a specific claim about the effect of H (reducing entropy makes predictions more confident), which is verifiable by understanding the typical effect of entropy minimization. The paper's description of H's role and the reviewer's understanding of its effect are both clearly stated, making this claim verifiable.", "helpfulness_rationale": "The review point raises two distinct and valid questions about the paper's methodology. The confusion about the order of operations and the effect of the regularization term H are significant points that, if clarified, would greatly improve the paper's clarity and impact. Both questions are directly related to the paper's claims and would provide valuable information to the authors, making this a 5 review point."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for an explanation of the objective and constraints in (3) and provides a concrete request: \"explain what are the objective and the constraints in (3)\".", "grounding_specificity_rationale": "The reviewer refers to \"Theorem 3\" and specifically asks about the objective and constraints in \"(3)\", indicating a clear identification of the relevant part of the paper.", "verifiability_rationale": "The reviewer states their understanding of the theorem's importance, which could be interpreted as a claim that the theorem is significant. However, they are not providing justification or evidence for this claim within the review point itself. The request is more of a request for clarification than a claim requiring verification. Therefore, it's 4 as the claim is supported by the context of the theorem's importance, but lacks explicit justification within the review point.", "helpfulness_rationale": "The reviewer explicitly states they would benefit from the explanation, indicating the comment is relevant and potentially useful for the authors. However, the comment itself doesn't provide the explanation, so it's not a fully helpful comment in itself. It's more of a request for information that is likely to be useful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'FLOT cost matrix in Algorithm 1 is not defined.' This clearly indicates an action the authors should take: find the definition of the FLOT cost matrix within Algorithm 1. The action is directly stated, making it explicit. Once the location is identified, the action of finding the definition is also concrete.", "grounding_specificity_rationale": "The comment explicitly mentions 'Algorithm 1' and states 'FLOT cost matrix is not defined' within that specific algorithm. The authors can directly identify the section and the specific element that needs a definition. This is a clear and precise reference, making it 5.", "verifiability_rationale": "The comment contains a claim: 'FLOT cost matrix in Algorithm 1 is not defined.' While the comment itself doesn't provide verification for this claim, it sets up a potential issue. The verifiability is limited as it doesn't offer a source or explanation for the undefined cost matrix. The claim is stated, but the supporting evidence is missing.", "helpfulness_rationale": "The comment identifies a specific element in Algorithm 1 (the FLOT cost matrix) that appears to be missing a definition. This is likely to be helpful for the authors as it points to a potential area of confusion or a necessary piece of information that is overlooked. It directs the authors to a specific location and highlights a likely issue."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks the authors to 'prove' the convergence of the second term in Eq. (30). This is a direct and specific request for action. The action is also concrete, as the authors are asked to demonstrate the convergence using a logical argument or mathematical proof. The reviewer clearly identifies the action and provides the specific location of the problem within the paper.", "grounding_specificity_rationale": "The reviewer refers to 'the bound in Theorem 2, Eq. (30)' and 'Grunewalder et al, 2010, Eq. (27)'. While they provide equation numbers, they do not explicitly state which specific theorem or section of the paper corresponds to 'the bound in Theorem 2'. This requires the authors to infer the location based on the context. However, once the location is inferred, the reviewer clearly specifies the 'second term' in Eq. (30) that needs proving. This demonstrates a high level of specificity regarding the issue.", "verifiability_rationale": "The reviewer presents a request for a 'proof' as a question. This is not a direct statement of a claim that needs verification. However, the request itself implies a need for justification and a logical argument to support the claim that the second term converges to 0. The reviewer is asking the authors to provide evidence (the proof) to support their work. While there isn't an explicit claim being made, the request for proof serves as a form of implicit claim verification. The lack of an external reference for this specific proof makes it 3.", "helpfulness_rationale": "The reviewer explicitly states, 'I'm willing to increase my score if the authors can address my questions properly.' This indicates a strong desire for the authors to improve their work based on the feedback provided. The request for a proof is a specific and potentially crucial piece of feedback that could help the authors identify and correct a flaw in their analysis. The reviewer's willingness to reward progress suggests that this feedback is valuable to them."}
{"actionability_label": "3", "grounding_specificity_label": "Ungrounded and Not Specific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review points out a *possibility* and asks a question about Algorithm 2. While it identifies a potential feature, it doesn't explicitly * tell the authors how to implement it or what changes to make. The criticism about 'avg' not being used and the unclear meaning of j' and i' are suggestions for improvement, not direct actionable steps for the authors. The request to update the response is a request, not an action.", "grounding_specificity_rationale": "The review refers to \"Algorithm 2\" generally. It doesn't specify *which* part of Algorithm 2 is problematic or *what* the issue is within that algorithm. The variables 'j'' and 'i'' are mentioned, but their connection to specific parts of the paper or algorithm isn't made explicit. The suggestion to update Algorithm 2 is a broad idea, not a specific reference to a part of the paper.", "verifiability_rationale": "The review states a *possibility* and questions the implementation of Algorithm 2. It doesn't make a claim that needs verification or justification. The suggestion to update Algorithm 2 is a suggestion, not a claim requiring evidence.", "helpfulness_rationale": "The review raises a valid point about the potential functionality of Algorithm 2 and points out a lack of clarity. However, it doesn't provide concrete steps for the authors to take or specific suggestions for improvement based on this observation. The request to update the response is a request, not a helpful suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the observed trend in Figure 5. While the question itself is a request for information, the *action* the reviewer is implicitly suggesting is to investigate *why* the accuracy drops and whether overfitting is a likely cause. This is not an explicit instruction on how to perform this investigation. The reviewer is prompting for further analysis rather than directly instructing on a specific action to take.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 5' but does not explicitly state which specific part of their paper this figure corresponds to. They use a general reference. This makes the grounding weak. Furthermore, the questions are general and do not specify which aspect of the figure or the model is experiencing the accuracy drop or the potential overfitting.", "verifiability_rationale": "The reviewer is posing questions, which can be interpreted as a claim that there is something to investigate. However, the reviewer does not provide any evidence or reasoning to support the claim that overfitting is the cause of the accuracy drop. There is no logical reasoning, common knowledge, or external references provided to back up this claim.", "helpfulness_rationale": "The reviewer's question is valuable as it prompts the authors to consider potential reasons for the accuracy drop and to investigate the possibility of overfitting. This encourages further analysis and investigation. While it doesn't provide a direct solution or a definitive answer, it is a helpful starting point for the authors to explore and potentially improve their model. The questions are specific enough to guide further research, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue with the distance calculation between episodes of different lengths and proposes a solution. They also clearly indicate the location in the code where this issue occurs. This is a direct and actionable suggestion for the authors.", "grounding_specificity_rationale": "The reviewer not only identifies the issue but also specifies *where* the problem lies in the code (between lines 282 and 283) and *how* the comparison is being done (padding the shorter sequence with the last state). This provides a clear and precise reference point for the authors.", "verifiability_rationale": "The reviewer provides a clear explanation of their understanding of how the code handles the comparison of episodes with different lengths. They also explain the potential drawback of not normalizing by the trajectory length. This information is verifiable and logically sound.", "helpfulness_rationale": "This review point is 5. By explicitly stating the issue with the distance calculation and proposing a solution, the reviewer directly addresses a potential ambiguity in the implementation. This will likely improve the clarity and reproducibility of the work, and potentially the performance of the method by addressing a valid concern raised by the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'In the experiment, the author didn\u2019t consider Vision Transformer' and asks a question about the 'pruning strategy will be different in self attention layers?'. These are explicit statements that suggest what the author should have done. While the suggestions are somewhat vague, the reviewer points to specific areas for improvement, making the actions 3. However, the lack of concrete steps on how to implement these suggestions makes it less actionable than a review that provides a clear, stepbystep improvement.", "grounding_specificity_rationale": "The review point explicitly mentions 'Vision Transformer' and 'self attention layers'. These are specific parts of the model architecture. The reviewer does not mention any unique elements of the paper, relying on the general knowledge of these architectural components. Therefore, the grounding is weak, as the reviewer can infer these parts but cannot precisely identify them without further context from the author.", "verifiability_rationale": "The review point states 'It is unsure if such technique is still working for larger image dataset such as ImageNet.' This is a claim that requires verification. However, the reviewer does not provide any specific evidence or references to support this claim within the review point itself. The suggestion to investigate the pruning strategy in selfattention layers is also vague and lacks specific guidance. Therefore, the claim is not wellsupported, making it 1 based solely on the information provided in this review point.", "helpfulness_rationale": "The review point raises important questions about the completeness of the experimental setup and the potential behavior of the model on larger datasets. The suggestion to consider Vision Transformers is a valuable point for improvement. The question about the pruning strategy in selfattention layers also points to a potential area for further investigation. While the review point is primarily negative in framing, it offers concrete suggestions for the authors to consider, making it 3 in guiding the authors towards further exploration and improvement of their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: \"Fig.1 to Fig.3 are very difficult to parse.\" They then provide specific details about what makes them difficult: \"The texts in the figures are too small,\" \"The inputs and outputs for each task are not clearly explained,\" and \"The captions are not selfcontained, and it is also very hard to link them to certain parts of the main text.\" These are all concrete actions or suggestions that the authors should take. The reviewer is not just stating a problem but also offering potential solutions.", "grounding_specificity_rationale": "The reviewer mentions \"Fig. 1 to Fig. 3,\" which provides some level of grounding by identifying the specific figures. However, the reviewer does not specify *which* part of the figures is difficult to parse, which texts are too small, or what specific aspects of the inputs/outputs are unclear. The descriptions of the issues are general and do not pinpoint the exact element within the figure that is causing the parsing difficulty. The captions are mentioned as being not selfcontained, but the specific details of why they are not selfcontained are not provided.", "verifiability_rationale": "The reviewer makes a claim: \"Fig.1 to Fig.3 are very difficult to parse.\" This is a statement that requires justification. The reviewer then provides suggestions for improvement: \"The texts in the figures are too small,\" \"The inputs and outputs for each task are not clearly explained,\" and \"The captions are not selfcontained, and it is also very hard to link them to certain parts of the main text.\" These suggestions, while not direct citations, offer evidence for the claim. They point towards *why* the figures are difficult to parse. The reviewer is not just stating a problem but also offering potential solutions and implicitly suggesting how the problem can be addressed.", "helpfulness_rationale": "The reviewer provides a clear and specific critique of the figures. They identify the exact issue: difficulty in parsing. They also offer concrete suggestions for improvement: making the text larger, explaining inputs and outputs more clearly, and making the captions selfcontained and better linked to the main text. These suggestions are directly actionable and would significantly improve the clarity of the figures. The reviewer is not just pointing out a problem but also providing a roadmap for how to fix it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing models in a new setting (conditional generation task) and cites a specific conditional framework from recent work as a baseline. While it implies an action (conducting the comparison), it doesn't explicitly state the steps or the expected outcome, making it 2.", "grounding_specificity_rationale": "The review point explicitly refers to 'Table 2' and 'Table 3' and mentions 'conditional generation task', 'continuous diffusion model', 'discrete diffusion model', 'GDSS', and 'DiGress'. This provides clear grounding to the specific parts of the paper being addressed and the models being compared.", "verifiability_rationale": "The review point makes a claim that the continuous diffusion model (GDSS) outperforms the discrete diffusion model (DiGress) based on the results in Table 2. It also suggests using a specific conditional framework from recent work as a baseline for the conditional generation task. The claim is supported by the performance comparison in Table 2 and the cited framework, making it 3.", "helpfulness_rationale": "The review point provides a relevant comparison between continuous and discrete diffusion models based on their performance in Table 2 and suggests a specific conditional framework from recent work as a baseline for the conditional generation task. This offers valuable context and guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"replace 't' with the size of T\", which is a direct and actionable suggestion. This clearly indicates what change should be made to the code. There is no ambiguity about the action to be taken.", "grounding_specificity_rationale": "The reviewer begins with \"In the histogram intersection kernel\", which clearly identifies the specific part of the paper or code being addressed. This demonstrates strong grounding as the section, code snippet, or unique aspect is explicitly mentioned.", "verifiability_rationale": "The reviewer suggests replacing 't' with the size of T 'for clarity'. While the reasoning is implied (improving readability), the suggestion itself is a logical and direct action that can be verified by implementing the change and observing the resulting clarity. There is no need for external references to validate this suggestion.", "helpfulness_rationale": "The reviewer provides a specific and actionable suggestion to improve the clarity of the code by changing the variable name. This directly addresses a potential readability issue and is a valuable feedback point for the authors. The suggestion is clear and directly targets a potential improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point provides explicit suggestions for improvement, such as checking transcription norms at specific lines and correcting typos. The reviewer also suggests clarifying language, which is a concrete action. While the suggestions are general, they point to specific areas for the authors to focus.", "grounding_specificity_rationale": "The reviewer points out general areas for improvement like 'writing clarity,' 'typos,' and 'formatting,' which could be interpreted as weak grounding. However, the reviewer also provides specific line numbers and examples of errors, making the grounding more concrete. The suggestion to clarify language, while general, refers to a specific aspect of the paper (the method section).", "verifiability_rationale": "The review point makes claims about the issues in the paper, such as the need to check transcription norms and correct typos. While the reviewer doesn't provide explicit references for these specific issues, the claims are based on common knowledge about writing and formatting. The suggestion to clarify language is also verifiable.", "helpfulness_rationale": "The review point identifies specific issues and provides suggestions for improvement. However, the suggestions are somewhat general and could be more comprehensive. For example, while the typo is identified, the specific type of typo and how to correct it could be elaborated. The lack of specific references makes it less helpful than a review with external citations."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'Notation is confusing' and provides specific suggestions ('M and N are used without definition', 'Suggestion  Spell out F.L.T.R in figure 4', 'Figure 1 text is too small to see', 'It is recommended to have notation and figure crossreferencing (e.g. M and N are not shown in the figure)'). These suggestions are direct and actionable, indicating a clear understanding of where the confusion lies and how it can be addressed.", "grounding_specificity_rationale": "The reviewer states 'Notation is confusing' without specifying which part of the paper or figure this refers to. While the reviewer suggests improvements ('Suggestion  Spell out F.L.T.R in figure 4'), they don't explicitly link the confusion to 'M' or 'N' or Figure 1. Therefore, the grounding of the issue is not precise.", "verifiability_rationale": "The reviewer makes a claim by stating 'Notation is confusing' and then provides suggestions for improvement ('Suggestion  Spell out F.L.T.R in figure 4', 'Figure 1 text is too small to see', 'It is recommended to have notation and figure crossreferencing (e.g. M and N are not shown in the figure)'). This claim is supported by the concrete suggestions the reviewer offers.", "helpfulness_rationale": "The reviewer's comment is 5 because it directly points out a specific area of confusion ('Notation is confusing') and offers clear, actionable steps to address it ('Suggestion  Spell out F.L.T.R in figure 4', 'Figure 1 text is too small to see', 'It is recommended to have notation and figure crossreferencing (e.g. M and N are not shown in the figure)'). These suggestions are directly aimed at improving the clarity and presentation of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly identifies a potential issue with the notation in Algorithm 1, specifically the use of 'p' for both a probability and a dummy variable. While it doesn't provide a detailed explanation of why this is confusing, it clearly points out a potential source of ambiguity and suggests a solution (using a different symbol). This makes it a partially actionable comment as the action of using a different symbol is clear, but the initial identification of the issue could be more explicit about the context of why 'p' is confusing.", "grounding_specificity_rationale": "The comment explicitly refers to 'Algorithm 1' and 'Phase 2' of the paper, clearly identifying the specific part of the paper being addressed. The suggestion to 'use a different symbol' is directly applicable to the identified location. Therefore, the comment is fully grounded as it accurately pinpoints the section being discussed. It is also specific as it directly suggests a solution related to the identified issue.", "verifiability_rationale": "The comment points out a potential source of confusion regarding the notation 'p' in Algorithm 1. While it doesn't provide a definitive reason *why* 'p' is confusing (e.g., it's used for probability elsewhere, the context isn't immediately obvious), it identifies a valid potential ambiguity in common notation. The suggestion to use a different symbol implies a lack of clarity in the current notation. Therefore, the comment is 3 as it points to a potential issue that could be clarified with further explanation or examples.", "helpfulness_rationale": "The comment is clear, concise, and directly addresses a potential issue that could hinder understanding of Algorithm 1. It suggests a straightforward solution (using a different symbol) that is directly applicable to the identified location. This makes the comment 5 as it provides a clear and actionable suggestion to improve the clarity of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests a mathematical formulation in the appendix and a figure depicting the WiC task. While these are suggestions for improvement, they are not explicit or concrete actions for the authors to take immediately. The reviewer identifies a lack of detail in the highlevel description, which is a vague suggestion.", "grounding_specificity_rationale": "The reviewer does not explicitly name a specific section, table, figure, or unique aspect of the paper when referring to the highlevel description or the figure. The mention is more general, such as 'highlevel description' and 'depicting the WiC task'. This indicates weak grounding as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer makes a claim that there is a lack of detail in the highlevel description and suggests improvements to the figure. However, the reviewer does not provide specific examples or references to support this claim. The suggestions are general and lack logical reasoning to justify them as improvements for the WiC task. Therefore, the claim is 3 but lacks key elements like examples or references.", "helpfulness_rationale": "The reviewer offers suggestions for improvement, such as a mathematical formulation in the appendix and a figure depicting the WiC task. These suggestions are relevant to the task and could be helpful for the authors. However, the suggestions are somewhat vague and lack immediate actionability. The reviewer identifies a lack of detail, which is a general statement without specific guidance on what needs to be added or improved."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly points out the missing experimental details for the YOSO pretraining experiment with Linformer in Figure 4, stating 'However, the pretraining experiment part does not provide steps vs ppl of linformer with YOSO in Figure 4.' This is an explicit action the authors should take. The reviewer also asks for the 'iteration wise convergence' comparison, which is another explicit action. While the reviewer doesn't provide the *specific* steps to take, they clearly identify the gap in the information.", "grounding_specificity_rationale": "The reviewer mentions 'YOSO' and 'Linformer' and refers to 'Figure 4' as the location where the missing information should be. However, they don't explicitly state the exact section, table, or unique aspect of the paper where this information is supposed to be found. The reference to Figure 4 is helpful but not a direct pinpoint. The reviewer also asks for an 'explanation' of the performance difference, which is a general request for information rather than a specific detail within a section.", "verifiability_rationale": "The reviewer presents a 'criticism' of the experimental setup by stating 'However, the pretraining experiment part does not provide steps vs ppl of linformer with YOSO in Figure 4.' This is a claim that needs to be addressed. The reviewer also presents a 'question' about the performance difference on downstream tasks, which is another claim that requires justification. While the claims are not necessarily false, they are not fully supported by the information present in the paper, making them 3.", "helpfulness_rationale": "The reviewer's review points directly address specific areas where the paper could be improved. They identify a missing piece of information ('steps vs ppl of linformer with YOSO in Figure 4') and a lack of explanation for a performance difference ('Is there any comparison to an explanation that can analyze this difference in performance?'). These points are directly actionable and would help the authors understand the experimental setup and the results better. The reviewer is not making a negative comment about the work itself, but rather pointing out specific areas for improvement in the presentation and analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly points out a discrepancy between the abstract and the text regarding the proposal distribution. They state that the abstract implies the proposal upper bounds the target, while the text clarifies this is not the case. This is a clear indication of an actionable point, as the authors need to clarify the abstract. The reviewer also specifies the location of this discrepancy (abstract and text) and the key property (upper bounding), making it concrete for the authors to act upon.", "grounding_specificity_rationale": "The reviewer directly references the abstract and the text, clearly identifying the specific part of the paper being addressed. They mention 'proposal distribution' and 'target distribution' as the specific elements. While they don't provide a literal section number, the concepts are very specific, allowing authors to identify the relevant parts. The comment is fully grounded as the authors can infer the exact sections based on the mentioned concepts.", "verifiability_rationale": "The reviewer makes a claim that 'the authors themselves clarify in the text.' This is a clear statement of opinion. While they don't provide a specific reference to the clarification, the claim itself is verifiable based on the reviewer's statement. The reasoning is that the reviewer is stating a fact about the text, which can be confirmed by the authors.", "helpfulness_rationale": "The reviewer identifies a potential point of confusion for the authors by highlighting the discrepancy between the abstract and the text. This is likely to be helpful as it points to a specific area where the text needs to be more precise. The reviewer's comment is specific about the location of the issue (abstract and text) and the nature of the discrepancy (implied upper bounding vs. clarified nonupper bounding). However, the exact location of the clarification within the text is not specified, which could make it slightly less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer points out a potential confusion arising from referencing '15' as 'PointNet'. While the reviewer identifies a problem, they don't offer a direct action or solution for the authors. They are highlighting a potential ambiguity in the referencing. The authors would need to determine if '15' is indeed the intended PointNet paper and adjust the citation accordingly. The reviewer doesn't specify how to resolve the confusion.", "grounding_specificity_rationale": "The reviewer states, 'Figure 1: Referring to 15 as \"PointNet\" is confusing when this name doesn't appear anywhere in this paper (15) and there exists another paper with this name.' The reviewer does not specify where in the paper the citation '15' is being used, nor does they specify what is wrong with the citation. The comment is general and does not pinpoint the exact location or nature of the issue.", "verifiability_rationale": "The reviewer makes a claim: 'Referring to 15 as \"PointNet\" is confusing...'. However, the reviewer does not provide any evidence or justification for this claim. They state the problem but do not explain why it is confusing or provide any supporting information.", "helpfulness_rationale": "The reviewer's comment points out a potential source of confusion for the authors. They highlight a lack of clarity in the referencing. While the reviewer identifies a problem, they do not offer a concrete solution or suggestion for the authors to address the confusion. The authors would need to determine if '15' is the intended PointNet paper and adjust the citation accordingly, but the reviewer doesn't provide guidance on how to do this."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the optimality of the policy gradient method in Eq. 6 for solving the optimal problem in Eq. 5. While the reviewer implies a desire for clarification and suggests a potential ambiguity in the learning aspect, the action is not explicitly stated. The reviewer does not directly instruct the authors to consider this or provide a concrete action to take. The reviewer is asking a question that implies a desire for improvement, but the specific action is not clearly defined.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Eq. 6' and 'Eq. 5' in their review point. They also mention 'Line 132' and 'd\u03c0(s)'. This clearly indicates that the reviewer has identified specific parts of the paper and can accurately pinpoint them. The language used is precise and directly refers to these elements.", "verifiability_rationale": "The reviewer poses a question about whether the policy gradient in Eq. 6 solves the optimal problem in Eq. 5. This constitutes a claim that needs to be supported. However, the reviewer does not provide any evidence, reasoning, or references within their review point to back up this claim. They are asking a question, but not making a statement that requires verification. The lack of supporting evidence makes this claim 1 based solely on the information provided in the review point itself.", "helpfulness_rationale": "The reviewer points out a potential ambiguity in the learning aspect and suggests clarifying the notation 'd\u03c0(s)'. This is a valuable feedback point as it directly addresses a potential point of confusion for the authors. The reviewer is suggesting a concrete improvement or clarification, making this a 3 review point. However, it doesn't offer a complete solution or a specific action to take beyond clarification."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "2 (2)", "verifiability_label": "X (X)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point asks a question about a technical detail within the proposed algorithm (Gaussian distribution) rather than explicitly stating an action the author should take. While the question implies a desire for clarification, it doesn't directly instruct the author on how to modify or improve the algorithm. Therefore, it is not explicit in terms of actionability. The action is implied but not stated.", "grounding_specificity_rationale": "The review point asks a question about a methodological choice ('general gaussian distribution') within the algorithm. However, it does not specify *which* part of the paper or algorithm this refers to. The reference is general ('the proposed algorithm'), making it difficult to pinpoint the exact location and the nature of the difference between 'general' and 'isotropic' gaussian. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point is a question about a technical detail (Gaussian distribution) and the difference between two types of it. It does not contain a claim that needs verification. The information can potentially be verified through knowledge of statistical distributions or by referring to the paper's methodology section if the algorithm is welldocumented. However, since there is no explicit statement being made, it doesn't fit into the 'claim extraction' process for verifiability. Therefore, it can be considered as having 'X (X)'.", "helpfulness_rationale": "The review point asks a question about a technical detail within the proposed algorithm. While this can be helpful for the author to understand the method better, it does not directly suggest a concrete action to improve the algorithm or the draft. It's a request for clarification rather than a directive for improvement. Therefore, it is not 5 in terms of providing actionable feedback for enhancement."}
{"actionability_label": "5", "grounding_specificity_label": "N/A", "verifiability_label": "N/A", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action (freezing partitioning) and explains its potential negative consequences (risky choice, strong assumptions). It directly suggests an improvement (at least discuss the limitations of this). This fits the definition of high actionability as the action is both explicit and concrete.", "grounding_specificity_rationale": "N/A", "verifiability_rationale": "N/A", "helpfulness_rationale": "The comment is a direct and constructive suggestion for improvement. It tells the authors what to consider (freezing partitioning) and why (risky choice, strong assumptions). It offers a potential solution (at least discuss the limitations of this), making it 5. The reviewer is taking a specific action to improve the paper, which is a valuable contribution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a missing justification for their choice, making it actionable for the authors. The request for explanation is a clear indication of a potential improvement needed in the paper. While the reviewer identifies a potential weakness, the action itself (asking for explanation) is clear.", "grounding_specificity_rationale": "Identical to actionability. The reviewer explicitly states a missing justification for their choice, making it actionable for the authors. The request for explanation is a clear indication of a potential improvement needed in the paper. While the reviewer identifies a potential weakness, the grounding specificity is the same as actionability.", "verifiability_rationale": "The reviewer makes a claim about the paper's methodology (that it should explain the choice of link prediction accuracy). The verifiability depends on the paper's content. The reviewer provides a clear claim that can be supported or unsupported based on the paper's justification for their early stopping method.", "helpfulness_rationale": "The comment directly addresses a potential weakness in the paper's methodology by asking for justification. The helpfulness depends on whether the authors provide the requested justification. The reviewer's comment is relevant to the paper's methodology and could be 5 if the authors address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly asks a question about a specific implementation detail ('how to set a reasonable classimbalanced task?'). This is a clear call for action. The request for 'concrete details' makes it 5 by specifying the desired information.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'sampling classimbalanced tasks' and asks for 'concrete details'. This clearly identifies the specific part of the paper being addressed and requests specific information, making it highly grounded and specific.", "verifiability_rationale": "The reviewer is not presenting a claim that needs verification. They are asking for a method or guidance on setting up the experiment. While the answer will likely involve explaining the fewshot setting and its implications for class imbalance, the review point itself doesn't present a claim that needs verification. It's more of a request for information that will then be used to verify something else. The borderline nature of the request makes it 3 as it implies a desire for a verifiable answer (i.e., how to *do* it).", "helpfulness_rationale": "The reviewer is directly asking for clarification on a specific implementation detail ('how to set a reasonable classimbalanced task?'). This is a common and valuable type of feedback for authors. It directly addresses a potential point of confusion and requests a concrete solution, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the paper lacks details on how the ground truth of sensitivity is achieved and how the pruning process was conducted. While the action (identifying a lack of detail) is clear, the method of achieving this lack of detail (lack of specifics on ground truth and pruning) is vague. Therefore, the action is 3 in that it points to a clear area for improvement, but the specifics are missing.", "grounding_specificity_rationale": "The reviewer is asking for information related to the 'ground truth of sensitivity' and the 'pruning process'. They are not explicitly pointing to a specific section, table, or figure, so the grounding is weak. Furthermore, the reviewer is asking for details on how these were achieved, which are not explicitly stated in the paper, making the specificity vague. Therefore, the grounding is 3.", "verifiability_rationale": "The paper states 'we first estimate a layer's sensitivity by pruning ...'. The reviewer correctly identifies that the claim about estimating sensitivity by pruning lacks sufficient detail and supporting evidence within the paper. There are no explicit references or examples provided to back up this claim. Therefore, the claim is not wellsupported and is 1.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors: 'we first estimate a layer's sensitivity by pruning ... but no details on how actual pruning was done'. This directly points to a missing piece of information that would be beneficial for the authors to understand and potentially replicate the experiments. This is a clear direction for improvement, making the review point 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for definitions of specific technical terms ('proper rotation matrix' and the implications of a nonpositive semidefinite matrix) and how to apply them. This is a clear and direct request for information, making the action 5. The reviewer is not just pointing out a problem but also specifying what needs to be addressed.", "grounding_specificity_rationale": "The reviewer mentions specific line numbers (97, 105106), indicating a clear attempt to pinpoint where the confusion lies. However, they do not explicitly state *what* is unclear about these lines. They are asking for clarification, implying they are unsure, but the specific element of the text that needs clarification is not precisely identified beyond the line numbers. This makes the grounding somewhat specific but not fully grounded.", "verifiability_rationale": "The reviewer points out a lack of clarity in the text and asks for explanations of specific technical terms. This constitutes a claim that the text is unclear and that specific improvements are needed. The reviewer provides a clear reasoning for this claim by stating the areas of confusion and the desired outcome (explanations of the terms). While the reviewer doesn't explicitly cite external references, the request itself serves as a form of justification.", "helpfulness_rationale": "The reviewer's request is clear, targeted, and directly aimed at improving the author's understanding. By asking for specific definitions and explanations, the reviewer provides a concrete suggestion for improvement. This type of feedback is 5 as it directly addresses a perceived weakness and offers a clear path for the author to enhance their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the suggestion to change the term 'g' and proposes a specific alternative ('binary operator'). This indicates a clear intention to provide a concrete change.", "grounding_specificity_rationale": "The reviewer mentions a specific paper (Cohen and Shashua, 2016) as the basis for their suggestion. This provides grounding by linking the suggestion to existing literature. The reviewer also explicitly names the symbol ('g') and suggests a specific alternative ('binary operator'), making the specificity high.", "verifiability_rationale": "The reviewer suggests an alternative term and draws a parallel to existing literature. While the suggestion itself isn't a definitive judgment, the reasoning behind it (improving clarity and aligning with existing practices) provides a basis for potential verification. The reference to Cohen and Shashua, 2016, suggests the validity of the 'binary operator' term within that context.", "helpfulness_rationale": "The reviewer's point is to improve clarity and align with existing literature by suggesting a different term for 'g'. This is a helpful suggestion as it can enhance the paper's presentation and connection to prior work. While it doesn't directly identify a flaw, it offers a concrete improvement suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the action: 'shrinking the captions' and provides a concrete suggestion: 'leaving more space for methods or related work'. This directly addresses what needs to be done.", "grounding_specificity_rationale": "The reviewer explicitly identifies the parts of the paper being addressed by naming 'Fig. 1 and Fig. 2' and clearly specifies the issue as 'large overlaps in their captions'. This demonstrates strong grounding as the specific figures and the nature of the problem are clearly stated.", "verifiability_rationale": "The reviewer states a problem ('large overlaps') and suggests a solution ('shrinking captions'). However, the *reason* for the overlap isn't explicitly stated or justified. There's no external reference or logical reasoning provided to support why shrinking captions is necessary or beneficial beyond improving presentation. The suggestion is presented without a clear explanation of its impact or connection to the identified problem.", "helpfulness_rationale": "The review point directly identifies a clear issue (overlap in captions) and provides a concrete suggestion (shrink captions). It directly links the suggestion to a positive impact on the paper's presentation (leaving space for more content). The language is clear and actionable."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that Vidgen et al, 2021 was included in 'several work' but then explicitly says it 'drops out'. This indicates a clear action the reviewer is pointing out: the absence of Vidgen et al, 2021 despite its potential relevance. The reviewer also asks a question about why it wasn't used, implying a desired action: to include it as a benchmark. The reviewer is directly addressing a specific detail and asking a question about it, making it actionable.", "grounding_specificity_rationale": "The reviewer mentions 'Vidgen et al, 2021' was 'included several work' but then explicitly states it 'drops out'. While the reviewer identifies the specific work, they don't explicitly state which part of Table 2 or the dataset description is causing the concern. The reviewer's question is general, asking why it wasn't used as a benchmark, rather than pinpointing a specific issue within the table or dataset. Therefore, while the work is identified, the specific part of the paper being addressed isn't clearly pinpointed.", "verifiability_rationale": "The reviewer states that Vidgen et al, 2021 'might be really similar to the dataset presented in this work'. This is a claim made without providing any specific justification or evidence. The reviewer doesn't offer any logical reasoning, common knowledge, or external references to support this assertion. The claim is presented as a possibility without any supporting arguments.", "helpfulness_rationale": "The reviewer raises a valid concern about the potential similarity of Vidgen et al, 2021 to their dataset and questions its exclusion as a benchmark. While the reviewer points out a potential gap in the related work discussion, they do not provide specific suggestions or actions for the authors to take based on this observation. The review primarily highlights a question and a potential omission rather than offering concrete guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a fact ('fully realistic datasets will make it hard...') and expresses an opinion ('I agree with the authors' judgement...'). However, they do not provide specific instructions or actions on how to implement this suggestion or address the issue of controlling variations in realistic datasets. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer mentions 'realistic datasets' as a general concept. While they identify the issue of controlling multiple aspects of variation, they do not specify which part of the paper or analysis this refers to. The grounding is present in the general concept, but the specific element is not clearly identified.", "verifiability_rationale": "The reviewer makes a claim by stating 'fully realistic datasets will make it hard...'. They also provide a reason for their agreement ('there is no immediate societal impact'), which serves as some justification for the claim. Therefore, the claim is partially supported but lacks extensive external references or detailed logical reasoning beyond the provided reason.", "helpfulness_rationale": "The reviewer acknowledges a potential limitation of using fully realistic datasets and the authors' judgment regarding societal impact. This shows an understanding of the authors' perspective. While the feedback points to a potential area for improvement in the dataset, it does not offer specific, actionable steps or alternative approaches. The feedback is relevant but lacks the depth of a fully detailed suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of understanding in a specific paragraph (L156166) and suggests considering the Gittins strategy. While the reviewer implies a problem, the action of 'improving clarity' is not explicitly stated as a direct action the authors should take. The suggestion to consider Gittins is a potential action, but the reviewer doesn't explicitly state it as a necessary change. The vagueness of 'dashed lines indicate that the agent can plan ahead...' makes it difficult to pinpoint a concrete action. The reviewer's comment is more about identifying a problem than directly instructing a solution.", "grounding_specificity_rationale": "The reviewer explicitly mentions a specific paragraph (L156166), indicating a degree of grounding. However, when referring to the figure and dashed lines, the reviewer uses phrases like 'the figure' and 'dashed lines,' which are general references rather than precise pointers to a unique element. The reviewer implies the figure and dashed lines are problematic, but doesn't explicitly state their exact location or number.", "verifiability_rationale": "The reviewer makes a claim that the paragraph is hard to understand and suggests considering a specific algorithm (Gittins). The reviewer also claims the explanation of dashed lines is vague. The claim about the paragraph's clarity is somewhat supported by the reviewer's statement. The suggestion to consider Gittins, while not a direct claim, provides context. The claim about the dashed lines being vague is verifiable. However, the reviewer doesn't provide specific examples or external references to support these claims, making the verifiability somewhat low.", "helpfulness_rationale": "The reviewer clearly identifies areas for improvement in the paragraph's clarity and suggests considering a specific algorithm. This indicates a desire for the authors to address these issues. However, the vagueness of the explanation regarding dashed lines ('dashed lines indicate that the agent can plan ahead...') makes it less helpful than it could be. The reviewer doesn't provide concrete steps or suggestions for how the authors should improve the paragraph or understand the dashed lines. While the reviewer points out problems, the lack of specific guidance reduces the overall helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests 'studying the behaviour of the model under higher noise.' This is an explicit action, as it directly states what the authors should do. However, the reviewer does not specify how to implement this action, making it implicit in terms of concrete steps. For example, they could mean increasing the standard deviation value, but don't provide the exact value or how it should be adjusted. Therefore, while the action is explicit, the lack of concrete implementation details makes it somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'the standard deviation of the noise' in the simulation study. This is an explicit identification of the specific part of the paper being addressed. The reviewer uses literal mention to identify this section. Therefore, the grounding is fully grounded. However, the reviewer does not specify *what* is wrong with the current noise level or *why* higher noise is relevant to the study. The connection is implied but not explicitly stated. For example, they could mean the current noise level is too low for meaningful analysis, but this is not explicitly stated.", "verifiability_rationale": "The reviewer states that the standard deviation of the noise is 3, 'but judging from the observations in the plot compared to the true trajectories, this is actually not a very high noise value.' This statement is a claim, as the reviewer is making an inference about the noise level based on the visual comparison of the plot and the true trajectories. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. They are making an observation based on visual inspection, which is not a rigorous verification. Therefore, the claim is not wellsupported.", "helpfulness_rationale": "The reviewer points out a potential misinterpretation of the noise level in the simulation study and suggests studying the model's behavior under higher noise. This is a constructive comment that identifies a potential weakness in the analysis and provides a clear direction for improvement. While the reviewer doesn't specify the exact noise level or how to implement the study, the suggestion is clear and actionable in terms of exploring a different parameter setting. This comment is likely to guide the authors to reexamine their simulation setup and potentially expand their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the performance of DVP on video with different lengths. While it identifies a relevant area of interest, it does not explicitly state what action or improvement should be taken. The reviewer is prompting for an analysis or experiment, but lacks the direct instruction on how to proceed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'DVP performance,' 'video,' and 'different length.' These are specific elements of the paper and the aspect being discussed. The comment clearly identifies the section, table, figure, or unique aspect being addressed.", "verifiability_rationale": "The review point is a question, not a claim that requires verification. It does not present a statement that needs to be supported by evidence or reasoning. It's a request for information rather than a critique or suggestion.", "helpfulness_rationale": "The review point is a question about a specific aspect of the paper. While relevant, it doesn't provide direct feedback or criticism. It's asking for clarification or further information, but lacks the constructive suggestion that would be 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the potential oversight: 'the proposed training objective has ignored the KLdivergence term in equation (3)'. They also explicitly suggest an evaluation: 'Can you evaluate such approximation error, ie. calculate the actual KLdivergence and check whether it indeed approaches zero?'. The action is to calculate and check, which is a concrete and direct instruction for the authors.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Section 3.3: The proposed training objective' and 'equation (3)', providing a clear and specific reference to the part of the paper being discussed. They also explicitly state what is wrong ('the KLdivergence term') and what needs to be done ('calculate the actual KLdivergence and check whether it indeed approaches zero'). This provides strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim: 'the proposed training objective has ignored the KLdivergence term in equation (3)'. This claim is supported by the logical reasoning that the KLdivergence term is a standard component of certain training objectives and its omission could lead to suboptimal performance. The reviewer also suggests a concrete way to verify this claim by 'calculating the actual KLdivergence', which provides a clear method for investigation.", "helpfulness_rationale": "The reviewer provides a specific and actionable point of feedback. They identify a potential methodological oversight and suggest a concrete way to evaluate it. This is valuable information for the authors and directly addresses a potential issue in their work. It guides them on how to potentially improve their training objective and understand its behavior better."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that Section 2 shows 'limited connection' with the 'methodology section'. While this identifies a potential issue, it doesn't specify *how* the connection is limited or what specific aspects of the connection need improvement. The reviewer also mentions the 'theoretical analysis is somewhat simplistic and closely related to 1'. This is a general statement about the analysis, but it doesn't provide concrete steps or suggestions on how to make the analysis more robust or different from 1.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 2' and 'methodology section' when pointing out the lack of connection. This demonstrates a clear identification of the specific part of the paper being addressed, making the grounding 'fully grounded'. However, the reviewer does not specify *what* is lacking in the connection or the theoretical analysis. The mention of '1' is a reference, but it doesn't detail *specific* aspects of the related work that are causing the perceived similarity. Therefore, the specificity is 'underspecific'.", "verifiability_rationale": "The reviewer makes statements like 'In my opinion, Section 2 shows limited connection with the methodology section' and 'the theoretical analysis is somewhat simplistic and closely related to 1'. These statements are claims. However, the reviewer does not provide any evidence, reasoning, or references to support these claims. The connection is presented as an opinion, and the similarity to 1 is also presented as an opinion without any supporting data or analysis. Therefore, the verifiability is '1'.", "helpfulness_rationale": "The reviewer's comments identify areas where the paper could be improved, such as the connection between Section 2 and the methodology and the simplicity of the theoretical analysis. However, the reviewer does not provide specific, actionable suggestions or concrete steps on how to improve these aspects. The feedback is more about pointing out shortcomings than offering clear guidance on how to address them. Therefore, the helpfulness is '2'."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question and suggests a potential area of discussion. While it implies a connection to 'losses' and 'specular areas', it doesn't explicitly state what needs to be done or how to approach this discussion. The action is implied but not directly stated.", "grounding_specificity_rationale": "The review point introduces the concept of 'specular areas' without explicitly pointing to a specific part of the paper or providing a clear definition. The grounding is implied but not direct. The specificity is limited as it doesn't detail why specular areas are interesting or what specific aspects of them they find valuable.", "verifiability_rationale": "The review point is a question prompting for information and does not contain a claim that requires verification. Therefore, it doesn't fit into the verifiability categories.", "helpfulness_rationale": "The review point suggests a specific area of discussion related to 'losses' and 'specular areas'. This points towards a potential direction for improvement and could be helpful for the authors to further analyze the behavior of their model. However, it doesn't provide a concrete action or solution, making its helpfulness somewhat limited."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the paper is not strong enough for ICLR but does not provide any specific actions or suggestions on how to improve the paper to meet the standards of ICLR. The reviewer is expressing a concern without offering concrete steps.", "grounding_specificity_rationale": "The comment is a general assessment of the paper's suitability for ICLR and does not specify any particular section, table, figure, or element of the paper that needs improvement. It is 1 to any specific part of the submission.", "verifiability_rationale": "The comment expresses an opinion about the paper's strength without providing any evidence, logical reasoning, or references to support this opinion. It is a subjective statement without verifiable backing.", "helpfulness_rationale": "The comment is a negative assessment of the paper's suitability for ICLR and does not offer any specific suggestions or actionable steps for the authors to improve their paper. It is not helpful as it does not provide any constructive feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing definition of n_t in Algorithm 2 and the unclear meaning of 'appropriate number' in line 225. This directly points to a lack of information and a specific point of confusion, making the feedback actionable.", "grounding_specificity_rationale": "The reviewer directly references Algorithm 2 and line 225, providing a precise location within the paper where the issue lies. This indicates strong grounding as the reviewer can accurately pinpoint the section being discussed.", "verifiability_rationale": "The reviewer is not presenting a claim in the traditional sense of criticizing or recommending changes. Instead, they are pointing out a missing piece of information and a lack of clarity. Therefore, it fits the 'X' category as it doesn't state an opinion or judgment about the paper.", "helpfulness_rationale": "The reviewer provides clear and specific feedback on where the information is missing and what is unclear. This directly empowers the authors to improve their draft by providing the necessary context or explanation. The feedback is directly actionable and addresses a specific issue."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review points out a *discrepancy* between the claim (''in practice the mixing time is even better'') and the *lack of sufficient support* from the experiments. While it criticizes the claim, it doesn't directly instruct the author on *how to improve* the mixing time or *how to address the lack of support*. The suggestion to provide more support is implicit rather than explicit and concrete.", "grounding_specificity_rationale": "The review criticizes the claim about the 'mixing time' generally. While it *mentions* the mixing time, it doesn't explicitly identify a specific section, table, figure, or unique aspect of the paper related to the mixing time being addressed. The criticism is directed at the claim as a whole, not at a specific detail within that claim.", "verifiability_rationale": "The review makes a claim: ''the claims that 'in practice the mixing time is even better' are not nearly sufficiently supported by the experiments''. This is a claim that requires justification. However, the review point itself doesn't provide specific examples, references, or logical reasoning to support this claim. While it *suggests* more experiments, it doesn't *demonstrate* how the existing evidence is insufficient or *why* it's not sufficient.", "helpfulness_rationale": "The review identifies a potential weakness in the paper (''the mixing time'') and suggests providing more support. While this is generally helpful for the author, the review point itself doesn't offer specific, actionable steps for the author to take. The suggestion to do more experiments is broad and doesn't specify *how* the author should conduct those experiments or *what specific issues* need to be addressed. The helpfulness is limited by the lack of concrete guidance."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing notation for the vectors (x and t), the question about L2 normalization, and the question about the similarity metric. These are direct and actionable suggestions for improvement. The reviewer points out what is missing, which is a clear indication of an actionable point.", "grounding_specificity_rationale": "The reviewer directly references 'line 223' and asks specific questions about the elements of the equation (vectors, normalization, similarity metric). This explicit referencing and the specific nature of the questions demonstrate strong grounding specificity. The reviewer is not just saying 'this is unclear', but pinpointing the exact location and asking for details.", "verifiability_rationale": "While the reviewer doesn't state a claim that something is wrong, they are highlighting a lack of clarity regarding standard practices (vector notation, normalization, similarity metrics). This points to a potential area for clarification and understanding, which can be considered verifiable in the sense that the information is expected and missing. The reviewer is implicitly verifying that the implementation details are not standard.", "helpfulness_rationale": "The review point provides specific information and asks for clarification on key implementation details of the equation. This directly addresses potential ambiguities and missing information for the authors. By pointing out the missing notation, the need for normalization, and the similarity metric, the reviewer is providing concrete feedback that can help the authors understand and reproduce their work. This falls under the category of providing context and identifying areas for improvement, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review points out the importance of running multiple experiments and reporting statistics, which are crucial for reproducibility in deep RL. However, it does not explicitly state what specific changes the authors should make to their experimental setup or results analysis. The suggestion is more about a general good practice rather than a direct, actionable step.", "grounding_specificity_rationale": "The review mentions the need to run experiments multiple times and report statistics but does not specify which particular experiments or which specific statistical measures are problematic. It lacks a clear reference to a specific section or detail within the paper.", "verifiability_rationale": "The review states that running experiments multiple times and reporting statistics are important for reproducibility and assessing the significance of improvements in deep RL. While this is a factual observation, the review does not provide explicit justification for why these practices are crucial or how they directly relate to the current paper's content. The suggestion is presented as a general point rather than a specific critique of the authors' work.", "helpfulness_rationale": "The review raises a valid concern about the reproducibility of deep RL experiments and encourages a more rigorous approach by suggesting multiple runs and statistical reporting. While it doesn't provide specific instructions on how to implement these changes, it highlights a critical issue for the reliability of the results and suggests a valuable direction for future work. This makes it a helpful suggestion for improving the quality of the research."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point asks the authors to check specific locations (Figure 2, Line 433, and Line 468) for consistency. While this is a valid step, it does not explicitly tell the authors what action to take *after* identifying the inconsistency. The authors are not given a concrete instruction on how to address the potential issue.", "grounding_specificity_rationale": "The review point explicitly mentions specific parts of the paper (Figure 2, Line 433, and Line 468). This allows the authors to accurately pinpoint the referenced information, making the grounding fully grounded. However, the review point does not specify what is wrong with these parts or what needs to be improved. It only asks the authors to check for consistency.", "verifiability_rationale": "The review point does not make a claim that requires verification. It is a directive asking the authors to check specific locations for consistency. There is no assertion of a problem or a suggestion for improvement that needs to be supported by evidence.", "helpfulness_rationale": "The review point identifies a potential issue (inconsistency across specified locations) but does not provide a clear path for the authors to address it. It is a diagnostic step rather than a prescriptive one. While it highlights an area for improvement, it does not offer actionable guidance on how to make the necessary changes."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer is suggesting a potential experiment to validate the findings in Figure 1. While this is a valuable suggestion for future work, it is not a direct action that the authors can take to improve their current draft. The reviewer is implicitly suggesting that the current method might be flawed if the figure is not based on real experiments. However, the authors would need to conduct the experiment themselves to confirm this. The suggestion is a potential action, but it's not a concrete step they can take now.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 1' and suggests an experiment to support the phenomenon shown in the figure. The paper clearly identifies the specific part being addressed, and the issue (potential artificiality of the figure) is welldefined. The suggestion is also specific to this figure.", "verifiability_rationale": "The reviewer is making a claim about the origin of Figure 1 (real vs. artificial) and suggesting an experiment to verify it. This claim is not directly supported by the paper itself. The paper presents the figure but doesn't explicitly state its origin or provide justification for its potential artificiality. The suggestion of an experiment is a potential future action, not a verifiable claim about the current work.", "helpfulness_rationale": "The reviewer is asking a question about the origin of Figure 1 and suggesting an experiment to validate it. While this is a valuable suggestion for improving the rigor of the work, it doesn't directly address any identified weaknesses in the current draft. The authors would need to conduct the experiment themselves to confirm the reviewer's concern. The suggestion is a potential improvement, but it's not a direct fix for the current work, making it only marginally helpful."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states they were unclear about the numbers of parameters. This is an explicit statement of a problem. While the reviewer doesn't specify *how* they were unclear, the act of being unclear is concrete. Therefore, the comment is not vague.", "grounding_specificity_rationale": "The reviewer refers to 'parameters used in each approach' without specifying which approach or providing a unique reference point. While the section is implied, the reviewer cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed: 'the numbers of parameters'.", "verifiability_rationale": "The review point does not contain a claim. It is a statement of a lack of clarity. Therefore, it does not require verification. The verifiability score should be 'X'.", "helpfulness_rationale": "The reviewer explicitly states they were unclear about the numbers of parameters. This is a valid point that could help the author improve their draft by making the implementation details clearer. However, the reviewer does not suggest *how* to improve the draft based on this feedback. The feedback is about the information presented, not about actionable improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point does not explicitly state any action or suggestion for improvement. It criticizes the *lack* of statistical significance and the interpretation of results, but does not propose a concrete action to address these issues. Therefore, it is 1.", "grounding_specificity_rationale": "The review point explicitly mentions \"the evaluation results reported in table 1\" and attributes them to \"only three trials for each case.\" It also critiques the interpretation of \"at least two standard deviations better.\" This clearly identifies the specific part of the paper being addressed and details the nature of the issue. The grounding is explicit and specific.", "verifiability_rationale": "The review point makes a factual statement about the evaluation results being based on only three trials. However, it does not provide any evidence or justification for this claim. The verifiability lies in the fact that the number of trials is stated, but the *implication* of this limited number (lack of statistical significance) is not directly supported by evidence within the review point itself. Therefore, it is partially verifiable.", "helpfulness_rationale": "The review point identifies a valid statistical limitation (the small sample size) and points out a potential issue with the interpretation of results. It suggests that the reported improvements might not be reliable. This provides a clear direction for improvement, albeit one focused on statistical rigor. Therefore, it is 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the architecture is 'not clearly explained' and 'refers to Jiang et al. (2019) for details'. This indicates an implicit action, as the reviewer desires a clearer explanation. However, the reviewer does not specify *what* part of the architecture is unclear or what specific details are missing. Therefore, the action is not concrete. The lack of specificity makes it difficult for the authors to take action based on this comment alone.", "grounding_specificity_rationale": "The reviewer states that the architecture is 'not clearly explained' and 'refers to Jiang et al. (2019) for details'. This implies that the authors cannot confidently identify the specific part of the paper being addressed. The reviewer does not explicitly point to a specific section, table, or figure. While the reviewer mentions 'architecture', they don't specify *which* architecture or *what* aspect of it is missing. Therefore, the grounding is weak. The comment does not specify what needs to be addressed in this part, making it not specific.", "verifiability_rationale": "The reviewer makes a claim that the architecture is 'not clearly explained' and 'refers to Jiang et al. (2019) for details'. This is a verifiable claim as it provides a reason for the lack of clarity. However, the reviewer does not provide a direct justification *within this review* for why referring to another paper is a problem or what specific issues it reveals. The verifiability is somewhat limited as it relies on external knowledge or the reader's interpretation of Jiang et al. (2019).", "helpfulness_rationale": "The reviewer points out that the architecture is 'not clearly explained' and 'refers to Jiang et al. (2019) for details'. This is a valuable piece of feedback for the authors as it highlights a crucial missing element in the paper. While the reviewer doesn't specify *what* is missing, the fact that it's not explained and relies on an external reference is a significant issue that the authors would likely find helpful to address. The comment identifies a weakness in the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly identifies the metrics BertScore and BLEURT and suggests a concrete action to improve consistency by standardizing the naming. This provides clear guidance for the authors to follow.", "grounding_specificity_rationale": "The comment explicitly mentions the specific metrics BertScore and BLEURT, allowing the authors to accurately identify the relevant part of the paper. The suggestion to standardize the naming is also specific to these metrics.", "verifiability_rationale": "The comment does not contain a claim in the sense of stating an opinion or making a judgment about the metrics themselves. It points out a factual issue (inconsistent naming) and suggests a solution. Therefore, it doesn't fit into the 'X' category (X) as it does provide a suggestion, albeit not a claim about the metrics' quality.", "helpfulness_rationale": "The comment is clear, concise, and directly points to a minor issue with a specific detail ( naming inconsistency of metrics). It provides a clear suggestion for improvement (standardize naming). This is a helpful, actionable comment for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states weaknesses in the presentation quality of the paper and provides specific examples of areas that need improvement, such as figures, tables, and the 'Dataset' column. The suggestions for improvement are also clear and actionable.", "grounding_specificity_rationale": "The reviewer identifies specific elements of the paper, such as figures, tables, and the 'Dataset' column, as areas of weakness. They also specify the issues within these elements, like 'Figs 1&2', 'tables with a '', 'management of Fig 3 and Table 2', and a '*' in Table 1. This indicates a strong grounding of the comment in the paper's content.", "verifiability_rationale": "The reviewer makes a claim about the presentation quality being a weakness for a highquality publication like NeurIPS. However, they do not provide specific evidence or justification within this review point to support this claim. The suggestions for improvement are general and lack specific references to external works or logical reasoning within this point itself.", "helpfulness_rationale": "The reviewer provides suggestions for improving the presentation of the paper, specifically mentioning figures, tables, and the 'Dataset' column. While the suggestions are general and point to areas for improvement, they do not offer specific examples or detailed guidance on how to achieve these improvements. Therefore, the feedback is 3 but lacks the detail to be considered 4."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential area for improvement (vague explanation) but does not explicitly state how the author should go about making it less vague. It's a statement of observation rather than a directive action.", "grounding_specificity_rationale": "The comment explicitly mentions \"the last paragraph of Section 3 (lines 207210) on the single image case,\" which clearly identifies the specific part of the paper being referred to.", "verifiability_rationale": "The comment is a question and a statement about the explanation's vagueness, not a claim that requires verification. It's an observation about the current state of the explanation.", "helpfulness_rationale": "The comment points out a potential weakness in the explanation, which is generally helpful for the author as it highlights an area for improvement. However, it doesn't provide specific guidance on how to improve it, making it less impactful than a more detailed suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the proposed approach to pretraining has 'limited novelty since it more or less just follows the strategies used in ELECTRA.' While this points to a potential issue, it doesn't explicitly tell the authors what to do. They would need to infer that their approach is similar to ELECTRA and consider the implications for novelty. The action is implicit, requiring the authors to perform further investigation.", "grounding_specificity_rationale": "The reviewer critiques the 'pretraining approach' in general, without specifying a particular section, table, figure, or unique aspect of the paper. The grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer makes a claim about the proposed approach having 'limited novelty' and drawing a comparison to ELECTRA. However, they do not provide any evidence or justification to support this claim. The claim is presented without logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer's point about limited novelty is relevant information for the authors. It could help them understand the contribution of their work and potentially lead to improvements in their approach. However, because the criticism is somewhat vague and lacks specific details, its helpfulness is limited. The authors would need to interpret the comment themselves."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the motivation for the Newton algorithm in section 4 is 'somewhat lacking'. This indicates a clear perception that the existing justification is insufficient. While the reviewer doesn't pinpoint *what* is missing, they identify a concrete area for improvement by suggesting experiments. The lack of a specific action to take makes it only '3'.", "grounding_specificity_rationale": "The reviewer mentions 'section 4' as the area lacking motivation, which demonstrates 'weak grounding' as they are identifying a section but not specifying the exact part within that section. The suggestion to conduct 'experiments along these lines' is general and doesn't specify *which* experiments or *why* they are needed, making it 'underspecific'.", "verifiability_rationale": "The reviewer's comment is not a claim in the sense of presenting a statement that requires justification or evidence. They are expressing a subjective opinion about the lack of motivation. Therefore, it doesn't fit into the 'verifiability' categories as it lacks a claim to be verified.", "helpfulness_rationale": "The reviewer provides a suggestion for improvement by proposing 'experiments along these lines' to motivate the Newton algorithm. This directly addresses a potential weakness in the existing motivation. However, the suggestion is somewhat vague and lacks specific details, making it 'underspecific' and therefore only '3'."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that 'For the majority of language and score combinations (see Figure 3), the impact that the methods have on idiomatic vs random data is similar'. This is an explicit statement about the observed results. Furthermore, the reviewer suggests an alternative interpretation: 'hence the proposed MT modelling methods seem far from idiomspecific'. This suggests a concrete action the authors could take: investigate the reasons for this similarity and consider the alternative interpretation. The reviewer provides a clear observation and a direct suggestion for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 3' and discusses 'idiomatic vs random data' and 'language and score combinations'. While they mention a specific figure, the *review point itself doesn't explicitly name the section, table, or unique aspect of the paper being addressed*. The reviewer is critiquing the *analysis* of the data presented in the paper, but not directly pointing to a specific, clearly labeled part of *their own paper*. The reviewer is making a general observation about the trends in Figure 3, which is a general observation about the paper being reviewed, not a specific element within it.", "verifiability_rationale": "The reviewer makes a claim: 'For the majority of language and score combinations (see Figure 3), the impact that the methods have on idiomatic vs random data is similar; hence the proposed MT modelling methods seem far from idiomspecific.' This is a claim. The reviewer also provides an alternative interpretation: 'Therefore, the results simply appear to indicate that \"better NMT systems are also better at idiomatic translations\".' This alternative interpretation is a logical deduction or inference based on the observed similarity. The reviewer provides a claim and offers a logical explanation for it, which supports the claim.", "helpfulness_rationale": "The reviewer clearly criticizes a specific method (upweighing and KNN) and suggests an alternative interpretation of the results. This points the authors directly towards a potential issue with their method or their interpretation of the results. The reviewer's point is directly relevant to improving their understanding of their results and potentially their method. The reviewer's critique and suggestion are valuable and directly address a potential weakness in the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a discrepancy between the authors' intended behavior (multiple biases) and the implemented behavior (single bias in FFNs). While the reviewer identifies the location of the issue (section 3.4), they don't explicitly state how the authors should adjust the number of biases or provide a concrete solution. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 3.4' where the issue with the feedforward models and the limited number of biases is described. This directly identifies the specific part of the paper being addressed, making the grounding very clear. The reviewer also highlights the confusion about the intended behavior (C biases), further specifying the issue within that section.", "verifiability_rationale": "The reviewer states that 'the fact that they have C biases is confusing' without providing any justification or reasoning. There are no external references or logical arguments to support this claim. The reviewer simply states the perceived issue without explaining why it's a problem or how it should be addressed.", "helpfulness_rationale": "The review point identifies a relevant issue (the discrepancy between the intended and implemented number of biases) and points to its location in section 3.4. However, it fails to provide actionable steps for the authors to address this issue or explain why the situation is confusing. The lack of a clear solution or justification makes the review point less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a potential issue with Equation 8 and suggests a solution (subtracting 's' from dynamic information). While they identify a *potential problem*, they don't explicitly state *what to do* to fix it or how to implement the solution. The action is implied. The reviewer suggests 'subtracting s from the dynamic information' which is vague. They don't specify *how* to perform this subtraction or *why* they think this is the correct approach.", "grounding_specificity_rationale": "The reviewer refers to 'Equation 8' and 'dynamic information' within it. While they mention a specific location, they don't explicitly name the *part* of the paper being addressed. They can *infer* the focus is on Equation 8 and the 'dynamic information' within it, but they don't specify a precise section, table, figure, or unique aspect of the paper. The specificity is about the *type* of information, not a specific element within the paper.", "verifiability_rationale": "The reviewer states a potential issue ('may result in the loss of some dynamic information') and suggests a solution ('subtracting s from the dynamic information'). However, they don't provide any justification for why this is a good solution or how to verify it. They identify a *potential problem* and a *suggestion* for a *potential solution* but lack supporting evidence or reasoning.", "helpfulness_rationale": "The review point identifies a potential issue with a specific equation and suggests a possible solution. However, it lacks concrete details about the problem and the proposed solution. The reviewer doesn't specify *what is lost* when subtracting 's' or *how* subtracting 's' would help the LSTM capture dynamic changes. The suggestion is presented as a hypothesis rather than a clear and actionable improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for empirical evidence and explores a complex relationship between MC samples, performance, and network structure. It doesn't explicitly state an action the authors should take, but rather poses questions that the authors could use to guide their own investigation. The request is for information rather than a direct instruction.", "grounding_specificity_rationale": "The review point asks about the 'number of MC samples' and 'network structure'. While it refers to specific aspects of the model, it doesn't pinpoint a specific section, table, or figure. The references are general descriptions of model components. The reviewer is asking about the impact of these components, not about a specific element within the paper.", "verifiability_rationale": "The review point asks for 'empirical evidence' and 'how does the network structure affect this?'. While it implies a need for justification, it doesn't provide a claim that can be verified. The request is a question about a relationship, not a statement that needs to be proven or disproven. There is no explicit claim being made.", "helpfulness_rationale": "The review point asks a question about a complex relationship involving empirical evidence and network structure. While it highlights a potential gap in the reader's knowledge, it doesn't provide a direct solution or actionable advice. The request is for information rather than a clear path forward. The reviewer is pointing out an area that needs more investigation, but the review itself doesn't offer concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The reviewer points out the *lack of direct comparisons* with the baseline method in the *text* of the review. While the *consequence* (lack of clarity on improvement) is implied, the *specific action* of comparing test accuracy is not explicitly suggested or recommended by the reviewer. The reviewer focuses on the *absence* of comparisons in the *results* section (Section 3.4 and 3.5) rather than suggesting an *action* to take.", "grounding_specificity_rationale": "The reviewer criticizes the *lack of direct comparisons* in the *text* of the review. While the *general idea* of comparison is present, the *specific details* of *which tasks* and *how* these comparisons should be made are missing. The reviewer is pointing to a lack of *grounding* in specific experimental details.", "verifiability_rationale": "The reviewer states that the comment is 'not verifiable' because it lacks supporting evidence. The reviewer's statement itself is a claim ('this approach is indeed an improvement'). However, the reviewer does not provide any *logical reasoning*, *common knowledge*, or *external references* to support this claim. The statement is presented as a fact without justification.", "helpfulness_rationale": "The reviewer's comment is criticized for lacking *actionable feedback*. The reviewer points out the *absence* of direct comparisons, making it unclear if the approach is an improvement. This lack of specific information hinders the reviewer from providing *constructive suggestions* for improvement. The reviewer's comment is essentially a statement of uncertainty rather than a helpful critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer raises a valid point about the generalizability of the method to other domains. While the paper doesn't explicitly state the limitations of the method to specific domains, the reviewer's concern is a relevant question for authors considering applying the method in different contexts. The paper focuses on a specific dataset and event types, and it's unclear if the method would be equally effective in domains with different data structures or event definitions. The lack of explicit discussion on this aspect makes the comment somewhat vague in its implications.", "grounding_specificity_rationale": "The reviewer's concern about the selection of 21 event types from Freebase and their coverage in the ACE data is a valid point regarding grounding specificity. The paper mentions selecting event types from Freebase but doesn't detail the criteria for selection or the coverage of the ACE dataset. This lack of information makes it difficult to assess the scope and potential biases of the method. The reviewer's questions directly address how the method is grounded in the data, making this a relevant concern for authors.", "verifiability_rationale": "The reviewer's concern about the generalizability of the method to other domains is also a valid point regarding verifiability. The paper doesn't provide sufficient evidence or reasoning to support the claim that the method would be effective in other domains. The lack of explicit justification for the method's applicability beyond the specific dataset and event types makes this a partially verifiable concern. The reviewer's questions directly address the lack of supporting evidence for the method's broader applicability.", "helpfulness_rationale": "The reviewer's concern about the generalizability of the method to other domains is a relevant and important question for authors. Understanding the limitations of the method is crucial for its effective application. The reviewer's question about the selection of 21 event types from Freebase and their coverage in the ACE dataset is also a relevant concern. This information is crucial for assessing the scope and potential biases of the method. Both points are actionable and would help authors better understand the method's applicability and limitations."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the weakness of the current experiments and provides a clear prescription for improvement by suggesting more relevant tasks. The action is explicitly stated, and the prescription is concrete.", "grounding_specificity_rationale": "The reviewer identifies the specific area of the paper being criticized (the experiments related to 'language modeling capability') and provides specific suggestions for improvement (including tasks like language modeling, machine translation, or text summarization).", "verifiability_rationale": "The reviewer makes a claim about the weakness of the current experiments and provides logical reasoning to support this claim by explaining why these tasks don't reflect language modeling capabilities. They also suggest alternative tasks that *should* reflect these capabilities, providing further justification.", "helpfulness_rationale": "The review point is 5 as it clearly identifies a weakness in the experimental design and provides concrete suggestions for improvement. The actions are explicit and the prescriptions are specific, making it immediately actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly asks a question about a specific detail in a table, which can be considered an implicit action to seek clarification. However, it doesn't provide concrete steps on how to apply this information or what the implications are.", "grounding_specificity_rationale": "The comment refers to 'Table 3' and 'baseline models' generally. While the context implies the table's relevance to model comparison, it doesn't pinpoint the exact section or element within Table 3 that needs clarification. The mention of 'baseline models' is also general.", "verifiability_rationale": "The comment poses a question that could be answered by examining Table 3. It doesn't explicitly claim to provide a justification or reasoning for the question itself.", "helpfulness_rationale": "The question directly asks for clarification on a specific detail in a table relevant to model comparison. This is a direct and relevant question that would help the authors understand the experimental setup and results better. While it doesn't propose a solution, it seeks to clarify a potential point of confusion."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement is explicit about the lack of improvement but vague on the specifics. It identifies the comparison ('over existing RL method') but doesn't detail how the improvement is lacking or suggest concrete changes.", "grounding_specificity_rationale": "The reviewer refers to 'existing RL method' generally, not pinpointing a specific section, table, or unique aspect of the paper. The criticism is also general ('not impressive') and lacks specific details about what aspects are lacking.", "verifiability_rationale": "The review contains a claim ('The improvement of the proposed method over existing RL method is not impressive') but provides no supporting evidence or justification. It's an opinion without backing.", "helpfulness_rationale": "The review offers a judgment about the improvement but doesn't provide specific suggestions or identify weaknesses in the proposed method. It leaves the authors with an opinion rather than constructive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their belief about the dimensions of the projection matrices and claims that the current dimensions are incorrect. This is a direct identification of a potential error, making the action very explicit. The reviewer also specifies the incorrect and correct dimensions, making the action concrete.", "grounding_specificity_rationale": "The reviewer refers to the dimensions of the projection matrices, which are a specific mathematical element within the context of tensor decomposition. While they don't explicitly name a section, the reference is clear and points to a specific part of the mathematical formulation. The reviewer also clearly states what *should* be the dimensions, adding to the specificity. However, without knowing the exact section where these dimensions are mentioned in the paper, the grounding can be considered weak as the authors might need to infer the section based on the context.", "verifiability_rationale": "The reviewer presents a claim about the dimensions of the projection matrices. They provide a reasoning based on the requirement for matrix multiplication to be possible. While they don't provide a citation, the reasoning is based on fundamental principles of linear algebra and tensor operations. Therefore, the claim is verifiable but lacks external references, making it partially verifiable.", "helpfulness_rationale": "The reviewer offers a specific suggestion about the dimensions of the projection matrices. This is a direct and actionable feedback that directly addresses a potential technical issue. The suggestion is clear and directly related to the identified problem."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer states a claim about PACE being a 'diagnostictype prediction' but doesn't explicitly state what is being diagnostic or how this differs from existing diagnostic approaches. The reviewer also doesn't provide concrete steps for the authors to take.", "grounding_specificity_rationale": "The reviewer states a claim about PACE being a 'diagnostictype prediction' without explicitly referencing a specific part of the paper being discussed. The reviewer's statement is general and doesn't pinpoint a section, table, figure, or unique element of the paper.", "verifiability_rationale": "The reviewer makes a claim about PACE being a 'diagnostictype prediction' without making clear that prior work (e.g. ClimateBench or ClimateSet) does exactly this. However, the comment does not specify what needs to be addressed in this part.", "helpfulness_rationale": "The review point points out a potential misrepresentation of PACE's contribution by highlighting similarities to existing diagnostic methods. While this raises a valid concern about the novelty or framing of PACE, the reviewer doesn't provide specific references to those works within the review point itself, and the verifiability of this claim depends on external knowledge of ClimateBench and ClimateSet. The reviewer is stating their belief, but not providing evidence *within the review text* that prior work does exactly this. The reviewer is stating their belief, but not providing evidence *within the review text* that prior work does exactly this. The reviewer is stating their belief, but not providing evidence *within the review text* that prior work does exactly this."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests moving visual results from supplementary to the main paper, specifically for the crowd density estimation experiment. While the suggestion is concrete regarding the *type* of visual results ( crowd density estimation) and the *general* area (main paper), it doesn't explicitly state which section, table, or figure in the paper should receive these results. The action itself (moving visual results) is clear, but the specific location is not.", "grounding_specificity_rationale": "The reviewer suggests moving visual results *for crowd density estimation* to the main paper. This provides some specificity regarding the *type* of visual results. However, the reviewer does not explicitly identify a specific section, table, or figure in the paper where these results should be placed. The grounding is present in terms of the experiment, but the precise location within the paper is not specified.", "verifiability_rationale": "The reviewer's comment is a suggestion or recommendation for improving the paper's structure and presentation. It does not present a claim or assertion that requires verification. There is no logical reasoning, common knowledge, or external references provided to support the suggestion itself. It's a statement of preference or desired improvement.", "helpfulness_rationale": "The reviewer's comment directly suggests an improvement to the paper's organization by moving visual results from supplementary to the main paper, particularly for the crowd density estimation experiment. This is a concrete and actionable suggestion that, if implemented, would likely benefit the authors by improving the clarity and flow of the paper. The suggestion is directly related to the presentation of the experimental results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'While the paper shows improvements on CIFAR derivatives, it lacks analysis or results on other datasets (e.g., ImageNet derivatives)'. This directly identifies an area for improvement and provides a clear action: the authors should analyze other datasets. The reviewer also implies that the lack of analysis on other datasets is a weakness, suggesting the authors should address it. The reviewer does not explicitly state how to implement this action, but the action itself is clear and direct.", "grounding_specificity_rationale": "The review point explicitly mentions 'other datasets' and specifically names 'ImageNet derivatives' as an example. This clearly identifies the specific part of the paper being addressed, demonstrating strong grounding. The reviewer also implies the importance of analyzing other datasets, which is a specific aspect of the paper.", "verifiability_rationale": "The review point contains a claim: 'it lacks analysis or results on other datasets (e.g., ImageNet derivatives)'. This claim is supported by the statement 'While the paper shows improvements on CIFAR derivatives'. The reasoning is logical: the paper demonstrates improvements on one set of datasets but doesn't provide evidence for others. The reviewer provides a specific example ('ImageNet derivatives') to illustrate the lack of analysis. The claim is wellsupported by the paper's content.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper: the lack of analysis on other datasets. This is a valuable piece of feedback for the authors as it highlights a gap in the evaluation and suggests a direction for improvement. The reviewer implies that this lack of analysis might affect the generalizability of the findings. While the review doesn't explicitly state how to address this weakness, it clearly points to a specific area that needs further investigation. The reviewer's suggestion to 'present these results in the main paper' is a helpful suggestion for improving the paper's completeness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a discrepancy between the Abstract/Introduction and the Experiments section regarding the treatment of BigFive and MBTI. In the Abstract and Introduction, they are presented as models to be extended, suggesting a future development. However, in the Experiments section, they are treated as datasets, implying they are being used as input for analysis. This is an implicit suggestion for improvement in the Abstract and Introduction, but the Experiments section doesn't explicitly state how this extension should be done. The reviewer's point doesn't directly tell the authors *how* to apply this suggestion, making it not 5.", "grounding_specificity_rationale": "The reviewer's point is not explicitly tied to a specific part of the paper. They are pointing out a potential inconsistency between the Abstract/Introduction and the Experiments section. While they mention \"BigFive and MBTI are stated as models to be extended in Abstract and Introduction sections while they are used as mere datasets in Experiments,\" they don't specify *where* in those sections this inconsistency exists. The comment is more of a general observation about the different treatment of these terms. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer's point is a suggestion for improvement, indicating a potential issue with the paper's structure or presentation. They are suggesting that the Abstract and Introduction should be consistent with the Experiments section regarding the treatment of BigFive and MBTI. However, the reviewer does not provide any evidence, reasoning, or external references to support this suggestion. They are simply stating a potential inconsistency. Therefore, the claim is underspecified and not verifiable.", "helpfulness_rationale": "The reviewer's point highlights a potential inconsistency in the paper's treatment of BigFive and MBTI. By pointing out that these models are described as models to be extended in the Abstract and Introduction but used as datasets in the Experiments, the reviewer is suggesting a need for clarification or consistency. While the point doesn't directly tell the authors how to fix the issue, it identifies a potential area for improvement in the paper's structure and presentation. Therefore, it is 3 in pointing out a potential problem."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'Rejection rate is not shown in any experiments' which is a direct request for information. While the reviewer also adds the implicit suggestion 'One could view a misclassification as a rejection', the primary action is to point out the missing information. Therefore, it is 3 as the missing information is clearly identifiable, but needs further interpretation to understand the connection to rejection.", "grounding_specificity_rationale": "The comment refers to 'any experiments' without specifying a particular section, table, figure, or unique aspect of the paper. While the reviewer implies it's related to the experiments discussed in the paper, they don't explicitly point to a specific part. Therefore, the grounding is weakly grounded as the area (experiments) is implied, but the specific part isn't clearly identified.", "verifiability_rationale": "The comment states a claim: 'Rejection rate is not shown in any experiments'. While there is no direct external reference, the reviewer provides a logical reasoning: 'One could view a misclassification as a rejection'. This reasoning, while not a citation, provides a justification for why the rejection rate is important. Therefore, the claim is 3 as there is implicit logical reasoning.", "helpfulness_rationale": "The comment asks for information ('Rejection rate is not shown...'). Information about rejection rates is generally helpful for authors to understand the evaluation process and potential biases. However, the reviewer also states 'One could view a misclassification as a rejection', which introduces a potential for misinterpretation or a negative framing. This nuance reduces the overall helpfulness. Therefore, it is 3 as the information is generally useful, but the potential for misinterpretation makes it less definitive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer is asking for information about the final thresholds used and the full set of hyperparameters. While the action is explicit (identifying thresholds and hyperparameters), the request lacks context and specificity regarding how this information relates to the paper's content or weaknesses. The reviewer doesn't state what these thresholds and hyperparameters are or how they should be applied, making the action somewhat vague and less actionable for improving the draft.", "grounding_specificity_rationale": "The reviewer mentions 'thresholds' and 'hyperparameters' as the specific part of the paper being addressed. This indicates a degree of grounding as the terms are specific technical terms. However, the review does not specify *where* in the paper these thresholds and hyperparameters are discussed or defined. The grounding is weak because the reviewer cannot confidently determine which part the comment addresses. The specificity is also underspecific as the review does not detail what needs to be addressed in this part (e.g., are these thresholds for model selection, regularization, or something else?).", "verifiability_rationale": "The reviewer is asking about the final thresholds and hyperparameters. This can be interpreted as a request for clarification or a question about the validity of these parameters. However, the review does not provide any evidence or justification for why these specific thresholds and hyperparameters are used or if they are appropriate. There is no logical reasoning, common knowledge, or external references provided to support the claim about these parameters. The claim is 1 because the reasoning and evidence are missing.", "helpfulness_rationale": "The reviewer is asking for information about the final thresholds used and the full set of hyperparameters. While this information is relevant for reproducibility, it does not directly address any identified weaknesses or suggest improvements to the paper's content. The request is broad and lacks specific connection to the paper's strengths or areas for improvement. Therefore, the feedback is incomplete and lacks actionable insights for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an action to be taken (optimize Figure 1) but does not provide specific steps on how to achieve this. The action is explicit, but the implementation is vague.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 1', clearly identifying the specific part of the paper being addressed. It also specifies the issue with this part: 'could be optimized to use less whitespace'.", "verifiability_rationale": "The review point is a suggestion and does not contain a claim that can be verified. It proposes a change but doesn't justify why the current version is problematic or provide evidence for its claim.", "helpfulness_rationale": "The review point identifies a potential area for improvement (Figure optimization) and points to a specific element (Figure 1). While it lacks specifics on how to optimize, it does highlight a relevant actionable area for the author. It's a relevant suggestion, but lacks concrete guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a potential issue with the theoretical construction by pointing out that replacing the first column of Qo with vo in P'o leads to the first state being unreachable and derived from a terminating state. This directly identifies a modification and its consequence, making it a clear and actionable observation.", "grounding_specificity_rationale": "The reviewer refers to 'Line 140' and specifically mentions 'Qo' and 'P'o', grounding the comment to a specific part of the paper and the variables involved. They also mention the consequence of the change on 'the first state', further specifying the area of concern within the theoretical framework.", "verifiability_rationale": "The reviewer makes an assumption about the implications of the change, stating that either Assumption 1 (finite length of an option) or Assumption 2 (terminating state) is responsible for the reachability issue. This claim is based on an assumption and not directly supported by evidence or logical reasoning within the paper itself.", "helpfulness_rationale": "The reviewer clearly identifies a potential issue in the theoretical construction by highlighting the change in Qo and its impact on the reachability of states in P'o. This points the author to investigate the relationship between Qo, P'o, and state reachability, which is a helpful direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests an alternative approach: 'if authors did not find improvement in FLOPs or inference time, I suggest looking at if there is any improvement on the accuracy or specific properties.' Furthermore, the reviewer provides a concrete example: 'For example, with the recurrent model, maybe the sequential relationship is easier to mode?' This makes the action very clear and direct.", "grounding_specificity_rationale": "The reviewer suggests 'accuracy' and 'specific properties' as areas to investigate. While 'accuracy' is a general term, the reviewer's focus on 'specific properties' and the concrete example of 'sequential relationships' indicate a degree of grounding. The example helps to ground the suggestion to a specific aspect of the model or data.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a suggestion for the authors to consider. Therefore, it does not fit the criteria for verifiability, which involves supporting a claim with evidence or reasoning.", "helpfulness_rationale": "This review point is 5 because it directly addresses the scenario where the initial suggestions (improving FLOPs or inference time) did not yield results. It offers a clear and actionable alternative direction for the authors: investigating accuracy and specific properties. The inclusion of a concrete example ('sequential relationships' in the context of a recurrent model) further enhances the helpfulness by providing a specific area to explore. This guidance is very valuable for the authors in navigating their research process."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential issue with the choice of datasets but doesn't explicitly state what action the authors should take. While the reviewer suggests alternative datasets, the action of switching datasets isn't directly implied or detailed.", "grounding_specificity_rationale": "The review point explicitly mentions the 'FlatCam Face' and 'Headpose detection' datasets and their characteristics (popularity, uncommon). It also suggests alternative datasets. This clearly grounds the comment in specific parts of the paper and provides information about the problematic datasets. The specificity lies in pointing out the *characteristics* of the chosen datasets that make them difficult to evaluate.", "verifiability_rationale": "The claim is that the chosen datasets are 'unpopular' and 'weird choices'. While the reviewer offers *suggestions* for alternative datasets, they don't provide specific references or examples to *verify* the unpopularity of the chosen datasets. The claim is based on the reviewer's perception.", "helpfulness_rationale": "The review point identifies a potential issue with the dataset choice and offers suggestions for alternative datasets. While the suggestions are general categories, they provide a direction for the authors to consider different benchmarking options. The reviewer's assessment of the datasets' popularity is subjective, but the suggestion to use alternative datasets is a reasonable and actionable point for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues ( formatting, font, margins) and suggests an action (fixing the style). While the action is somewhat vague (e.g., *how* to fix the style), the reviewer clearly indicates what needs to be done. The reviewer also suggests a potential benefit (gaining space for experiments).", "grounding_specificity_rationale": "The reviewer explicitly mentions the formatting issues (NeurIPS style, abstract font, bottom margins) and even suggests potential improvements (gaining space, potentially the NLP experiments). This demonstrates a clear identification of the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer points out the problems (font size, margin) but doesn't provide explicit reasons *why* these are problematic or *sources* for this information. While common knowledge about formatting guidelines exists, the lack of explicit justification makes it somewhat less verifiable.", "helpfulness_rationale": "The reviewer provides clear suggestions for improvement (fixing the style, moving experiments) and explains how these could benefit the authors (gaining space for experiments). This directly addresses the authors' needs and provides actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment states \"annotations in Figure 4 can be further enlarged for visibility.\" This indicates an implicit action: the reviewer suggests making the annotations larger. However, the action is not explicitly stated as \"change the font size of the annotations in Figure 4 to a larger value\" or any similar concrete instruction. The term \"further\" makes the action somewhat vague, as it doesn't specify the exact method of enlargement. Therefore, while the reviewer points to an area for improvement, the specific steps to achieve it are not clearly defined.", "grounding_specificity_rationale": "The review point explicitly mentions \"Figure 4\" and then refers to a specific element within it, \"annotations in Figure 4.\" This clearly identifies the specific part of the paper being addressed. The reviewer does not need to infer which figure or element the comment is about; it is directly stated. This demonstrates strong grounding specificity as the exact location is pinpointed.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It is a suggestion for improvement: \"annotations in Figure 4 can be further enlarged for visibility.\" There is no logical reasoning, common knowledge, or external references implied. It is simply a suggestion, not a statement that needs to be proven or supported. Therefore, it does not fit into the categories of verifiable or 1 as it lacks a claim to be evaluated.", "helpfulness_rationale": "The review point directly points to a specific issue in Figure 4 (the visibility of annotations) and offers a clear, albeit slightly openended, solution (enlarging the annotations). It tells the author *where* the problem lies and *what kind of change* is being suggested. While it doesn't diagnose the exact cause of the visibility issue, it clearly identifies the area for improvement and provides a direction for action. This makes it a helpful suggestion for the author to take a step towards improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action: 'This is also true for relation classification, not only documentlevel RE or joint entity and relation extraction.' However, it does not provide concrete steps on how to address this issue or what specific changes are needed in lines 2627. The action is implied but not detailed.", "grounding_specificity_rationale": "The comment explicitly mentions 'lines 2627,' which grounds the feedback to a specific part of the paper. However, it doesn't specify *what* is wrong with those lines. The grounding is present, but the specificity of the issue is limited.", "verifiability_rationale": "The comment contains a claim: 'Multiple entities typically exist in both sentences and documents'. This claim is verifiable as a general principle in relation classification. However, it doesn't provide specific examples or references to support the claim within the context of lines 2627. The verifiability is based on a general understanding of relation classification, but lacks specific evidence for the identified location.", "helpfulness_rationale": "The comment identifies a valid point about a common misunderstanding in relation classification. It could potentially help the authors diagnose issues in lines 2627 by highlighting a typical error. However, it lacks specific guidance on what exactly is wrong or how to fix it, making it less directly helpful for immediate implementation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a concrete action: 'change a label to 'worse''. This is a clear and actionable suggestion that authors can directly implement to improve the figure. The reviewer is not just pointing out a problem but also suggesting a specific fix, making it 5.", "grounding_specificity_rationale": "The review point explicitly refers to 'Fig.4' and the 'color bar' and suggests that one of the labels should say 'worse'. This demonstrates strong grounding specificity as the reviewer not only identifies the specific part of the paper but also pinpoints the exact element within that part that needs improvement. The suggestion is also very specific, indicating a clear understanding of the issue.", "verifiability_rationale": "The review point does not present a claim that requires verification. It is a suggestion for improvement rather than a statement that needs to be supported by evidence. Therefore, it does not fit the criteria for verifiability as defined in the prompt.", "helpfulness_rationale": "The review point is 5 because it directly identifies a specific issue (potential mislabeling of the color bar) and suggests a concrete action (changing a label to 'worse'). This actionable feedback is immediately useful for the authors to improve their work. The specificity of the suggestion further enhances its helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states \"...training/validation/test\" should be \"...training/validation/test sets\u201d.\nThis is direct and clear, indicating an explicit action. Furthermore, the suggestion to add 'sets\" is concrete, specifying exactly what needs to be added.", "grounding_specificity_rationale": "The comment explicitly mentions \"Row 757\" in the supplementary material. This is a clear indication of full grounding. Additionally, the comment specifies what is missing (\"training/validation/test\") and what should be added (\"training/validation/test sets\"), providing high specificity.", "verifiability_rationale": "The comment contains a claim (\"...training/validation/test\" should be \"...training/validation/test sets\") and provides a justification (that it's a common practice to include the 'sets\"). While it doesn't provide external references, the reasoning is clear and based on common understanding.", "helpfulness_rationale": "The comment directly points to a specific location in the supplementary material (Row 757) and suggests a concrete improvement (adding 'sets\"). This makes it 5 for the author to know exactly where to make the change and what to add."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point does not explicitly state what the authors should do. While it suggests an improvement in the presentation of the formula, it lacks specific instructions on how to achieve this. The reviewer is asking for a *definition* of the quantile, which implies a desire for action, but the action itself is vague.", "grounding_specificity_rationale": "The reviewer identifies the specific part of the paper being addressed, which is the formula containing the quantile. They are asking for a definition of the quantile, which is a specific element within the formula. However, the reviewer does not provide specific examples of what is unclear about the current explanation of the quantile. The grounding is present, but the specificity of the grounding could be improved.", "verifiability_rationale": "The reviewer makes a claim that the definition of the quantile is confusing. This claim can be considered verifiable because the reviewer is stating a judgment about the clarity of the explanation and suggesting a concrete improvement by providing a clearer presentation. However, the specific nature of the confusion is not detailed, making it somewhat underspecific.", "helpfulness_rationale": "The reviewer explicitly states their dissatisfaction with the current presentation of the formula and provides a clear suggestion for improvement by defining the quantile. This directly addresses their needs and empowers them to significantly improve their draft. The suggestion is concrete and actionable in terms of providing a clearer explanation."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their belief that the model by Dozat and Manning (2016) is no longer stateoftheart and suggests replacing it with a 'very high performing model'. This indicates a clear action: to replace the specific model mentioned in line 152 with a more general alternative. While the action is not entirely concrete as the specific alternative is not named, it is more concrete than inferring the need for change.", "grounding_specificity_rationale": "The reviewer refers back to 'the model' in line 152, which suggests they are commenting on a specific model discussed earlier. However, the reviewer does not explicitly identify the specific section, table, figure, or unique aspect of the paper where the model is discussed. The criticism is about the model itself, not a specific element within the model or the paper's explanation of it. Therefore, while there's likely implicit grounding, the reviewer doesn't explicitly pinpoint the referenced part.", "verifiability_rationale": "The reviewer's claim that the model by Dozat and Manning (2016) is no longer stateoftheart is based on their general knowledge of the field. While they could potentially provide a specific citation, it's not explicitly requested or implied in the review point. Therefore, the claim is supported by common knowledge or general understanding rather than explicit references or external verification. The reviewer does not claim that something is incorrect or lacking detail within a specific part of the paper, so 'X' is not applicable here.", "helpfulness_rationale": "The reviewer makes a claim: 'I think the model by Dozat and Manning (2016) is no longer stateoftheart.' This claim is supported by the reviewer's general knowledge of NLP advancements. The reviewer then suggests replacing it with a 'very high performing model,' which is a helpful action based on this claim. While the suggestion is somewhat vague, it provides a clear direction for improvement by identifying a specific area of concern and a general direction for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question ('Besides norm, is there any other property of features can be used?') which, while not explicitly stating a solution, implicitly encourages the authors to consider alternative feature properties. This can be seen as an implicit action to explore different feature aspects. However, it lacks specific guidance on what these properties might be or how to identify them, making it somewhat vague in its actionable nature.", "grounding_specificity_rationale": "The reviewer asks about 'other properties of features' without explicitly stating which specific property or aspect of the features they are referring to. The authors would need to infer that they are looking for information beyond the 'norm' property. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses. The specificity is also low as the request is broad and doesn't specify what kind of property or aspect is being sought.", "verifiability_rationale": "The review point is a question, not a statement containing a claim. Therefore, it does not contain a claim and cannot be verified. The classification for this point is 'X'.", "helpfulness_rationale": "The review point is a question prompting the authors to consider other properties of their features. While this encourages exploration and asks for relevant information, it does not directly tell the authors what to do or how to improve their draft. It's a helpful prompt but lacks the direct actionability of a suggestion. Therefore, it is 3 as it encourages further investigation and provides a direction for improvement, but it doesn't offer a concrete solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of 'network changes or losses' and poses a question about the use of two SIRENs for 'f' and 'd'. While the question is openended, it implies a potential area for improvement or a simplification that could be beneficial. The reviewer's statement about 'network changes' is somewhat vague, as it doesn't specify what is missing or how it should be changed. The question about the SIRENs is specific, but it lacks a clear direction for the authors. The reviewer's comment is not entirely explicit, as the justification for the two SIRENs is missing. The concreteness is also limited as the reviewer doesn't specify *why* the method is constructed on top of previous methods or what the implications are.", "grounding_specificity_rationale": "The reviewer mentions 'network changes or losses' and 'networks f and d'. While they don't explicitly name the section or table where these are defined, the mention of 'networks' and the specific functions 'f' and 'd' strongly implies they are referring to a specific part of the paper. However, the reviewer doesn't explicitly state *what* is wrong with the method or the networks. They ask a question about the choice of SIRENs, which is relevant to the grounding but doesn't pinpoint a specific issue within that grounding. Therefore, the grounding is present but not fully specific.", "verifiability_rationale": "The reviewer expresses a concern about the method being 'mostly constructed on top of previous methods' and asks a question about the use of two SIRENs. While they imply a potential weakness, they don't provide any evidence or justification for their claim. There is no logical reasoning, common knowledge, or external references provided to support their assertion. The comment is a claim (the concern about the method's novelty) without any supporting evidence or justification.", "helpfulness_rationale": "The reviewer raises a valid concern about the novelty of the method and asks a pertinent question about the choice of SIRENs. However, they don't provide any specific suggestions or explanations for why the method is constructed on top of previous methods or what the implications of using two SIRENs are. The comment is a question prompting for clarification and justification, but it doesn't offer concrete guidance on how the authors should improve their draft. The lack of explicit suggestions makes it less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides explicit suggestions for improvement, stating \"remove RQ1\" and \"analyze the proportion of explicit hate information in the dataset and its effect on performance and corresponding effect on RQ2 & RQ3 tsne plots.\" These are direct actions the authors should take.", "grounding_specificity_rationale": "The reviewer's suggestions are very specific. They not only identify the need to remove RQ1 but also specify the analysis to be conducted: \"analyze the proportion of explicit hate information in the dataset\" and link it to performance and tsne plots. They also mention \"corresponding effect on RQ2 & RQ3 tsne plots\", indicating a clear understanding of where the impact is expected.", "verifiability_rationale": "The reviewer provides a claim that the performance of hate speech detection models can be improved by analyzing the proportion of explicit hate information. This claim is supported by logical reasoning and the reference to a specific analysis article. The reviewer suggests a concrete analysis and links it to a specific visualization technique (tsne plots), providing a clear path for verification.", "helpfulness_rationale": "The reviewer explicitly states that their point is 'valuable feedback' and offers 'detailed, actionable, and constructive suggestions'. They propose removing RQ1 and analyzing the proportion of explicit hate information, which directly addresses potential redundancy and provides a clear direction for improvement. The connection to performance and visualization techniques further enhances the helpfulness."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point asks a question ('Could you elaborate...') which suggests a desire for more information. However, it doesn't explicitly state what needs to be done or how to achieve the desired outcome. It's a request for clarification, not a directive for the author to make changes.", "grounding_specificity_rationale": "The review point mentions 'other works focusing on the semantic face editing' and '1' as an example. While it attempts to ground the discussion in existing literature, it doesn't pinpoint a specific aspect of these works that needs clarification. The mention of 'semantic face editing' is general, and the reviewer doesn't specify a unique element within that field.", "verifiability_rationale": "The review point contains a claim (the request to elaborate on the difference) but fails to provide any supporting evidence or justification. It simply asks a question without explaining why this difference is important or what evidence they have.", "helpfulness_rationale": "The review point is a request for clarification, not a constructive critique or suggestion for improvement. It doesn't directly point out a weakness in the submitted work or offer a solution. It's more of a question to the authors, lacking the actionable feedback that would be helpful."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks about Figure 3 and refers to a specific element within it, 'OAA'. This indicates a clear and direct request for the author to address a specific part of the paper and a specific detail within that part. The action is explicit, and the details are concrete.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 3' and even mentions a specific element within it, 'OAA'. This demonstrates that the reviewer has identified the specific part of the paper being addressed and even pinpointed a specific element within that figure. The grounding is explicit and the specificity is high.", "verifiability_rationale": "The reviewer makes a claim about the content of the appendix and provides a logical next step for verification by suggesting 'look into the appendix'. While they don't provide specific references, the action to verify is clear and logical, making it 3.", "helpfulness_rationale": "The reviewer directly points out a missing element ('OAA') in Figure 3 and suggests investigating the appendix. This is a clear and actionable feedback, providing the author with a specific area to look into and a potential cause for the issue. The feedback is not just about identifying a problem but also about suggesting a solution path."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper claims to present a new PIC approach, but the work is actually a 'fix' of 12. The reviewer also points out that the lines 2930, where this distinction is made, are vague and lack detail. The reviewer suggests that the authors should explicitly state their contribution relative to 12 and mention 12 in the introduction. This is an explicit statement that identifies a specific issue (the unclear claim of novelty) and provides a concrete action: to clarify the relationship to 12 and explicitly mention it.", "grounding_specificity_rationale": "The reviewer explicitly mentions the introduction (lines 2930) as the section where the confusion about the contribution arises. This is a strong form of grounding as the authors can directly identify the specific part of the paper being addressed. Furthermore, the reviewer clearly specifies the *issue*: the lack of clarity regarding the relationship to 12 and the need to explicitly mention 12. This specificity goes beyond simply mentioning the section and delves into the specific problem.", "verifiability_rationale": "The reviewer makes a claim that the introduction lacks clarity regarding the paper's contribution and its relationship to 12. This claim is verifiable because the reviewer provides a specific location (lines 2930) where this lack of clarity is evident. The reviewer also suggests a solution: explicitly mentioning 12 and stating that the proposed solution is a 'fix' of 12. This provides a clear reasoning and a concrete suggestion, making the claim verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors to improve their paper. They point out a specific issue (unclear contribution) and provide a concrete action: to clarify the relationship to 12 and explicitly mention 12 in the introduction. This directly addresses a potential misunderstanding and guides the authors on how to make their work clearer. The reviewer's suggestion is immediately actionable and directly addresses a potential problem, making it 5."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the impact of the GS module on the effective receptive field, rather than providing a direct action or suggestion. While the question is relevant, it doesn't tell the authors what to do or how to improve their draft. The suggestion to look at 2 is a resource but not a concrete action.", "grounding_specificity_rationale": "The reviewer mentions the 'GS module' and 'effective receptive field' but doesn't explicitly point to a specific section, table, or figure in the paper. The connection to the specific part of the paper where the GS module is applied isn't clearly defined, making the grounding somewhat weak.", "verifiability_rationale": "The review point is a question, not a declarative statement that requires verification. There is X being made that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer is asking a relevant question about a potential improvement. While the review point doesn't provide a direct solution, it encourages the authors to consider the impact of the GS module and potentially investigate further, making it 3 for guiding improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification on the rationale and relationship between G4RL and HRAC, which are not direct actions or instructions for the author. While the information could be extracted, the reviewer is not prompting the author to perform a specific action based on this comment. The comment seeks understanding rather than direct instruction.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'G4RL' and 'HRAC' and asks a question about their combination and potential dependency. This directly identifies the specific parts of the paper being discussed. The comment also clearly specifies the nature of the question. This meets both criteria for full grounding and specificity.", "verifiability_rationale": "The reviewer is asking a question, not making a claim that needs verification. There is no assertion of truth or falsehood. The comment is a request for information rather than a statement that can be supported or refuted.", "helpfulness_rationale": "The reviewer is seeking clarification, which can be helpful for the author to understand the concepts and potentially improve their work. However, the comment itself doesn't actively prompt the author to make changes or take a specific action. It's more about seeking understanding than providing direct guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to understand why uniform sampling performs better despite the authors' argument. This indicates a clear and direct action they wish to take. The action is also concrete, as they are asking for an explanation of the results in Table 2.", "grounding_specificity_rationale": "The reviewer directly references 'Table 2' and explains their confusion about the results in the context of the authors' argument about the predictor's accuracy. This demonstrates a strong grounding in the specific section and table where the results are presented. The specificity is also clear, as they are explaining *why* they are confused based on their understanding of the methods.", "verifiability_rationale": "The reviewer presents a logical deduction based on their understanding of the methods (linear/exponentialdecay sampling and uniform sampling) and the authors' argument about the predictor's accuracy. They are stating what they believe is the expected outcome and then pointing out that the actual outcome (uniform sampling performing better) contradicts this expectation. This is a clear and verifiable claim, although the reviewer doesn't provide external evidence to support their deduction. The reasoning is logical and based on established principles.", "helpfulness_rationale": "The reviewer is directly asking for clarification on a specific result in the paper. This is a 5 and helpful piece of feedback for the authors. They are identifying a potential issue in their understanding or the presented results and are seeking to improve the clarity of the presentation."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "Both points are actionable. The reviewer explicitly states what kind of explanation is needed (a brief explanation) and suggests where it should be located (lines 14 and 47). The request about the subscripts in Figure 1 also points to a specific area for improvement.", "grounding_specificity_rationale": "Both points are grounded and specific. The reviewer explicitly identifies the location (lines 14 and 47) and the nature of the issue (need for explanation of 'multiaspect' and clarification of subscripts in Figure 1).", "verifiability_rationale": "Both points are 3. The reviewer's questions imply a lack of clarity or understanding, suggesting a need for more explicit information or correction. While not claims, they point to areas where verification or justification is needed.", "helpfulness_rationale": "Both points are 4. The reviewer anticipates the need for clarification and explanation, which are likely to be beneficial for the author. The specific request about the subscripts is also likely to be helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the problem: 'Missing citation for the public skipgram data set'. This is a clear indication of an actionable issue. The reviewer is pointing out a specific location where the citation is needed. However, the review does not provide concrete steps on how to address this. The authors would still need to go find the data set and cite it themselves.", "grounding_specificity_rationale": "The review point explicitly mentions 'the public skipgram data set' and 'line 425'. This provides very specific information about the missing element and its location. The authors can easily identify the referenced part of the paper.", "verifiability_rationale": "The review point contains a claim: 'There is a missing citation for the public skipgram data set at line 425'. This claim is stated directly. However, the reviewer does not provide any justification or reasoning for why this is a problem or how it was discovered. The claim is presented as a factual observation.", "helpfulness_rationale": "The review point identifies a factual error: the missing citation. While this is a valid criticism, it doesn't provide specific guidance on how to fix it. The authors would still need to independently search for the data set and cite it. The helpfulness is limited to pointing out a necessary citation, which might be obvious to some readers but is important for others."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a potential weakness in the method description by highlighting the missing discussion of a hyperparameter \u03b3. While it doesn't explicitly state how to set it or analyze its sensitivity, it implicitly suggests that this omission is a problem that needs to be addressed. The reviewer is prompting the authors to take specific steps to improve the method description.", "grounding_specificity_rationale": "The review point mentions 'arbitrary hyperparameter \u03b3' and 'a given graph'. While it doesn't provide a literal section or table number, it clearly points to a specific aspect of the method (the graph analysis) and a specific parameter within that method. This allows the authors to infer the location of the relevant information, making the grounding somewhat specific.", "verifiability_rationale": "The review point contains a claim: 'The discussion on arbitrary hyperparameter \u03b3 is missing, including how to set it in practice for a given graph and analyzing on the sensitivity of this hyperparameter'. It also provides a justification by outlining what should be included in the discussion. This makes the claim verifiable.", "helpfulness_rationale": "The review point directly addresses a potential area for improvement in a method description by pointing out the lack of discussion on a hyperparameter and suggesting concrete steps for improvement (how to set it, analyze its sensitivity). This provides clear guidance and is therefore 5 for the authors."}
{"actionability_label": "Low", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "Low", "actionability_rationale": "The reviewer states the methodology is 'hard to follow' and 'confusing'. While they don't explicitly say 'I need to reread the methodology' or 'The notation is unclear', the sentiment implies an implicit actionability issue. The lack of specific guidance on what is confusing makes the action implicit.", "grounding_specificity_rationale": "The reviewer mentions the 'Methodology section' as the area with the problem, indicating they can identify the specific part of the paper being addressed. However, they do not specify what is wrong with the description of the model architecture or the notation. They mention 'confusing' and 'inconsistent notation' generally, not pointing to a specific instance.", "verifiability_rationale": "The reviewer makes a claim: 'The model architecture description is rather confusing and sometimes uses inconsistent notation.' However, they do not provide any external references or logical reasoning to support this claim. They present it as an observation rather than a statement backed by evidence.", "helpfulness_rationale": "The reviewer states the description is 'hard to follow' and 'confusing'. This directly indicates a lack of clear and actionable feedback, making the review less helpful for the authors to understand and improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the issue with Figure3 (it's represented as a vector when scalars are expected) and suggests a concrete action: 'redefine the figure'. This action is clear and directly addresses the identified problem.", "grounding_specificity_rationale": "The comment explicitly refers to 'figure3' and clearly identifies the problem as the incorrect representation of quantities as vectors instead of scalars. This precise reference and the clear specification of the change demonstrate strong grounding and specificity.", "verifiability_rationale": "While the comment itself isn't a claim stating a fact, it implies a critique of the figure's representation based on the understanding that quantities should be scalars. The reasoning is logical and based on common knowledge, making it verifiable. However, it doesn't provide specific references to external works, making it somewhat rather than 5.", "helpfulness_rationale": "The comment is clear, specific, and directly points out an issue with a particular figure, suggesting a concrete improvement. It is likely to be understood by the authors and encourage them to make changes. While it doesn't offer a highly specific type of redefinition (e.g., exact plotting parameters), it is a helpful starting point for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests a comparison across different voxel resolutions, which is a direct action for the authors to take. However, the initial questions about computational cost and voxel resolution are implicit, as the reviewer doesn't directly state what they expect to find or how this comparison should be done. The observation about the 1x1x1 resolution is also implicit, as it's an interesting observation but not a direct request for action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'voxellike feature', 'high computational and memory cost', 'resolution of the 3D voxel', and 'importance of the global feature'. This clearly grounds the comment in specific parts of the paper. The suggestion to compare different resolutions is also very specific. The observation about the 1x1x1 resolution is also grounded as it refers to a specific case.", "verifiability_rationale": "The review point contains a claim: 'What is the resolution of the 3D voxel, and does it introduce unnecessary overhead to the whole network?'. This claim is 3 as the reviewer is asking a question that could be answered by referring to the methods or experiments section. However, the reviewer doesn't provide any specific evidence or reasoning to support this claim.", "helpfulness_rationale": "The review point raises valid questions about the methodology and suggests a valuable comparison. It is likely to be helpful for the authors in understanding the impact of voxel resolution on their network. The observation about the 1x1x1 resolution is also a helpful insight. However, the initial questions about computational cost are more of a suggestion than a direct request for improvement, making the overall helpfulness slightly lower."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue (difficult to see trends in Table 3) and suggests a general direction for improvement (developing set trends). While it implies an action, it doesn't explicitly state what needs to be done, making it partially actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'Table 3' and refers to the behavior of 'PM+CL', 'PM', and 'CL'. This allows the authors to directly locate and understand the relevant information, making it 5.", "verifiability_rationale": "The review point doesn't contain a claim that requires verification. It's a suggestion for investigation rather than a statement of fact that needs support.", "helpfulness_rationale": "The review point points to a specific observation in the results (difficult to see trends) and suggests a relevant area for further investigation (development set trends). While it doesn't provide concrete steps, it offers a meaningful direction for the authors, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out two explicit actions: 'it is difficult to understand e.g. figure 5' and 'the main metrics reported are performance compared to remaining weights, but the authors could report flops or model size'. However, the reviewer does not specify how to improve the understanding of Figure 5 or how to report flops or model size. The actions are identified but lack concrete details on implementation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 5' and 'the main metrics reported', which are specific parts of the paper. However, the reviewer does not specify *what* is wrong with Figure 5 or *why* reporting flops or model size would be beneficial. The grounding is present but lacks detail on the specific issue.", "verifiability_rationale": "The reviewer states 'it is difficult to understand e.g. figure 5' and 'the main metrics reported are performance compared to remaining weights, but the authors could report flops or model size'. These statements express a judgment about the clarity of the figure and the reported metrics without providing any external references or logical reasoning to support these judgments.", "helpfulness_rationale": "The reviewer identifies two actionable points: improving the clarity of Figure 5 and suggesting the inclusion of flops or model size in the metrics. These points are directly aimed at helping the authors improve their draft. However, the lack of specific guidance on how to achieve these improvements makes them less immediately helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they would like simplification and better explanation, indicating a clear action. They also point to specific sections and lines (3964, Figure 7, Section 8), making the action very explicit. Furthermore, they suggest *how* to improve the explanation by simplifying and clarifying the architecture and computations, making the action concrete.", "grounding_specificity_rationale": "The reviewer directly points to specific sections (Figure 7, Section 8) and lines (3964) within the paper, indicating a strong grounding. They not only identify the section but also specify the lines within that section, showing a high level of precision. Additionally, they provide a specific suggestion for improvement within that identified section (simplifying the architecture and computations), demonstrating a high degree of specificity within the grounded area.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement, which can be considered a judgment or opinion. However, the *content* of the suggestion itself does not require external verification to be considered helpful. The reviewer is not stating that *this specific suggestion is true* or *requires evidence* to be valid. The suggestion itself is a constructive critique.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement by pointing to specific sections and lines and suggesting simplification. This directly addresses a potential weakness in the paper and offers a concrete way to improve it. The suggestion is specific and directly related to the identified areas, making it 5 and helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a clear and explicit suggestion for an additional experiment. They identify the goal (evaluating oversmoothing), the model (EIGNN), the setting (standard), the data (realworld), and the comparison (GCNII). This directly addresses a potential weakness in evaluating oversmoothing techniques by proposing a concrete methodology for comparison.", "grounding_specificity_rationale": "The reviewer's suggestion is grounded in the specific area of evaluating oversmoothing techniques. While it doesn't pinpoint a specific section or table within a paper, the focus is clearly on the *evaluation* of oversmoothing methods. The suggestion is also specific about the *model*, the *problem*, the *setting*, and the *comparison*.", "verifiability_rationale": "The reviewer's suggestion is a claim that *this specific experiment will help evaluate oversmoothing*. While it doesn't provide explicit evidence *within this review* to verify the claim, the suggestion is logically sound and directly addresses a relevant research question. The *implication* is that performing this experiment would provide valuable data for comparing different oversmoothing techniques.", "helpfulness_rationale": "The reviewer's suggestion is 5 as it directly addresses a relevant and active area of research (evaluation of oversmoothing techniques). It provides a concrete and actionable experiment that could provide valuable insights for researchers working in this field. It helps the authors understand the strengths and weaknesses of different oversmoothing methods and potentially leads to improvements in graph neural network architectures."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the missing element: \"a separate part or subsection\". It also explicitly states the actions needed: \"introduce the inference strategy\" and \"explain how to use multiple prompts in the test stage\". This is a clear and direct indication of what needs to be added and how.", "grounding_specificity_rationale": "The comment explicitly identifies the section where the method is described: \"approach method\". This is a clear and precise identification of the relevant part of the paper. Furthermore, it specifically asks for details about the inference strategy and the use of multiple prompts within that section, making it highly specific within the identified section.", "verifiability_rationale": "While the comment itself doesn't contain a claim in the sense of stating something is wrong, it implicitly suggests that the current method description is lacking in detail regarding the inference strategy's implementation. The request implies a need for more information, which could be seen as a form of implicit justification. However, without a clear claim, the level of verifiability is limited. The reasoning for adding this detail isn't explicitly stated as being lacking in the current work.", "helpfulness_rationale": "The comment is 5 because it directly points out a specific area for improvement: the lack of detail regarding the inference strategy and the use of multiple prompts. It provides a clear direction for the author to add a new subsection and include the necessary information. The request is specific and actionable, guiding the author on where and what to add."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'Figure 4 is confusing' and 'it's not clear what the columns mean.' This directly points to a specific area that needs improvement. The reviewer also identifies the *specific* issue: 'it's not clear what the columns mean,' which is a concrete action the authors should take.", "grounding_specificity_rationale": "The reviewer directly refers to 'Figure 4' and then specifies the *part* of the figure that is unclear: 'it's not clear what the columns mean.' This demonstrates strong grounding as the reviewer accurately identifies the specific element within the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim: 'Figure 4 is confusing' and 'it's not clear what the columns mean.' However, the reviewer does not provide any justification or explanation for *why* the figure is confusing or *why* the columns are unclear. The reviewer simply states the observation. There are no external references or logical reasoning provided to support the claim itself.", "helpfulness_rationale": "The reviewer directly points to a specific area for improvement: 'Figure 4 is confusing' and 'it's not clear what the columns mean.' This encourages the authors to reexamine the figure and potentially make changes to improve its clarity. The reviewer's comment is directly actionable and addresses a concrete issue."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests discussing the results of the Streetview experiment and asks questions about the conclusion. This provides a clear direction for improvement. However, the reviewer does not specify *how* to discuss the results or *how* to draw conclusions from them. The action is present, but the implementation details are missing.", "grounding_specificity_rationale": "The reviewer refers to the 'experiment results' as the part of the paper being addressed. This is a clear reference, although not a literal mention of a section or table. The reviewer also specifies the *type* of experiment results being discussed, which adds some specificity. However, the reviewer does not explicitly state what aspect of the experiment results is lacking or what needs to be improved.", "verifiability_rationale": "The reviewer makes claims about the experiment results and asks questions, which can be interpreted as judgments or suggestions. These claims are not explicitly supported by external references or logical reasoning within the review point itself. The reviewer is inferring what might be lacking based on their understanding of good experimental reporting. The claim is present, but the justification is implied rather than explicitly stated.", "helpfulness_rationale": "The reviewer points out two distinct areas for improvement: discussing the experiment results and clarifying the realworld applications and computational complexity. These are relevant and important suggestions. However, the suggestions are somewhat general and lack specific details on how to achieve these improvements. The feedback is relevant but could be more actionable."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'I wonder why the results are so low' and 'The results are even lower than some simple early methods...', indicating a clear intention to understand the discrepancy. The request to 'More explanations can be given' is a direct action the reviewer desires to take.", "grounding_specificity_rationale": "The reviewer mentions 'ablation experiments' and names specific methods ('fCLSWGAN' and 'fVAEGAND2') but does not explicitly state which section, table, or unique aspect of the paper they are referring to. This indicates a weak grounding as the reviewer can infer the context but cannot precisely identify the referenced part.", "verifiability_rationale": "The reviewer states that the results are 'even lower than some simple early methods'. This is a claim that requires justification and explanation to be considered verifiable. The reviewer is making a statement that needs to be supported.", "helpfulness_rationale": "The reviewer's statement directly addresses a potential issue with the ablation experiments and raises a question that is likely to be helpful for the authors. The request for 'explanations' is a clear desire for actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the weakness: 'models in conventional methods are trained on the original training set in addition to the generated adversarial examples. In contrast, the base model is trained on the adversarial set only.' They then provide a clear and actionable suggestion: 'It is better to compare the model trained on the original dataset with that trained on the mixture so as to highlight the impact of the augmented adversarial examples.' This action is concrete and directly addresses the identified issue.", "grounding_specificity_rationale": "The reviewer identifies specific parts of the paper being addressed. They mention 'the base model is trained on the adversarial set only' and 'the model trained on the original dataset'. These are explicit references to specific training scenarios. They also mention 'the augmented adversarial examples', further specifying the area of interest. The reviewer's comments are precise and directly point to the relevant sections and issues.", "verifiability_rationale": "The reviewer makes a claim: 'It is better to compare the model trained on the original dataset with that trained on the mixture'. They also provide a justification for this claim: 'Since this experiment serves as the motivation throughout this work, it is critical to make it more convincing.' This justification is logical and directly supports the reviewer's suggestion, making the claim verifiable.", "helpfulness_rationale": "The reviewer's comment is highly valuable. They identify a specific weakness in the experimental setup and provide a clear and actionable suggestion to address it. The reviewer emphasizes the 'criticality' of the base model's performance and how the suggested experiment would 'make it more convincing'. This directly helps the authors improve their draft by highlighting a crucial aspect of their methodology."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a need for a 'more detailed plan,' but it does not specify *what* aspects of the limitations should be addressed or *how* the authors plan to address them. The suggestion is general and lacks concrete details, making it difficult for the authors to know exactly what steps to take. While the reviewer identifies a direction for improvement, the lack of specificity makes it less actionable.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or the limitations being discussed. It refers to 'the authors' limitations' in a general sense. There is no mention of a specific section, table, figure, or unique element of the paper that the reviewer is addressing. Therefore, the suggestion is 1 in a specific location within the document.", "verifiability_rationale": "The review point is a suggestion for improvement, not a declarative statement containing a claim that needs verification. It does not present a judgment, opinion, or assertion that requires supporting evidence. It is a constructive suggestion, not a critique that needs to be justified.", "helpfulness_rationale": "The review point identifies a need for a 'more detailed plan' but does not provide specific guidance on how to achieve this. While it points to a direction for improvement, the lack of specificity makes it less helpful than a suggestion that offers concrete steps or actions. The feedback is valuable in pointing out the need for more detail, but it lacks the actionable steps necessary for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential confusion in Eq. 3 regarding the use of p_m in the numerator and p_c in the denominator. While they identify a symptom (potential confusion), the reviewer doesn't explicitly state the action the authors should take to address this. They suggest adding variance in Alg. 2, which is a concrete action. They also suggest using \u03bc_g for consistency, which is a suggestion for improvement, not a direct action on the current work. Therefore, the review point is partially actionable, with one clear action and one implied action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Eq. 3' and 'Alg. 2', indicating a clear grounding of the comment in specific parts of the paper. They explain *why* there's confusion in Eq. 3 (potential hindrance to further improvement) and *why* variance should be added in Alg. 2 (to improve robustness). They also point out a lack of consistency in notation. These are all specific observations and suggestions related to these parts of the paper.", "verifiability_rationale": "The reviewer makes claims about the potential confusion in Eq. 3 and the suggestion to add variance in Alg. 2. They imply that the confusion might stem from the inconsistency in notation and that adding variance would be a logical improvement. The lack of consistency in notation is a verifiable observation. The suggestions are based on logical reasoning and potential benefits.", "helpfulness_rationale": "The reviewer's points about clarifying the notation in Eq. 3 are likely to be helpful for the authors as it could resolve confusion. The suggestion to add variance in Alg. 2 is also likely to be helpful if implemented, as it could improve the model's robustness. The suggestion for consistency with notation is also likely to be helpful for the authors, as it would make the paper clearer and the implementation easier. While the actual impact of adding variance is uncertain, the suggestions are directly related to improving the work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states an implicit action: 'I would like the paper to include a more comprehensive discussion about the computational complexity of the proposal.' While the reviewer doesn't state the *how* or *why*, the desire for more information implies an action to improve the paper. However, the action is vague as the reviewer doesn't specify *which* aspects of computational complexity are missing or what specific information they need.", "grounding_specificity_rationale": "The reviewer mentions 'computational cost' and 'computational complexity' as areas for improvement. This grounds the comment to a specific part of the paper. However, the reviewer doesn't specify *which* section or table this relates to, making the grounding weak. The comment also doesn't specify *what* is wrong with the current discussion, making the specificity low.", "verifiability_rationale": "The reviewer states a claim: 'While the paper mentions the additional cost didn't lead to 'significant delays in computation\", it is not clear why.' This is a verifiable claim as it requires an explanation. However, the reviewer doesn't provide *any* justification or examples to support their claim, making the verifiability low.", "helpfulness_rationale": "The reviewer clearly identifies a gap in the paper regarding computational cost and complexity. They explicitly state a desire for more information. This indicates a helpful comment as it points out a relevant area for improvement. However, the lack of specificity in the request makes the helpfulness somewhat limited. The reviewer doesn't suggest *how* the paper could address the computational cost, making the helpfulness 'somewhat' rather than 'highly'."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a weakness: 'Missing indepth analysis on experimental results' and provides a specific example: 'For example, why the improvements of models are limited on offense detection dataset and are significant on coarse stereotype set?'. This indicates a clear action the authors should take: conduct a more detailed analysis of the experimental results to understand the varying performance across datasets.", "grounding_specificity_rationale": "The reviewer mentions 'experimental results' generally but does not specify which section, table, or figure in the paper contains this information. While they provide an example of the inconsistency, they do not point to the exact location of the results within the document. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim: 'There is a lack of indepth analysis of experimental results'. This claim is supported by the statement itself and the provided example of the performance differences across datasets. While the example doesn't provide specific evidence or references, it serves as a basis for justification.", "helpfulness_rationale": "The reviewer identifies a specific area where the paper lacks analysis and provides a concrete example of this weakness. This information is valuable for the authors to understand the limitations of their experimental evaluation and potentially improve it. While the reviewer does not suggest specific improvements, they highlight a clear area for further work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the concern about the condition in Proposition 6.1 and provides a clear action: to clarify this condition and compare it with Section 4. The request is direct and actionable for the authors.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Proposition 6.1' and the condition '\u03b7 \u2265 C_0', indicating a clear identification of the specific part of the paper being addressed. They also suggest comparing this with 'Section 4', further specifying the area of concern. This demonstrates strong grounding as the authors can easily pinpoint the referenced section and the issue.", "verifiability_rationale": "The reviewer makes a claim about the condition '\u03b7 \u2265 C_0' being strong and contrasting it with the typical small value of '\u03b7'. However, the reviewer does not provide specific evidence or references to support this claim within the review point itself. While the potential for verification exists (the authors could investigate typical ranges of \u03b7), the claim is not currently backed by logical reasoning, common knowledge, or external references within the provided text.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors to improve their draft. They point out a potential issue with a key condition and propose a comparison with another section to clarify the situation. This is a valuable piece of feedback that directly addresses a potential weakness in the model description."}
{"actionability_label": "4", "grounding_specificity_label": "3: 5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the missing baselines and provides specific examples (MVGRL and gptgnn). It also suggests adding these baselines, which is a clear action. The reviewer identifies the task (graph classification) and the type of methods to include, making the action concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the graph classification task' and names specific methods ('MVGRL' and 'gptgnn'). This clearly grounds the suggestion to a specific part of the paper and a specific area of comparison. The specificity is high as the reviewer identifies the exact task and the relevant methods to be included.", "verifiability_rationale": "The reviewer makes a claim about the insufficiency of the baselines and provides specific examples. However, the reviewer does not provide any evidence or justification for why these specific baselines are crucial or how their inclusion would improve the evaluation. The claim is present, but the evidence for its verifiability is weak.", "helpfulness_rationale": "The review point clearly identifies a potential weakness in the experimental setup (insufficient baseline comparison) and suggests a concrete improvement (adding specific baselines). This makes the review helpful in guiding the authors to address a potential gap. However, the review lacks specific details about which datasets to use or how to implement the comparison, making it less impactful than a more detailed suggestion."}
{"actionability_label": "2", "grounding_specificity_label": "3: 4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification on the meaning of the numbers in the tables, not explicitly stating what action the authors should take. While they imply a desire for better clarity, the action isn't directly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 1, 2, 3' as the location of the issue, providing a clear grounding. They also specify that the numbers relate to MNIST and CIFAR datasets, further grounding the issue to specific parts of the paper.", "verifiability_rationale": "The reviewer is not making a claim or assertion about the tables. They are asking for information or clarification, which does not involve verifying a statement.", "helpfulness_rationale": "The reviewer is asking for clarification, which can be helpful in understanding the results. However, it doesn't directly point out a weakness or suggest an improvement, making it less directly helpful than a comment that identifies a problem."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing theoretical guarantees (existence and smoothness of SDE solutions, discretization guarantees) and suggests improvements (referring to 'any guarantees'). This is both explicit and concrete.", "grounding_specificity_rationale": "The reviewer mentions 'theoretical work on sampling and particlebased optimization methods' but doesn't specify which part of the paper this relates to. The comment is not precise about the section or table. However, the reviewer does clearly identify the issue as a lack of theoretical guarantees, which is specific to the mentioned methods. Therefore, while the grounding is weak, the specificity is present.", "verifiability_rationale": "The reviewer makes a claim about the weakness of the analysis based on the lack of theoretical guarantees. The reviewer then provides a rationale for why the analysis is weak, linking it to the missing theoretical underpinnings. This rationale is logical and directly addresses the identified issue.", "helpfulness_rationale": "The reviewer clearly identifies a deficiency in the paper's theoretical analysis and suggests specific areas for improvement by referencing 'any guarantees'. This is a direct and actionable feedback for the authors, guiding them to strengthen their theoretical foundation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states the need to understand how the graph G is built using the human skeleton, which is a specific action. However, it lacks concrete details on the process, making it vague. For example, it doesn't specify the types of nodes or edges used, or the criteria for connecting them based on the human skeleton.", "grounding_specificity_rationale": "The comment asks about the construction of G in Section 3.3, indicating a clear identification of the specific part of the paper being addressed. However, it does not specify the exact elements or size of G, thus not fully grounding the request. The request is somewhat general about 'how' it's built, without pinpointing the exact section or table containing the details.", "verifiability_rationale": "The comment requests the size and elements of G, which are factual information that could be derived from common knowledge or by looking at the paper. However, it doesn't explicitly state a claim or assertion. Therefore, it's not strictly verifiable in the sense of supporting a claim, but it does point out a missing detail that could be verified.", "helpfulness_rationale": "The comment identifies a lack of clarity regarding the construction of graph G and requests more specific information. While it doesn't make a claim or assertion, it points out a deficiency in the current understanding. Therefore, it's not entirely unhelpful, but it's also not providing a direct solution or improvement suggestion. It's more of a request for clarification that could lead to better understanding."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "Not Verifiable", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the issue: 'calling \"hyperspectral\" is confusing.' This indicates an explicit action or suggestion, as the reviewer directly points out a problem. However, the review does not provide concrete steps on how to make the terminology less confusing. It lacks detail on how to apply the suggested improvement. Therefore, while explicit, the action is vague and lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The reviewer mentions 'hyperspectral' generally. They do not explicitly identify a specific section, table, figure, or unique aspect of the paper where the confusion arises. While they point out a potential issue, they do not specify what needs to be addressed in this part. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point is a statement of observation: 'calling \"hyperspectral\" is confusing.' There is X or suggestion being made. It's a description of a problem, not a claim that needs verification. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The review point identifies a valid issue: the confusing terminology 'hyperspectral'. However, it does not offer any concrete suggestions or actionable steps for the authors to improve their draft. It's a diagnosis of a problem but lacks a prescription for a solution. Therefore, it is not helpful in guiding the authors to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides specific suggestions for how the concept of energy should be interpreted in Section 5.2 and asks for clarification on the 'peak' in Figure 5. These suggestions are directly tied to specific parts of the paper, making them explicit. Furthermore, the reviewer provides concrete guidance on how to interpret the concept, making it actionable. While the reviewer doesn't explicitly state 'split at that point' for a high energy, the suggestion is clear and actionable. The request for clarification on the peak also implies a need for a specific interpretation, which is actionable.", "grounding_specificity_rationale": "The reviewer's suggestions are directly tied to specific parts of the paper. The suggestion about energy interpretation is explicitly linked to Section 5.2, and the comment about the peak in Figure 5 is directly related to that figure. The reviewer does not need to make educated guesses to identify the relevant sections or parts. The suggestions are precise and point to specific locations in the paper.", "verifiability_rationale": "The reviewer is not making a claim that needs verification. They are suggesting how the concept of energy should be interpreted and asking for clarification on a specific element in a figure. These are suggestions and requests, not statements that require logical reasoning, common knowledge, or external references. The reviewer is proposing a specific interpretation and asking for a definition, which is a suggestion, not a claim needing justification.", "helpfulness_rationale": "The reviewer's suggestions are likely to be helpful for the authors. By providing a specific interpretation of the energy concept and asking for clarification on the peak in Figure 5, the reviewer is directly addressing potential points of confusion and providing actionable feedback. This is a valuable contribution to the review process, as it guides the authors on how to improve their understanding and presentation of the concept."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer requests a breakdown of how individual components contribute to performance improvements. While the request is somewhat implicit, the act of providing such a breakdown can be considered an action taken by the authors to understand the impact of different components. However, the request lacks specific details on *which* components and *how* they contribute, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'Linformer', 'window attention', and 'contrition' by name, indicating a degree of grounding regarding the components being discussed. However, the reviewer does not explicitly state how these components contribute to performance improvements. The request is for an explanation of their contribution, which is missing. Therefore, the grounding is present but lacks specificity in explaining the contribution.", "verifiability_rationale": "The reviewer states 'it would be better if how each of them contributes to the final performance improvements are given, e.g., how the performance of simply combining the Linformer and the window attention in Big Bird using contrition'. This statement clearly presents a claim about the contribution of specific components to performance. The reviewer also provides an example ('simply combining the Linformer and the window attention in Big Bird using contrition') to illustrate the desired explanation. This provides some level of justification for the claim.", "helpfulness_rationale": "The reviewer explicitly states 'it would be better if how each of them contributes to the final performance improvements are given, e.g., how the performance of simply combining the Linformer and the window attention in Big Bird using contrition'. This is a direct and clear request for information that would significantly improve the authors' understanding and potentially their work. The reviewer's statement itself is a helpful suggestion for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem (unknown role of visual information) and suggests an action (the ablation study should verify it). The mention of 'implementation detail' is also explicit. Therefore, it's **Explicit**. The reviewer clearly states the *specific* ablation study (Table 10) and the *specific* module (perception module). The request for 'detailed implementation' is also concrete. Therefore, it's **Concrete**.", "grounding_specificity_rationale": "The reviewer explicitly names the ablation study in Table 10 and the 'perception module'. This is a clear and specific reference point. Therefore, it's **Fully Grounded**. The reviewer clearly specifies *what* is missing ('implementation detail') and *what* needs to be verified ('statistical significance'). This is highly specific. Therefore, it's **Fully Specific**.", "verifiability_rationale": "The reviewer makes a clear claim: 'The ablation study does not explicitly verify the effectiveness' and further elaborates with specific evidence from Table 10 and the statistical significance concern. This constitutes a **Claim**. The reviewer provides specific evidence (similar performance in Table 10, sample size, lack of implementation details) to support their claim. This evidence is logical and points to a potential issue. While it doesn't definitively prove the effectiveness is *lack* of verification, it strongly suggests it. Therefore, it's **3**.", "helpfulness_rationale": "The reviewer provides specific information about the ablation study and the potential issues with the 'w/o perception' experiment. They highlight a concrete area for the authors to investigate and improve their statistical analysis. This directly addresses a potential weakness and suggests a concrete next step. Therefore, it's **5**."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that previous works on Lasso screening are not cited or compared, which is a direct criticism of a specific claim in the paper. The action is to identify missing citations and comparisons.", "grounding_specificity_rationale": "The review point explicitly refers to 'the end of Sec. 4.2' and the specific claim 'Transfer Lasso showed the best accuracy in feature screening'. This is a clear and precise identification of the relevant part of the paper and the issue.", "verifiability_rationale": "The review point contains a claim (that previous works are not cited or compared) and provides a clear reason (lack of citation and comparison) for this claim. While it doesn't provide specific examples of missing works, the reasoning is logical and actionable for the authors.", "helpfulness_rationale": "The review point directly identifies a weakness in the paper (lack of context and comparison to prior work) and provides a clear direction for improvement (cite and compare). This is immediately actionable and helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the authors' claim and points out the specific errors in the CLT statement. The phrase \"this statement makes multiple incorrect assertions\" indicates a clear action the authors should take: to correct their understanding of the CLT's limitations. While the reviewer doesn't provide a direct solution, they identify the problem clearly.", "grounding_specificity_rationale": "The reviewer directly references \"line 238\" of the paper, providing a specific location for the problematic statement. They also clearly identify the specific errors in the authors' claim regarding the CLT. This strong grounding allows the authors to directly address the issue in their own text.", "verifiability_rationale": "The reviewer presents a claim that the authors' statement is incorrect. They provide logical reasoning and references to statistical principles (like the limitations of the CLT in nonasymptotic regimes) to support their claim. While they don't provide external citations, the reasons for the error are generally verifiable within the field of statistics.", "helpfulness_rationale": "The reviewer directly points out specific errors in the authors' claim about the CLT and explains why these errors exist. This is 5 because it guides the authors to identify and correct a specific, potentially confusing, point in their own description of the CLT. While the reviewer doesn't explicitly tell them how to fix it, they provide a clear direction for improvement."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The request explicitly states 'analyze the time complexity' which is an action. However, it lacks the specifics of what aspects of the time complexity should be analyzed or the criteria for the analysis. Without knowing the specific policies, the action is incomplete.", "grounding_specificity_rationale": "The request mentions 'policies mentioned in Section 4' but does not specify which section or table contains these policies. Therefore, the authors cannot confidently identify the referenced part. The request also does not specify what needs to be analyzed within these policies, making it not specific.", "verifiability_rationale": "The request is a claim (a request for analysis) but lacks supporting evidence or logical reasoning. The reviewer assumes the authors will perform this analysis without providing justification.", "helpfulness_rationale": "The request is relevant to the field of algorithm analysis (time complexity). However, it lacks the specifics of which policies need analysis and what aspects of their time complexity are important. This lack of detail makes the request less actionable and therefore less helpful to the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The reviewer's point is about the *proposed method* itself, not an explicit action or suggestion. While the reviewer identifies areas where the proposed method might fall short (ineffectiveness of automatic scores, cost of human evaluation, limitations of arenabased systems), they don't explicitly state what action or suggestion the proposed method offers. The criticism is more about the potential drawbacks of the method rather than a direct critique of a stated action.", "grounding_specificity_rationale": "The reviewer's criticism is general and doesn't specify which part of the proposed method (FFAEVAL) they find ungrounded. They broadly criticize the effectiveness and cost of different evaluation methods. Without specific details about the proposed method, it's difficult to determine if the reviewer can confidently pinpoint the referenced part. Therefore, I consider it 1.", "verifiability_rationale": "The reviewer provides specific criticisms about the limitations of automatic scores, human evaluation, and arenabased systems. These criticisms are based on logical reasoning and common knowledge about the challenges in evaluating dialogue systems. While the *proposed method itself* isn't described in detail, the reviewer's statements about its potential drawbacks are verifiable based on existing knowledge of evaluation challenges. Therefore, I consider it 3 as the reviewer provides reasons for their assessment, but without a clear claim about the proposed method, it's hard to be 5.", "helpfulness_rationale": "The reviewer explicitly states that the proposed method is '1' and provides reasons why, such as the ineffectiveness of automatic scores, the unaffordable nature of human evaluation, and the limitations of arenabased systems. These are strong negative statements directly addressing the value of the proposed method. Therefore, I consider it highly unhelpful as the reviewer provides a clear and strong assessment of its potential shortcomings."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question and provides a suggestion (please define t_R^m) regarding a specific part of the paper mentioned in the review. This constitutes an explicit action, and the suggestion is concrete, indicating a clear next step for the author. The reviewer is directly prompting the author to clarify a specific point and provide a definition, which is a clear and actionable request.", "grounding_specificity_rationale": "The reviewer directly refers to t_R^m in the equation mentioned in the review. While they don't explicitly state 'Section X, equation Y,' the context strongly implies they are referring to the equation mentioned in the review. This constitutes strong grounding as the reviewer can confidently identify the specific part of the paper being addressed. The reviewer also specifies what needs to be addressed \u2013 the definition of t_R^m.", "verifiability_rationale": "The review point does not contain a claim in the sense of asserting something is wrong or needs improvement. The reviewer is asking a question and making a suggestion. Therefore, there is X to verify. However, the suggestion to define t_R^m could be considered implicitly verifiable if the author can provide a definition or clarify the notation.", "helpfulness_rationale": "The reviewer's question directly addresses a potential ambiguity in the notation, which could hinder the author's understanding and subsequent work. The suggestion to define the term is a direct and actionable improvement. This is likely to be helpful for the author as it clarifies a key aspect of the paper and potentially resolves a point of confusion."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the observation about the BLEU1 scores (a bit worse) and directly suggests a verification step (statistically significant). This is a clear indication of an explicit and concrete action for the authors.", "grounding_specificity_rationale": "The reviewer refers to specific parts of the paper (table 6, row 3 and 4) and a specific metric (BLEU1). This strong referencing makes the grounding fully grounded. They also specify what needs to be addressed (verify the statistical significance).", "verifiability_rationale": "The reviewer makes a claim about the statistical significance of the improvements based on the numerical observation. They also suggest a method for verification (statistical significance testing). While the suggestion is present, it lacks specific details about the statistical test and its justification. Therefore, it is 3.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the results (lower BLEU1) and suggests a concrete action (statistical verification). This actionable feedback is helpful for the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'it would be good to compare to other existing methods', which is a direct and clear action for the authors to take.", "grounding_specificity_rationale": "The review point names specific methods (RefNeRF and MipNerf) and explains their relevance to the paper's focus on appearance decomposition and larger outdoor scenes, providing clear grounding and specific examples.", "verifiability_rationale": "The review point suggests comparing to specific methods, implying their existence and potential relevance, but doesn't provide explicit verification within the point itself.", "helpfulness_rationale": "This review point is 5 as it directly suggests concrete, actionable improvements to the paper. By recommending specific existing methods for comparison, it points the authors directly to a relevant area of related work and a clear direction for enhancing their evaluation. This is a very direct and useful suggestion that would likely improve the paper's positioning and validation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential ambiguity in the use of 'P', which could hinder understanding. While the reviewer identifies the issue, the specific action to take (e.g., using different notation or explicitly defining 'P') isn't immediately clear or actionable without further clarification from the authors. The inconsistency makes it difficult to know exactly what 'P' represents in different contexts.", "grounding_specificity_rationale": "The reviewer explicitly states where the confusion arises, pointing to specific equations (3 and 4) and line number (44) in the appendix. This demonstrates strong grounding as the authors can easily identify the specific part of the paper being addressed. The reviewer also clearly specifies what is wrong: the dual use of 'P' for probability and CDF. This is highly specific.", "verifiability_rationale": "The reviewer makes a clear claim that 'P' is used inconsistently for probability and CDF, leading to confusion. The reviewer provides specific evidence (equations 3 and 4, line 44 in the appendix) to support this claim. This claim is verifiable through direct examination of the manuscript. The logical reasoning supporting the claim is clear.", "helpfulness_rationale": "The reviewer identifies a specific and actionable issue in the manuscript, highlighting the inconsistent use of 'P'. The reviewer also suggests potential fixes (using different notation or explicitly defining 'P'). This feedback is clear, specific, and directly addresses a potential source of confusion for the authors, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the potential issue ('are all feature spaces wellsuited for 1NN?') and suggests a solution ('If feature dimensions are individually standardized, it would avoid this issue'). This makes the action clear and directly actionable for the authors.", "grounding_specificity_rationale": "The reviewer directly mentions 'line 213', providing a very specific location in the paper. This is strong grounding. The reviewer then elaborates on the issue by mentioning 'feature spaces', '1NN', 'spherical Gaussian', and 'individually standardized'. This provides a detailed explanation of the problem and the proposed solution within the context of the mentioned line.", "verifiability_rationale": "The reviewer makes a claim ('are all feature spaces wellsuited for 1NN?') and provides a reason ('If a feature space is not close to a spherical Gaussian, it may perform poorly.') and a potential solution ('If feature dimensions are individually standardized, it would avoid this issue'). This provides logical reasoning and a suggestion for improvement.", "helpfulness_rationale": "The reviewer's point is directly relevant to the performance of a commonly used method (1NN) and suggests a practical improvement by standardizing feature dimensions. This is likely to be helpful for the authors if they are using 1NN."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out two distinct issues in the text: the inaccurate description of reward in standard MDPs on line 143 and the unclear definition of actions on line 154. They state, 'This is not true of standard MDP formulations' regarding line 143, and ask a question about the nature of actions on line 154. These are clear, direct actions or suggestions for improvement. The reviewer also provides specific line numbers, indicating a clear understanding of the location of the issues.", "grounding_specificity_rationale": "The reviewer provides the exact line numbers (143 and 154) where the issues are located, demonstrating a strong grounding. They also explicitly explain the likely misunderstanding on line 143, stating 'This is not true of standard MDP formulations' and explaining the potential confusion between reward after state change and reward after action. Furthermore, they directly address the ambiguity on line 154 by asking a question about the nature of the actions. This level of detail and specificity clearly shows the authors can identify the relevant part of the paper and understand the issue.", "verifiability_rationale": "The reviewer makes a claim about the inaccuracy of the statement on line 143, stating 'This is not true of standard MDP formulations'. While the reviewer does not provide external references to support this claim, the claim itself is verifiable by comparing the text to the standard definition of reward in MDPs. The reviewer also clearly specifies the issue on line 154, asking about the nature of the actions. The claim is specific about the location and nature of the error, making it 3.", "helpfulness_rationale": "The reviewer identifies a potential source of confusion for readers regarding the description of MDPs. By pointing out the inaccurate phrasing on line 143 and the unclear definition of actions on line 154, the reviewer is providing actionable feedback that could help improve the clarity and accuracy of the paper. The reviewer's suggestion to clarify the reward mechanism is a direct and helpful improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the inconsistency between L_task and L_class. While it doesn't directly tell the authors what to do, it points to a clear discrepancy that needs attention. The action is implicit: the authors should be aware of this difference and ensure consistency in their naming conventions.", "grounding_specificity_rationale": "The review point mentions L_task and L_class, which are specific concepts within the text and figure. However, it doesn't pinpoint a specific element within these losses (e.g., a particular layer in a neural network, a specific metric within the loss function). The grounding is implied rather than explicitly stating a section, table, or figure number.", "verifiability_rationale": "The review point contains a claim: 'the task loss is called L_task in the text but L_class in figure 1'. This claim is verifiable because the reviewer is pointing out a discrepancy that can be confirmed by checking the text and the figure. The evidence for this claim is the explicit mention of L_task in the text and the reference to L_class in Figure 1.", "helpfulness_rationale": "The review point identifies a potential source of confusion for the authors regarding the naming of loss functions. While it doesn't provide a solution, it highlights a detail that could affect the clarity and reproducibility of their work. This level of detail can be helpful for the authors to ensure they are referencing the correct information consistently."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a clear problem: the evaluation methodology is criticized. This is an explicit statement of action. However, the *how* is vague. Therefore, the reviewer's point is 3 but lacks specific details on how the evaluation should be improved.", "grounding_specificity_rationale": "The reviewer criticizes the evaluation methodology (answer generation and summarization) as being 'close to \"open domain\" generation rather than \"close domain\" generation such as machine translation.' The reviewer does not explicitly identify a specific part of the paper being addressed by this criticism. The grounding is implied rather than explicit.", "verifiability_rationale": "The reviewer makes a claim about the evaluation methodology being 'close to \"open domain\" generation' and suggests machine translation as a more suitable 'close domain' task. The reviewer provides a logical reasoning: 'machine translation has known uncertainties, so the current evaluation is also \"close to \"open domain\"'. While the reasoning is present, it lacks specific examples or references to external works to fully verify the claim.", "helpfulness_rationale": "The reviewer suggests a different evaluation methodology (machine translation) as a way to improve the work. While this could be a helpful suggestion, it is not a direct, actionable improvement to the authors' current work. The reviewer does not provide specific steps or guidance on how to implement machine translation for evaluation. Therefore, the reviewer's point is 3 but lacks concrete suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "Part 1 of the review point is not actionable as it's a question about the significance of certain parts and a request for further investigation, not a direct suggestion for improvement. Parts 2 and 3 are explicit and point to specific missing elements, making them actionable. Therefore, the review point contains some actionable elements but also lacks clear instructions on how to apply them.", "grounding_specificity_rationale": "Part 1 of the review point is 1 as the reviewer is making a statement about the importance of certain parts without explicitly pointing to a specific section or element. Parts 2 and 3 are fully grounded as they explicitly point to specific locations in the paper (equation and a specific element within an equation).", "verifiability_rationale": "Part 1 of the review point is not verifiable as it's a statement about the importance of certain parts, not a claim requiring verification. Parts 2 and 3 are verifiable as they point out specific missing elements or notational errors that can be verified by examining the relevant sections of the paper. The missing notation and missing element are clear claims that can be supported by checking the equations.", "helpfulness_rationale": "Part 1 of the review point is not helpful as it's a question and request for clarification, not a suggestion for improvement. Parts 2 and 3 are helpful as they point out specific areas where the paper could be improved by correcting notational errors or specifying missing elements. These suggestions are actionable and directly address potential issues in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states the sentence is confusing and provides a specific line number. This suggests a potential lack of clarity or explicitness. While the reviewer identifies a problem, they don't explicitly state the next step the author should take. \"Reread\" is a suggestion, not a direct action.", "grounding_specificity_rationale": "The reviewer explicitly refers to \"the sentence 9395\". This clearly identifies the specific part of the paper being addressed, indicating strong grounding. The comment also directly asks the author to reread the sentence, which is a specific action within that part.", "verifiability_rationale": "The reviewer states the sentence is \"confusing\" and \"I believe I understood it after rereading it and the subsequent sentences but it is not immediately obvious what is meant.\" This is a statement of opinion and a claim about the clarity of the writing. The reviewer doesn't provide any external references or logical reasoning to support their claim about the sentence being confusing. They are stating their *perception* of the sentence's clarity.", "helpfulness_rationale": "The reviewer's primary goal is to help the author understand a confusing sentence. They suggest rereading, which is a common and often helpful debugging strategy. However, the reviewer doesn't explicitly state the next step the author should take. \"Reread\" is a suggestion, not a direct action. While the comment points to a specific area for improvement, it lacks a clear next action for the author."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "Lines 7879: 'yes, but you need a citation there'  This is an implicit action, as the reviewer is pointing out a potential improvement (using diffusion models) but doesn't explicitly state how the authors should apply this. Lines 129130: 'Previous work has tried to tackle... but with limited success'  This is an implicit action, as the reviewer is pointing out a limitation of previous work, but the authors need to infer how to address this limitation. Lines 156158: 'This improves the reliability and efficiency, because diffusion models are more compute efficient a training smaller dimensional latent variables and input tokens inherently have different lengths'  This is an implicit action, as the reviewer is providing a reason why diffusion models are efficient, but the authors need to infer how this relates to their work. Lines 217218: ' we can always sample more efficiently using different samplers from the literature that trade off sample quality.'  This is an explicit action, as the reviewer is directly suggesting a method for improvement.", "grounding_specificity_rationale": "Lines 7879: 'diffusion models'  While the reviewer mentions a specific area, they don't pinpoint the exact section, table, figure, or unique aspect of the paper being addressed. Lines 129130: 'previous work'  The reviewer mentions a general category of work without specifying which part of the paper or section it refers to. Lines 156158: 'diffusion models'  Similar to lines 7879, this is a general mention without specific grounding. Lines 217218: 'diffusion models'  Again, a general mention without specific grounding.", "verifiability_rationale": "Lines 7879: 'yes, but you need a citation there'  The claim is that diffusion models outperform GANs, but there is no citation provided to support this claim. Lines 129130: 'Previous work has tried to tackle... but with limited success'  This is a claim about previous work, but there is no citation provided to support this claim. Lines 156158: 'This improves the reliability and efficiency, because diffusion models are more compute efficient a training smaller dimensional latent variables and input tokens inherently have different lengths'  This is a claim about efficiency, but there is no citation provided to support this claim. Lines 217218: ' we can always sample more efficiently using different samplers from the literature that trade off sample quality.'  This is a claim about sampling methods, but there is no citation provided to support this claim.", "helpfulness_rationale": "Lines 7879: 'yes, but you need a citation there'  While the reviewer points out a potential improvement, they don't explain *why* it's an improvement or provide evidence, making it 3 but lacking depth. Lines 129130: 'Previous work has tried to tackle... but with limited success'  This points out a limitation, which is helpful for the authors to consider. Lines 156158: 'This improves the reliability and efficiency, because diffusion models are more compute efficient a training smaller dimensional latent variables and input tokens inherently have different lengths'  This provides a reason for efficiency, guiding the authors towards a potentially better approach. Lines 217218: ' we can always sample more efficiently using different samplers from the literature that trade off sample quality.'  This suggests an alternative method, which is helpful for the authors to explore."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the inconsistency between Fig 1 and Fig 2 and provides a specific suggestion for how the shared encoderdecoder should be used. The action of identifying the discrepancy and suggesting a change is direct and clear.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Fig 1' and 'Fig 2' by name, grounding the comment in specific parts of the paper. Furthermore, they specify the *types* of diagrams in each figure ('scatter plot' and 'bar chart'), adding further specificity to the referenced elements.", "verifiability_rationale": "The reviewer identifies a discrepancy between two figures. While they suggest a change, they do not provide a logical justification or reference for why the inconsistency is a problem or why their suggestion is better. The reasoning is based on observation rather than verifiable evidence.", "helpfulness_rationale": "The reviewer points out a potential source of confusion for the reader regarding the diagrams in the paper. While the action is explicit and the grounding is specific, the lack of explanation for *why* the inconsistency is a problem makes the feedback less actionable and therefore less helpful for the reader."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer is directly asking for a clarification on how a specific inequality follows from a previous result (Lemma 7). This is a clear and explicit request for an action: to explain the connection between the inequality and Lemma 7. The reviewer is not stating a fact but rather asking for a justification or explanation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Lemma 7' and the inequality after line 433. This demonstrates a strong grounding in the specific part of the paper being discussed. The reviewer is not making an educated guess or inferring the relevance of these elements but is directly pointing to them.", "verifiability_rationale": "The reviewer is asking for a clarification on a mathematical step. While the statement itself is not an opinion, the request for clarification implies that the connection between the inequality and Lemma 7 is not immediately clear or obvious. Therefore, it is not 'X' (X) and requires justification, making it 'partially verifiable'.", "helpfulness_rationale": "The reviewer is directly addressing a potential point of confusion for the authors by asking for clarification on a specific mathematical step. This is a constructive and helpful suggestion, as it directly addresses a potential weakness in the paper and encourages the authors to seek a better understanding. The reviewer is not merely pointing out a problem but is actively seeking to improve the clarity of the presentation."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "Both suggestions in the review point are implicitly suggesting an action. The first suggests including results, and the second suggests evaluating performance. However, the actions are not explicitly stated, and the details on how to perform these actions are missing, making them only 2.", "grounding_specificity_rationale": "The review point explicitly mentions specific components: 'the bottomup method 9', 'crowdpose dataset', 'Table 4', 'MS coco dataset', and 'easy (non occluded) settings'. This indicates a high level of grounding specificity as the authors can easily identify the referenced parts and the specific aspects being addressed.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It consists of suggestions for future actions and experiments, not statements that need to be proven or justified. Therefore, it has X and is not verifiable.", "helpfulness_rationale": "The review point offers suggestions for improving the authors' work by including results on a new dataset and evaluating performance on a standard dataset. While these suggestions are relevant and could be helpful, they lack specific details on how to implement them, making them somewhat vague and less immediately actionable. Therefore, they are 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states: \"The claim of making use of \u201cannotation guideline\u201d may be an overstatement  this paper only considered label name, label description and fewshot examples, however, annotation guideline in IE domain are very complicated and was curated by linguists. E.g., For TACRED slot filling (https://tac.nist.gov/2015/KBP/ColdStart/guidelines/TAC_KBP_2015_Slot_Descriptions_V1.0.pdf), section 3.6 per:city_of_birth, they use \u201cGPEs below the city level (e.g. 5 boroughs of New York City) are not valid fillers.\u201c as an example rule to guide annotators. The prompts proposed by this paper might not fully capture the depth of true guideline understanding.\" This is a statement of a potential overstatement and a description of what the paper *did*. It doesn't explicitly state an action or a concrete step to be taken. Therefore, it is not fully actionable.", "grounding_specificity_rationale": "The reviewer states: \"The prompts proposed by this paper might not fully capture the depth of true guideline understanding.\" This statement directly refers to the *prompts* proposed by the paper, which are a specific part of the methodology. The reviewer is not just saying \"this paper did something\", but specifically pointing to a deficiency within the paper's proposed method. Therefore, it is fully grounded. Furthermore, the reviewer *specifies* what they think is missing  the complexity of humancurated annotation guidelines. This is a clear statement about the content.", "verifiability_rationale": "The reviewer states: \"The prompts proposed by this paper might not fully capture the depth of true guideline understanding.\" This is a claim made by the reviewer. To verify this claim, we would need to examine the prompts proposed by the paper and assess their ability to capture the complexity of annotation guidelines. However, the review point does not provide any specific examples of the prompts or cite any external sources to support this claim. The criticism is general and lacks evidence. Therefore, it is 1.", "helpfulness_rationale": "The reviewer states: \"The claim of making use of \u201cannotation guideline\u201d may be an overstatement  this paper only considered label name, label description and fewshot examples, however, annotation guideline in IE domain are very complicated and was curated by linguists. E.g., For TACRED slot filling (https://tac.nist.gov/2015/KBP/ColdStart/guidelines/TAC_KBP_2015_Slot_Descriptions_V1.0.pdf), section 3.6 per:city_of_birth, they use \u201cGPEs below the city level (e.g. 5 boroughs of New York City) are not valid fillers.\u201c as an example rule to guide annotators. The prompts proposed by this paper might not fully capture the depth of true guideline understanding.\" This review points out a potential overstatement regarding the use of annotation guidelines and raises a concern about the prompts' ability to capture the complexity of these guidelines. While the reviewer identifies a potential issue, they do not offer any concrete suggestions or actions for the authors to take. The feedback is informative but lacks actionable steps."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the weakness: 'the author only compare their method to the BERTbaseline.' This is a clear and direct statement of the missing comparisons. It also concretely identifies the *missing* baselines: 'token pruning and token combination baselines.' While it doesn't suggest *how* to implement these, it clearly points out the *what*. Therefore, it provides actionable information for the authors to improve their experimental setup.", "grounding_specificity_rationale": "The review point mentions 'experimental comparison' as a specific area for weakness. While it doesn't pinpoint a specific section, table, or figure, the focus on the *type* of comparison is somewhat specific. The missing baselines ('token pruning and token combination baselines') are also mentioned, although not with perfect precision. Therefore, while not fully grounded, it has some grounding related to the type of comparison.", "verifiability_rationale": "The review point makes a claim: 'the author only compare their method to the BERTbaseline. The author should compare their method to token pruning and token combination baselines.' This claim suggests a weakness in the experimental setup. However, it doesn't provide specific evidence or references to support this claim. It's a suggestion for improvement rather than a verifiable statement based on logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point clearly identifies a weakness in the experimental comparison and provides a specific suggestion for improvement: comparing to 'token pruning and token combination baselines.' This directly addresses a potential area for enhancement in the authors' work. It guides the authors towards considering specific types of baselines that could strengthen their experimental evaluation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a specific action: 'Compare to coordinateaware methods like TFN or SchNet.' This is a clear indication of an actionable suggestion, as it directly points the authors to a relevant improvement. The suggestion is not just a comment but a concrete next step in their research.", "grounding_specificity_rationale": "The review point refers to 'the experimental section' as the area for comparison. While it doesn't pinpoint a specific subsection or table, the reference is precise enough to be considered fully grounded. The reviewer clearly identifies the section where the comparison should take place. Furthermore, the suggestion is specific about the methods to compare against (TFN and SchNet).", "verifiability_rationale": "The review point makes a claim: 'A comparison to coordinateaware methods, such as TFN or SchNet, seems appropriate.' This claim is verifiable because the reviewer is suggesting a comparison to methods that are wellestablished in the field as coordinateaware. While the reviewer doesn't provide a detailed explanation of why these methods are relevant, the suggestion is based on common knowledge and logical reasoning within the domain of geometric deep learning.", "helpfulness_rationale": "The review point is 5 because it directly suggests a specific and relevant improvement to the experimental section. By recommending a comparison to coordinateaware methods like TFN and SchNet, the reviewer provides the authors with a clear direction for enhancing their work. This actionable feedback is likely to be beneficial for the authors in understanding the limitations of their current approach and incorporating more relevant baselines."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out a lack of detail in the related work. This suggests the reviewer *identified a problem* (insufficient related work), but didn't *suggest a specific action* to improve it. The suggestion to \"give more work on GLN\" and \"reflect the advantages or difference of the proposed method, such as the difference from BGLN\" is a statement of what *should* be done, not a concrete action the authors can take *now*. The reviewer is identifying a gap in the background, but not providing a direct path to fill it.", "grounding_specificity_rationale": "The reviewer mentions \"related work\", \"GLN\", and \"BGLN\". This indicates they are referring to specific areas or concepts within the paper. However, they don't explicitly state *which* parts of the related work are lacking or *how* GLN or BGLN differ. The grounding is present in identifying the general area, but it's not specific enough to pinpoint the exact issue or provide a clear direction for comparison.", "verifiability_rationale": "The reviewer states \"the introduction of related work is not sufficient\" and \"more work on GLN should be given\". These statements express a judgment about the current state of the related work. However, the reviewer doesn't provide any logical reasoning, common knowledge, or external references to *support* this claim. It's presented as a statement of what is missing, not a claim that can be verified or refuted.", "helpfulness_rationale": "The review point primarily identifies a deficiency in the related work section. While the reviewer suggests adding more work on GLN, this is a suggestion for improvement rather than a specific, actionable piece of feedback that the authors can directly implement. The feedback doesn't offer concrete steps or guidance on how to address the identified gap. It's about pointing out a problem without providing a clear path to solution."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment points out a difference in the number of dropout rates used for different approaches but does not explicitly suggest a change or action to be taken by the authors. It raises a question about the rationale behind this difference, which is a valid point but not directly actionable for improving the draft itself.", "grounding_specificity_rationale": "The comment refers to 'Moon's approach' and 'Variational dropout,' which are specific methods. However, it doesn't explicitly name sections, tables, or figures. The grounding is weakly grounded as the authors can infer the methods but it's not explicitly stated.", "verifiability_rationale": "The comment identifies a difference in hyperparameter settings but does not provide any justification or reasoning for why a single dropout rate is used for Moon's approach. It lacks any supporting evidence or logical reasoning, making it 1.", "helpfulness_rationale": "The comment points out a potential inconsistency in the hyperparameter settings for dropout. While this highlights a potential area for clarification in the original paper, it doesn't directly suggest a concrete improvement or action for the authors. The feedback is more of a question than a direct suggestion for change."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'no information from 2hop neighbors is included' and suggests an 'action' of including it. This directly tells the authors what to do and how to do it.", "grounding_specificity_rationale": "The review point refers to '2hop neighbors' without specifying the exact part of the paper being addressed. While the concept is implied, the specific section or table where this information might be discussed is not mentioned. The reviewer is making an inference about what might be missing, rather than directly pointing to a specific element.", "verifiability_rationale": "The review point contains the claim 'again, this method is simple, but it is highly unclear why it is effective.' This claim is not supported by any evidence or reasoning within the review point itself. The reviewer expresses uncertainty without providing examples or references to back up their assertion about the method's effectiveness.", "helpfulness_rationale": "The review point directly suggests a concrete improvement to the authors' work by stating 'again, this method is simple, but it is highly unclear why it is effective' and then suggesting 'including 2hop neighbors'. This is a clear and actionable suggestion that empowers the authors to potentially refine their method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks for clarification on the training procedure of the model in Figure 7, which is a direct request for information. However, the request is framed as a question rather than a direct instruction on what to do with the information.", "grounding_specificity_rationale": "The reviewer asks 'Was it on full field flicker stimulus changing contrast with a fixed cycle?' This is a specific question about the training data. However, the original paper likely already mentions the full field flicker stimulus, so the reviewer is inferring the training data based on the figure caption and the context of the paper.", "verifiability_rationale": "The reviewer makes a claim about the model's inability to handle longer time scales and asks if the adaptation time scale would change. While the reviewer mentions the model's limitation, the original paper doesn't explicitly state this limitation in the same way. The reviewer is making an inference and asking a question, and while they mention Smirnakis et al., the connection isn't explicitly stated in the review point itself.", "helpfulness_rationale": "The reviewer's request to clarify the training procedure of the model in Figure 7 is highly relevant and directly addresses a need for understanding the experimental setup. While it's phrased as a question, it clearly identifies a missing piece of information that would be helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the potential problem with comparing experiments using different amounts of data and proposes a solution by suggesting comparisons with equal data. This is a clear and actionable point, as it directly addresses a potential flaw in the experimental design and provides a concrete direction for improvement. The reviewer identifies the issue and suggests a specific action (comparing with equal data).", "grounding_specificity_rationale": "The reviewer explicitly names the experimental setups (H>N, H>N+B, etc.) and explains why the data difference is a concern. This demonstrates strong grounding specificity, as the reviewer accurately identifies the parts of the paper being discussed and clearly explains the issue. The reviewer not only names the experiments but also articulates the logical consequence of comparing them with unequal data.", "verifiability_rationale": "The reviewer identifies a potential flaw in the experimental design (unequal data in comparisons) and proposes a solution involving more controlled experiments. This claim is verifiable through logical reasoning. The reviewer's point is based on a logical principle: for valid comparisons, the manipulated variables (in this case, the amount of data) should be held constant. This is a verifiable principle of experimental design.", "helpfulness_rationale": "The reviewer's point directly addresses a potential issue with the experimental methodology and could help clarify the data usage. While the reviewer doesn't propose a specific action for the author, they highlight a potential problem that could hinder the author's interpretation. This is helpful in identifying a potential area for further consideration or clarification. The reviewer's point is relevant to understanding the limitations of the comparisons."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer's questions directly address how the algorithm should be used and what information is needed. The questions about T > 2 and the placement of the comment are actionable suggestions. The reviewer wants to know the typical behavior of Algorithm 1 with more iterations and where the comment about the algorithm should be placed. These are specific and actionable requests for improvement.", "grounding_specificity_rationale": "The reviewer's questions about Algorithm 1 and Laplacian eigenmaps are specific to the paper's content. The comment about the placement of the comment is also specific. The reviewer can confidently identify the section where Algorithm 1 is described (Section 4) and knows that a citation is needed for Laplacian eigenmaps, which is typically found in the introduction. The information is directly requested.", "verifiability_rationale": "The reviewer's claim is that Algorithm 1 typically runs with T >> 2 and that a reference is needed. This claim is verifiable based on common practices in iterative algorithms. The reviewer is making a logical deduction about the typical behavior of such algorithms. The missing citation is a clear lack of information that needs justification. The claim is supported by logical reasoning and a missing reference, making it partially verifiable.", "helpfulness_rationale": "The reviewer's questions are directly aimed at improving the paper's clarity and completeness. The reviewer wants to understand the typical behavior of Algorithm 1 with more iterations and why a specific citation is missing. These questions are actionable and likely to be helpful for the authors in understanding and improving their work. The information provided in the review point is likely to be valuable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer's comment is a general criticism of the paper's organization and focus, specifically questioning the relevance of the ResNet architecture description to the Conditional Batch Normalization (CBN). While the comment identifies a potential issue (excessive detail on ResNet), it doesn't explicitly state what is missing or how the CBN could be improved. The reviewer implies a lack of clear motivation for the CBN by suggesting it distracts from the core contribution. However, the comment doesn't pinpoint specific, actionable improvements to the CBN itself, focusing more on the presentation of the ResNet section.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly pointing to a specific section or detail within the paper that needs clarification. They are making a general statement about the inclusion and relevance of the ResNet architecture description. While they imply that the description might be distracting, they don't identify a specific element within the description that is unclear or needs to be grounded in the paper. The comment is more about the logical flow and motivation rather than pinpointing a specific missing piece of information.", "verifiability_rationale": "The reviewer's comment is not presented as a claim that requires verification. They are expressing an opinion about the organization and focus of the paper, suggesting that the ResNet description might be unhelpful and that the benefits of CBN are clear. There is no explicit statement that needs to be supported by evidence or references. The comment is a critique of the presentation rather than a statement that requires logical reasoning or external references.", "helpfulness_rationale": "The reviewer's comment is 3 in identifying a potential issue with the paper's structure and focus. They point out that the description of the ResNet architecture might be detracting from the emphasis on the Conditional Batch Normalization (CBN). This could lead readers to question the clarity and motivation for the CBN. However, the comment doesn't offer specific, actionable improvements to the CBN itself. It primarily criticizes the *organization* of the paper rather than providing concrete suggestions for *how* the CBN could be better explained or motivated."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a lack of clarity regarding the sparsity of a matrix, making it partially actionable. However, it doesn't provide a concrete solution, thus it's 2.", "grounding_specificity_rationale": "The review point explicitly refers to 'equation (1)' and the 'resulting matrix', making it 5.", "verifiability_rationale": "The review point is a question about a missing detail, not a claim requiring verification. Therefore, it has X and is labeled 'X'.", "helpfulness_rationale": "The review point identifies a potential issue (sparse matrix) without offering a solution. This is helpful in pointing out a potential problem but lacks actionable improvement, making it 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the lack of direct evidence for the motivation and provides a concrete suggestion for how to verify it by plotting a figure of accuracy over time. The action is clearly identified and the method for implementation is specified.", "grounding_specificity_rationale": "The reviewer identifies the issue of motivation decline but does not specify a particular section, table, or figure within the paper where this decline occurs. They are addressing the general concept of predictor accuracy over time.", "verifiability_rationale": "The reviewer makes a claim about the lack of direct evidence for the motivation and provides a method (plotting a figure) to verify this claim. The suggestion is specific and actionable.", "helpfulness_rationale": "The reviewer's comment is highly specific, identifying a potential weakness in the motivation and providing a clear direction for the authors to address it by visualizing the accuracy decline. This directly empowers the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises several points that, while not inherently actionable, could be made actionable with further clarification. The request for a clearer definition and calculation of 'excessive risk' in line 103 is a direct request for an explicit action. The question about negative values, while not explicitly stated as an action, implies a desire for an explicit action to understand how the optimal solution \u03b8* can be negative. The observation about positive values in figures could be made actionable by asking for clarification or explanation. The request for justification of excessive risk as a fairness measure is a direct request for an explicit action. However, the lack of explicit instructions or clear actions makes the overall comment borderline. The reviewer doesn't provide concrete steps on how to address the questions, making it difficult to pinpoint actionable items.", "grounding_specificity_rationale": "The reviewer's comment is 1 in the paper. They are asking for clarification on a concept (excessive risk) without explicitly referencing a specific section, table, or figure. The comment is vague and doesn't identify where the issue lies. The comment is also underspecific, as it asks for a general explanation of excessive risk and its comparability. There is no mention of a specific part of the paper being addressed. Therefore, the grounding is weak because the reviewer doesn't identify a specific element of the paper they are referring to.", "verifiability_rationale": "The reviewer's comment is verifiable. They are asking for a definition and calculation of 'excessive risk', which is a claim that requires justification. They are also asking for an explanation of why excessive risk is a good representation for fairness, which is another claim that needs justification. The paper should provide a clear definition of excessive risk, a method for calculating it, and a justification for why it's a good fairness metric. The lack of explicit justification makes the claim 1. The reviewer is asking for information that needs to be present in the paper for the claim to be verifiable.", "helpfulness_rationale": "The reviewer's comment is not 5 because it lacks explicit and actionable requests. While the reviewer raises valid points, they don't provide concrete steps on how to address them. The questions are not framed as explicit actions that the authors can take. The reviewer doesn't suggest any improvements to the paper based on their feedback. The comment is more of a request for clarification and justification rather than a direct suggestion for improvement. The lack of explicit actions makes it difficult for the authors to directly use the feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point provides an explicit action: clarifying the dependence of the optimistic parameter on 'a'. While the ellipsis suggests this, the reviewer explicitly states 'a single optimistic parameter'. However, the reviewer does not provide concrete details on *how* this dependence should be clarified or what specific information is needed. The action is implied but not fully executed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'a single optimistic parameter' in relation to 'for every arm a', making the grounding clear. The reviewer also explicitly states the alternative initialization strategy, making the grounding complete.", "verifiability_rationale": "The reviewer provides a clear explanation of the implication of 'for every arm a' and suggests a specific alternative initialization strategy with a derived condition. This provides sufficient justification for both points.", "helpfulness_rationale": "The review point provides a clear suggestion for improvement by clarifying the dependence of the optimistic parameter and proposing an alternative initialization strategy. This directly addresses potential ambiguities and offers a concrete change."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action: 'Define L and E in the immediate vicinity.' This is a clear and actionable suggestion that authors can directly implement to improve the clarity of the text. The suggestion is directly derived from the identified issue.", "grounding_specificity_rationale": "The reviewer identifies the specific location of the issue ('line 296') and suggests a solution ('define L and E in the immediate vicinity'). This demonstrates strong grounding as the authors can precisely identify the problematic part of the paper. The suggestion is also specific, indicating where the definition should occur.", "verifiability_rationale": "The reviewer claims there is an inconsistency in the formatting of L and E. This is a verifiable claim as it points to a specific observation within the text. While no external references are provided, the inconsistency itself serves as the evidence. The claim is directly supported by the observed difference in formatting at line 296 and 302.", "helpfulness_rationale": "The reviewer provides a clear and direct suggestion to improve the clarity of the text by defining L and E. This is immediately helpful to the authors as it directly addresses a potential point of confusion or lack of clarity. The suggestion is actionable and specific."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment 'More experiments are required' does not specify what action the authors should take. It suggests a general improvement but lacks concrete steps or details on how to achieve it.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper (e.g., a section, table, or figure) that is weak. It is a general statement about the experimental section being weak, without pinpointing the exact issue.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a suggestion for more experiments, not a statement that needs supporting evidence.", "helpfulness_rationale": "The comment is a general suggestion for more experiments but lacks specific details on what experiments to add, why they are needed, or how to design them. This generality makes it less helpful for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit suggestions for improving the writing in specific locations. For example, it suggests adding 'ing' to 'compact' on line 2, changing 'of' to 'to' on line 56, and changing 'to' to 'to' on line 158. While the last point is slightly less explicit, it still points to a specific area for improvement. Each point suggests a concrete action the authors should take.", "grounding_specificity_rationale": "The review point explicitly identifies the specific lines where potential issues exist. For example, it states \"Despite of being compact\u00e2\u0080\u009d > \u00e2\u0080\u009cDespite being compact\u00e2\u0080\u009d\" on line 2, indicating a precise location. Similarly, it refers to specific line numbers (56 and 158) for the identified issues. The reviewer also points to a specific part of the sentence on line 265, further demonstrating strong grounding.", "verifiability_rationale": "The review point contains suggestions that are supported by common knowledge and general writing principles. For instance, the suggestions on lines 2, 56, and 158 are based on specific grammatical rules. The suggestion to rephrase the sentence on line 265 is based on the general principle of improving clarity and conciseness in writing. While not backed by a specific citation, the suggestions are logically derived from established practices.", "helpfulness_rationale": "The review point provides specific suggestions that are likely to be helpful to the authors. By pointing out specific grammatical errors and suggesting improvements in writing style, the reviewer is directly addressing potential areas of concern. The suggestions are actionable and would likely lead to tangible improvements in the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks a question ('Does the proposed method perform better...') and suggests a comparison ('it would be interesting to see a comparison...'). This constitutes an explicit action, and the action is concrete as it specifies the comparison between sequential and combinational design. The reviewer is directly prompting the authors to investigate a specific aspect of their method.", "grounding_specificity_rationale": "The review point explicitly mentions 'pure combinational logic (without register)' as the context for the performance comparison. This directly grounds the comment to a specific part of the paper and clearly identifies the issue being addressed. The comment also specifies the difference between 'sequential design' and 'combinational design', further specifying the area of comparison.", "verifiability_rationale": "The review point contains a claim ('it would be interesting to see a comparison...') that suggests a suggestion for further analysis. While the suggestion itself isn't a direct call for evidence, it implies a need for empirical data (the comparison). The reviewer doesn't explicitly state *how* this comparison should be done, making it somewhat underspecific in terms of verifiable evidence. However, the suggestion is based on a logical inference from the observation of the potential simplification with combinational logic.", "helpfulness_rationale": "The review point raises a valid question about the potential benefits of a simpler design approach and suggests a valuable experiment ('it would be interesting to see a comparison...'). It provides a clear direction for the authors to explore the relationship between register usage and performance. The point is specific to the proposed method and offers a concrete next step for investigation. While it doesn't provide a definitive answer, it prompts further analysis and could lead to valuable insights."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer is explicitly asking for the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This is a direct and explicit request for information that would allow the authors to understand how well the baseline performs in capturing topic transitions.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'LDA+LSTM' baseline and the 'topic switch percent' metric. This clearly grounds the request in a specific part of the paper and a specific aspect of its performance.", "verifiability_rationale": "The reviewer is asking for a performance metric, which implies a measurable value. The 'topic switch percent' is a standard metric used to evaluate topic models. Therefore, the information is likely verifiable, assuming the paper includes this metric.", "helpfulness_rationale": "The reviewer is asking for a specific piece of information (performance metric) that would likely help the authors understand the effectiveness of their baseline LDA+LSTM model in capturing topic transitions. This is a relevant and useful piece of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desired action: 'bold numbers for the baselines' and specifies the scope: 'specifically for WMT17WIKT the best result... is actually in the baselines.' This indicates a clear intention to improve the presentation of information.", "grounding_specificity_rationale": "The reviewer directly references 'Table 4' and the 'baselines' within it. This shows a clear identification of the specific part of the paper being addressed, indicating strong grounding. They also point out a specific issue ('the best result... is actually in the baselines'), adding to the specificity.", "verifiability_rationale": "The reviewer points out a factual inconsistency: the claim that the best result is in the proposed method's results, but the actual best result is in the baseline. This discrepancy can be verified by examining the table's data. The reviewer's statement is a logical deduction based on the presented information.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion: 'bold numbers for the baselines'. They also point out a potential error in the presented results ('the best result... is actually in the baselines'). This directly addresses a potential issue and suggests a concrete improvement to the presentation of the results, making it 5 for the authors to understand and implement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment 'unreliable neighbors' is vague and doesn't explicitly state the action to be taken. While it implies a potential issue, it doesn't provide a clear path for improvement. The action of identifying and addressing 'unreliable neighbors' is not made concrete. Therefore, it is considered **vague**.", "grounding_specificity_rationale": "The comment 'unreliable neighbors' is 1 as it does not specify which part of the paper or element is being referred to. The term 'neighbors' is very broad and lacks precision. Therefore, it is considered **1** and **not specific**.", "verifiability_rationale": "The comment 'unreliable neighbors' does not contain a claim that requires verification. It is more of a suggestion for clarification or improvement. There is no logical reasoning, common knowledge, or external references provided to support the need for examples of 'unreliable neighbors'. Therefore, it is considered **1**.", "helpfulness_rationale": "The comment identifies a potential area for improvement (need for examples) but fails to provide context, justification, or actionable steps. It is a request for more information without offering a clear path forward. Therefore, it is considered **2**."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer's point about the insufficient backing for the synergy between DQD and PPO, the missing mention of TD3GA, and the central claim about TD3GA being crucial is presented as a statement that needs further elaboration. While the reviewer identifies the *what* (insufficient backing, missing TD3GA mention), the *how* to improve the DQD framework is not explicitly stated. The reviewer points out a gap in the suggested improvement, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly states that the main paper does not mention the TD3GA algorithm. This clearly indicates a lack of explicit grounding regarding the specific algorithm being discussed. While the general point about the importance of comparisons is implied, the specific algorithm (TD3GA) is not mentioned, nor is it implied from the context of 'combining DQD with TD3 is crucial'. The grounding is weak because the reviewer cannot confidently identify the referenced part of the paper.", "verifiability_rationale": "The reviewer makes a claim that the main paper does not mention the TD3GA algorithm. This claim is verifiable based on the paper's content. The reviewer also implies that the comparison to TD3 is crucial, suggesting a justification for their point. However, the connection between the missing TD3GA mention and the central claim about its importance could be more explicit. The claim is 3 as it is supported by the missing information, but the reasoning could be clearer.", "helpfulness_rationale": "The reviewer's comment points out a genuine gap in the paper's analysis by highlighting the missing discussion of TD3GA. While the comment identifies a weakness and suggests a direction for improvement (understanding synergies), it does not provide concrete suggestions on how to address this weakness. The feedback is present but lacks actionable steps, making it 3."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "3 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "2 (2)", "actionability_rationale": "The review point asks a question about a surprising result rather than providing explicit instructions on how to improve the draft. The reviewer does not state what action the authors should take or how to implement it. The request is for an explanation, not a solution or modification.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Sections 6.1 and 6.2' in the paper, which grounds the comment in a specific part of the document. However, the comment does not specify what is wrong or needs improvement within those sections. It asks for an explanation of a general observation.", "verifiability_rationale": "The review point contains a claim: 'This could you explain why this occurs?'. However, the reviewer does not provide any evidence, reasoning, or external references to support this claim within the review point itself. The request is for clarification, not a justification based on existing information.", "helpfulness_rationale": "The review point is primarily a question seeking an explanation for a surprising result. While this can be helpful for understanding, it does not directly suggest concrete actions or improvements for the authors. The review point itself does not offer any actionable feedback or identify a clear weakness in the draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the desired experiment: 'It would make for a stronger case if the paper reports the numbers observed when the label noise experiment is performed on imagenet with 1000 classes as well'. This clearly identifies the action the authors should take. The action is also quite concrete, specifying the exact experiment to be included.", "grounding_specificity_rationale": "The comment explicitly mentions 'label noise experiment', 'ImageNet', and '1000 classes'. This clearly identifies the specific part of the paper and the details of the experiment being referred to. The grounding is very strong.", "verifiability_rationale": "The comment contains a claim: 'It would make for a stronger case if the paper reports the numbers observed when the label noise experiment is performed on imagenet with 1000 classes as well'. This claim is supported by the fact that the paper *does not* currently report these numbers, and the reviewer is suggesting it would be a valuable addition. The claim is somewhat implicitly supported by the absence of these results and the reviewer's implication that they would strengthen the paper.", "helpfulness_rationale": "The comment is a suggestion for the authors to include additional experimental results. While it doesn't directly instruct the authors on *how* to change their method, it points to a specific area where more evidence would be beneficial. The suggestion is clear and directly addresses a potential weakness (missing experimental validation on a standard benchmark with a known issue)."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states \"the evaluation in the paper is not sufficiently comprehensive and lacks transparency regarding the experiment setup.\" While it identifies a lack of comprehensiveness and transparency, it doesn't pinpoint *what* is missing in terms of actionability. The reviewer states a general limitation without specifying a concrete action or suggestion that the authors should take.", "grounding_specificity_rationale": "The review point is a general critique of the evaluation process. It doesn't specify a particular section, table, figure, or unique aspect of the paper being addressed. The reviewer mentions \"the experiment setup\" and \"one dataset\" as general areas of concern, without pointing to a specific element within the paper.", "verifiability_rationale": "The review point contains a claim: \"the evaluation in the paper is not sufficiently comprehensive...\" However, this claim is not supported by any specific evidence, logical reasoning, or external references within the review point itself. The reviewer states a limitation without providing justification or examples.", "helpfulness_rationale": "The review point identifies areas for improvement (transparency, exploring variations, using more datasets) but lacks specific details or concrete suggestions. While it points towards better evaluation practices, it doesn't provide the authors with a clear roadmap or actionable steps to take. The lack of specific examples makes it less helpful than a more detailed critique."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states the 'lack of comparative experiments' in Section 4.3 and suggests including 'bottleneck in ResNet' and 'linear bottleneck in MobileNetV2'. This is an explicit action identifying a specific weakness in the experimental setup. The suggestion is also concrete, naming specific types of nonlinear blocks. The reviewer is directly addressing a potential improvement to the paper's experimental validation.", "grounding_specificity_rationale": "The comment explicitly mentions 'Section 4.3' and names specific 'nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2'. This provides a clear and precise reference to the part of the paper being addressed. The reviewer is not making a general statement but rather pinpointing a specific area for improvement by referencing particular architectural features. This indicates strong grounding.", "verifiability_rationale": "The comment contains a statement ('In Section 4.3, there lack of comparative experiments...') which can be considered a claim. However, the reviewer does not provide any specific evidence, references, or logical reasoning to support this claim. The suggestion to include 'bottleneck in ResNet' or 'linear bottleneck in MobileNetV2' is a suggestion for improvement, not a verifiable claim itself. Therefore, the claim is not supported by evidence, making it 1.", "helpfulness_rationale": "The comment points out a potential gap in the experimental evaluation of the proposed method by suggesting the inclusion of specific nonlinear block architectures. While the suggestion is concrete in terms of the types of blocks mentioned, the comment itself doesn't provide a clear justification for *why* these blocks are relevant or how their inclusion would necessarily improve the evaluation. The reviewer is identifying a potential area for improvement but lacks a strong argument to convince the authors of its value without further explanation or evidence."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the action of splitting the tables and specifies the content of each new table (SFII columns in one, SPDI columns in the other). This makes the action both explicit and concrete.", "grounding_specificity_rationale": "The reviewer explicitly identifies the relevant parts of the paper (Tables 4 and 5) and further specifies the content within those parts (SFII and SPDI columns). This strong identification makes the grounding highly specific.", "verifiability_rationale": "The reviewer makes a suggestion about improving readability. While the suggestion itself is a claim, the verifiability relies on the reader's understanding that moving columns by type could potentially improve clarity. There isn't a direct logical reasoning or external reference provided to *verify* the benefit of this action.", "helpfulness_rationale": "The reviewer clearly states the desired change (splitting the tables). This is a direct and actionable suggestion. While the potential benefits of improved readability are generally positive, the reviewer doesn't explicitly state *why* this is a crucial improvement or what specific impact it will have on the authors' work. The helpfulness is reasonable but not definitively proven by the reviewer's statement alone."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly names the elements of the figure ('valid' and 'orig') and states that clarification is needed. This is a concrete action with clear instructions on how to apply it.", "grounding_specificity_rationale": "The comment explicitly mentions the specific part of the paper it addresses, which is Figure 5 and within that figure, the elements 'valid' and 'orig'. This can be achieved through literal mentions of sections, tables, figures, etc. Therefore, the grounding is fully grounded. The comment also clearly identifies what is wrong or missing ('difference') and how it should be implemented ('clarify'). This is highly specific.", "verifiability_rationale": "The comment contains a claim ('it would be helpful to specify what does \"valid\" and \"orig\" differ in') and provides a justification by stating that clarification is needed. This justification, while not providing external references or logical reasoning in the form of a proof, indicates an understanding of the need for clarification and a request for information. Therefore, it can be considered 3 as it implies a logical need for further information.", "helpfulness_rationale": "The comment directly requests clarification on a specific aspect of a figure, which is likely to be helpful for the authors in understanding the results better. The request is clear and directly addresses a potential point of confusion. While the comment doesn't explicitly state *why* it's helpful, the act of clarifying differences is generally beneficial for understanding data presentation. Therefore, it can be considered 3 as it points towards a beneficial improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point implicitly suggests a potential improvement (comparing to computer vision methods) but doesn't explicitly state the action of comparing or how to implement it. The critique of lossbased sampling is an implicit action of preferring computer vision methods. Therefore, it's 2.", "grounding_specificity_rationale": "The reviewer mentions 'a method mentioned in the computer vision setting' which is a general reference and not a specific part of the paper. Therefore, it's 1.", "verifiability_rationale": "The reviewer makes claims about the relevance of lossbased sampling and the potential applicability of computer vision methods. These claims are generally verifiable based on the understanding of these methods. Therefore, it's 4.", "helpfulness_rationale": "The review point identifies a potentially useful direction (comparing to computer vision methods) and critiques something less relevant (lossbased sampling). While not explicitly stating how to adapt the computer vision methods, it offers a direction for improvement. Therefore, it's 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem ('terse and not very clearly explained') but does not directly instruct the author on what to do or how to improve the discussion. The author would need to infer the need for more detail and clarity.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'equation (10)', which allows for accurate identification of the section being discussed. However, the review does not specify *what* is wrong with the discussion around this equation. The author would need to infer the issue.", "verifiability_rationale": "The review point makes a statement of observation ('The discussion around equation (10) is very terse, and not very clearly explained') but does not present a claim that requires verification. It's a description of a situation, not a proposition that needs to be proven.", "helpfulness_rationale": "The review points out an area for improvement ('discussion around equation (10)') which is relevant to the author. While it doesn't specify *how* to improve it, it highlights a potential weakness in the writing. This provides some guidance for the author to focus their attention."}
