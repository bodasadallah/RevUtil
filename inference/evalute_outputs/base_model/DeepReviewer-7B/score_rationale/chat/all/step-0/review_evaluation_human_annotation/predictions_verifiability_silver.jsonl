{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states the paper 'does not dig into the theory' and 'does not show the convergence properties of the proposed algorithm'. This directly points to a lack of theoretical analysis and a missing demonstration of convergence. The action the reviewer implies is for the authors to include a theoretical analysis and show the convergence properties of their algorithm. This action is quite explicit as the reviewer directly states the missing elements. The concreteness is also high as the reviewer specifies the exact area lacking theory (convergence properties) and the specific algorithm being criticized. The reviewer clearly identifies what needs to be added.", "grounding_specificity_rationale": "The reviewer mentions 'theory profs' and 'convergence properties'. While the reviewer clearly identifies the *area* lacking theory (convergence properties), they do not explicitly pinpoint a specific section, table, or figure in the paper where this analysis should be included. The mention of 'theory profs' is somewhat informal and doesn't directly identify a concrete part of the paper. The grounding is present in that the reviewer knows *what* is missing (convergence analysis), but the specific *location* within the paper is not clearly defined. The reviewer implies it should be related to the algorithm description, but not explicitly pointing to a section or table.", "verifiability_rationale": "The reviewer makes a claim that 'the paper does not dig into the theory' and 'does not show the convergence properties of the proposed algorithm'. This is a clear claim that identifies a deficiency in the paper. However, the reviewer does not provide any specific evidence or justification for this claim. They state the fact but do not explain *why* this is a problem, *where* in the paper this deficiency exists (beyond the general area of algorithm description), or provide references to support this claim. The verification relies on the reviewer's assertion without further elaboration or supporting arguments.", "helpfulness_rationale": "The reviewer points out a significant omission in the paper: the lack of theoretical analysis and the absence of a demonstration of convergence properties for the proposed algorithm. This is a crucial piece of feedback for the authors as it highlights a fundamental gap in their work. The reviewer clearly identifies the *area* needing improvement, which is valuable information. However, the feedback lacks specific details about *why* this is a problem or *how* the authors should approach this improvement. While the core issue is clear, the lack of guidance makes it less immediately helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their understanding of how HIERENC's input is calculated, identifying the process of averaging representations of all possible entity instantiations. This makes the reviewer's interpretation clear and explicit. The reviewer also suggests an alternative approach, which is a concrete action the authors can take.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'HIERENC's input' and details the calculation process: 'the average of the representations of all instantiations of context filled by every possible entity in the vocabulary.' This directly identifies the specific part of the paper being addressed and provides a clear description of the calculation, making the grounding fully explicit.", "verifiability_rationale": "The reviewer presents a claim about the potential noise introduced by the averaging process. However, the review point itself does not provide any evidence or reasoning to support this claim. The reviewer's statement is a suggestion for improvement without any verification within the provided text.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors to consider alternative approaches to HIERENC's input calculation. This directly addresses a potential implementation detail and offers a concrete solution, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer is implicitly suggesting that the selection of 10 answers might lead to underestimation of performance because it excludes the other answers. They are pointing out a potential flaw in the evaluation process. While they are not directly stating an action to be taken, the question implies a concern about the implications of the sampling strategy.", "grounding_specificity_rationale": "The reviewer is asking a question about the study's methodology, specifically the selection of 10 answers. While they are referring to a specific aspect (the selection process), the question itself does not explicitly identify the section, table, figure, or unique element of the paper being addressed. The grounding is weak because the reviewer is not pointing to a specific part of their own work, but rather critiquing the evaluation process.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question about the methodology. Therefore, the concept of verifiability does not directly apply to this review point.", "helpfulness_rationale": "The reviewer is not suggesting a concrete change or improvement to their work. They are questioning a methodological choice. While the question is relevant to understanding the evaluation process, it does not directly provide the authors with actionable feedback to improve their draft. Therefore, it is not 5 in the context of providing constructive feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's point is somewhat implicit. While the instructions ask the authors to 'reconsider their data selection process' and 'explore alternative data sources,' these are general instructions. The reviewer's suggestion to clarify the specific subset of Li et al. (2019a)'s dataset makes the action more concrete. Without this clarification, the authors still don't know exactly what needs to be changed.", "grounding_specificity_rationale": "The reviewer correctly identifies a lack of strong grounding. The comment states, 'Line 226238 seem to suggest that the authors selected sentences from raw data of these sources,' which is not strongly grounded. While the general idea of using data from Li et al. (2019a) is mentioned, the specific dataset and the unique aspect being addressed are not explicitly identified. The comment also states, 'but line 242244 say these already have syntactic information,' which further weakens the grounding as the specific issue being addressed is not clearly defined.", "verifiability_rationale": "The reviewer's point about the contradiction is a claim that needs to be verified. The paper states both that the authors 'selected sentences from raw data of these sources' and that these 'already have syntactic information.' This presents a potential inconsistency that needs to be addressed with evidence. The reviewer's suggestion to explicitly mention Li et al. (2019a) earlier and provide a clear distinction is aimed at verifying this claim.", "helpfulness_rationale": "The reviewer's comment is intended to be helpful by highlighting a potential issue with the clarity and precision of the paper. However, the current phrasing of the comment itself doesn't provide concrete, actionable feedback to the authors. The reviewer is pointing out a potential contradiction and suggesting a clearer attribution, but they are not providing a direct solution or a clear path forward. Therefore, the impact of this comment on guiding the authors is limited."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a lack of explanation regarding the average duration in Table 1. While the reviewer doesn't explicitly state the *action* to take, they imply it's a metric for model performance. This suggests the original text likely intended to convey this but didn't explicitly state it, making it only *partially actionable* as the reviewer can now infer the intended meaning. The reviewer also doesn't explicitly state which part of the paper they are referring to, making the grounding *weak*.", "grounding_specificity_rationale": "The reviewer asks 'What is the purpose of the average duration reported in Table 1?' This directly asks for the *meaning* of a specific element in the paper. The original text likely lacks a clear explanation of what this average duration represents. The reviewer doesn't explicitly identify a specific part of Table 1 (e.g., a particular column or row), making the grounding *weak*. The information is not clearly specified, requiring the reviewer to ask for clarification, indicating the specificity is *underspecified*.", "verifiability_rationale": "The reviewer makes a claim that there is no supporting explanation about the average duration in Table 1. They then suggest it likely represents a model's performance. This claim is *partially justified* as the reviewer points out the lack of explanation, and the suggestion about performance provides a potential explanation. Therefore, the verifiability is *3*.", "helpfulness_rationale": "The reviewer's question directly addresses a perceived lack of clarity regarding Table 1. Their suggestion to ask about the purpose and whether it includes waiting time is a direct and actionable improvement the authors could make. While the suggestion is brief, it is clear and directly addresses the identified weakness, making the review *3*."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about interpreting results in Table 3 and makes comparative statements about different models. It does not explicitly state an action or provide a solution. While it implies actions like 'understand the implications' and 'consider the overlap in confidence intervals', these are not concrete steps that the authors can directly implement. Therefore, it is not 5.", "grounding_specificity_rationale": "The review point explicitly refers to specific metrics (MOSQ, MOSV, GT Mel A, Baseline, 95% CI) and models (Chinese, English, NVSB, Mel A, Baseline) within the context of Table 3. This demonstrates strong grounding specificity as the authors can easily identify the referenced parts of the paper.", "verifiability_rationale": "The statements in the review point are based on the interpretation of the data presented in Table 3 and the calculated/observed relationships between the metrics and models. The reviewer is making logical inferences based on the existing information. While it doesn't introduce new verifiable facts, it is a valid interpretation of the provided data, making it 3.", "helpfulness_rationale": "The review point asks a question and offers interpretations of the results in Table 3. While it doesn't directly instruct the authors on how to improve their draft, it encourages them to critically analyze the presented data and consider the implications of the observed relationships. This can be helpful for gaining a deeper understanding of the results and identifying potential areas for further investigation. However, it doesn't provide a concrete action or solution, making it less directly helpful than a review that suggests specific changes. Therefore, it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point describes a problem (inconsistent spacing) but does not provide a specific action or suggestion on how to address it. The reviewer states the issue but doesn't tell the authors what to do or how to fix it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 2 and Table 3', which are specific parts of the paper. This indicates that the reviewer can identify the relevant sections, although they don't pinpoint a specific cell or element within those tables.", "verifiability_rationale": "The reviewer points out an observation (inconsistent spacing) without providing external references or logical reasoning to support this observation within the review point itself. The statement is a deduction rather than a claim requiring justification.", "helpfulness_rationale": "The review point identifies a valid issue (formatting inconsistency) that could affect the paper's presentation. However, it doesn't offer any suggestions or guidance on how to improve the formatting. It's a potential problem but lacks actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly states 'antecedent missing', indicating a problem with something preceding 'both tasks'. This makes the action explicit. However, it doesn't specify *what* is missing, making the action implicit.", "grounding_specificity_rationale": "The comment refers to 'both tasks' but doesn't specify *which* tasks or *where* in the paper these tasks are discussed. The reference to 'antecedent missing' doesn't pinpoint a specific section or element. This makes the grounding weak. While it mentions a potential issue, it doesn't clearly detail what is wrong or missing in 'both tasks'.", "verifiability_rationale": "The comment states that an 'antecedent' is missing, which can be considered a claim. However, it doesn't provide any justification, examples, or references to support this claim. There's no logical reasoning or external references to back up the assertion that an antecedent is missing.", "helpfulness_rationale": "The comment identifies a potential issue ('antecedent missing') but doesn't offer any concrete steps or context for the authors to act upon. It's a symptom, not a diagnosis with treatment. The authors are left with a problem statement without a solution or direction."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'the explanations for features in Section 3.2 are somewhat intertwined and thus confusing.' They then provide a clear and actionable suggestion: 'The section would be more coherently organized with more separate paragraphs dedicated to each of lexical features and sentencelevel features, by:'. This demonstrates a direct identification of a weakness and a specific, verifiable action to address it. The reviewer is not just stating a problem; they are also suggesting a concrete solution.", "grounding_specificity_rationale": "The reviewer's comment is grounded in Section 3.2, as they directly refer to the section where the explanations are described as 'somewhat intertwined'. While they don't explicitly state 'Paragraph X', the focus on 'lexical features' and 'sentencelevel features' within that section implies a good understanding of where the confusion lies. The reviewer also specifies the *type* of features, adding to the specificity of the grounding. Furthermore, the suggestion to 'separate paragraphs dedicated to each of lexical features and sentencelevel features' directly addresses the identified area of confusion, indicating a clear understanding of the specific part of the paper being discussed.", "verifiability_rationale": "The reviewer makes a claim that the explanations are 'somewhat intertwined and thus confusing'. This claim is verifiable through logical reasoning. The reviewer suggests a solution ('separating paragraphs dedicated to each of lexical features and sentencelevel features') that directly addresses the identified problem. While the reviewer doesn't provide external references to support this claim, the logical connection between the intertwined explanations and the proposed solution makes the claim verifiable. The reviewer is inferring that separating the paragraphs will improve clarity and reduce confusion.", "helpfulness_rationale": "The reviewer's comment is 5 because it directly addresses a potential pain point for the authors \u2013 confusing explanations in a specific section. The suggestion to 'separately paragraphs dedicated to each of lexical features and sentencelevel features' is a concrete and actionable improvement. This directly tackles the identified issue and provides a clear direction for the authors to take. The reviewer is not just pointing out a problem; they are also offering a specific and verifiable solution, making the comment 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point presents several distinct and actionable items for the authors. The reviewer explicitly states: 'It is unclear how the proposed models compare to models that only consider different senses but not sememes.' This directly points to a missing comparison that the authors need to address. The reviewer also asks: 'Perhaps the MST baseline is an example of such a model?'. This is a clear question prompting the authors to clarify the relevance of the MST baseline to their work. Furthermore, the reviewer states: 'If so, this is not sufficiently described (emphasis is instead put on soft vs. hard word sense disambiguation)'. This indicates a lack of detail in the description of the MST baseline, which the authors need to rectify. Lastly, the reviewer suggests: 'The paper would be stronger with the inclusion of more baselines based on related work.' This is a direct suggestion for improvement that the authors should consider. All these points are concrete and actionable.", "grounding_specificity_rationale": "The reviewer's review point does not explicitly identify a specific section, table, figure, or unique aspect of the paper that it is addressing. While the reviewer mentions 'models,' 'sememes,' 'senses,' and 'MST baseline,' these are general concepts and do not pinpoint a specific part of the paper. The reviewer also mentions 'related work,' which is a broad category. Therefore, while the reviewer is addressing a relevant issue, they are not providing a precise location within the paper where this issue is most pertinent.", "verifiability_rationale": "The review point makes claims that can be verified. The reviewer states: 'It is unclear how the proposed models compare to models that only consider different senses but not sememes.' This is a claim that can be supported by examining the methodology and experimental setup of both the proposed models and the MST baseline. The reviewer also states: 'Perhaps the MST baseline is an example of such a model?'. This is a claim that can be verified by examining the description of the MST baseline and confirming whether it only considers senses. The reviewer further states: 'If so, this is not sufficiently described (emphasis is instead put on soft vs. hard word sense disambiguation)'. This is a claim that can be verified by examining the description of the MST baseline and checking for details about its implementation. Finally, the reviewer suggests: 'The paper would be stronger with the inclusion of more baselines based on related work.' This is a claim that can be verified by examining the current baselines and comparing them to relevant work.", "helpfulness_rationale": "The review point is 5 for the authors. The reviewer provides specific and actionable feedback that directly addresses potential gaps in the paper. By pointing out the lack of clarity in the comparison between models considering sememes and those only considering senses, the reviewer guides the authors to a crucial area for improvement. The question about the MST baseline's relevance and the suggestion to provide more details are also valuable and actionable. Furthermore, the suggestion to include more baselines based on related work is a concrete recommendation that can significantly strengthen the paper. The reviewer is not just pointing out a problem; they are also suggesting concrete steps to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states that the selection process for frame similarity factors and attributes similarity factors is unclear. However, it does not specify what aspects of the selection process are unclear or how the selection should be done. This makes it somewhat vague and not fully actionable.", "grounding_specificity_rationale": "The comment mentions 'frame similarity factors' and 'attributes similarity factors' but does not explicitly identify the specific part of the paper being addressed. While it implies a lack of clarity in the selection of these factors, it doesn't specify which section, table, or unique aspect of the paper this refers to. Therefore, it is weakly grounded. However, it does specify what needs to be addressed (the selection process for these factors), making it somewhat specific.", "verifiability_rationale": "The comment states a problem ('unclear how the frame similarity factors and attributes similarity factors are selected') but does not provide any evidence, examples, or logical reasoning to support this claim. It is a statement of a problem without a solution or justification. Therefore, it is 1.", "helpfulness_rationale": "The comment identifies a potential issue ('unclear how the frame similarity factors and attributes similarity factors are selected') but does not offer any suggestions, solutions, or further information on how to address this problem. It's a question posed without an answer. Therefore, it is 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for a discussion on the convergence of the joint learning process and its connection to obtaining stable points in probabilistic metric space. This directly points to a missing action or suggestion for the authors. The reviewer identifies the specific aspect of the method (joint learning process) and the desired outcome (understanding of stable points). This makes the action quite explicit. While the reviewer doesn't provide concrete steps on how to achieve this, they clearly state what needs to be done, making it actionable in the sense that the authors know what information is missing.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'convergence of the proposed joint learning process (for RNN and CopyRNN)' as the specific part of the paper they are referring to. They also clearly state what is missing: 'a discussion on the convergence... and its connection to obtaining stable points in probabilistic metric space'. This strong identification of the section and the specific issue demonstrates high grounding specificity. The reviewer doesn't just mention a section; they pinpoint the exact mechanism and the desired explanation.", "verifiability_rationale": "The reviewer explains *why* the convergence of the joint learning process is important, stating that it helps readers understand how stable points in probabilistic metric space are obtained and that this is crucial for understanding and potentially reproducing the results. While the reviewer doesn't provide new references to external works, the explanation of the underlying concepts and the importance of the process is logically sound and builds upon common knowledge in the field of machine learning and optimization. The reviewer implicitly argues that without this discussion, the results might be difficult to interpret and reproduce.", "helpfulness_rationale": "The reviewer clearly identifies a gap in the explanation of a key technical aspect of the proposed method. They highlight the importance of understanding the convergence of the joint learning process for comprehending the stable points in probabilistic metric space and for the reproducibility of the results. This is a significant and actionable piece of feedback for the authors. It directly addresses a potential barrier to understanding and adoption of their method. The reviewer's request for this discussion is a valuable contribution that would enhance the clarity and completeness of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the desired actions for the authors: '681 as mentioned above, you should discuss the results for the task of inferring knowledge on objects, and also include results for model (B)'. This provides a clear path for improvement. The second part of the review point, '778 \"latent in verbs\": why don't you mention objects here?', also directly instructs the authors on what to do regarding the 'latent in verbs' concept. The actions are clear and direct.", "grounding_specificity_rationale": "The review point explicitly refers to 'the results for the task of inferring knowledge on objects' and 'results for model (B)', which are specific parts of the paper. It also refers to 'the term \"latent in verbs\"' and asks for 'objects here', which are specific elements within that concept. The authors can easily identify the sections and the specific aspects being discussed.", "verifiability_rationale": "The review point makes claims about what the authors should do, such as 'you should discuss the results for the task of inferring knowledge on objects' and 'also include results for model (B)'. While not purely objective claims, they are directives that imply a desired state of the paper. The 'how' of these suggestions is also provided in the same sentence, making the claims 3.", "helpfulness_rationale": "The review point is 5 as it directly identifies potential weaknesses in the paper's discussion (lack of discussion on object knowledge and missing mention of objects in 'latent in verbs') and provides clear and actionable suggestions for improvement (discussing the results for object knowledge, including results for model (B), and mentioning objects in the 'latent in verbs' discussion). The suggestions are concrete and directly address the identified issues."}
{"actionability_label": "None", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out that the paper relies on supplemental space and references specific sections of the supplementary material (e.g., Sup. Fig. 6, model comparison, span vs. sentence investigation). While the reviewer identifies a problem, they do not explicitly state what action the authors should take to address it. The reviewer suggests the paper is not 'truly independent', but doesn't provide concrete steps for achieving this. Therefore, the comment is 3 as it identifies a problem, but lacks specific guidance on how to fix it.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific sections of the supplementary material that are referenced in the main text (e.g., Sup. Fig. 6, model comparison, span vs. sentence investigation). This clearly indicates that the reviewer has identified the specific part of the paper being addressed. Furthermore, the reviewer describes the nature of the problem (the paper not being 'truly independent'), which specifies what the issue is. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim about the paper's independence based on the references to the supplementary material. However, the reviewer does not provide any evidence or reasoning to support this claim within the review point itself. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the paper is not 'truly independent' due to these supplementary references. Therefore, the claim is 1.", "helpfulness_rationale": "The reviewer's point about the reliance on supplemental space and the references to the supplementary material highlights a structural issue in the paper's presentation. While this information is valuable for readers to understand the context, it does not directly provide actionable feedback for the authors to improve their draft. The reviewer identifies a problem but does not suggest concrete steps or improvements that the authors can implement. Therefore, the review point is 3 in identifying a problem, but it lacks direct actionable feedback for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'sentence classification is an easier task' and 'the proposed augmentation method has potential to be used on more NLP tasks.' These statements identify potential weaknesses and areas for improvement. However, the reviewer does not provide concrete steps on how to address these points. For example, they don't specify which aspects of sentence classification are easier or how the method should be adapted for other NLP tasks. The suggestions are broad and lack specific implementation details, making the action implicit rather than explicit. Therefore, while the weaknesses are identified, the lack of concrete action makes it partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'sentence classification is an easier task' and 'the proposed augmentation method has potential to be used on more NLP tasks.' While they identify a potential weakness in the task, they do not explicitly point to a specific section, table, figure, or unique aspect of the paper where this weakness is located. They also do not specify what needs to be addressed in this part. The reviewer's statements are general and do not pinpoint the exact location or nature of the issue. While they suggest a broader application, they don't detail how this relates to the current paper's content. Therefore, the grounding is weak as the specific part being addressed is not clearly identified.", "verifiability_rationale": "The reviewer makes claims such as 'the setting is only on extremely lowresource regime' and 'sentence classification is an easier task.' These are statements that could be verified. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. They simply state them as observations without explaining *why* they are weaknesses or how they impact the method. The lack of justification makes it difficult to assess the validity or importance of these points. Therefore, the claims are not verifiable because they lack supporting evidence or justification.", "helpfulness_rationale": "The reviewer identifies two key weaknesses: the experimental setup being limited to an extremely lowresource regime and the sentence classification task being easier than other NLP tasks. They also suggest that the proposed augmentation method has potential for broader application. While the reviewer points out limitations, they also highlight a potential future direction for the method. They do not explicitly state that the method is not helpful, but they do not provide concrete, actionable feedback on how to improve the current draft based on these observations. The suggestions are general and lack specific implementation details. Therefore, the helpfulness is somewhat limited as the feedback is not specific enough to guide the authors effectively."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states what the authors should do: 'authors should describe more about the traits of the experts' and 'authors should justify why annotation must be carried out by the experts, outside its commercial values'. The reviewer provides clear instructions on the desired actions, making it 5.", "grounding_specificity_rationale": "The review point asks specific questions about the experts' roles and the differences in annotation between experts and nonexperts. While it doesn't explicitly state the section where these traits are described, it clearly identifies the expected outcome (describing traits and justifying expert involvement), indicating a degree of grounding. The reviewer is asking for specific information about the experts and the annotation process, making it somewhat specific but not fully grounded as it doesn't point to a specific section or table.", "verifiability_rationale": "The reviewer poses a question (' Were the experts linguistic experts or domain experts?') that could be answered with evidence (e.g., citing literature on the importance of linguistic expertise in annotation). However, the prompt itself doesn't contain a claim that is being verified. The reviewer is asking for justification, which could be supported by external references, making it 3. The reviewer is asking a question that could be answered with logical reasoning and potentially external references, but the prompt doesn't present a claim that is definitively verifiable.", "helpfulness_rationale": "The review point directly addresses the authors' needs by asking questions that are relevant to improving their annotation process and understanding the rationale behind expert involvement. The questions are clear and directly related to the authors' work, making it 5. The reviewer is asking questions that directly address the authors' needs for improving their annotation process and understanding the rationale behind expert involvement, making it 5."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point states \"It will be nice to see some examples of the system on actual texts (vs. other components & models).\" The phrase \"vs. other components & models\" is a direct statement of a comparison, which implies a need to *distinguish* between different aspects. This is an explicit action. However, the suggestion to *see* it (i.e., to provide examples) is vague. While the *act* of seeing is implied, the *how* of seeing it (e.g., a specific interface, data format) isn't detailed. The suggestion to *compare* against other components is also general.", "grounding_specificity_rationale": "The reviewer doesn't specify *which* system they are referring to (e.g., a specific model, a general framework, a novel approach). They also don't pinpoint *where* they would like to see examples (e.g., on a specific type of text, for a particular task). The reference is general. While the reviewer mentions 'system\" and \"examples,\" the lack of specificity makes it unclear what they mean. They don't describe *what* aspects of the system they find lacking or *why* they need examples.", "verifiability_rationale": "The review point clearly states a desire for *examples*. This is a statement of what the reviewer *wants* to see, indicating a *claim* that examples are needed. However, the reviewer states a *wish* for examples. While this is a valid suggestion, it's not a claim that *something is wrong* or *something needs to be improved*. It's a request for more information or clarification. Verifiability requires a statement that *something is the case* and *why*.", "helpfulness_rationale": "The reviewer's suggestion is relevant and directly addresses a potential limitation of the system (lack of demonstration) and offers a concrete solution (providing examples). It's a valuable and actionable suggestion. It points to a clear area for improvement and offers a clear path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the hypotheses are not studied and clearly explains why these hypotheses are valuable. The suggestion to study them is a direct action the authors can take to improve their work.", "grounding_specificity_rationale": "The reviewer explicitly names the hypotheses (lines 078086) and explains their potential value, making the grounding very specific.", "verifiability_rationale": "The reviewer makes a claim that the paper does not study the hypotheses. This claim is supported by the absence of experimental work or analysis directly related to these hypotheses in the paper.", "helpfulness_rationale": "The reviewer highlights the importance of the unexplored hypotheses, which directly guides the authors' future work and provides a clear direction for further investigation."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their lack of understanding regarding the use of the Challenge Set (CS). They ask, 'What is not clear also to me is how is used the Challenge Set.' This directly indicates a lack of clarity on the reviewer's part, which translates to a lack of actionable information for them. Since the reviewer isn't proposing an action, the actionable aspect is also low.", "grounding_specificity_rationale": "The reviewer states, 'the CS is created by the linguistic experts and it's used for evaluation purposes. Is this used also to augment the training material?' This shows a lack of grounding in the paper's content. The reviewer doesn't explicitly identify the section or table where the CS is mentioned or used for evaluation. They also don't specify how the CS is used for training augmentation. While they are asking questions, they are not pointing to a specific part of the paper they believe is missing information. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer's questions about the CS's usage are not supported by explicit reasoning, common knowledge, or external references within the review point itself. They are asking 'What is not clear also to me is how is used the Challenge Set.' and 'Is this used also to augment the training material?'. These are questions, not statements that can be verified. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer's primary concern is the lack of clarity regarding the CS's usage. While they are not directly criticizing the *process* of using the CS, they are criticizing the *explanation* of its use. A request for clarification, even if it doesn't lead to a concrete action, points to a significant gap in understanding. Therefore, the review point is not very helpful as it doesn't provide concrete actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"The relatively poor performance on nouns makes me uneasy.\" This clearly indicates an action the reviewer is taking  to investigate the cause of this poor performance. The reviewer also mentions \"PPDBClus\" as a dataset where the gap is large, which further specifies the area of concern. The reviewer also states \"This also directly contradicts the claim that the clustering approach is generalizable to all parts of speech (124126), since the performance clearly isn't uniform.\" This shows the reviewer has identified a discrepancy and wants the authors to address it. The reviewer's statement \"I would like to understand the gap better\" directly implies an action the authors should take to clarify this issue.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"nouns\" as the specific part of the paper being addressed. They also mention \"PPDBClus\" as a specific dataset where the performance discrepancy is observed. Furthermore, the reviewer directly references a specific claim in the paper (\"the clustering approach is generalizable to all parts of speech (124126)\") that they are contradicting. This precise identification of the problematic element and the evidence supporting the contradiction demonstrates high grounding specificity.", "verifiability_rationale": "The reviewer makes a clear claim: \"This also directly contradicts the claim that the clustering approach is generalizable to all parts of speech (124126), since the performance clearly isn't uniform.\" This claim is supported by the evidence provided in the review point itself. The reviewer explicitly states the poor performance on nouns and the higher GAP for PPDBClus, which directly relates to the claim about generalizability. The reviewer also points to the specific line numbers (124126) where the generalizability claim is made, providing a direct link between the observation and the claim. This strong connection between the reviewer's statement and the evidence within the paper demonstrates high verifiability.", "helpfulness_rationale": "The reviewer's point directly addresses a specific concern raised by the authors (poor performance on nouns) and highlights a potential flaw in the paper's claims. This provides valuable information for the authors to understand and potentially improve their model. The reviewer's statement \"I would like to understand the gap better\" indicates a clear direction for the authors to take, which is helpful for their development. The reviewer's identification of a contradiction and their attempt to understand it are all actions that would be beneficial for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "UnderSpecific", "verifiability_label": "X (X)", "helpfulness_label": "5", "actionability_rationale": "The reviewer states they don't understand the abstract discussion in section 5.2 and asks for examples. This suggests the improvement they desire is implicit rather than explicitly stated. While the request points towards a concrete action (providing examples), the current version of section 5.2 lacks the concrete steps to achieve this improvement. The action is implied but not clearly articulated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 5.2' when stating their lack of understanding. This indicates they can identify the specific part of the paper being addressed. However, the discussion in section 5.2 is described as 'abstract,' meaning the reviewer still doesn't understand the implications or how to apply the information within that section. While the section is identified, the explanation is not specific enough to guide the reviewer's understanding or application of the information.", "verifiability_rationale": "The reviewer is asking for clarification on the discussion in section 5.2, not making a claim that needs verification. Therefore, there is X to evaluate for verifiability in this context.", "helpfulness_rationale": "The reviewer clearly states they need examples to understand the discussion in section 5.2. This is a specific and actionable request. While the current version of section 5.2 might lack these examples, the request itself is a valuable and direct feedback point that the authors can use to improve their draft. The feedback is specific to the information the reviewer needs."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment is explicit in stating the suggestion but is vague on how to implement it. The suggestion is to include a hard prompt baseline in Table 1, but the comment doesn't specify which hard prompt baseline or how this would be done. The action is explicit (include the baseline), but the implementation details are missing, making it vague.", "grounding_specificity_rationale": "The comment explicitly mentions 'Table 1' and 'hard prompt baseline', which grounds the specific part of the paper being addressed. The comment also identifies the issue as 'lack of context for performance gains', which clearly specifies what needs to be improved in the referenced part. The grounding is explicit, and the issue being addressed is clearly defined.", "verifiability_rationale": "The comment makes a claim that including a hard prompt baseline in Table 1 would 'see the increase in performance of each method'. This claim is not verifiable without specific examples of the methods being compared and the expected performance gains. There is no logical reasoning, common knowledge, or external references provided to support this claim. The claim is made without sufficient justification.", "helpfulness_rationale": "The comment suggests adding a hard prompt baseline to Table 1. While this could be helpful for readers unfamiliar with hard prompting, it is a relatively minor detail. The suggestion lacks a clear rationale for why this specific addition would be particularly beneficial, and it doesn't address any specific weaknesses or improvements needed in the current draft. The suggestion is present, but it lacks a strong justification and specific implementation details, making it somewhat incremental."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the 'Lack of numerical results' as a problem and also mentions the need to 'apply it to some popular algorithms' and 'compare with existing DP algorithms'. These are clear actions or requests for information. The need to 'apply it' implies a direct action, and the need to 'compare' suggests a concrete step to be taken.", "grounding_specificity_rationale": "The reviewer explicitly states the 'Lack of numerical results' and then further specifies the areas needing numerical grounding by mentioning 'popular algorithms' and 'existing DP algorithms'. This demonstrates a clear identification of the specific part of the paper being addressed, making it 5.", "verifiability_rationale": "The reviewer states a 'Lack of numerical results' without providing any immediate evidence or justification within this review point. While the lack of results is a logical observation, the reviewer doesn't explain *why* there are no numerical results or how they should be obtained. The claim is made without sufficient supporting evidence or justification.", "helpfulness_rationale": "The reviewer clearly identifies a deficiency ('Lack of numerical results') and directly asks for solutions or guidance on how to address it ('how to apply it to some popular algorithms' and 'their performance compared with existing DP algorithms'). This is a direct and actionable request for the authors, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing element: 'results of proposed InvP with these wider backbones.' They also identify the specific architectures: 'ResNet50 2x and 4x'. This clearly indicates an explicit and concrete action the authors should take.", "grounding_specificity_rationale": "The reviewer refers to 'InvP' and 'wider backbones (ResNet50 2x and 4x)' which are precise and specific mentions of the relevant parts of the paper. This indicates strong grounding as the authors can easily identify the referenced part.", "verifiability_rationale": "The reviewer makes a claim by stating 'The experimental comparisons are not enough' and then provides a suggestion for verification by mentioning 'MoCo and SimCLR also test the results with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7)'. While the claim itself is a judgment, the suggestion for verification provides a logical reasoning and a potential source of evidence, making it 3.", "helpfulness_rationale": "The reviewer provides a very specific and actionable suggestion: 'It would be interesting to see the results of proposed InvP with these wider backbones.' This directly points to a concrete improvement the authors can make and is therefore 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the incorrect table for the callout of Table 5 and explains the issue with the callout of Figure 6. The action is clearly stated and the method of correction is directly specified.", "grounding_specificity_rationale": "The reviewer accurately identifies the specific tables and figures being referred to (Table 5 and Figure 6). Furthermore, the reviewer specifies the nature of the issue with the callout of Figure 6, indicating a clear understanding of the problem within that specific part of the paper.", "verifiability_rationale": "The reviewer's claim about the incorrect callout in Figure 6 is directly verifiable by examining the figure and its callout. The reviewer also points out the callout belonging to Table 5, which is also verifiable.", "helpfulness_rationale": "The reviewer provides clear and actionable feedback by specifying the correct table for the callout of Table 5 and explaining the issue with the callout of Figure 6. This feedback is directly aimed at improving the accuracy of the paper's presentation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states \"comparisons with SketchRNN\" as a suggested improvement. This is a clear and direct action that the authors can readily implement. The suggestion is not just a general comment but a specific comparison to a wellknown method, making it actionable and concrete.", "grounding_specificity_rationale": "The review point mentions \"experiments\" generally but doesn't specify a particular section, table, or figure. While it identifies the *area* of improvement (experiments) and the *nature* of the suggested improvement (comparison with SketchRNN), it doesn't pinpoint the exact part of the paper that needs adjustment. Therefore, while the general area is grounded, the specific section or element within the experiments isn't explicitly identified.", "verifiability_rationale": "The review point makes a claim: \"The paper reports only self comparisons. The paper also doesn't explain why this is so, which adds to the poor motivation problem.\" The claim is supported by stating the *what* (lack of selfcomparisons) and the *why* (it's a problem in a generative setting). While it doesn't provide a direct citation immediately following the statement, the reasoning is present and logical.", "helpfulness_rationale": "The review point is clear and directly addresses a stated problem with the experiments: the lack of comparison to SketchRNN. The suggestion is specific and actionable, providing a concrete direction for improvement. This makes the feedback valuable and directly useful for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment identifies a general issue ('several places may cause confusion') but does not specify which parts of the paper are unclear or how to address these issues. It lacks explicit and concrete instructions for improvement, making it not actionable.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper being addressed. It is a general statement about the paper's clarity without pinpointing the problematic section, table, figure, or element. Therefore, it is 1.", "verifiability_rationale": "The comment states a potential issue ('several places may cause confusion') but does not make a specific claim that requires external evidence or logical reasoning to be verified. It is a statement of observation rather than a verifiable claim.", "helpfulness_rationale": "The comment identifies a problem ('several places may cause confusion') but does not provide any specific, actionable, or constructive suggestions for improvement. It lacks the necessary details and guidance to be considered helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review points to a lack of tools, which is an explicit action. However, it lacks concrete suggestions for the authors. They identify a gap but don't propose how the authors should address it.", "grounding_specificity_rationale": "The reviewer mentions \"reinforcement learning setting,\" which grounds the comment to a specific area. However, they don't specify a *particular* tool or paper, and the comment itself doesn't identify a *specific* issue within that broad category. The grounding is at the level of the domain rather than a specific element within it.", "verifiability_rationale": "The reviewer makes a claim about the absence of tools and provides references to support this claim. The claim is logically reasoned and supported by external references, making it 5.", "helpfulness_rationale": "The reviewer identifies a potential limitation or area for improvement in the context of reinforcement learning. However, they don't actively engage with the authors to propose changes or clarifications based on this observation. They identify a *problem* but don't offer a *solution* or *how* this impacts the authors' work. The helpfulness is limited as it's a statement of fact rather than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The phrase \"i.e., the techniques are really only 'standard\" to a small group of experts\" explicitly states an action: comparing the authors' work to what is considered 'standard\" and noting the expert audience. However, the level of detail is low, as the reviewer doesn't specify which techniques or how to carry out this action. The reviewer also mentions \"The results, while mostly based on 'standard\" techniques, are not obvious a priori\", which implies an action of evaluating the results' obviousness, but this action is not fully explicit or concrete.", "grounding_specificity_rationale": "The comment discusses the results of the techniques but does not explicitly identify a specific part of the paper or the authors' work that is affected. The reviewer uses terms like 'standard techniques\" generally, without linking them to a specific section, table, figure, or unique aspect of the paper. The comment is about the techniques used, not a specific part of the authors' work.", "verifiability_rationale": "The review point contains a claim: \"The results, while mostly based on 'standard\" techniques, are not obvious a priori, and require a fair degree of technical competency (i.e., the techniques are really only 'standard\" to a small group of experts)\". This is a statement of opinion about the nature of the results. However, the source of this claim is not explicitly linked to external references or logical reasoning within the review point itself. The reviewer's assessment is based on their experience and understanding of the techniques.", "helpfulness_rationale": "The review point raises a valid concern about the accessibility of the results and the required expertise. This could be helpful for the authors to understand the limitations of their work or the context in which their techniques are being applied. However, the review point does not offer specific suggestions for improvement or actionable steps for the authors to take based on this observation. The reviewer identifies a potential issue but doesn't guide the authors on how to address it."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states that 'the difference between the two proposed systems is only a few percentage points'. This is an explicit statement of a quantitative difference. However, the comment does not specify *which* percentage points or which systems are being compared, making it somewhat vague on how to apply the conclusion. The comment raises a valid point about the potential impact of the data difference on the justification of the direct model's superiority, but it doesn't provide concrete actions for the authors to take based on this observation.", "grounding_specificity_rationale": "The comment generally discusses the impact of the training data difference on the models. While it touches upon a specific aspect (training data), it doesn't explicitly identify a *specific* part of the paper being addressed. It's a general comment about the training data of the models. Therefore, the grounding is weak. While the topic is the training data, the specific details of the data difference are missing, making it not fully specific.", "verifiability_rationale": "The comment presents a statement about the data difference as a point of concern regarding the justification of the direct model's superiority. However, it doesn't provide any external references or logical reasoning to support its claim about the impact of the data difference. It's a hypothesis based on general knowledge of machine learning, lacking specific examples or references to back up its assertion. Therefore, the verifiability is low as there is no clear justification for the claim.", "helpfulness_rationale": "The comment raises a valid concern about a potential flaw in the direct model's justification based on the data difference. However, it lacks specific details and supporting evidence. While it points out a potential issue, it doesn't offer a solution or a clear path forward. The comment is somewhat general and doesn't offer concrete suggestions for improvement. Therefore, its helpfulness is limited as it doesn't provide actionable guidance."}
{"actionability_label": "4", "grounding_specificity_label": "1 and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies areas for improvement but lacks specific details on what those improvements should be. For instance, it mentions the need for a clearer motivation for GaRare and a more detailed algorithmic presentation, but doesn't specify *how* the motivation should be framed or *what specific steps* should be taken to detail the algorithm. The comparison to GaLore is somewhat vague, asking for advantages without specifying what those advantages might be.", "grounding_specificity_rationale": "The reviewer does not explicitly state which part of the paper is being addressed regarding the motivation of GaRare. They also do not specify what the advantages of GaRare are over GaLore or detail the process of recovering updated parameters from projected gradients. The mention of 'theoretical analysis' is also vague.", "verifiability_rationale": "The reviewer's comments do not contain explicit claims that require verification. They are suggestions for improvement rather than statements that need to be proven or justified. For example, 'lacks evidence or justification for GaRare's advantages over GaLore' is a statement of a perceived gap, not a claim that needs to be supported by evidence. Similarly, 'a more detailed algorithmic presentation is needed' is a suggestion, not a claim.", "helpfulness_rationale": "The review point is likely to be 3 as it points out areas where the paper could be improved. The suggestions for a clearer motivation and a more detailed algorithmic presentation are actionable and could guide the authors in refining their work. However, the vagueness of the suggestions might limit their immediate impact."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the intention to conduct an ablation study on the VisDial dataset and specifically requests the performance of ATT(+H) without attention retrieval. This is a clear and direct action the authors should take. The request is also concrete, specifying the model (ATT(+H)) and the exact modification (removing attention retrieval).", "grounding_specificity_rationale": "The reviewer mentions 'visDial dataset' and 'ATT(+H)' which indicates a specific part of the paper they are referring to. While they don't provide a literal section number, the mention of a specific dataset and model component strongly implies they understand where this information is located within the paper. The request to evaluate ATT(+H) without attention retrieval further specifies the exact area of investigation.", "verifiability_rationale": "The reviewer states a request to conduct an ablation study and evaluate a specific model variant. While this isn't a direct criticism of the paper's content, it's a suggestion for further validation based on a perceived need or a desire for a more thorough understanding of the model's components. The request itself acts as a form of justification for why this additional experiment is relevant. The reviewer is implicitly suggesting that the current validation might not be sufficient and that exploring the impact of attention retrieval is important.", "helpfulness_rationale": "The reviewer provides a clear and specific request for an ablation study. They explicitly state the goal (conducting an ablation study on VisDial) and the specific experiment they want to perform (evaluating ATT(+H) without attention retrieval). This is a valuable suggestion for the authors as it directly addresses the contribution of the attention mechanism and aims to further validate the model. The request is actionable and directly contributes to improving the understanding of the proposed method."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential weakness in the approach (reinforcement learning) but doesn't explicitly state the desired action or solution. The suggestion to use gradient descent is implicit.", "grounding_specificity_rationale": "The reviewer makes a general comment about the potential weakness of reinforcement learning for the static VQA task without referring to a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer states a potential weakness (reinforcement learning might be less dataefficient) but provides no evidence, examples, or references to support this claim.", "helpfulness_rationale": "The reviewer identifies a potential limitation in the methodology, which can be a valuable point for the authors to consider. However, the lack of a concrete suggestion makes it less helpful compared to a point with a clear recommendation."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a lack of information regarding the distribution of video lengths, which can be considered an implicit action. However, it doesn't explicitly state how this information should be used or what specific actions need to be taken based on this distribution. The reviewer suggests including a table and explaining the balancing process, which implies an action, but the point itself doesn't detail the action.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or dataset. It is a general comment about the video length distribution being crucial for assessment. Therefore, it lacks grounding specificity as it doesn't pinpoint where the issue lies. The reviewer mentions 'the benchmark' and 'the 11 categories' in their suggestions, indicating a lack of immediate focus on a specific element of the paper being reviewed.", "verifiability_rationale": "The review point identifies a weakness in the paper (lack of information on video length distribution) but doesn't provide any external references or logical reasoning to support this claim. It simply states that the paper 'does not provide relevant explanations'. While the reviewer's suggestion to include a table and explain the balancing process is a potential solution, the point itself doesn't offer any verifiable information or propose a method to confirm the absence of this information in the original paper.", "helpfulness_rationale": "The review point identifies a potential issue in the paper regarding the lack of information on video length distribution and its impact on reasoning ability. It also suggests concrete actions the authors could take to address this, such as including a table and explaining the balancing process. While the point itself doesn't *provide* the table or the explanation, it does point to a need for more information and proposes steps to address it, making it 3 in guiding the authors towards improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential issue (the dataset not being available) but lacks a direct instruction on how the author should respond or act upon this information.", "grounding_specificity_rationale": "The comment refers to 'the promised dataset' generally, without specifying a particular section, table, figure, or element within the paper.", "verifiability_rationale": "The statement is a factual observation about the current state of the dataset, not a claim requiring verification or justification.", "helpfulness_rationale": "The comment points to a potential limitation or missed opportunity related to the dataset, which could be relevant to the author's assessment of their work, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue with the cosine similarity in Fig. 3e and suggests a specific alternative visualization (directly illustrating the latter loss term of Eqn 13). This is a clear and actionable suggestion, as the authors can directly identify the modification they should apply to their draft. The reviewer is not just pointing out a problem but also suggesting a concrete solution.", "grounding_specificity_rationale": "The reviewer directly references 'Fig. 3 e.' and explains the context of the observation. They also connect the observation to a specific part of their work (Eqn 13). This shows a strong grounding in the paper's structure and content, making it clear which part the comment addresses and what needs to be addressed in this part.", "verifiability_rationale": "The reviewer's statement about cosine similarity is a logical deduction based on the definition of cosine similarity. While they don't provide a *new* external reference, the logic is sound and based on established principles. Therefore, it's 3. The reviewer is not making a claim that requires external validation but is instead explaining a known property of the metric they are using.", "helpfulness_rationale": "The reviewer suggests an alternative visualization for the results in Fig. 3e. While this could be helpful for the authors to better understand the relationship between the preactivations and the output cosine similarity, it doesn't directly address a specific weakness or error in the current visualization. The suggestion is more about exploring alternative representations rather than providing a clear, actionable improvement. The helpfulness is moderate as it offers a potential improvement, but it lacks a direct, prescriptive recommendation like 'change this parameter' or 'add this analysis.'"}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of comparison with TTA methods and asks for a proof of the superiority of data processing. This is a clear and actionable request for the authors to address a gap in their work. The reviewer directly points out what needs to be done and how it should be done (experimental comparison).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'testtime adaptation (TTA) methods' and provides a brief description of their purpose. This demonstrates a clear grounding of the comment in a specific category of related work. The reviewer also asks for a proof, which is a specific request related to the identified area.", "verifiability_rationale": "The reviewer's statement about the superiority of data processing is a belief, not a claim that is supported by evidence within the review point itself. While the reviewer requests a proof, the initial statement lacks any explicit justification or reference to external works. Therefore, it is 1 based on the information provided in the review point.", "helpfulness_rationale": "The reviewer's request to compare the paper's approach with TTA methods is directly relevant to the paper's focus on robustness in video action recognition. The request for experimental proof is a crucial step towards validating this comparison. While the request is clear and actionable, it focuses on comparing against model parameter adjustments rather than existing data processing methods, which might limit its immediate helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the incorrect expression for J(\u03b8) and provides the correct expression, Q(st0, \u03c0\u03b8(st0)). The action for the author is clear: replace the incorrect expression with the correct one. This is a concrete action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3.2.1' and provides the exact mathematical expression (J(\u03b8)) that is incorrect. This clearly identifies the specific part of the paper being addressed. The comment is 5.", "verifiability_rationale": "The reviewer makes a claim by stating that the first expression for J(\u03b8) is incorrect and providing the correct expression. While the reviewer doesn't explicitly prove the original expression is incorrect within this review point, the actionability of correcting the expression makes its verifiability relatively high. Other reviewers would likely independently arrive at the same correct expression or be able to derive it.", "helpfulness_rationale": "The reviewer directly points out an error in a specific mathematical expression within a defined section and provides the correct alternative. This is a 5 and concrete piece of feedback that would be immediately useful for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states \"allows/expensive approaches\" twice, indicating a desire for the authors to consider using costly methods. This is an explicit action. Furthermore, the reviewer suggests *where* these expensive approaches might be used, specifying 'p.8' and providing titles and venues for Osawa et al. (2019) and Swiatkowski et al. (2020). This provides a clear direction for the authors to explore these possibilities. The reviewer's suggestions are directly linked to specific parts of the paper or relevant works, making the action concrete.", "grounding_specificity_rationale": "The reviewer mentions \"p.8\" and provides specific paper titles and publication venues (Osawa et al. (2019), Swiatkowski et al. (2020)). This demonstrates an attempt to ground the feedback in specific parts of the paper or relevant works. However, the reviewer does not explicitly state which *section* of p.8 needs to be addressed, nor does the paper title alone fully specify the relevant section within the NeurIPS paper. While the *what* and *where* (in a broad sense) are suggested, the precise *where* within the paper isn't pinpointed. Therefore, while the grounding is present, it's not fully specific.", "verifiability_rationale": "The reviewer identifies a claim: \"Various words in many of the references need capitalization\". This is a clear statement of a problem. The reviewer then provides specific examples: 's/expensive approaches2) allows/expensive approaches2) allows/ p.8: s/estimates3) is/estimates, and3) is/\" and lists publication venues: \"Osawa et al. (2019) was published in NeurIPS 2019 Swiatkowski et al. (2020) was published in ICML 2020\". These examples serve as logical reasoning and specific evidence to support the claim. The reviewer also provides *where* the capitalization issues are likely to be found (p.8 and specific venues). This demonstrates a clear attempt to verify the claim by providing concrete examples and references.", "helpfulness_rationale": "The reviewer suggests improvements to the paper's writing and referencing. For example, they recommend \"correcting capitalization errors\" and pointing out \"inconsistencies in referencing\". While these suggestions are relevant and could be helpful, they lack specific, actionable steps for the authors. The reviewer doesn't provide concrete guidance on *how* to correct the capitalization or *which* specific errors need fixing. The suggestions are broad and general, making it difficult for the authors to pinpoint exactly what needs to be changed. The reviewer also lists specific papers, but doesn't explain *why* these papers need to be cited differently or *how* the authors should adjust their referencing style. The helpfulness is limited by the lack of concrete, actionable advice."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing information they expected to find, indicating an implicit action that needs to be taken to understand the method. The request for specific parameters and the lambda value directly implies a need for this information to be actionable.", "grounding_specificity_rationale": "The reviewer implies the need for specific parameters but doesn't explicitly state which section, table, or unique aspect of the paper contains this information. While the *content* of the request is specific, the *location* is not.", "verifiability_rationale": "The reviewer presents a statement about missing information without providing any justification or evidence for why they couldn't find the parameters. The claim is presented as a factual statement without supporting reasoning or references.", "helpfulness_rationale": "The reviewer is directly asking for crucial implementation details (model parameters and lambda value), which is highly valuable information for understanding and potentially reproducing the work. This request provides a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that applying CBN to layer 2 *in addition* to layers 3 and 4 *deteriorates* performance for GuessWhat?! compared to when CBN is applied to layers 3 and 4 only. The reviewer also asks for an explanation of *why* this might be happening. This directly points to a performance issue and requests a specific action (investigation), making it 5. The explicit statement about the performance difference and the request for explanation enhance its actionability.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 2' and 'layer 2' as the specific part of the paper being addressed. This direct identification of the experimental setup makes the grounding very strong. Furthermore, the reviewer compares the performance of GuessWhat?! in this specific setup to a control setup (CBN only on layers 3 and 4), further specifying what is being addressed. This combination of explicit identification and specific comparison leads to full grounding and specificity.", "verifiability_rationale": "The reviewer states a claim that 'applying CBN to layer 2 deteriorates performance for GuessWhat?! compared to when CBN is applied to layers 3 and 4 only.' This is a clear statement requiring justification. The reviewer also asks for an explanation of *why* this might be happening, indicating an attempt to provide logical reasoning or references. While the request for explanation doesn't provide explicit external references or logical reasoning within the review point itself, it implies the potential for such explanations. Therefore, it is partially verifiable.", "helpfulness_rationale": "The review point identifies a performance issue with a specific experimental setup and asks for an explanation. This is valuable feedback for the authors as it highlights a potential area of concern and encourages further investigation. While it doesn't directly provide a solution, it points towards a direction for improvement. Therefore, it is 3 in guiding the authors to explore potential reasons for the performance degradation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about why the proposed method cannot handle headpose in the same way as another method. While this is a valid question, it doesn't provide explicit or concrete actions for the authors to take. The suggestion to condition headpose parameters is presented as a question rather than a direct instruction. Therefore, while the issue is relevant, the reviewer doesn't offer a clear path for the authors to address it immediately.", "grounding_specificity_rationale": "The reviewer mentions 'headpose' and 'NeRF' and even names a specific related work (Gafni et al.). This indicates some level of grounding as they are referring to specific concepts and a related paper. However, they do not explicitly identify a specific section, table, or figure within their own paper that is lacking in headpose handling. They are referring to the problem at a more general level.", "verifiability_rationale": "The reviewer presents a claim that the proposed method cannot handle headpose in the same way as Gafni et al. While they provide context and a suggestion, they do not offer direct evidence or logical reasoning within their review point to *verify* this claim. It remains an inference based on their understanding of the limitations.", "helpfulness_rationale": "The reviewer's point is relevant to the authors in that it highlights a potential limitation of their method and suggests a way it could be improved by referencing another work. However, the point is primarily diagnostic, asking a question rather than providing a direct, actionable suggestion for improvement. Therefore, while it is relevant, it doesn't directly equip the authors with a concrete next step."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a similarity between spurious features and backdoor triggers, suggesting that the observed patterns might not be coincidental. However, the review stops short of providing explicit instructions or concrete steps for the authors to take based on this observation. While it identifies a potential area for further investigation, it doesn't tell the authors how to proceed. For example, they might need to conduct experiments to test the impact of these features or explore specific mitigation strategies. The reviewer doesn't offer a direct action or a clear methodology.", "grounding_specificity_rationale": "The reviewer refers to \"Section 3.1 and 3.2\" and 'spurious examples in this paper.\" While the sections are named, the reviewer doesn't explicitly point to a specific table, figure, or unique element within those sections that are being identified as spurious. The reference is somewhat general. However, the reviewer *does* specify the *nature* of the spurious features (similarity to backdoor triggers, artificial patterns). This aspect of the feature is clearly defined.", "verifiability_rationale": "The reviewer makes a claim: \"It is wellknown that a few training examples with such triggers... would have a large impact on the trained model.\" This is a claim that requires justification. The reviewer *mentions* the similarity to Gu et al. (2019) 1, which provides some external reference. However, the *explanation* of *why* this similarity might lead to a large impact is brief and relies on the reader's prior knowledge of the field. While there's some external reference, the reasoning isn't fully elaborated.", "helpfulness_rationale": "The reviewer raises a valid point about a potential connection between spurious features and backdoor triggers. This is relevant to the authors' work and could potentially lead to interesting discussions and further research. While the review doesn't provide a direct solution, it highlights a potential area for investigation that could be valuable for the authors. It points to a relevant issue that warrants further exploration."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that the optimization algorithm is 'directly from some previous works'. This is a clear indication of an actionable point for the authors to consider. However, the reviewer does not specify *which* previous works or *how* it is directly taken from them, making it somewhat vague on the exact implementation.", "grounding_specificity_rationale": "The reviewer mentions 'optimization algorithm' generally, without specifying a particular section, table, figure, or unique element of the paper. This indicates weak grounding as the authors cannot confidently determine the referenced part. The comment also lacks specificity on what is being optimized or how the algorithm is implemented, making it underspecific.", "verifiability_rationale": "The reviewer makes a claim that the optimization algorithm 'reduces the contribution'. However, this claim is not supported by any evidence or reasoning within the review point. There are no logical arguments, common knowledge, or external references provided to justify this assertion. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer raises a concern about the optimization algorithm being directly derived from previous works, which could potentially reduce the paper's contribution. While the reviewer identifies a potential issue, they do not offer any specific suggestions or solutions to address this concern. The helpfulness is limited as the review point primarily highlights a potential problem rather than providing actionable improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential area for improvement in the authors' discussion of related work, but it doesn't explicitly state an action or suggest how to address this gap. While it points out a difference in focus, it doesn't directly instruct the authors on what to do next.", "grounding_specificity_rationale": "The review point doesn't explicitly mention any specific part of the paper (e.g., a particular method, algorithm, or experimental setup) where the authors seem to be focusing. It describes the authors' general focus on SSC and the lack of contrast with other methods, but doesn't pinpoint the exact location of this focus within the paper. Therefore, it can be considered weakly grounded.", "verifiability_rationale": "The review point makes a claim about the authors' focus and the lack of contrast with other methods. It provides some justification by stating that these methods are computationally efficient and have similar guarantees. However, it doesn't provide specific examples or references to support this claim about the authors' focus. While it offers some reasoning, it lacks concrete evidence to fully verify the claim.", "helpfulness_rationale": "The review point identifies a potential gap in the authors' discussion of related work by pointing out the absence of contrast with specific methods. However, it doesn't directly instruct the authors on what to do about this gap. While it highlights a potential area for improvement, it doesn't provide a clear path forward for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states 'Small contributions over previous methods (NCNet 6 and Sparse NCNet 21)' and 'despite that it seems hard to differentiate it from its predecessors'. This indicates an explicit statement of a weakness. However, the reviewer does not specify *how* the contribution is small or *what* aspect of the method lacks differentiation. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer mentions 'NCNet 6' and 'Sparse NCNet 21' by name, which grounds the comment to specific papers. However, the reviewer also states 'mostly (good) engineering' and 'despite that it seems hard to differentiate it from its predecessors'. While the papers are mentioned, the reviewer does not clearly specify *what* aspect of the method or the paper they are referring to as being 'small contributions' or 'hard to differentiate'. The specificity is limited to the papers but the application to the current work is vague.", "verifiability_rationale": "The reviewer makes several claims: 'Small contributions over previous methods (NCNet 6 and Sparse NCNet 21)', 'despite that it seems hard to differentiate it from its predecessors', and 'mostly (good) engineering'. These are statements of opinion or judgment about the paper's strengths and weaknesses. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The claims are presented as observations without further justification.", "helpfulness_rationale": "The reviewer points out that the contribution is 'small' and 'hard to differentiate from predecessors'. While this information might be helpful for the authors to understand the novelty of their work, it does not directly suggest a concrete, actionable improvement to their current method or paper. The reviewer also mentions 'mostly (good) engineering', which is a general statement and lacks specific feedback on what aspects of the engineering are good. The feedback is more about the perceived limitations of the contribution rather than direct guidance on how to improve it. Therefore, while the feedback is relevant, it lacks the specific, actionable steps that would make it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states that the paper's description of semantic segmentation as a 'lowlevel cue' is incorrect and suggests removing this statement. The action is clear: identify and remove the statement. The implementation is also clear: know where to look for the statement and what to replace it with (or remove it entirely).", "grounding_specificity_rationale": "The comment explicitly refers to 'semantic segmentation' as the specific concept being discussed. This is a clear and precise identification of the part of the paper being addressed. The comment also specifies the issue: 'the categories are specified for each pixel', which is a specific detail within the definition of semantic segmentation that contradicts the 'lowlevel cue' characterization.", "verifiability_rationale": "The comment contains a claim: 'the statements about semantic segmentation being a lowlevel cue should be removed from the paper.' This claim is not 5 within the review point itself. While the reviewer points out the discrepancy (categories per pixel vs. typical lowlevel cues), they do not provide external references or detailed logical reasoning to definitively prove the 'lowlevel cue' characterization is incorrect within this specific review point. The reasoning is based on the definition of semantic segmentation and the common understanding of lowlevel cues, but this is an inference.", "helpfulness_rationale": "The comment is a clear and actionable suggestion to correct a potential error in the paper's description of semantic segmentation. It directly identifies a specific issue and provides a concrete direction for improvement. This is a valuable piece of feedback for the authors to identify and correct a potential misunderstanding or inaccuracy."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the observation that the performance without reinforcement learning dropped lower than without the dependency tree, providing a clear action for the authors to investigate this ablation experiment. It also points out the missing cases in the tables where neither component is used, implicitly suggesting a need to review the experimental setup and reporting. The reviewer's suggestion to look into the ablation experiment and check the tables are direct actions the authors can take.", "grounding_specificity_rationale": "The reviewer refers to 'the ablation experiment' and the 'two tables,' which, while not explicitly naming a section or figure, clearly points to specific parts of the paper being discussed. The reviewer also specifies the *issue* observed in the ablation experiment (performance drop) and the *missing information* in the tables (cases where neither component is used). This provides a degree of grounding by identifying the area of concern and the specific missing detail.", "verifiability_rationale": "The review point makes a claim about the ablation experiment's results and the missing cases in the tables. While it doesn't provide a detailed explanation or citation, it points to a potential lack of transparency or detail in the experimental reporting. The reviewer's statement about the tables not listing the cases where neither component is used is a direct observation that requires further investigation, indicating a lack of verifiable support for the expected behavior.", "helpfulness_rationale": "The review point is helpful in identifying a potential issue in the ablation study, which is relevant for understanding the contribution of different components. By highlighting the missing cases in the tables, the reviewer guides the authors to investigate the experimental setup and reporting. While it doesn't directly tell the authors how to fix the issue, it points them towards a specific area of concern and a potential missing piece of information, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The question about intended use cases is implicit, and the statement about marginal improvements is explicit but lacks detail on how to act on it.", "grounding_specificity_rationale": "The reviewer infers the topic is methodology and asks about an intended use case, which isn't explicitly stated as the paper's focus.", "verifiability_rationale": "The claim about interpretability lacks specific evidence or reasoning within the paper.", "helpfulness_rationale": "The review raises a valid concern and encourages clarification, but doesn't directly critique the methodology or suggest a concrete improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out that the paper claims GCL intentionally creates degree bias, but the theorems seem to focus on community structure. This highlights a lack of clarity in the paper regarding the mechanism by which GCL achieves this. The reviewer is asking for a more explicit explanation of how the method *intentionally* induces degree bias, rather than just stating it as a given outcome of the theorems. This is a direct request for clarification on a stated claim.", "grounding_specificity_rationale": "The reviewer explicitly states, 'How to get a small degree of bias from a clear community structure needs more explanations.' This directly points to a lack of specificity in the paper regarding the *mechanism* of how GCL achieves degree bias from a clear community structure. The reviewer is asking for a more precise explanation of the process, not just the outcome. They are also noting a potential disconnect between the theorems (focused on community structure) and the stated goal of achieving degree bias.", "verifiability_rationale": "The reviewer states, 'Theorem 1 and 2 prove that GCL conforms to a clearer community structure via intracommunity concentration and intercommunity scatter, but its relationship with degree bias is not intuitive enough.' This indicates a lack of clear verification for the claim that GCL achieves degree bias. The reviewer is pointing out that while the theorems explain community structure, they don't explicitly demonstrate or explain the connection to degree bias. The claim is present, but the reasoning and connection to the theorems are not sufficiently clear or verifiable.", "helpfulness_rationale": "The reviewer's point is highly valuable. They are highlighting a gap in the paper's explanation of how GCL achieves degree bias. This lack of clarity hinders understanding and makes it difficult for others to build upon or reproduce the results. The reviewer is essentially pointing out a missing piece of information that would be crucial for the reader to grasp the method's functionality."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point asks a question seeking clarification rather than directly proposing an action or suggesting an improvement. While it points to a potential area of confusion, the action of clarifying is not explicitly stated as an action to be taken within the paper itself. The reviewer is asking for a definition or explanation of a concept that is not immediately clear.", "grounding_specificity_rationale": "The reviewer explicitly states their confusion: 'how one constructs images for a clean exemplar manifold for a nonstochastic network?' and 'how is the denominator of figure 2.c computed for the ResNet50 & ATResNet50 networks?'. This directly targets a specific part of the methodology described in the paper, making the grounding specific. The reviewer is asking for a precise definition or explanation of a specific element.", "verifiability_rationale": "The reviewer states a fact ('earlier they state that the exemplar manifolds are constructed using either adversarial perturbations or from stochasticity of the network') and then asks a question ('how one constructs images for a clean exemplar manifold for a nonstochastic network?'). The information about stochasticity is present, but the reviewer needs to infer that 'clean exemplar manifold' refers to the unperturbed case. The connection between the stated fact and the implied inference is not explicitly stated in the paper, making it 3.", "helpfulness_rationale": "The reviewer's question directly addresses a potential ambiguity in the methodology. They are seeking clarification on how the denominator of Figure 2c is computed, which is a crucial part of understanding the manifold capacity calculation. This question has the potential to significantly improve the clarity and understanding of the paper for the authors, making it 5."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "2 (2)", "verifiability_label": "1 (1)", "helpfulness_label": "1 (1)", "actionability_rationale": "The review point explicitly states the claim 'Originality is limited...' which is an explicit statement. However, it does not provide any concrete actions or suggestions for the authors to improve their work. The reviewer identifies a potential weakness but doesn't offer a path forward. Therefore, while the action is identified, it lacks the necessary detail to be fully actionable.", "grounding_specificity_rationale": "The reviewer mentions 'variable splitting' and 'algorithm' as the basis for their claim about limited originality. While these are specific concepts, they are not tied to a particular section, table, or figure in the paper. The reviewer is grounded in the concepts discussed in the paper, but they are not specifying a particular aspect of the paper they are referring to. The claim is general to the approach rather than specific to a particular element.", "verifiability_rationale": "The review point contains the claim 'Originality is limited...' which is a statement of opinion. The reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no evidence presented to back up the assertion about the originality being limited. Therefore, the claim is 1.", "helpfulness_rationale": "The review point states 'Originality is limited...' and provides no suggestions or actionable steps for the authors. It presents a negative assessment of the paper's contribution without offering any constructive feedback or guidance on how the authors can address this perceived limitation. Therefore, it is not helpful for guiding the authors' work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly names the paper 'Ghoshdastidar and Dukkipati (AAAI 2015)' and states its relevance to the authors' work by mentioning 'hypergraph data with tensors'. This is an explicit statement of relevance. The suggestion to 'discuss and compare against to provide a better understanding of the stateoftheart' is a concrete action the authors can take.", "grounding_specificity_rationale": "The review point explicitly names the paper 'Ghoshdastidar and Dukkipati (AAAI 2015)'. This is a literal mention of a specific section, table, figure, or unique aspect of the paper. The review also explains the relevance of this paper by mentioning 'hypergraph data with tensors', which clearly identifies the specific aspect of the paper being addressed.", "verifiability_rationale": "The review point contains a claim: 'This AAAI 2015 paper deals with hypergraph data with tensors as well so it should be discussed and compared against to provide a better understanding of the stateoftheart.' This claim is supported by the statement that the paper deals with 'hypergraph data with tensors', which are specific features. However, the review point does not provide specific examples or references within the review itself to pinpoint exactly where the authors should look in the missed paper.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the authors. It identifies a potential gap in the related work (the missed AAAI 2015 paper) and provides a concrete next step: 'discuss and compare against to provide a better understanding of the stateoftheart'. This directly addresses a likely weakness and offers a constructive improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'Some ablation study is missing...' which is a clear and direct action. It identifies the missing element and the purpose of the study, making it actionable for the authors.", "grounding_specificity_rationale": "The comment explicitly refers to 'ablation study' and specifies the importance of understanding the role of hyperparameters like \u03c3, \u03b7, and \u03c4. The authors can easily identify the missing element and the specific parameters involved, making it 5.", "verifiability_rationale": "The comment contains a claim that an ablation study is missing and that it is crucial. However, it does not provide any evidence or reasoning to support this claim. It presents a suggestion without justification, making it 1.", "helpfulness_rationale": "The comment points out a missing experimental component (ablation study) and highlights the importance of specific hyperparameters. While it identifies a gap, it does not provide concrete guidance on how to conduct the ablation study or why these specific parameters are so crucial. Therefore, it is 3 but lacks the depth needed to fully assist the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what is unclear or how the authors should apply any changes. The reviewer states they had trouble following the experimental procedures and evaluations but does not identify the specific steps or sections that caused the difficulty. Therefore, the action is not clearly defined, making it 1.", "grounding_specificity_rationale": "The reviewer can identify the area of the paper they are referring to, which is the experimental procedures and evaluations. While they don't provide a literal section number, the description is specific enough to pinpoint the relevant content. Therefore, the grounding is present, but not perfectly precise, making it weakly grounded. The specificity of the identified area is also high as they clearly indicate *what* is unclear.", "verifiability_rationale": "The review point is a statement of opinion about the paper's readability, not a claim that requires verification. There is no assertion of what is wrong or needs improvement. Therefore, it does not contain a claim that can be supported by evidence.", "helpfulness_rationale": "The reviewer identifies a problem area (experimental procedures and evaluations) but does not offer specific suggestions for improvement. They point to a location but don't explain *why* it's unclear or *how* to clarify it. This is better than a completely unhelpful comment but lacks the depth of a 5 one. The helpfulness is moderate as the reviewer points to a specific issue, but lacks concrete solutions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the paper's claim: 'Finally, INRs operate on a perdatainstance basis, meaning that one timeseries instance is required to train an INR'. They then directly identify the action: 'This claim is true but I don't think it is an advantage'. The action is also concrete, as the reviewer clearly states the implication of this perdatainstance operation.", "grounding_specificity_rationale": "The reviewer's critique focuses on the implication of the perdatainstance operation, which is that it limits the practicality of INRs for models handling single time series data. While the reviewer doesn't explicitly mention 'section 2' or 'timeseries data' in their critique, the context of the review point is clearly within the discussion of INRs and their operation. The reviewer provides context and implication by stating 'I don't think it is an advantage', suggesting they understand the practical limitations. However, the grounding is not explicit, as the reviewer doesn't directly point to a specific section or table in the paper.", "verifiability_rationale": "The reviewer presents a claim: 'This claim is true but I don't think it is an advantage'. The claim that the statement is 'true' can be considered 3, as it aligns with a generally understood characteristic of INRs. However, the claim that it is 'not an advantage' lacks direct support or justification within the review point itself. The reviewer is making an inference about the practical implications of the perdatainstance operation.", "helpfulness_rationale": "The reviewer's point is helpful because it clarifies a potential misunderstanding of the paper's claim about INRs. By highlighting that a model handling only single time series data is 'almost useless,' the reviewer provides valuable context and guidance for potential users or implementers of INRs. This helps authors understand the limitations and practical applicability of the technology discussed in the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that 'certain parameters are bounded on one side (acceleration and scaling parameters).' This provides a clear and concrete action for the authors to take, identifying the missing information and the specific parameters involved. The action is not just implied but explicitly stated.", "grounding_specificity_rationale": "The review point refers to 'specific model' and mentions 'gamma^1 and gamma^m', which are specific mathematical objects within the model description. It also explicitly mentions 'acceleration and scaling parameters', which are specific components of the model. The authors can directly identify the relevant parts of the model being discussed, and the information provided is specific to these parts.", "verifiability_rationale": "The review point makes a claim: 'it should be clear from the beginning that we are not operating in a setting with infinite subdivisions for gamma^1 and gamma^m and that certain parameters are bounded on one side (acceleration and scaling parameters).' This claim is supported by the subsequent explanation of the implications of these bounded parameters. The reasoning is logical and directly relates to the model's description.", "helpfulness_rationale": "The review point directly points out a specific, actionable issue related to the model's assumptions. It tells the authors what to look for and what might be missing, which is a helpful piece of feedback. While it doesn't provide a solution, it identifies a concrete problem that the authors should be aware of."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a limitation in the experiments and suggests improvements. The reviewer points out that most experiments (excluding Section 4.1.1) are limited to RoBERTabase and questions the generalizability of the results to other models with learnable APEs. The reviewer suggests investigating differences in model size, objective function, and architecture, specifically mentioning GPT2. While the reviewer doesn't explicitly state an action, the suggestion to 'explore other models' and 'include more analysis and discussion' implies a clear action to be taken by the authors. The reviewer also suggests looking at Figure 2 for GPT2, which is a concrete action.", "grounding_specificity_rationale": "The review point explicitly mentions 'most of the experiments' and 'excluding Section 4.1.1', which grounds the reference to specific parts of the paper. The reviewer then states 'it is unclear if the results can be generalized to other models adopting learnable APEs', which clearly identifies the issue being addressed. The reviewer suggests 'further investigations' and specifically mentions 'GPT2' and 'Figure 2', which are concrete elements. The reviewer also states 'it is important to investigate whether the results can be generalized', which is a clear action to be taken. The reviewer's suggestion to 'include more analysis and discussion' for different model sizes, objectives, and architectures further grounds the reference to specific aspects of the work.", "verifiability_rationale": "The review point presents a claim: 'most of the experiments (excluding Section 4.1.1) are limited to RoBERTabase only, and it is unclear if the results can be generalized to other models adopting learnable APEs'. This claim is supported by the reviewer's statement that 'it is important to investigate whether the results can be generalized to differences in model size, objective function, and architecture (i.e., encoder, encoderdecoder, or decoder)'. The reviewer also provides a specific suggestion: 'In particular, it is worthwhile to include more analysis and discussion for GPT2. For example, I would like to see the results of Figure 2 for GPT2.' This provides a clear justification for the claim. The reviewer explicitly states a reason for investigating other models and provides a concrete example (GPT2 and Figure 2). The claim is directly followed by a justification and a specific example, making it 5.", "helpfulness_rationale": "The review point directly identifies a limitation in the experimental setup, specifically the lack of generalizability of results to other models with learnable APEs. It provides a clear direction for improvement by suggesting the authors investigate differences in model size, objective function, and architecture, with a specific focus on GPT2 and referencing Figure 2. The reviewer's suggestion to 'explore other models' and 'include more analysis and discussion' are actionable steps that the authors can take to address the identified weakness. The reviewer's request to 'look at Figure 2 for GPT2' is a very specific and helpful suggestion that directly points the authors to a concrete area of their work to investigate further. This review point provides a clear and actionable next step for the authors, making it 5."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "1 and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggestion. It raises a question about the scope of the method's applicability. While it doesn't directly tell the authors what to do, it encourages them to consider the limitations of their work and whether the principles apply to other areas and models. The lack of a clear action makes it less actionable than a suggestion to improve a specific section.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or method that is being questioned. The question is about the general applicability of the method across different areas and models. While it implies a concern about the scope, it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. Therefore, it lacks strong grounding specificity.", "verifiability_rationale": "The review point makes a claim about the limited scope of the experiments and the lack of generalization to other areas and models. This claim is 3 because the reviewer provides specific examples (NLP and CNNs) and a potential reason (focus on stateoftheart performance). However, the claim doesn't provide a clear justification or evidence to support the assertion that the method is 'only good for image data and ViT'. The reasoning is present but could be more robust.", "helpfulness_rationale": "The review point raises a valid question about the generalizability of the proposed method. It challenges the authors to consider whether the principles they've developed are applicable beyond the specific context of image data and ViT. This is a helpful point because it prompts the authors to think critically about the limitations of their work and whether they need to explore the method's performance in other domains or with different models. While it doesn't provide a definitive answer, it encourages a more comprehensive evaluation of their approach."}
{"actionability_label": "3. 3", "grounding_specificity_label": "3. 3", "verifiability_label": "1. 1", "helpfulness_label": "2. 2", "actionability_rationale": "The reviewer explicitly states their opinion about the authors' understanding of learning rate scaling and its practical implications. This is a direct statement of what they believe. While they don't propose a specific alternative, the implication is clear: the authors should reconsider the necessity of the stated condition. The action is implicit in the statement, but the reviewer doesn't identify a concrete action the authors should take to address this perceived flaw.", "grounding_specificity_rationale": "The reviewer states a belief about *practical experience*. While they don't explicitly point to a *specific* section or table in the authors' paper, the implication is that the authors' experience differs from the stated condition. This is weak grounding. The specificity is in the *necessity* and *scalability* of a specific condition, but the grounding is weak because they don't explicitly point to a specific section or table in the authors' paper that contradicts their understanding of learning rate scaling.", "verifiability_rationale": "The reviewer states a claim: \"I never see a step size grows with the sample size in practice\". This is a clear statement of opinion. However, the reviewer doesn't provide any evidence or justification for their claim. They are stating an observation based on their own experience, but without backing it up with literature or data. The claim is presented as a statement of observation without any supporting evidence or justification.", "helpfulness_rationale": "The reviewer's comment raises a valid point about the authors' understanding of learning rate scaling. However, they don't offer any concrete suggestions or evidence to support their claim. The impact is limited because the authors are the ones being questioned, not given clear directions on what to do. While the reviewer highlights a potential issue, they don't provide actionable steps for the authors to take. The helpfulness is limited because the authors are not given clear guidance on how to adjust their learning rate based on the reviewer's experience."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a missing element (evaluation details) but doesn't explicitly state the desired improvement to the abstract based on this missing information. The action is implied, not explicitly stated.", "grounding_specificity_rationale": "The review point refers to the abstract as a whole and criticizes its general lack of evaluation details. It doesn't specify a particular section, table, figure, or unique aspect of the paper being addressed.", "verifiability_rationale": "The reviewer makes claims about the abstract: \"The abstract does a good job explaining the proposed idea\" (a judgment) and \"but lacks description of how the idea was evaluated\" and \"and what was the outcome\" (claims that need justification). These claims could be supported with more information, but the information isn't explicitly provided or referenced.", "helpfulness_rationale": "The reviewer points out a lack of detail in the abstract. This directly translates to a lack of actionable feedback for the authors. While the abstract is deemed \"good\" in explaining the idea, the absence of information on how it was evaluated and the outcome makes it difficult for the authors to understand the practical implications and potential issues."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states their 'doubt' about the experimental results and provides specific examples of POMDP problems with nonconvex value functions. They then criticize the lack of experiments related to these specific examples. This is an explicit statement of a problem and suggests a clear action for the authors: to add experiments for the mentioned POMDP settings.", "grounding_specificity_rationale": "The reviewer mentions specific POMDP examples (surveillance with thresholded rewards, privacypreserving data collection) but does not explicitly state which part of the paper these examples are meant to represent. They imply these are relevant to the paper's motivation but don't point to a specific section or table. Therefore, while the examples themselves are specific, the connection to the paper's content is weak.", "verifiability_rationale": "The reviewer makes a claim that the experiments are not convincing and that the chosen examples are not representative. However, they do not provide any external references or logical reasoning to support their claim about the unconvincing nature of the experiments or the lack of relevant examples. They are expressing a concern based on their interpretation, not providing evidence.", "helpfulness_rationale": "The reviewer's primary criticism is the lack of experimental validation for specific examples. This directly hinders the reader's ability to assess the paper's claims and understand the practical implications. The lack of concrete evidence makes the paper less useful."}
{"actionability_label": "2", "grounding_specificity_label": "1 and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests a type of analysis but doesn not explicitly state the steps or tools to perform it, making it implicit. While the suggestion is relevant, the lack of concrete steps means it's not fully actionable.", "grounding_specificity_rationale": "The reviewer refers to 'epochwise analysis' and 'finite sum settings' generally, without specifying a particular section, table, figure, or unique element in the paper. This makes it 1 in a specific part of the paper. While the reviewer mentions specific areas like 'batch size' and 'sampling strategies,' these are not specific to a particular part of the paper that the reviewer is implying the authors should focus on. The comment is more of a suggestion for future work rather than a direct critique of a specific element.", "verifiability_rationale": "The reviewer makes a claim about the potential benefits of epochwise analysis and provides logical reasoning to support it, such as investigating different batch sizes and sampling strategies. This claim is verifiable through common knowledge in optimization and the understanding of how these factors influence algorithm progress. However, the reviewer does not provide specific examples or references to external works to back up these claims.", "helpfulness_rationale": "The reviewer suggests a potential improvement to the analysis section by proposing epochwise analysis. While the suggestion lacks specific implementation details, it points to a relevant area for improvement that could benefit the authors. The reviewer is making a suggestion that, even if not fully actionable, has the potential to be helpful for the authors in understanding the behavior of their optimization algorithms."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a problem (ambiguity in distinguishing extreme speech) and provides an example. This suggests an implicit action, but the action itself is vague and lacks detail on how to apply it. The reviewer doesn't explicitly state what needs to be done to differentiate the speech types.", "grounding_specificity_rationale": "The reviewer mentions the definitions in the Paper Summary but does not explicitly refer to a specific section, table, or unique aspect of the paper where these definitions are located. The example provided is general and does not pinpoint a specific part of the paper being addressed.", "verifiability_rationale": "The reviewer claims there is ambiguity in the labeling of the instance. This is a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The ambiguity is presented as a statement without further justification.", "helpfulness_rationale": "The reviewer identifies a problem (ambiguity in distinguishing extreme speech) and provides an example. This suggests some level of helpfulness in pointing out an issue. However, the lack of grounding and verifiability makes it less helpful for the authors to directly address the problem."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point directly instructs the authors on what to do: 'Add a graph showing the plot of T vs number of images, and Expectation(T) over the imagenet test set.' This is a clear and explicit action. The reviewer also explains *how* to interpret the graph, stating 'It is important to understand whether the performance improvement stems solely from the network design to exploit spatial redundancies, or whether the redudancies stem from the nature of ImageNet, ie., large fraction of images can be done with Glance and hence any algorithm with lower resolution will have an unfair advantage. Note, algorithms skipping layers or channels do not enjoy this luxury.' This explicit statement further clarifies the intended use of the graph.", "grounding_specificity_rationale": "The review point explicitly mentions 'T', 'number of images', 'Expectation(T)', and 'Imagenet test set'. This provides a very clear and specific reference to the parts of the paper and data that the authors should use to create the graph. The reviewer also explains the *purpose* of the graph, which further grounds the request.", "verifiability_rationale": "The reviewer provides a clear *request* for a graph and explains *why* it would be useful. While they don't provide a definitive method for generating the graph, the request is based on a logical understanding of the potential factors influencing performance and the potential impact of ImageNet characteristics. The reviewer's explanation is a plausible hypothesis and provides a direction for the authors to follow.", "helpfulness_rationale": "The review point is 5. It directly addresses a potential ambiguity in the authors' results by suggesting a specific analysis (the graph). It provides a clear direction for the authors to take, asking them to consider the source of performance improvement. The request is specific about the type of graph and the datasets involved. It encourages the authors to critically evaluate their work and consider alternative explanations for their results. The reviewer's explanation of the potential reasons for the performance improvement is also helpful in guiding the authors' thinking."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'I believe this needs to be changed to be mathematically correct...'. However, the action is vague as it doesn't specify *how* the mathematical correctness needs to be improved or what specific aspect of the equations requires correction. The suggestion about notation clarity ('unless that makes a bunch of other equations messy. Also, why is it L_l instead of just L? That notation should be introduced beforehand.') is also vague and doesn't provide concrete steps for improvement. The comment lacks specific details on how the mathematical correctness should be addressed and why L_l is problematic without further context.", "grounding_specificity_rationale": "The comment explicitly mentions 'mathematically correct' and 'notation clarity' as areas for improvement. It points to a potential issue with equations (implying a specific part of the paper) and suggests introducing a notation (L_l). However, it doesn't explicitly identify a specific section, table, figure, or unique element of the paper where the issue lies. The mention of 'equations' is general, and while 'notation clarity' targets a specific aspect, the overall grounding is not precise.", "verifiability_rationale": "The comment contains a claim: 'I understand what it's trying to say but I believe this needs to be changed to be mathematically correct...'. The reasoning provided is that the authors understand the general idea but there's a specific issue with mathematical correctness. However, the justification for this claim is vague. The comment doesn't provide specific examples, references, or logical reasoning to support the claim that the mathematical correctness needs to be changed. The suggestion about notation clarity ('unless that makes a bunch of other equations messy. Also, why is it L_l instead of just L? That notation should be introduced beforehand.') lacks concrete evidence or references to support the claim about notation.", "helpfulness_rationale": "The comment provides specific suggestions for improvement, such as 'I believe this needs to be changed to be mathematically correct...' and 'why is it L_l instead of just L? That notation should be introduced beforehand.' These suggestions are directly related to the authors' work and aim to address potential issues. The reviewer also asks a question ('Fig.') which encourages the authors to clarify a specific aspect of their work. While the suggestion about the 'Fig.' is less specific, the other points are actionable and directly address potential weaknesses. The reviewer is actively engaging with the authors' draft and pointing out areas that need attention."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement 'When trained and evaluated with the same timestep, Figure 5 shows similar performance between the baseline model and the timeaware model' is an explicit action or suggestion. However, the reviewer then states 'This makes the effectiveness of the proposed methods questionable when the goal is just to achieve good performance'. This is an implicit action, as the reviewer is inferring that the similar performance indicates a potential issue with the effectiveness of the proposed methods. The reviewer also suggests trying different timesteps, which is an action that could be taken, but it is not explicitly stated as a direct action to be performed by the authors. Therefore, while the initial observation is explicit, the subsequent actions are inferred, making it 2.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 5' as a specific part of the paper. Furthermore, it clearly states 'when trained and evaluated with the same timestep, Figure 5 shows similar performance'. This indicates that the authors can accurately pinpoint the section being referenced and understand the issue being discussed within that section. Therefore, the grounding is both explicit and accurate, leading to full grounding.", "verifiability_rationale": "The review point contains a claim: 'This makes the effectiveness of the proposed methods questionable when the goal is just to achieve good performance'. This is a statement of opinion or judgment. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion to 'maybe under some scenarios where the training timestep and evaluation timestep are different' is a potential solution, not a verification of the current claim. Therefore, the claim is not supported by evidence, making it 1.", "helpfulness_rationale": "The review point identifies a potential limitation of the proposed methods based on an observation regarding similar performance. While it raises a valid concern, it does not offer a concrete suggestion or explanation for why the methods might be ineffective in this specific scenario. The reviewer suggests trying different timesteps, which could be a helpful action, but the point itself doesn't provide a clear path forward or a deeper analysis of the issue. Therefore, the review point is not 5 as it doesn't directly guide the authors towards a solution or a deeper understanding of the problem."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a lack of clarity regarding how disentanglement is guaranteed. While the reviewer identifies a missing piece of information (the mechanism for ensuring disentanglement), they do not explicitly state what steps or methods are used to achieve this. The reviewer is implicitly suggesting that the authors should elaborate on this aspect. Therefore, the action is implied but not explicitly stated, making it partially actionable. The reviewer is not suggesting a specific action to take, but rather pointing out a gap in the explanation.", "grounding_specificity_rationale": "The reviewer mentions \"Broader Impacts and Limitations\" as the section where the issue of disentanglement is discussed. While the reviewer identifies a relevant section, they do not specify *which* part of that section or what *exact* point within it is causing confusion. The grounding is present but not fully specific. The reviewer could have been more precise about which subsection or paragraph is lacking clarity.", "verifiability_rationale": "The reviewer states that \"It is not clear how disentanglement is guaranteed.\" This is a claim made by the reviewer. The reviewer provides the context of the \"Broader Impacts and Limitations\" section acknowledging this as a limitation, which partially supports their claim. However, the reviewer does not provide any specific examples, references, or logical reasoning to back up their assertion that the disentanglement is not clearly explained or guaranteed. The claim is stated, but the lack of clarity is not rigorously proven or explained further.", "helpfulness_rationale": "The reviewer's point directly addresses a practical issue for the authors: the lack of clarity regarding the disentanglement mechanism. This feedback is relevant and encourages the authors to provide more detailed explanations in the \"Broader Impacts and Limitations\" section. While the reviewer doesn't explicitly suggest a solution, they highlight a specific area where the authors need to improve their writing. The feedback is focused and directly addresses a potential area for confusion, making it 3 in guiding the authors to enhance their paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'It would be good to include...' which is a direct and clear request for a specific action. The reviewer also specifies 'a baseline in the left graph in fig 3', making the action even more concrete. There is no ambiguity about what the reviewer wants the authors to do.", "grounding_specificity_rationale": "The reviewer explicitly states 'a baseline in the left graph in fig 3'. This directly and precisely identifies the section of the paper and the specific element requested. There is no ambiguity about which part of the paper is being referred to.", "verifiability_rationale": "The reviewer makes a suggestion ('It would be good to include...') which can be considered a claim that the authors would benefit from this addition. While the reviewer doesn't explicitly state *why* this baseline is helpful, the request itself is a verifiable action. The reviewer is suggesting a standard practice in the context of learning curves.", "helpfulness_rationale": "The reviewer provides a clear and practical suggestion aimed directly at improving the visualization of learning curves. The suggestion is directly relevant to the authors' work and is likely to be helpful in understanding the learning process. The request is specific and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1: X", "helpfulness_label": "2", "actionability_rationale": "The review point suggests discussing different input types, which is relevant. However, it lacks specific, actionable steps on how to do this. The vague pronoun 'it' makes it unclear what needs to be discussed.", "grounding_specificity_rationale": "The review point is very general and doesn't specify which part of the paper it's addressing. The vague pronoun 'it' makes it difficult to ground the comment specifically.", "verifiability_rationale": "The review point is a suggestion, not a claim that needs verification.", "helpfulness_rationale": "The suggestion is relevant but lacks concrete action. It's a valuable idea but not a fully actionable suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly asks a question about the relationship between equations, which is a clear and actionable suggestion for the authors to consider the implications of these equations. The question is specific and targets a potential area for improvement.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Eq. 3', 'Eq. 4', and 'Table 5' and mentions the 'OfficeHome' dataset. This demonstrates a clear understanding of the paper's structure and content, making the grounding very specific.", "verifiability_rationale": "The reviewer provides specific numerical values from Table 5, stating that the improvement from 64.35 to 64.71 on the OfficeHome dataset is marginal. This is a verifiable statement based on the provided data.", "helpfulness_rationale": "The reviewer's point is 5. They are not just pointing out a weakness; they are suggesting that the lack of significant improvement in some datasets warrants further investigation and potentially a refinement of the proposed solution. This is a valuable insight for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the action: \"the question answering requires the template mapping to transform the question into a masked statement\". This clearly identifies an action that needs to be taken or improved. Furthermore, the reviewer explains how this transformation is done, which makes the action quite concrete.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific part of the paper being addressed: \"the question answering requires the template mapping to transform the question into a masked statement\". This demonstrates strong grounding as the reviewer is directly referring to the process of question transformation. The reviewer also specifies the potential limitation regarding generalization to non'Wh' questions, adding further specificity.", "verifiability_rationale": "The reviewer states a concern: \"might cause the poor generalization to questions that are not 'Whtypes'/transformable\". This is a claim that requires verification. While the reviewer doesn't provide the verification within the review point itself, the statement itself points to a potential issue that could be supported or refuted with evidence. The core issue (limitation of 'Wh' questions) is clear, and the impact on generalization is also stated.", "helpfulness_rationale": "While the reviewer raises a valid concern about a specific implementation detail, the impact on the overall helpfulness is somewhat limited. The suggestion is very specific and technical, and its direct applicability might vary depending on the context and the specific QA system being used. It's a targeted critique rather than a broadly applicable piece of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states that 'To utilize a volumetric representation in the deformation field is not a novel idea' and names a specific prior work, VolumeDeform. This directly points out a potential area for improvement or alternative approaches. The action is clearly stated, making it concrete.", "grounding_specificity_rationale": "The comment implies the relevance of 'volumetric representation' to the 'deformation field', which is a key component of the method described in the paper. While not a direct mention of a section or table, this implies a specific part of the paper. The comment also specifies what it is referring to by explaining *why* it's not novel (lack of novelty) and mentions a specific prior work (VolumeDeform), making it highly specific within the context of volumetric deformation.", "verifiability_rationale": "The comment contains a claim: 'To utilize a volumetric representation in the deformation field is not a novel idea'. The reviewer provides a potential justification by mentioning 'VolumeDeform has proposed volumetric grids to encode both the geometry and motion, respectively.' This provides a reference point and a basis for further investigation. However, the explanation of *why* this is the case or *how* VolumeDeform achieves this is not detailed, making the verifiability somewhat incomplete.", "helpfulness_rationale": "The review points out a potential lack of novelty in the use of volumetric representations. While this is a valid observation, it does not offer concrete suggestions for improvement or alternative approaches. The comment is more of a headsup than a constructive suggestion to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a problem (drop in accuracy) caused by a change (ICLHAR). While it suggests discussing this issue, it doesn't explicitly recommend any specific actions or modifications to address the accuracy drop. The action is implicit, requiring the authors to infer the need for discussion.", "grounding_specificity_rationale": "The review point mentions 'ICLHAR' and 'accuracy scores' and their respective changes ('improving consistency' and 'dropping from 70.4 to 55.6 on TRIP). This clearly identifies the specific part of the paper and the metric being discussed, making it 5.", "verifiability_rationale": "The review point makes a claim ('This should be discussed or at least acknowledged in the main text') but doesn't provide specific reasons why this discussion is important or examples of what aspects of the ICLHAR implementation should be addressed. The justification is weak and lacks detailed support.", "helpfulness_rationale": "The review point identifies a clear weakness ('drop in accuracy scores') and suggests a direction for improvement ('discussion or acknowledgement'). While it doesn't offer specific, actionable steps on how to improve the discussion or the ICLHAR implementation, it provides a clear problem and a general suggestion for resolution, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out the limitations of the innovations and the performance being tied to the oracle expert. While it identifies a problem, it doesn't specify *how* or *what* needs to be changed. The action is implied but not explicitly stated in concrete terms.", "grounding_specificity_rationale": "The review mentions 'innovations of network architecture design' and 'constraint embedding'. While it refers to these concepts, it doesn't pinpoint specific sections, tables, or unique elements within the paper that are affected. The grounding is present but not fully specific.", "verifiability_rationale": "The review states that the 'innovations of network architecture design and constraint embedding are rather limited' and that 'the performance is limited by the performance of the oracle expert'. This is a claim that needs to be supported. However, the review does not provide specific evidence, references, or logical reasoning to back up this claim. The justification is missing.", "helpfulness_rationale": "The review identifies potential limitations in the 'innovations of network architecture design' and 'constraint embedding', and attributes the performance issues to the 'performance of the oracle expert'. While this points to a potential area for improvement, it does not offer specific, actionable steps or suggestions on how to address these limitations or improve the architecture or embedding. The feedback is diagnostic but lacks constructive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of the AUC and proposes concrete solutions, such as calibration curves and a feasibility study. These suggestions directly address the identified issues with the AUC, making the criticism actionable. The reviewer also points out the difference between the traditional method and their method, providing a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'related studies' and 'this paper' when suggesting improvements, indicating a general direction for future work. However, they do not explicitly refer to a specific study or detail how their method differs from the traditional method. The grounding is weak because the specific elements being addressed are not clearly defined within the paper.", "verifiability_rationale": "The reviewer claims that the AUC has limitations in the clinical context and suggests calibration curves as a way to verify this. While the claim is made, the reviewer does not provide specific examples of where these calibration curves should be applied or why the traditional method is insufficient beyond a general statement. The verifiability is moderate as the claim is made, but the supporting evidence is vague and lacks specific examples or references.", "helpfulness_rationale": "The reviewer provides specific and actionable feedback on the limitations of the AUC and suggests concrete improvements, such as calibration curves and a feasibility study. These suggestions are directly aimed at enhancing the evaluation process and addressing the identified weaknesses. The reviewer also highlights the difference between the traditional method and their method, providing a clear direction for improvement. The suggestions are clear and directly address the identified issues, making the review 5."}
{"actionability_label": "3", "grounding_specificity_label": "2: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states the observation that the range of ID and OOD doesn't change much after sparsification. However, it doesn't provide any concrete action or suggestion on how to address this observation or what it implies. The comment also implicitly suggests that the assumption in Lemma 2 is not well discussed and its relevance to DICE is unclear, but it doesn't explicitly state what should be done about it. Therefore, while the action is present, the concreteness of the action and the explicitness of the suggestion are lacking.", "grounding_specificity_rationale": "The comment refers to 'Figure 4' and the 'range of ID and OOD', indicating a clear identification of the specific part of the paper being discussed. Similarly, it refers to 'Lemma 2' and 'DICE', also indicating a clear identification of the specific parts. Therefore, the grounding is explicit and the authors can easily identify the referenced sections.", "verifiability_rationale": "The comment contains claims: 'the range of ID and OOD seems not to be changed much by sparsification' and 'Lemma 2 requires approximately identical mean as the assumption'. However, it does not provide any logical reasoning, common knowledge, or external references to support these claims. The implications for DICE are also not discussed. Therefore, the claims are present, but they are not wellsupported.", "helpfulness_rationale": "The comment points out observations and raises questions related to the paper's content. However, it does not offer any concrete suggestions or actionable steps for the authors to take based on these observations. The questions asked are not followed by any guidance or proposed solutions. Therefore, the feedback is present but lacks actionable value."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a clear and actionable list of suggestions. They explicitly state *what* is missing and *why* it's a problem. For example, they state 'Besides, the experiments seem not too strong and fair to me' and then suggest 'why all the baselines use the position kernels, why don't we use the default settings of these baselines in the literature?'. This indicates that the reviewer understands the implications of their comments and can guide the authors towards concrete improvements.", "grounding_specificity_rationale": "The reviewer's points are quite general. They talk about the 'experiments,' 'baselines,' and 'limitations' without pinpointing specific sections or tables in the paper. While they mention 'position kernels' and 'default settings,' they don't explicitly state which section or table is affected. The reviewer's critique is highlevel, identifying areas for improvement rather than specifying the exact location of the issue within the paper.", "verifiability_rationale": "The reviewer makes several claims and provides justifications for them. For example, they state 'Besides, the experiments seem not too strong and fair to me' and then suggest 'why all the baselines use the position kernels, why don't we use the default settings of these baselines in the literature?'. This demonstrates that the reviewer has identified specific problems and has provided logical reasoning to support their claims. The suggestions also indicate a clear understanding of how the authors can address these issues.", "helpfulness_rationale": "The reviewer's comments are directly helpful to the authors in improving their work. They provide concrete suggestions for improvement, such as 'use the default settings of these baselines in the literature' and 'include missing baselines related to BO with discrete & categorial variables'. These suggestions are actionable and directly address the identified weaknesses. The reviewer is not just criticizing but also offering clear paths for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point describes the observed behavior of the model's correlation after training but does not provide explicit instructions or concrete steps on how to address this issue. It states 'there is a drop of correlation after a short period of training, which goes up with more training iterations' which is a description of what happened, not what to do. There is no mention of how to adjust parameters, implement changes, or interpret the results to improve the model.", "grounding_specificity_rationale": "The review point mentions 'correlation' and 'training iterations' but does not specify which part of the model or the training process is exhibiting this behavior. It is general and does not point to a specific section, table, figure, or unique aspect of the paper. The reviewer is observing a trend rather than pinpointing a specific issue.", "verifiability_rationale": "The review point describes an observation about the model's behavior during training. It does not make a claim that requires verification or justification. It is a statement of fact about what happened, not a proposition that needs to be supported by evidence or logical reasoning. There are no external references or logical arguments provided to explain the observed correlation changes.", "helpfulness_rationale": "The review point identifies a phenomenon (correlation drop followed by increase) that the authors might be experiencing. While it points out a potential issue, it does not offer concrete solutions or actionable advice on how to address it. It is more of an observation than a constructive suggestion for improvement. The reviewer does not provide guidance on how to interpret this behavior or what steps to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a question ('Is this something unique to the sparsity detection problem or is this true for GNN in general?') which implies an implicit action of seeking clarification. However, the reviewer does not explicitly state how they would go about finding this clarification or what specific steps they would take. The suggestion ('Section 4.3: representation bits > presentation bits') is a direction for the authors to look, but the reviewer themselves doesn't provide a concrete action on their part. Therefore, while the intent is actionable, the specific steps are not clearly defined, making it 2.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Section 4.3: presentation bits > representation bits'. This is a very specific reference to a section and a concept within the paper, indicating strong grounding. However, the reviewer *asks* for insight, implying a lack of it within that section. The grounding itself is specific, but the lack of insight is a separate issue addressed by verifiability.", "verifiability_rationale": "The reviewer states ('all sparsity patterns do almost equally well. No insight provided as to what is happening here.') which is a claim requiring justification. However, the reviewer does not provide any specific examples, references, or logical reasoning to support this claim. While the suggestion to look at GNNs in general could be considered a potential basis for external verification, the reviewer's own statement lacks sufficient evidence within the context of the paper being reviewed. Therefore, the claim is present, but the supporting evidence is weak and speculative.", "helpfulness_rationale": "The reviewer directly asks for clarification ('Section 4.3: representation bits > presentation bits') and seeks insight ('Is this something unique to the sparsity detection problem or is this true for GNN in general?'). These are clear requests for information that could directly help the authors improve their draft. While the review point itself doesn't offer a solution, it points towards areas where the authors need more information, which is helpful in the context of improving their work. The reviewer's intent to seek clarification and insight is a valuable contribution to the authors' understanding."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4. This is a direct identification of a missing component, making it a concrete action. The reviewer also implies that the derivation should be corrected by including the temperature, providing a clear action to be taken.", "grounding_specificity_rationale": "The reviewer refers to 'Eqn. 3' and 'Eqn. 4', which are specific parts of the paper. They are also referring to the 'derivation' process between these equations. This demonstrates strong grounding as the reference is very specific. Furthermore, the reviewer explicitly states that the missing element is the 'temperature \u03c4', which is a specific detail within that derivation.", "verifiability_rationale": "The reviewer makes a claim that the derivation from Eqn. 3 to Eqn. 4 is missing the temperature \u03c4. While the reviewer doesn't provide a detailed explanation of *why* it's missing, the implication is that the temperature is a crucial component of such derivations, especially given the mention of \u03c4. The suggestion to 'mention it' or 'do it rigorously' provides a direction for verification, making the claim 3.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for improvement: the derivation from Eqn. 3 to Eqn. 4 should include the temperature \u03c4. This directly addresses a potential weakness in the paper and provides a concrete action for the authors to take. The reviewer's comment is directly aimed at helping the authors improve their draft by correcting a specific omission."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "1 (1)", "verifiability_label": "X (X)", "helpfulness_label": "4 (4)", "actionability_rationale": "The review point explicitly suggests an action (adding a citation) and provides a method (using an example like 2). While it doesn't pinpoint the exact location of the citation, the phrasing implies it relates to the discussion of differential privacy, making it 3.", "grounding_specificity_rationale": "The review point refers to 'differential privacy' generally and suggests adding a 'citation' without specifying which part of the paper this relates to or where the citation should go. This makes it 1 in terms of specific paper sections or elements, and also not specific in the details of what needs to be added.", "verifiability_rationale": "The review point is a suggestion or recommendation, not a declarative statement that requires verification. It doesn't make a claim about the paper's current state or propose a new idea. Therefore, it has X and is classified as 'X'.", "helpfulness_rationale": "The review point suggests adding a citation to support the discussion of differential privacy. This is a common practice in academic writing and helps improve the rigor and clarity of the paper. It directly addresses a potential weakness (a lack of supporting evidence) and provides a concrete improvement, making it 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides two explicit statements that are directly actionable for the authors. The first point directly addresses a potential misunderstanding about the level of assumptions, and the second points to a specific error in an inequality. Both points are clear and provide concrete directions for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3.2' and the specific claim within that section. While they don't pinpoint a specific part *within* the claim, they clearly reference a section and a general area of the claim, making it 5.", "verifiability_rationale": "The reviewer identifies two claims: 'this methodology requires significant additional assumptions' and 'the inequality on line 310 has wrong sign'. For the first claim, the reviewer provides a reasoning based on common ML assumptions, making it 3. For the second claim, the reviewer provides a specific location and a clear error, making it 5.", "helpfulness_rationale": "The reviewer provides two concrete suggestions for improvement. The first is a question about the framing of a claim, and the second is a specific correction to an inequality. These are both actionable and directly address potential issues in the draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for a comparison with other methods (CaCE, raw gradients) and a discussion on transforming highdimensional data to lowdimensional latent spaces. These are clear actions the authors should take. The reviewer also suggests these should be in the 'experimentally with other methods' and 'significant discussion' sections, providing further detail on the actions.", "grounding_specificity_rationale": "The reviewer identifies the need for comparisons with other methods and a discussion on data transformation. While they don't explicitly state where in the paper these should be located, they clearly point to these as key elements that are missing. The reviewer provides a general location (experimentally with other methods and significant discussion) but doesn't specify the exact section or subsection.", "verifiability_rationale": "The reviewer argues that the paper lacks experimental comparison with other methods and a discussion on the advantages and disadvantages of different dimensionality reduction techniques. This is a valid point about the lack of supporting evidence for the paper's choice of Shapely values. While the claim is valid, the paper doesn't currently provide the necessary justification or experimental validation for this choice.", "helpfulness_rationale": "The reviewer's concerns directly impact the usefulness of the paper. They express a desire for more comprehensive analysis, specifically regarding comparisons with other methods and the discussion of dimensionality reduction techniques. These are actionable suggestions that would significantly improve the paper's contribution and clarity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that Appendix A.2 does not illustrate the state space representation clearly. The action is to examine Appendix A.2 and ensure the representation is clear. The information needed to act is directly provided.", "grounding_specificity_rationale": "The comment explicitly mentions 'Appendix A.2' and 'state space representation', allowing the authors to precisely identify the section and the specific concept being criticized. The specificity is in pointing out the lack of clarity in the illustration.", "verifiability_rationale": "The comment contains a claim ('Appendix A.2 does not illustrate the state space representation of the environment clearly') that is not supported by evidence within this review point. The verifiability relies on the authors independently examining Appendix A.2.", "helpfulness_rationale": "The comment identifies a potential area for improvement (clarity of illustration) and suggests a way to improve it (making it clear). It provides a direction for the authors to take, even if it doesn't definitively prove the issue exists within this review point."}
{"actionability_label": "4", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a limitation of the authors' approach regarding the scale of the problems it can handle. While the reviewer identifies a limitation, the suggestion lacks specific actionable steps on how to improve the method for large problems. The language is general and doesn't provide concrete modifications or recommendations.", "grounding_specificity_rationale": "The reviewer states a limitation of the authors' approach but does not specify which part of the paper or method this limitation applies to. The comment is general and does not pinpoint a specific section, table, figure, or unique aspect of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the authors' approach for large problems. However, the claim lacks sufficient evidence or justification. The reasoning provided is general and does not reference external works or specific examples to support the claim.", "helpfulness_rationale": "The reviewer points out a limitation of the authors' approach, which is valuable feedback for the authors. However, the feedback lacks specific actionable steps or suggestions on how to address the identified limitation. The comment is more of a headsup about a potential scalability issue rather than a detailed solution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review points out a lack of clarity but doesn't tell the authors what to do or how to improve their draft based on this lack of clarity. It identifies a problem but doesn't provide a specific action.", "grounding_specificity_rationale": "The review point refers to 'characteristic function regularization' generally and doesn't specify which part of the paper it addresses. It also doesn't explain why this is a problem or what needs to be addressed in this part.", "verifiability_rationale": "The statement is an opinion about the clarity of the motivation, not a claim requiring verification or support.", "helpfulness_rationale": "The review identifies a weakness in the authors' draft \u2013 the lack of clarity in the motivation for using characteristic function regularization. This is likely to be helpful for the authors as it highlights an area that needs attention and further explanation. While it doesn't provide a solution, it identifies a problem."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the combination of existing techniques, which is an implicit suggestion for improvement. However, they don't specify how to combine them or what the specific problem is, making it 3 but lacking detail.", "grounding_specificity_rationale": "The reviewer mentions specific papers (Lykouris et al., 2018; Zhou et al., 2021) and the general areas of 'corruption,' 'weighted version of OFUL,' and 'variable decision sets.' While they *mention* these concepts, they don't explicitly point to a *specific section* or *unique aspect* of the paper being addressed. It's more of a highlevel observation about the techniques used rather than a specific identified weakness.", "verifiability_rationale": "The reviewer makes a statement about the combination being 'not surprising,' which is a claim. However, they don't provide any evidence or reasoning to support this claim, making it 1.", "helpfulness_rationale": "The reviewer identifies a potential issue with the approach, suggesting the combination might be redundant. However, they don't offer concrete, actionable advice on how to address this issue or improve the paper. They state it as an observation, not a claim that requires verification."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies the *problem* of writing issues but does not provide any specific steps or actions for the authors to take. It mentions 'grammatical errors' and 'abuses of mathematical symbols' as examples, which are symptoms rather than specific actions. The authors are not given concrete instructions on how to address these issues. The comment is explicit in stating the problem but lacks explicit and concrete actions on how to improve the draft.", "grounding_specificity_rationale": "The review point does not specify which part of the paper is experiencing writing issues. It broadly refers to the entire paper. The authors cannot confidently determine the exact location of the problem based on this comment alone. While the reviewer mentions 'grammatical errors' and 'abuses of mathematical symbols,' these are general categories and do not pinpoint a specific section, table, figure, or unique aspect of the paper. The grounding is weak because the authors cannot confidently identify the referenced part. The comment identifies what is wrong but not where it is located within the paper.", "verifiability_rationale": "The review point makes a claim about the paper's writing quality ('The paper contains severe writing issues such as grammatical errors, abuses of mathematical symbols, unclear sentences, etc.'). However, it does not provide any specific evidence or references to support this claim. There are no logical reasoning, common knowledge, or external references provided to back up the assertion of 'severe writing issues'. The claim is made without sufficient justification or examples. The reasoning is that the claim is stated but lacks supporting evidence or justification.", "helpfulness_rationale": "The review point identifies a significant problem with the paper ('the paper contains severe writing issues such as grammatical errors, abuses of mathematical symbols, unclear sentences, etc.'). However, it fails to offer any specific suggestions or actions for the authors to improve their draft. The comment points out the problem but does not provide any constructive feedback or guidance on how to address these issues. The authors are left without any actionable feedback to start with, making the review point unhelpful in improving their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point asks for clarification on specific aspects of the experimental setup, which can be interpreted as an implicit action for the authors: to understand the importance of the figures and potentially run experiments. However, the action is not explicitly stated, making it somewhat 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Fig 3c' and 'Fig 3' in the review point, indicating a clear reference to specific parts of the paper. The questions are also about 'untrained networks' and 'random data', suggesting an attempt to ground the feedback in specific elements. However, the reviewer does not explicitly state *which* part of the paper they are referring to (e.g., 'Section 4.2', 'Table 1'). The questions are more about clarifying the *meaning* of existing elements rather than directly pointing to a specific location. Therefore, it's weakly grounded but specific about the content.", "verifiability_rationale": "The reviewer is making a claim that the paper lacks certain information (experiments for untrained networks, details about random data) and provides a suggestion (to include them). This claim is 3 because the reviewer is pointing out a gap in the current presentation. However, the reviewer does not provide any external references or logical reasoning to support this claim beyond the absence of the information. Therefore, it's 3.", "helpfulness_rationale": "The reviewer is directly asking for clarification on crucial aspects of the experimental setup, specifically the results for untrained networks and the details of the random data used. This is 5 as it directly addresses potential weaknesses or ambiguities in the paper. The reviewer is essentially asking the authors to provide more context and justification for their claims. This information is essential for understanding the significance of the results and for the authors to potentially address limitations in their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the improvement is small (0.2%1%) and suggests repeating experiments and conducting statistical significance analysis. While the reviewer doesn't provide concrete steps on how to apply this feedback, the suggestion to repeat experiments and analyze results can be considered an implicit action. However, the lack of detail on *how* to conduct these experiments and analyze the results makes the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'previous methods,' 'Table 1,' 'Fig.5,' and 'statistical significance' when critiquing the results. While these are specific elements of the paper, the reviewer doesn't explicitly identify the *exact* section, table, or figure being addressed. The reviewer's claim that the results are '1 at all' because they don't identify a specific area is an overstatement, as they do point to specific parts of the paper. However, the reviewer doesn't specify *what* is wrong within those parts, making it not fully specific.", "verifiability_rationale": "The reviewer claims the results are '1' due to the lack of mean and standard deviation and the difficulty in determining statistical significance. While the reviewer *identifies* a lack of specific information (mean, standard deviation, statistical significance), they don't provide *examples* of where these are missing or *external references* to support this claim. The reasoning provided is logical, but the lack of concrete evidence makes it only partially verifiable.", "helpfulness_rationale": "The reviewer suggests repeating experiments and conducting statistical significance analysis as a way to improve the paper. This is a direct and actionable suggestion that, if implemented, could lead to a significant improvement in the paper's rigor and impact. While the reviewer's *evaluation* of the paper's potential rejection based on this suggestion is a consequence of the lack of statistical significance, the *suggestion itself* is a valuable piece of feedback that directly addresses the identified weaknesses. The reviewer's suggestion is clear and directly addresses the lack of statistical analysis."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the 'approach section' is missing. This directly points to an actionable improvement: the authors should add this section to the main paper. The action is clearly identified, making it concrete.", "grounding_specificity_rationale": "The reviewer explicitly names the missing section as 'approach'. This indicates strong grounding as the authors can directly identify the specific part of the paper where this information should be located. However, the reviewer does not specify *where* within this section the information should go (e.g., 'in subsection 3.1'), making it only 4.", "verifiability_rationale": "The reviewer is not making a claim about the approach section. They are pointing out its absence. There are no logical reasoning, common knowledge, or external references provided in this review point. Therefore, there is no verifiable information being presented.", "helpfulness_rationale": "The reviewer's comment highlights a structural issue in the paper \u2013 the absence of a dedicated 'approach' section. While not a critique of the content itself, this omission can make it difficult for the authors to understand the methodology and organization of their work. This is a valuable piece of feedback that, if addressed, could significantly improve the paper's clarity and accessibility."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the weakness in the introduction regarding the biological plausibility of backpropagation. They point to the specific sentence and suggest making the statement more nuanced. This indicates a direct action the authors should take.", "grounding_specificity_rationale": "The reviewer not only identifies the weakness but also specifies the exact section (introduction) and the claim within that section ('the biological plausibility of backpropagation...'). They also explain what is wrong ('may be too weak') and how it should be improved ('It is widely accepted that backpropagation is biologically implausible'). This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim about the introduction stating that the statement regarding the biological plausibility of backpropagation may be too weak. They then provide evidence for this claim by stating that 'It is widely accepted that backpropagation is biologically implausible.' This provides a clear justification for the comment.", "helpfulness_rationale": "The reviewer clearly identifies a specific issue in the introduction, provides a concrete suggestion for improvement, and backs up their claim with common knowledge about backpropagation's biological plausibility. This makes the comment 5 and informative."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'thoroughly explore the implications of their proposed method for other NLP tasks.' This clearly indicates what the authors should do.", "grounding_specificity_rationale": "The comment mentions 'other NLP tasks,' which is a specific area of the paper related to the proposed method. While it doesn't pinpoint a specific section or table, it clearly identifies the issue.", "verifiability_rationale": "The comment contains a claim: 'this somewhat limits the generalizability of the results.' The reviewer provides a logical explanation for this claim: 'this somewhat limits the generalizability of the results'.", "helpfulness_rationale": "The comment identifies a specific area for improvement ('implications of their proposed method for other NLP tasks') and highlights a limitation ('this somewhat limits the generalizability of the results'). This makes the feedback relevant and actionable, even if it doesn't offer a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a limitation of the experiments (toy data) and suggests a direction for improvement (real data). While it implicitly suggests the need for experiments on real data, it doesn't explicitly state the steps to take or how to implement this change. The suggestion is for future work rather than immediate action on the current draft. Therefore, it is not fully actionable.", "grounding_specificity_rationale": "The review point mentions 'toy data' and 'real data' generally. It does not specify which real datasets or problems are relevant or which aspects of the method or experiments need to be addressed in the context of real data. The grounding is weak as the authors cannot confidently determine the referenced part of the paper.", "verifiability_rationale": "The review point identifies a limitation of the experiments and suggests exploring real data. While it points out a potential area for future research, it doesn't provide a specific claim that requires verification. It's more of an observation and a suggestion for improvement rather than a statement that needs to be proven. Therefore, it doesn't have a claim that can be considered verifiable.", "helpfulness_rationale": "The review point identifies a limitation of the experiments (using toy data) and suggests exploring real data. While this is a valid point for improving the practical relevance and impact of the method, the review point itself doesn't offer specific, actionable steps for the current draft. It highlights a potential area for future work rather than providing immediate guidance for improvement. Therefore, it is not 5 for the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests 'more experiments' but does not specify how these experiments should be conducted. While it implies an action (conducting more research), the lack of concrete details makes it difficult for the authors to know exactly what steps to take. The action is stated but not explicitly detailed, falling short of providing a clear, actionable step.", "grounding_specificity_rationale": "The review point explicitly mentions 'deeper networks' and 'other network structures' and provides specific examples like 'ResNet50' and 'MobileNet'. This clearly identifies the specific aspect of the paper being addressed, demonstrating strong grounding. The reviewer is not making an educated guess but rather directly referring to specific types of network architectures.", "verifiability_rationale": "The review point contains a claim that 'more experiments on deeper networks... are needed'. This is a statement of a requirement or a suggestion for improvement. Furthermore, the reviewer provides references (1 MoBiNet, 2 Dynamic Channel Pruning, 3 Learning Dynamic Routing) to support the idea that exploring these network structures is relevant and beneficial. These references provide external evidence and justification for the suggestion, making the claim verifiable.", "helpfulness_rationale": "The review point directly suggests a valuable next step for the authors: conducting more experiments with specific network architectures. This is a clear and actionable direction that directly addresses a potential weakness in the paper's empirical validation. The inclusion of references further enhances the helpfulness by providing context and supporting evidence for the suggestion, making it a concrete and informed recommendation."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "2", "verifiability_label": "Partially Verifiable", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point is a statement of uncertainty, not a suggestion for action. Reviewers are expected to propose solutions, not just identify problems.", "grounding_specificity_rationale": "The review point refers to 'the proposed sample selection mechanism' and 'label distribution' without specifying which section or table of the paper these concepts relate to. This lack of specificity makes it difficult to pinpoint the exact issue.", "verifiability_rationale": "While the review point itself isn't a claim, it implies a lack of understanding in the authors, which could be seen as a missing justification for the authors to understand the mechanism. This suggests the reviewer's point is not fully supported by evidence within the paper.", "helpfulness_rationale": "The review point identifies a lack of clarity but does not provide specific suggestions or guidance on how the authors should improve their draft. It highlights a missing explanation rather than offering a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a limitation in the evaluation scope but does not directly suggest an action or improvement to the draft. It criticizes the limited selection of models without proposing specific changes to the paper itself.", "grounding_specificity_rationale": "The review point mentions the 'results/analysis' section, which grounds the comment to a specific part of the paper. However, it does not specify a particular issue or suggestion within that section, making it not fully specific.", "verifiability_rationale": "The review point makes a claim about the evaluation being limited to 'two relatively old and small models' but does not provide any evidence or justification for this statement within the review point itself. It presents the limitation as an observation without supporting reasoning or references.", "helpfulness_rationale": "The review point criticizes the limited scope of the evaluation but does not offer any concrete suggestions or improvements to the draft. It points out a weakness without providing actionable feedback or constructive solutions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the connection between Knowledge Distillation (KD) and Label Smoothing (LS) and provides specific conditions (uniformly distributed teacher network and temperature set to 1) that are relevant to the discussion. While the reviewer doesn't explicitly detail *how* KD becomes a special form of LS under these conditions, the connection is clearly presented. The conditions are also explicitly mentioned. Therefore, the reviewer provides an explicit statement and identifies the relevant aspects.", "grounding_specificity_rationale": "The reviewer mentions specific techniques (KD and LS) and even attempts to ground the connection in specific conditions (uniform distribution and temperature). This indicates a strong grounding. However, the reviewer doesn't explicitly state *what* makes KD a 'special form' of LS or provide examples of how the conditions lead to this conclusion. While the grounding is present, the specific details of the relationship are not fully elaborated.", "verifiability_rationale": "The reviewer presents a claim: 'KD can be viewed as a special form of LS.' This is a statement that requires justification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The conditions are mentioned, but their direct link to KD being a 'special form' of LS is not explained or supported. Therefore, the claim is presented without sufficient verification.", "helpfulness_rationale": "The reviewer's point is about understanding the relationship between two important techniques in machine learning. While potentially valuable for researchers familiar with these concepts, it's unlikely to be universally helpful for someone trying to understand *why* these techniques work or how to apply them. The connection is presented without a clear explanation of its practical implications or how it would help the authors improve their work. The reviewer's comment is more of a conceptual link rather than a concrete improvement suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that 'performance degrades' when adding information about missing/wrong/redundant data. This is a clear indication of an actionable observation. The reviewer also specifies the *type* of information being added, making the action even more concrete. Authors can directly identify the issue: the additional information is causing a performance drop. The request for explanation is a direct action to understand a phenomenon.", "grounding_specificity_rationale": "The reviewer refers to 'FBN results (table 5)' which is a specific part of the paper. This demonstrates strong grounding. Furthermore, the reviewer asks a specific question about the *reason* for the performance degradation in this specific table. This specificity is evident in the request itself.", "verifiability_rationale": "The reviewer presents a claim: 'performance degrades when using the additional information'. This is a claim that needs verification. However, the review point itself does not provide any evidence or reasoning to support this claim. The reviewer is asking for clarification, which is a request for information, not a statement that is inherently verifiable within the review point.", "helpfulness_rationale": "The reviewer's request is a direct question about a specific result (FBN results in table 5). While it doesn't provide a solution or a complete explanation, it points to a clear area of confusion and asks for clarification. This is a helpful point because it prompts the authors to investigate further and understand the impact of the added information. It's 4 because it identifies a problem and asks for an explanation, rather than providing a direct solution."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing analysis of the noiseinjected models' loss landscapes and provides a clear action for the authors to take: 'To claim that the minima found by minimizing the loss in Eq (3), the analysis on the losses of the noiseinjected models after training is required.' This is a direct and actionable suggestion.", "grounding_specificity_rationale": "The reviewer mentions 'noiseinjected models' and 'loss landscapes,' which are specific parts of the paper. They also imply that the analysis should be done on the loss function used in the context of noiseinjected models (referencing Eq 3), making the grounding quite explicit.", "verifiability_rationale": "The reviewer makes a claim about the relationship between minimizing the averaged loss and finding flat minima. While they don't provide a direct proof within the review point, their argument is based on logical reasoning and common knowledge in optimization. They identify a potential gap in the analysis.", "helpfulness_rationale": "The reviewer provides a very specific and actionable suggestion for the authors: 'To claim that the minima found by minimizing the loss in Eq (3), the analysis on the losses of the noiseinjected models after training is required.' This directly addresses the identified weakness and empowers the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a problem with the text size in the figure and labels. While the issue is clear, the review doesn't specify how to address this. The action is implicitly stated (improve readability), but the implementation is missing. This falls under '2' as the action is implied but not explicitly stated or actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the text inside the figure and the labels' as the part with the issue. This is a clear and specific identification of the problematic element. The grounding is strong as the section is directly referenced. This falls under '5' as the part being addressed is accurately pinpointed, and the issue within that part is clearly defined.", "verifiability_rationale": "The reviewer states that the text is 'too small to read without zooming' and that it should be 'roughly the same size as the manuscript text.' This statement is a claim that needs to be supported. However, the review does not provide any evidence, reasoning, or references to justify why this specific text size is an issue or how it differs from the manuscript text. There are no external references or logical explanations provided to back up this claim. This falls under '1' as the claim is made without sufficient support or justification.", "helpfulness_rationale": "The reviewer points out a clear visual issue: the text in the figure and labels being too small. This is a relevant and actionable feedback for the authors, as it directly impacts their ability to understand and interpret the figure. However, the review stops at identifying the problem. It doesn't offer any suggestions or actions on how to resolve this issue. While the feedback is relevant, the lack of proposed solutions limits its helpfulness. This falls under '3' as the feedback identifies a meaningful weakness, but it lacks concrete suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point talks about the *position* of features being different for different categories. While it points to a *difference*, it doesn't explicitly state *what* needs to be changed or *how* the positions should be altered. It's more of an observation than a direct instruction.", "grounding_specificity_rationale": "The review point doesn't explicitly mention *which* features or categories are being referred to. It's a general statement about the *position*.", "verifiability_rationale": "The review point is a statement of observation, not a claim requiring verification.", "helpfulness_rationale": "The review point points out a potential issue with prompt design (different positions for different categories). This could be helpful for the authors if they are using multiple local prompts."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests replacing some of the natural language description with notation and adding breakout diagrams showing the attention mechanisms. These are explicit actions the authors can directly identify and implement. While the level of detail could be higher, the core actions are clear.", "grounding_specificity_rationale": "The reviewer refers to 'section 4' and 'attention mechanisms' within that section. While they don't specify the exact subsection, they clearly identify the part of the paper being addressed, making it grounded. However, the suggestion is quite general and doesn't specify *how much* natural language to replace or *how many* diagrams to add, making it underspecific.", "verifiability_rationale": "The reviewer's comment focuses on suggestions for improvement rather than stating a claim that needs verification. They suggest 'replacing some of the natural language description with notation' and 'adding breakout diagrams showing the attention mechanisms'. These are recommendations, not statements that require logical reasoning, common knowledge, or external references to be considered valid. The reviewer is offering potential improvements, not making a claim that needs to be proven.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, including concrete actions like replacing natural language with notation and adding diagrams. These suggestions are directly actionable and likely to be beneficial for the authors. The reviewer is not presenting a claim that needs verification, but rather offering concrete improvements to the model's presentation."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a limitation in the method's generalizability due to limited training data. While it points out a potential issue, it doesn't directly tell the author *what* to change or *how* to address it. It's a statement of concern rather than a directive.", "grounding_specificity_rationale": "The reviewer mentions \"this method\" and \"these samples.\" While not a direct section reference, it points to a specific area of the paper. The issues raised, \"limited number of molecules\" and \"indistribution testing for these samples,\" are specific within that referenced part.", "verifiability_rationale": "The review states a limitation: \"I think the value of this method would be limited if it needs to train for each molecule individually.\" This is a claim. The reviewer provides a justification: \"This paper only does experiments on a very limited number of molecules and only provides indistribution testing for these samples.\" This justification, while not a citation, provides a logical reason for the concern.", "helpfulness_rationale": "The feedback is relevant to the method's limitations but doesn't offer a clear path for improvement. It highlights a potential area where the method might struggle. While it's a valid concern, it doesn't directly instruct the author on how to fix the issue."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that 'symbols are a little bit complicated' and 'takes a lot of time to understand'. This indicates an implicit action: the reviewer desires the symbols to be easier to understand. While the action is not stated directly, the implication is clear. The action is also concrete as the reviewer suggests making the symbols 'easier to understand'.", "grounding_specificity_rationale": "The reviewer refers to 'symbols' generally. While they imply these symbols are from the paper, they do not specify which symbols or what aspects of the symbols are unclear. The reviewer's statement is a general observation about the symbols, lacking specific details. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim: 'symbols are a little bit complicated'. However, they do not provide any evidence or justification for this claim. There is no logical reasoning, common knowledge, or external references provided to support the statement that the symbols are complicated. Therefore, the claim is 1.", "helpfulness_rationale": "The reviewer's comment is a critique of the paper's clarity, specifically mentioning the complexity of the symbols. While this points to a potential issue that could hinder understanding, the review itself does not directly offer specific, actionable improvements or solutions related to the symbols. It's a negative comment about the paper's clarity, but it doesn't actively propose how to improve it. Therefore, the review is 3 in identifying a problem but less helpful in providing direct solutions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states they 'don't understand' the red line, indicating a need for an action (explanation). However, the explanation itself is missing, making it difficult to determine the exact nature of the issue. Therefore, it is implicitly stated but vague.", "grounding_specificity_rationale": "The reviewer asks 'Where does the test data come from?' and 'Do you have a ground truth?' These questions directly identify the specific part of the paper (Figure 3) and the specific issue (the need for a ground truth), demonstrating strong grounding specificity.", "verifiability_rationale": "The reviewer is making a request for clarification (an explanation), which can be considered a claim requiring justification. However, the justification (the explanation) is missing at the time of the review point. Therefore, it is not yet verifiable until the explanation is provided.", "helpfulness_rationale": "The reviewer explicitly asks for help in understanding the red line, indicating a request for improvement. While the request itself is helpful, the lack of a clear explanation at the time of the review point makes it only marginally helpful."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about the comparison between periodicity and compositionality, indicating an implicit action. While the core concept of model ability is abstract, the question is quite specific about the comparison between two models and a specific method of testing. Therefore, it is 3 but not entirely concrete.", "grounding_specificity_rationale": "The reviewer clearly identifies the issue being discussed (the extent to which periodicity explains the results compared to compositionality) and explicitly mentions the models being compared (a model that cannot capture periodicity and an explicitly compositional model). They also suggest a method for testing (adding periodicity to the spectral kernel). This indicates that the reviewer can confidently identify the specific part of the paper and the issue being addressed, making it 5.", "verifiability_rationale": "The reviewer is asking a question and seeking clarification. While there isn't a direct claim being made, the underlying intent is to understand the extent to which periodicity explains the results, which can be considered a form of inquiry that could be verified through further analysis or experimentation. The suggestion to add periodicity to the spectral kernel provides a basis for verification. Therefore, it is 3.", "helpfulness_rationale": "The reviewer's question directly addresses a relevant aspect of the models and seeks clarification, making it 5 for understanding the models' capabilities and the role of periodicity. The request for comparison is also a valuable piece of information for understanding the relative strengths of the two models. Therefore, the review is 5."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two specific areas for improvement but lacks explicit instructions on how to address them. While the suggestions are present, the absence of concrete steps or modifications makes it less actionable compared to a review that explicitly states 'change this section' or 'add this analysis'.", "grounding_specificity_rationale": "The review point explicitly mentions 'Table 6' and 'Table 1' and focuses on the discrepancy regarding 'MCTpair'. This demonstrates a clear identification of the specific part of the paper being addressed, making it grounded. The reviewer also suggests 'ablation studies of MCT without the adaptive metrics', which directly points to a specific component, further enhancing grounding.", "verifiability_rationale": "The review point identifies a discrepancy between two tables and suggests an ablation study. While it points to the *what* (discrepancy, ablation study), it doesn't provide sufficient justification or evidence to verify the existence of the discrepancy or the expected outcome of the ablation study. The reasoning is implied but not explicitly stated, and the external references are missing. Therefore, while it suggests something, the lack of verifiable support makes it less verifiable than a review with explicit reasoning and references.", "helpfulness_rationale": "The review point identifies potential weaknesses in the author's work (discrepancy in results, lack of ablation studies) and suggests experiments to address them. While the suggestions are relevant and point towards potential improvements, they are at a high level and lack specific details on how to implement the ablation study or what specific changes should be made to the MCTpair analysis. The reviewer doesn't provide concrete, actionable steps beyond suggesting experiments. Therefore, it is helpful in guiding the author towards further investigation but lacks the detailed guidance needed for complete actionable improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests 'More discussions are required here' as an improvement. While this is a suggestion for change, it doesn't explicitly state what needs to be discussed or how the authors should approach it. The reviewer implies an action (engaging in more discussion) but lacks specific details on *how* to do this. Therefore, it's 2.", "grounding_specificity_rationale": "The reviewer mentions 'the 10 subtasks' and 'bAbi' when stating that the subtasks are 'rather simplistic for bAbi'. This demonstrates some level of grounding as the reviewer refers to specific elements of the paper (the subtasks and the model). However, the reviewer doesn't specify *which* of the 10 subtasks are simplistic or provide a clear definition of what constitutes 'simplicity' in this context. Therefore, it's 2.", "verifiability_rationale": "The reviewer makes a claim: 'The 10 subtasks are rather simplistic for bAbi.' This claim is presented without explicit logical reasoning, common knowledge, or external references to support it within the review point itself. While the reviewer states the claim, they don't provide evidence *within this review* to back it up. Therefore, it's 1 within the context of this specific review point.", "helpfulness_rationale": "The reviewer suggests 'More discussions are required here' as a way to improve the subtasks. This is a clear and actionable suggestion that directly addresses a potential weakness. The reviewer identifies a problem ('simplistic subtasks') and proposes a concrete solution ('more discussions'). This is a helpful comment for the authors as it directly points to an area for improvement and provides a direction for action. Therefore, it's 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question about the limitations of the triplet approach, indicating a clear and direct action. They are asking whether this limitation is fundamental or if there's a way to extend it to longer subsequences. This shows a clear intention to understand and potentially address a specific issue related to the method.", "grounding_specificity_rationale": "The reviewer does not explicitly state which part of the paper or method the triplet approach refers to. While the concept of a sliding window is mentioned, the specific implementation or application of this approach within the context of the paper is not clearly identified. Therefore, the grounding is weak. The reviewer also does not specify what is wrong with the triplet approach, making the specificity low.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are posing a question about the limitations of the triplet approach. There is no assertion that something is wrong, needs justification, or requires external references. Therefore, there is no verifiability to assess.", "helpfulness_rationale": "The reviewer's question directly addresses a potential limitation of the method (the triplet approach). By asking whether this limitation is fundamental or if it can be extended, they are prompting the authors to consider a relevant issue. This question has the potential to guide the authors in choosing appropriate methods and understanding the scope of their analysis. While it doesn't propose a solution, it encourages a deeper reflection on the method's limitations, which can be helpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment asks a question ('What is a 'sqeuence of episodes\" here?') and points to a potential gap in the explanation (\"Missing related work...\"). While it identifies a potential area for clarification, it doesn't explicitly state an action the authors should take. The lack of a direct instruction makes it less actionable.", "grounding_specificity_rationale": "The comment refers to \"practice and evaluation\" as the \"two types of this kind of sequence\" and asks for \"related work\". It doesn't explicitly state which part the comment addresses. The authors cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part (clarification and related work).", "verifiability_rationale": "The comment is a question and a request for information, not a declarative statement containing a claim that needs verification. The purpose is to help the authors improve their draft, not to make a claim about it.", "helpfulness_rationale": "The comment raises a valid point about clarity and completeness (\"What is a 'sqeuence of episodes\" here?\" and \"Missing related work...\"), but it doesn't directly instruct the authors on how to fix these issues. The request for clarification and related work is helpful but lacks concrete steps."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their disagreement with the label 'ablation study' regarding the study of different subdomain sizes. They provide a clear explanation of why they believe it's not an ablation study, identifying the key difference as the study of parameters rather than the removal of components. This makes the action clear: 'The study is likely not an ablation study.'", "grounding_specificity_rationale": "The reviewer's statement about the study not being an 'ablation' study does not directly address or ground a specific part of the paper or method. They are making a general critique about the nature of the study. Therefore, the grounding is weak as the reviewer cannot confidently identify which part of the paper they are referring to.", "verifiability_rationale": "The reviewer's statement about the study not being an 'ablation' study is a claim that can be verified by understanding the definition of an ablation study. An ablation study typically involves removing or disabling a component of a system to observe its effect. The reviewer argues that changing subdomain sizes is a parameter study, not a component removal. While the reasoning could be more detailed, the claim is verifiable based on the definitions. Therefore, the claim is verifiable, but the reviewer does not provide specific evidence or references to support their claim.", "helpfulness_rationale": "The reviewer's point about the study not being an 'ablation' study is a helpful clarification for the authors. It provides a specific piece of information that can help them understand the nature of the study and potentially adjust their expectations or approaches. While the information itself might not directly point to a specific weakness, it is still valuable information."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a limitation of the new metric, which is that it's only tested on a single dataset. While the reviewer points out this issue, they don't explicitly state how this limitation should be addressed or what actions the authors should take. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the new proposed metric' and 'only tested on a single dataset'. This clearly identifies the specific aspect of the paper being referred to, indicating strong grounding. The language is precise and directly targets the mentioned elements.", "verifiability_rationale": "The reviewer makes a claim about the metric's testing. While the verifiability of this claim isn't explicitly detailed in the review point itself (e.g., providing evidence of the single dataset), the claim itself is clear and could potentially be supported by evidence. The reviewer states a fact that could be verified.", "helpfulness_rationale": "The reviewer points out a potential issue with the metric's evaluation scope. This is a reasonable concern for authors and could guide them in understanding the metric's limitations. While it doesn't offer a solution, it highlights a relevant aspect for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states actions the authors should take: 'should be defined' for the abbreviation 'NE' on L73 and 'explain the superscript notation' in Eq 6. These are direct and actionable suggestions. The reviewer also suggests adding a list of citations, which, while not an action, implies a specific area of improvement related to the content of the paper.", "grounding_specificity_rationale": "The review point explicitly refers to specific parts of the paper: 'L73' and 'Eq 6'. These are literal mentions, indicating strong grounding. The reviewer also suggests defining 'NE' and explaining the superscript notation, which are specific actions related to the content of L73 and Eq 6, respectively.", "verifiability_rationale": "The review point contains claims that the authors should take specific actions: define 'NE' and explain the superscript notation. While the reviewer doesn't provide explicit references or examples *at the moment of writing the review*, the *act* of defining abbreviations and explaining notation is a logical next step if one were to address the criticism of undefined terms and unclear notation. The reviewer's suggestion to add citations is a suggestion for improvement, not a direct criticism of a specific part of the paper being discussed at that moment.", "helpfulness_rationale": "The review point is clear, identifies specific issues, and provides actionable suggestions. The reviewer directly points out the lack of definition for 'NE' and the undefined superscript notation, which are concrete problems. The suggestion to define 'NE' and explain the notation is a logical and specific next step for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point does not contain an explicit or implicit action or suggestion. It is a statement about the quality of the evaluation and the baselines, not a direct instruction on how to improve the draft.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper being discussed. It is a general statement about the evaluation and baselines.", "verifiability_rationale": "The review point contains a claim (i.e., the statement that the evaluation is weak and the baselines are inappropriate). However, it does not provide any specific evidence or justification for these claims. The reasoning is vague and general.", "helpfulness_rationale": "The review point is not helpful because it does not provide any actionable feedback or suggestions. It criticizes the evaluation and baselines without offering concrete improvements or justifications."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action of 'spelling out the setting' as a way to improve clarity. This action is concrete as it specifies exactly what needs to be done. The reviewer also provides a specific example of where this clarification should occur (first three paragraphs of section 2). Therefore, the action is welldefined and actionable for the authors.", "grounding_specificity_rationale": "The reviewer identifies the specific part of the paper being addressed as the 'first three paragraphs of section 2'. This is a clear and precise identification, indicating strong grounding. The reviewer also specifies the issue as being the 'setting', which further enhances the specificity of the feedback.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement rather than a statement of fact or opinion. There is X being made, so it falls under the 'X' category (X).", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for improvement: 'spelling out the setting' in the specified location. This directly addresses a potential point of confusion and is a concrete action the authors can take. Therefore, the suggestion is 5."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides explicit suggestions for improvement by suggesting the use of more modern 3D CNNs like X3D and SlowFast and asking for a comparison of advantages. However, the reviewer does not provide concrete details on how to implement these suggestions, such as specific experimental setups or metrics to evaluate the performance. The suggestions are general and lack actionable steps.", "grounding_specificity_rationale": "The reviewer explicitly mentions the limitations of the chosen baselines (R3D and C3D) and suggests comparing the proposed method with more recent 3D CNNs (X3D, SlowFast). This clearly identifies the specific aspect of the paper being addressed, demonstrating strong grounding. The reviewer also asks for a comparison of advantages, further specifying the nature of the improvement.", "verifiability_rationale": "The reviewer makes a claim that the experiments are 'not quite convincing' and that using older baselines is a limitation. They also suggest testing the method with newer 3D CNNs as a potential solution. While the reviewer identifies a potential issue and suggests a possible improvement, the claim that the experiments are 'not quite convincing' is not fully supported by evidence within the review point itself. There is no concrete data or logical reasoning provided to definitively prove the limitations of the baselines or the advantages of the newer models.", "helpfulness_rationale": "The reviewer raises a valid concern about the choice of baselines and suggests a relevant direction for future experiments by proposing the use of more modern 3D CNNs. The questions posed are clear and directly related to the methodology. While the reviewer doesn't provide a definitive solution or proof, the suggestions are concrete and actionable, providing a clear direction for the authors to consider. The reviewer's point is directly relevant to the work and offers a practical improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer is directly asking for specific information about the implementation details of the attention module within the ResNet20 architecture. They are asking for the number of attention modules, their placement (after each block or stage), and the overall organizational structure. This is an explicit request for action, making it 5 as the authors can directly use this information to understand and potentially replicate the architecture.", "grounding_specificity_rationale": "The reviewer is asking for specific details about where the attention module is located within the ResNet20 architecture. They are asking about the number of modules and their placement (after each block or stage). The comment explicitly refers to 'sections' of the paper (the ResNet20 architecture) and asks for details about a specific element ('attention module') within that section. This is fully grounded as the authors can directly identify the referenced part and the specific issue (the location of the attention module).", "verifiability_rationale": "The reviewer is making a claim about the lack of specific details regarding the attachment of the attention module to the ResNet20 architecture. They are stating that the paper does not provide information about the number of modules, their placement, and the organizational structure. This claim is fully supported by logical reasoning (the absence of this information in the paper) and common knowledge about architectural details. External references are not needed to understand the missing information.", "helpfulness_rationale": "The reviewer is directly asking for clarification on a crucial implementation detail of the attention module's integration into the ResNet20 architecture. This is a clear indication that the authors are struggling with this aspect and would benefit from more specific information. While the review point doesn't directly provide a solution, it points to a specific area needing explanation, making it 5 in guiding the authors to understand the architecture."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states an action: 'What is the precise bitrate range used for BDrate comparison?' However, it does not provide concrete steps or guidance on how to determine this range. The action is implied but not explicitly stated in terms of how to identify the relevant information.", "grounding_specificity_rationale": "The comment explicitly mentions 'high bitrate' and 'low bitrate' without specifying the exact ranges. This is weak grounding as the authors cannot confidently determine the referenced part. However, the comment does specify what needs to be addressed: the bitrate range for BDrate comparison.", "verifiability_rationale": "The comment contains a claim: 'The proposed method looks stronger at high bitrate but close to the baselines at low bitrate.' However, this claim is not supported by any logical reasoning, common knowledge, or external references within the review point itself. The 'how' is missing.", "helpfulness_rationale": "The comment points out a performance difference between the proposed method and baselines at different bitrate ranges. While this highlights a potential area for improvement, it does not directly suggest concrete steps or comparisons with the suggested related work. The feedback is present but lacks actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The review suggests a *distinction* between two concepts. While it points to a potential area for clarification, it doesn't directly instruct the authors on *what to do*. Therefore, it's not fully actionable. The suggestion to 'distinguish' is an implicit action. The authors aren't told *how* to perform this distinction.", "grounding_specificity_rationale": "The review *mentions* the 'allornothing or cutoff phenomenon' and 'machine learning and NeurIPS community.' This provides a *unique element* of the paper being referenced. It also implies a *need for clarification* regarding this element. The reviewer names specific concepts within the paper, making the grounding strong. The explanation of *why* this distinction is important (familiarity with statistical bounds in the ML community) adds some specificity and context.", "verifiability_rationale": "The review makes a claim about the distinction between the 'allornothing or cutoff phenomenon' and 'usual statistical bounds.' The reviewer explains *why* they think this distinction is important, linking it to the familiarity with statistical bounds in the ML community. This provides a basis for verification, even if it's not a direct citation. The logical reasoning is present.", "helpfulness_rationale": "The review points out a potential area for improvement in the paper's clarity and context. While it doesn't provide a direct stepbystep solution, it identifies a specific area where the authors might be lacking knowledge or where the writing could be improved. This is helpful in guiding the authors to consider the relationship between different statistical concepts. The reviewer's suggestion is not about a specific fix, but about a potential gap in understanding or a need for clearer explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'marginal' improvements and suggests 'further analysis'. This indicates a clear action: to point out the lack of significant improvement and suggest a need for more investigation. While 'marginal' is somewhat vague, the intention is clear.", "grounding_specificity_rationale": "The comment does not specify which three tasks, previous works, or selfimplemented baselines are being referred to. It also does not detail what aspects of these are causing the marginal improvements. The reference is general and lacks specific identification of the parts of the work being discussed.", "verifiability_rationale": "The comment contains a claim ('The improvements on three tasks over the previous works and selfimplemented baselines are marginal') but does not provide any evidence, reasoning, or references to support this claim. It lacks logical reasoning, common knowledge, or external references to back up the assertion.", "helpfulness_rationale": "The comment provides feedback on the marginal improvements but lacks specific guidance on how to achieve better results. The suggestion to 'do further analysis' is a general direction and does not offer concrete steps or insights for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "N/A", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states the issue: 'All the linear convergence rates rely on Theorem 8'. This is an explicit action the authors should take. However, the comment does not provide any guidance on how to address this issue or what steps to take next. The action is identified, but the implementation is left ambiguous.", "grounding_specificity_rationale": "The comment does not specify *where* in the appendix Theorem 8 is located. It only mentions 'Theorem 8' generally. Therefore, the grounding is weak as the authors cannot precisely identify the referenced part. The comment also does not specify what is unclear about the proof. The grounding is weak because the specific part is not identified, and the nature of the issue is not detailed.", "verifiability_rationale": "The comment does not contain a claim. It is a statement of concern about the theorem and its proof. Therefore, the concept of verifiability does not apply as there is no assertion to be verified or supported. The comment is a statement of concern, not a claim requiring evidence.", "helpfulness_rationale": "The comment identifies a potential issue (reliance on a potentially unclear theorem) but does not provide any actionable steps or suggestions for the authors to address this. The helpfulness is limited as the authors are left to navigate this potential problem on their own. The comment is a statement of concern, not a helpful suggestion or guidance."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The reviewer's comment is a suggestion for improvement rather than a direct instruction on what the authors should do. It recommends changing the presentation of results in Tables 1 and 2 by performing hyperparameter search and model selection on the test set. This is a recommendation, not an actionable instruction.", "grounding_specificity_rationale": "The reviewer mentions 'Tables 1 and 2', 'dev set', 'best results', 'hyperparameter search', 'model selection', and 'test set'. While they identify the location of the issue (tables and sets), they don't specify *which* results in *which* table are problematic or *how* the hyperparameter search was conducted. The grounding is weak because the specific element being addressed isn't clearly identified.", "verifiability_rationale": "The reviewer's comment is a suggestion for a different experimental setup and result presentation. It doesn't contain a claim that something is wrong with the current approach. Therefore, it doesn't have verifiable content.", "helpfulness_rationale": "The reviewer's comment provides a direction for the authors to improve their work by suggesting experiments on the test set with averaging and error bars. This is a helpful suggestion that points towards a valid way to strengthen the evaluation. However, it lacks specific details on *how* to perform these experiments."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The paper mentions 'topicword parameters' but doesn't explicitly state how these were obtained. While the paper states 'We use a topicword model to generate synthetic data' and mentions the dataset size and vocabulary size, it lacks detail on the parameter estimation process. This makes the information somewhat implicit and requires the reader to infer the methodology, impacting actionability.", "grounding_specificity_rationale": "The paper mentions the AG News dataset and its size (100,000 news articles). However, it doesn't explicitly state how the unique elements of the paper were identified for this dataset. The paper mentions 'a vocabulary of 10,000 tokens' but doesn't detail how this vocabulary was derived. This makes the grounding somewhat weak as the authors need to infer the specific elements being addressed.", "verifiability_rationale": "The paper states 'We use a topicword model to generate synthetic data' and mentions the dataset size and vocabulary size. However, it doesn't provide a clear justification or explanation of how the 'topicword parameters' were obtained. This makes the claim somewhat underjustified and requires the reader to infer the methodology, impacting verifiability.", "helpfulness_rationale": "The review point raises valid questions about the methodology, specifically how the topicword parameters were obtained and the train/test split size. While the paper mentions the dataset size and vocabulary size, it lacks detail on the parameter estimation process. This makes the review point 3 in identifying a missing piece of information but lacking in detail to be fully helpful for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"ignores some other NAS (e.g. supernet/oneshot approaches, etc...)\" and names specific examples, making it 4. Once the action is identified (comparing against supernet/oneshot approaches), the authors know exactly what needs to be done and how to apply the action by looking at the performance of these alternative NAS methods and identifying the strengths and weaknesses compared to the proposed method. The authors can then consider incorporating these approaches into their analysis to provide a more comprehensive evaluation of their proposed method.", "grounding_specificity_rationale": "The reviewer does not explicitly state which part of the paper is being addressed (e.g., methodology, experimental setup, results discussion). The comment is more of a general statement about the analysis of BRPNAS. However, when the reviewer suggests \"includes comparisons against supernet/oneshot approaches\", it can be considered somewhat specific as it refers to a type of NAS method. The grounding is present in the suggestion itself, but the initial statement lacks a clear reference point within the paper. Therefore, it can be considered 3.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the comparisons by stating \"only compares against 3 basic alternatives and ignores some other NAS (e.g. supernet/oneshot approaches, etc...)\". However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. They are simply stating a fact about the current analysis. There is no evidence or justification provided to back up the assertion that only basic alternatives were used and other NAS approaches were ignored. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer's comment directly points out a potential area for improvement in the analysis of BRPNAS by suggesting \"includes comparisons against supernet/oneshot approaches\". This is a clear and actionable suggestion that directly addresses the identified limitation. Authors can understand the suggestion and take concrete actions to improve their draft by conducting experiments to compare the performance of their method against supernet and oneshot approaches. This provides a clear direction for future work and enhances the overall quality of the paper. Therefore, the comment is 5 as it directly suggests a concrete next step for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3: Somewhat Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests focusing on the main contribution of the paper, but this is presented as a general suggestion rather than a specific action or improvement to be implemented. The reviewer doesn't explicitly state what the authors should do with the zeroshot and density estimation sections, making it difficult to pinpoint a concrete action. The suggestion is more of a highlevel comment about the paper's focus rather than a actionable item for the authors.", "grounding_specificity_rationale": "The reviewer mentions the 'zeroshot version' and 'density estimation' as potential distractions. This indicates a weak grounding as the authors cannot confidently determine which part the comment addresses. However, the reviewer does specify what they are referring to as distracting, suggesting some level of specificity in identifying the potential issue.", "verifiability_rationale": "The reviewer claims that the zeroshot version and connection to density estimation are distracting to the main point of the paper. This claim is presented as an opinion ('I find...') without any logical reasoning, common knowledge, or external references to support this assertion. There is no clear justification provided for why these elements are considered distracting.", "helpfulness_rationale": "The reviewer offers a suggestion to focus on the main contribution of the paper. While this is a reasonable suggestion, it is presented as a general direction rather than a highly specific and actionable feedback. The reviewer does not provide concrete examples of how the authors should improve their draft based on this suggestion. The feedback is more of a highlevel comment about the paper's focus rather than a detailed guide for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of attacks with different strength and the lack of analysis on how different thresholds influence detection performance. These are clear omissions that directly impact the experimental setup and results. The reviewer directly points out what is missing, making the action clear and actionable.", "grounding_specificity_rationale": "The review point mentions 'attacks with different strength' and 'influence of different thresholds on detection performance,' which are general concepts. However, it does not specify which section, table, or unique element of the paper these attacks or thresholds relate to. The reviewer also doesn't detail how the thresholds influence the performance. While the concept is mentioned, the specific grounding and details are lacking, making it somewhat grounded but not fully specific.", "verifiability_rationale": "The review point states that the experiment results lack certain elements and that the influence of thresholds is not analyzed. This is a clear statement of a problem, but it lacks logical reasoning, examples, or external references to support why these issues exist or how they should be addressed. The criticism is primarily a suggestion for improvement rather than a claim requiring verification. The reviewer doesn't provide any evidence or justification for their claims, making it 1.", "helpfulness_rationale": "The review point identifies specific areas for improvement in the experimental design and analysis. It points out missing elements and suggests a way to enhance the detection performance analysis. This is a constructive criticism that directly suggests actionable steps for the authors. The feedback is clear and directly addresses potential weaknesses, making it 5 for the authors to refine their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the *purpose* of training a discriminator and the *context* (Figure 1) for its use. The request is also quite direct: 'For evaluation, since the claim of this paper is to reduce exposure bias, training a discriminator on generations from the learned model is needed to confirm if it is the case, in a way similar to Figure 1.' This indicates a clear action to be taken. However, the reviewer does not specify *how* this discriminator training would be implemented or what specific metrics would be used to assess the discriminator's performance. The concern about coadaptation, while valid, is presented as a potential issue rather than a fully specified action with implementation details.", "grounding_specificity_rationale": "The reviewer mentions 'generations from the learned model' and 'Figure 1' in relation to the discriminator training. While not a perfect literal mention of a specific section or table, these phrases clearly indicate the *source* of the data and the *context* of the evaluation. The reviewer also explicitly states the *claim* of the paper is to 'reduce exposure bias,' which further grounds the suggestion. The suggestion is specific to the model's behavior and the evaluation method described in relation to Figure 1.", "verifiability_rationale": "The reviewer *claims* that training a discriminator in this specific way will 'confirm if it is the case reduce exposure bias in a way similar to Figure 1.' However, the reviewer does not provide any specific examples, references, or logical reasoning to *justify* why this training will specifically confirm the claim of reducing exposure bias. While the context is provided, the *how* and the *why* of this specific approach being effective in confirming the claim are not clearly explained or supported. The concern about coadaptation is presented as a potential issue, but it's not presented as a wellsupported claim.", "helpfulness_rationale": "The reviewer suggests a specific experimental setup involving training a discriminator to evaluate the model's ability to reduce exposure bias. While this is a concrete suggestion, the reviewer does not provide any justification for *why* this is a particularly effective or relevant way to validate the paper's claim. The suggestion lacks context or explanation of its potential benefits or limitations in the specific context of the paper. Without a clear rationale, the suggestion feels somewhat arbitrary."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point asks a question about the impact of specific experimental choices but does not explicitly state what the authors should do or how to investigate this further. The question is framed as a request for information rather than a direct instruction. Therefore, while the reviewer points to a relevant area, the authors are not given a clear path to address it. The action is implied but not explicitly stated, and the concreteness is lacking as the authors would need to conduct further experiments or literature review themselves.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'L170' in the paper, which clearly identifies a specific part of the document. This demonstrates strong grounding as the reviewer is pointing to a unique and identifiable section. The specificity is also relevant as the question is about the impact of these specific experimental choices on the performance difference.", "verifiability_rationale": "The review point does not contain a claim in the sense of recommending a change or stating an opinion. It is a question seeking information about the impact of specific experimental choices. Since there is X being made, the verifiability aspect is not applicable.", "helpfulness_rationale": "The review point raises a relevant question about the experimental setup and its impact on performance. This information is valuable for the authors to understand the limitations and potential areas for improvement of their work. While the review point doesn't directly guide the authors to a solution, it points to a gap in their understanding of the experimental details and their potential impact. It is not completely useless, as it highlights an area where further investigation or clarification might be needed. Therefore, it is 4 in that it prompts further analysis and consideration of the experimental choices."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'it would have been interesting to see a runtime comparison at test time.' This action is concrete, as it tells the authors exactly what to do and how to implement it.", "grounding_specificity_rationale": "The review point refers to the paper's mention of Chebyshev polynomials. While it doesn't explicitly name a section or table, the context strongly implies it's referring to the previously discussed method involving Chebyshev polynomials. The reviewer has a reasonable understanding of the paper's content. The suggestion is specific to a 'runtime comparison' at the 'test time', clearly identifying the area within the experimental evaluation that needs improvement.", "verifiability_rationale": "The review point contains a suggestion ('it would have been interesting to see...') which implies a desire for a specific type of analysis. This can be considered a request or implied improvement, which fits within the definition of a claim in this context. It's not a direct criticism of a flaw, but it indicates a desired improvement. The suggestion is actionable and directly relates to a standard evaluation practice in the field (runtime analysis). While it doesn't provide *new* information, it points to a *lack* of a standard analysis, which can be verified by the authors.", "helpfulness_rationale": "The review point is 5. It directly suggests a specific and useful improvement: a runtime comparison is a standard and informative evaluation step. It encourages the authors to adopt a best practice. The suggestion is actionable and provides a clear direction for the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the proposed method 'seems only works for digit or text images' and provides examples like MNIST and SVHN. This is an explicit statement of what the method cannot do. The reviewer does not provide any implicit information that would suggest a different interpretation. The action of identifying a limitation is clear and direct.", "grounding_specificity_rationale": "The reviewer's comment does not identify a specific part of the paper (e.g., a section, table, or figure) where the method seems to have limitations. They are making a general statement about the applicability of the method to different types of images. Therefore, the grounding of this comment is weak. The comment does specify what the method seems to be limited to (digit or text images), but without pointing to a specific part of the paper, it lacks the precision of full grounding.", "verifiability_rationale": "The reviewer makes a claim: 'The proposed method seems only works for digit or text images...'. This is a clear claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The claim is stated without any backing. Therefore, the verifiability of this claim is low.", "helpfulness_rationale": "The reviewer's question is about the limitations of a method. While this is a valuable piece of information for potential future work or for understanding the scope of the method, it does not directly provide actionable advice on how to improve the current draft. The reviewer is not suggesting a specific action or improvement based on this limitation. The helpfulness lies in identifying a potential area for improvement, but it doesn't actively guide the authors on how to make their current draft better. Therefore, it is 3 in that it highlights a potential issue, but not in providing concrete solutions."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the figures are 'not clear' and provides a specific example of confusion with the relation of the 3 subfigures. They also mention that some modules are not labeled in the figure, such as CMAF, L_BT, VoLTA. This indicates a clear and actionable issue for the authors, as they can directly identify the problem and understand the need for improvement.", "grounding_specificity_rationale": "The reviewer specifically mentions 'figure 2' and the subfigures within it, and points out the missing labels (CMAF, L_BT, VoLTA). This demonstrates strong grounding as the reviewer accurately identifies the specific part of the paper being addressed and clearly specifies the issue within that part.", "verifiability_rationale": "The reviewer makes a claim that the figures are 'not clear'. However, the reviewer does not provide any logical reasoning, examples, or external references to support this claim. While the lack of labels (CMAF, L_BT, VoLTA) is a clear issue, the reviewer does not explain *why* these are unclear or suggest *how* they should be improved. The claim is stated, but the reasoning behind it is missing.", "helpfulness_rationale": "The reviewer's comment is 5 because they clearly identify a significant issue (figure clarity) and point to specific elements within the figure that are lacking. By mentioning 'figure 2' and the subfigures, as well as the missing labels, the reviewer directly informs the authors of the areas that need improvement. This makes the feedback very actionable and directly addresses a concrete problem."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential 'questionable design choice' related to the use of perplexity. While they identify 'catastrophic forgetting' and 'domain drift' as possible issues, they do not explicitly state what specific action needs to be taken or how the draft should be modified. The reviewer implies that the metric might not accurately reflect the original task due to these factors, but they don't provide concrete steps to address this.", "grounding_specificity_rationale": "The reviewer mentions 'perplexity' and its relation to 'semantic information retention', 'catastrophic forgetting', and 'domain drift'. However, they do not explicitly identify the specific part of the paper (e.g., a section, table, or figure) where this issue is most relevant. While they describe the concepts involved, they don't pinpoint the exact location within the draft that needs attention.", "verifiability_rationale": "The reviewer makes a claim about a potential issue with perplexity and its relation to domain drift. They attempt to justify this claim by defining perplexity and the concepts of catastrophic forgetting and domain drift. However, they do not provide specific examples or external references to support their assertion about how these factors are controlled or how the draft should be adjusted to mitigate them.", "helpfulness_rationale": "The reviewer raises a valid concern about a potential methodological issue with the use of perplexity as a metric. They highlight the possibility of 'domain drift' and the need to control for 'catastrophic forgetting'. While this points to a potential problem, the review does not offer specific, actionable steps for the authors to take to address this issue in their draft. The suggestions are more general and about the design choice itself rather than specific changes to the draft."}
{"actionability_label": "3. 3", "grounding_specificity_label": "3. 3", "verifiability_label": "1. 1", "helpfulness_label": "3. 3", "actionability_rationale": "The questions are explicit in asking about the impact of the number of images and the need to explain BYOL. However, the direction of the impact (worse or better) and the specific aspects of BYOL to explain are not explicitly stated, making it somewhat vague on how to apply the information.", "grounding_specificity_rationale": "The reviewer mentions 'the cluster structure is defined by the identity,' which provides a point of grounding. However, the connection between this and the questions about the number of images and BYOL performance is not explicitly stated, making it weakly grounded. The request to explain BYOL is broad and lacks specific elements, making it underspecific.", "verifiability_rationale": "The reviewer presents two questions as claims. However, no evidence or reasoning is provided to support these claims. The questions are openended and lack specific examples or references, making them 1.", "helpfulness_rationale": "The questions directly address potential concerns about the experimental setup and the method used (BYOL). They prompt the authors to consider the impact of a key factor (number of images) and to understand the method they are using. While the questions are openended, they are still valuable for guiding the authors and seeking clarification, making them 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the concern: \"I'm unsure if 44k dialogues is sufficient...\" This indicates a clear action the authors should take. However, the reviewer does not provide a specific action or solution, making it only 3.", "grounding_specificity_rationale": "The reviewer clearly identifies the issue as being related to training data, dialogues, user traits, personalities, and content topics. While they don't pinpoint a specific section or table, they clearly indicate the area of concern, making it fully grounded. They also provide some explanation about the insufficiency of the data, making it somewhat specific.", "verifiability_rationale": "The reviewer presents a claim about the sufficiency of the dataset without providing any evidence or references. They express a concern based on their understanding of LLM training data but do not offer any logical reasoning, common knowledge, or external references to support their claim. Therefore, the claim is 1.", "helpfulness_rationale": "The reviewer raises a relevant concern about the training data, specifically questioning its adequacy for capturing diverse user traits and personalities for a given content topic. This is a pertinent issue for authors training or evaluating models. However, the reviewer does not offer a concrete solution or specific advice on how to address this issue. They raise a question rather than providing a direct answer. Therefore, while the concern is valid, the lack of a concrete solution limits its immediate helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The review point suggests using 'other metrics' to evaluate the Results. While this is a direct instruction for the authors to consider alternative evaluation methods, it lacks specific details on which metrics to use or how to apply them. The action is explicit (suggesting a change), but the concreteness is lacking, making it 3 but not fully actionable.", "grounding_specificity_rationale": "The review point suggests using 'other metrics' to evaluate the Results but does not explicitly identify which part of the paper this suggestion refers to. The authors can infer that it relates to the Results section, but the grounding is not precise. The specificity is also low as the suggestion is very general and doesn't detail the application of these other metrics.", "verifiability_rationale": "The review point is a suggestion for the authors to use different metrics for evaluation, not a claim or assertion about the current draft. There is no logical reasoning, common knowledge, or external references provided to support this suggestion. Therefore, it does not contain a claim and is not verifiable.", "helpfulness_rationale": "The review point suggests using other metrics for evaluation. While this is a relevant suggestion for improving the evaluation process, it is a relatively minor point and does not directly address a specific weakness or improvement needed in the current draft. It lacks a clear connection to a specific issue, making it 3 but not entirely helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests considering 'LLM evaluation' and points to a specific paper 2. While this is an explicit statement, the reviewer does not specify *which* aspect of LLM evaluation they are referring to. The reviewer also states, 'it would still be good to see how SynTextBench metric compares to the other metrics proposed in the literature.' This is an explicit action, but the reviewer does not provide concrete details on *how* to compare these metrics or under what conditions one metric might be preferred over another. The lack of specific guidance makes this action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'LLM evaluation' and a specific paper 2. This indicates a potential grounding as the reviewer is referring to a specific piece of work. However, the reviewer does not explicitly state the *section* of the paper they are referring to, nor do they specify *which* aspect of LLM evaluation they are focusing on. The mention of a specific paper is a weak form of grounding, but the lack of specificity in the referenced section or aspect weakens the overall grounding specificity.", "verifiability_rationale": "The reviewer states, 'Additionally, there has been a large amount of work on LLM evaluation 2' and 'it would still be good to see how SynTextBench metric compares to the other metrics proposed in the literature.' This constitutes a claim as the reviewer is making a statement about the relationship between SynTextBench and other metrics. The reviewer also mentions a specific paper 2, which provides some verifiable evidence. However, the reviewer does not provide sufficient details on *how* to compare these metrics or under what conditions one might be preferred over the other. The request for a comparison lacks the necessary logical reasoning and specific examples to fully verify the claim.", "helpfulness_rationale": "The reviewer's point about the existing work on LLM evaluation and the potential comparison of SynTextBench with other metrics is relevant to researchers in the field. They are highlighting a potential area for further investigation and suggesting a comparison that could be valuable. However, the lack of specificity in the comparison request makes the advice less actionable and potentially less impactful. The reviewer identifies a relevant area but does not provide concrete suggestions or comparisons, limiting the helpfulness of the comment."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a potential issue ('annotations are a little hard to follow') but does not explicitly state what needs to be changed or how the writing should be improved. It points to a *potential* cause rather than a direct action. The reviewer doesn't specify the *type* of annotation or the *specific* writing issue, leaving the author with no clear direction for improvement.", "grounding_specificity_rationale": "The comment does not specify which part of the paper is being referred to. It broadly mentions 'annotations' and 'writing' without pinpointing a specific section, table, figure, or any other identifiable element. The reviewer's statement is general and lacks specificity about the location of the problem.", "verifiability_rationale": "The comment states a problem ('Poor writing and annotations are a little hard to follow') but does not offer any specific evidence or justification for why this is an issue. It's a statement of observation, not a claim requiring verification. There is no logical reasoning, common knowledge, or external references provided to support the statement.", "helpfulness_rationale": "The comment identifies a potential area for improvement (difficulttofollow annotations and poor writing) but does not provide any concrete suggestions or actionable steps for the author to take. It's a symptom rather than a direct prescription. The reviewer doesn't offer any specific edits, clarity improvements, or actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out that the proposed method achieves SOTA in 8 out of 14 metrics in Table 2. While this identifies a weakness (not achieving SOTA in all cases), it doesn't explicitly state the *action* to be taken. The reviewer also notes that the method achieves best overall F1 but not best F1 in all single types. This implicitly suggests an action: investigate why the method performs differently across evaluation types. However, the action itself is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer refers to 'Table 2' and 'evaluation metrics' in their comment. This demonstrates a clear identification of the specific part of the paper being addressed. They also mention 'Twitter2017 > Twitter2015' setting and 'F1 scores', further specifying the context. The information provided is specific to the results presented in Table 2.", "verifiability_rationale": "The reviewer states that the proposed method achieves SOTA in 8 out of 14 metrics in Table 2. This is a claim that can be verified by looking at the data in Table 2. The reviewer also states that the method achieves best overall F1 but not best F1 in all single types. This claim can be verified by comparing the F1 scores in Table 2. The evidence provided is sufficient and logical.", "helpfulness_rationale": "The reviewer points out a discrepancy in the F1 scores between the overall evaluation and the singletype evaluations. This observation highlights a potential weakness in the method's performance across different evaluation types. While the reviewer doesn't explicitly state how to improve this, the observation itself is a valuable piece of feedback that can guide further analysis and refinement of the method. It points to a specific area where the method's performance needs attention."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer's question is explicit about the authors' decision to only consider ECG segments with one label assigned. The reviewer is asking for the *reason* behind this choice. The action the reviewer is suggesting is for the authors to explain their reasoning. This is a clear and direct request for information, making it 5.", "grounding_specificity_rationale": "The reviewer is asking a question about a specific methodological choice made by the authors (only considering singlelabel ECG segments). However, the reviewer does not explicitly identify *which* part of the paper or report this choice relates to. While the context suggests it relates to the difficulty of associated reports, the connection is implied rather than explicitly stated. Therefore, the grounding is weak. It is not specific because the reviewer doesn't pinpoint the exact aspect of the report that makes it easier.", "verifiability_rationale": "The reviewer is making a claim: 'I only consider ECG segments with one label assigned to them.' This is a declarative statement. However, the reviewer does not provide any evidence or justification for *why* the authors made this choice. The suggestion that this makes associated reports easier is an inference, not a directly stated claim. The reasoning behind this choice is missing. Therefore, the claim is not wellverified.", "helpfulness_rationale": "The reviewer is asking a question directly about a specific methodological choice made by the authors. This is a direct request for clarification and justification. It encourages the authors to explain their reasoning and potentially improve their work by considering the difficulty of associated reports. This is a very relevant and helpful feedback point for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests improving the results presentation, implying a need for action. However, the specific action or change the authors should make is not explicitly stated. The reviewer points out the yaxis label being ambiguous and the missing runtime, but doesn't detail how to fix these issues. The suggestion to use a scatter plot is a recommendation, not a specific action to take on the existing figures.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 2 and 3', which clearly grounds the comment to a specific part of the paper. The comment identifies issues with the yaxis label ('ambiguous') and the missing runtime, which are specific details about the referenced figure. However, the reviewer doesn't detail *what* is wrong with the figures beyond these two points.", "verifiability_rationale": "The reviewer makes a claim about the results presentation: 'Results presentation can be improved' and 'yaxis is labeled as \u201cperformance\u201d which is ambiguous, and the runtime is not represented in those figure'. This claim is 3 because the reviewer points out specific issues (ambiguous label, missing runtime) that could be supported by examples or references. However, the reviewer doesn't provide a solution or justification for why these issues are problematic.", "helpfulness_rationale": "The reviewer provides specific feedback about the results presentation, suggesting improvements like using a scatter plot and highlighting best results in tables. While the feedback is valuable and constructive, it doesn't offer concrete, actionable steps for the authors to take immediately. The reviewer identifies areas for improvement but doesn't explicitly state what the authors should do next."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a direct question about the mechanism of NodeSort and its relationship to the base node, key nodes, and model performance. This directly identifies an area where clarification is needed, making it a 5 point for the authors. The authors can directly identify the need to understand how the base node influences the sorting process and its impact on key nodes and performance.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'NodeSort,' 'differentially sorts nodes,' 'base node,' 'key nodes,' and 'model performance,' clearly identifying the specific aspect of the model being discussed and the elements affected. This strong identification of the specific part of the paper and the changes it entails makes it 5.", "verifiability_rationale": "The review point is a question, not a declarative statement with a claim. While it points to a potential area of confusion or lack of clarity in the model's description, it doesn't present a claim that can be verified logically, commonly, or with external references. Therefore, it has X and is not verifiable.", "helpfulness_rationale": "The review point highlights a potential area where the authors might be lacking understanding. By asking about the relationship between NodeSort, the base node, key nodes, and performance, the reviewer is directing the authors to seek more information or clarification about the model's inner workings. This can be helpful for the authors to improve their understanding and potentially the model itself."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the direction of an arrow in a diagram. While this prompts the authors to understand the relationship between the Gaussian space and the latent space, it doesn't explicitly tell them *what* to do with this information. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer explicitly identifies the 'arrow' and the 'latent space' and 'n^(i)' in the diagram. They are pointing to specific parts of the paper (the diagram) and specific elements within those parts. The question is directly about the relationship between these identified parts.", "verifiability_rationale": "The reviewer is asking a question based on their interpretation of the diagram. There is X being made; it's a request for clarification. The purpose is to understand the diagram better, not to critique or justify a claim.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific detail in the paper. While this can be helpful for the authors to understand the method better, it doesn't directly point out a flaw or suggest an improvement to the paper itself. It's more about seeking understanding of the existing work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that 'AR' in Table 5 stands for 'domain adaptation tasks and algorithms'. This is a clear and direct action, making it 5. The reviewer not only identifies an issue but also provides the solution.", "grounding_specificity_rationale": "The reviewer explicitly identifies the location of the undefined abbreviation in Table 5. Furthermore, the reviewer provides a specific definition for 'AR' as 'domain adaptation tasks and algorithms'. This makes the grounding both strong and specific.", "verifiability_rationale": "The reviewer makes a claim that the paper lacks definition for abbreviations. The reviewer then provides a specific and verifiable definition for 'AR' as 'domain adaptation tasks and algorithms'. This makes the claim verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improving the paper by defining the abbreviation 'AR'. This is directly helpful for the author and addresses a specific issue. The feedback is precise and provides a concrete solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer is implicitly suggesting that using qvalue instead of advantage is a potential improvement to their analysis. While the suggestion is not explicitly stated as 'do this,' it implies a preference for a different method. This makes the comment 3, as the reviewer identifies a potential change to their approach. However, the comment lacks specific details on how to implement this change or what advantages qvalue offers over advantage in this specific context.", "grounding_specificity_rationale": "The reviewer's comment focuses on a *technical difference* in their analysis (advantage vs. qvalue) rather than a specific element within the paper (e.g., a particular figure, table, or section). While they are implicitly suggesting a change related to their analysis, they do not point to a specific part of their work that needs addressing. The comment is about the *method* of analysis, not a specific issue within the paper's content. Therefore, the grounding is weak as the reviewer doesn't identify a specific part of their work being addressed.", "verifiability_rationale": "The reviewer's comment is a question about the common practice of using advantage instead of qvalue. They are not presenting a claim that requires verification or evidence. The comment is a query for information rather than a statement that needs to be supported by logical reasoning, common knowledge, or external references. Therefore, the comment does not contain a claim that needs to be verified, making it 1.", "helpfulness_rationale": "The reviewer's comment is a question about a technical detail in their analysis. While it might be helpful for the author (the reviewer) to understand the common practice, it does not directly critique or improve the author's draft. It's a question, not a suggestion for change. Therefore, it is not 5 in the sense of providing actionable feedback or identifying weaknesses in the author's work. It might be 3 if the author found the question informative, but as a review point, it lacks a direct critique or improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "X", "actionability_rationale": "The reviewer raises a point about the 'Unsupervised Online Adaptation' setting. While the method might be unsupervised in terms of not requiring *new* labeled data during adaptation, the reviewer correctly points out that the *description* of the method implies a training set with documents, quires, and labels is required. This raises a question about the explicitness of the actionability. The reviewer is suggesting that the method might not be as unsupervised as claimed, which is a potential action for the authors to consider. The specificity of this action is moderate, as the reviewer is pointing to a detail in the method description.", "grounding_specificity_rationale": "The reviewer's point about the 'Unsupervised Online Adaptation' setting can be analyzed through the lens of grounding specificity. The reviewer is implicitly grounding the issue in the *presence* of labels in the training set. While the method might be unsupervised in terms of not requiring *new* labeled data, the need for existing labeled data (the 'labels' in the training set) makes the grounding somewhat explicit. The reviewer is pointing to a specific component of the method that has a label dependency. Therefore, the grounding is somewhat specific as it directly relates to the presence of labels.", "verifiability_rationale": "The reviewer's review point does not contain a claim in the sense of suggesting a problem or proposing a solution. They are questioning the validity of a claim made by the authors (that the method is unsupervised). Therefore, based on the definitions provided, this review point does not contain a verifiable claim. It's more of a critique or a request for clarification regarding the authors' description.", "helpfulness_rationale": "The reviewer's review point is primarily a critique of the authors' description of their method. They are questioning the validity of a claim made by the authors. While this points to a potential issue with the authors' understanding or description, it doesn't directly offer a helpful suggestion or actionable improvement to the authors' work. It's more of a diagnostic question than a constructive suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states that VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1. This directly identifies a difference in implementation. The reviewer then concludes that this makes the comparison in Table 1 unfair. This is a clear statement of an action the authors should take or consider.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper (e.g., a particular table or section). It is a general statement about the experimental setup. While it mentions 'Table 1' and 'sample weights W u i', it doesn't pinpoint the exact location or element being affected.", "verifiability_rationale": "The review point makes a claim about the unfairness of the performance comparison in Table 1 due to different sample weights. To verify this claim, one would need to examine Table 1 and confirm that VINS indeed uses different sample weights while the other methods use a weight of 1. Assuming this information is present in Table 1, the claim is supported by evidence.", "helpfulness_rationale": "The review point raises a valid concern about the fairness of the experimental comparison in Table 1. By pointing out the difference in sample weights, the reviewer highlights a potential issue that could affect the interpretation of the results. This provides the authors with a direction to investigate or adjust their comparison. While it doesn't offer a solution, it identifies a potential flaw in the experimental design."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "1 (1)", "verifiability_label": "1 (1)", "helpfulness_label": "1 (1)", "actionability_rationale": "The review point states a potential issue but does not provide a concrete action or step for the authors to take. It identifies a problem related to the reply buffer but lacks specific guidance on how to address it.", "grounding_specificity_rationale": "The review point refers to 'reply buffer' without specifying which part of the paper or context this relates to. It also doesn't pinpoint the specific algorithm or component within the PRMRL framework. The reference '1' indicates a citation, but doesn't provide specific details about a section or element within that cited work.", "verifiability_rationale": "The review point states a potential consequence: 'The time complexity will be too high if the reply buffer is too large.' This is a claim about the relationship between the reply buffer size and time complexity. However, the review point does not offer any justification or explanation for *why* this might be the case. There is no reference to specific algorithms, theoretical limitations, or empirical observations.", "helpfulness_rationale": "The review point identifies a potential problem related to time complexity. While it points out a *potential* issue with the reply buffer, it doesn't offer any concrete solutions, suggestions, or guidance on how to address it. The lack of actionability, grounding, and verifiability makes it difficult for the authors to take any meaningful steps."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the action needed: 'It is better for authors to display the performance of accelerating SGMs by involving some other baselines'. It also provides a clear 'how' by suggesting 'involving some other baselines with a different perspective, such as 'optimizing the discretization schedule or by modifying the original SGM formulation' 16, 15, 23, 46, 36, 31, 37, 20, 10, 25, 35, 45'. The suggestions are direct and actionable.", "grounding_specificity_rationale": "While the review point doesn't explicitly state the 'section' or 'figure' where SGM performance is discussed, the context strongly implies it's referring to a section discussing model evaluation or experimental results, which would likely be where SGM performance is analyzed. Furthermore, the suggestions for baselines are very specific ('optimizing the discretization schedule' and 'modifying the original SGM formulation'). This provides strong grounding and specificity.", "verifiability_rationale": "The review point makes a claim: 'It is better for authors to display the performance of accelerating SGMs by involving some other baselines'. This claim is supported by providing 'specific examples' of what constitutes 'some other baselines' (optimizing the discretization schedule and modifying the original SGM formulation). While it doesn't cite specific papers *in this review point*, it does point to relevant research areas 16, 15, 23, 46, 36, 31, 37, 20, 10, 25, 35, 45, which would serve as external references. The claim is logically supported by the suggestions.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for improving the comparison of SGMs. It proposes specific types of baselines that offer a different perspective, which is valuable for a comprehensive evaluation. While it doesn't provide a complete solution, it points in a constructive direction for the authors to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point requests the inclusion of a conclusion and summary, which is a helpful direction. However, it lacks specificity, failing to indicate *how* these should be provided. Therefore, it is 3, as it points to a needed improvement, but lacks the explicit steps required for full actionability.", "grounding_specificity_rationale": "The review point requests a conclusion and summary but does not specify *which* paper or section this refers to. This lack of specificity means it is 1 in a particular part of the work, making it unhelpful for the authors who would need to know where to focus their improvements.", "verifiability_rationale": "The review point is a request, not a declarative statement containing a claim. Therefore, it does not have verifiability.", "helpfulness_rationale": "The review point suggests improvements to the conclusion and summary, which is a positive direction. However, the lack of specificity in how to achieve these improvements makes the suggestion less helpful for the authors. It's better than a completely unhelpful comment but lacks the actionable details needed for full helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests comparing the proposed framework with a method designed to defend against multiple attacks. This is an explicit action as the reviewer directly states the comparison. The action is also concrete as the reviewer specifies the type of method to compare with, even if it's not a specific name. This provides a clear direction for the authors to improve their work by considering a broader range of defense mechanisms.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'a method that is designed to defend against multiple attacks.' This clearly identifies the specific area of related work the reviewer is referring to, making the grounding 'Full Grounding'. However, the reviewer does not specify a particular method within this category, making the specificity 'UnderSpecific'. Therefore, the overall grounding specificity is 'Weakly Grounded and UnderSpecific'.", "verifiability_rationale": "The reviewer suggests comparing the proposed framework with a method designed to defend against multiple attacks. This statement itself is a claim that the authors should consider. However, the reviewer does not provide any justification or reasoning for why this comparison would be beneficial or how it would improve the authors' work. Therefore, the verifiability of this claim is '1' based on the provided text.", "helpfulness_rationale": "The reviewer's suggestion to compare the proposed framework with a method designed to defend against multiple attacks is a relevant and valuable suggestion for the authors. It points to a potential limitation of the current comparison (focusing on a single attack) and offers a direction for more comprehensive evaluation. While the suggestion itself is not a concrete fix, it is a meaningful improvement direction. Therefore, the helpfulness of this review point is '3'."}
{"actionability_label": "5 (5)", "grounding_specificity_label": "5 (5)", "verifiability_label": "X (X)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point explicitly asks for a definition of a specific term (\tau_i^l) which is crucial for understanding the timewarp function. This is a direct and explicit request for clarification, indicating a lack of understanding or a desire for more precise information. Once the definition is provided, the author can understand the timewarp function, making this an actionable request.", "grounding_specificity_rationale": "The reviewer explicitly asks for the definition of a specific term (\tau_i^l). They are indicating they understand the context (the paper) and are pointing out a specific element within it that needs clarification. This demonstrates strong grounding specificity as the reviewer can accurately pinpoint the section, table, figure, or unique aspect being addressed.", "verifiability_rationale": "This review point is not a claim or assertion. It is a request for information. Therefore, it doesn't fit into the categories of 'X' (X) or verifiability. It's a request for a definition, not a critique or a suggestion.", "helpfulness_rationale": "This review point provides information that is crucial for understanding a key component of the paper (the timewarp function). While it doesn't directly suggest improvements, it provides essential context and clarification that could indirectly lead to better understanding and potentially improved work. It's helpful in the sense that it clarifies a necessary component."}
{"actionability_label": "borderline actionability", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies the *types* of errors (writing errors, grammatical error, missing title) but doesn't specify how to *fix* them. It's a general statement about the *paper* as a whole, lacking specific instructions for improvement.", "grounding_specificity_rationale": "The comment explicitly mentions the *location* of the errors on 'page 5' and the term 'performance' lacking a title, making the grounding fully grounded. However, it doesn't specify *what* the writing errors are on page 5 or what's wrong with the 'performance' section, making it specific only in terms of location.", "verifiability_rationale": "The review point identifies the presence of writing errors and the lack of a title for the 'performance' section. This is a statement of observation about the paper's quality, not a claim that requires verification. There is X that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The review point highlights the presence of writing errors and the missing title. While it points out areas for improvement, it doesn't provide specific instructions or guidance on how to address these issues. The authors still need to go back and read the paper to figure out what to do, limiting its helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the action needed: 'rewrite' the first sentence of the abstract. It doesn't just suggest an improvement but directly tells the author what to do.", "grounding_specificity_rationale": "The comment explicitly mentions 'the abstract' and further specifies 'the first sentence' of the abstract. This precise identification of the paper section demonstrates strong grounding specificity.", "verifiability_rationale": "The comment suggests an improvement ('rewrite') but doesn't provide any specific evidence or reasoning to support why the first sentence needs rewriting. It lacks the logical reasoning or external references that would make it verifiable.", "helpfulness_rationale": "The comment directly identifies a potential weakness ('needs to be rewritten') and provides a clear direction for improvement ('the first sentence of the abstract'). This direct and actionable feedback is 5 for the author."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "2 (2)", "verifiability_label": "3 (3)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point is a question, not a statement with a clear action. It asks \"One would suspect...\" rather than directly suggesting a change. While the suspicion is implied, the reviewer isn't explicitly stating what should be done. It's a hypothesis, not a directive.", "grounding_specificity_rationale": "The review refers to the \"method\" in general and doesn't specify which part of the paper it addresses. The reviewer states a suspicion about the method's complexity without pinpointing *which* part of the method or *what specific aspect* is causing this suspicion. The authors cannot confidently determine which part the comment addresses. Further, the comment does not specify what needs to be addressed in this part.", "verifiability_rationale": "The review contains a claim: \"One would suspect that there is an underlying, simpler, principle that is propulsing the quality gains.\" This is a statement of belief and a potential issue. The reviewer offers a *hypothesis* as the justification for their claim. They are suggesting a possible explanation for the observed results. While it might not be a fully supported claim in the absence of evidence, it *is* a claim that *could* be investigated. The claim is present, and the reviewer offers a potential explanation (the \"underlying, simpler principle\").", "helpfulness_rationale": "The review raises a valid point about potential overcomplexity and suggests a search for simpler principles. This is a constructive criticism aimed at improving the method. The suggestion, while not a direct solution, is still a valuable direction for the authors to consider. It prompts them to reflect on their approach and potentially simplify it. The review identifies a potential issue and offers a relevant direction for improvement, even if it doesn't provide a concrete solution."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the hGRU architecture 'seems pretty adhoc and not very well motivated' but does not explicitly identify an action or suggest a concrete improvement. While it implies a potential issue, the authors are left to infer what needs to be changed. The suggestion is vague and lacks specific guidance on how to make it better.", "grounding_specificity_rationale": "The comment refers to 'the hGRU architecture' generally, without specifying a particular section, table, figure, or unique element of the paper where the adhoc nature is specifically an issue. It doesn't pinpoint the exact location or detail what is problematic within the hGRU architecture itself.", "verifiability_rationale": "The comment contains a claim ('the hGRU architecture seems pretty adhoc and not very well motivated') but does not provide any specific examples, citations, or logical reasoning to support this claim. It lacks the necessary evidence to be considered verifiable.", "helpfulness_rationale": "The comment identifies a potential area for improvement (hGRU being adhoc) but does not offer specific suggestions or explain why it's a problem. The authors would know there's an issue with the architecture, but they wouldn't receive concrete guidance on how to address it. The feedback is general and lacks actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests a potential change to Algorithm 1 Line 8, indicating an actionable suggestion. However, the suggestion is not fully detailed, leaving the authors to infer the exact nature of the change. The reviewer asks a question, which can be considered an implicit action to clarify the issue.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or algorithm. The reviewer is asking about the implementation details of Algorithm 1 Line 8 in general. Therefore, the grounding is weak as the authors cannot precisely identify the referenced part. The questions are also general and do not specify what needs to be analyzed for asymptotic performance or experimental details.", "verifiability_rationale": "The review point raises a question about the algorithm's implementation without providing any justification or evidence. The reviewer is asking for clarification on a potential issue but doesn't offer any logical reasoning, common knowledge, or external references to support their concern. The questions are openended and lack specific examples or references.", "helpfulness_rationale": "The review point raises a specific concern about Algorithm 1 Line 8 and asks related questions. This suggests a genuine interest in the authors' work and points to a potential area for improvement. However, the questions are openended and lack specific requests for information or solutions. The reviewer doesn't provide a clear path forward or a definitive answer, making the feedback somewhat exploratory rather than directly corrective."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'It is not clear what are the challenges when the authors analyze Adam under the (L0,L1)smoothness condition.' They then suggest a concrete action: 'It is better to explain the challenges, especially the difference between this one and Zhang et al.' This directly addresses the identified issue and provides a clear path for improvement.", "grounding_specificity_rationale": "The reviewer identifies the specific area of confusion: 'It is not clear what are the challenges when the authors analyze Adam under the (L0,L1)smoothness condition.' They also suggest a specific improvement: 'It is better to explain the challenges, especially the difference between this one and Zhang et al.' This suggests a clear grounding in the specific analysis being discussed and a specific suggestion for clarification.", "verifiability_rationale": "The reviewer makes a claim: 'It is not clear what are the challenges when the authors analyze Adam under the (L0,L1)smoothness condition.' They then suggest a way to verify this claim by providing an explanation: 'It is better to explain the challenges, especially the difference between this one and Zhang et al.' This constitutes a verifiable claim and a suggestion for verification.", "helpfulness_rationale": "The reviewer identifies a weakness in the draft: 'It is not clear what are the challenges when the authors analyze Adam under the (L0,L1)smoothness condition.' They then suggest a concrete improvement: 'It is better to explain the challenges, especially the difference between this one and Zhang et al.' This actionable suggestion directly addresses the identified weakness and empowers the authors to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the two main categories of person reID methods (twostep and endtoend) and their reliance on pedestrian detectors. This clearly identifies an action the authors should take: explore alternative approaches or delve deeper into the limitations of relying solely on pedestrian detectors for reID.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'twostep method,' 'endtoend method,' and 'pedestrian detector.' These are specific terms within the field of person reID, indicating strong grounding. The reviewer also describes the nature of these methods (relying on detectors) and even suggests a potential alternative (endtoend methods), further specifying the issue.", "verifiability_rationale": "The review point presents a statement about the basis of person reID methods. While it doesn't contain a direct claim requiring external verification, it describes a generally verifiable observation about the current landscape of reID techniques. The statement is supported by common knowledge in the field, although a citation to specific works could strengthen it.", "helpfulness_rationale": "The review point is 5 as it identifies a key characteristic of person reID methods (reliance on pedestrian detectors) and suggests exploring alternative approaches. This provides the authors with a clear direction for further research and a deeper understanding of the field."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action to be taken: 'I suggest to add a first sentence to introduce what this section is about.' This clearly indicates the reviewer wants the author to add a sentence explaining the purpose of Section 3.2. The action is also concrete, as the reviewer directly states the desired outcome.", "grounding_specificity_rationale": "The review point directly references 'Section 3.2', which is a specific and identifiable part of the paper. The reviewer is not making a general comment about the entire paper or a vague suggestion about the content of Section 3.2. The grounding is explicit and points to a specific location.", "verifiability_rationale": "The review point makes a suggestion ('I suggest to add a first sentence') but does not provide any justification or evidence for why this is a good idea or how it would improve the paper. It is a statement of preference rather than a claim supported by reasoning or references. There is X extraction needed as the point is a suggestion, not a statement of fact or opinion.", "helpfulness_rationale": "The review point is 5 because it directly identifies a specific area for improvement (the lack of an introduction to Section 3.2) and provides a clear and actionable suggestion (adding a first sentence). This is a valuable piece of feedback for the author, as it points them to a common issue and offers a concrete solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly states the 'initial rationale selector' is 'perfect'. While it identifies a specific component, it lacks concrete information on what constitutes 'perfect' in this context. Without a clear definition or indication of an issue, the action remains vague. The reviewer's interpretation that 'no additional work needs to be done' highlights the lack of actionable information.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper or the rationale selector that is 'perfect'. The reviewer is questioning the meaning of this statement, implying a lack of clear identification. The comment is 1 because the authors cannot confidently determine which part the comment addresses. The statement 'no additional work needs to be done' suggests the authors are unsure what the comment implies.", "verifiability_rationale": "The comment contains a claim ('the initial rationale selector is perfect') but lacks supporting evidence or justification. The statement is presented as an opinion without any logical reasoning, common knowledge, or external references. The reviewer's statement is a direct observation of the comment's content.", "helpfulness_rationale": "The comment is not helpful because it does not provide any actionable feedback for the authors. The statement 'perfect' is vague and does not pinpoint a problem or suggest an improvement. The reviewer's interpretation that 'no additional work needs to be done' directly reflects the lack of helpfulness. The comment is an opinion without guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer asks a question about a potential improvement to the methodology (using domain ontologies) but doesn't explicitly state what the authors should do differently. While the action is implied (improving the methodology), it's not a direct instruction. The reviewer also asks a question about a specific detail in the paper (line 211) without explicitly stating they are referring to that line and asking for clarification. The action is implied (asking for clarification), but it's not a direct instruction.", "grounding_specificity_rationale": "The reviewer asks if the authors experimented with domain ontologies, but doesn't explicitly identify the section or table where this information might be found. The reviewer asks about the number of questions and accuracy related to line 211, but doesn't explicitly state they are referring to the methodology or results discussed in that line. The information is not directly linked to a specific part of the paper.", "verifiability_rationale": "The reviewer states a question about whether the authors used domain ontologies, which can be interpreted as a claim. However, they don't provide any evidence or reasoning to support this claim. The reviewer asks about the number of questions and accuracy related to line 211, which can also be interpreted as a claim. However, they don't provide any evidence or reasoning to support this claim.", "helpfulness_rationale": "The reviewer asks a question about a potential improvement to the methodology, which is a relevant question but doesn't directly identify a flaw or actionable improvement. The reviewer asks for specific details about the experimental setup on line 211, which is helpful for understanding the paper but might not directly point to a flaw or actionable improvement in the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the suggestion: \"It would be better to compare with other selfsupervised learning methods that are not based on contrastive learning.\" This is a direct and clear indication of an action the reviewer wants the authors to take. The action is to add a comparison to the related work section. The reviewer also provides the *type* of comparison they desire, which makes the action quite concrete. While the specific methods are not named, the *category* of comparison is clear.", "grounding_specificity_rationale": "The reviewer implies a need to add content to the related work section. While the *section* where the comparison should be added is not explicitly named (e.g., 'Comparison with other SSL methods'), the implication is clear: the related work section. The reviewer's comment is an educated guess about where the comparison would be most relevant. Therefore, it can be considered 'Weakly Grounded' as the authors can infer the section, but cannot precisely identify the referenced part. The comment also specifies *what* needs to be compared (other SSL methods not based on contrastive learning), which makes it 'Specific'.", "verifiability_rationale": "The reviewer makes a claim: \"It would be better to compare with other selfsupervised learning methods that are not based on contrastive learning.\" This is a statement of suggestion and implies a value judgment. The reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion is presented as a recommendation without backing. Therefore, the claim is not verifiable based on the provided text.", "helpfulness_rationale": "The reviewer suggests adding a comparison to the related work section. This directly addresses a common need for clarity and context in research papers. By adding this comparison, the authors would gain a better understanding of how their method relates to other selfsupervised learning techniques. This suggestion is directly actionable and provides a clear next step for the authors. Therefore, the suggestion is helpful in guiding the authors to improve their draft by providing relevant context."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification on the 'abstention process' and its relation to 'prediction probability thresholds' and 'decision thresholds'. While the reviewer's question is explicit about the concepts involved, the paper does not explicitly define or explain these terms or their relationship. The request is clear, indicating a lack of understanding, but the specifics of the abstention process are not detailed, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer is asking about the 'abstention process' and how it relates to 'prediction probability thresholds'. The paper does not explicitly mention 'prediction probability thresholds' in the context of the abstention process. The reviewer's question implies a connection to probabilities, but this is not explicitly stated or grounded in the paper. The specificity of the request is limited, as it doesn't pinpoint the exact mechanism or provide examples.", "verifiability_rationale": "The reviewer is making a claim about the difference between 'prediction probability thresholds' and 'decision thresholds'. The paper does not explicitly define or explain these terms or their relationship. The reviewer's claim is based on an assumption about how these concepts might relate, but this assumption is not supported or verified within the provided text. The claim lacks sufficient justification.", "helpfulness_rationale": "The reviewer is asking for clarification on a technical detail of the abstention process. Such clarification is generally helpful for understanding a mechanism. However, the lack of detail in the original explanation makes the potential benefit limited. The request is clear, but the impact on the authors' understanding is uncertain without more information."}
{"actionability_label": "4 (4)", "grounding_specificity_label": "3 (Somewhat Grounded and Specific)", "verifiability_label": "3 (3)", "helpfulness_label": "5 (5)", "actionability_rationale": "The review point explicitly states a weakness ('lack of meaningful baselines') and suggests a specific action to address it ('comparing with a chainofthought prompting approach'). This directly points to an actionable recommendation.", "grounding_specificity_rationale": "The review point mentions 'various model criticism techniques' in Section 2. While it doesn't explicitly state which technique is being criticized, the *general* criticism is implied. The suggestion to compare with 'chainofthought prompting' is a concrete baseline but doesn't directly target a specific part of the paper being discussed in Section 2.", "verifiability_rationale": "The suggestion to compare with chainofthought prompting is verifiable. However, the *statement* of the lack of meaningful baselines isn't explicitly linked to a specific reason or evidence within the provided text snippet. The reviewer is making an *assessment* of the baselines used.", "helpfulness_rationale": "The review point clearly identifies a weakness ('lack of meaningful baselines') and provides a specific and actionable suggestion ('comparing with a chainofthought prompting approach'). The suggestion is also verifiable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the model pretraining but doesn't provide a specific action or solution. While it highlights a potential issue (generalization without labels), it doesn't directly address the actionability aspect. The reviewer doesn't explicitly state what the authors should do next or how to implement the suggestion.", "grounding_specificity_rationale": "The review point identifies the topic of pretraining and generalization, which are specific parts of the paper. It asks about the entire dataset or the training set, which are specific elements. However, it doesn't specify what is wrong or needs improvement within these areas. The grounding is present, but the specificity of the identified issue is lacking.", "verifiability_rationale": "The review point poses a question about a potential issue (generalization without labels) but doesn't provide a claim or assertion that can be verified. It's a diagnostic question rather than a statement that requires evidence. Therefore, it doesn't fit into the 'Verifiability' categories as it lacks a verifiable statement.", "helpfulness_rationale": "The review point raises a valid concern about the generalization capabilities of the model when labels are absent. However, it doesn't offer any specific advice, solutions, or guidance to the authors on how to address this issue. It's a question that could be helpful, but without a proposed solution, it's not actively helpful in improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a small performance difference in an ablation study but does not propose any action or solution based on this observation. They are simply questioning the significance of the difference.", "grounding_specificity_rationale": "The reviewer refers to 'an ablation study in Tab.' but does not specify which part of the table or which aspect of the ablation they are questioning. They are not pointing to a specific section, table, figure, or unique element of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim about the significance of the performance difference in the ablation study but does not provide any evidence or justification for this claim. They state 'there is little difference' without supporting it with logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer raises a valid concern about the significance of a performance difference in an ablation study. However, they do not provide any evidence or justification to support their claim that the difference is 'little.' This makes the review less helpful as it lacks a strong argument."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states 'No new evaluation metrics are proposed. Only existing evaluation metrics are proposed.' This clearly identifies an action that is not being taken, making it 3 in terms of identifying what is missing. However, it doesn't suggest what *should* be done instead.", "grounding_specificity_rationale": "The comment makes a general statement about the evaluation process without referencing specific parts of the paper, methodology, or providing reasons for the observed need for indepth exploration. It lacks both grounding and specificity as it doesn't pinpoint a particular area or detail within the evaluation process.", "verifiability_rationale": "The comment makes claims about the evaluation process, such as 'No new evaluation metrics are proposed. Only existing evaluation metrics are proposed.' and 'In the experimental analysis section, there needed to be an indepth exploration of the reasons for these experimental results.' However, it does not provide any logical reasoning, references, or external evidence to support these claims. The claims are presented without sufficient justification.", "helpfulness_rationale": "The comment identifies a potential area for improvement (exploring new metrics) but doesn't offer concrete suggestions or actionable steps for the authors. It's more of a diagnostic observation about the current evaluation process than a prescriptive improvement suggestion. Therefore, it's not 5 in guiding the authors towards specific changes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem (abuse of notation) and suggests a solution (using different notation). While the suggestion is general, it points to a concrete action the authors can take to improve clarity. The reviewer identifies the conflicting uses of 'K' but doesn't specify the exact correct notation, making it partially concrete.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific issue with the notation 'K' and points to the lines in the paper where this abuse occurs (L166 and L176). They also state what the problem is (conflicting uses) and what should be done (use different notation). This provides precise information about the problematic section and the nature of the issue.", "verifiability_rationale": "The reviewer makes a claim about the abuse of notation 'K'. This claim is supported by stating where the conflicting uses are mentioned (lines 166 and 176). The reviewer also explains the problem (conflicting uses of the same symbol for different concepts) and suggests a solution (using different notation). This provides a clear justification for the claim, making it 5.", "helpfulness_rationale": "The reviewer's point about the abuse of notation is directly relevant to the clarity and correctness of the paper. It helps authors understand that the symbol 'K' has multiple meanings and should avoid potential confusion. The suggestion to use different notation is a clear and actionable improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states a limitation of the work, focusing on the AMP algorithm's applicability to nonGaussian problems. While it points to a theoretical interest, it directly identifies a practical concern. The mention of \"AMP algorithm\" provides a concrete element, even if the *degree* of actionability could be debated (see borderlines below).", "grounding_specificity_rationale": "The review point explicitly mentions \"the AMP algorithm,\" which grounds the comment to a specific aspect of the paper. Then, it further specifies the concern regarding \"nonGaussian problems,\" making the grounding quite specific.", "verifiability_rationale": "The review point presents a statement of opinion: \"So practical impact may be limited.\" This is a subjective assessment and lacks any supporting evidence, examples, or references to back up this claim.", "helpfulness_rationale": "The reviewer points out a potential limitation of the work's practical application. While the point is relevant, the lack of verifiable evidence makes it difficult for the authors to understand the basis of this claim and how to address it. The criticism is present, but lacks the necessary detail to be fully constructive."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer implicitly suggests that the authors should clarify the connection between human cognition and the CPR model and provide more context for the statement about the influence of these factors. While the suggestion is vague, it is a direct action the authors can take to understand the comment.", "grounding_specificity_rationale": "The reviewer points to a statement made by the authors regarding the influence of cognitively basic adaptation mechanisms and the CPR structure. However, they do not explicitly identify which specific part of the paper or methodology this statement refers to, making the grounding of the comment underspecific.", "verifiability_rationale": "The reviewer makes a claim about the unclear connection to human cognition and the surprising nature of the statement. However, they do not provide any external references or logical reasoning to support this claim, making it 1.", "helpfulness_rationale": "The reviewer's comment directly identifies a potential weakness in the paper (the unclear connection to human cognition) and suggests a specific improvement (clarification). This directly benefits the authors and provides actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the wording is 'overly exaggerated' and points to a specific phrase in the conclusion as an example of this issue. While it doesn't provide specific steps on how to change the wording, it clearly identifies a problem and a location. Therefore, it is 3 as it identifies a specific area for improvement.", "grounding_specificity_rationale": "The comment explicitly mentions the 'conclusion' as the area of concern and provides a specific example of the 'overly exaggerated' wording. This clearly identifies the specific part of the paper being addressed and details what is wrong with it. Therefore, it is 5.", "verifiability_rationale": "The comment makes a judgment that the 'wording is overly exaggerated' in the conclusion. However, it does not provide any evidence, logical reasoning, or external references to support this claim. It is a subjective opinion without any backing. Therefore, it is 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement ('conclusion') and highlights a characteristic of the writing ('overly exaggerated'). This provides the authors with a clear direction for their revision efforts. However, it does not offer specific, actionable steps on how to make the wording less flamboyant. Therefore, it is 3 as it points to a need for change, but lacks concrete suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a relevant area for improvement (parameter efficiency) but doesn't explicitly state the action to be taken or the expected outcome. The action is implicit (performing ablation studies). The lack of explicitness makes it less actionable than a comment that directly states 'You should analyze the parameter count and GFLOPs of your model and compare it to TubeR using ablation studies.'", "grounding_specificity_rationale": "The comment grounds the suggestion in specific metrics (learnable parameters, GFLOPs) and a specific comparison (TubeR). However, it doesn't explicitly point to a specific section or table in the paper where these details are discussed. The grounding is present but could be more precise.", "verifiability_rationale": "The comment makes a claim that ablation studies are needed for comparison, which is generally verifiable in the context of method evaluation. However, it doesn't provide sufficient justification or reasoning for why this claim is valid in the specific context of the proposed method and TubeR. The lack of detailed reasoning makes it less 5 than a comment that provides a clear rationale for the need for ablation studies.", "helpfulness_rationale": "The review point identifies a relevant and valuable area for authors to explore (parameter efficiency and comparison with TubeR). However, it lacks specific details on how to perform the ablation studies, what specific aspects to analyze, and what the expected outcomes should be. The reviewer doesn't provide actionable steps for the authors, leaving them to figure out the next steps themselves. This lack of explicit guidance reduces its helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the absence of a comparison to 'simple feature acquisition baselines' as a weakness. This directly identifies an action the authors should take (include a comparison) and implicitly suggests the authors should know about or consider such baselines. However, the action is not very concrete, as the reviewer doesn't specify which baselines or how to implement the comparison.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'simple feature acquisition baselines' as the missing element for comparison. This directly identifies the specific part of the paper (the experimental section, likely) and the issue within it (the lack of comparison to standard baselines). This demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer states a claim (the absence of comparison is a weakness) but provides no justification or evidence for this claim. There is no logical reasoning, common knowledge, or external references provided to support the assertion that this lack of comparison is problematic. Therefore, the claim is 1.", "helpfulness_rationale": "The reviewer points out a significant weakness (lack of comparison) that would be valuable for the authors to know. This makes the review point 3 in identifying an area for improvement. However, the lack of specificity in the review point limits its helpfulness as the authors don't know what to compare or why this comparison is crucial."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests improvements (how about other bit operations?) and asks questions about specific details (how did you deal with DVS input?). While these are relevant, the suggestions are broad and the questions lack specificity. The comment also points out a perceived issue with Fig. 5 a ('seems strange'), which could be considered an implicit action. However, the lack of concrete details makes it difficult to determine exactly what needs to be done. The reviewer also suggests analyzing energy consumption, which is a suggestion for improvement, not a concrete action.", "grounding_specificity_rationale": "The reviewer refers to 'Fig. 5 a' which is a specific element in the paper. They also ask about 'how did you deal with DVS input?' which implies a specific aspect of the methodology. However, the reviewer does not explicitly state what is wrong with Fig. 5 a or how the DVS input was handled. The lack of specificity in identifying the issue or the method makes the grounding weak.", "verifiability_rationale": "The reviewer states 'Fig. 5 a seems strange' and 'If you can analyze the energy consumption as reference15 did, this paper would be more solid'. The first statement is a subjective opinion without any supporting evidence or reference. The second statement is a suggestion for improvement, not a claim requiring verification. The lack of logical reasoning or external references makes the claim 1.", "helpfulness_rationale": "The review point offers several suggestions for improvement, such as exploring more bit operations and analyzing energy consumption. While these suggestions are relevant to the paper's topic, they do not directly address any specific weaknesses or errors identified by the reviewer. The feedback is more about suggesting directions for future work rather than providing concrete, actionable feedback to improve the current draft. The lack of specificity makes it difficult for the authors to take concrete steps based on this review."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer raises a question about a potential issue (oversmoothing) with a specific technique (similarityaware positive sample selection). While this points to a potential problem, the review point lacks explicit instructions on how to act or modify the authors' approach. The concern is presented as a problem, not a direct instruction on how to fix it or what changes are needed. Therefore, while the reviewer identifies a potential area for improvement, they do not provide clear guidance on how to achieve it.", "grounding_specificity_rationale": "The reviewer raises concerns about oversmoothing and the impact of selecting positive samples within the same dataset. While they mention 'similarityaware positive sample selection,\" they don't pinpoint a specific part of the paper being affected. The concerns are general to the method. The reviewer's comments are about the method's potential negative effects (oversmoothing, lack of generalization) rather than a specific section, table, figure, or unique aspect of the paper being addressed.", "verifiability_rationale": "The reviewer states their concerns about the method and its potential impact on generalization. They don't explicitly claim that their model has a flaw. The language is about the potential flaw of the authors' model. The reviewer is expressing a concern, not making a claim that something is incorrect or needs to be supported.", "helpfulness_rationale": "The reviewer raises concerns about a potential issue with the authors' method. They don't offer any suggestions or insights on how to address these concerns. The feedback is primarily a question about potential issues rather than actionable suggestions. The reviewer is pointing out a potential limitation of the authors' approach but doesn't provide any concrete feedback or suggestions to improve it."}
{"actionability_label": "3", "grounding_specificity_label": "X", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer points to a specific area of interest ('fast SMP') and a specific type of comparison ('expressiveness'). However, they don't directly instruct the authors on how to improve their model. While the question is specific, it's more of a topic for discussion than a direct action item.", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "The reviewer is directly asking a question and suggesting a discussion, which is a clear and helpful way to provide feedback. While it doesn't directly tell the authors how to improve their model, it points towards a potentially fruitful area of investigation and could inspire them to explore further."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points out a *lack* of clarity regarding social norms. It doesn't *imply* an action or suggest *how* to improve this. The weakness is identified, but the improvement direction is missing. While it identifies a problem, it doesn't provide actionable steps to address it.", "grounding_specificity_rationale": "The comment mentions 'social norms\" generally. It doesn't pinpoint a specific section, table, figure, or unique aspect of the paper where this lack of clarity is evident. The reference to 'social norms\" is broad.", "verifiability_rationale": "The comment states a problem (\"The types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper.\"). This is a claim about a missing element. However, the *reasoning* for this claim isn't provided. It's stated as a fact, not explained *why* this lack of clarity is a problem or how it impacts the work.", "helpfulness_rationale": "The review points out a *specific* area for improvement: the lack of clarity regarding social norms. It doesn't explicitly suggest *how* to address this. While it identifies a weakness, the lack of a concrete improvement direction makes it less helpful than it could be."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The request explicitly asks for a definition of the dashed lines, which is a direct and clear action for the authors to take. The phrasing is straightforward and identifies a specific detail they need to understand.", "grounding_specificity_rationale": "The reviewer explicitly asks about 'dashed lines in fig. 2AB and 4B'. This directly points to specific elements within the paper, making it fully grounded. The section, table, figure, or element is clearly identified.", "verifiability_rationale": "While the reviewer isn't making a claim about the figures themselves, the request implies a lack of clarity regarding a specific visual element. The information about the dashed lines *does* exist within the paper (albeit not explicitly defined as 'dashed lines'), so it is verifiable. However, the reviewer is highlighting a potential point of confusion for the authors, suggesting the paper could be clearer. The information is present, but the expectation of it being explicitly defined is not.", "helpfulness_rationale": "The request is clear and directly addresses a potential area of confusion for the authors regarding the figures. It is actionable and provides a specific expectation. While the information might not be explicitly defined as 'dashed lines', the reviewer's intent suggests it's a relevant detail for understanding the figures, making it a helpful point of feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state any action or suggestion for the authors. It is a critique of the perceived significance of the work rather than a direct feedback on how to improve it.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or the authors' work that it is referring to. It is a general statement about the overall significance of the results.", "verifiability_rationale": "The review point does not contain a claim or a statement that requires verification. It is an expression of opinion about the significance of the results.", "helpfulness_rationale": "The review point does not provide any actionable feedback or suggestions for the authors. It is a critique of the perceived significance of the work without offering any concrete improvements or remedies."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a limitation: 'However, another popular class of kernels such as Matern kernels are not included, since their spectrum only decay polynomially.' This suggests a potential improvement by considering these kernels. While the suggestion is not a stepbystep action, it is a clear direction for the authors. The reviewer also states, 'The authors assume that the spectrum of a kernel is subgaussian. This is OK, as the popular Gaussian kernels are in this class.' This suggests the authors should consider the implications of this assumption, which is a form of action, albeit a more implicit one.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the spectrum of a kernel' and then specifically focuses on 'Matern kernels'. This clearly identifies a specific aspect of the paper being discussed. The reviewer further explains, 'However, another popular class of kernels such as Matern kernels are not included, since their spectrum only decay polynomially.' This provides a specific detail about the properties of Matern kernels, making the grounding quite explicit.", "verifiability_rationale": "The review point presents a claim: 'The authors assume that the spectrum of a kernel is subgaussian. This is OK, as the popular Gaussian kernels are in this class. However, another popular class of kernels such as Matern kernels are not included, since their spectrum only decay polynomially.' This claim is supported by the reviewer's explanation of the difference in spectral decay between subgaussian and polynomially decaying kernels. The reasoning is based on the known properties of these kernel types.", "helpfulness_rationale": "The review point offers a concrete suggestion: 'Consider including Matern kernels in your analysis.' This directly addresses a potential limitation identified in the previous points. By suggesting this, the reviewer is providing a clear direction for the authors to potentially improve their analysis by considering a different class of kernels."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the importance of unsupervised pretraining based on their analysis of Table 4. They also suggest focusing more on this aspect, which is a clear action the authors can take to improve their draft. The reviewer identifies the specific area (unsupervised pretraining) and provides evidence (Table 4) to support their claim.", "grounding_specificity_rationale": "The reviewer mentions 'unsupervised pretraining' and refers to 'Table 4' to support their claim. They also implicitly refer to the 'main paper' by stating it lacks discussion. While the exact section in the main paper isn't specified, the reviewer clearly identifies the area of concern and the type of evidence supporting the claim. The suggestion to 'focus more on the pretraining method' is also a specific direction.", "verifiability_rationale": "The reviewer makes a claim based on the data presented in Table 4, stating that unsupervised pretraining is a key factor. They also point out the lack of detailed discussion on this topic in the main paper. The claim is supported by the data in Table 4, which provides evidence for the reviewer's observation.", "helpfulness_rationale": "The reviewer identifies a specific weakness in the paper \u2013 the lack of detailed discussion on unsupervised pretraining, despite its apparent importance based on experimental results. They directly suggest a concrete improvement: focusing more on this pretraining method. This actionable feedback is directly relevant to the authors and addresses a potential area for enhancement in their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question ('How would we choose which ELM to pick?') and raises a concern ('Does this require us to know the speaker\u2019s gender beforehand?'). This constitutes an explicit action. The reviewer also points out the potential drawback ('This seems like a drawback') and asks for clarification ('i.e., at least in the cases where vocal traits match speaker identity'), indicating a clear action to be taken or understood.", "grounding_specificity_rationale": "The reviewer asks about choosing between 'male' and 'female' ELMs. While the question is about a specific choice, the underlying need is about the application of the ELM and its accuracy in a pipeline setting. The reviewer doesn't explicitly state they know the speaker's gender, making the grounding less about pinpointing a specific section and more about understanding a requirement. However, the reviewer is asking about the implications of this choice, which relates to the specific part of the paper dealing with gender detection.", "verifiability_rationale": "The reviewer states a concern about accuracy ('This seems like a drawback as the accuracy should be calculated after using a gender detection model in the pipeline'). This is a claim. However, the reviewer does not provide any evidence, justification, or references to support this claim. They state what they believe is a problem but do not explain why it's a problem or provide examples.", "helpfulness_rationale": "The reviewer's point provides some guidance on how to approach ELM selection by asking about the process and the need for gender information. However, the concern about accuracy in a pipeline is raised without any supporting evidence or justification. This makes the advice partially helpful but potentially less reliable due to the unsubstantiated concern."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out a lack of technical substance and simply adds a new loss. While the reviewer identifies a potential area for improvement (adding a new loss), they don't specify *how* to do this or what the implications would be. The action is stated, but the execution details are missing.", "grounding_specificity_rationale": "The reviewer mentions '31' but doesn't provide context or explain why this specific work is relevant or how the new loss relates to it. The reviewer doesn't explicitly state that this is the paper they are referring to, making the grounding weak. The reviewer doesn't explain *how* the new loss relates to or improves upon the work in '31'. The description is vague.", "verifiability_rationale": "The review states that the paper is 'incremental and does not have much technical substance.' This is a subjective assessment and a judgment about the paper's quality. It also states '31' is relevant and suggests adding a 'new loss,' which can be interpreted as a suggestion or request for change. Therefore, this review does contain a claim. The reviewer's claim is based on their opinion of the paper's novelty and the potential usefulness of adding a new loss. There's no concrete evidence or reasoning provided to *justify* why the paper is incremental or why adding a new loss is a good idea. It's presented as a statement of opinion.", "helpfulness_rationale": "The review criticizes the paper's lack of substance and suggests a potentially trivial change (adding a new loss). This is generally unhelpful for the authors as it doesn't pinpoint specific weaknesses or offer concrete, actionable improvements. It's more of a general critique without specific details on how to improve the paper based on the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly asks a question about the difference between two equations and their terms. While the question itself is not an explicit instruction, it implies a desire to understand the underlying reasons. Therefore, it can be considered somewhat explicit in its intent to improve understanding.", "grounding_specificity_rationale": "The reviewer directly refers to equations (7) and (10) and their terms X and H^(1). This demonstrates strong grounding as the specific parts of the paper are identified.", "verifiability_rationale": "The review point is a question seeking clarification, not a declarative statement that makes a claim about the paper. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The review point is a question seeking clarification about the difference between two equations and their terms. While it is helpful in guiding the authors' understanding, it does not directly identify a flaw or suggest a concrete improvement to the equations themselves."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out the 'main concern with the paper is the applicability of the model to realworld diffusion process'. While this identifies a problem, it doesn't explicitly state an action the authors should take to address it. The reviewer suggests 'providing empirical evidence', but doesn't specify how the authors should go about this. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer mentions 'the main concern with the paper is the applicability of the model to realworld diffusion process'. While they identify a concern, they don't specify which part of the paper this relates to. They don't mention a specific section, table, figure, or unique element of the paper. The issue is general and not tied to a specific part.", "verifiability_rationale": "The reviewer states 'the main concern with the paper is the applicability of the model to realworld diffusion process'. This is a statement of judgment or suggestion. The reviewer does not provide any specific evidence, logical reasoning, or external references to support this claim. There is no justification for why the model isn't applicable to realworld diffusion processes.", "helpfulness_rationale": "The review points out a valid concern regarding the realworld applicability of the model. However, it does not provide any specific guidance or suggestions on how the authors can address this concern. The reviewer suggests 'providing empirical evidence' but doesn't outline how the authors should conduct or present this evidence. The feedback is present but lacks actionable steps for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment implies an improvement is needed but doesn't explicitly state what should be done. The suggestion is vague and doesn't provide concrete steps for the authors to follow.", "grounding_specificity_rationale": "The comment doesn't specify which two datasets were used, making it weakly grounded. It also doesn't detail what aspects of the method's performance are limited by this testing, further reducing grounding specificity.", "verifiability_rationale": "The comment identifies a limitation (limited testing) but doesn't provide any justification or evidence for why this is a significant issue or how more datasets would solve it. It lacks references or logical reasoning to support the claim.", "helpfulness_rationale": "The comment raises a valid concern about the limited scope of the experiments and suggests a relevant improvement (testing on more datasets). This directly addresses a common issue in research and guides the authors towards further investigation, making it a helpful suggestion."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "1 (1 and Not Specific)", "verifiability_label": "3 (3)", "helpfulness_label": "1 (1)", "actionability_rationale": "the main contribution of combining attention with other linear mechanisms is not novel\" is a critique, not a prescription for change. It lacks specific action items.", "grounding_specificity_rationale": "the main contribution of combining attention with other linear mechanisms is not novel\" is a general statement and doesn't pinpoint a specific part of the paper or method where the lack of novelty is a problem.", "verifiability_rationale": "the main contribution of combining attention with other linear mechanisms is not novel\" contains a claim and provides a basis for verification by pointing to the reviewer's own observation in the paper. However, it lacks specific examples or references.", "helpfulness_rationale": "the main contribution of combining attention with other linear mechanisms is not novel\" is a critique, not a prescription for change. It lacks specific action items."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests a *plot* to visualize weight changes across layers after unlearning. This is an explicit action, as the reviewer directly states what they want the authors to do. The action is also concrete in the sense that it specifies the *type* of visualization (a plot) and the *purpose* of the visualization (to see how different layers are affected). While the exact *details* of the plot are not specified (e.g., what axes to use), the reviewer clearly identifies the *type* of visualization and its intended purpose.", "grounding_specificity_rationale": "The reviewer mentions 'how different different weights of the model move' and 'plot the relative weight change'. The reviewer explicitly identifies the *part* of the model being addressed (the weights of the model) and the *specific aspect* of those weights (the relative weight change). This demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer's suggestion is a request for a *plot* to visualize weight changes. While the suggestion itself is not a claim requiring verification, it implies a need for a specific type of analysis. The reviewer provides a clear *purpose* for the plot, which can be considered a form of implicit justification for why this visualization would be helpful. The suggestion is directly related to understanding the method's behavior.", "helpfulness_rationale": "The reviewer suggests a *plot* to visualize weight changes across layers after unlearning. This is a clear and actionable suggestion that directly addresses a potential need for the authors to understand how their method affects different parts of their model. The suggestion is directly relevant to improving their draft by providing a visual representation of the weight changes, which can aid in interpreting the unlearning process. While the exact details of the plot are not specified, the reviewer provides a clear direction for the authors to take."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer has identified a clear discrepancy between two definitions, specifically pointing out a potential conflict. They are explicitly stating that if Z' is the empty set, the definition implies conditional independence, but Equation (7) contradicts this. This is a direct and actionable observation of a potential error or lack of clarity in the theoretical framework. The reviewer is directly identifying a problem that needs to be addressed.", "grounding_specificity_rationale": "The reviewer's review point directly references specific elements of the paper: 'Lemma 2', 'Eq (7)', and 'the definition of minimal conditional dependence'. This demonstrates a strong grounding as the reviewer is pinpointing the exact location of the potential conflict within the provided text. They are not making a general statement but rather focusing on a specific part of the paper.", "verifiability_rationale": "The reviewer provides a logical argument based on the definitions of conditional independence and minimal conditional dependence. They are stating that if Z' is the empty set, the definition implies that x and y are independent given W, but Equation (7) contradicts this. This logical inconsistency is verifiable based on the definitions provided. The reviewer is not making a claim based on external knowledge but rather on the internal inconsistency of the presented definitions.", "helpfulness_rationale": "The reviewer's review point is 5 because it identifies a potential error or lack of clarity in the theoretical framework. By pinpointing the conflict between the definition of minimal conditional dependence and Equation (7), the reviewer is providing a concrete piece of feedback that could lead to a correction or clarification in the paper. The reviewer is not just pointing out a problem but also suggesting a direction for investigation (further clarification or proof)."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The authors identify a specific part of the paper (subscripts) and suggest a general improvement (enhancement). This points towards an actionable suggestion.", "grounding_specificity_rationale": "The authors explicitly refer to 'figure3' and specifically mention 'subscripts'. This demonstrates strong grounding as they identify a specific part of the paper.", "verifiability_rationale": "The authors make a statement about the 'subscripts' in 'figure3' and suggest they 'could be enhanced for better readability and aesthetic appeal'. This can be considered a claim, but lacks specific evidence or references to support it.", "helpfulness_rationale": "The review point directly points to a specific issue within a specific part of the paper (subscripts in figure3) and suggests a clear and actionable improvement (enhanced for better readability and aesthetic appeal). Authors would likely want to know how to improve the clarity of these subscripts. The suggestion is direct and specific enough to guide improvement once the authors locate figure3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a desire to understand how the archetype positions are updated after initialization. While the paper mentions the initialization method (FurthestSum) and the variables involved (Q and z_i), it does not provide a clear, explicit description of the update mechanism. The reviewer is pointing to a missing detail in the algorithm, which is a specific action the authors would need to take to improve their draft by understanding this update process.", "grounding_specificity_rationale": "The reviewer mentions 'Algorithm 2' and the variables 'Q' and 'z_i' in their comment. This indicates a reasonable level of grounding as the authors can identify the specific part of the paper being addressed. However, the comment does not specify *what* needs to be updated or *how* it should be updated. The reviewer is pointing to a missing detail within that specific section, rather than a fully specified action on their part.", "verifiability_rationale": "The reviewer makes a claim that the paper lacks clarity on how the archetype positions are updated. This claim is verifiable based on the provided text, as the paper describes the initialization but does not detail the update process. The reviewer's statement is a logical deduction based on the missing information in the paper. However, the paper could have provided more specific references or examples to support this claim.", "helpfulness_rationale": "The reviewer's question is directly relevant to understanding and potentially improving the algorithm. While the request itself isn't immediately providing a solution, it points to a missing piece of information that would be 5 for the authors trying to implement or understand the method. The reviewer is asking for a specific action (to explain the update) that is likely to be beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies limitations of the method (training at pixel level, independent training, highorder factor graph) and suggests areas for improvement (efficiency, comparison with existing work). While it points out potential issues, it doesn't explicitly state concrete actions or modifications the authors should make based on these observations. The suggestions are more like potential areas for future work rather than direct instructions for improvement.", "grounding_specificity_rationale": "The review point refers to the 'shape model' and 'parse model' generally, and mentions 'training and testing' in the context of these models. While it broadly touches on different aspects of the method, it doesn't pinpoint a specific section, table, or unique element of the paper that it is addressing. The references are general and don't provide a clear location for the authors to focus their attention.", "verifiability_rationale": "The review point criticizes the method and suggests improvements (e.g., 'It is timeconsuming'). It doesn't provide any external references or logical reasoning to support these claims. The criticisms are presented as statements of opinion without providing evidence or justification. The suggestions for improvement are also vague and lack specific details on how to achieve them.", "helpfulness_rationale": "The review point identifies valid concerns about the efficiency and complexity of the method and suggests improvements. However, it doesn't offer concrete, actionable suggestions for how the authors can improve their draft based on these observations. The suggestions are more like general recommendations rather than specific, stepbystep guidance. The overall tone is critical rather than constructive, making it less helpful in improving the draft itself."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states that the motivation is difficult to follow. While this implies a need for improvement, it doesn't explicitly state what needs to be changed or how. The criticism about being an 'incremental engineering paper' is vague and doesn't provide a concrete action.", "grounding_specificity_rationale": "The review point refers to the general 'motivation' of the paper without specifying a particular section, table, figure, or element. The criticism about being an 'incremental engineering paper' is also general and lacks specificity.", "verifiability_rationale": "The review point contains claims about the difficulty in following the motivation and the paper being an 'incremental engineering paper.' However, it does not provide any evidence, examples, or references to support these claims.", "helpfulness_rationale": "The review point identifies a general weakness (difficult to follow motivation and being incremental) but does not offer specific, actionable suggestions or examples of how to improve the paper. The feedback is at a relatively low level of specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review points out the lack of novelty and incremental nature of the work and identifies an alternative benchmark. However, it does not specify how the authors should address these weaknesses or implement the suggested alternative. The suggestions are general and lack concrete steps for improvement.", "grounding_specificity_rationale": "The review mentions the 'lack of novelty and incremental nature of work' and refers to 'the other synthetic benchmark paper'. While it identifies a weakness, it does not specify a particular section, table, figure, or unique element within the authors' paper that needs improvement. The reference to the alternative benchmark is more about the concept rather than a specific part of their work.", "verifiability_rationale": "The review states that 'a critical weakness of the paper is the lack of novelty and incremental nature of work'. This is a claim, but the review does not provide any evidence, data, or logical reasoning to support this claim within the review point itself. The reviewer identifies the problem but doesn't prove it.", "helpfulness_rationale": "The review identifies a potential area for improvement by suggesting an alternative benchmark. While it doesn't offer concrete solutions, it provides context and highlights a potential limitation of the current approach. This information can help the authors understand their work's place in the field and consider alternative directions. It's better than a completely generic criticism that offers no specific guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for *explanations* and *interpretations* of the experimental setting and the results presented in Figure 3. While they are pointing out areas where more detail is needed, the action is to *understand* rather than *apply* a specific change. The request is to explain, not to add. The reviewer is not explicitly stating what needs to be done, but rather asking what needs to be done and why.", "grounding_specificity_rationale": "The reviewer mentions 'Fig 3' but does not specify which parts of the figure or method they are referring to. The phrase 'I Fig 3' suggests they are aware of the figure's existence but lack precise identification. This indicates weak grounding as the authors need to determine the specific area of focus themselves.", "verifiability_rationale": "The reviewer is asking questions about the correspondence between learning curves and MPHATE, the interpretation of 'worse performing model', and the presence of accuracy numbers. While they are asking for *justification* and *explanation*, there is no explicit claim being made in the review point itself. The request is to *understand* the implications of the results, not to *validate* a claim made elsewhere. The questions are about interpretation, not logical reasoning or external references within this specific point.", "helpfulness_rationale": "The reviewer is asking for *explanations* and *interpretations* of the experimental setting and the results presented in Figure 3. While this can be helpful for the authors to understand the paper better, it is not a direct instruction on how to *improve* their draft. The request is to *understand* rather than to *apply* a specific change. The reviewer is not telling the authors *what to do*, but rather asking what needs to be done and why. The helpfulness is limited to gaining a better understanding of the presented work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests exploring labeled consistency training but doesn't provide explicit steps or propose a concrete change to the current method. While the suggestion is relevant, it lacks actionable steps, making it 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions the area of graph anomaly detection and names two relevant papers, providing strong grounding and specific examples. This can be achieved through:  Literally mentions sections, tables, figures, etc.  Mentions unique elements of the paper.  General comments that clearly imply the relevant parts without explicitly naming them. In this case, the reviewer names the area of application (graph anomaly detection) and provides specific references related to graph contrastive learning, which falls under the 'Literally mentions sections, tables, figures, etc.' category as the papers are directly relevant to the suggested technique. The comment clearly specifies what needs to be addressed in this part (exploring labeled consistency training).", "verifiability_rationale": "The reviewer poses a question about the potential benefit of labeled data in consistency training and suggests that exact labels might provide effective information. This constitutes a claim. However, the claim lacks direct empirical verification within the review itself. The suggestion also mentions the potential for labeled data to provide 'effective information' for consistency training the model in dealing with the task of graph anomaly detection. While the reviewer doesn't provide a definitive proof, they offer a plausible hypothesis based on the nature of labeled data and the task. The claim is not definitively proven, but it's supported by logical reasoning and the suggestion to use existing research on graph contrastive learning as potential evidence. The claim is not definitively proven, but it's supported by logical reasoning and the suggestion to use existing research on graph contrastive learning as potential evidence.", "helpfulness_rationale": "The reviewer offers a suggestion about exploring labeled consistency training for graph anomaly detection. This is relevant to the task and points towards a potentially valuable area of improvement. While the suggestion doesn't provide a direct solution, it offers a direction for further research and experimentation. The reviewer also names two relevant papers, which provides context and potential avenues for investigation. The suggestion is directly related to the task of graph anomaly detection and offers a concrete direction for improvement by suggesting a different training paradigm. The reviewer's suggestion is directly relevant to the task and offers a concrete direction for improvement by suggesting a different training paradigm. While it doesn't provide a complete solution, it offers a valuable perspective and a potential area for further exploration."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies the need for reorganization in the experimental section and points to a lack of highlighting of the method's superiority. However, it does not explicitly state what aspects of the experimental section need reorganization or how the reorganization should be conducted. The suggestion to focus on the content that highlights superiority is a direction but lacks specific details on what constitutes 'better' or how to achieve this highlighting. Therefore, while the general problem is identified, the specific actions and their implementation are not clearly defined.", "grounding_specificity_rationale": "The review point mentions 'the experimental part needs to be reorganized' and 'experimental content...does not highlight the superiority of the method'. While the issue is specific, the reviewer does not explicitly identify a particular section, table, figure, or unique element of the experimental section that requires reorganization. The focus is on the section broadly, making the grounding somewhat implicit.", "verifiability_rationale": "The review point contains a claim: 'the experimental part needs to be reorganized' and 'experimental content...does not highlight the superiority of the method'. However, within this review point itself, there is no explicit justification, evidence, or logical reasoning provided to support these claims. The reviewer states the problem they believe exists but does not offer any examples, references, or explanations within this point. Therefore, the claim is stated but not fully justified within this review.", "helpfulness_rationale": "The review point identifies a potential weakness in the experimental section ('the experimental part needs to be reorganized') and suggests focusing on content that highlights the method's superiority ('experimental content...does not highlight the superiority of the method'). However, it lacks specific, actionable guidance on how to reorganize the experimental section or how to better highlight the method's superiority. The suggestions are general directions rather than concrete steps for the authors. Therefore, while the point points to an area for improvement, it does not provide sufficient detail to be 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a contrasting viewpoint regarding the applicability of SGC compared to PEFT methods, specifically mentioning that PEFT methods are typically for computeconstrained scenarios. They also suggest a concrete action: 'include a plot with sparsity on the xaxis and performance on the yaxis'. This makes the criticism actionable for the authors.", "grounding_specificity_rationale": "The reviewer suggests a *type* of plot (visualization) with specific axes (sparsity and performance). While they hint at the *area* of comparison (flexibility vs. practicality), they don't explicitly name a specific section or table in the paper where this comparison should be made. The suggestion is about the *form* of the comparison, not the *location*.", "verifiability_rationale": "The reviewer makes a claim about PEFT methods and suggests a way to verify it by including a specific type of plot. They provide a clear claim and a direct suggestion for verification, which supports the claim's verifiability.", "helpfulness_rationale": "The review point clearly criticizes a claim about SGC's applicability and offers a concrete suggestion for improvement by including a specific visualization. The language is direct and constructive, aiming to help the authors address the identified limitation."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question about the training time discrepancy between the German and Law school datasets in Experiment 2 and suggests a concrete action: publishing the code. This demonstrates a clear intention to provide actionable feedback.", "grounding_specificity_rationale": "The reviewer refers to specific experiments (Experiment 2), methods (ERM, plugin, Kearns et al.), and datasets (Gerrymandering, Independent). This indicates a strong attempt to ground the feedback in specific parts of the paper. The suggestion to publish code, while not directly related to the datasets, is also a specific request.", "verifiability_rationale": "The reviewer does not explicitly state a claim. They are posing a question and suggesting a practical improvement (code publication). Therefore, this review point does not contain a claim and is classified as 'X'.", "helpfulness_rationale": "The reviewer's question about the training time discrepancy is a valid point that could help the authors understand the experimental setup better. The suggestion to publish the code is a direct way to improve the reproducibility and impact of the work. While the suggestions are valuable, they don't directly identify a flaw in the methodology itself, but rather a potential issue in the experimental setup or reporting. The helpfulness is good but not groundbreaking."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the human baseline follows significantly less data (1 hour vs. 15 hours) compared to the model baseline. This is an explicit observation about the potential for the human baseline to be limited by the amount of data. While the reviewer doesn't provide concrete steps the human should take, the observation itself is a clear indication of a potential weakness in the human baseline. Therefore, the reviewer provides an explicit action that the human should consider when evaluating their model's performance.", "grounding_specificity_rationale": "The reviewer refers to the 'abstract' and the comparison to the 'human baseline' in the model's performance. While the reviewer doesn't pinpoint a specific section, table, or figure within the abstract, the reference to the abstract and the comparison is a clear indication that the reviewer is addressing a specific part of the paper where the human baseline is discussed. The comment is not a general statement but rather focuses on a particular aspect of the comparison. Therefore, the grounding is somewhat specific.", "verifiability_rationale": "The reviewer states that the human baseline is 'already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources'. This is a claim made in the abstract. However, the reviewer does not provide any external references or logical reasoning to support this claim within this review point itself. The claim is presented as a statement of fact without further justification. Therefore, the claim is not 5 based on the information provided in this review point.", "helpfulness_rationale": "The reviewer points out a crucial difference between the human and model baselines, highlighting that the human's performance is likely limited by the amount of data they follow. This provides valuable context for the authors when interpreting their model's performance. While the reviewer doesn't offer specific suggestions for improvement, they do identify a potential weakness in the human baseline. This information is helpful for the authors to consider when evaluating their results and understanding the limitations of the human baseline. Therefore, the review point is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that RL methods are missing from the related work and that these methods are used as baselines. This directly points to a specific area for improvement, making it 5.", "grounding_specificity_rationale": "The review point mentions 'related work' and 'RL methods' generally. While it identifies the area of concern, it does not specify a particular related work or a specific aspect of RL methods, resulting in weak grounding.", "verifiability_rationale": "The review point makes a claim about the use of RL methods as baselines in related work. This claim is generally verifiable based on common knowledge in the field of NMT.", "helpfulness_rationale": "The review point identifies a valid gap in the related work and suggests a concrete improvement (including RL methods as baselines). This is likely to be helpful for the authors, although it lacks specific guidance on which RL methods to consider."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential ambiguity in the term 'Efficient Proxy' but does not explicitly state what action the authors should take to resolve this ambiguity. While the reviewer points out the difference between a 'particular efficient proxy' and 'efficient proxies in general', they do not provide a concrete step for the authors to clarify their usage of the term.", "grounding_specificity_rationale": "The reviewer explicitly mentions the term 'Efficient Proxy' and further clarifies the ambiguity by distinguishing between 'a particular efficient proxy' and 'efficient proxies in general'. This clearly identifies the specific part of the paper (or concept) being discussed and the issue within it.", "verifiability_rationale": "The reviewer's comment is a statement of clarification and asks for more information, specifically about the authors' understanding of 'Efficient Proxy'. It does not contain a claim that requires verification or justification.", "helpfulness_rationale": "The reviewer's comment seeks to understand the authors' intent and provide context regarding the term 'Efficient Proxy'. While it doesn't directly offer a solution or suggestion, it contributes to a better understanding of the paper's context and helps the authors clarify their work. It is not entirely useless, but it doesn't immediately improve the draft either."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the methods are 'stacked' and then 'DBSCAN' is used. This is a clear indication of an action: the authors should investigate whether the complex methods are necessary or if DBSCAN is sufficient. The reviewer also infers a potential redundancy, which is a concrete action the authors can take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Mirzasoleiman et al., 2020', 'Grouplearning setting', and 'DBSCAN'. This is explicit grounding, as the authors can directly identify the specific parts of the paper being referred to.", "verifiability_rationale": "The reviewer makes a claim: 'They stack the methods... and then use one classical method DBSCAN to cluster.' The reviewer also provides a reasoning: 'This could indicate a lack of novelty or a potential inefficiency.' This claim is verifiable by examining the paper's methodology and comparing it to the cited works. The reasoning is logical and points to a potential issue.", "helpfulness_rationale": "The reviewer's point is 5. It identifies a potential area for simplification or a lack of novelty. It provides a clear suggestion for the authors to consider the necessity of combining complex methods with a simpler one. This is actionable and constructive."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests an experiment to investigate the impact of different random projection matrices on the MFTMA scores. This is a clear and actionable suggestion for the authors. They are proposing a specific experiment (resilience test) to determine the robustness of the metric.", "grounding_specificity_rationale": "The reviewer mentions 'pathological projection matrices' and 'random projection matrices' by name, and suggests an experiment to test the resilience of MFTMA scores. This clearly identifies the area of concern and the method being investigated. The suggestion to test resilience is also specific to the method and the metric being evaluated.", "verifiability_rationale": "The reviewer makes a claim about the potential for skewing MFTMA scores with pathological random projections. They also suggest an experiment to verify this claim. This is a verifiable suggestion, as the experiment directly tests the claim about the metric's behavior under different conditions.", "helpfulness_rationale": "The reviewer provides a concrete suggestion for an experiment to address a potential limitation of the MFTMA method. This directly helps the authors understand the method's robustness and reliability. The suggestion is actionable and directly addresses a potential issue with the metric."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for an example of synthetic data, which is an actionable suggestion for the authors to provide. It also implicitly suggests that the authors should clarify the terms 'support data' and 'predicted training count data'. While the action is clear, the specific implementation or transformation of the synthetic data is not explicitly stated, making it somewhat vague on how to execute this action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'synthetic data', 'Figure 1', 'support data', and 'predicted training count data'. They also ask for the 'model used here explicitly'. This clearly identifies specific parts of the paper and the concepts being discussed, making it fully grounded.", "verifiability_rationale": "The reviewer is not making a claim that needs to be verified. Instead, they are pointing out areas where the authors could improve their writing and methodology description. The suggestion to provide more detail is verifiable in that it's a request for information that would improve the paper. However, the reviewer is not providing evidence to support a claim, so it's not 5.", "helpfulness_rationale": "The review point directly asks for clarifications and provides specific suggestions for the authors to improve their draft. The reviewer requests an example of synthetic data, clarification on terminology in Figure 1, and the explicit model used. These are all actionable and directly address potential weaknesses or lack of clarity in the paper. The suggestions are clear and would empower the authors to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential issue ('overly simple') but doesn't explicitly state what needs to be done. It suggests exploring alternatives, but doesn't specify *how* to make the model more complex or what aspects to consider.", "grounding_specificity_rationale": "The comment is a general assessment of the model's simplicity and doesn't specify which part of the model or the paper is being referred to.", "verifiability_rationale": "The comment is a subjective opinion ('seems overly simple') and lacks any supporting evidence, logical reasoning, or references.", "helpfulness_rationale": "The comment identifies a potential area for improvement (simplicity) but lacks specific, actionable advice on how to make the model more complex. It's a suggestion but not a detailed guide."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point is a declarative statement about the paper's focus, not a directive asking the authors to do something. There's no 'how to' element.", "grounding_specificity_rationale": "The phrase 'narrow task (climate change QA) in a specific language (Arabic)' directly and precisely identifies a section or aspect of the paper.", "verifiability_rationale": "The statement about the 'broader impact' is an opinion, not a claim that can be supported by evidence *within the paper* itself. It's a generalization about the potential influence of the work.", "helpfulness_rationale": "The review point identifies a limitation, which is valuable information, but it doesn't offer any actionable steps or insights on how to improve the paper's broader impact. It's more of a statement of fact about the paper's scope rather than a constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "1", "actionability_rationale": "The reviewer raises a concern about the novelty of the paper's findings in light of previous work using the 'winnertakeall' property. While the reviewer points out that this property has been used in NNbased clustering algorithms, the paper does not explicitly state how the current work contributes novelly beyond this. The reviewer's statement is a claim that lacks specific actionable steps or concrete suggestions on how the paper advances the field. The reviewer does not identify a specific part of the paper being addressed, making it difficult to ground the criticism. The reviewer's statement is a claim that lacks specific actionable steps or concrete suggestions on how the paper advances the field.", "grounding_specificity_rationale": "The reviewer mentions 'previous works such as NNbased clustering algorithms 1' and 'Sec 5' as examples, indicating a degree of grounding. However, the reviewer does not explicitly state which specific part of the paper the criticism refers to. The mention of 'previous works' and 'Sec 5' suggests an attempt to ground the criticism, but the lack of a precise reference point makes it only partially grounded.", "verifiability_rationale": "The reviewer makes a claim that the paper's findings are similar to previous work and questions the contribution. The reviewer provides examples (NNbased clustering algorithms 1) and a reference point (Sec 5) to support their claim. The claim is that the paper's findings are not novel due to prior work using the 'winnertakeall' property. The reviewer provides a logical reasoning by pointing out the similarity to previous work and the simplified settings. The reviewer also provides external references (NNbased clustering algorithms 1) to support their claim.", "helpfulness_rationale": "The reviewer states that the paper's findings are similar to previous work and questions the contribution. The reviewer's tone is critical and questions the value of the work, which is generally not helpful for the authors. They do not offer alternative approaches or specific suggestions to improve the paper. The reviewer's statement is a negative assessment with no clear positive takeaways for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two explicit suggestions: (1) to mention the negligible computational cost of CHR in the main paper and (2) to include runtime examples. These are direct actions the authors can take to improve their draft. The reviewer clearly states the *what* and *how* of the suggestion, making it actionable.", "grounding_specificity_rationale": "The reviewer explicitly states the *where* of the suggestion by mentioning the 'main paper' and the *what* by detailing the two suggestions: mentioning the computational cost and including runtime examples. While they don't provide a specific section number, they clearly imply the main paper as the target location, making it grounded. They also specify the *how* by detailing the suggestions.", "verifiability_rationale": "The reviewer provides concrete suggestions with a clear intent. The claim that the suggestions are ' helpful' is supported by the fact that they directly address a practical concern (computational cost) and aim to improve the paper's impact by making the method more accessible. The reviewer's intention to provide examples also supports the claim. While no external references are given, the suggestions are based on commonsense knowledge and the reviewer explicitly states their intention to provide examples, making it verifiable.", "helpfulness_rationale": "The reviewer's suggestions are directly aimed at improving the paper's clarity and practical applicability. By mentioning the computational cost in the main paper, the reviewer helps motivate the method for a broader audience. Including runtime examples provides concrete evidence of the method's efficiency and assists readers in applying it. These suggestions are clear, actionable, and directly address a practical concern, making them 5 for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the purpose of Figure 3 and provides specific suggestions for improvement, indicating a clear action. The reviewer also specifies the aspect of the figure they are concerned about (interpretation) and what they want to know (the role of spatial arrangement), making the action very concrete.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 3' by name, which is a clear and direct reference to a specific part of the paper. Furthermore, the reviewer specifies the type of ambiguity they found ('interpretation') and what they want to know ('the role of spatial arrangement'), adding detail to the reference and making it specific.", "verifiability_rationale": "The reviewer does not make a claim about what is wrong with the figure or the process. Instead, they identify a problem (ambiguity) and suggest a step to address it (elucidate the procedure). While the suggestion is valuable, it does not involve a claim that requires verification based on logical reasoning, common knowledge, or external references. Therefore, it leans towards 'X'.", "helpfulness_rationale": "The reviewer provides specific feedback about a figure and asks a targeted question. This directly addresses a potential ambiguity and encourages the authors to seek clarification on a specific aspect. This is a clear and actionable piece of feedback that directly informs how the authors should interpret the figure and what information is crucial for the token quantization process."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment suggests an alternative approach (polynomial time check) but does not explicitly state what the authors should do with the information about the current 'polynomial time' check on the 'tabular case'. It implies a desire for a more direct check, but the action is not clearly defined.", "grounding_specificity_rationale": "The comment explicitly mentions 'polynomial time' check and the 'tabular case', providing a clear and specific reference point within the authors' work. This allows the authors to identify the exact aspect being discussed.", "verifiability_rationale": "The comment is not a claim that requires verification. It is a suggestion for a different approach, not a statement that needs to be proven or supported by evidence.", "helpfulness_rationale": "The comment asks a question and suggests an alternative approach. While it doesn't directly state the benefits of the alternative, it provides a point of discussion and encourages the authors to consider a different method for checking the Witness oracle."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests an action: 'compare with existing code completion commercial applications, such as Copilot.' This action is clear and directly addresses a potential improvement for the RepoEval benchmark. The suggestion is not implicit but rather stated directly. The action is also concrete, as it specifies the type of comparison and the model to be used (Copilot).", "grounding_specificity_rationale": "The review point mentions 'RepoEval' and 'Copilot' as specific elements. It explicitly states the purpose of the comparison: 'to compare with existing code completion commercial applications, such as Copilot, and it is essential to compare with these stateoftheart code completion systems.' This demonstrates a clear identification of the relevant parts of the paper and the specific issue being addressed.", "verifiability_rationale": "The review point contains a claim: 'I suggest that the authors compare...'. However, it does not provide any specific justification or reasoning for why this comparison is necessary or beneficial. While the suggestion is related to improving the benchmark, it lacks concrete evidence or examples to support its validity. There are no external references or logical reasoning provided to back up the claim.", "helpfulness_rationale": "The review point directly suggests a specific and relevant improvement for the RepoEval benchmark: comparing it with stateoftheart code completion systems. This is a clear and actionable suggestion that directly addresses the paper's evaluation scope. The reviewer provides a concrete example (Copilot) and a purpose (to identify areas for improvement). This makes the suggestion immediately useful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'The choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB)' which is a clear action. Furthermore, the reviewer directly identifies the implication of this choice, 'raises questions about generalizability', making the action quite direct and understandable. The reviewer also suggests 'whether other tasks or datasets might yield different insights', which is a clear action to investigate further.", "grounding_specificity_rationale": "The reviewer mentions 'MTEB' and 'subset' which provides some grounding. However, the reviewer does not explicitly state which specific subset of MTEB was used. The reviewer also states 'raises questions about generalizability' without specifying what those questions are or providing any examples. Therefore, while the general area is mentioned, the specific part and the nature of the questions are not clearly identified, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer states 'The choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB) raises questions about generalizability'. This is a claim that needs to be supported. However, the reviewer does not provide any logical reasoning, examples, or external references to back up this claim. The reviewer simply states the implication without explaining why this is a concern or what specific questions are being raised. Therefore, the claim is not wellsupported, making the verifiability borderline.", "helpfulness_rationale": "The reviewer asks 'whether other tasks or datasets might yield different insights'. This is a valuable question for authors as it prompts them to consider the limitations of their evaluation strategy and whether alternative approaches might be more appropriate. While the reviewer does not provide a direct solution or suggestion, the question itself is a constructive point for discussion and potential improvement, making it 3 in that context."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer is pointing out a lack of clarity in a specific experimental setup (shifted MNIST) and suggesting a valuable experiment. While the reviewer's point is helpful in identifying a potential area for improvement, it does not directly instruct the authors on what specific action to take. The suggestion is more of an observation and a hint towards a potential experiment rather than a direct command to perform a specific action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'shiftedMNIST\" and highlights the difference between `shift=0` and `shift~ N ( 0 , \u03c3 2 )`. This clearly identifies the specific part of the paper and the issue being addressed. The reviewer also suggests a specific experiment, further grounding the feedback in a concrete aspect of the work. The language used is precise and directly refers to the described experimental setup.", "verifiability_rationale": "The reviewer states that the difference between `shift=0` and `shift~ N ( 0 , \u03c3 2 )` is unclear. However, the reviewer does not provide any justification or reasoning to support this claim. There are no references to external knowledge or logical arguments presented to explain why this difference might be unclear. The statement is presented as a fact without any supporting evidence.", "helpfulness_rationale": "The reviewer points out a potential ambiguity in the experimental setup of shifted MNIST and suggests an experiment to test performance on the observational distribution. While the reviewer does not provide a direct solution or action item, the feedback is valuable and points towards a potential area for clarification and further experimentation. This type of feedback is generally helpful for improving the clarity and rigor of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: 'As I just mentioned, the paper only analyzed, under which cases will the Algorithm 1 converges to permutations as local minima.' This directly points to a lack of analysis regarding the quality of these local minima. The reviewer also suggests an improvement: 'However, it will be better if the quality of this kind of local minima could be analyzed (e.g. the approximation ratio of these local minima, under certain assumptions).' This suggests a concrete action: to analyze the quality. The action is also quite specific, mentioning 'approximation ratio of these local minima, under certain assumptions'.", "grounding_specificity_rationale": "The reviewer refers to 'Algorithm 1' and 'permutations as local minima', which are specific parts of the paper. They explicitly identify the issue as the 'quality of these local minima' and even suggests a specific metric for analysis: 'e.g. the approximation ratio of these local minima, under certain assumptions'. This demonstrates strong grounding as the specific elements are mentioned and a specific suggestion is made.", "verifiability_rationale": "The reviewer states a suggestion for improvement: 'it will be better if the quality of this kind of local minima could be analyzed (e.g. the approximation ratio of these local minima, under certain assumptions)'. This constitutes a claim that the paper should address. However, the reviewer does not provide any immediate evidence or logical reasoning to support why analyzing the quality of these local minima is necessary or beneficial. While the suggestion is reasonable, it lacks direct verification within the review itself.", "helpfulness_rationale": "The reviewer clearly identifies a limitation in the paper's analysis of Algorithm 1, specifically the lack of analysis on the quality of the local minima. They directly suggest a concrete improvement: 'it will be better if the quality of this kind of local minima could be analyzed (e.g. the approximation ratio of these local minima, under certain assumptions)'. This is a specific and actionable piece of feedback that directly targets a potential weakness in the paper and proposes a clear direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer is asking how information redundancy is built into the algorithms. The paper mentions 'duplicates the initial input tensor across multiple processing units before propagation' in the Fill algorithm and 'a collection of learnable parameters that are shared across these processing units' in the weight pool. While the paper describes the *outcome* (information redundancy), it doesn't explicitly state the *action* of how this redundancy is *implemented* within the algorithms. The reviewer is asking for a more detailed explanation of the mechanisms involved.", "grounding_specificity_rationale": "The reviewer is asking how information redundancy is built into the algorithms. The paper mentions 'duplicates the initial input tensor across multiple processing units before propagation' in the Fill algorithm and 'a collection of learnable parameters that are shared across these processing units' in the weight pool. The paper also states 'This sharing further amplifies the redundancy and contributes to the model's robustness against noise.' This provides some grounding by specifying the location of the shared parameters. However, it doesn't explicitly identify the *specific* part of the paper being addressed (the algorithms themselves) with high confidence, making it only partially grounded. The grounding is also somewhat specific as it focuses on the weight pool.", "verifiability_rationale": "The reviewer is asking how information redundancy is built into the algorithms. The paper mentions 'duplicates the initial input tensor across multiple processing units before propagation' in the Fill algorithm and 'a collection of learnable parameters that are shared across these processing units' in the weight pool. The paper also states 'This sharing further amplifies the redundancy and contributes to the model's robustness against noise.' This claim is supported by the description of the weight pool, making it 3. The reasoning is clear, and the external reference is the description of the weight pool itself, although it could be strengthened by more explicit connections between weight sharing and redundancy.", "helpfulness_rationale": "The reviewer is asking how information redundancy is built into the algorithms. The paper mentions 'duplicates the initial input tensor across multiple processing units before propagation' in the Fill algorithm and 'a collection of learnable parameters that are shared across these processing units' in the weight pool. The paper also states 'This sharing further amplifies the redundancy and contributes to the model's robustness against noise.' This provides a clear and actionable feedback on how to improve the model's robustness. The suggestions are directly linked to specific parts of the model (algorithms and weight pool), making it 5. The feedback is actionable and constructive."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point implicitly suggests an action by asking 'How important is the added complexity?' and 'Will one IN do?'. These questions imply that the authors should investigate the impact of this design choice. However, the reviewer does not explicitly state the steps or methods for this investigation, making it only implicitly actionable. The reviewer also does not specify the exact nature of the ablation studies, leaving the authors to infer the necessary steps.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'multiple INs at different speeds in the dynamics predictor,' which is a specific technical detail within the paper. This allows the authors to identify the relevant section. While the reviewer also uses the general term 'a seemingly important novel feature,' this does not hinder the identification of the specific implementation detail. Therefore, the grounding is strong, although it could be more focused on the ablation aspect itself.", "verifiability_rationale": "The review point contains a claim: 'This design choice is not ablated.' The reviewer also poses questions ('How important is the added complexity? Will one IN do?') that require further investigation and justification. While the reviewer does not provide explicit justification for this claim, the questions themselves suggest a need for empirical evidence (ablation studies). Therefore, the claim is 3.", "helpfulness_rationale": "The review point is 5 as it directly points out a potential weakness in the model's design (the lack of ablation for the multiple INs) and asks targeted questions that guide the authors towards further investigation. This provides a clear direction for the authors to improve their draft by conducting additional experiments. The reviewer's questions are specific and actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for experimental results 'of excluding such mixup technique from the proposed method' in the context of 'the experiments on SplitCIFAR100 and SplitTinyImageNet'. This clearly indicates an action the authors should take: conduct experiments excluding the mixup technique on these specific datasets. The action is directly stated, making it explicit.", "grounding_specificity_rationale": "The reviewer identifies the 'experiments on SplitCIFAR100 and SplitTinyImageNet' as the specific context where the mixup technique is being questioned. While the reviewer doesn't explicitly state *which* part of the paper these experiments are addressing, the mention of specific datasets strongly implies they are referring to a particular section or table detailing the experimental setup. However, the reviewer doesn't pinpoint the exact section, table, or unique element being addressed, making the grounding somewhat weak. The specificity of the request is high within the context of those experiments, but the broader grounding is lacking.", "verifiability_rationale": "The reviewer makes a claim: 'there should be experimental results of excluding such mixup technique from the proposed method in the experiments on SplitCIFAR100 and SplitTinyImageNet'. This claim is supported by the lack of such experiments. The reviewer provides a clear statement of what evidence is missing. The claim is directly related to the experimental setup and the impact of a specific technique. The evidence provided (the absence of the requested experiment) is sufficient to verify the claim.", "helpfulness_rationale": "The reviewer's request for 'experimental results of excluding such mixup technique from the proposed method' is a highly valuable suggestion for the authors. It directly addresses a potential contribution of the mixup technique and would significantly help them understand its impact on the proposed method's performance. The request is specific and directly targets a potential weakness or contribution of the method. The potential benefit to the authors is significant."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer requests more information about how the network fits the residual. While they don't explicitly state it's missing, their phrasing suggests it's not readily apparent or described. The request is for a general process, which is vague. There's no explicit instruction or implicit assumption revealed that directly points to a specific action the reviewer should take regarding this aspect.", "grounding_specificity_rationale": "The reviewer refers to 'the training of the network' generally, without specifying a particular section, algorithm, or detail within the training process. This lack of specificity makes it difficult to pinpoint the exact issue. The reviewer doesn't identify a unique element of the paper they are referring to, making the grounding weak. While they express a concern, they don't narrow down the scope to a specific part of the network or the training procedure.", "verifiability_rationale": "The reviewer states, 'I can't find details on how they make the network fit the residual instead of directly learning the input  output mapping.' This statement itself is a claim that needs verification. However, the reviewer does not provide any evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up their assertion that the details are missing. The statement is presented as a fact without justification.", "helpfulness_rationale": "The reviewer's comment identifies a specific area of the paper (the network's training and its relation to residual learning) that they find unclear. This points to a potential weakness in the paper's explanation or presentation. By highlighting this gap, the reviewer is providing valuable feedback that can help the authors improve their clarity and completeness. While the comment itself isn't a direct suggestion for improvement, it identifies a specific issue that needs addressing."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "None", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for information about the experiment setup, which can be considered an actionable request as it points to a missing element that could be improved. However, the request is quite general and doesn't specify exactly what information is needed, making it only 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3.3', which grounds the request to a specific part of the paper. However, the request itself is quite general and doesn't specify the exact details of the experiment setup within that section. Therefore, it is weakly grounded but not specific about the content.", "verifiability_rationale": "X", "helpfulness_rationale": "The request points to a missing piece of information that is generally useful for understanding and potentially improving the work. However, the lack of specificity makes it less actionable and potentially misleading if the authors haven't read the BadNets paper. Therefore, it is 3 as it identifies a missing detail, but not very helpful in its current form."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly mentions 'steps 1 & 2' of the algorithm and 'speed disparities observed between the RSPs and FDs'. This indicates an explicit action or suggestion. Furthermore, it is a concrete action as it points to specific parts of the algorithm and a specific observation. However, it does not directly tell the authors what to do with these steps or the observation.", "grounding_specificity_rationale": "The review point mentions 'steps 1 & 2' of the algorithm and 'speed disparities observed between the RSPs and FDs'. This indicates that the authors can identify the specific part of the paper being addressed, making it fully grounded. Additionally, the review points out a specific observation, making it specific about the issue. However, it does not explain *why* these steps are problematic or *how* the RVC algorithm works in detail.", "verifiability_rationale": "The review point makes a claim: 'I wonder if an error in the initial calibration steps (steps 1 & 2) occurred that might explain the speed disparities observed between the RSPs and FDs.' This is a claim that requires verification. However, the review point does not provide any evidence, reasoning, or references to support this claim. It is a hypothesis without justification.", "helpfulness_rationale": "The review point suggests a potential cause for the observed speed disparities and recommends citing the RVC paper. While this points to a potential issue and offers a potential solution (citing a paper), it does not directly guide the authors on how to investigate or fix the problem. It is a suggestion without detailed steps or analysis."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points out a difference between artificial and biological networks. While it states a fact, it doesn't directly tell the authors what to do or how to address this difference. It's a statement of a known issue, not a direct instruction for improvement.", "grounding_specificity_rationale": "The review mentions \"artificial networks trained using ASAP\" and \"biological networks,\" which are specific concepts. However, it states a general relationship between these concepts (\"do not necessarily resemble\") without pinpointing a specific part of ASAP or a specific aspect of biological networks that causes this difference. The grounding is implicit rather than explicit.", "verifiability_rationale": "The review contains a claim: \"the artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks (other than the weight transport problem, which is of arguable importance)\". This claim is generally verifiable within the field of neural networks, as the structural differences between artificial and biological networks are a recognized concept. However, the claim doesn't provide specific examples or references to support this assertion, making it somewhat general.", "helpfulness_rationale": "The review is a critique of a specific technique (ASAP) and its perceived limitations compared to biological networks. While it raises a valid point, it doesn't offer concrete suggestions or actionable steps for the authors to improve their work based on this observation. It's a statement of a difference, not a direct path to improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks 'did you do any statistical significance test?' which is a direct question about a methodological choice. This constitutes an explicit action, but the action itself is vague as it doesn't specify the test or the reasoning behind not doing it.", "grounding_specificity_rationale": "The reviewer asks a question related to statistical significance, which is relevant to the comparison between the proposed method and baselines. However, the reviewer does not explicitly identify the specific part of the paper or methodology being addressed in relation to the statistical significance test. The connection is implied but not clearly stated, leading to weak grounding. Furthermore, the question is general and does not specify the type of statistical test considered or the expected outcome, making it not specific.", "verifiability_rationale": "The reviewer asks a question, which is a request for information rather than a declarative statement of a claim. Therefore, there is X, and the label would be 'X'. While the question is relevant to verifying the statistical significance of the results, the absence of a claim means the verifiability framework doesn't directly apply to this specific point.", "helpfulness_rationale": "The reviewer's question directly addresses a crucial aspect of the experimental methodology \u2013 the statistical significance of the results. This is a highly relevant and potentially helpful point as it probes the validity and interpretation of the findings. While it's a question and not a direct suggestion, it points to a potential weakness in the analysis and encourages the authors to consider the statistical rigor of their comparison. Therefore, it is 3 as it highlights a potential area for improvement in their methodology."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem ('it does not become clear how those emission distributions affect inference') and provides a clear direction ('Which of the common inference tasks...'). This is an explicit action and a concrete suggestion on how to address the issue.", "grounding_specificity_rationale": "The reviewer mentions 'common inference tasks in a discrete HMM' and specifically names 'filtering, smoothing, marginal observation likelihood'. This is a clear identification of the relevant concepts and specific tasks, making it 5.", "verifiability_rationale": "The reviewer makes a clear statement about a gap in the paper ('it does not become clear how those emission distributions affect inference') and poses a specific question ('Which of the common inference tasks...'). This constitutes a claim that needs verification. While the answer isn't provided, the request itself is a verifiable claim pointing to a specific area of expertise and a clear direction for investigation.", "helpfulness_rationale": "The reviewer clearly identifies a gap in the paper and provides a specific direction for improvement by asking a targeted question. This directly helps the authors understand the impact of emission distributions on inference."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking for a justification for a specific limitation in the experimental setup (the number of datasets used for comparison). While the reviewer doesn't explicitly state what action they would like to take, they are prompting for clarification on a discrepancy between the claimed and actual number of datasets. This falls under the 'implicit' category as the reviewer is seeking to understand the reasoning behind the choice of datasets, which is not immediately obvious from the paper alone.", "grounding_specificity_rationale": "The reviewer explicitly states that only 10 out of 120 datasets are considered for comparison. This directly identifies the specific part of the paper (the comparison methodology) being addressed. Therefore, the grounding is 'Full Grounding'. The specificity is also 'High' as the reviewer clearly specifies the number of datasets used for the limited comparison.", "verifiability_rationale": "The reviewer makes a claim about the paper's methodology, stating that only 10 out of 120 datasets are considered. This is a clear claim. However, the paper does not explicitly *support* this claim with logical reasoning, common knowledge, or external references within the provided text. The reviewer is asking *why* this is the case, implying a lack of explicit justification. Therefore, the verifiability is 'Low' as the claim is stated without sufficient backing.", "helpfulness_rationale": "The reviewer points out a potential limitation in the experimental setup by highlighting the discrepancy in the number of datasets used. While this doesn't directly critique the results presented in the paper, it does point out a potential area for improvement in future work. It encourages the authors to provide more comprehensive results. Therefore, it is 3 in identifying a potential flaw in the experimental design, even if it doesn't directly harm the current conclusions."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a perceived disconnect between the introduction's focus on lowrank factorization and the paper's actual focus on polytopes. While the reviewer doesn't explicitly demand a change, the implication is that the introduction's mention of lowrank factorization is either unnecessary or potentially misleading given the paper's content. This suggests a lack of clarity in the introduction regarding the paper's core contribution. The reviewer also implies that if there are connections to lowrank factorization, they should be made explicit. This indicates a lack of explicitness in linking these two areas.", "grounding_specificity_rationale": "The reviewer explicitly mentions the introduction's discussion of lowrank factorization and the paper's focus on polytopes. This directly identifies the specific parts of the paper being referenced. The reviewer's statement that the connection between these two areas is unclear further emphasizes the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim about a disconnect between the introduction and the paper's content. To verify this claim, the authors would need to explicitly state the reason for mentioning lowrank factorization in the introduction. Without this statement, the claim is based on an interpretation of the introduction. The reviewer's suggestion to discuss implications for lowrank factorization is a suggestion for improvement, not a claim that has been verified.", "helpfulness_rationale": "The reviewer's suggestion to clarify the motivation and explicitly discuss the implications for lowrank factorization is a constructive feedback point. It directly addresses a potential area of confusion for the authors and suggests a way to improve the paper's clarity and impact. This feedback is relevant and likely to be helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer is asking for clarification on the labels used in the datasets from Section 4.1. While the request itself isn't an explicit action, it implies a desire to understand the nature of the data being generated and evaluated. The reviewer is essentially asking for a concrete action: to understand how the labels are assigned. This request, while not directly prompting an action, is a crucial piece of information for the reviewer to fully grasp the methodology and potentially reproduce the work. The lack of clarity on the label origin is a potential weakness in the paper's explanation.", "grounding_specificity_rationale": "The reviewer is explicitly asking about the *source* of the labels in the datasets. This directly identifies the specific part of the paper being addressed (Section 4.1 and its associated datasets). The request is also quite specific, asking whether the labels come from the dataset itself or from the reviewer's understanding. This strong specificity indicates a clear grounding of the reviewer's question in the paper's content.", "verifiability_rationale": "The reviewer is asking a direct question about the origin of labels. This is a logical reasoning request, as the reviewer wants to understand the basis of these labels. The information is likely available within the paper's methodology section, making it verifiable through reading and understanding the described process. The request is also a statement requiring justification (how the labels are determined), which fits the criteria for verifiability.", "helpfulness_rationale": "The reviewer is explicitly asking for information that is crucial for understanding the paper's methodology and potentially reproducing the results. They are asking for clarification on a key aspect of the datasets used in the experiments. This directly addresses a potential gap in the reviewer's understanding and is therefore 5. Without this information, the reviewer might struggle to fully grasp the experimental setup and the significance of the results."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point mentions 'adapt the existing architecture' and 'producing identity/tag heatmaps with the joint heatmaps'. While it implies a change, it doesn't explicitly state what action the authors should take next or how to implement this adaptation. The connection to 'identity/tag heatmaps' is a result, not a specific action. The vagueness makes it difficult to know exactly what needs to be done.", "grounding_specificity_rationale": "The reviewer refers to '31' and the 'existing architecture'. However, they do not explicitly identify the specific part of '31' or their own work that is being addressed. The statement is general and lacks pinpointing. The issue of 'adaptation' is mentioned, but the specific component being adapted is not specified.", "verifiability_rationale": "The review contains the statement 'The paper is rather incremental with respect to 31'. This is a claim that the paper does not represent a significant advancement over 31. However, the reviewer does not provide any evidence, examples, or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to justify this statement.", "helpfulness_rationale": "The review points out that the paper is 'rather incremental' with respect to 31. While this identifies a potential area for improvement (further development or differentiation from 31), it does not offer specific suggestions or actionable steps for the authors to take. The criticism is presented as a negative observation rather than a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states they do not understand how the \u03bb parameter is computed (Part 1) and do not understand the explanation of why ELLA does not increase sample efficiency in a COMBO environment (Part 2). While the reviewer's intention to understand is implicit in Part 3, the lack of clarity in the initial parts makes them actionable. The reviewer is directly asking for a clarification of a process and an explanation of a phenomenon, both of which are actionable. The implicit actionability in Part 3 is weakened by the lack of understanding expressed in the preceding parts.", "grounding_specificity_rationale": "Part 1 of the review points to specific sections (8 lines 281285) where the \u03bb calculation is discussed, indicating an attempt at grounding. However, the reviewer explicitly states they do not understand the process, suggesting the grounding is not fully specific or clear. Part 2 also points to specific sections (9 lines 310313) regarding ELLA's sample efficiency, again showing an attempt at grounding, but the reviewer's lack of understanding indicates the grounding is not fully specific or clear. Part 3 explicitly mentions specific citations related to curiositydriven exploration, demonstrating strong grounding specificity as the reviewer is asking for clarification on a specific concept.", "verifiability_rationale": "The reviewer states they do not understand how the process of calculating the \u03bb is done (Part 1), implying a claim that the paper lacks a clear explanation, making it 1. Similarly, the reviewer states they do not understand how the process of calculating the \u03bb is done (Part 2), implying a claim that the paper's explanation is unclear and 1. For Part 3, the reviewer asks for clarification on the meaning of curiositydriven exploration, referencing specific papers. While the reviewer is asking for information, the lack of understanding of the cited work makes the claim 1.", "helpfulness_rationale": "The reviewer's comments are primarily requests for clarification and explanation. While these are relevant, they do not provide actionable feedback or insights that would significantly improve the original work. The reviewer is asking for more information rather than pointing out a flaw or suggesting a solution. The lack of clarity makes the feedback less helpful in improving the understanding or implementation of the methods described."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about which alternating direction method is used. While this implicitly points to a potential area for improvement (lack of clarity on the method), it doesn't explicitly state an action the author should take. The reviewer doesn't directly tell the author what to do or how to apply the information.", "grounding_specificity_rationale": "The reviewer asks about 'alternating direction method' and 'minmin problem' generally, without specifying which section or unique aspect of the paper they are referring to. While the question is specific about the method used, the grounding of this question to a particular part of the paper is weak.", "verifiability_rationale": "The reviewer poses a question, which is not a direct claim or statement that requires verification. There is no assertion that something is wrong or needs to be improved, nor is there a suggestion for a change. The question itself doesn't require external references or logical reasoning to understand.", "helpfulness_rationale": "The reviewer's comment is more of a request for clarification on a technical detail rather than a direct suggestion for improving the draft. While it might be helpful for the author to understand the specific method used, it doesn't actively guide them on how to revise their work. The helpfulness is limited to providing information, not constructive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states \"The experiments should be more comprehensive and general\" and suggests improvements by \"increasing the model size\" and \"including more baselines.\" These are direct and concrete actions the authors can take to improve their draft. The reviewer provides clear directions for modification.", "grounding_specificity_rationale": "While the review point mentions \"experiments,\" \"language modeling task,\" \"image classification task,\" \"model size,\" and \"baselines,\" it doesn't explicitly identify a *specific* element within a table, figure, or section that needs improvement. The reviewer provides general directions rather than pinpointing a particular detail. For example, they don't say \"Table 2, the results for the 'small' model on the 'text classification' task are inconsistent\" \u2013 they broadly state the need for more comprehensive experiments.", "verifiability_rationale": "The review point contains a claim that the current experiments are \"limited\" and suggests improvements. However, within the *review point itself*, there is no explicit justification for *why* the current experiments are limited or *how* increasing the model size and adding more baselines would necessarily make them more comprehensive or general. The justification would need to be present within the *review point* to be considered verifiable.", "helpfulness_rationale": "The review point directly suggests concrete and actionable improvements to the authors' draft. By recommending increasing the model size and adding more relevant baselines, it provides a clear path for the authors to enhance their experiments and potentially improve their results or conclusions. It doesn't just criticize; it offers a specific direction."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential misunderstanding or misapplication of Hoeffding's inequality. While the action is to check the conditions, the reviewer doesn't explicitly state the action of verifying the independence of samples. The implication is that the authors should verify their analysis.", "grounding_specificity_rationale": "The reviewer refers to 'Line 124125' of the paper, providing a literal reference point. The comment also specifies the conditions of Hoeffding's inequality (independent samples), making it highly specific to the mentioned line and the potential issue.", "verifiability_rationale": "The reviewer makes a claim about the conditions of Hoeffding's inequality and the impact of stochastic algorithms. The reasoning is present, explaining why the independence condition is crucial and how stochasticity might strengthen the analysis. However, the reviewer doesn't provide specific references to the paper's equations or algorithms, making it somewhat underspecified.", "helpfulness_rationale": "The reviewer identifies a potential issue with the paper's statistical analysis and suggests that the authors should doublecheck their analysis, particularly the independence of samples. The reviewer also offers a potential explanation for why stochastic algorithms might strengthen the analysis. This provides clear guidance for the authors and addresses a specific technical concern, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly asks if it's possible to add a metalearning approach to Table 1, which is a direct and actionable question.", "grounding_specificity_rationale": "The comment directly refers to 'Table1', which is a specific element of the paper. While the 'why' isn't explicitly stated, the reference is precise.", "verifiability_rationale": "The comment is a question and does not contain a claim that needs verification.", "helpfulness_rationale": "The comment suggests a potential future addition to Table 1 but lacks concrete reasons why this would be beneficial for the authors' current work, making it somewhat speculative."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a potential issue with terminology but does not explicitly state what needs to be changed. It implies an action (correcting the terminology) but lacks specific guidance on how to apply it.", "grounding_specificity_rationale": "The comment mentions 'causal mechanisms' generally, without pinpointing a specific section or element of the paper. It does not explicitly state what is incorrect within these mechanisms, making it somewhat specific about the concepts but not the location or nature of the problem.", "verifiability_rationale": "The comment implies that using 'causal mechanisms' and 'causality' interchangeably is problematic, which could be considered a deduction. It is supported by common knowledge of the difference between causality and temporal relationships.", "helpfulness_rationale": "The comment points out a potential area for improvement in the authors' writing by highlighting the difference between causality and temporal relationships. It encourages the authors to be more precise in their terminology."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the impact of replacing procedure steps with a random mechanism and specifies that the random mechanism performs *better than* the procedure steps. This is a clear and actionable observation about the algorithm's behavior.", "grounding_specificity_rationale": "The reviewer directly mentions 'XAIFOOLER' and 'procedure steps,' clearly identifying the specific part of the paper being addressed. They also specify the nature of the issue: a performance drop when procedure steps are replaced with a random mechanism. This is both grounded and specific.", "verifiability_rationale": "The reviewer makes a claim about the performance of the algorithm when procedure steps are replaced with a random mechanism. However, they do not provide specific evidence or analysis within this review point to *verify* this claim. The potential for this outcome exists, but it remains unproven based solely on this review.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the algorithm's performance and suggests investigating the behavior of a random mechanism. This is a valuable and actionable piece of feedback for the authors, guiding them towards further analysis and potential improvements."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action or suggestion, which is that the results in section 4 apply only to shallow fullyconnected ReLU networks. This action is direct and clear, allowing the author to understand the limitation. While it doesn't provide a solution, it points to a concrete area of concern.", "grounding_specificity_rationale": "The comment explicitly mentions 'section 4', which is a specific part of the paper. It also clearly specifies the type of network 'shallow fullyconnected ReLU networks'. This makes the grounding both explicit and specific.", "verifiability_rationale": "The comment is a factual statement about the content of the paper. It states that the results in section 4 apply to a specific type of network. This claim is verifiable based on the existence of section 4 and the definition of shallow fullyconnected ReLU networks within that section. There are no external references needed to support this claim.", "helpfulness_rationale": "The comment is helpful because it alerts the author to a potential limitation regarding the scope of the results in section 4. It helps the author understand that the findings might not generalize to other types of networks. However, it doesn't provide a solution or specific guidance on how to address this limitation, making it 3 rather than 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment implicitly suggests that the authors should consider the comparison between sequential MCB and a single MCT layer, as it points out that 'no results were shown'. While it doesn't explicitly state 'add a section on the MCB vs. MCT comparison', the implication is clear. The authors are encouraged to engage with this discussion and potentially add information. Therefore, it can be considered 3 as the authors are prompted to take a specific action related to the discussion.", "grounding_specificity_rationale": "The comment is generally weakly grounded as it refers to a 'discussion' of the decision head without specifying the exact section, table, or figure. While the topic is implied to be within the 'decision head' discussion, the specific location is not pinpointed. Therefore, it is not fully grounded to a specific part of the paper.", "verifiability_rationale": "The comment itself does not make a claim that requires verification. It is a question about what might have been observed, not a statement that needs to be supported by evidence. Therefore, it does not fall under the 'verifiability' category and is classified as 'X'.", "helpfulness_rationale": "The comment is helpful because it points out a missing element (the results of the MCB vs. MCT comparison) and encourages the authors to engage with the discussion. It highlights a potential area for improvement in the paper's completeness. Therefore, it can be considered 3 as it prompts the authors to address a specific aspect of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies areas for improvement in language usage and suggests general improvements. While the reviewer points out actionable areas for improvement (e.g., 'improve language usage'), the suggestions are quite broad and lack specific, actionable steps. The reviewer doesn't explicitly state what the author should do next, leaving room for interpretation.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific instances where language usage might be improved (e.g., 'we typically considers'). This demonstrates strong grounding as the reviewer clearly identifies the specific parts of the paper being addressed. Furthermore, the reviewer provides suggestions for improvement related to these specific instances.", "verifiability_rationale": "The reviewer provides specific examples of language issues (e.g., 'we typically considers') and suggests improvements. This makes the claim verifiable, as the reviewer provides evidence and examples to support their critique. The suggestions are directly linked to the identified issues.", "helpfulness_rationale": "The reviewer provides a clear list of specific language issues and suggests concrete improvements. This makes the feedback 5, as the author can directly address the identified problems. The suggestions are actionable and directly related to the issues raised."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states they are 'not clear regarding the choice of 20 distribution sets'. This indicates an implicit action \u2013 they are trying to understand this choice. However, they don't directly instruct the authors on how to choose the number or what the implications are, making it less explicit. The request for clarification is 3, but not a fully explicit instruction.", "grounding_specificity_rationale": "The reviewer doesn't specify *which* choice they are unclear about (e.g., the number 20 itself, or the *reasoning* behind that number). While they are pointing to a specific element (the number 20), their lack of further specification makes the grounding weak. They are *specific* about *what* is unclear (the choice of 20), but not *where* in the paper or what concept this choice relates to.", "verifiability_rationale": "The reviewer isn't making a claim about what *should* be done. They are asking for clarification on an existing choice. While the request could be considered a form of implicit verification (they are questioning the validity of the choice), it lacks the explicit justification or evidence that would make it 5. The request is about understanding, not necessarily identifying a flaw.", "helpfulness_rationale": "The reviewer is asking for more information, which is generally helpful. It allows the authors to better understand the experimental setup and potentially improve their work. However, the request is broad and doesn't directly address a specific problem or suggest a concrete improvement. It's helpful in that it prompts clarification, but potentially less impactful than targeted feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the weakness: 'perplexity experiments are carried out on obsolete language models (ngram HMM, RNN)' and suggests an improvement: 'to better align the paper with current NLP trends, I believe the authors should showcase their approach using transformerbased (masked) language models'. This is an explicit statement of a problem and a suggestion for improvement. However, the reviewer does not specify *how* the authors should go about implementing this suggestion, such as which specific transformer models to use or how to modify the experimental setup. Therefore, while the action is identified, the lack of detail makes it only partially actionable.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific part of the paper being addressed: 'perplexity experiments are carried out on obsolete language models (ngram HMM, RNN)'. This clearly points to a specific methodology section. The reviewer also specifies the *type* of obsolete models (ngram HMM, RNN) and suggests a *specific* alternative (transformerbased models). This indicates a clear understanding of the section and the nature of the models being criticized. Therefore, the reviewer not only identifies the section but also specifies the issue within it, making it 5.", "verifiability_rationale": "The reviewer makes a claim: 'perplexity experiments are carried out on obsolete language models (ngram HMM, RNN) that are rarely used nowadays'. This is a statement that could be verified. The reviewer provides the names of the models (ngram HMM, RNN) and states their 'rarely used nowadays', which provides some justification for the claim. While the reasoning is clear, it doesn't explicitly cite external references to support the claim about the models' usage. Therefore, the claim is verifiable but lacks explicit external references, making it 3.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'to better align the paper with current NLP trends, I believe the authors should showcase their approach using transformerbased (masked) language models'. This directly addresses a likely concern for researchers in the field, which is the relevance and modernity of their experiments. The suggestion is specific and directly related to the identified weakness. Therefore, the reviewer's comment is 5 as it directly addresses a relevant and current issue for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, not a direct instruction. It lacks explicitness and specificity, making it not actionable for the authors. While the reviewer states a desire for *more*, the *how* is vague. They don't specify *what* kind of additional experiments would be beneficial, or *why* the current experiments are insufficient. This lack of specificity makes it difficult for the authors to know how to improve their work.", "grounding_specificity_rationale": "The review point identifies the area of concern as 'the experiments are not sufficient.' It grounds the feedback in the experimental setup, even if the specifics are not fully elaborated. The reviewer is pointing to a *specific* area in the paper (the experiments) where improvements could be made.", "verifiability_rationale": "The review point is a suggestion, not a claim requiring evidence. It does not present a verifiable statement. The reviewer is offering a suggestion, not making a claim that *something is wrong* or *something needs to be changed*. There's no 'I think this is incorrect' or 'I have evidence that this is a problem.' It's simply a desire for more.", "helpfulness_rationale": "The review point offers a suggestion for more experiments, which is 3 as it identifies a potential area for improvement (more empirical or toy experiments). However, it lacks specific details, making it less helpful overall. The suggestion is general and lacks concrete guidance on *how* to conduct more experiments or *why* the current ones are insufficient."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the difficulty in estimating mu, making it partially actionable. However, they don't specify how to improve the estimation process, making it less concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'mu, but as it is the proportion of missing observations,' which grounds the comment. However, they don't specify what is wrong with the estimation, making it underspecific.", "verifiability_rationale": "The reviewer makes a claim about the difficulty of estimating mu but doesn't provide any evidence or references to support this claim.", "helpfulness_rationale": "The reviewer points out a potential issue (difficulty in estimating mu) but doesn't offer any suggestions or constructive feedback, making it unhelpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the potential simplification of removing the absolute value in the Frobenius norm definition and provides a clear reason (tensor entries are real numbers). The action is to remove the absolute value, and the implementation is straightforward. The reviewer directly identifies a potential improvement.", "grounding_specificity_rationale": "The comment explicitly mentions 'line 77', providing a precise location in the document where the Frobenius norm definition is located. This demonstrates strong grounding as the author can easily identify the referenced part. The comment also specifies what is being considered for removal (the absolute value).", "verifiability_rationale": "The claim that the absolute value is not needed because tensor entries are real numbers is logically sound and verifiable. While the reviewer doesn't provide a specific reference within the review, the claim is based on a fundamental understanding of tensor properties. The reasoning is clear and the suggestion is actionable.", "helpfulness_rationale": "The comment is concise and directly points out a potential simplification in a definition. It offers a clear suggestion (removing the absolute value) that is actionable for the author. While the comment is helpful, it could be more impactful if it provided a specific reference or a more detailed explanation of why the absolute value might be unnecessary in this specific context (e.g., if the entries are always nonnegative due to the context of the paper)."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a specific weakness: the lack of highprobability bounds, which are only provided in expectation. They suggest using ensemble methods as a way to achieve this. This is an explicit action identifying a problem and a concrete suggestion for improvement.", "grounding_specificity_rationale": "The reviewer explicitly states the weakness: 'Only bounds in expectation are provided' and directly suggests a solution: 'Would it be possible to get highprobability bounds?'. This demonstrates a clear understanding of the specific issue and a direct attempt to address it. The suggestion is concrete, pointing to a specific type of bound and a potential method to obtain it.", "verifiability_rationale": "The reviewer makes a claim: 'Only bounds in expectation are provided' and offers a suggestion: 'Would it be possible to get highprobability bounds?'. This claim is verifiable as the paper's current bounds are stated. The suggestion is a logical next step to improve the robustness of the results. The reviewer also implies the importance of highprobability bounds by suggesting a specific method (ensemble methods) to achieve them.", "helpfulness_rationale": "The reviewer clearly identifies a limitation in the current bounds (only expectation bounds) and offers a concrete suggestion (highprobability bounds and ensemble methods). This directly addresses a potential weakness in the paper's analysis and provides a clear path for improvement. The reviewer's statement is a direct and actionable criticism."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states \"I was all excited to see how the authors managed to get the diversity term into their model and got disappointed when I learned that there is no diversity.\" This clearly indicates an explicit action or suggestion that the authors should take, which is to implement diversity enforcement. The reviewer directly points out a missing element that they expected to be present.", "grounding_specificity_rationale": "The reviewer mentions the title contains the word \"diversity\" and that the paper \"motivates\" extensively (even the word diversity is in the title). While they don't explicitly state which part of the paper is problematic, they link the lack of explicit diversity enforcement to the *general concept* of diversity as presented in the motivation. They don't specify *which* part of the motivation is problematic, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer states their * expectation was that the model *would* enforce diversity, and their * disappointment* is that it doesn't. This is a clear claim about what the model *should* have done. However, the reviewer does not provide any external references or logical reasoning to *prove* that the model *should* enforce diversity based on the paper itself. The claim is based on their expectation, which is not verifiable within the paper's content.", "helpfulness_rationale": "The reviewer clearly identifies a *specific area for improvement* \u2013 the lack of explicit diversity enforcement. They also point to the *motivation* section as the likely source of their expectation. While the claim about verifiability is 1, the *actionability* is high, and the *grounding* is weak but the *direction* of improvement is clear. The authors know *what* is missing (explicit diversity) and *where* it might be relevant (the motivation)."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The comment states 'some experiments are missing' and provides examples like 'contrastive learning' and 'adversarial learning'. While it identifies a problem, it does not explicitly tell the authors what to do or how to address it. The authors still need to infer the missing experiments and then decide how to add them or discuss them.", "grounding_specificity_rationale": "The comment is vague about which specific experiments are missing. It doesn't point to a particular section, table, figure, or unique aspect of the paper. The examples given are general categories of learning methods rather than specific details within the paper. Therefore, the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The comment makes a claim: 'some experiments are missing'. However, it does not provide any justification or reasoning for this claim. There are no references to external work or logical explanations to support the assertion that these experiments are indeed missing or necessary. The claim is presented without sufficient backing.", "helpfulness_rationale": "The comment identifies a valid weakness in the paper ('missing experiments') but fails to provide actionable guidance. It does not tell the authors what specific experiments to add, how to add them, or why these experiments are important. The suggestion is too general and lacks direction, making it less helpful for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'suggest an alternative metric' and names a specific alternative metric 'DinoV2 Frechet Distances'. This is a clear, direct action that authors can readily follow.", "grounding_specificity_rationale": "The review point explicitly mentions the 'FID metric' and suggests an 'alternative metric' 'DinoV2 Frechet Distances'. It does not leave the authors to infer which part of the paper is being addressed, making the grounding explicit. Furthermore, it clearly specifies what alternative metric should be used, making it specific.", "verifiability_rationale": "The review point contains a claim that FIDs have 'clear flaws' and suggests using 'DinoV2 Frechet Distances' as a solution. The claim about the flaws of FIDs is generally verifiable, even if the reviewer doesn't provide specific evidence here. The suggestion to use DinoV2 Frechet Distances is also wellsupported by the cited paper C. The connection between the problem and the solution is clear and logical.", "helpfulness_rationale": "The review point identifies a clear limitation of a commonly used metric (FID) and provides a specific, wellestablished alternative (DinoV2 Frechet Distances). It explains the potential flaws of FIDs and how the alternative addresses them, providing a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests conducting three specific experiments: occluding images, simulating keypoint detection failures, and inspecting longrange inference capacity. It also provides clear motivations for each experiment, linking them to simulating irregularity in neural/behavioral data and assessing the model's ability to make predictions based on incomplete information. The reviewer directly suggests running these experiments.", "grounding_specificity_rationale": "While the reviewer doesn't explicitly name a specific section or table in the paper, they refer to \"above\" and the general context of neural/behavioral data. However, the *nature* of the suggested experiments and their stated purposes are quite specific. The reviewer clearly articulates the *why* behind each experiment. The grounding is implicit in the *type* of experiments being suggested, but the specific *purpose* of each is welldefined.", "verifiability_rationale": "The review point contains a claim: suggesting specific experiments and their rationale. This claim is wellsupported by the stated purpose of each experiment (e.g., \"This (a) simulates the irregularity...\") and the logical reasoning behind them. The reviewer explicitly suggests running these experiments, implying a clear path for verification.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the authors. It directly addresses potential limitations in the current work (irregularity in data, need for inference capacity) and proposes concrete experiments to evaluate the model. The suggestions are wellmotivated and provide a clear direction for improvement. The reviewer anticipates the need for these experiments and offers a solution."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for clarification on specific terms within the abstract, which is a direct and actionable request. They identify the terms 'lowrank feature subspace,' 'attacked samples,' and 'mild assumptions' as unclear and request their meaning. This indicates a clear need for the authors to understand these elements to grasp the abstract's content. While the terms themselves are technical, the request to understand them is a clear action the authors should be able to take.", "grounding_specificity_rationale": "The reviewer directly points to the abstract as the location of the unclear statement. They then specify the terms within the abstract that are causing confusion: 'lowrank feature subspace,' 'attacked samples,' and 'mild assumptions.' This demonstrates a high level of grounding as the authors can easily identify the specific part of the paper being addressed.", "verifiability_rationale": "While the reviewer doesn't explicitly state a claim, the abstract itself makes a claim by stating that a lowrank feature subspace, a small number of attacked samples, and other mild assumptions can ensure something. The reviewer's comment highlights the lack of justification or explanation for this claim within the abstract. The abstract presents a statement without providing sufficient reasoning or examples to support it. Therefore, the claim is not 5 because the supporting evidence is missing.", "helpfulness_rationale": "The reviewer's comment directly addresses a clear need for the authors to understand a specific part of the abstract. They explicitly ask for clarification on the terms 'lowrank feature subspace,' 'attacked samples,' and 'mild assumptions.' This is a 5 comment because it directly points to the area of confusion and guides the authors to seek the necessary information. The comment is actionable and directly addresses a lack of clarity."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point suggests exploring new areas (other modalities) but doesn't provide explicit instructions on how to make modifications to the current draft.", "grounding_specificity_rationale": "The review point makes a general suggestion about future work but doesn't specify which part of the paper or what aspect of the work is lacking results in other modalities.", "verifiability_rationale": "The review point is a suggestion or a desire for future work, not a claim that needs to be verified.", "helpfulness_rationale": "The review point offers a suggestion for future work but doesn't directly point out weaknesses in the current draft or provide concrete steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the paper 'defines and creates a fewshot situation for graph link prediction, but the proposed method does not consider how to effectively use \u201cfewshot\u201d and how to guarantee the trained model can be generalized well to new tasks with 0/few training steps.' This clearly identifies an implicit action the reviewer believes is missing. While the reviewer doesn't provide a concrete solution, they clearly point out what needs to be addressed.", "grounding_specificity_rationale": "The reviewer mentions 'how to leverage a few instances,' 'how to guarantee the trained model can be generalized,' and 'new tasks with 0/few training steps.' While the reviewer doesn't pinpoint a specific section or table in the paper, they are referring to general aspects of the paper's content. The reviewer's comments are about the general structure and content of the paper, rather than a specific, identifiable part.", "verifiability_rationale": "The reviewer makes a claim about the paper's shortcomings: 'The motivation of this work should be further justified. In fewshot learning, we usually consider how to leverage a few instances to learn a generalizable model. This paper defines and creates a fewshot situation for graph link prediction, but the proposed method does not consider how to effectively use \u201cfewshot\u201d and how to guarantee the trained model can be generalized well to new tasks with 0/few training steps.' This claim is not supported by any evidence or reasoning within the review point itself.", "helpfulness_rationale": "The reviewer clearly identifies significant weaknesses in the paper: the lack of justification for the motivation and the absence of a clear connection between the fewshot setup and the generalization ability. This provides valuable information for the authors to improve their work, making the feedback helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The criticism points to a lack of clarity in the writing, but it doesn't explicitly state which parts are unclear or how to improve them.", "grounding_specificity_rationale": "The reviewer states the ablations are hard to locate, indicating they can identify the ablations (weak grounding), but they don't specify which ablations (specificity).", "verifiability_rationale": "The reviewer's claim about the writing being hard to improve is a subjective statement without supporting evidence or logical reasoning.", "helpfulness_rationale": "The reviewer identifies a potential issue (difficulttolocate ablations), which could be helpful, but the lack of specificity makes the feedback less actionable."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states \"I think the differential privacy application is a bit too 'halfbaked' at the present time\". This indicates an opinion about the current state of the application. While the reviewer suggests \"I would encourage the authors to think through it more clearly,\" this is a general suggestion without specific steps or actionable items. The lack of explicit and concrete steps makes it less actionable.", "grounding_specificity_rationale": "The reviewer refers to \"the differential privacy application\" generally, without specifying a particular section, table, figure, or unique aspect of the paper or application that needs improvement. The reference is broad and lacks precision.", "verifiability_rationale": "The reviewer states \"I think the differential privacy application is a bit too 'halfbaked' at the present time\". This statement expresses an opinion or judgment about the paper's state. The reviewer does not provide any evidence, references, or logical reasoning to support this claim. It is presented as a subjective assessment.", "helpfulness_rationale": "The reviewer provides a general critique of the differential privacy application, suggesting it needs more work and offering a direction for improvement. However, the suggestion is broad and lacks specific details or actionable steps. The reviewer also mentions the placement of experimental results in the appendix, which is a general observation rather than a specific, actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement compares the multilingual chainofthought to the villa chainofthought but does not explicitly state what the authors should do with this comparison. It raises a question about the relative contribution, but lacks a clear action for the authors to take based on this comparison alone.", "grounding_specificity_rationale": "The review point explicitly mentions 'multilingual chainofthought' and 'villa chainofthought', clearly identifying the specific aspects being compared. It also specifies the comparison being made ('incremental compared to'). This is 5.", "verifiability_rationale": "The statement presents a claim: 'The contribution of multilingual chainofthought is incremental compared to the villa chainofthought.' This claim is not supported by any evidence or reasoning within the review point itself. It is a statement of opinion without justification.", "helpfulness_rationale": "The review point raises a valid question about the relative contribution of different chainofthought approaches. While it doesn't provide a direct solution or action for the authors, it highlights a meaningful distinction that could be helpful for them to consider in their work. It points to a relevant area for further discussion or investigation."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of clarity regarding the use of 'robotic manipulation' and suggests 'bimanual manipulation' as a more specific alternative. While the reviewer identifies a potential area for improvement, they do not explicitly state what action the authors should take. The suggestion is presented as a question or point for clarification rather than a direct instruction. Therefore, the action is implicit and vague.", "grounding_specificity_rationale": "The reviewer suggests 'bimanual manipulation' as a specific type of robotic manipulation. This directly refers to a unique aspect of the methodology. The reviewer can accurately pinpoint the specific type of manipulation being questioned. Therefore, the grounding is explicit and precise.", "verifiability_rationale": "The reviewer's point about the lack of clarity in 'robotic manipulation' does not inherently provide a claim that requires verification. The reviewer is expressing an opinion about the specificity of the methodology. While the suggestion to use 'bimanual manipulation' could be considered a potential claim if it were framed as a recommendation, within the provided text, there's no explicit claim being made and verified. Therefore, it can be considered not verifiable or verifiability is not explicitly stated in the provided text.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the clarity and specificity of the methodology. By suggesting 'bimanual manipulation,' they are providing a concrete suggestion for improvement. While the comment itself doesn't directly instruct the authors on what to do, it points out a potential area for clarification and improvement, which can be helpful for the authors. Therefore, it is 3 as it highlights a potential area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer implicitly suggests that the inconsistency of UNIFORM's advantage in the 1shot setting could be a direction for further investigation or improvement. While not explicitly stating an action, the question implies a desire to understand why UNIFORM isn't as effective in this specific scenario.", "grounding_specificity_rationale": "The reviewer explicitly mentions the '1shot setting' and the 'results' in their comment. They refer to 'tables' which suggests they are aware of the specific location of this information within the paper. This indicates a clear understanding of the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim about the inconsistency of UNIFORM's advantage. They provide some context by stating that the 'results are clear,' which supports their claim. However, they do not delve into the reasons *why* this inconsistency exists or provide external references to back it up. The claim is supported by the presented information, making it 3.", "helpfulness_rationale": "The reviewer points out a specific observation about the experimental results and asks a relevant question about a potential underlying reason. This directly addresses a potential weakness in the analysis and encourages the authors to consider the 1shot setting further. While it doesn't offer a concrete solution, it provides a clear direction for the authors to investigate, making it 3 in guiding their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about whether the authors have considered the reason why information value is a stronger predictor for dialogue and if existing linguistic theories support this. This is a probing question, not a directive action. The authors are not explicitly told what to do or what aspect to focus on. The reviewer is seeking information and discussion, not a solution or a specific action to take.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify a specific part of the paper being addressed. While they mention 'discussion' as a potential mechanism, they do not point to a specific section, table, figure, or unique aspect of the paper. The comment is general and does not provide enough detail to ground the discussion in a specific part of the work.", "verifiability_rationale": "The reviewer presents a claim: 'Have the author(s) thought about the reason why, information value is a stronger predictor' and 'is there any already existing linguistic theory which could explain it.' This is a claim that needs to be verified. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. The comment is a question posed to the authors, not a statement that can be evaluated for verifiability.", "helpfulness_rationale": "The reviewer's comment is a question intended to encourage the authors to think more deeply about the relationship between information value and dialogue. While it prompts discussion and potentially deeper analysis, it does not directly identify a weakness in the authors' work or provide a concrete action for them to take. It's a suggestion for improvement in terms of thought process, but not a direct critique or actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the authors did not spend much time commenting on the aspects of AutoML's impact on future architecture design. This is an explicit action the authors should have taken. However, the *action* itself (pointing out the lack of discussion) is somewhat vague in terms of *how* the authors should improve their draft based on this comment. They need to *find* the relevant information in the paper.", "grounding_specificity_rationale": "The reviewer *identifies* a specific area (AutoML's impact on future architecture design) and *specifically* asks about 'biggest takeaways.' This is quite specific. However, the reviewer doesn't explicitly state which section, table, or unique element of the paper this refers to. Therefore, while the topic is specific, the grounding is weak because it relies on the authors making an educated guess.", "verifiability_rationale": "The reviewer *claims* that the authors did not spend much time commenting on these aspects. This is a claim that could be verified by examining the paper. It's not definitively '1' because the paper *could* contain this information, just not in the way the reviewer suggests. It's also not '5' because we don't have access to the paper to confirm the authors' lack of discussion. Therefore, it's somewhere in between.", "helpfulness_rationale": "The reviewer clearly states a limitation in the paper's discussion. This directly points to an area where the authors could improve their work. The information is relevant and actionable (the authors know *what* is missing). While the *how* of improvement might not be fully specified, the *what* is clear and directly helpful. The reviewer's point is a valuable constraint for the authors to consider when designing future architectures."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that T_a(t) is used in Section 3.1. This is a clear indication of an actionable point, as the reviewer directly points to the location of the usage. The reviewer is asking the authors to find where T_a(t) is used in Section 3.1, which is a direct action they can take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3.1' as the specific part of the paper where T_a(t) is used. This is a literal mention of a section, making the grounding fully grounded. The reviewer also specifically asks 'where is T_a(t) used in Section 3.1?', which clearly identifies the issue within that section, making the specificity fully specific.", "verifiability_rationale": "The reviewer identifies a potential issue (T_a(t) being used in Section 3.1) and asks for clarification on its location. This constitutes a claim that there is a usage in Section 3.1. While the information is present in the paper (Section 3.1), the reviewer is asking for verification of its existence and location, which can be supported by logical reasoning and direct observation within the paper. Therefore, it is 3 as the information is present and can be found.", "helpfulness_rationale": "The reviewer points out a discrepancy between the usage of T_a(t) in Section 3.1 and its definition in Section 4. This directly helps the authors locate the relevant information and understand where the variable is being used before its definition. This is a very actionable and helpful piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification and an explanation regarding the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score. While the action of clarifying and explaining is implied, it is not directly stated in the review point. The reviewer wants the authors to understand and justify these adjustments. The lack of explicitness makes it 2.", "grounding_specificity_rationale": "The review point refers to 'Figure 3' and 'Frequency Stability score' without explicitly stating which part of the paper Figure 3 refers to or providing a detailed explanation of the Frequency Stability score within the review point itself. The authors need to infer the location and concept, making it implicitly grounded. The level of specificity is low, making it weakly grounded.", "verifiability_rationale": "The review point asks the authors to explain *why* the adjustments to the amplitudes are effective in enhancing model performance. Without this explanation, the claim about the effectiveness of the adjustments is not verifiable. The reviewer is asking for a justification that goes beyond merely stating facts.", "helpfulness_rationale": "The review point explicitly states that the reviewer is 'confused' about the empirical analysis in Figure 3 and requests clarification and an explanation of the adjustments. This directly indicates a need for improvement and suggests the original point was 1. The request for clarification and explanation makes it 3 in guiding the authors towards a better understanding."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of comparison with CoCoOp and suggests its necessity. The action 'compare' is directly implied, making it explicit. The suggestion to 'compare' is also concrete, indicating a clear action to be taken.", "grounding_specificity_rationale": "The review point explicitly mentions 'CoCoOp' by name. This is a literal mention of a specific work, indicating full grounding. The comment also specifies what is missing  the comparison, making it specific.", "verifiability_rationale": "The review point contains a claim: 'It is necessary to compare with CoCoOp'. However, it does not provide any evidence or justification for this claim. It is a suggestion based on the extended version of CoCoOp, but the review itself lacks logical reasoning, common knowledge, or external references to support this suggestion.", "helpfulness_rationale": "The review point is clear, identifies a specific related work, and provides a direct suggestion for improvement by pointing out the missing comparison. This is a constructive and actionable piece of feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests improvements to Fig. 1, but the specific actions to be taken are not clearly defined. While the reviewer mentions 'better to show' and suggests improvements to components like 'prompt generation', 'manual check', 'Demonstration selection', 'ground truth scores', 'automatic scoring', and 'model training optimization', the exact steps or methods for achieving these improvements are not specified.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Fig. 1', indicating a clear identification of the specific part of the paper. However, the reviewer does not specify *what* is wrong with Fig. 1 or *why* it needs improvement. The suggestion is general and does not pinpoint a specific issue within the figure.", "verifiability_rationale": "The reviewer makes a suggestion that Fig. 1 should be drawn better. This constitutes a claim (an opinion or judgment about the figure). However, the reviewer does not provide any justification or reasoning for why Fig. 1 *should* be drawn better. There is no logical reasoning, common knowledge, or external references provided to support this suggestion.", "helpfulness_rationale": "The reviewer suggests that Fig. 1 should be drawn better. While this is a relevant suggestion for the presentation of the paper, it does not directly address any identified weaknesses or errors in the methodology or experimental setup. The suggestion is for improvement in presentation rather than for addressing specific issues in the core work. Therefore, it does not provide actionable feedback on any specific weaknesses."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem ('abbreviations like \"MoCo\" should not appear') and suggests a solution ('since a reader might not know what it means'). This constitutes an explicit action. The reviewer directly tells the author what needs to be done. The action is to remove or rewrite the section header containing the abbreviation, which is a concrete action. The reviewer clearly identifies the specific part of the paper (Section 136) and the issue within it (presence of an abbreviation). The suggestion is directly related to this identified part.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section (136)' and the content within that section, specifically mentioning 'MoCo'. This is a literal mention of the section number, making it fully grounded. The comment clearly identifies the specific part of the paper being addressed. The reviewer then provides a specific suggestion related to this part, namely, to ensure the abbreviation is clear to the reader.", "verifiability_rationale": "The review point contains a claim: 'abbreviations like \"MoCo\" should not appear in the section header, since a reader might not know what it means'. This claim is verifiable through common sense and best practices for writing. The reasoning is that readers might not be familiar with the abbreviation and could find it confusing. While it doesn't provide a specific citation, the logic is generally accepted and verifiable.", "helpfulness_rationale": "The review point directly identifies a practical issue (the presence of an abbreviation in a section header) and offers a clear and actionable suggestion (to make it clear to the reader). This is 5 because it directly addresses a potential source of confusion for the reader and provides a clear direction for improvement. The suggestion is concrete and directly related to the identified problem."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer states their opinion about the paper's novelty and suggests a type of improvement ('topic entities'). This indicates an attempt to provide actionable feedback. However, the suggestion is vague and lacks specific details on how to implement the improvement, making it only partially actionable.", "grounding_specificity_rationale": "The reviewer makes general statements about the improvements and novelty, without specifying which datasets or aspects of the paper are being criticized. The suggestion for improvement is also very broad, lacking specificity.", "verifiability_rationale": "The reviewer's statements are opinions, not claims that require verification. They are expressing their assessment of the paper's value, not presenting facts that need to be proven.", "helpfulness_rationale": "The reviewer's comments are primarily negative, focusing on the perceived limitations of the work. While they identify a potential area for improvement, the suggestion is too vague and lacks concrete steps, making it unhelpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states \"Only marginal improvements over baselines...\" which is an explicit action suggesting the author doesn't see significant gains. However, the reviewer doesn't specify *what* aspects of the method or results are affected by these marginal improvements. While the reviewer claims the method performs better than baselines, the lack of specificity makes it difficult to act upon. The reviewer also states \"Although the authors claim the method performs better than the baselines...\" which implies an expectation of improvement, but the subsequent statement \"the error range is rather high, suggesting that the performance differences between some methods are not very significant\" indicates uncertainty about the actual magnitude of the improvement. The reviewer's statement is clear and actionable in identifying a potential issue, but the lack of detail makes it 3.", "grounding_specificity_rationale": "The reviewer makes a general statement about the overall performance of the method compared to baselines. They do not explicitly identify a specific part of the paper or result where the marginal improvements occur. The reviewer mentions \"marginal improvements\" and \"performance differences between some methods are not very significant,\" but these are general statements about the overall performance, not specific to a particular section or table. The reviewer does not provide specific examples or details about what aspects of the method or results are affected by these improvements. The lack of specificity in identifying the area of improvement makes the grounding weak.", "verifiability_rationale": "The reviewer makes a claim that \"Only marginal improvements over baselines...\" and \"Although the authors claim the method performs better than the baselines...\". However, the reviewer does not provide any evidence or justification for this claim. They state \"the error range is rather high, suggesting that the performance differences between some methods are not very significant,\" which is presented as a fact without further explanation or reference to external sources. The reviewer does not explain *why* the error range is high or *why* the performance differences are not significant. There is no logical reasoning, common knowledge, or external references provided to support the claim that the method performs better than the baselines despite the high error range. The reviewer's statement is a claim without sufficient support.", "helpfulness_rationale": "The reviewer's comment primarily focuses on questioning the significance and reliability of the claimed improvements. While the reviewer points out the high error range, they do not offer any specific suggestions or insights to address this issue. The reviewer's comment is framed as a concern about the results rather than a constructive suggestion for improvement. The reviewer does not provide any actionable steps or guidance for the authors based on their findings. The comment is primarily critical and does not offer any value to the authors in terms of actionable advice or evidence. The reviewer's comment is not helpful in guiding the authors towards improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states 'It is still unclear how to make the new proposed evaluation set more diverse and representative than the previous method and how to select those representative images.' This statement is explicit in identifying uncertainty but is vague in specifying the exact nature of the uncertainty. The reviewer doesn't pinpoint which aspects of the evaluation method or the image selection process are unclear. Therefore, while the reviewer's intent is clear, the specific action needed is not welldefined.", "grounding_specificity_rationale": "The reviewer mentions 'the new proposed evaluation set' and 'representative images' but does not specify which evaluation set or images are being referred to. The reviewer also does not clearly identify which part of the evaluation method or image selection process is unclear. The grounding is weak because the specific elements being discussed are not explicitly named.", "verifiability_rationale": "The reviewer makes a claim: 'It is still unclear...'. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. There is no logical argument, external references, or examples given to justify the statement of uncertainty. The claim is presented without any backing.", "helpfulness_rationale": "The reviewer's comment is a question and a statement of uncertainty ('It is still unclear...'). While this points to a potential area for improvement in the draft, it doesn't directly identify a problem or offer a solution. The comment is more of a request for clarification than a critique or a suggestion for improvement. Therefore, it is not particularly helpful in its current form."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'include a background section' and 'provide a brief overview of the original DPO algorithm'. However, it does not specify *how* to implement these actions, such as which section to add the background to or what specific elements of the MDP to cover. The action is stated, but the concrete steps are missing.", "grounding_specificity_rationale": "The comment explicitly mentions 'a background section' and 'the original DPO algorithm', directly identifying the specific part of the paper being addressed. The grounding is strong as it points to specific elements of the paper. The comment also specifies what is missing ('lack of') and what is needed ('introduce', 'overview'). The specificity is good as it points to the need for background information on RL and a description of DPO.", "verifiability_rationale": "The comment contains a claim: 'Without this, it is difficult to follow the subsequent sections' and 'Additionally, a brief overview of the original DPO algorithm should be provided'. The claim is supported by stating the consequence ('difficult to follow') and the suggestion ('provide a brief overview'). The reasoning is clear and directly related to the identified issue. The claim is verifiable as it highlights a logical connection between the missing background and the difficulty in understanding the subsequent sections, and the suggestion directly addresses the identified problem. The claim is wellsupported by logical reasoning.", "helpfulness_rationale": "The review point directly identifies a potential knowledge gap for the authors (lack of background on RL and DPO) and provides a clear direction for improvement ('include a background section' and 'provide a brief overview of the original DPO algorithm'). This is a helpful call to action that addresses a likely need for the authors to understand the context of the paper. While it doesn't provide specific implementation details, it clearly points out what is missing and what should be added. The reviewer is making a logical connection between the missing background and the difficulty in understanding the subsequent sections, and the suggestion directly addresses the identified problem. This is a valuable piece of feedback that guides the authors in improving their understanding of the paper's context."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks 'Is 'interpretable' program relevant to the notion described in the work of 'DoshiVelez, F., & Kim, B. (2017). Towards a rigorous science of interpretable machine learning. arXiv preprint arXiv:1702.08608'?'. This is an explicit action to identify a potential connection or distinction. The reviewer is also asking for a clarification, which implies a lack of immediate understanding, making the action concrete.", "grounding_specificity_rationale": "The reviewer directly mentions the work of DoshiVelez and Kim. This is a literal mention of a specific paper, providing strong grounding. The reviewer is also asking about the *relevance* of their concept to a *specific definition* of interpretability in that paper, adding to the specificity.", "verifiability_rationale": "The reviewer is making a claim about the relevance of their concept to a specific definition of interpretability. This claim can be verified by comparing the definitions and understanding the context of both the reviewer's work and the DoshiVelez and Kim paper. While the verification might require some effort on the reviewer's part, the claim is verifiable.", "helpfulness_rationale": "The reviewer is asking a very specific question about the relationship between their work and a particular definition of interpretability. This is a 5 request aimed at improving understanding and potentially addressing a potential point of confusion. The potential for helpfulness is high as it directly addresses a specific concern."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a limitation in the experimental setup but does not explicitly state an action or provide concrete steps for the authors to take. While it points out the lack of diversity in datasets, it doesn't tell the authors how to address this limitation. Therefore, it is not 5.", "grounding_specificity_rationale": "The review point explicitly mentions 'MNIST' and 'a single realworld dataset'. This allows the authors to identify the specific part of the paper being addressed, which is the 'experiments' section. However, it doesn't pinpoint a subsection, table, or figure. Therefore, it is 3.", "verifiability_rationale": "The review point makes a claim about the limitations of the experiments. While it identifies the datasets, it doesn't provide specific evidence or references to support this claim. The verifiability is limited as the authors would need to independently verify the number and nature of the datasets used in their own work or similar studies. Therefore, it is underspecified.", "helpfulness_rationale": "The review point identifies a weakness in the experimental setup (limited datasets). However, it does not offer any suggestions or guidance on how the authors can improve their experiments. It is a diagnosis of a problem, not a prescription for a solution. Therefore, it is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'I agree the efficiency could be improved since the FLOP is quadratic on activation side length. But in terms of parameters, more details are expected'. This is a direct and actionable suggestion for the authors to clarify the parameter behavior in the S2D structure. The reviewer identifies a specific area of concern and proposes a concrete step to address it by seeking more details.", "grounding_specificity_rationale": "The reviewer refers to 'S2D structure' and 'the number of parameters' as the specific area of concern. While they don't provide a precise section number, the concept is clearly defined and localized to the discussion of the S2D structure and its parameters. The reviewer identifies the specific issue within this broader concept.", "verifiability_rationale": "The reviewer makes a claim: 'the paper is not clear why the number of parameters does not change'. They then provide an example of how parameters should behave if kernel height/width stay the same (increased depth). They also suggest a solution ('more details are expected'). This claim is supported by logical reasoning (the relationship between kernel size, depth, and parameters) and the reviewer provides a clear example to illustrate the expected behavior. The reviewer explicitly states a lack of clarity and provides a basis for further investigation.", "helpfulness_rationale": "The reviewer points out a potential point of confusion for the authors regarding the parameter consistency in the S2D structure. They request clarification on a specific technical detail. This directly addresses a likely area of uncertainty for the authors and encourages them to seek more information. While the reviewer doesn't propose a solution, they highlight a potential issue that needs addressing, which is helpful for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a potential improvement by suggesting the proposed method could incorporate scoring causal predictions and interventional data, similar to approach 10. However, it doesn't explicitly state what action the authors should take to implement this improvement or how they should go about it. The reviewer suggests 10 cannot use this side information, but doesn't provide a concrete reason why or how 10 might be modified to do so. The reviewer also doesn't specify how the authors should use this information if it were available. While the reviewer points out a potential avenue for improvement, they don't provide actionable steps for the authors to follow. The reviewer's statement about 10 is a hypothesis, not a direct instruction. Therefore, the review point lacks explicit actionability as it doesn't tell the authors what to do or how to do it.", "grounding_specificity_rationale": "The reviewer mentions 'approach 10' and 'scoring causal predictions' and 'interventional data'. This indicates a degree of grounding as the reviewer refers to a specific paper and a specific idea within that paper. However, the reviewer doesn't explicitly state the exact section or table in 10 where these concepts are discussed or relevant. The grounding is weak because the authors would need to go back and forth between their paper and 10 to find the connection. The reviewer implies the similarity but doesn't pinpoint the exact location of the relevant information in 10.", "verifiability_rationale": "The reviewer claims that the proposed method is 'very similar in spirit' to 10 and suggests that 10 'can also be equipped with scoring causal predictions and the interventional data'. This statement is presented as a possibility without any evidence or justification. The reviewer doesn't provide any logical reasoning, common knowledge, or external references to support this claim. The reviewer also doesn't explain why 10 *cannot* use these side information. The reasoning is speculative and lacks verifiable support. The reviewer doesn't provide any concrete examples or references to back up their claim about 10. The reasoning is based on a hypothesis, not a verified fact.", "helpfulness_rationale": "The review point raises a valid question about potential improvements and suggests a logical extension of the proposed method by drawing parallels to 10. However, it fails to provide any concrete suggestions or actionable steps for the authors. The reviewer asks 'why 10 cannot use these side information?' but doesn't offer any explanation or evidence to support this claim. The reviewer also doesn't suggest any specific ways the authors could implement the suggested improvement. The review point is more of a point for discussion than a direct recommendation for improvement. It lacks the necessary details and concrete steps to be helpful to the authors. While the reviewer identifies a potential area for future work, they don't provide any specific guidance on how the authors should proceed."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the absence of a sparsity constraint and its consequence on the number of factors, which is a direct and actionable improvement for the authors to consider.", "grounding_specificity_rationale": "The reviewer's criticism is not tied to a specific section or element of the paper, making the grounding weak. While they identify the issue (lack of sparsity constraint), they don't pinpoint where in the paper this relates to.", "verifiability_rationale": "The reviewer makes a claim about the implications of the lack of a sparsity constraint, but they do not provide explicit reasoning or references to support this claim, making it 3.", "helpfulness_rationale": "The reviewer provides a clear and actionable criticism that directly relates to the method's design and potential limitations, making it 5 for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: 'the authors do not really comment on why the GPC (benchmark) is performing better than BPC (their method).' This is a clear and direct criticism, identifying a lack of explanation for a specific result. The reviewer then provides a reason: 'this is b/c of the bandit feedback and not using information about the form of the cost function.' This makes the criticism actionable, as it points to a specific area where the authors should look for further analysis.", "grounding_specificity_rationale": "The reviewer's point is generally about the presentation of the simulation study. While the reviewer doesn't explicitly name a specific section or table within the paper, they are commenting on the *overall* presentation of the simulation results. This makes the grounding *weak*. However, the reviewer *does* specify *what* is being criticized: 'why the GPC (benchmark) is performing better than BPC (their method).' This specificity makes the criticism somewhat specific, as it focuses on the performance difference between the two methods. Therefore, it's weakly grounded but somewhat specific.", "verifiability_rationale": "The reviewer makes a claim: 'the authors do not really comment on why the GPC (benchmark) is performing better than BPC (their method).' This claim is supported by the reasoning provided in the review point: 'this is b/c of the bandit feedback and not using information about the form of the cost function.' This reasoning is logical and based on established concepts, making the claim 5.", "helpfulness_rationale": "The reviewer's point is constructive. They are not simply pointing out a flaw but are offering a potential explanation and suggesting it be highlighted. While they don't propose a solution, they identify a *need* for better explanation of the simulation results. This makes the criticism 5 in guiding the authors' analysis."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states, 'I might be helpful to quantify and clarify the claim \"ReLU does not work very well in very deep or in convolutional networks.\"' This is a clear indication of an explicit action. Furthermore, the reviewer suggests 'quantifying' and 'clarifying,' which are concrete actions that the authors can take. The reviewer also suggests 'specifically mentioning the AlexNet paper,' which is a concrete and actionable suggestion. The reviewer's comment directly addresses a potential weakness in the paper's description of ReLU usage. The reviewer is not just stating an opinion but suggesting a specific way to improve the understanding of ReLU's limitations.", "grounding_specificity_rationale": "The reviewer mentions 'convolutional networks' when identifying a potential weakness of ReLU. This grounds the comment to a specific aspect of the paper. The reviewer also mentions 'very deep networks,' which is a general concept but often tied to the context of ReLU limitations. Furthermore, the reviewer suggests 'specifically mentioning the AlexNet paper,' which grounds the comment to a specific example of ReLU usage within a convolutional network. The reviewer also suggests 'clarifying the limitations of ReLU in these contexts,' which adds further specificity to the feedback. The reviewer is not just making a general statement but is pointing to a specific area of the paper and even suggesting a specific paper to look at.", "verifiability_rationale": "The reviewer makes a claim: 'ReLU does not work very well in very deep or in convolutional networks.' This is a clear claim that needs to be supported. While the review point itself doesn't provide direct evidence *within this point*, the reviewer *implies* a belief that the original paper made this claim. The reviewer suggests 'quantifying' and 'clarifying,' which implies a belief that the original paper's claim needs more support. The reviewer also suggests 'specifically mentioning the AlexNet paper,' which can be seen as an attempt to provide external reference. The reviewer's comment suggests that the claim is *interpretable* and *plausible* based on their understanding of ReLU and its use in AlexNet. The reviewer is not just stating a random claim but is making a claim that is potentially verifiable with further investigation or clarification.", "helpfulness_rationale": "The reviewer directly addresses a potential issue with ReLU usage in the paper. They suggest 'quantifying' and 'clarifying,' which are actionable steps the authors can take to understand the limitations of ReLU in their specific context. The reviewer also suggests 'specifically mentioning the AlexNet paper,' which is a concrete suggestion for the authors to look at a specific example. The reviewer's comment is focused on improving the understanding of ReLU's behavior and its impact on deep and convolutional networks. The suggestions are directly related to improving the draft and are not vague or general. The reviewer is providing a clear direction for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "Weakly Grounded and Partially Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the need for 'experiments on distributed deployment' and 'a larger model'. These are direct and clear actions the authors should take. The phrasing is direct and implies specific modifications.", "grounding_specificity_rationale": "The review point mentions 'distributed deployment' and 'a larger model'. While it doesn't pinpoint a specific section, table, or figure, it clearly refers to specific types of experiments and model characteristics. This implies a degree of grounding as the authors can infer the need for these specific aspects of evaluation. The specificity is in the *type* of experiment/model requested, but not the exact implementation details.", "verifiability_rationale": "The review point states a need for 'experiments on distributed deployment' and 'a larger model' without providing any justification or reasoning for why these are necessary. There are no claims, opinions, or suggestions about the benefits or implications of these actions. It's a statement of what needs to be done, but not why or how.", "helpfulness_rationale": "The review point identifies a need for more comprehensive experimentation and the use of larger models. While it doesn't provide specific implementation details, it points to concrete areas where the authors can improve their draft. It suggests a direction for action, even if that direction lacks precise specification."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states two actions that need to be taken: 'discuss why it is important for the patterns to be rooted' and 'how they choose the roots'. These are direct and actionable steps that the authors can follow.", "grounding_specificity_rationale": "The reviewer does not explicitly identify a specific part of the paper where the importance of rooted patterns is discussed. While the reviewer suggests a potential simplification to nonrooted patterns, this is a generalization and not a specific instruction. The reviewer's comment is highlevel and lacks a clear connection to a specific section or element of the paper.", "verifiability_rationale": "The reviewer states a fact ('A brief discussion is expected...') and offers a potential solution ('it might be better for the sake of exposition to discuss this case only in the supplementary material'). This statement is verifiable, as it proposes a concrete action and a specific location for that action. The reasoning is logical and directly addresses the lack of clarity.", "helpfulness_rationale": "The reviewer's suggestion to discuss the importance of rooted patterns and how roots are chosen directly addresses a potential lack of clarity and motivation in the paper. This is a constructive suggestion that empowers the authors to improve their draft. While the suggestion is not a definitive solution, it provides a clear direction for the authors to seek further explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a claim about the need for more explanation regarding the consistency between training and inference (Line 9597, Line 308310). However, the reviewer does not specify how to achieve this more detailed explanation. The action is stated, but the concrete steps are missing.", "grounding_specificity_rationale": "The reviewer mentions specific line numbers (Line 9597, Line 308310) where the issue is discussed, indicating that the authors can identify the specific part of the paper being addressed. However, the reviewer does not specify what is wrong with the consistency or how to explain it based on these lines.", "verifiability_rationale": "The reviewer makes a claim about the consistency between training and inference being easily satisfied due to the smoothness of neural models and suggests providing more explanations. The reviewer does not provide any specific examples, citations, or logical reasoning to support this claim. The claim is stated, but there is no evidence to back it up.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: to give more explanations on the consistency between training and inference. This directly addresses a point raised in the paper and offers a concrete improvement for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point identifies an unclear aspect (base layer GNN encoding) and suggests an action (ablation study). However, it doesn't specify *why* it's unclear or *how* the ablation study would be conducted, making it somewhat, but not fully, actionable.", "grounding_specificity_rationale": "The reviewer mentions \"base layer GNN encoding\" but doesn't explicitly link it to a specific section, table, figure, or unique element of the paper. The explanation of what is unclear is also vague.", "verifiability_rationale": "The review point is a question (\"It's unclear...\") and doesn't make a claim that requires verification or justification.", "helpfulness_rationale": "The review points out a potential area of confusion (\"unclear base layer GNN encoding\") and suggests an action (ablation study). However, it lacks specific details about the uncertainty or the scope of the ablation study, making it somewhat, but not fully, helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem of the paper not adequately discussing the computational complexity of counting homomorphisms. They also suggest concrete actions, such as explicitly mentioning upper bounds and elaborating on empirical runtimes. This indicates a clear and direct identification of the issue and potential solutions.", "grounding_specificity_rationale": "The reviewer mentions 'computational complexity' and specifically refers to a line in the paper (line 145) where they discuss efficient computation. They also suggest 'improving the paper' by explicitly stating upper bounds and elaborating on runtimes, which are specific actions and details.", "verifiability_rationale": "The reviewer claims that the paper lacks a discussion on the computational complexity of counting homomorphisms. This is a claim that could be verified by examining the paper. While the reviewer doesn't provide specific references or examples within the review point itself, the suggestion to 'improve the paper' implies a potential gap in the current discussion.", "helpfulness_rationale": "The reviewer identifies a specific weakness in the paper \u2013 the lack of discussion on the computational complexity of counting homomorphisms \u2013 and provides concrete suggestions for improvement. They suggest explicitly stating upper bounds and elaborating on empirical runtimes. This directly addresses potential needs for the authors and offers actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states two actions the authors should take: 'we fixed the form of ..' and 'One Question: For the baseline MCL with deep learning, how did the author ensure that each of the networks have converged to a reasonable results'. These are clear and actionable steps. The reviewer is not asking the authors to infer what needs to be done, but rather directly points out specific issues and asks a direct question related to the method.", "grounding_specificity_rationale": "The review point explicitly refers to 'line 108' and the specific phrase 'the form of ..'. This demonstrates strong grounding as the reviewer is directly pointing to a specific location and detail in the paper. The suggestion to 'fix the form' is also quite specific.", "verifiability_rationale": "The review point makes two claims: 1) there is a typo ('f' should be 'g') and 2) the MCL baseline's convergence needs clarification. The typo is verifiable through direct observation of the text. The request for clarification on MCL convergence is verifiable by referencing relevant literature on ensemble methods and deep learning convergence.", "helpfulness_rationale": "The review point directly identifies a likely typographical error, which is a minor but important detail for readability and professionalism. The request for clarification on the MCL baseline is also 5 as it directly addresses a potential area of concern or misunderstanding in the methodology. The suggestions are clear and directly address the identified issues."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a missing element (inference time study) and suggests a reason (direct nature of the method) and a potential solution (comparing to other methods). While the suggestion is not a direct stepbystep action, it clearly identifies an area for improvement and guides the authors on how to approach it. The reviewer implicitly suggests the authors should investigate inference time and compare their method to existing approaches.", "grounding_specificity_rationale": "The reviewer states that the method is 'a pose estimation method that is direct and does not require detection or keypoint grouping'. While this describes the *nature* of the method, it doesn't explicitly identify a *specific* section, table, figure, or unique aspect of the paper where this should be studied. The suggestion is general and doesn't pinpoint a location for the study.", "verifiability_rationale": "The reviewer makes a claim: 'This is a pose estimation method that is direct and does not require detection or keypoint grouping.' This claim is verifiable by examining the method's description in the paper. The reviewer also suggests comparing the inference time to 'previous topdown and bottomup pose estimation methods'. While the suggestion itself isn't a verifiable claim about the current work, the underlying idea of comparing inference time is a valid point that can be supported by external references or logical reasoning about performance evaluation.", "helpfulness_rationale": "The reviewer identifies a relevant aspect of the work (performance evaluation, specifically inference time) and provides a clear direction for improvement (comparing to other methods). While the suggestion is not the most specific possible, it directly leads to a concrete next step for the authors and highlights a potential area for optimization or further research. The reviewer's point is valuable and actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out two concrete errors in the mathematical formulation within the proof. They state 'In Theorem A.3 proof, how the input x has two indices?' and 'Moreover, shouldn\u2019t \u2211 k ( W k ( 2 ) ) 2 = 1 / d , not d ?'. These are direct, actionable criticisms that the authors can use to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly references 'Theorem A.3 proof' and points to the specific equations mentioned in the review point. The grounding is literal and precise, indicating a high level of grounding. The specificity is also high as the reviewer identifies two distinct issues within the proof.", "verifiability_rationale": "The reviewer makes specific claims about errors in the proof. The verifiability is high because the reviewer provides clear directions on how the authors can verify these claims: 'Check the derivation of the sum of squares in the proof and verify the dimensionality of the input vector.'", "helpfulness_rationale": "The reviewer provides a highly specific and actionable critique of a mathematical error in the appendix. The reviewer clearly identifies two distinct issues, making the feedback very targeted and helpful for the authors to understand and correct the error."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states a concern about the use of vague terms like 'somewhat' and 'good generative ability' in the description. This indicates an explicit action or suggestion. However, the reviewer also raises a question about how to ensure the correctness of pluggedin entities/relationships without ground truth, which makes the action vague and lacking detail on how to apply it. The vagueness of the suggestion makes the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions sections 4.3 and 4.4, showing some level of grounding as they are aware of the paper's structure. However, they do not explicitly identify the specific part within those sections that is problematic. The lack of a precise reference to a sentence, table, or figure makes the grounding weak. Furthermore, the reviewer does not specify what needs to be addressed in that part (e.g., the incorrect entities/relationships). This lack of specificity makes the grounding weakly specific.", "verifiability_rationale": "The reviewer raises a question about how to ensure the correctness of pluggedin entities/relationships without ground truth. While the reviewer identifies a problem (lack of grounding), they do not provide any evidence or reasoning to support this claim within the review point itself. The claim is presented as a question arising from the paper's lack of grounding, but the review point doesn't offer any justification or solution for this concern. Therefore, the verifiability of this claim is 1.", "helpfulness_rationale": "The reviewer raises a valid concern about the methodology and the potential for ambiguity in the results. However, the reviewer does not offer any concrete solutions or suggestions to address this issue. The comment reflects a concern but does not actively contribute to the paper's improvement by providing actionable feedback or a solution to the identified problem. Therefore, the helpfulness of this review point is limited."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of FedPCL regarding its dependence on pretrained models and the sensitivity of performance to this choice. They also explicitly state that the new framework addresses this limitation. This is a clear and actionable point.", "grounding_specificity_rationale": "The reviewer clearly identifies 'FedPCL' as the relevant part of the paper and explicitly states the issues related to its reliance on pretrained models. They also specify the consequences of this reliance, making the grounding strong and the specificity clear.", "verifiability_rationale": "The reviewer makes a claim that the new framework 'adequately addressed the limitations.' They then provide specific details about the new framework's features (lightweight, reduced costs, prototype extraction) as evidence supporting this claim, making it verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion by proposing a new framework to address the identified limitation of FedPCL. They explain the impact of the limitation (sensitivity to pretrained models) and offer a concrete solution, making the comment 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly suggests an action: 'see' the tentative attention maps. This indicates a clear direction for the authors to take. While it doesn't specify *how* to implement this action, the suggestion itself is a concrete step they can follow to potentially improve their understanding of the model's attention mechanisms.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper or the draft. It is a general suggestion related to visualization. Therefore, it is 1 in the specific context of the work.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a suggestion for the authors to explore further analysis. Therefore, it does not fall under the 'Verifiability' aspect.", "helpfulness_rationale": "The comment provides a suggestion that is relevant to understanding attention mechanisms and could potentially lead to improvements in the model's interpretability. While it doesn't provide a definitive answer or solution, it offers a concrete direction for the authors to explore, making it helpful in guiding their investigation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the current structure is confusing and suggests concrete actions to improve it. The suggestions are directly tied to the identified issues, making them actionable. The reviewer points out the scattered description of the layerwise attention mechanism and proposes a solution, which is a clear action.", "grounding_specificity_rationale": "The reviewer explicitly mentions sections 2.3 and 2.4 where the attention mechanisms are described. This is a clear and precise identification of the relevant part of the paper. The reviewer also identifies the need to reference normalization and feature scaling, which are specific techniques. While the exact subsections for these techniques are not named, the general area is welldefined.", "verifiability_rationale": "The reviewer makes claims about the current organization and the need for improvement. These claims are supported by logical reasoning. The reviewer suggests specific actions, such as moving sections and creating a separate section, which are clear and verifiable. The suggestions are based on common sense and best practices in academic writing.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as moving sections and adding a section for references. These suggestions are directly aimed at addressing the identified weaknesses and are actionable for the authors. The reviewer's comments are clear, concise, and directly helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'I don't understand Figure 5', indicating a need for the authors to take action to clarify or explain this figure. The comment is direct and points to a specific area of confusion, making it actionable. The reviewer is asking for a solution or clarification, which is a concrete action the authors can take to improve their understanding.", "grounding_specificity_rationale": "The reviewer mentions 'Figure 5' generally and points to a potential issue with the 'labels'. They do not specify which part of Figure 5 they are struggling with (e.g., a specific label, the overall interpretation, the connection to the text). The comment is about a general lack of understanding related to this figure, not a specific element within it. Therefore, while the reviewer is referring to a specific paper element, the comment itself lacks precise identification of the issue within that element.", "verifiability_rationale": "The reviewer states 'I don't understand Figure 5' and suggests 'labels are wrong'. This is a statement of a problem, not a claim requiring verification. There is no logical reasoning, common knowledge, or external references provided to support this statement. The reviewer is expressing a concern but hasn't provided evidence or justification for why they don't understand or why the labels are incorrect. Therefore, the claim is not verifiable based on the information provided.", "helpfulness_rationale": "The reviewer identifies a specific area of confusion ('Figure 5') and suggests a potential cause ('labels are wrong'). This points to a clear weakness in the draft that needs improvement. While the comment doesn't offer a solution, it highlights a concrete area where the authors can seek clarification or correction. The reviewer is providing a specific example of a problem, which is helpful for guiding the authors to improve their understanding of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The comment explicitly states the action of 'adding missing supervised baselines' and provides a clear indication of what is missing ('missing'). This makes the action quite explicit. However, it doesn't specify the *how* or *which* baselines to add, making it somewhat vague.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper being addressed. It refers to 'supervised baselines' in general, which could be anywhere in the paper. Therefore, the grounding is weak. While it specifies what is missing ('missing'), it doesn't pinpoint where this omission occurs or what specific aspect of the supervised baselines is lacking.", "verifiability_rationale": "The comment contains a claim ('add missing supervised baselines') that suggests a beneficial improvement. However, it lacks specific justification or examples to support this claim. It doesn't provide any logical reasoning, common knowledge, or external references to back up the suggestion. Therefore, the verifiability is low.", "helpfulness_rationale": "The comment identifies a valid area for improvement (including baselines) and suggests a concrete action (adding them). However, it lacks specifics on *which* baselines or *how* to implement the comparison, making it less impactful than a more detailed suggestion. It's a suggestion without concrete details, making it 3 but not fully helpful."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "1", "verifiability_label": "1 (1)", "helpfulness_label": "1 (2)", "actionability_rationale": "The reviewer explicitly states three actions: questioning the method's novelty on deterministic systems, suggesting evaluation on stochastic domains, and pointing out the missing BEAR baseline. While the actions are clear, the underlying reasoning for these actions is not detailed.", "grounding_specificity_rationale": "The reviewer does not explicitly identify a specific part of the paper they are referring to when making their points. They are generally commenting on the method's applicability and the experimental setup.", "verifiability_rationale": "The reviewer makes several claims, such as questioning the method's novelty, suggesting evaluation on stochastic domains, and pointing out the missing BEAR baseline. However, the reasoning and justification for these claims are not provided.", "helpfulness_rationale": "The reviewer's suggestions are relevant to improving the method's description and evaluation. However, the lack of specific justification and evidence makes it difficult to assess the actual impact of these suggestions on the authors' understanding and ability to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation of the proposed method but does not explicitly state what the authors should do to address this limitation. The suggestion is more of a concern than a direct action.", "grounding_specificity_rationale": "The reviewer identifies a general weakness in the proposed method's ability to detect hallucinations in openended responses but does not specify which part of the method or process is problematic. The explanation is underspecific.", "verifiability_rationale": "The reviewer makes a claim about the method's limitations and provides a specific example to support it. While the claim is not universally proven, it is supported by a specific instance.", "helpfulness_rationale": "The reviewer highlights a potential limitation of the proposed method, which could be helpful for the authors to be aware of and consider. It's a constructive critique."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action the authors should take: 'verify the conclusion about the label noise and model size on MNIST and CNN.' This is a clear and direct instruction, making it 5. The reviewer is directly prompting the authors to perform a specific task.", "grounding_specificity_rationale": "The reviewer suggests verifying the conclusion on specific, wellknown datasets (MNIST) and model architectures (CNNs). While this demonstrates an attempt to ground the theoretical findings in a concrete experimental setting, the review point itself does not *require* the authors to perform this verification at this time. The reviewer is suggesting a future step, not a current grounding of the work.", "verifiability_rationale": "The reviewer states, 'It is unclear how these theoretical findings relate to realworld deep learning models,' which is a claim that needs to be supported. However, the review point itself does not provide any evidence or reasoning to support or refute this claim. The lack of justification makes the claim 1 based on the information provided in the review point.", "helpfulness_rationale": "The reviewer's suggestion to verify the conclusion on MNIST and CNN is a constructive and helpful comment. It directly addresses a perceived weakness (the lack of connection to realworld models) and provides a clear direction for the authors to take. The reviewer is offering a concrete improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment implicitly suggests an action: creating a table to compare CoT methods. However, it doesn't explicitly state how to implement this action, such as identifying the specific dimensions for comparison or the CoT methods to include. Therefore, while the action is implied, the lack of detail makes it somewhat vague.", "grounding_specificity_rationale": "The comment doesn't explicitly identify the specific part of the paper being addressed (e.g., a particular section or table). It refers to 'section 4.2' which is a general reference. While the reviewer is implicitly pointing to the experimental setup and methodology, they don't explicitly state which specific aspect of the paper they are referring to. Therefore, the grounding is weak.", "verifiability_rationale": "The comment raises a question about the assumption of 'frequenterror clusters' and the token/step thresholds. While it suggests a potential area for further investigation, it doesn't provide a clear justification or evidence for or against this assumption. It also doesn't offer a specific alternative threshold. The reasoning is presented as a question rather than a claim supported by evidence. Therefore, the verifiability is somewhat borderline.", "helpfulness_rationale": "The review point offers several concrete suggestions for the authors. Firstly, it suggests a table to compare different CoT prompting methods, which is a clear and actionable suggestion. Secondly, it questions the assumption that 'questions of all the wrong demonstrations fall into the same frequenterror cluster', prompting the authors to consider alternative explanations for their results. Finally, it challenges the chosen token and step thresholds in section 4.2, encouraging the authors to reevaluate their experimental setup. All these suggestions are directly aimed at improving the authors' work and provide clear directions for them to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point points out a *potential* issue (large training loss with suboptimal weight decay) and suggests a *consequence* (suboptimal cosine similarities). It also mentions the *lack of reporting* of cosine similarities for strong weight decay. While it identifies areas of concern, it doesn't explicitly *recommend* an action like investigating the training loss or exploring alternative weight decay strategies. It also doesn't provide a concrete *fix*. The reviewer states a relationship between weight decay and cosine similarity but doesn't directly tell the author *what* to do. The suggestion is implicit.", "grounding_specificity_rationale": "The reviewer mentions \"cosine similarities for such large weight decay strengths are not reported\" and \"the plots end at a weight decay strength where cosine similarities are still close to optimal.\" These phrases directly refer to the specific aspects of the paper being discussed (cosine similarities and weight decay strengths). The reviewer is also referencing the parameters of the weight decay (strengths).", "verifiability_rationale": "The reviewer states a *prediction* about the behavior of the model with suboptimal weight decay (\"we would expect a large training loss...\") and points out a *lack of reporting* of cosine similarities. These are statements that could be verified through experimentation or analysis. The reviewer also states a *consequence* (\"we would expect... thus suboptimal cosine similarities\"). While the reviewer doesn't provide specific evidence *within this review point*, they highlight a potential area where further investigation could be beneficial by pointing out the missing cosine similarity reporting.", "helpfulness_rationale": "The review points out a potential issue (large training loss with suboptimal weight decay) and suggests investigating the cosine similarities. While it doesn't offer a definitive solution within this point, it identifies a direction for further analysis. The reviewer highlights a potential gap in the reported results (lack of cosine similarity reporting for strong weight decay) and suggests exploring the implications of this gap. This points out a valuable area for further investigation that could lead to improvements in the model's training and performance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests *specific analyses* to perform (impact of cost, reward incentives, collective return) and *specific scenarios* to explore (different alpha values, roles of winners/cooperators). However, it does not explicitly name an action to *do* next with the paper itself. The action is implied but not stated directly.", "grounding_specificity_rationale": "The review point is general and doesn't mention a specific part of the paper. It talks about 'roles between 'winners' and 'cooperators'' and 'collective return' without linking these concepts directly to a specific section or table in the submitted paper. The reviewer doesn't specify what issue is being addressed.", "verifiability_rationale": "The review point contains a claim: 'It seems like roles between \u201cwinners\u201d and \u201ccooperators\u201d emerge because the cost to reward the other agent becomes high for the cooperators.' This is a statement of observation based on the reviewer's understanding of potential dynamics. However, the reviewer does not provide any specific evidence or references from the submitted paper to support this claim. The reasoning is based on their own understanding of the potential impact of cost, not on verifiable information from the paper.", "helpfulness_rationale": "The review point suggests a *potential research direction* and raises a *specific question* about the cost of incentivization. While it offers a *general idea* for further analysis, it doesn't provide concrete steps or specific feedback on the *current draft* of the paper. The suggestion is interesting and could be valuable for researchers in the field, but it doesn't directly address potential weaknesses or improvements in the submitted paper. It's more of a suggestion for future work than immediate actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the lack of interpretive insights in the discussion and the lack of comparison with stateoftheart methods not based on gyrostructures. It also states that the outperformance of the proposed approach is unclear. These are explicit and concrete actions that the authors should take. While the review doesn't specify *how* to add interpretive insights or *which* methods to compare, the action of addressing these gaps is clear.", "grounding_specificity_rationale": "The review point mentions the 'related discussion' and 'experiments part' where the issues lie. It also mentions 'gyrostructures,' 'SPDbased models,' and 'stateoftheart methods.' While it doesn't pinpoint a specific section or table, it clearly refers to the experimental section and the discussion of results. The grounding is present but not as precise as it could be.", "verifiability_rationale": "The review point states that the 'related discussion lacks interpretive insights' and that there is a 'lack of comparison with other stateoftheart methods that might not rely on gyrostructures.' These are claims that need to be supported. However, the review point does not provide any logical reasoning, common knowledge, or external references to support these claims. The claims are presented as observations or areas for improvement without further justification.", "helpfulness_rationale": "The review point identifies specific weaknesses in the paper, namely the lack of interpretive insights in the discussion and the absence of comparisons with certain stateoftheart methods. While these are valid points that could help the authors improve their work, the review point itself does not offer concrete suggestions or guidance on how to address these issues. It simply points out the areas that need improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states \"I would like to see more details about the two baselines presented in Figure 5.\" This is an implicit request for action. While the reviewer identifies the need for more information, they don't specify *what* details are required. Therefore, the action is identified but not fully specified, making it '3'.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"Figure 5\" when stating \"Figure 5 is hard to comprehend.\" This clearly identifies the specific part of the paper being addressed, achieving 'Full Grounding'. Additionally, the reviewer asks for 'more details about the two baselines presented in Figure 5', which specifies what needs to be addressed in this part. This demonstrates a high level of specificity.", "verifiability_rationale": "The reviewer states \"Figure 5 is hard to comprehend.\" This is a subjective judgment about the clarity of the figure. While the reviewer also suggests providing 'more details about the two baselines presented in Figure 5', this is a request for information, not a claim that can be directly verified. The statement about CATER and translation APIs is a suggestion for future work, which is also not verifiable with a claim. Therefore, the review contains a statement that lacks supporting evidence or justification, making it '1'.", "helpfulness_rationale": "The reviewer's comment directly points out a potential weakness in the paper: the lack of clarity in Figure 5 and the insufficient details about the baselines. They also suggest a relevant improvement: extending CATER to other languages. This feedback is directly related to potential weaknesses and offers a constructive suggestion for improvement. Therefore, the review is '3' as it identifies areas for improvement, but the lack of verifiability makes it difficult to fully assess the value of the feedback."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer states a desire for a clearer literature review and suggests making it 'explicit'. While the reviewer indicates an intention to improve the literature review, the specific actions or changes needed are not explicitly detailed. The reviewer doesn't provide concrete steps on how to make the literature review explicit. Therefore, the action is implied but not fully specified, making it 2.", "grounding_specificity_rationale": "The reviewer mentions 'GFlowNet for sequence generation' as a key area of comparison. This directly identifies a specific part of the paper (the method section, potentially under the related work or experiments) and specifies what needs to be addressed (the distinction from existing work using GFlowNet). The grounding is explicit, and the specificity is about the utilization of GFlowNet for sequence generation.", "verifiability_rationale": "The reviewer states that the literature review is 'not adequate' and needs to be 'clearer'. This constitutes a claim that the literature review is unclear. However, the reviewer does not provide any specific examples or references to support this claim. There is no logical reasoning or external evidence presented to verify the claim. Therefore, the claim is stated but not wellsupported.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'improvement of the literature review'. This directly addresses a potential weakness in the paper (lack of clarity in the literature review) and offers a specific direction for improvement. The suggestion is directly aimed at helping the authors improve their draft. The reviewer also points out a specific area for improvement (literature review)."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states they think section 3.2 can be removed, which is a direct action. However, they do not specify *why* they believe this section is unnecessary or problematic. The action is concrete (identifying the section for removal), but the underlying reasoning is missing.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'section 3.2' as the part of the paper being addressed. This demonstrates strong grounding as the section is clearly identified. However, the reviewer does not specify *what* is wrong with section 3.2 or why it should be removed. The grounding is explicit, but the specificity of the feedback is lacking.", "verifiability_rationale": "The reviewer presents a suggestion ('I would say that section 3.2 can be eliminated') without providing any justification or reasoning for this claim. There are no external references or logical arguments supporting the suggestion. The comment contains a claim (the suggestion to eliminate the section) but lacks sufficient evidence to verify it.", "helpfulness_rationale": "The reviewer suggests eliminating section 3.2. While this is a concrete action (identifying the section), the reviewer does not explain *why* they think this section should be removed. The suggestion is a recommendation for change without a clear rationale. The authors would know an action needs to be taken (eliminate the section), but they wouldn't understand the *reason* for it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the desired improvements by adding performance evaluations on word similarity and sentence translation tasks, and adding experiments on morphologically rich and lowresource languages. The reviewer clearly indicates the specific areas where these additions should be made. The actions to be taken are also clear: evaluate on these tasks and include experiments on these language types. This provides a direct path for the authors to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'word similarity and sentence translation tasks' and 'morphologically rich languages like Finnish, Hebrew, etc.' This clearly identifies the specific parts of the paper being addressed. The use of concrete examples enhances the grounding. The reviewer is not just stating a general idea but pinpointing specific areas within the experiments section. The language used is precise and directly refers to specific aspects of the paper.", "verifiability_rationale": "The reviewer suggests adding performance on word similarity and sentence translation tasks and adding experiments on morphologically rich languages. While the reviewer doesn't provide specific evidence or references to support these suggestions within the review point itself, the *act* of adding these experiments is the verifiable part. The reviewer is making a suggestion that, if implemented, would likely improve the paper's evaluation and robustness. The suggestion is clear and points to specific areas where the experiments should be expanded. The reviewer is not just stating a general opinion but suggesting specific improvements.", "helpfulness_rationale": "The review point provides concrete suggestions for improving the paper. The reviewer explicitly suggests adding performance evaluations on word similarity and sentence translation tasks and adding experiments on morphologically rich and lowresource languages. These suggestions are directly relevant to improving the paper's evaluation and robustness. The reviewer is not just pointing out a problem but suggesting specific, actionable improvements. The suggestions are clear and directly address potential weaknesses in the current experimental setup."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the limitation: 'little insights are given about why do we need to do selfsupervised learning on this kind of data.' This directly points out a missing action or suggestion.", "grounding_specificity_rationale": "The review point refers to 'selfsupervised learning on this kind of data' (360 video with spatial audio), which is a specific part of the paper. However, it does not explicitly state what the 'this kind of data' refers to in terms of its characteristics or why it necessitates selfsupervised learning.", "verifiability_rationale": "The review point contains a claim: 'little insights are given about why do we need to do selfsupervised learning on this kind of data.' However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. It simply states the problem without addressing it.", "helpfulness_rationale": "The review point identifies a valid limitation in the paper: the lack of justification for applying selfsupervised learning to this specific type of data. It highlights a potential gap in the authors' reasoning or analysis. However, it does not offer any suggestions or alternative approaches to address this limitation."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The suggestion is explicit in stating that results should be averaged. However, it lacks specific details on how this averaging should be performed, which makes it somewhat vague on how to execute it.", "grounding_specificity_rationale": "The comment does not specify which part of the paper or experiment this averaging refers to. It is a general suggestion about the process of statistical analysis, making it weakly grounded. It also does not specify what is wrong with the current results or how averaging will address these issues, making it underspecific.", "verifiability_rationale": "The review point does not contain a claim. It is a suggestion for improvement, not a statement of opinion or assertion.", "helpfulness_rationale": "The suggestion is generally helpful as it addresses a common concern in research \u2013 the need for robust statistical analysis. However, it lacks specific details on how to implement the averaging, making it somewhat limited in its immediate impact."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The first part of the review point, 'How the capacity of the SR model affects the FID,' is somewhat explicit as it directly asks a question about a relationship between two key parameters. However, it is somewhat vague as it does not specify how the capacity affects the FID or provide any guidance on how to investigate this relationship. The second part, 'And lastly, since the proposed method is pipelining, there are some unexpected artifacts,' is also somewhat explicit as it points to a specific issue arising from the method. However, it does not provide any specific information about *which* artifacts are unexpected or *how* they were generated. Therefore, while the questions are clear, they lack concrete guidance on how to address them.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or method. It is a general statement about the impact of model capacity on FID and a general observation about unexpected artifacts arising from the pipelining. Therefore, the grounding is weak as the reader has to infer the relevance of the model capacity and artifacts to the proposed method.", "verifiability_rationale": "The review point does not contain a claim. It is a statement of observation ('there are some unexpected artifacts') without providing any evidence or asking a question that could be answered with evidence. Therefore, it does not have verifiability as it lacks a claim to be verified.", "helpfulness_rationale": "The review point identifies two key areas for improvement. The first part, 'How the capacity of the SR model affects the FID,' is helpful as it points to a relevant relationship that the authors might not have considered or could benefit from exploring. The second part, 'And lastly, since the proposed method is pipelining, there are some unexpected artifacts,' is also helpful as it highlights a practical issue with the proposed method that needs to be addressed. Both points are clear and identify meaningful weaknesses or suggestions for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "None", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer points to 'some pretty 'old' benchmarks' and the possibility of 'indirectly seen data.' While it identifies a *potential* area for improvement, it doesn't provide concrete steps or specifics on *how* to analyze these benchmarks or what specific data might be problematic. Therefore, it's partially actionable.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed model' and 'many benchmarks' without specifying a particular benchmark or a unique aspect within the model or data. This means the authors cannot confidently determine which part the comment addresses, making it weakly grounded.", "verifiability_rationale": "The reviewer *claims* that more details about the evaluation procedures would be helpful. The reasoning for this claim isn't explicitly stated in the review point itself. The reviewer is making a suggestion, not providing a justification for *why* more details are necessary. Therefore, it's 3.", "helpfulness_rationale": "The review point identifies a potential area for improvement ('especially for some pretty 'old' benchmarks') and suggests a specific type of analysis ('more careful analysis'). While it doesn't provide concrete steps, it points to a relevant concern and encourages a more thorough investigation. However, it doesn't directly address a specific problem the authors are currently facing, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem: 'In the experimental part, this paper verifies different metrics for different OPE methods. However, in Figure 4 and Figure 5, the different methods in the two sets of benchmarks proposed in this article are quite different in different OPE methods.' This is a clear and direct identification of a discrepancy. The reviewer also identifies the relevant parts of the paper: 'different metrics', 'different OPE methods', and 'different datasets in different figures'. The action is to understand the differences in the experimental setup.", "grounding_specificity_rationale": "The reviewer identifies the *what* (different datasets) but does not explicitly state the *why* or the connection between the different OPE methods and the need for different benchmarks. While the paper mentions 'benchmarks' in the abstract and introduction, the specific reasons for the dataset differences in Figures 4 and 5 are not clearly explained in the review point. The reviewer points to a *gap* in the explanation, implying a lack of clear grounding for the choice of datasets.", "verifiability_rationale": "The reviewer *claims* there are differences in the datasets used for different OPE methods in Figures 4 and 5. However, the review point itself does not provide any evidence, justification, or reasoning to support this claim. There are no references to external works or logical arguments presented to explain why the datasets would differ. The claim is made without sufficient backing within the review point itself.", "helpfulness_rationale": "The reviewer raises a valid point about the differences in experimental setup. Understanding the rationale behind using different datasets for different OPE methods is crucial for interpreting the results presented in Figures 4 and 5. This information would significantly enhance the reader's ability to understand and evaluate the paper's findings. The reviewer's comment directly addresses a potential area of confusion or lack of clarity in the experimental design."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point criticizes the comparison between the proposed method and SOTA without prior information, stating it's unfair due to the extra complexity of using VAE/GAN + CL. While the reviewer identifies a valid concern about the experimental setup and the added complexity, the review point itself does not explicitly state what action the authors should take to address this. The criticism is presented as a statement of unfairness rather than a direct instruction on how to improve the draft.", "grounding_specificity_rationale": "The review point generally refers to 'the experimental results' and 'the proposed method' without specifying a particular section, table, figure, or unique aspect of the paper. While it identifies a potential area for improvement (including prior information and analyzing the extra complexity), it doesn't pinpoint the exact location within the paper where this improvement should be made. The reviewer is vague about which specific part of the results or method is causing the unfairness.", "verifiability_rationale": "The review point contains a claim: 'such comparison is a bit unfair' and 'such extra complexity and cost need to be considered.' However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support why this comparison is unfair or why the extra complexity is a significant cost. The statement is presented as an observation rather than a wellverified claim. The reviewer offers a suggestion but doesn't substantiate it with evidence.", "helpfulness_rationale": "The review point is 3 in that it identifies a valid concern regarding the experimental setup and the added complexity of the proposed method. It encourages the authors to consider the cost and the impact of prior information. However, it does not provide concrete, actionable steps for the authors to take to address this concern. The reviewer states a problem but doesn't offer a clear path forward for the authors to resolve it."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding a new element (collaborative games) to the experiments. This implies a concrete action: designing and implementing such games. The comment explicitly states what to add, making it clear and actionable.", "grounding_specificity_rationale": "The review point is a general suggestion about exploring collaborative settings. It does not specify which experiments or parts of the paper it is referring to. The comment is broad and lacks specificity regarding the existing work.", "verifiability_rationale": "The review point suggests a future experiment (collaborative games) rather than critiquing existing methodology or results. There is X that requires verification or justification based on current evidence. It is a suggestion for future work, not a statement that needs to be proven.", "helpfulness_rationale": "The review point suggests a new experiment, which could be valuable for future research and understanding of the evaluated methods in different settings. While it doesn't pinpoint a specific current issue, it offers a direction for improvement and further exploration, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The comment identifies a deficiency (missing experimental settings) and its consequence (figures are hard to believe). While it doesn't explicitly state how to fix it, it clearly points to the need for this information. This implies an actionable suggestion, albeit implicit.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1 to Figure 9', allowing the authors to accurately identify the specific parts of the paper being addressed. It also clearly states what is missing in these parts ('experimental settings'). This demonstrates strong grounding and specificity.", "verifiability_rationale": "The comment contains a claim ('the experimental settings for Figure 1 to Figure 9 are totally missing') and provides a logical connection (lack of settings makes the figures unconvincing). While it doesn't provide specific examples or external references, the reasoning is clear and directly relates to the identified issue.", "helpfulness_rationale": "The comment directly points out a clear weakness in the paper (missing experimental details) and its impact on the credibility of the figures. This directly informs how the authors should improve their work, making the review point 5 in guiding the authors towards addressing this specific issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the regularization term is 'adhoc' and that the use of mean and standard deviation is not justified. They also suggest alternatives like the median. These are direct criticisms of the methodology and implications for how it should be applied. The reviewer clearly indicates what needs to be addressed.", "grounding_specificity_rationale": "The reviewer directly refers to 'the regularization term,' 'the mean,' and 'the standard derivation' in the regularization. These are specific parts of the paper being addressed, and the reviewer names them explicitly. This demonstrates strong grounding as the reviewer can accurately pinpoint the referenced part of the paper.", "verifiability_rationale": "The reviewer does not present a claim that requires verification in the same way as a criticism of a finding. Instead, they are questioning the choice of mean and standard deviation and suggesting the median as an alternative. While this could be considered a potential improvement, the statement itself doesn't present a claim that needs supporting evidence. The lack of a clear claim makes it difficult to assign a high verifiability score. The reviewer's suggestion implies a lack of justification, which could be seen as a potential issue, making it 3.", "helpfulness_rationale": "The reviewer points out a potential area for improvement in the methodology by questioning the adhoc nature of the regularization and suggesting alternatives. This is a constructive criticism that directly relates to how the authors should approach their work. The suggestions are concrete and actionable, making it 5 for the authors to consider and potentially refine their regularization strategy."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides two explicit suggestions that are actionable. 'Need to report average over multiple runs' is a clear instruction on what to do. 'Results are very close together and it is hard to favor one method' is a clear observation that points to a potential limitation or area for further discussion. However, the suggestion 'Sec. 3.3: What information is in Fig. 9 middle and right?' is an implicit action, as the authors are asked to interpret the figure rather than being given a specific task to perform. Therefore, while two suggestions are clear, one is less specific.", "grounding_specificity_rationale": "None of the review points explicitly identify a specific part of the paper they are referring to. 'Need to report average over multiple runs' and 'Results are very close together and it is hard to favor one method' are general observations about the experimental results. 'Sec. 3.1: Since this is the toydataset, a discussion why the decision boundaries look as they do, would be interesting' and 'Sec. 3.3: What information is in Fig. 9 middle and right?' are suggestions for interpretation or discussion, not specific actions on a particular section or table. Therefore, the grounding is weak.", "verifiability_rationale": "The review point contains two claims that are verifiable. 'Need to report average over multiple runs' is a suggestion based on standard practices and can be verified by examining the experimental setup and results. 'Results are very close together and it is hard to favor one method' is an observation that can be verified by looking at the numerical data. The other two points are suggestions for interpretation or discussion, which do not require external verification. Therefore, two of the points are verifiable.", "helpfulness_rationale": "The review point provides several helpful suggestions. 'Need to report average over multiple runs' directly addresses a potential limitation in the experimental methodology. 'Results are very close together and it is hard to favor one method' highlights a potential area for further discussion or analysis. 'Sec. 3.3: What information is in Fig. 9 middle and right?' helps the authors understand the results better. While some points are more direct than others, they all provide some level of guidance or insight for the authors. Therefore, the review point is helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer correctly points out that the authors state the center correlation was not insightful (an implicit claim) and then use it in Figure 4. The actionability is somewhat lacking because the authors don't explicitly state *how* the center correlation is useful in Figure 4. The vagueness makes it difficult for the authors to understand the connection and apply this information.", "grounding_specificity_rationale": "The reviewer's confusion about which 'center correlation' the authors are referring to highlights the weak grounding. The authors mention 'the center correlation' without specifying which one (e.g., correlation with specific features, model outputs, etc.). Furthermore, the specificity is lacking because the authors don't clearly explain what is wrong with this metric or how its use in Figure 4 addresses those issues. The comment identifies a weakness but doesn't pinpoint the exact area or detail within the 'center correlation'.", "verifiability_rationale": "The verifiability is low because the authors' statement about the center correlation being 'not insightful' lacks sufficient justification. The authors don't provide any logical reasoning, common knowledge, or external references to support this claim. The comment is presented as a statement of opinion without any backing, making it difficult for the authors to understand the basis for this assessment and the subsequent use of the metric in Figure 4.", "helpfulness_rationale": "The helpfulness is low because the reviewer's confusion about the utility of the center correlation and its use in Figure 4 directly impacts the authors' ability to understand the authors' reasoning and potentially improve their work. The lack of clarity regarding the connection between the statement on lines 8082 and the subsequent use of the metric makes it difficult for the authors to act upon this information."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action to be taken: 'remove the 45degree line' and 'add a thin gray diagonal line'. This action is concrete and directly addresses the issue of interpretability. The reviewer clearly identifies the part of the plot that needs improvement ('above/below diagonal') and specifies the exact change to be made. There is no ambiguity about the action to be performed.", "grounding_specificity_rationale": "The reviewer explicitly identifies the part of the paper being addressed, which is the plot and its annotations, specifically mentioning 'above/below diagonal'. The comment is grounded because it refers to a specific visual element and a specific area within that element. The reviewer provides a clear and precise indication of where the change should be applied.", "verifiability_rationale": "The reviewer's suggestion is 3. While they don't provide a direct justification for why the 45degree line is problematic, the suggestion to replace it with a diagonal gray line implies that the 45degree line might be redundant or confusing for users. This suggests a practical issue with the current visualization, and the suggestion offers a concrete alternative. The implication is that users find the 45degree line difficult to interpret or unnecessary.", "helpfulness_rationale": "The review point is 5 because it directly addresses a practical issue with the visualization tool. The reviewer provides a clear and actionable suggestion for improving the interpretability of the plot. The suggestion is specific and easy to implement, providing the authors with a clear direction for improvement. The reviewer's focus on user experience is a valuable feedback point."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'is sufficient' as a critique of the writing style at lines 240 and 428. While the reviewer identifies the lines, the actionability is somewhat vague as the reviewer doesn't provide a concrete suggestion for improvement. The reviewer's suggestion to clarify the meaning of 'sufficient' is a potential action, but it's not explicitly stated as an action to be taken by the authors.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'L240 and L428' in their comment, indicating a clear identification of the specific parts of the paper being addressed. However, the specificity of the criticism is limited. The reviewer is broadly criticizing the use of 'is sufficient' without pinpointing a specific error or improvement needed at those lines.", "verifiability_rationale": "The reviewer makes a claim that the use of 'is sufficient' at lines 240 and 428 is problematic. However, the verifiability of this claim is low. There is no logical reasoning, common knowledge, or external references provided to support why 'is sufficient' is problematic in this context. The reviewer's suggestion to clarify the meaning is a potential justification but lacks concrete evidence.", "helpfulness_rationale": "The reviewer points out a potential issue with the writing style ('is sufficient') and offers a suggestion to improve clarity. While the suggestion itself isn't concretely stated, the reviewer's identification of a writing issue and their attempt to improve it show a helpful intent. The comment encourages the authors to be more precise in their language."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point poses a question about the scientific insight of the model, which implies an implicit request for clarification regarding its novelty and advantages over existing methods. While it doesn't explicitly state 'Action X: Change Section Y,' the question directly addresses a potential weakness in the authors' work by highlighting a lack of clear explanation. The reviewer is prompting the authors to elaborate on the specific scientific contributions and how they overcome limitations of prior approaches. This is a clear indication that the reviewer desires more information and a justification for the proposed model.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'this model (as formulated in Section 2.3)' and 'these nonlinear RNN models.' This demonstrates that the reviewer has identified a specific section and type of model being discussed. However, the reviewer then states that the model's explanation of emergent behavior and its prototype approximation capabilities are unclear. While the section is identified, the specific details and explanations within that section that the reviewer finds lacking are not explicitly stated. The reviewer is pointing to a *potential* area of confusion for the authors, but not providing a direct, concrete example within the text being discussed.", "verifiability_rationale": "The reviewer makes a claim that 'it is unclear to me what scientific insight we get from this model and formalism over the prior taskoptimized approaches.' This is a verifiable statement as it expresses a direct opinion about the lack of clarity in the model's scientific contribution. The reviewer then provides supporting evidence by stating that the model is not shown to be a prototype approximation to nonlinear RNN models exhibiting emergent behavior. This provides a logical reasoning and a specific example (lack of explanation of prototype approximation and emergent behavior) to support the claim. The reviewer is not merely stating an opinion but is also providing a reason for their opinion.", "helpfulness_rationale": "The reviewer's point is highly relevant to the authors as it directly addresses a potential weakness in their work: the lack of clear scientific insight and explanation compared to existing methods. The reviewer is asking for clarification and justification of the proposed model's novelty and advantages. This is a direct and actionable feedback that the authors can use to improve their manuscript. The reviewer is not just pointing out a problem but also suggesting a direction for the authors to seek clarification or further explanation. This feedback is very helpful in improving the manuscript."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the issues with specific elements of the paper, such as the font size in legends and axis labels, the formatting of a proposition number, and the confusion between numbered propositions and equations. It also points out the font size in figure captions and the similarity of font size between text and figure caption font size. These are all concrete actions the authors should take to improve their draft.", "grounding_specificity_rationale": "The review point explicitly mentions specific elements of the paper that need improvement, such as 'texts in legends and axis labels,' 'proposition number,' 'figure captions,' and 'text size.' This demonstrates a high level of grounding specificity as the authors can directly identify the referenced part of the paper.", "verifiability_rationale": "The review point does not make any claims that require justification or evidence. It simply states observations and suggestions for improvement. For example, it points out that 'Proposition (1) > Proposition 1. > (1) is confused with Equation 1.' This statement is verifiable by examining the paper. Similarly, it suggests increasing the font size in legends and axis labels, which is a clear action based on the observation that they are too small. There are no claims that require external references or logical reasoning to be considered valid.", "helpfulness_rationale": "The review point provides clear and actionable feedback directly related to the identified issues. It guides the authors on *what* to improve and *how* to do it. For example, it suggests increasing the font size in legends and axis labels, reformatting the proposition number, and clarifying the distinction between proposition numbers and equations. These are all concrete and actionable suggestions that the authors can easily implement."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their suggestion to compare against Journey TRAK and provides a specific reason (difference in effect size compared to CLIP cosine similarity). The suggestion is clear and directly addresses a potential improvement to their counterfactual experiments.", "grounding_specificity_rationale": "The reviewer identifies a specific aspect of their work (counterfactual experiments) and links it to an external piece of work (Journey TRAK). While they don't explicitly state 'Section 4.3 of your paper,' the connection is clear within the context of counterfactual analysis. The reviewer also specifies the *type* of comparison (comparison against Journey TRAK) and highlights a *specific* difference in effect size (Figure 2).", "verifiability_rationale": "The reviewer is suggesting an *additional experiment* that could potentially reveal a different result. This is a suggestion, not a claim requiring immediate verification. The comment is more about exploring further rather than stating a definitive fact.", "helpfulness_rationale": "The reviewer's suggestion to compare against Journey TRAK is a constructive suggestion for improvement. It points to a potential area for deeper investigation and could lead to a more robust evaluation of the counterfactual experiments. While it doesn't directly fix a problem, it offers a valuable direction for further analysis."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the action taken in the paper: 'simply discards any TF bins that have a magnitude of less than epsilon'. This is a clear and direct action. While the reviewer later questions if this is a 'VAD' or just noise suppression, the *action* described is explicit. The reviewer also mentions 'if this is what you do', indicating they are inferring an action from the description. However, the core action of discarding TF bins is stated directly.", "grounding_specificity_rationale": "The reviewer explicitly names 'VAD' and describes its function: 'simply discards any TF bins that have a magnitude of less than epsilon'. They also state 'this is very unlikely to be defined over frequency, it's usually only over time'. This clearly grounds the discussion to a specific part of the paper (the VAD) and its typical operation (over time). The reviewer provides specific details about the mechanism and the expected domain of VAD.", "verifiability_rationale": "The reviewer makes a claim: 'Your VAD description is puzzling. What is stated in the paper simply discards any TF bins that have a magnitude of less than epsilon. If this is what you do I wouldn't call it a VAD, you are simply discarding TF bins with zero magnitude that will result in a division by zero. A VAD is supposed to look for the presence of speech (not just energy), and is also very unlikely to be defined over frequency, it's usually only over time.' This claim is 3. The reviewer provides a description of the mechanism (discarding TF bins below epsilon) and arguments against it being a true VAD (resembling noise suppression, operating over frequency). While the claim itself is somewhat subjective, the supporting arguments are based on the reviewer's understanding of VAD principles.", "helpfulness_rationale": "The reviewer's comment is critical and points out a potential misunderstanding or simplification in the paper's description of VAD. While the reviewer's interpretation might be helpful for the authors to understand the nuances of VAD and the implications of the paper's approach, the feedback is somewhat conditional on the actual implementation in the paper. The reviewer's point is not universally applicable and depends on the accuracy of the paper's description of its VAD implementation. Therefore, the helpfulness is moderate."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not provide explicit or concrete actions for the authors. It suggests a discussion and asks questions about the potential effects of a timevarying model, but it does not tell the authors what to do or how to implement these suggestions. The questions are openended and do not offer specific steps for improvement.", "grounding_specificity_rationale": "The review point attempts to ground the discussion in the 'discussion' section (4.2) of the paper. However, it does not explicitly identify the specific part of the paper being addressed within that section. While the section number is provided, the exact subsection or element is not specified. The questions raised are relevant to the model description in Section 4.2, but the connection is implied rather than explicitly stated. The specificity of the questions is also limited, as they focus on general effects rather than specific issues with the fixed model.", "verifiability_rationale": "The review point contains an implied claim that a timevarying model could have different effects on volatility and predictive intervals compared to a fixed model. However, this claim is not supported by any logical reasoning, common knowledge, or external references within the review point itself. The suggestions are presented as hypotheses rather than verifiable statements.", "helpfulness_rationale": "The review point raises a valid concern about the limitations of a fixed model and suggests exploring timevarying alternatives. It encourages the authors to think critically about their model and consider potential improvements. While it doesn't provide a direct solution, it offers a direction for further investigation and discussion, which can be helpful for guiding the authors' thinking."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a potential benefit (improved teacher network performance) and asks for specific metrics (KID/FID). This suggests a clear action the authors could take. While the 'how' of the unfair comparison isn't detailed, the request for data makes the action somewhat concrete.", "grounding_specificity_rationale": "The comment explicitly mentions 'simultaneous training' and 'teacher network', which are specific parts of the paper. It also requests 'KID/FID metrics', which are specific examples of metrics. This strong mention of specific sections and metrics indicates high grounding specificity.", "verifiability_rationale": "The comment contains a claim ('the comparison may be unfair') but does not provide any evidence or justification for this claim. While it requests specific metrics (KID/FID), the lack of supporting reasoning makes it only partially verifiable. The request itself is a claim that needs justification (e.g., why are KID/FID relevant here?).", "helpfulness_rationale": "The comment raises a concern about the fairness of a comparison and requests specific metrics. While this is a valuable request, the concern is not substantiated with any reasoning or evidence. The helpfulness is limited by the lack of a clear connection between the potential unfairness and the relevance of KID/FID in this specific context. The request is helpful but the claim is not wellsupported."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point directly describes the mathematical formula for the refined region vector and explicitly suggests an alternative formula with a scaling variable. The reviewer clearly identifies the current method and proposes a modification, indicating a direct action the authors could take. The suggestion is concrete, stating the addition of a scaling variable.", "grounding_specificity_rationale": "The review point explicitly refers to line 157 and provides the exact mathematical formula for the refined region vector. The reviewer clearly identifies the specific part of the paper being discussed, and the suggestion is directly related to this formula. The reviewer's statement is a direct identification of the relevant element.", "verifiability_rationale": "The review point provides a clear mathematical description of the current method and explicitly suggests an alternative method with a scaling variable. The reviewer logically reasons that the current method might only scale regions by a factor of two and proposes a more flexible approach. The suggestion is supported by a clear explanation of the current method's limitations.", "helpfulness_rationale": "The review point is highly specific, pointing out a potential limitation in a technical description. The reviewer offers a concrete alternative solution by suggesting the addition of a scaling variable. This is a clear and actionable suggestion that would directly benefit the authors in understanding and potentially improving their method."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'failures on the ALFRED benchmark often occurred due to goal misspecification'. This clearly identifies an actionable issue for the authors  they should aim to improve goal specification. However, the point does not specify *how* this misspecification occurs or what aspects of the goal are problematic. It lacks concrete details on the nature of the misspecification, making it somewhat vague on how to apply this action.", "grounding_specificity_rationale": "The review point mentions 'goal misspecification' and 'ALFRED benchmark'. While it identifies the *type* of misspecification, it does not explicitly identify a specific part of the paper being addressed. The connection to the ALFRED benchmark is implied through the context of failures *due* to this misspecification. Therefore, it is 1 in a specific section, table, figure, or unique aspect of the paper. It is also not specific in detailing what is wrong with the goal predicate.", "verifiability_rationale": "The review point makes a claim: 'Failures on the ALFRED benchmark often occurred due to goal misspecification'. This is a statement that requires verification. However, the review point is descriptive, stating a correlation between failures and goal misspecification without providing any logical reasoning, common knowledge, or external references to support this claim. It does not explain *why* this correlation exists or provide evidence for it.", "helpfulness_rationale": "The review point identifies a potential weakness ('goal misspecification') that authors could address. It is actionable in that sense. However, it lacks the necessary detail and specificity to be 5. The authors are left wondering what exactly needs to be improved  is it the natural language description, the formal goal predicate, or the interaction between the two? The point does not offer any guidance on how to diagnose or fix this misspecification, making it less than 5."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states, 'I think the improvement of this method over SOTA methods such as IGEV is small.' This is a direct statement of a perceived lack of impact, indicating an actionable suggestion for the authors to consider further improvements. The reviewer also suggests analyzing disparities, which is a concrete action. Therefore, the reviewer's point is clear and actionable.", "grounding_specificity_rationale": "The reviewer's question, 'Does this mean that there is no multipeak distribution problem in iterative optimization schemes similar to IGEV?', is not directly pointing to a specific part of the paper being discussed. While the suggestion to 'analyze the distribution of disparities produced by IGEV compared to other baselines' is more grounded, the initial question itself lacks specificity. The reviewer is making a deduction about the nature of the improvement, not directly identifying a specific issue within a section or table.", "verifiability_rationale": "The reviewer's claim that 'the improvement of this method over SOTA methods such as IGEV is small' is subjective and lacks concrete evidence or logical reasoning within the review point itself. While the suggestion to 'analyze the distribution of disparities produced by IGEV compared to other baselines' could potentially be considered verifiable if the analysis is clearly described, the initial claim is not supported by any specific references or logical arguments within the provided text. Therefore, the verifiability of this claim is low.", "helpfulness_rationale": "The reviewer provides a critique of the magnitude of improvement and offers a suggestion for improvement by analyzing disparities. While the initial statement about the small improvement is subjective, the suggestion to analyze disparities is a concrete action that could be helpful for the authors. The reviewer's overall point is that the comment provides a direction for further investigation, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests investigating 'how specific models (e.g., GPT4o vs. InternVL2) behave differently when ReGuide is applied' and recommends focusing on 'differences in false positive rates (FPR)'. These are concrete actions with clear implications for the authors. While the first part of the review point, 'ModelSpecific Insights: The paper focuses on generic findings across models, but a deeper investigation into how specific models (e.g., GPT4o vs. InternVL2) behave differently when ReGuide is applied could add nuance to the conclusions.', is somewhat vague, the second part, 'For example, the differences in false positive rates (FPR) between models with and without ReGuide should be presented for a better comparison.', is explicit and actionable. The reviewer directly states a specific aspect of the model behavior to investigate and a metric to focus on. The reviewer also suggests 'present for better comparison', which is a general suggestion about presentation, but the core actionable part is the investigation of specific models and FPR.", "grounding_specificity_rationale": "The review point explicitly states 'how specific models (e.g., GPT4o vs. InternVL2) behave differently' and 'differences in false positive rates (FPR)'. The reviewer names specific models and a specific metric to focus on. The reviewer also states 'For example, the differences in false positive rates (FPR) between models with and without ReGuide should be presented for a better comparison.', which clearly specifies the area of investigation. The reviewer uses 'e.g.' to provide examples, indicating an awareness of potential variations, but the core of the suggestion is very grounded in specific elements of the paper. The reviewer also mentions 'when ReGuide is applied', which directly refers to a specific condition in the study. The reviewer's suggestion to 'present for better comparison' is a general statement about presentation, but the core of the suggestion is very grounded in specific elements of the paper.", "verifiability_rationale": "The review point makes a claim about the value of investigating specific models and FPR. While it doesn't explicitly provide a logical reasoning for why this is beneficial, it suggests a direction for further exploration. The reviewer states 'ModelSpecific Insights: The paper focuses on generic findings across models, but a deeper investigation into how specific models (e.g., GPT4o vs. InternVL2) behave differently when ReGuide is applied could add nuance to the conclusions.' This is a claim that requires justification. The reviewer also states 'For example, the differences in false positive rates (FPR) between models with and without ReGuide should be presented for a better comparison.' This is a claim that requires justification. The reviewer doesn't provide any external references to support this claim. The reviewer's claim is that investigating specific models and FPR will add nuance and improve the conclusions, but this is not explicitly supported by logical reasoning, common knowledge, or external references within the scope of this review. The reviewer's claim is that investigating specific models and FPR will add nuance and improve the conclusions, but this is not explicitly supported by logical reasoning, common knowledge, or external references within the scope of this review.", "helpfulness_rationale": "The review point provides specific suggestions for improving the paper by investigating how specific models behave differently when ReGuide is applied and by focusing on differences in false positive rates (FPR). These suggestions are actionable and directly address potential areas for improvement. The reviewer explicitly mentions 'e.g., GPT4o vs. InternVL2' and 'false positive rates (FPR)', making the suggestions concrete and easy to follow. The reviewer also suggests 'For example, the differences in false positive rates (FPR) between models with and without ReGuide should be presented for a better comparison.', which further clarifies the desired outcome. The reviewer's suggestions are directly tied to specific aspects of the model and a measurable metric, making them 5 and verifiable. The reviewer's suggestions are directly tied to specific aspects of the model and a measurable metric, making them 5 and verifiable."}
{"actionability_label": "5", "grounding_specificity_label": "Somewhat Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the question: 'It is unclear from the results how much performance gain is due to the task formulation, and how much is because of pretrained language models.' This directly identifies the action the authors should take. Furthermore, the reviewer specifies the method for investigation: 'The paper should include results using the GCPG model without pretrained initializations.' This provides a clear and concrete action to be taken. The request is not only explicit but also directly addresses a crucial aspect of the paper's contribution.", "grounding_specificity_rationale": "The reviewer is asking about the contribution of the 'task formulation'. While the paper likely has a section dedicated to this, the reviewer is not directly pointing to a specific equation or table. They are asking about the *impact* of this formulation. Therefore, while the topic is clearly identified, the specific part of the paper being addressed is not explicitly stated. The reviewer could infer that the task formulation is discussed in the 'Method' section, but this is an inference, not a direct statement.", "verifiability_rationale": "The reviewer makes a claim: 'It is unclear from the results how much performance gain is due to the task formulation, and how much is because of pretrained language models.' This is a clear statement of a problem. The reviewer then proposes a method to verify this claim: 'The paper should include results using the GCPG model without pretrained initializations.' This provides a logical reasoning and a specific method (the ablation study) to verify the claim. While the results of this ablation are not presented, the *method* for verification is clearly stated.", "helpfulness_rationale": "The reviewer is directly asking for clarification on a key aspect of the paper's contribution. Specifically, they are asking: 'How much performance gain is due to the task formulation, and how much is because of pretrained language models?' This is a very relevant question for the authors to address, as it helps them understand the relative importance and impact of their proposed method. The reviewer is not asking for a completely new experiment, but rather a clarification on an existing one."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests 'If possible, results on ImageNet can be more convincing of the proposed method.' This implies an action, but it is not explicitly stated. The reviewer suggests that using ImageNet could lead to more convincing results, but the specific steps to achieve this are not detailed. The action is implicit, and the specifics are lacking. Therefore, while the potential action is suggested, the explicitness and concreteness of the action are not fully realized.", "grounding_specificity_rationale": "The review point does not specify which part of the paper it is referring to. It is a general suggestion about the overall convincingness of the results. The reviewer does not identify a specific section, table, figure, or unique aspect of the paper that would benefit from results on ImageNet. Therefore, the grounding is weak as the referenced part is not clearly identified.", "verifiability_rationale": "The review point does not contain a claim. It is a suggestion for improvement rather than a critique or assertion of a problem. Therefore, there is X to verify, and the verifiability scale does not apply.", "helpfulness_rationale": "The review point suggests using ImageNet results to increase the convincingness of the proposed method. While this is a potential improvement, the review point does not explain *why* ImageNet results would be more convincing or what specific issues they would address. The suggestion is vague and lacks justification in relation to the paper's content. Therefore, the review point is not very helpful in providing concrete feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "2", "actionability_rationale": "The reviewer criticizes the lack of actionable insights, focusing on the absence of proposed solutions. The comment doesn't tell the authors *how* to leverage the connection for improvement.", "grounding_specificity_rationale": "While the reviewer doesn't explicitly mention a specific section or table, the focus on 'connection' suggests a general point about the relationship between two concepts. The reviewer implies the relevance of the paper's findings but doesn't pinpoint the exact area within the paper being addressed.", "verifiability_rationale": "The reviewer makes a clear claim: 'the conclusion could be easily and intuitively obtained.' They then provide reasoning, like 'when multimodal complementary is higher, the robustness is more delicate when one of the modalities is corrupted.' This reasoning supports the claim that the conclusion is verifiable.", "helpfulness_rationale": "The reviewer argues that the insights are not significant enough to be helpful. They believe the paper could be the first to study this connection, but the reviewer deems the findings easily intuitive and lacking insightful solutions. The comment doesn't offer concrete steps or solutions for improving robustness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the issue: 'Focusing on which clusters are 'best' rather than what the differences in representation are between them, seems an odd choice'. This is a direct and clear identification of a potential problem. The reviewer points out a discrepancy in the approach and highlights the lack of focus on the comparative aspects. The action is 'identifying a potential issue in the methodology' and the suggestion is 'to consider the differences in representation'. The information is directly derived from the text.", "grounding_specificity_rationale": "The reviewer refers to 'clusters' and 'representation' by name, and also mentions 'the motivation of the paper', which implies a broader context. While they don't provide a specific section or table number, the terms are clearly identified. The issue is specifically about the comparison of representations between clusters. The comment clearly specifies what needs to be addressed in the referenced part (the comparison of representations).", "verifiability_rationale": "The reviewer makes a claim: 'Focusing on which clusters are 'best' rather than what the differences in representation are between them, seems an odd choice'. This is a subjective assessment. The reviewer then connects this observation to 'the motivation of the paper', implying that this choice might be problematic for the paper's goals. This connection is implied but not explicitly proven or disproven within the review point itself.", "helpfulness_rationale": "The review point raises a valid concern about the methodology. It points out a potential inconsistency in the approach. While it doesn't directly suggest a specific change, it highlights an area that needs attention. It could be helpful for the authors to consider the differences in representation when discussing the 'best' clusters. The reviewer's comment is relevant to the paper's direction and could influence the authors' interpretation and framing of their results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the caption for Figure 7 is incorrect and directly provides the correct label ('Edge Dynamics') instead of the current one ('Node Dynamics'). This is a clear and direct action that the authors can easily implement.", "grounding_specificity_rationale": "The reviewer directly mentions 'Figure 7' and clearly states that the current label is 'Node Dynamics' while the correct label should be 'Edge Dynamics'. This provides a 5 instruction.", "verifiability_rationale": "The reviewer makes a claim that 'The caption for Figure 7 is incorrect' but does not provide any evidence or justification for this claim. There are no logical reasoning, common knowledge, or external references provided to support this assertion.", "helpfulness_rationale": "The reviewer identifies a factual error in the paper's presentation by pointing out the incorrect caption for Figure 7. This directly helps the authors improve their draft by correcting this inaccuracy."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking for the motivation behind considering explicitness (E) and size (S) as extra evaluation aspects. While they provide examples of how changes in probing capacity or latent size can affect DCI, the explicit action of considering E and S is implied rather than directly stated. The reviewer is prompting for clarification, which can be seen as an implicit suggestion for an action.", "grounding_specificity_rationale": "The reviewer mentions 'DCI framework', 'ES', 'probing capacity', and 'latent size'. They also refer to specific aspects like 'disentanglement (D) of different representation methods'. This demonstrates a clear grounding of the comment within the relevant concepts and specific areas of evaluation. The reviewer is pointing to specific factors that are relevant to the DCI framework.", "verifiability_rationale": "The reviewer provides examples of how changes in probing capacity and latent size can affect DCI, suggesting an entanglement between DCI and ES. They also propose considering E and S as extra evaluation aspects. While the reviewer offers a rationale and examples, the claim that these factors are 'extra' and how they are precisely measured or verified isn't fully established. The reviewer is providing a basis for further investigation rather than a 5 claim.", "helpfulness_rationale": "The reviewer is asking a question and providing a rationale for considering explicitness and size as extra evaluation aspects. While the review point itself doesn't directly improve the draft, it identifies a potential area for improvement and suggests a solution. The reviewer is prompting for clarification, which can be seen as a helpful suggestion for further analysis."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing information: 'the standard deviation after multiple experiments is not provided.' This is an explicit action that the authors should take. Furthermore, the review point implicitly suggests an action by pointing out the 'limited improvement' and 'random fluctuations,' implying that the standard deviation is relevant for assessing significance. While the action of calculating standard deviation isn't directly stated, the reviewer provides a clear direction for improvement.", "grounding_specificity_rationale": "The review point explicitly mentions 'the experimental section' of the paper, which is a clear and specific reference. It then further specifies the missing information as 'the standard deviation after multiple experiments.' This level of detail demonstrates strong grounding as the authors can easily identify the relevant section and the specific issue. The suggestion to compare SoRA's improvement to the standard deviation also adds to the specificity.", "verifiability_rationale": "The review point contains a claim: 'The improvement brought by SoRA compared with the baseline is quite limited, which may be due to random fluctuations.' This claim is not based on concrete evidence within the review itself, but it suggests a potential explanation and a direction for investigation. The reviewer implicitly suggests that the standard deviation is a relevant factor in assessing the significance of the improvement. While the reviewer doesn't provide the standard deviation, they offer a logical reasoning (random fluctuations) and a suggestion (compare to standard deviation) to support their claim.", "helpfulness_rationale": "The review point directly identifies a missing piece of information (standard deviation) and suggests a way to address it (compare SoRA's improvement to the standard deviation). This provides clear, actionable feedback to the authors. The suggestion is directly linked to understanding the significance of their results and improving their analysis. The reviewer's comment is very helpful in guiding the authors towards a more rigorous evaluation of their experimental results."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a concern: 'it would be important to think about whether they are practical and safe for querying in the real world.' This clearly indicates an action the authors should take. However, the comment does not specify *how* to determine practicality and safety, making the action implicit rather than concrete.", "grounding_specificity_rationale": "The comment refers to 'practicality and safety for querying in the real world' but does not identify a specific part of the paper being addressed. It lacks the precision needed to pinpoint a section, table, figure, or unique element of the work. Therefore, the grounding is weak.", "verifiability_rationale": "The comment contains a claim: 'it would be important to think about whether they are practical and safe for querying in the real world.' However, this claim is not supported by any evidence, reasoning, or references. There is no logical justification or external references provided to back up this concern.", "helpfulness_rationale": "The comment raises a valid and important concern about the practicality and safety of the proposed interventions in realworld applications. This concern is likely to be helpful for the authors as it highlights a crucial aspect that needs consideration during the development and deployment of their work. While it doesn't provide concrete solutions, it points towards a direction for future work and experimentation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests that images and their augmentations can be interchangeable, implying an action of questioning the current approach. While the reviewer doesn't explicitly state 'I suggest treating images separately,' the sentiment is present. The action is implied but not explicitly stated, making it borderline.", "grounding_specificity_rationale": "The reviewer mentions 'images' and 'augmentations' in their review point. This indicates that the reviewer has identified a specific part of the paper being discussed. However, the reviewer does not explicitly state which section, table, or figure contains these elements, making the grounding somewhat weak. The specificity of the feedback is limited as the reviewer does not detail *which* images or *how* augmentations should be treated.", "verifiability_rationale": "The reviewer presents a counterargument to the idea that images and their augmentations need to be treated separately, suggesting they can be interchangeable. This constitutes a claim. However, the reviewer does not provide any specific examples, data, or references to support this claim. The statement is presented as an opinion without justification.", "helpfulness_rationale": "The reviewer expresses a disagreement with the idea that images and their augmentations should be treated separately. While this is a valid point of discussion and offers an alternative perspective, the feedback is specific to a particular aspect of the paper (images and augmentations) and lacks a clear, actionable recommendation. The helpfulness is limited as the reviewer does not provide a concrete solution or further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the uncertainty regarding the contribution of each component and suggests a method to address this uncertainty by evaluating on baselines. The action is clearly stated and directly addresses the identified issue.", "grounding_specificity_rationale": "The review point refers to specific components of the proposed method (generative shape model, word parsing model) and the overall paradigm (detectionparsing). While the initial statement is somewhat general, the suggestion to evaluate on baselines provides a clear direction for the evaluation, making the grounding somewhat strong. However, the initial statement lacks precise identification of the referenced parts.", "verifiability_rationale": "The review point contains a claim (unclear contribution) and suggests a method to verify it (evaluating on baselines). While the suggestion itself isn't a 5 claim with references, it provides a logical pathway for verification. The claim is stated clearly, and the suggestion offers a way to support it, making it 3.", "helpfulness_rationale": "The review point directly identifies a potential weakness (unclear contribution) and provides a concrete suggestion for improvement (evaluating on baselines). This directly helps the authors understand where their method might be lacking and how to address it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a question about the method's behavior without the Lipschitz Hessian assumption. This is a clear and direct action for the authors to address. The action is also concrete as the authors would need to explain how the method functions under this condition, providing a specific task to perform.", "grounding_specificity_rationale": "The comment explicitly mentions 'the Lipschitz Hessian assumption' by name, which is a specific element of the paper. This constitutes full grounding. The comment also specifies what is missing \u2013 the behavior of the method without this assumption, making it highly specific.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a question posed to the authors, implying an expectation that the method's behavior under this condition is wellunderstood or explainable. However, there is no logical reasoning, common knowledge, or external references provided to support this expectation. Therefore, it is underspecific as it identifies a gap but doesn't specify how to address it.", "helpfulness_rationale": "The comment directly points out a potential area of confusion or a missing piece of information regarding the method's behavior under a specific condition. This is likely to be helpful for the authors in understanding their own method better. While it doesn't provide a definitive solution, it highlights a crucial point that needs clarification, making it a valuable suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states 'Some of the pieces are simply using existing methods, such as equation (12)'. This implies an action, but it is not explicitly stated. The reviewer also says 'the presentation of these methods are also vague (can only be understood after checking the original paper)'. This suggests the action is not welldefined or concrete. The lack of explicitness and concreteness makes the actionability borderline.", "grounding_specificity_rationale": "The reviewer mentions 'equation (12)', which is a specific part of the paper. However, the reviewer also states 'can only be understood after checking the original paper'. This indicates that the grounding is weak because the reviewer cannot confidently determine the referenced part without external knowledge. While the part is identified, the issue with it is not specified within the reviewed paper, making it underspecific.", "verifiability_rationale": "The reviewer states 'Some of the pieces are simply using existing methods, such as equation (12)'. This statement is a factual observation and does not contain a claim or suggestion. Therefore, it does not have verifiability in the context of this framework, which focuses on claims and their support. The possible values for verifiability are 15 and X, where X indicates X.", "helpfulness_rationale": "The reviewer's comment is a pointer towards a potential issue (using existing methods) but lacks the specifics to be truly helpful. The action is implied and vague, and the grounding is weak because the issue is not clearly defined within the reviewed paper. While the comment identifies a potential area for improvement, it does not provide concrete steps or explanations, making it 3 but not highly so. The lack of specificity makes it 3 but not highly so."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point implicitly suggests the author should add the missing results to Table 4, making it actionable. However, the specific action of 'adding' is not explicitly stated, making it only 2.", "grounding_specificity_rationale": "The review point explicitly refers to 'Table 4' and states that it is 'incomplete' by not including results for 'all four datasets'. This provides a clear and specific reference point within the paper, making it fully grounded. The issue is also clearly specified as the absence of specific data, making it fully specific.", "verifiability_rationale": "The review point states that 'Table 4 is incomplete' without providing any justification or evidence for this claim. There are no logical reasons, common knowledge, or external references provided to support this statement. Therefore, it is 1.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper: the incompleteness of Table 4. While it doesn't explicitly tell the author what to do, it clearly points to an area that needs improvement. This provides valuable information to the author and helps them understand what is missing. Therefore, it is 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the stability definition is problematic and suggests a solution by adding a lower bound. This indicates a clear and direct identification of an issue and a proposed improvement, making it actionable. The specificity of suggesting a lower bound further enhances its concreteness.", "grounding_specificity_rationale": "The reviewer refers to 'the stability definition' and 'the left side' of the equation. While they don't provide a specific section number, the reference is clear enough to pinpoint the area being discussed. This can be considered fully grounded as the specific part of the paper is implied. The specificity of pointing out the potential for the left side to be arbitrarily small and suggesting a lower bound further enhances its grounding.", "verifiability_rationale": "The reviewer makes a claim that the left side of the stability definition can be arbitrarily small. While they don't provide a formal proof within this review point, the claim itself is verifiable based on the reviewer's understanding of mathematical definitions. The suggestion to add a lower bound also implies a belief in the usefulness of such a modification. Therefore, it is considered verifiable. However, without explicit evidence or a detailed explanation within this review point, it might be considered 'partially verifiable' as the full justification isn't fully presented.", "helpfulness_rationale": "The reviewer directly points out a potential issue with a key definition (stability) and offers a concrete suggestion to improve it by adding a lower bound. This directly addresses a core concept and provides a clear direction for improvement. This is a 5 comment as it guides the authors on how to refine their definition."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a potential weakness (incremental contribution, lack of impressiveness) but does not provide explicit instructions on what changes are needed or how to implement them. It's vague on the specific aspects of the pipeline to improve.", "grounding_specificity_rationale": "The comment is 1 at all in a specific part of the paper. It refers to the 'pipeline' and 'pack of tricks' generally without pinpointing a specific section, table, figure, or unique aspect of the work being criticized.", "verifiability_rationale": "The comment contains a claim ('the contribution of this work is incremental...') but lacks supporting evidence or justification. It's presented as an opinion without backing.", "helpfulness_rationale": "The comment criticizes the 'incremental nature' and the 'pack of tricks' but does not offer concrete suggestions or guidance on how to improve the work. It's a critique of the approach rather than a direct prescription."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests 'clearly show' the tuple structure, which is a direct and explicit action for the authors to take. They know exactly what needs to be done  modify how triples are represented. The suggestion is not vague or inferred.", "grounding_specificity_rationale": "The reviewer refers to 'line 122' and 'triples,' which grounds the comment to a specific part of the paper. However, the suggestion is about 'how' to show the triples, which is a general improvement rather than pinpointing a specific element within the triple that needs clarification.", "verifiability_rationale": "The reviewer states that triples denoted as $(e_1, r, e_2)$ would clearly show its tuplelike structure instead of sets. This statement is a claim that the current representation is not clear. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion is presented as a desire for improvement rather than a justified assertion about the current state of the representation.", "helpfulness_rationale": "The reviewer's comment directly points to a potential improvement in the presentation of triples. They suggest that the current notation is 'clunky' or 'not clear' and proposes a change ('would clearly show'). This is a clear and actionable suggestion that empowers the authors to make the change. While the suggestion is not specific about the exact alternative representation, it clearly identifies an area for improvement and provides a direction for action."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises a valid concern about the limitations of quantization, but the criticism lacks a clear, actionable step for the authors to take. While the reviewer points out that quantization is not scalable and can hinder the paper's goal of fast convergence, the paper does not explicitly state how the proposed method addresses this issue. The reviewer's comment is more of a question or a statement of a problem rather than a direct instruction on how to improve the method. Therefore, the actionability is limited as the authors are not given a specific task to perform.", "grounding_specificity_rationale": "The reviewer's comment is somewhat general about the limitations of quantization. While they mention that quantization is not scalable and can hinder the paper's goal, they do not pinpoint a specific part of the paper or methodology that is causing this issue. The comment is more of a highlevel critique rather than a detailed explanation of where the problem lies. Therefore, the grounding specificity is moderate as the authors are not given a precise section or element to focus on.", "verifiability_rationale": "The reviewer's comment is presented as a critique of the paper's approach rather than a claim that requires verification. They are questioning the effectiveness of quantization, but they do not provide any evidence or reasoning to support this critique. Therefore, the verifiability is low as the comment does not identify a specific claim that the authors need to justify or address.", "helpfulness_rationale": "The reviewer raises a valid concern about the limitations of quantization and its impact on the paper's goal of fast convergence. This is a relevant issue for the authors to consider, as it highlights a potential bottleneck in their method. While the reviewer does not offer a specific solution, their comment points to a potential area for improvement or further investigation. Therefore, the review point provides some insight into a potential problem, making it 3 for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides a clear argument against the justification for using PCC over KL divergence, stating that the scale invariance of PCC is not a strong enough reason. They then offer a counterargument, explaining that constraint strength is defined by gradient distribution and providing an example with MSE and KL divergence. This directly identifies an implicit action the authors should take: to consider gradient comparisons when choosing a constraint. The reviewer's statement is explicit about the weakness in the justification.", "grounding_specificity_rationale": "The reviewer states their position about the justification for PCC vs. KL divergence but does not explicitly identify *where* within the paper this assumption is made. They are criticizing the *justification* rather than pinpointing a specific, identifiable section being discussed. Therefore, while the reviewer's point is relevant, it doesn't directly pinpoint a specific part of the paper being discussed.", "verifiability_rationale": "The reviewer makes a claim: 'The assumption that PCC is a more relaxed constraint compared with KL divergence because of its invariance to scale and shift is not convincing enough.' However, they do not provide any evidence or references to support this claim. The reviewer's argument is presented as a statement of opinion without backing. Therefore, the claim is not supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer provides a clear and logical argument against the justification for using PCC over KL divergence. They highlight a potential weakness in the current reasoning and offer a specific alternative (gradient comparison) and explain why it is relevant. This provides valuable information to the authors by directly addressing a potential gap in the justification for their choice of constraint. The reviewer's point is actionable and directly addresses a potential area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about the impact of noise addition on the GPI model's fit to behavioral data. This is a direct and actionable question that encourages the authors to investigate further. The reviewer also suggests exploring alternative measures, which is a concrete action to take. The question is clear and the suggestions are specific.", "grounding_specificity_rationale": "The reviewer refers to 'Fig. 4' and 'GPI with noise added' by name, indicating a clear understanding of the specific part of the paper being discussed. They also suggest exploring 'alternative measures' and 'pattern separation tasks,' which are specific aspects of the methodology and results. This strong referencing demonstrates a high level of grounding. The suggestions are also specific and actionable.", "verifiability_rationale": "The reviewer poses a question about the GPI model's performance with added noise, implying a potential area of uncertainty or a point that needs clarification for the authors. They also suggest exploring 'alternative measures' and 'pattern separation tasks,' which are logical next steps based on their question. While the reviewer doesn't make a definitive claim about the model's performance, their questioning and suggestion are logically connected to the potential issue raised, making it 3. The reviewer is pointing out a potential area for further investigation rather than simply stating a fact.", "helpfulness_rationale": "The reviewer's points directly address potential limitations of the GPI model and suggest concrete improvements. By asking about the impact of noise and recommending alternative measures, they are guiding the authors to reexamine their model and consider alternative approaches. The suggestion to discuss pattern separation tasks further highlights areas where the authors' understanding and analysis could be strengthened. These suggestions are all directly relevant to improving the authors' work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the action of benchmarking with a small learning rate for attention parameters and provides a clear purpose for this comparison.", "grounding_specificity_rationale": "The comment accurately identifies the specific aspect of the proposed approach being investigated: 'small learning rate for attention parameters'.", "verifiability_rationale": "The comment contains a claim about the interest in a specific benchmark but does not provide any supporting evidence or justification for why this comparison would be valuable.", "helpfulness_rationale": "The comment suggests a useful experiment, indicating a potential weakness or area for improvement in the proposed approach. However, it lacks specific details about the learning rate, implementation, or expected results, making it less directly actionable."}
{"actionability_label": "4", "grounding_specificity_label": "X", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the difference in training parameters used for the proposed method and the baselines. They mention 'AdamW with cosine lr' for the proposed method and 'adam with fixed lr' for the comparison methods. This is a clear and explicit statement of a difference in the experimental setup, which can be directly acted upon.", "grounding_specificity_rationale": "The review point does not specify a particular part of the paper being addressed. It is a general comment about the experimental setup and the choice of training parameters. Therefore, it does not have strong grounding in the paper's content.", "verifiability_rationale": "The review point is a suggestion for improvement in the experimental setup, not a claim that requires verification. It proposes using the same setting as the baselines to ensure a fairer comparison. It doesn't present any logical reasoning, common knowledge, or external references to support this suggestion.", "helpfulness_rationale": "The reviewer provides a concrete and actionable suggestion for improving the experimental setup. They suggest reproducing the baselines' results using the same training parameters. This is a valuable suggestion that directly addresses a potential source of unfairness in the comparison and empowers the authors to potentially reevaluate their results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The suggestion to explore the combination of SOTA and an adaptive metric is an explicit action, indicating a desire for improvement. However, it lacks specific details on how to achieve this combination, making it somewhat vague and less actionable.", "grounding_specificity_rationale": "The reviewer mentions 'SOTA method (e.g. LST)'. While 'SOTA' is a general term, 'LST' is not explicitly defined as a specific model (e.g., LSTM, LeNet, etc.) without further context. Therefore, the grounding is weak. While the suggestion is specific to exploring a combination, the lack of clarity on the specific SOTA method and the adaptive metric makes the grounding weak.", "verifiability_rationale": "The reviewer states their curiosity about the performance of the SOTA method combined with the adaptive metric. This constitutes a claim. However, the reviewer does not provide any evidence, reasoning, or references to support this curiosity. The claim is presented without any backing, making it 1.", "helpfulness_rationale": "The reviewer's curiosity is a valid point of inquiry for the authors, as exploring new combinations can potentially lead to improvements. However, the suggestion is very general and lacks specific details on how to combine the SOTA method with the adaptive metric. This generality limits its immediate helpfulness for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides several explicit suggestions for improving the plots, such as making them larger, using colorblindfriendly options, and labeling the axes clearly. These suggestions are concrete and directly address the identified issues with the plots. The reviewer also suggests using different labels to avoid confusion, indicating a clear understanding of the problem and a direct path to solution.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'the plots' and then details specific problems with them, such as them being 'too small,' the colors being 'hard to distinguish,' the axes being 'poorly labeled,' and the labels being 'visually too similar.' This demonstrates a clear and specific identification of the part of the paper being addressed, making the grounding highly specific.", "verifiability_rationale": "The reviewer makes a claim that the plots are 'terrible' and then provides specific reasons for this assessment, such as them being the 'main presentation of the experimental results' and the issues with size, color, labeling, and labels. The reviewer also offers suggestions to improve the plots, which serve as evidence supporting the claim. This makes the claim verifiable and provides a basis for improvement.", "helpfulness_rationale": "The reviewer's comment is 5 because it directly identifies the problem with the plots (they are the main presentation of results) and provides specific, actionable suggestions for improvement. The suggestions are concrete and directly address the identified issues, making it easy for the authors to understand and implement the changes."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the performance gains are 'not very high' and 'less than 1%'. This indicates an explicit action: to critique the performance improvements. However, the vagueness of 'less than 1%' makes it difficult to pinpoint exactly where the gains are marginal, thus making it not fully actionable.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper (e.g., 'the caption', 'the warmup') where the performance gains are being discussed. It's a general statement about the overall impact of adding a caption and warmup. Therefore, it lacks grounding in a specific section or element of the paper. Additionally, it doesn't specify what is wrong with the caption or warmup, making it not specific about the issue.", "verifiability_rationale": "The review point is a statement of opinion: 'The performance gains are not very high, more most of the metrics the different between the baseline (w/o caption + w/o warmup) and best approach (with caption + warmup) is less than 1%'. This is a subjective judgment and does not require external verification or logical reasoning to be understood. It's a statement of what the reviewer believes, not a claim that needs to be proven.", "helpfulness_rationale": "The reviewer provides a direct critique of the impact of adding a caption and warmup, stating that the performance gains are not significant. This is a valuable piece of feedback for the authors, as it highlights a practical limitation of their approach. While it doesn't offer a specific solution, it points out a concrete issue that needs attention, making it 3 in guiding improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a question about the value of specific feedback information, not a statement that proposes an action to be taken. It's asking 'What is the performance without each of these two types of information and what is the performance with just the natural language feedback?' rather than suggesting a way to improve something based on this information.", "grounding_specificity_rationale": "The reviewer is asking a question about the value of specific feedback information in a feedback network. They are not explicitly identifying a specific part of the paper or feedback that they are referring to. The question is about the general concept of the value of this information, not a specific instance of it.", "verifiability_rationale": "The review point is a question about the value of specific feedback information, not a claim that needs to be verified. It's asking 'What is the performance without each of these two types of information and what is the performance with just the natural language feedback?' rather than making a statement that can be supported or refuted with evidence.", "helpfulness_rationale": "The review point is a question about the value of specific feedback information, not a suggestion that is likely to be helpful for improving the draft or the feedback process. It's asking about performance metrics rather than directly addressing how the information can be used to make improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that 'Table 1 does not show standard deviations' and 'this includes'. The first part is explicit about the missing information and is concrete about what is missing. While the second part is a general statement, it implies a lack of specificity. Therefore, it is 3.", "grounding_specificity_rationale": "The review point explicitly refers to 'Table 1' and specifies that 'standard deviations' are missing. This provides a clear and specific reference point for the reviewer. Therefore, it is 5.", "verifiability_rationale": "The review point implies that the absence of standard deviations in Table 1 is a problem, suggesting it is a significant omission. While it doesn't explicitly state that standard deviations are a statistically significant error, the implication is that it hinders the proper evaluation of the results. Therefore, it is 3.", "helpfulness_rationale": "The review point clearly identifies a deficiency in the experimental reporting (missing standard deviations) and states that this makes the submission 'far stronger' if the experiments were more extensive. This directly points to an actionable improvement and explains why the current version is weaker. Therefore, it is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the limitation: 'The experiments of the paper are done only on neural networks and image classification tasks.' This clearly identifies a lack of exploration in other areas. However, the comment does not provide specific guidance on *how* to address this limitation or *what* should be done. It suggests exploring other architectures and tasks but doesn't specify which ones or how to implement this exploration. Therefore, while it points to an actionable area, the action itself is vague.", "grounding_specificity_rationale": "The comment explicitly identifies the specific part of the paper being addressed: 'the experiments of the paper are done only on neural networks and image classification tasks.' This is a clear and precise identification of the limitation. The comment also specifies the *nature* of the limitation: a lack of exploration in other areas. The grounding is strong and specific to this aspect. However, the comment does not specify *which* other architectures or *which* other classification tasks to explore. While the identification is precise, the suggestion for improvement is general. Therefore, the grounding is fully grounded, but the specificity of the suggestion is underspecific.", "verifiability_rationale": "The comment does not contain a claim or assertion that needs verification. It is a suggestion for future work, not a critique of existing methodology or results. Therefore, it does not fit the 'verifiability' category and should be marked as 'X'.", "helpfulness_rationale": "The comment identifies a clear weakness in the paper's experimental scope: the limited exploration of architectures and tasks. It suggests a relevant improvement: exploring a broader range of architectures and tasks. This provides a direction for future research and is beneficial for the authors in understanding the generalizability of their findings. While it doesn't provide specific solutions or verifiable claims, it offers a valuable suggestion for improvement. Therefore, it is 3 in guiding future work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "6", "helpfulness_label": "None", "actionability_rationale": "The review point identifies a potential issue (unclear impact of mitigation strategies on performance) but does not explicitly state what action the author should take or how to address it. It presents a question rather than a directive. Therefore, it is Partially Actionable.", "grounding_specificity_rationale": "The review point refers to \"mitigation strategies\" and \"overall performance of the model\" in a general way. It lacks specific details about which strategies are being discussed or which aspects of performance are affected. Therefore, it is 2.", "verifiability_rationale": "The review point expresses an uncertainty or observation about the relationship between mitigation strategies and model performance but does not present a claim that requires verification or support. It's more of a question than a definitive statement. Therefore, it is X.", "helpfulness_rationale": "The review point raises a valid concern about a potential tradeoff. It highlights a potential area for further discussion or investigation. While it doesn't offer a solution, it points to a relevant issue that could be helpful for the author. Therefore, it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of consistent results and suggests that the proposed methods are not consistently better than the baselines. While they identify a problem, they do not explicitly state what action the authors should take to address this issue or how to implement it. The reviewer suggests additional experiments but does not provide a concrete action for the authors to follow. Therefore, the review point lacks explicit and actionable suggestions for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'Table 2' as the specific part of the paper being addressed. While they don't pinpoint a specific section, table, or figure within Table 2, they are clearly referring to a specific location in the paper where the results are presented. This indicates a level of grounding as the authors can infer the issue is related to the findings in Table 2. However, the reviewer does not specify *what* is wrong in Table 2, making it only weakly grounded. The claim is specific about the results being inconsistent, but the location within Table 2 is not explicitly identified.", "verifiability_rationale": "The reviewer makes a claim that the results are inconsistent and that the proposed methods are not consistently better than the baselines. While they state this claim, they do not provide any external references or logical reasoning within the review point itself to support this observation. The justification for this claim would come from analyzing the results presented in Table 2, which the reviewer hasn't done. Therefore, the claim is stated but not explicitly supported by evidence or reasoning within the review point.", "helpfulness_rationale": "The reviewer's overall assessment is that the point is insufficient to justify the claims in the paper. While they provide some context by referring to Table 2 and the comparison with baselines, their conclusion is that the point is not very helpful. They do not offer a strong recommendation or actionable steps for the authors to take based on this observation. The reviewer's statement is a critique of the impact of the point, rather than a clear recommendation for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the paper would benefit from a more detailed comparison with related work, in particular regarding time complexity and competitiveness. This is a clear indication of an actionable suggestion. The reviewer also specifies the *how* \u2013 by making the comparison more detailed and including specific aspects like time complexity and competitiveness. This makes the action concrete and actionable.", "grounding_specificity_rationale": "The reviewer mentions 'related work' generally, which is a weak grounding as they do not specify a particular section, table, or unique aspect of the paper. However, the reviewer *does* specify the *what* \u2013 'time complexity and competitiveness' of the prior art. This adds a layer of specificity to the identified area, even though the grounding itself is weak.", "verifiability_rationale": "The reviewer makes a statement about the paper 'benefiting' from a more detailed comparison. While they don't provide external references or specific examples to *verify* this claim, their statement itself points to a potential gap or area for improvement. The reviewer is essentially claiming that the current comparison is lacking in specific aspects. The lack of explicit evidence doesn't make it 1, but it also doesn't make it 5 either.", "helpfulness_rationale": "The reviewer clearly identifies a potential area for improvement: a more detailed comparison with related work, specifically mentioning time complexity and competitiveness. This is a valuable suggestion that could help the authors better position their work and understand its contribution. While the reviewer doesn't provide *specific* suggestions beyond these aspects, the identification of this improvement is helpful. The mention of a 'minor' point suggests they believe this improvement is relatively small but still valuable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the presented method claims to improve performance and computation speed but does not clearly explain how it differs from using ODA directly. This statement identifies an implicit action: the reviewer is pointing out a lack of clarity in the presented method's explanation. The action is to understand how the presented method improves upon ODA. However, the explanation of *how* it improves is missing, making it vague on how to apply this understanding.", "grounding_specificity_rationale": "The reviewer mentions 'ODA' specifically. However, they do not specify the exact section, table, or unique aspect of the paper where ODA's description is located. They also do not explicitly state what aspects of the presented method's improvement are being compared to ODA. While the section name 'ODA' is mentioned, the specific location and the nature of the comparison are unclear.", "verifiability_rationale": "The reviewer makes a claim about the presented method's explanation lacking clarity regarding its improvement over ODA. To verify this, one would need to examine the descriptions of both the presented method and ODA in the paper. Without access to the paper, we assume the reviewer has made a genuine observation based on their reading. Therefore, we assume the claim is valid, making it 3. The lack of explicit examples or references to support the claim is the basis for 'somewhat'.", "helpfulness_rationale": "The reviewer points out a potential weakness in the presentation of the presented method. They highlight a lack of clear explanation of the improvements over ODA. This directly addresses a potential area of confusion for the reader trying to understand the contribution of the presented method relative to ODA. It provides a suggestion for improvement (to clarify the explanation) and helps the reader grasp the core contribution more easily."}
{"actionability_label": "Partially Actionable (2)", "grounding_specificity_label": "3 (3)", "verifiability_label": "3 (3)", "helpfulness_label": "5 (4)", "actionability_rationale": "The reviewer explicitly states the comparisons with 9 and 16 and the focus on computational cost with 9. However, the *rationale* behind these choices is not clearly articulated. Why compare with 9 first? Why compare computational cost specifically with 9 and not 16? These questions highlight a lack of explicit reasoning, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer clearly identifies the proposed method and the works 9 and 16 as the subject of comparison. The mention of \"computational cost\" also explicitly identifies a specific aspect of the work. However, the *rationale* for focusing on these specific comparisons and the computational cost is missing, making it somewhat underspecific.", "verifiability_rationale": "The reviewer provides a clear claim: \"The authors should provide a clear rationale for the comparisons and the focus on computational cost.\" The *justification* for these choices is stated as being to \"understand the differences and potential advantages\" (for comparisons) and \"to highlight the computational efficiency\" (for computational cost). While the *what* and *why* are present, the *how* is not elaborated upon with references or logical reasoning. The claim is stated but not fully supported.", "helpfulness_rationale": "The reviewer provides a clear and actionable feedback. They are asking for specific improvements to the paper's structure and clarity regarding the comparisons and the computational cost analysis. The feedback is directly aimed at improving the authors' understanding and the paper's presentation. The reviewer is essentially asking for a more detailed explanation and justification."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for a comparison between the PL condition used and a specific PL condition proposed in a paper. While this can be considered an implicit suggestion for improvement (identifying a potential area for further exploration or clarification), it lacks explicit action or concrete details on how to perform the comparison. The reviewer doesn't specify what aspects of the PL conditions should be compared or what the expected outcome of the comparison should be.", "grounding_specificity_rationale": "The review point explicitly states the comparison to be made with a specific PL condition proposed in a paper. This clearly grounds the comparison to a specific part of the paper, making it fully grounded. The point also specifies what is being compared (the PL condition), making it specific about the aspect being addressed.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It is a request for information or comparison, not a statement that needs to be proven or justified.", "helpfulness_rationale": "The review point asks for a comparison between the PL condition used and a specific PL condition proposed in a paper. While this can be considered a relevant suggestion for authors to consider, it does not explicitly identify a weakness or provide a concrete improvement. The request is vague and lacks specifics on *how* the comparison should be made or what the expected outcome should be. Therefore, it is not 5 as it does not directly address a specific need or weakness of the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out the absence of a discussion regarding the computational cost and effort associated with the multistage training and multiple discriminators. While the reviewer doesn't explicitly state an action to be taken, the lack of this discussion can be interpreted as an implicit suggestion for the authors to address this aspect. The action is not explicitly stated, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'computational effort' generally and refers to '31, 33, *' without specifying which paper or section. This indicates a lack of precise identification of the relevant part of the paper where this discussion should occur. The grounding is weak because the reviewer doesn't pinpoint the exact location of the missing information.", "verifiability_rationale": "The reviewer makes a claim that 'there is a complete lack of discussing the impact of adding additional parameters and additional computational effort'. This is a clear statement of a missing element. However, the reviewer does not provide any evidence or reasoning to support this claim. The claim is stated without any verification or justification.", "helpfulness_rationale": "The reviewer's comment highlights a significant omission in the paper: the lack of discussion about the computational cost and effort. This directly points to a necessary improvement that the authors should make to ensure the reproducibility and practical applicability of their work. The reviewer's comment is directly relevant and encourages the authors to address a crucial aspect."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the perceived weaknesses: '(1) It is not clear if this trend holds across different model architectures' and '(2) if so, no theoretical evidence is advanced for this correlation.' It then suggests actions: 'Investigating different model architectures' and 'Seeking theoretical insights.' These are both concrete and directly address the identified issues.", "grounding_specificity_rationale": "The review point clearly refers to 'the analysis of the correlation between dataset size and the Frobenius norm and the singular values.' This is a specific part of the paper and the analysis being discussed. The reviewer then elaborates on the specific issues within this analysis, making the grounding quite explicit.", "verifiability_rationale": "The review point makes a claim: 'It is not clear if this trend holds across different model architectures, and if so, no theoretical evidence is advanced for this correlation.' While it doesn't provide direct evidence *within this point*, it clearly states a potential gap in the existing analysis and suggests a direction for future work (theoretical evidence). This can be considered partially verifiable as it points to a potential area for further investigation and highlights a theoretical gap.", "helpfulness_rationale": "The review point is helpful because it identifies a potential area for improvement in the analysis (lack of generalizability across architectures and lack of theoretical backing). It provides clear suggestions for the authors to investigate different architectures and seek theoretical insights. While it doesn't offer new empirical data, it guides the authors towards further investigation and helps them understand potential limitations in their current analysis."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises two questions. The first question, 'In L114 the authors concluded that for linear classification the pretraining dataset should match the target dataset in terms of being object orscene centric. If this is true, is it a setback for SSL algorithms that strive to learn more generic representations?', is somewhat vague and doesn't explicitly state an action or suggest a concrete improvement. The second question, 'Then it goes back again to whether by combining two datasets SSL model can learn better representations.', is more actionable as it directly relates to a potential improvement strategy. However, the reviewer doesn't provide a specific action or suggestion, making it partially actionable but not fully explicit.", "grounding_specificity_rationale": "The review point doesn't explicitly mention a specific section, table, figure, or unique element of the paper being addressed. The questions are more about the interpretation and implications of the findings rather than pointing to a particular part of the paper. Therefore, the grounding is weak.", "verifiability_rationale": "The review point raises questions about the implications of the findings. While it doesn't directly state a claim that requires verification, the questions themselves could be considered claims that need to be supported by further investigation or experimentation. However, the reviewer doesn't provide any evidence or reasoning to support these claims within the review point itself. The claims are speculative and require further analysis from the authors.", "helpfulness_rationale": "The review point raises a valid concern about the potential for information leakage in the AutoAugment pretraining process and its implications for SSL algorithms. The questions directly relate to the content of the paper and prompt the authors to consider a potential limitation and a possible solution. While the reviewer doesn't provide a definitive answer, the questions are specific and relevant to the paper's topic, making the review point helpful in identifying a potential area for further investigation and discussion."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a weakness in the paper's analysis of multilingual entity representations and provides concrete suggestions for improvement, such as adding more analysis, visualizations, and case studies. These suggestions are direct and actionable, indicating a clear understanding of what needs to be addressed. The reviewer does not leave ambiguity about the actions to be taken.", "grounding_specificity_rationale": "The reviewer mentions 'multilingual alignment of entity representations,' 'language family,' and 'lowresourced languages,' which grounds the feedback in specific aspects of the paper. However, the reviewer's primary action is to suggest *adding* analysis, rather than *identifying* a specific part of the paper that needs improvement. While the grounding is present, it's not as explicit as in a review that directly points to a specific table or figure. The reviewer is grounding the *type* of analysis being suggested.", "verifiability_rationale": "The reviewer does not make a claim or assertion about the paper. Instead, they are pointing out a limitation or weakness in the existing analysis. There is no need for external references or logical reasoning to verify the point. The reviewer is stating an observation about the paper's current state.", "helpfulness_rationale": "The reviewer provides specific and actionable suggestions for improving the paper's analysis of multilingual entity representations. They suggest adding analysis, visualizations, and case studies, and specifically mention language families and lowresource languages. These suggestions are directly aimed at addressing the identified weakness and are likely to be helpful for the authors in improving their work."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a need for more details on 'attention' but does not specify how to obtain or implement these details, making it 3 but not fully actionable. It is implicit in that the authors would need to infer the action of seeking more information on 'attention'.", "grounding_specificity_rationale": "The comment refers to 'attention' generally, without specifying a particular section, table, figure, or unique element within the paper. While it implies a need for more information in this area, it doesn't clearly identify where this information should be found. It is weakly grounded in that it points to a general concept, but not a specific part of the paper.", "verifiability_rationale": "The comment is a suggestion for improvement rather than a declarative statement of fact. It does not make a claim that requires verification. It is a constructive suggestion, not a claim.", "helpfulness_rationale": "The comment identifies a valid need for more details on the 'attention' mechanism, making it 3 in highlighting an area for improvement. However, it lacks the specificity of how to achieve this improvement, making it less than fully helpful. It is helpful in pointing to a valid area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the issues with the references list, such as duplicates and missing venue/year information. It directly points out what needs to be addressed without requiring the author to infer the actions. The language is clear and directly instructs the author to 'check the references section'. This provides a clear and direct action for the author to take.", "grounding_specificity_rationale": "The comment identifies the problem as being with the 'references list' but does not specify the exact section, table, or figure where the issues are located. While it mentions 'duplicates' and 'missing publication venues'/'years', it doesn't pinpoint their exact positions within the references section. The author would need to infer the specific areas to focus on.", "verifiability_rationale": "The comment contains a claim about the issues with the references list. It states that duplicates and missing venue/year information exist. However, it does not provide a detailed explanation of *why* these are problems or *how* they should be addressed. The suggestions are brief and lack specific guidance on fixes. While the implications are generally understood in academic writing, the explicit justification and concrete suggestions are limited.", "helpfulness_rationale": "The comment identifies a concrete issue with the references list, specifically mentioning duplicates and missing venue/year information. It directly tells the author what to look for and check in the references section. While it doesn't provide a comprehensive solution or explain the consequences of these issues in detail, it clearly highlights a actionable problem that the author can address."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question asking for a reason. While it prompts an action (explaining why Gaussian noise was chosen), the action itself is vague and lacks detail on how to apply it. The reviewer is asking *why*, not *how to change* the experiments.", "grounding_specificity_rationale": "The reviewer is asking *why* the results are shown only for Gaussian noise. They are not explicitly pointing to a specific part of the paper (like a section or table) being addressed. They are making a general comment about the experimental setup.", "verifiability_rationale": "The review point is a question seeking justification for a limited experimental setup. There is X being made. There is no suggestion for improvement. There is no judgment being made. It's a question for clarification.", "helpfulness_rationale": "The review point is a question seeking justification for a limited experimental setup. While it points to a potential weakness in the paper's claims, it doesn't directly identify a flaw or suggest a concrete improvement. It's a question, not a critique or a suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The suggestions are present but could be more specific. The reviewer offers a related concept and references, but the exact nature of the \"convoluted\" description isn't pinpointed.", "grounding_specificity_rationale": "The comment identifies the area as \"result description\" and suggests looking at \"figures,\" which is a general area. However, the reviewer also mentions 'specific visualizations\" which could be considered a more specific reference if the authors know which ones. The references 1 and 2 are also specific.", "verifiability_rationale": "The claim is about the significance of figure differences. The suggestions to look at \"topography plots\" and \"differences in figures\" and the references to papers provide a basis for verification.", "helpfulness_rationale": "The point about result description clarity is relevant. However, the suggestion to examine \"figures\" is somewhat general and could be more specific about which figures or what aspects to focus on."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the missing details: 'missing details about division to train and test sets, numbers as well as how the division was made'. This clearly indicates what information is lacking and how it should be presented. The reviewer is directly pointing out a deficiency in the provided information.", "grounding_specificity_rationale": "The reviewer's comment is general to the methodology of splitting the data. They are not specifying which part of a particular section or table is missing. While they mention 'numbers' and 'how the division was made', they don't point to a specific element within a section, table, or figure. The grounding is at the level of the methodology rather than a specific element within the paper.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are pointing out a deficiency or a missing piece of information. There is X being made, as the comment is about what is lacking, not what is present and its validity.", "helpfulness_rationale": "The reviewer's comment identifies a potential issue for the authors, specifically the lack of clarity on the train/test split. While they are not actively prompting the authors to improve their draft, they are highlighting a detail that could be crucial for reproducibility and model training. The potential benefit is there, but it's not a strongly proactive suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need for human labor in building text descriptions and highlights the variability of optimal textual formats across tasks and models. They suggest exploring different textual formats as a potential solution. These points are direct and actionable, providing clear directions for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'text descriptions for each task' and 'optimal textual format' as areas needing improvement. While they don't pinpoint a specific section or table, they clearly specify the *type* of text descriptions and the *factors* influencing their format. This indicates a strong focus on the content and structure of the descriptions themselves.", "verifiability_rationale": "The reviewer presents a statement about the laborintensive nature of text descriptions and the variability of optimal formats. This can be considered a claim that highlights a limitation or an area for improvement. However, the reviewer does not provide any external references or logical reasoning to *verify* this claim within the review point itself. The statement is based on the reviewer's understanding of the challenges.", "helpfulness_rationale": "The reviewer directly points out the need for human labor in creating text descriptions and suggests exploring different textual formats as a way to reduce this labor. This is a clear and actionable feedback that directly addresses a practical challenge faced by the authors. The suggestion to explore different formats is constructive and provides a concrete direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the limitations of the experimental validation, identifying the lack of consideration for deeper networks and the absence of detail regarding the optimization strategy (including the grid search). The reviewer clearly implies actions that the authors should take, such as exploring deeper networks and providing a description of their optimization and hyperparameter selection process. While the actions are not fully detailed, they are direct and point towards concrete improvements.", "grounding_specificity_rationale": "The comment explicitly mentions 'Experimental validation are not convincing' and then focuses on a specific aspect of the experimental setup: 'Only shallow networks are considered (2 or 3 layers)'. This clearly indicates that the reviewer is addressing a specific part of the paper, making the grounding explicit. The comment also specifies what is lacking in that part ('optimization strategy, including the grid search strategy for hyperparameters selection'). This level of detail in identifying the specific aspect and what is missing makes it highly specific within that context.", "verifiability_rationale": "The comment contains a claim: 'Experimental validation are not convincing'. However, it does not provide any evidence or reasoning to support this claim. The reviewer points out specific limitations ('Only shallow networks are considered (2 or 3 layers)') and the lack of detail on the optimization strategy ('optimization strategy, including the grid search strategy for hyperparameters selection is not described'), but does not explain *why* these issues are significant or how they impact the results. The claim is made without sufficient justification or references.", "helpfulness_rationale": "The comment identifies a clear weakness in the experimental validation ('Experimental validation are not convincing') and points towards specific areas for improvement, such as considering deeper networks and providing details about the optimization strategy. While the comment doesn't explicitly offer solutions or a detailed plan, it clearly highlights problems that the authors should address. The reviewer's suggestions, though not fully elaborated, provide a direction for improvement. Therefore, the comment is helpful in guiding the authors towards necessary changes, even if it lacks the most detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the work does not prove any new theoretical results. This is a clear action the authors should take: investigate the theoretical properties of the loss function in this specific setting. The reviewer identifies a concrete weakness that the authors can directly address.", "grounding_specificity_rationale": "The reviewer mentions 'this work' and 'this setting,' which implies they are referring to the overall context and application of the loss function. However, they do not explicitly name the paper, section, table, figure, or unique aspect where the loss function is introduced. While the reviewer identifies a gap (lack of theoretical results), they don't specify *where* in the paper this should be investigated. They don't provide specific examples of sections or tables. Therefore, the grounding is weak because the authors can only *infer* the location based on the general context of the work and the application of the loss function.", "verifiability_rationale": "The reviewer makes a claim: 'this work does not prove any new theoretical results.' However, they do not provide any evidence or reasoning to support this claim. They are stating a fact without offering a justification or reference. There is no logical reasoning, common knowledge, or external references provided to back up this statement. Therefore, the claim is not verifiable based on the information given.", "helpfulness_rationale": "The reviewer's comment is clear and identifies a factual deficiency in the work. While the lack of new theoretical results might be a limitation, the reviewer's comment itself is a valid piece of feedback for the authors. It guides them to consider the theoretical underpinnings of their work and whether the chosen loss function has any novel theoretical properties in this specific setting. Even if the authors are satisfied with the empirical results, the lack of theoretical grounding is a valid point for discussion and future work. Therefore, the comment is helpful in identifying a relevant area for the authors to consider."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "Not Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a hypothesis about why certain image parts might be easier or harder for humans. This action is direct and clear, indicating that the authors should take specific steps to investigate or address this hypothesis. The reviewer also proposes a specific mechanism for this hypothesis (consistency/training data vs. ambiguous labels/pose), making the action quite concrete.", "grounding_specificity_rationale": "The reviewer does not explicitly identify which specific 'two parts' of the paper they are referring to. They use general terms like 'these two parts,' making it difficult to pinpoint the exact area being discussed. While the reviewer provides a potential explanation for the hypothesis, this explanation is not directly linked to a specific section, table, figure, or unique element of the paper.", "verifiability_rationale": "The reviewer is proposing a hypothesis about human performance on a task related to image parts. While this hypothesis could potentially be supported by external references or verifiable data from human experiments, the provided text does not contain a claim that requires explicit verification within the context of the paper itself. The focus is on suggesting a potential explanation rather than making a definitive statement that needs backing.", "helpfulness_rationale": "The reviewer directly asks the authors for evidence to support their hypothesis. This is a clear and actionable request that directly addresses a potential weakness or area for improvement in the authors' understanding or experimental design. The question is very specific and directly points towards potential areas where the authors need to provide more evidence or analysis."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly identifies the limitation of the testing to 'single supporting fact dataset (Task 1 of bAbI)' and poses a question about the performance on 'other tasks'. This is an explicit action as the reviewer is directly pointing out a missing piece of information. The action is also concrete as the reviewer is asking about the performance on the remaining tasks of the bAbI benchmark.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the bAbI paper or dataset beyond the general 'bAbI' framework and 'Task 1'. While it implies a concern about the generalizability of the findings, it doesn't pinpoint a specific section, table, or figure. Therefore, the grounding is weak as the authors would need to infer the relevance of the comment to the bAbI context.", "verifiability_rationale": "The comment itself is not a claim that requires verification. It's a question about the performance of the bAbI model on different tasks. Therefore, it doesn't fit the verifiability framework which focuses on the presence and support of claims.", "helpfulness_rationale": "The comment raises a valid point about the potential limitations of evaluating a model on only a single task of the bAbI benchmark. However, it is more of a question prompting further investigation or discussion about the model's capabilities across different tasks, rather than providing direct actionable feedback for improving the bAbI model itself. Therefore, it is not 5 for the authors of the bAbI paper in improving their own draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue (time complexity) related to hypervolume calculation in LaMOO. While they don't explicitly state how to address this, they identify the problem and its potential impact on scalability. This can be considered an implicit action, and since the reviewer identifies the problem and specifies the potential impact, it can be argued that the action is somewhat concrete. However, the reviewer doesn't directly identify what needs to be done to improve the algorithm, making it less explicit.", "grounding_specificity_rationale": "The reviewer mentions 'hypervolume calculation' and 'LaMOO algorithm' but doesn't explicitly identify a specific part of the algorithm or paper they are referring to. The connection is implied but not clearly stated. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim about the impracticality of LaMOO for manyobjective problems due to the computational cost of hypervolume calculation. This claim could potentially be supported by arguments about the known complexity of hypervolume calculations. Therefore, the claim is 3.", "helpfulness_rationale": "The reviewer's comment is a critique of the LaMOO algorithm's potential scalability issues. While they identify a problem, they don't offer specific suggestions or improvements to the algorithm. The comment is focused on a limitation rather than providing actionable feedback for improvement. Therefore, it is not very helpful in terms of providing actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer provides suggestions and asks questions, which are actionable. However, the level of detail is lacking. For example, they suggest 'improving the paper' but don't specify which aspects or how to do it. While the suggestions are relevant, the lack of concrete steps makes the action implicit rather than explicit. The reviewer also asks for clarification on 'brittle convergence properties,' indicating a desire for more detail, but the current information is highlevel.", "grounding_specificity_rationale": "The reviewer mentions specific areas for improvement, such as 'state, reactiveness, and learning during an episode' and specifically asks for clarification on 'brittle convergence properties.' This indicates an attempt to ground the feedback. However, the grounding is not fully specific. The reviewer doesn't pinpoint the exact parts of the paper being addressed, nor does they provide concrete examples or details about what constitutes 'brittle convergence properties' in the context of the work being reviewed. The grounding is present but lacks the precision required for full grounding specificity.", "verifiability_rationale": "The reviewer states their intention to be 'honest and direct' and asks for clarification on 'brittle convergence properties.' This suggests an attempt to provide verifiable feedback. However, the criticism of the title is quite general ('way too generic and vague') and lacks specific examples or references. The request for clarification is a step towards verifiability, but the lack of concrete details and the openended nature of some points make it difficult to fully assess the verifiability of the feedback. The reasoning is present, but the lack of supporting evidence or examples hinders full verifiability.", "helpfulness_rationale": "The reviewer raises several relevant points, such as the limitations of evolutionary methods and the importance of state, reactiveness, and learning. They also express a desire for 'honest and direct' feedback. While the points are relevant, the lack of specific details and the somewhat openended nature of some suggestions make the feedback less immediately helpful. The reviewer's intention to be direct is a positive aspect, but the lack of concrete steps or examples hinders the overall helpfulness of the comment. The criticism of the title, while valid, is too general to be immediately helpful without further elaboration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states actions or modifications the authors should make to their draft. It asks about the synthesis of the focal stack, the forward model, and the handling of depth discontinuities, all of which are actionable steps for the authors to understand and implement.", "grounding_specificity_rationale": "The review point explicitly mentions 'the synthesis of the focal stack' and 'the forward model of using a defocus map and an image to synthesize defocused image'. This directly identifies the specific part of the paper being addressed. The reviewer also asks about 'how do you handle the edges where depth discontinuities happen?', which further pinpoints the area of concern. The language is clear and directly refers to specific components of the method.", "verifiability_rationale": "The review point raises questions about the methodology and implementation details of the paper. While it doesn't provide a claim that requires verification, it points out potential areas of confusion or lack of clarity. The reviewer is asking for clarification on how a specific process is synthesized, what the underlying principle is, and how a practical issue is handled. While not a definitive statement, it implies a need for further explanation and justification of these aspects, which can be considered a form of implicit verification or request for justification.", "helpfulness_rationale": "The review point is 5 as it directly addresses key uncertainties and implementation details for the authors. It asks specific questions about the synthesis of the focal stack, the forward model, and the handling of depth discontinuities. These are all crucial aspects for the authors to understand in order to replicate, build upon, or extend the work. The questions are clear, specific, and directly relevant to the methodology described in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests 'there should be some empirical justification'. This is a direct and explicit action the reviewer proposes. However, the reviewer does not specify *how* this empirical justification should be done, leaving the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'the first claimed contribution' of the paper, which indicates they are specifically addressing a previously stated claim. They also mention 'points' and 'apriori knowledge about dimensions of subspaces,' which are specific aspects of that contribution. This shows the reviewer is identifying a specific area within the paper that needs improvement. The comment is not just general; it targets a specific part of the paper and its details. The reviewer is stating that the paper lacks empirical justification for this specific claim, implying they are aware of where the weakness lies.", "verifiability_rationale": "The reviewer *claims* that the paper lacks empirical justification for its first contribution. This is a statement of a deficiency. While the reviewer's suggestion to add empirical justification is a valid point, the *claim* itself is not supported by any evidence or references within this review point. The reviewer is stating the lack of something without providing evidence of its existence or the need for it.", "helpfulness_rationale": "The reviewer explicitly states 'It would have been better if there were some empirical justification about this.' This is a clear statement identifying a weakness in the paper's current approach to validating its contribution. The reviewer provides a specific suggestion ('there should be some empirical justification') to address this weakness. This makes the comment both a clear identification of a problem and a concrete suggestion for improvement, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states the lack of a comprehensive discussion of previous work. However, it does not specify what aspects of the previous work are missing or how the authors plan to address this deficiency. The action is implied rather than explicitly stated and performed.", "grounding_specificity_rationale": "The comment explicitly mentions the area of 'previous work on this topic'. This clearly identifies the specific part of the paper being addressed. However, it does not specify what is missing or what needs to be improved in this area. The grounding is present, but the specificity is lacking.", "verifiability_rationale": "The comment itself does not contain a claim that requires verification. It is a statement of observation or a suggestion for improvement. While the authors could potentially verify the claim by checking their related work, the comment itself does not present a verifiable statement.", "helpfulness_rationale": "The comment identifies a valid weakness in the authors' draft \u2013 the lack of a comprehensive discussion of previous work. However, it does not provide any specific, actionable advice on how the authors can improve this aspect of their work. It is a critique rather than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking for clarification on a specific implementation detail regarding the training process and the role of the OT problem. While the reviewer doesn't explicitly state that the action is missing, they are asking for more information on how the training steps and OT solving are conducted. The reviewer is also asking for clarification on whether the OT sample selection is a onetime process or iterative, which implies a lack of clarity on the exact procedure. The request for runtime information further suggests a need for more detailed actionability. The reviewer is not criticizing the existing content but rather asking for more information to be actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'equation (10)', 'equation (3)', '2.4.3', 'training steps', 'OT sample selection', 'iteratively', and 'runtime' in their review point. This demonstrates a clear understanding of the relevant sections and a desire for precise information. The reviewer is asking about specific parts of the method and their implementation. This indicates that the information is present but not clearly linked or explained. The reviewer is asking for more detail, which suggests a lack of explicit grounding on how these components interact.", "verifiability_rationale": "The reviewer is asking for clarification on the purpose of solving the OT problem in equation (3) and its connection to the training steps. While the reviewer doesn't explicitly state that the claim is unsupported, they are asking for a justification for why solving the OT problem is necessary. The reviewer is asking 'what is the runtime for solving the entropic regularized discrete OT problem, and the runtime for OT sample selection?' which implies a lack of clarity on the computational aspects. The request for a flowchart further suggests a desire for a clearer, more logical explanation of the process, indicating a lack of explicit verifiability.", "helpfulness_rationale": "The reviewer's questions are directly aimed at clarifying implementation details and understanding the purpose of a key step (solving the OT problem). This is likely to be very helpful for the authors who are implementing or understanding the method. The reviewer is asking for specific information about the training process, the OT sample selection, and the computational costs. This information is likely to be crucial for reproducing or understanding the method. The request for a flowchart is a concrete way to improve understanding, making the review point 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for experiments with continuous tasks and a comparison with entropy methods, which are implicit actions. However, it doesn't clearly state *how* to conduct these experiments or *how* to compare the methods, making the action implicit rather than explicit. The reviewer also asks for justification for not including these experiments, which is a vague suggestion.", "grounding_specificity_rationale": "The review point explicitly mentions 'continuous tasks' and 'entropy methods for conditional optimization' and asks for 'experiments' and a 'comparison'. It also asks for 'justification' for not including these experiments. The reviewer identifies the specific areas where the paper lacks experiments and comparisons. The reviewer also mentions 'ConBO' as a specific method, which grounds the discussion to a particular method. The reviewer also asks for 'common knowledge' about the practical relevance of these methods, which is a general justification.", "verifiability_rationale": "The review point asks 'why are these entropy methods not included in the experiments?' and 'how does the empirical performance of these methods compare to ConBO?'. These are questions that require justification and comparison, which are not explicitly provided in the paper. The reviewer asks for 'common knowledge' about the practical relevance of these methods, which is a general justification rather than specific references or examples.", "helpfulness_rationale": "The review point effectively highlights significant omissions in the paper: the lack of experiments with continuous tasks and the absence of a comparison with entropybased methods. This is valuable feedback as it points out areas where the paper's claims or the practical applicability of the proposed method might be strengthened. The reviewer's questions directly address these gaps, forcing the author to consider these aspects and potentially conduct further experiments or include a comparison. The reviewer also asks for justification for not including these experiments, which is a valid point that could guide the author's future work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their desire for a clearer explanation of the difference between 'similarity' and 'exit times in nature'. While they don't provide a specific action to take beyond seeking clarification, the desire itself is a clear indication of an actionable need. The reviewer is willing to engage with the paper to understand a specific point.", "grounding_specificity_rationale": "The reviewer mentions 'similarity' and 'exit times in nature' as concepts they don't understand. However, they don't explicitly point to a specific section, table, or unique aspect of the paper where these terms are used in a way that is unclear to them. The grounding is implied rather than explicitly stated, making it weakly grounded.", "verifiability_rationale": "The reviewer is not claiming that something is wrong or missing in the paper. They are asking for clarification on a specific concept ('similarity' and 'exit times in nature'). This request itself is a form of information gathering and is therefore verifiable, even though the information in the paper might not be clear enough to satisfy the reviewer's need for understanding.", "helpfulness_rationale": "The reviewer's statement that they 'think this is a very novel thing for feature selection' and their explicit desire for a 'more detailed explanation' indicates that the review provides insight into the paper's content. While the explanation might not be perfect, it is a valuable contribution to the authors' understanding, making the review helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is implicitly asking about the limitations of the framework regarding general POMDP formulations, which is an implicit action or an action that needs to be inferred.", "grounding_specificity_rationale": "The reviewer is asking about limitations related to general POMDPs, which is a specific topic, but they are not explicitly pointing to a specific section or figure in a paper they are reviewing.", "verifiability_rationale": "The review point is a question about the capabilities of a framework, which is not a claim that needs verification.", "helpfulness_rationale": "The reviewer's question is relevant and could guide further discussion, but it doesn't immediately provide actionable steps for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out that the experiments are limited and suggests including sentence inference tasks. While the reviewer doesn't explicitly state 'You should add MNLI and RTE to your experiments,' the suggestion implies an action to expand the scope. The reviewer also mentions 'open domain QA tasks,' which is a more concrete example of a task type. The reviewer's point is that the current experiments are not comprehensive enough, and they suggest a specific type of task to address this. While the exact implementation isn't specified, the reviewer provides a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the experiments are limited' and then provides specific examples of task types, namely 'sentence similarity tasks,' 'open domain QA tasks,' and 'sentence inference tasks.' This clearly indicates that the reviewer has identified the specific area of the paper being addressed and has provided details about the nature of the tasks. The reviewer is not just saying 'the experiments are weak'; they are pointing to the *type* of weakness by naming specific task categories.", "verifiability_rationale": "The reviewer claims that 'sentence inference tasks such as MNLI and RTE are common tasks in the NLP field.' While this statement lacks a direct citation, the claim is generally accepted knowledge within the NLP community. The reviewer provides a *general* justification based on common practices in the field. The reviewer is making a claim that is supported by logical reasoning and common knowledge, although it might not be backed by a specific citation.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper: the limited scope of the experiments. The reviewer provides a relevant suggestion by proposing the inclusion of sentence inference tasks, which are a common and important category of tasks in NLP. The reviewer explicitly names specific tasks like MNLI and RTE, making the suggestion concrete. The grounding is strong because the reviewer identifies the specific area of improvement and provides examples. The claim about the commonality of sentence inference tasks is generally verifiable based on common knowledge in the field. Overall, the review point provides a clear and actionable suggestion for the authors to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The review point states \"How to set the parameter S remains a problem.\" While it identifies a problem related to parameter S, it does not explicitly state how to set it or provide concrete steps for doing so. The action is implicit, requiring the authors to infer the need for clarification or a solution.", "grounding_specificity_rationale": "The review point refers to \"parameter S\" in general, without specifying which parameter or where in the paper this refers to. The grounding is weak because the authors cannot confidently determine the specific part being addressed. The specificity is also underspecific as it does not detail what is wrong with parameter S.", "verifiability_rationale": "The review point is a statement of a problem, not a claim that requires verification. It does not make any assertions or assertions with supporting evidence. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The review point identifies a potential issue with parameter S. By pointing out this problem, it provides the authors with a direction to investigate or address the issue. While it doesn't offer a solution, it is more helpful than a completely silent review, as it highlights a specific area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests a human evaluation over automatic metrics. This is an explicit action. However, the reviewer does not specify how this human evaluation would be conducted or what specific aspects of the caption generation would benefit from it. The action is stated, but the details are lacking, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer suggests a human evaluation for caption generation. This comment does not explicitly identify a specific part of the paper or metric that is problematic. The suggestion is general and does not pinpoint a particular area needing improvement. Therefore, the grounding is weak. The comment does not specify *why* automatic evaluation metrics are misleading or *what* aspects of caption generation they fail to capture. The comment is 1 in a specific element of the paper or metric, and it does not detail what is wrong with the automatic metrics in the context of caption generation. The comment is 1 and not specific.", "verifiability_rationale": "The reviewer states that 'automatic evaluation metrics can be misleading'. This is a claim. While the reviewer identifies a potential issue (automatic metrics), they do not provide specific examples of what is misleading or why they are problematic in the context of caption generation. The claim is made, but the supporting evidence is weak and lacks specific examples. The claim is present, but the reasoning is not fully developed or supported by evidence. The claim is 3.", "helpfulness_rationale": "The reviewer suggests a human evaluation for caption generation. This comment offers a suggestion or recommendation. However, the suggestion is brief and lacks specific details on how this human evaluation would be conducted or what benefits it would provide for caption generation. The reviewer is encouraging a change in evaluation method, but lacks the specifics to make the feedback 5. The feedback is a suggestion, but it lacks the detailed reasoning and specifics needed to be 5. The feedback is 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the convergence proof is 'trivial' and provides a clear explanation of why, pointing to the contradiction between the claim about Z and Assumption 4.1, leading to a 'clear covariance matrix' for Z. They also suggest that 'previous theorems can be trivially adapted with straightforward modifications'. This provides a clear path for the authors to address the perceived weakness, making the action explicit. The reviewer also identifies the specific issue: the i.i.d. assumption and its implications, making the action concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Assumption 4.1' and 'the properties of Z' as the specific part of the paper being addressed. This is a literal mention, indicating full grounding. The reviewer also clearly explains the implications of the i.i.d. assumption for the covariance matrix of Z, providing specific details about what needs to be addressed.", "verifiability_rationale": "The reviewer makes a claim that the convergence proof is 'trivial'. This claim is supported by the reasoning that the i.i.d. assumption leads to a 'clear covariance matrix' for Z and that 'previous theorems can be trivially adapted with straightforward modifications'. While there isn't a direct citation of external literature, the reasoning is logical and connects the claim to observable properties of the model and potential modifications. The reviewer provides sufficient evidence to support their claim.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the theoretical proof (the triviality of the convergence proof) and provides a specific direction for the authors to investigate this issue (looking at the implications of the i.i.d. assumption and potential modifications). While they don't explicitly recommend a specific alternative approach, they offer actionable feedback that can guide the authors in improving their theoretical framework. The reviewer's suggestions are aimed at making the work more robust, which is a helpful direction."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the multinode seed cascades are 'artificially created by merging singlenode seed cascades'. This is a direct and clear statement of a methodological limitation that the authors should be aware of. The reviewer identifies the action of merging cascades as the flaw.", "grounding_specificity_rationale": "The reviewer explicitly states that the multinode seed cascades are 'artificially created by merging singlenode seed cascades'. This clearly identifies the specific part of the paper (the experimental setup) being addressed. Furthermore, the reviewer provides details on *how* the setup is created, making the grounding specific. The reviewer also states that 'This should be mentioned clearly', indicating a clear understanding of what needs to be addressed in this part.", "verifiability_rationale": "The reviewer makes a claim that the experimental setup is 'only semireal'. This claim is supported by the description of how the multinode cascades are created ('merged singlenode seed cascades'). The reviewer provides a logical explanation for why the setup is not fully realistic. The reviewer also suggests that 'This should be mentioned clearly', which is a direct action the authors should take.", "helpfulness_rationale": "The reviewer directly points out a potential limitation in the experimental setup and suggests it be addressed. This provides the authors with a clear direction for improvement. The reviewer identifies the specific issue (the semireal nature of the setup) and suggests a concrete action (mentioning it clearly). This is a helpful and actionable feedback."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies limitations in the evaluation of bias, specifically stating that only gender, race, and religion are assessed. While this highlights a potential gap, it doesn't explicitly state what needs to be done to address this limitation or how to implement a solution. The reviewer points out the absence of other important biases and datasets, but doesn't provide concrete steps or suggestions for improvement.", "grounding_specificity_rationale": "The review point mentions 'bias benchmarks,' 'datasets,' and 'stateoftheart generative models' as areas where improvements are needed. This indicates a degree of grounding as the reviewer refers to specific aspects of the evaluation process. However, the review doesn't specify *which* particular bias measures, datasets, or evaluation metrics are missing. The grounding is present, but it's not very specific about the exact deficiencies.", "verifiability_rationale": "The review point makes a statement about the limitations of current bias benchmarks, stating that they only assess gender, race, and religion. This is a claim about the state of the field. While the reviewer doesn't provide specific examples of missing biases or datasets, the statement itself is a verifiable observation about the current scope of evaluation. The reviewer points out the absence of evaluation on stateoftheart generative models, which is a verifiable limitation.", "helpfulness_rationale": "The review point directly addresses the limitations in the evaluation of bias by highlighting the narrow scope of assessed biases and the absence of evaluations on stateoftheart generative models. This provides clear feedback on areas where the evaluation process could be improved. The reviewer suggests expanding the scope of bias assessment and including evaluations on more complex models, which are actionable suggestions for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "2", "actionability_rationale": "The reviewer's point, while not directly about actionability, implicitly critiques the lack of explanation for the metrics, which would make it difficult for the authors to understand the relevance and apply them. Without a clear understanding, the potential actionability of using these metrics is diminished. The reviewer suggests a citation, implying a need for more explicit guidance on how to use the metrics.", "grounding_specificity_rationale": "The reviewer's point directly addresses the lack of specific grounding for the metrics. They are not pointing to a complete lack of grounding, but rather a failure to clearly identify *which* metrics are being referred to and *why* they are relevant. This lack of specificity makes it difficult for the authors to understand the information fully.", "verifiability_rationale": "The reviewer's point, while not a direct critique of verifiability, contributes to it. The lack of explanation makes it harder to verify the information. The reviewer's suggestion for a citation implies a need for more robust justification or references to support the claims being made about the metrics.", "helpfulness_rationale": "The reviewer explicitly states that the description of the metrics is limited and that the information is not helpful. They suggest a citation as a way to improve the helpfulness of the review point. This directly points to a lack of clarity, specificity, and justification, which are crucial for helpful feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem of designing fast label aggregation algorithms for a streaming setting and highlights the gap in motivation. While the reviewer doesn't provide specific details on *how* this lack of motivation is a problem, the implication is clear: it makes the paper less useful for researchers working in this area. The reviewer also identifies the issue with the datasets used in the empirical analysis, stating they are static, and this is a clear action that needs to be addressed. The reviewer's point is directly actionable and points to a clear area for improvement.", "grounding_specificity_rationale": "The reviewer mentions the 'objective of designing fast label aggregation algorithms for a streaming setting' as the context for the paper. However, they do not explicitly identify a specific section, table, figure, or unique aspect within this broad objective. While the reviewer points out the lack of motivation, this is a general statement about the problem, not a specific reference to a part of the paper. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim about the paper 'But it doesn\u00e2\u0080\u0099t spend any time motivating the applications in which such algorithms are needed.' This is a clear claim that requires verification. Similarly, the reviewer states 'All the datasets used in the empirical analysis are static datasets.' This is another claim that needs to be supported. However, the reviewer does not provide any evidence or references to support these claims. The lack of motivation and the use of static datasets are presented as facts without justification, making the claims 1.", "helpfulness_rationale": "The reviewer's points are clear and directly address potential weaknesses a reader might have \u2013 the lack of motivation for the problem and the use of static datasets instead of streaming data. While the reviewer doesn't propose solutions, they clearly identify significant shortcomings that could hinder the paper's impact. The reviewer's feedback is directly actionable and points to areas where the paper could be significantly improved. The feedback is constructive in highlighting the need for more context and the relevance of the streaming setting."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks 'How is this connected?' which is a direct action to explain the relationship between the general difficulty of symmetric tensor decomposition and the specific 'nice' landscape of symmetric order4 tensors. This action is clear and aims to provide a concrete understanding of the connection.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the fact that tensor decomposition is in general harder in the symmetric than in the nonsymmetric case' and 'the recent findings about the `nice' landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors'. This clearly identifies the specific parts of the paper being addressed, making the grounding strong. The reviewer also asks 'how is this connected', which specifies the nature of the relationship being sought.", "verifiability_rationale": "The reviewer presents a claim that there is a connection between the two mentioned aspects of tensor decomposition and asks for an explanation. This claim is verifiable if the authors can logically explain how the general difficulty relates to the specific landscape property. The request for 'how' indicates a need for reasoning and explanation, making it 3.", "helpfulness_rationale": "The reviewer's question directly addresses a key relationship between two important concepts in tensor decomposition. By asking how the general difficulty connects to the specific landscape, the reviewer is providing valuable context and guidance for the authors, which is 5 for their understanding and potential improvements."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action (conducting error analysis) and provides a clear direction on how to implement it (under different scenarios). The phrasing is direct and prescriptive.", "grounding_specificity_rationale": "The comment refers to 'model performance' generally, without specifying a particular aspect or table. This makes the grounding weak as the authors cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part (under different scenarios).", "verifiability_rationale": "The comment contains a claim ('Error analysis plays a crucial role...') but does not provide any supporting evidence or justification for this claim. It also does not specify what needs to be addressed in this part (e.g., examples, references).", "helpfulness_rationale": "The comment provides a general suggestion (conducting error analysis) which is relevant to improving model performance. However, it lacks specific details on how to perform the error analysis or the scenarios to consider, making it 3 but not fully comprehensive."}
{"actionability_label": "4", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem: 'As shown in Table 3 (a), the performance is getting worse with growth of the maximum number of identities.' They also suggest a potential solution: 'It means that the capacity should be preset to some small number (e.g., 10). In realworld scenario, we can have more than 10 objects and most of the time we don't know how many objects we will need to handle in the future. Have the authors thought about how to scale up without compromising performance?'. This indicates an explicit action and a clear suggestion.", "grounding_specificity_rationale": "The reviewer refers to 'Table 3 (a)' and 'maximum number of identities,' which are specific parts of the paper. This demonstrates grounding by identifying the relevant section and the specific parameter being discussed.", "verifiability_rationale": "The reviewer makes a claim about the performance trend based on Table 3 (a). However, they do not explicitly provide evidence or reasoning within the review point itself to support this claim. The verifiability depends on the reader having access to Table 3 (a) and being able to observe the trend.", "helpfulness_rationale": "The reviewer points out a clear issue related to scalability and suggests a potential solution. While the suggestion is somewhat broad, it does provide a direction for improvement. The reviewer's statement about the capacity needing to be preset to a small number is a concrete piece of actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the problem regarding the contribution of individual modules and parameters, indicating an intention to address it. However, the proposed action lacks specific details on how this investigation should be conducted.", "grounding_specificity_rationale": "The reviewer refers to 'the main performance gain' and 'individual modules' without specifying the exact section, table, or unique aspect of the paper where this issue is located. This makes the grounding of the problem somewhat weak.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It presents a question for further analysis rather than making a definitive statement.", "helpfulness_rationale": "The comment is relevant to the research and points out a limitation in the ablation study. It suggests a potential improvement by conducting further investigation, which is a constructive and helpful suggestion for the authors' work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitations of MIA testing and recommends ULiRA, providing a clear action for the authors.", "grounding_specificity_rationale": "The reviewer refers to 'the paper' generally, not a specific section or element, making the grounding weak.", "verifiability_rationale": "The reviewer claims MIA testing is insufficient and suggests ULiRA but provides no specific evidence or justification *within this review point* to support these claims.", "helpfulness_rationale": "The review points out a valid weakness and suggests a concrete improvement, making it 3. However, the lack of specific justification for the recommendations makes it less impactful."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies specific areas of the paper (simulations, figures) and points out the lack of detail in describing experimental procedures and the confusion in figures (e.g., 'sample count'). While the reviewer highlights the *problems* and *areas for improvement*, they do not explicitly state what the authors *should do* to address these issues. The implications are implied but not explicitly stated as actions. The reviewer points out the *lack of specific instructions* on how to improve the work.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific areas of the paper that need improvement, such as 'simulations' and 'figures'. They also point out specific issues within these areas, like the lack of detail in describing experimental procedures and the confusion surrounding the term 'sample count'. This demonstrates a clear identification of the specific part of the paper being addressed. The reviewer provides concrete information about *what is wrong* in these areas.", "verifiability_rationale": "The reviewer makes claims about the qualitative nature of the explanations and the lack of statistical rigor (absence of error bars and pvalues). However, the reviewer does not provide logical reasoning, common knowledge, or external references to support these claims. The claims are presented as observations without further justification. The reviewer identifies the *problems* but doesn't explicitly explain *why* they are problems or provide evidence to back them up.", "helpfulness_rationale": "The reviewer clearly states the problems the authors face, such as the qualitative nature of the explanations and the lack of detail in the experimental procedures. They also suggest concrete improvements, such as adding more details to the paper and supplementary information, and recommending the inclusion of error bars and pvalues. The reviewer provides *directions* for the authors to take to improve their work. The suggestions are specific and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential area for improvement by questioning the generality of the discussed biases and prediction shifts. While it points to a relevant issue, it doesn't explicitly tell the authors *how* to address this generality or what specific changes are needed. The reviewer is suggesting further investigation, which is an implicit action but lacks concrete details on implementation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 3.2' and 'Theorem 1' when discussing the biases and prediction shifts. This clear referencing of a specific part of the paper demonstrates strong grounding specificity. The reviewer is directly addressing the issues presented in these sections, indicating a high level of precision in identifying the relevant content.", "verifiability_rationale": "The reviewer raises a question about the generality of the observed biases and prediction shifts. This constitutes a claim that these issues might be common. However, the review point lacks specific examples, references to external work, or logical reasoning to support this claim. The reviewer is inferring the generality based on the presented examples, which is underspecified and lacks sufficient evidence.", "helpfulness_rationale": "The review point highlights a practical concern regarding the realworld impact of the identified biases and prediction shifts. By questioning their generality, the reviewer is pointing out a limitation that authors might encounter when applying their work. This raises a valuable point about the practical relevance and potential limitations of the findings, making it 3 for identifying areas where further investigation or clarification might be needed. However, it doesn't provide concrete solutions or guidance on how to address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly suggests 'a few more datasets' which indicates an intention to improve the draft. However, it does not specify how these additional datasets should be obtained, used, or relate to the crosstask transferability aspect. The action is implied but not explicitly stated, and the method of implementation is vague.", "grounding_specificity_rationale": "The comment refers to 'datasets' and 'crosstask transferability' generally, without pinpointing a specific section, table, figure, or unique element of the paper. The issue is not framed in terms of a particular part of the work, making the grounding implicit and lacking precision.", "verifiability_rationale": "The review point is a suggestion for improvement ('a few more datasets would've been appreciated') rather than a claim that needs verification. There is no logical reasoning, common knowledge, or external references provided to support this suggestion. It is presented as a desired outcome rather than a statement requiring validation.", "helpfulness_rationale": "The comment directly addresses a common limitation in machine learning research \u2013 the need for sufficient and diverse datasets, especially for crosstask transferability. It points towards a specific area for improvement that authors would likely find relevant. While it lacks specific details on *how* to find these datasets, it does identify a concrete and actionable direction for authors to focus their efforts, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the method in Section 3.1 seems to follow the previous work, Luciddreamer, but does not explicitly state what action they are suggesting or how it would be implemented. The statement is general and lacks specific details about the method or the novel effort.", "grounding_specificity_rationale": "The reviewer refers to 'Sec. 3.1' and 'Luciddreamer' when expressing their concern. However, they do not explicitly identify the specific part of Section 3.1 that they believe is unoriginal or point to a specific section in Luciddreamer for comparison. The grounding is weak because it relies on a general reference to the section and the previous work.", "verifiability_rationale": "The reviewer makes a claim that the method in Section 3.1 seems to follow Luciddreamer. However, they do not provide any evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up their assertion. The claim is presented without any verification.", "helpfulness_rationale": "The reviewer's comment is primarily a criticism of the method in Section 3.1, stating that it seems to be a direct adoption of Luciddreamer. While this points to a potential issue, the comment does not offer any constructive suggestions or actionable steps for the authors to improve their work. It is a negative comment without any proposed solutions."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises several questions about the framework's applicability to specific challenges (nonconvex losses, nonnorm type constraints) but does not provide concrete actions or solutions. While it identifies areas of concern, the lack of explicit suggestions on how to address these issues makes the action element somewhat vague. The reviewer asks 'Would the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant? Or would it still give some intuitions on the risk upperbound?' This shows an understanding of potential limitations but doesn't offer a clear path forward, making it partially actionable but lacking concrete steps.", "grounding_specificity_rationale": "The reviewer refers to 'binary classification' and 'nonconvex losses' without explicitly citing specific sections or tables in the paper. This makes the grounding weak. The reviewer also mentions 'nonnorm type constraints' and 'nonvanishing duality gap' without referencing them in the paper. This further weakens grounding. While the reviewer mentions binary classification, it's not explicitly linked to a section number or table, making the grounding weak. The lack of specific references makes it difficult to pinpoint the exact issue being addressed.", "verifiability_rationale": "The reviewer makes claims about the framework's limitations and potential relevance. However, these claims are speculative and lack direct evidence or references within the review point itself. The reviewer states 'Would the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant? Or would it still give some intuitions on the risk upperbound?' These are questions posed rather than verifiable claims supported by logical reasoning, common knowledge, or external references. The reviewer does not provide any specific examples or references to support these claims, making the verifiability low. The reviewer's questions are speculative and lack supporting evidence within the review point.", "helpfulness_rationale": "The review point raises valid concerns about the framework's limitations and asks insightful questions. However, the feedback is more critical and questioning than constructive and actionable. The reviewer asks 'Secondly, what relevance does the framework have with problems of nonconvex losses and/or nonnorm type defenses?' and 'If the true mean is known through an oracle, can one use the covariance or any other statistics to design a better defense?' These are insightful questions but do not offer concrete solutions or improvements. The reviewer's comments are more of a critique of the framework's applicability rather than a helpful suggestion for improvement. The lack of actionable feedback makes the review less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly suggests a new experiment involving sparsifying the trained models. However, it lacks specific details on how to implement this sparsification. While the reviewer implies a concrete action, the lack of detail makes it somewhat vague on how to apply it.", "grounding_specificity_rationale": "The comment explicitly mentions 'the baselines on the left hand side' of Figure 3, which indicates a clear identification of the specific part of the paper being referenced. However, it does not specify *which* baselines or *why* they are being considered for sparsification. The grounding is present but not fully specific.", "verifiability_rationale": "The comment implicitly suggests a claim that exploring sparsification could be beneficial for comparing against the proposed model. However, it does not provide any justification or reasoning for this claim. The suggestion is presented without supporting evidence or explanation.", "helpfulness_rationale": "The comment suggests an additional experiment that is relevant to the field. However, it lacks specifics on how to perform the sparsification or what insights to expect from the comparison. The suggestion is present but lacks the necessary details to be fully helpful to the authors."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem of lack of reproducibility and lists concrete actions to improve it, such as providing RNN implementation details and other technical specifics. The comment is clear and points to specific areas needing improvement.", "grounding_specificity_rationale": "The reviewer provides specific examples of missing information, such as 'RNN implementation details' and 'many other technical details'. While not a literal mention of a section, the examples are concrete and clearly identify the issue. The comment is grounded in the specific areas where details are lacking.", "verifiability_rationale": "The reviewer makes a claim that the paper lacks the necessary details for reproducibility and provides logical reasoning to support this claim, such as stating that the paper aims for an intuitive understanding rather than detailed implementation specifics. The reasons for the claim are clear and based on the information provided.", "helpfulness_rationale": "The reviewer clearly identifies a problem (lack of reproducibility) and suggests a solution (providing more details). The comment is helpful in guiding the authors to improve their draft by adding necessary technical information."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"error bars\" and \"more random trials\" as improvements. These are concrete actions that authors can directly implement to enhance the visual representation and statistical robustness of their results. The reviewer provides specific details on *where* the error bars should be added (Figure 1) and *how* the random trials should be conducted, making the action very clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly refers to \"Figure 1\" when suggesting improvements. This demonstrates strong grounding as the specific part of the paper being addressed is clearly identified. Furthermore, the reviewer provides specific details on *what* should be added (error bars and more random trials) and *where* it should be added (Figure 1). This level of detail ensures that the authors can directly apply the feedback.", "verifiability_rationale": "The reviewer presents a suggestion for improvement: \"Figure 1 would be much stronger if...\" This constitutes a claim that the current Figure 1 is lacking. The reviewer then provides supporting evidence for this claim by stating that \"error bars and/or if there were more random trials that would (potentially) get rid of some of the (most likely) random fluctuations in the results.\" This logical reasoning and the suggestion of concrete improvements make the claim 3.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in Figure 1 (lack of error bars and potential random fluctuations) and provides concrete suggestions to improve it. This is a valuable piece of feedback for the authors as it directly addresses a potential limitation of their visualization and statistical analysis. The suggestions are actionable and directly tied to improving the clarity and reliability of the results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests adding an introduction to energy models in the related work section, which is a direct action the authors can take. While the suggestion lacks specific details about which part of the related work to add it to, it is an explicit instruction. The request to clarify Figure 1 by pointing out which learning rates and steps correspond to the points is also an explicit action the authors should perform. However, the lack of specificity in both actions makes them somewhat vague.", "grounding_specificity_rationale": "The suggestion to add an introduction to energy models in the related work section is not strongly grounded as it doesn't specify where in the related work this should go. However, the suggestion to clarify Figure 1 by pointing out which learning rates and steps correspond to the points is strongly grounded as it explicitly refers to a specific part of the paper (Figure 1) and what needs to be clarified within it.", "verifiability_rationale": "The review point does not contain any claims that require verification. The suggestions are recommendations and requests for clarification, not statements that need to be proven or justified.", "helpfulness_rationale": "The suggestion to add an introduction to energy models in the related work section is likely to be helpful as it provides context and background for the work. The suggestion to clarify Figure 1 by pointing out which learning rates and steps correspond to the points is also very helpful as it directly addresses a potential source of confusion and improves the clarity of the results. While the first suggestion is somewhat general, the second is very specific and directly addresses a potential weakness in the presentation of the results."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not provide explicit or implicit actions for the authors to take. The reviewer is asking a question about the potential of the model, which is a query, not a directive. There is no guidance on how to make the model more novel or testable.", "grounding_specificity_rationale": "The reviewer does not explicitly or implicitly refer to a specific part of the paper or concept. The question is about the model in general, not about a specific section, table, figure, or unique element of the paper. The grounding specificity is weak as the authors cannot confidently identify the referenced part.", "verifiability_rationale": "The review point does not contain a claim that can be verified. The reviewer is posing a question about the potential of the model, not making a statement that can be supported by evidence or references. There is no logical reasoning, common knowledge, or external references provided to support the question.", "helpfulness_rationale": "The review point raises a valid concern about the potential lack of novelty and testability of the model. While it doesn't provide a direct solution, it highlights a potential issue with the framing of the work. The authors are informed about a potential limitation, which can be considered helpful in prompting them to reconsider the scope and impact of their model."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point is a question prompting a simplification of Theorem 2, but it does not explicitly state what needs to be done or how to achieve this simplification. It lacks concrete instructions, making it difficult for the authors to directly apply the feedback. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The review point does not specify which part of the paper (e.g., a specific section, table, or figure) is being addressed. It is a general suggestion about presenting a simplified version of Theorem 2 without pinpointing the exact location within the paper. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point itself is not a claim that requires verification. It is a question prompting the authors to consider a simplification. While it implies a desire for clarification, it doesn't present a statement that needs to be supported by evidence or references. Therefore, it doesn't fit the criteria for verifiability as it lacks a claim to be verified.", "helpfulness_rationale": "The review point identifies a potential area for improvement (presenting the theorem more simply) but does not provide explicit instructions or concrete steps on how to achieve this. It is a suggestion for improvement rather than a direct critique or actionable advice. The authors are left with a question and a desire for clarification, but no direct guidance on how to proceed. Therefore, it is not 5 as it does not directly address their needs for improvement in a actionable way."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states \"just multiply each feature map element wise by H_psi?\" which is a clear and direct instruction on how to modify the feature map. This directly tells the authors what calculation to perform.", "grounding_specificity_rationale": "The review point directly references \"KeyQN section What is the keypoint mask averaged feature vector?\". This clearly identifies the specific section and concept being addressed. The reviewer assumes the authors are familiar with the notation (H_psi) and the context of elementwise multiplication, making the grounding quite explicit.", "verifiability_rationale": "The review point proposes a specific mathematical operation (\"multiply each feature map element wise by H_psi\"). This is a claim that can be verified by examining the implementation details of the KeyQN section or by checking the consistency of the described method. The question mark indicates a desire for clarification, suggesting a potential issue that needs verification.", "helpfulness_rationale": "The review point is highly specific, directly addressing a potential area of confusion related to the \"keypoint mask averaged feature vector\" concept. It provides a concrete, actionable suggestion (the mathematical operation) and ends with a question mark, indicating a desire for clarification, which is a valuable feedback point for the authors."}
{"actionability_label": "High", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "High", "actionability_rationale": "The review point explicitly states actions or suggestions that are direct or apparent. It suggests using styles (dashed lines) and adding color to the curves in Figure 2 right. These actions are concrete and directly tell the authors what needs to be changed.", "grounding_specificity_rationale": "The authors can accurately pinpoint the issue to Figure 2 right. The comment clearly identifies the specific part of the paper being addressed. Furthermore, it specifies what needs to be addressed in this part (distinguish between the different curves) and how to implement the change (use styles, add color). This is 5.", "verifiability_rationale": "The review point contains a suggestion for improvement, which can be considered a claim that requires justification. While it doesn't explicitly provide examples or references, the suggestion itself implies that improving the figure's clarity is beneficial. The reasoning is clear and the suggested methods are logical.", "helpfulness_rationale": "The review point identifies a clear weakness in Figure 2 right (difficulty in distinguishing curves) and provides specific, actionable suggestions (use styles, add color) to address this weakness. The suggestions are directly applicable and constructive for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a clear action: \"tone down the intro\". This action is directly related to the identified issue and is a concrete step the authors can take. The reviewer also suggests a change: \"not call this language learning\". While the suggestion is somewhat openended, it points to a specific area for improvement in the introduction. The reviewer's point about the discrepancy between the claimed language learning and the actual QA task is also actionable, as it highlights a specific area where the authors need to clarify their methodology and framing.", "grounding_specificity_rationale": "The reviewer identifies a specific part of the paper being addressed: the introduction and the framing of the task as 'language learning'. They also identify the issue within that part: the mismatch between the claimed language learning and the actual QA task. The reviewer suggests a specific change: \"tone down the intro\", which directly relates to the identified issue. The grounding is explicit, as the reviewer clearly points to the introduction as the area needing clarification. The specificity is also high, as the reviewer clearly identifies the discrepancy between the claimed language learning and the actual task.", "verifiability_rationale": "The reviewer makes a claim: \"the paper claims language learning while evaluating on question answering\". This claim is verifiable by reading the introduction and the description of the task. The reviewer also suggests a solution: \"tone down the intro\", which is a suggestion that, while not explicitly verifiable with external evidence, is a direction for the authors to take. The reviewer's point is clear and directly points to a discrepancy that can be confirmed by examining the paper's content.", "helpfulness_rationale": "The reviewer provides a critique of the paper's framing and methodology, highlighting a discrepancy between the claimed language learning and the actual QA task. They also offer a concrete suggestion: \"tone down the intro\". This feedback is directly relevant to the authors and provides a clear direction for them to improve their draft. The reviewer's point is actionable and addresses a specific issue that needs clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific limitation of the paper's approach by stating, 'However, this paper exploits an easy reduction from the problem of collaborative ranking, and hence, the lower bound results follow as an easy corollary of these collaborative ranking results.' This statement identifies a weakness in the paper's methodology and suggests a potential reason for it. While it doesn't explicitly state what needs to be changed, it points to a specific type of reduction and its consequence, making it 3. The reviewer could have elaborated on the implications of this 'easy reduction' for the batched ranking problem, making it more actionable for the authors.", "grounding_specificity_rationale": "The reviewer refers to 'batched ranking problems,' 'round complexity,' 'lower bound results,' and 'collaborative ranking.' While they don't explicitly point to a specific section or table in the paper, they clearly connect these concepts. The reviewer is implicitly referring to the general areas of batched ranking and its relation to collaborative ranking. However, they don't specify a particular section, table, or unique element within the paper that they are referring to. This makes the grounding somewhat weak, as the authors would need to infer the specific area being discussed. The reviewer mentions 'lower bound results' and 'collaborative ranking,' which are specific enough to point to a potential area of concern, but the connection isn't explicitly tied to a specific part of the paper.", "verifiability_rationale": "The reviewer makes a claim by stating, 'However, this paper exploits an easy reduction from the problem of collaborative ranking, and hence, the lower bound results follow as an easy corollary of these collaborative ranking results.' This is a claim that requires verification. However, the reviewer does not provide any specific reasoning, examples, or external references within the review point itself to support this claim. They are stating their interpretation of the paper's content. Therefore, based on the information within the review point, the verifiability is somewhat lacking. The reviewer could have provided more details or references to make it more verifiable.", "helpfulness_rationale": "The reviewer's comment identifies a potential weakness in the paper's approach by highlighting the use of an 'easy reduction' from collaborative ranking for batched ranking. This points to a specific area where the paper's contribution might be limited. While the reviewer doesn't offer a direct solution, they provide a reason for the potential limitation, which could be helpful for the authors in understanding the scope of the paper's findings and potentially identifying areas for improvement. The feedback is focused on a specific aspect of the paper and its implications, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review states that the prompting technique is 'very basic' and that 'carefully curated prompts' could be better. However, it does not explicitly state what the current prompts are or what specific actions the authors should take to improve them. The reviewer suggests improvement but does not provide concrete, actionable steps. Therefore, while the reviewer identifies a potential weakness, the lack of specific actions makes it only partially actionable.", "grounding_specificity_rationale": "The review mentions 'prompting technique' in general and 'systematic reviews' as the domain. It does not specify which part of the prompt or the systematic review process is being criticized. The comment is a general critique of the general prompting technique used, not a specific reference to a section, table, figure, or unique aspect of the paper being reviewed. Therefore, the comment is 1 in a specific part of the paper.", "verifiability_rationale": "The review states that the 'prompting technique used in this study is very basic' and that 'carefully curated prompts' could gain better results. This implies a weakness in the current technique. While the reviewer suggests improvement, the claim about the technique being 'very basic' is subjective and lacks specific evidence or references. The suggestion is a potential improvement rather than a verifiable claim about the current technique's flaws. Therefore, the comment makes a claim that could be supported but does not provide sufficient evidence to make it 5.", "helpfulness_rationale": "The review points out that the 'prompting technique used in this study is very basic' and suggests that 'carefully curated prompts' could be better. However, it does not provide specific examples of what constitutes a 'carefully curated prompt' or how the authors should go about curating them. The suggestion is general and lacks concrete steps for the authors to follow. Therefore, while the review identifies a potential area for improvement, it does not offer specific, actionable advice for the authors, making it only slightly helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests adding experiments on larger datasets, which is an implicit action. However, it doesn't explicitly state *how* to do this or what specific changes are needed. The comment also expresses a concern about probabilities at large batch sizes, which could be interpreted as an implicit action to investigate this issue, but it's not explicitly stated. Therefore, the action is implied but not clearly defined.", "grounding_specificity_rationale": "The comment is about 'computational might be an issue' and 'maintaining the probabilities might become an issue.' It doesn't explicitly identify a specific part of the paper or methodology being discussed. The reviewer is making general statements about potential limitations rather than pinpointing a specific problem. Therefore, the comment is 1 at all.", "verifiability_rationale": "The comment expresses a concern about probabilities at large batch sizes but doesn't provide any specific examples, references, or logical reasoning to support this concern. It's a statement of potential issue without evidence or justification. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The review point primarily suggests 'additional experiments on larger data sets' and expresses a concern about probabilities at large batch sizes. While the suggestion is generally positive, it lacks specific details on how to implement these experiments or address the probability issue. The reviewer also states, 'I don't think this aspect is critical,' which is a negative statement that doesn't provide actionable feedback. The lack of specific suggestions and the negative framing make the review point less helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the performance gap between the submitted model and GLaMM and UNINEXT. It also mentions specific metrics (RES cIoU, REC accuracy, IoU>0.5) and models (GLaMM, UNINEXT) in the context of Table 4. This provides a clear direction for the authors to investigate the performance differences.", "grounding_specificity_rationale": "The review point explicitly refers to 'Table 4' as the location of the performance comparison. It then mentions specific models (GLaMM, UNINEXT) and metrics (RES cIoU, REC accuracy, IoU>0.5) within the context of this table. This provides strong grounding and specificity.", "verifiability_rationale": "The review point contains a claim ('Table 4: The performance on REC and RES are clearly behind more recent models') and provides supporting evidence by mentioning specific models (GLaMM, UNINEXT) and their performance numbers (83.2 RES cIoU on RefCOCO TestA, 89.4 REC accuracy (IoU>0.5) on RefCOCOg Test). This provides logical reasoning and references to external works.", "helpfulness_rationale": "The review point directly points out the performance gap and suggests comparing against specific recent models. While it doesn't explicitly state the performance of the submitted model in Table 4, it provides a clear direction for improvement and comparison. The mention of specific metrics and models makes the feedback actionable."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the similarity to ConsiStory's framewise SDSA approach and highlights the only notable difference as the mask source, making it clear what needs to be considered. The reviewer also states that the primary method relies on framewise SDSA, which largely mirrors the approach used in ConsiStory. The only notable difference lies in the mask source, utilizing CLIPseg and OTSU segmentation rather than crossattention. This makes the action clear: the authors should consider the limitations of relying on framewise SDSA and explore alternative methods like crossattention for mask generation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'framewise SDSA' and links it to 'ConsiStory,' and also specifies the differences in 'CLIPseg' and 'OTSU segmentation' as the *only* notable difference. This provides a clear and specific reference point for the authors. The authors can accurately pinpoint the section, table, figure, or unique aspect being addressed.", "verifiability_rationale": "The reviewer makes a claim about limited novelty and supports it by comparing their method to ConsiStory. This provides a basis for verification. The claim is supported by the logical reasoning that relying on an existing method might limit innovation. The common knowledge of existing approaches is used to support this claim. The external references (ConsiStory) are cited to support this claim.", "helpfulness_rationale": "The reviewer directly states a problem: 'The innovation of the proposed video storyboarding approach is limited.' This is a clear and helpful statement for the authors to understand the limitations of the work. The reviewer's statement is a direct assessment of the work's contribution and its potential impact."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point is a question, not a direct instruction. This suggests it's *implicitly* actionable. Authors might infer the need for the method to perform better on cluttered scenes. However, it doesn't specify *how* to achieve that. It doesn't point to a specific aspect of the method that needs fixing. It's a suggestion for further experimentation rather than a direct instruction on how to improve the current draft.", "grounding_specificity_rationale": "The review clearly refers to \"this method,\" indicating it's addressing the authors' own work. It doesn't point to a specific section, table, figure, or unique element of the paper. The reviewer is *implying* a potential limitation of the method based on a *guess* about where issues might arise (cluttered scenes). It doesn't pinpoint a specific line or argument in the paper where a weakness exists. The grounding is in the general concept of the method's performance in complex scenarios.", "verifiability_rationale": "The review contains a claim: \"It seems that the weakness that this method is addressing would be more prominent in images comprised of multiple objects, or cluttered scenes.\" This is a statement of observation and a potential limitation. However, the reviewer offers a *hypothesis* about why the method might struggle in cluttered scenes (images with multiple objects). This is a suggestion for further investigation (comparing on a cluttered dataset) rather than a direct, verifiable statement about a flaw *within the paper itself*. There's no citation of existing literature to support this specific weakness. The claim is based on a hypothesis and a suggestion for future work, not a direct, evidencebased criticism of the paper's content.", "helpfulness_rationale": "The review points out a potential area for improvement and suggests a way to test it. While it's not a direct critique of a flaw, it's a constructive suggestion for further analysis. However, it doesn't pinpoint *specific* weaknesses in the method or the paper. It avoids directly calling out errors, unclear explanations, or unsubstantiated claims within the paper itself. The suggestion to compare on a cluttered dataset is a direction for future research, not a direct feedback on the current draft. It's more of a forwardlooking comment than a critique of existing content."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states that the kernels are implemented with OpenAI's Triton, not CUDA, and suggests that a fullpage explanation is unnecessary. This is a direct and concrete action that the authors can readily implement. The reviewer also implies that the current explanation is likely too verbose given the known differences between Triton and CUDA implementations.", "grounding_specificity_rationale": "The comment implicitly refers to the implementation details of the kernels, which is a specific part of the paper. While it doesn't explicitly name a section or table, it clearly identifies the issue as being related to the implementation choice (Triton vs. CUDA). The reviewer also provides a reason (wellknown engineering improvements) for why a fullpage explanation is unnecessary, which adds clarity to the specific area being discussed.", "verifiability_rationale": "The comment contains a claim that the kernels are implemented with OpenAI's Triton, not CUDA. This claim is supported by the statement that a fullpage explanation is unnecessary, which implies that the current explanation is likely verbose and could be simplified given the known differences between Triton and CUDA implementations. The reviewer provides a logical reasoning for this claim.", "helpfulness_rationale": "The comment is 5 as it directly identifies a potential point of confusion for the authors (whether CUDA was used) and provides a clear alternative (Triton). The suggestion to avoid a fullpage explanation is actionable and addresses a likely concern about the level of detail provided. The justification for this conciseness, based on 'wellknown engineering improvements,' adds further value and helps the authors understand the reasoning behind the suggestion."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer criticizes the claim of zeroshot transferability but does not explicitly state what the authors should do to address this issue or how they should conduct the transfer. The criticism is general and lacks specific actionable steps for the authors.", "grounding_specificity_rationale": "The reviewer criticizes the claim of zeroshot transferability but does not specify which part of the paper this claim refers to. The connection to a specific section, table, or unique aspect is missing. The reviewer's point is vague regarding the specific issue with the transferability claim.", "verifiability_rationale": "The reviewer makes a claim about the difficulty gap between source and target tasks making transferability questionable. However, this claim is presented as a statement of opinion without any logical reasoning, common knowledge, or external references to support it. There is no explicit justification for why this claim is valid or how it relates to the existing literature on transferability.", "helpfulness_rationale": "The reviewer provides a critique of the zeroshot claim but does not offer specific, actionable feedback or suggestions to the authors. While the criticism identifies a potential weakness, it does not provide a clear path for the authors to improve their draft based on this feedback."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a potential issue: \"I suspect whether the proposed method still works well on large backbone models like SwinB or SwinL.\" This is an explicit question about a specific aspect of the method. While the reviewer doesn't provide a direct solution, the question itself is actionable, as the authors can investigate the performance of their method on larger backbones. The lack of a specific section or table reference makes it somewhat explicit, but the reviewer's question is clear and points to a concrete area for improvement.", "grounding_specificity_rationale": "The reviewer doesn't explicitly name a specific section, table, figure, or unique aspect of the paper they are referring to. They mention \"different frameworks and tasks\" and \"backbone models\" generally. While they provide some context like 'small backbone ResNet50\" and \"global pooling,\" these are general terms within the context of the paper and don't pinpoint a specific part of the paper being addressed. The reviewer's question is about the *potential* performance on larger backbones, not a specific critique of a defined element.", "verifiability_rationale": "The reviewer presents a claim: \"I suspect whether the proposed method still works well on large backbone models like SwinB or SwinL.\" This is a statement of opinion or a question about a potential limitation. The reviewer also provides a potential explanation: \"I suspect this might be the case because it might be easy to improve a relatively small backbone since it is with a smaller receptive field.\" This provides some reasoning, but it's not a direct citation of external works. The claim is based on a hypothesis and a potential explanation, making it 3.", "helpfulness_rationale": "The reviewer raises a valid question about the scalability of the proposed method to larger backbones. This is a relevant concern for the authors, as it directly relates to the practical applicability of their method. The question is specific and directly addresses a potential limitation highlighted by the observation that the gains are marginal on smaller backbones. While the reviewer doesn't offer a solution, the question itself is a constructive point for further investigation and discussion."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "Verifiable", "helpfulness_label": "5", "actionability_rationale": "The statement explicitly states that the analysis of neural networks contributes less and identifies specific limitations, such as the extension being 'trivial' due to the NTK theorem and the focus on 'wide fullyconnected neural networks'. This clearly indicates an actionable suggestion for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'Sections 3.2, 3.3' and 'wide fullyconnected neural networks', indicating an attempt to identify the specific part of the paper being addressed. However, they do not explicitly name a specific section, table, or unique element of the paper. While they specify the *type* of neural network, they don't pinpoint a precise location within the document. Therefore, it is weakly grounded as the authors can infer the focus but not with certainty.", "verifiability_rationale": "The statement contains a claim that the neural network analysis is less significant and offers a justification by stating the extension is 'trivial' due to the NTK theorem and the focus on 'easy wide fullyconnected neural networks'. This justification, even if subjective, provides a basis for verifying the claim.", "helpfulness_rationale": "The review point directly criticizes the contribution of the neural network analysis and suggests it's a limitation. This is a clear and actionable feedback aimed at improving the authors' work by highlighting a specific area that needs attention."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state an action or suggest a change to the authors' work. It raises a general concern about the number of datasets used for evaluation and then provides a detailed response from the authors. While the response itself is helpful, the initial point lacks a clear action for the authors to take.", "grounding_specificity_rationale": "The review point does not mention any specific part of the paper or methodology. It is a general comment about the evaluation setup. Therefore, it cannot be grounded to a specific aspect of the authors' work.", "verifiability_rationale": "The review point does not contain a claim or suggestion that requires verification. It is a critique of a general aspect of the evaluation process, not a specific claim about the authors' work that needs evidence. Therefore, it is not verifiable in the context of the authors' specific work.", "helpfulness_rationale": "The review point itself does not provide any actionable feedback or suggestions for the authors. It raises a concern and then provides a detailed response from the authors. While the subsequent response is helpful, the initial point on its own does not directly improve the authors' work."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests clarifying the terminology used in the paper, specifically differentiating between 'relatively inexpensive' and 'expensive to evaluate'. While this is a valid suggestion for improving clarity, it does not directly instruct the authors on *how* to improve their draft. The reviewer proposes a clarification, which is a form of actionable suggestion, but it lacks concrete steps on implementation.", "grounding_specificity_rationale": "The reviewer points out a potential confusion in the terminology used in the abstract and introduction. While they imply a connection to the multifidelity framework, they do not explicitly name a specific section, table, figure, or unique aspect of the paper that is causing the confusion. The reviewer's comment is a general observation about the clarity of the initial sections.", "verifiability_rationale": "The reviewer identifies a potential inconsistency in the terminology used in the abstract and introduction ('relatively inexpensive' vs. 'expensive to evaluate'). This constitutes a claim that needs to be addressed. The reviewer does not provide any external references or logical reasoning to support this claim, but it is a verifiable observation about the paper's content. The reviewer points out a logical inconsistency, which is a form of verifiable information.", "helpfulness_rationale": "The reviewer's comment is a general observation about the clarity of the initial sections and suggests a specific action (clarifying terminology). While the suggestion is helpful, it lacks specific details on how to achieve the clarification. The reviewer identifies a problem and suggests a potential solution, making it 3 but not fully comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review starts with a question about how the method addresses sparse reward problems, implying a lack of action on their part. It states the method doesn't work well, but doesn't suggest *how* to make it work. The minor comment is also a question, not an action.", "grounding_specificity_rationale": "The reviewer mentions 'subtaskspecific rewards\" and \"dense reward signal\" without specifying *which* part of the paper they are referring to. They don't explain *how* the proposed method is supposed to be better or *why* Qmix wouldn't work. The reference to \"this method\" is vague.", "verifiability_rationale": "The reviewer makes the claim \"in practice, the proposed method requires subtaskspecific rewards to be specified, which would be similar to providing a dense reward signal that includes rewards for reaching subgoals.\" They *don't* provide any external references or logical reasoning to support this claim. They also don't explain *why* this is a problem for the other methods.", "helpfulness_rationale": "While the reviewer identifies a potential issue with the proposed method, they don't offer any concrete solutions or further explanation. Their suggestion about the sum of lowlevel rewards is a good starting point for discussion but isn't a direct fix for the proposed method. The overall impact is limited."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment asks for clarification on a specific aspect of the paper (training data) and a related question about a specific detail (access to AH36M data). While it doesn't explicitly state an action, it encourages the authors to clarify their methodology, which is a form of actionable feedback. The reviewer is prompting the authors to identify a missing piece of information that is crucial for understanding the implementation.", "grounding_specificity_rationale": "The comment explicitly mentions 'AH36M dataset' and 'other methods (HMR, SPIN)', indicating a clear reference to specific parts of the paper. The reviewer is directly addressing a potential ambiguity in the authors' description of their training process.", "verifiability_rationale": "The comment poses questions about the training data and the access to a specific dataset. It does not contain a claim that requires verification or support. It's a request for clarification of existing choices, not a statement that needs to be proven or justified.", "helpfulness_rationale": "The comment raises a valid point about the clarity of the authors' description of their training data and the access to the AH36M dataset. While it doesn't directly provide a solution or a new idea, it encourages the authors to be more transparent about their methodology, which is important for reproducibility and understanding the context of their work. However, it doesn't offer a concrete improvement or a fundamentally new perspective."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issues with the motivation and the model size, making it 3. However, they do not provide specific guidance on how to improve the motivation or address the unfair comparison. The mention of 'CAT' and 'GAN' suggests they are aware of specific components, but the lack of concrete suggestions for improvement makes it only partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'CAT' and 'GAN' but does not explicitly identify the specific section, table, figure, or unique aspect of the paper being addressed. The mention of 'CAT' and 'GAN' is a general comment about the model components, not a precise reference to a specific part of the paper. Therefore, the grounding is weak. While the reviewer identifies what is wrong (lack of motivation, unfair comparison, model size), they do not specify *where* these issues are located within the paper. The comment is not specific about the exact location or nature of the problem within the mentioned components. Therefore, it is not specifically specific.", "verifiability_rationale": "The reviewer makes claims about the unfair experimental comparison and the bigger model issue. However, they do not provide any evidence or reasoning to support these claims. They state that the comparison is unfair and that the model is bigger, but they do not explain *why* these are problems or how they impact the results. There are no external references or logical reasoning provided to back up these claims. Therefore, the claims are not verifiable.", "helpfulness_rationale": "The reviewer provides feedback on the motivation and experimental setup. While they identify areas for improvement, they do not offer specific, actionable steps for the authors to take. The feedback is general and lacks concrete suggestions. For example, they say the motivation is unclear but don't explain *how* to make it clearer. They mention the unfair comparison but don't suggest how to make it fair. The lack of specific guidance makes the feedback less helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review points out a potential issue with the experimental results and links it to the discrepancy between MSE and MAE. While it doesn't explicitly state what needs to be changed, it clearly indicates a problem that requires attention. The reviewer implies that the smaller MSE compared to the MAE is concerning, suggesting a lack of reliability in the experimental setup or results. This points to a need for further investigation or reevaluation of the experimental methodology.", "grounding_specificity_rationale": "The review explicitly mentions 'Table 1' and refers to the metrics 'MSE' and 'MAE'. This clearly identifies the specific part of the paper being addressed. The reviewer is not just making a general comment but is pinpointing a specific discrepancy within the experimental results section. This strong reference to a specific table and metrics demonstrates high grounding specificity.", "verifiability_rationale": "The review states that the experimental results are 'unreliable' and points to the discrepancy between 'MSE' and 'MAE' as 'raising concerns about their validity'. This constitutes a claim about the validity of the experimental results. However, the review does not provide any external references or logical reasoning to support why this discrepancy *implies* unreliable results. It presents the observation but doesn't offer evidence or justification for its significance. Therefore, the claim is not 5.", "helpfulness_rationale": "The review identifies a potential issue with the experimental results, specifically the discrepancy between MSE and MAE, which raises concerns about their validity. While this points to a problem, it does not offer specific suggestions or guidance on how to address it. The reviewer highlights a weakness but doesn't provide actionable steps for the authors to take. Therefore, the review is not 5 in terms of providing concrete improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem (lack of novelty) but doesn't specify how to address it or provide concrete steps. The phrase \"direct extension\" is vague and doesn't offer actionable advice.", "grounding_specificity_rationale": "The comment is general and doesn't specify which part of the methodology is lacking novelty. It doesn't mention any specific section, table, figure, or unique aspect of the paper being criticized.", "verifiability_rationale": "The comment makes a claim (\"There is not much novelty in the methodology\") but doesn't provide any evidence or justification for this claim. It's a statement of opinion without backing.", "helpfulness_rationale": "The comment raises a valid concern about the methodology's novelty but fails to offer any actionable steps or evidence to support the claim. It identifies a weakness but doesn't provide guidance on how to improve it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the proposed method is 'not consistently better than other methods.' This is an explicit statement identifying a lack of improvement in a specific area. The authors can directly identify the need for better performance compared to other methods.", "grounding_specificity_rationale": "The reviewer mentions 'a few methods' but doesn't specify which part of the paper or method the performance is inconsistent with. While the reviewer points out a problem, they don't clearly identify the specific aspect of the paper or method being discussed. The authors would need to infer which section or comparison is causing the issue.", "verifiability_rationale": "The reviewer claims the results 'violate the motivation.' This is a claim that needs to be supported. However, the reviewer does not provide any specific examples or reasoning to explain *why* these inferior results contradict the motivation. The claim is made without sufficient evidence or justification. The authors would need more information to understand the discrepancy and how it relates to the initial goals.", "helpfulness_rationale": "The reviewer explicitly states that the comment is '1' and '2.' This is a direct assessment of the comment's value to the authors. The authors receive no actionable feedback on the inconsistent performance and are left to guess the reasoning behind the violation of the motivation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states what the authors have *not* covered regarding the datasets and their importance. It directly points to the missing information and suggests adding it. This is a clear and direct indication of an action the authors should take. The action is also quite specific, identifying the *types of activities* and their *importance for occupant comfort and energy efficiency*.", "grounding_specificity_rationale": "The review point mentions \"the datasets\" generally, without specifying a particular section, table, or figure. While it implies the need for information related to these datasets, the exact location within the paper is not explicitly stated. This means the authors would need to infer where to find or discuss this information, making the grounding somewhat weak. However, the review does specify *what* information is needed (types of activities and their importance), which adds clarity to the request.", "verifiability_rationale": "The review point presents a statement about the authors' lack of coverage regarding the datasets and their importance. This constitutes a claim that the authors have *not covered more* on this topic and its relevance. However, the review point does not provide any external references, logical reasoning, or examples to *support* this claim. It's a statement of observation, not a claim that requires verification or evidence.", "helpfulness_rationale": "The review point clearly identifies a gap in the authors' understanding and provides a specific suggestion for improvement. It tells the authors exactly what information is missing (coverage of dataset types) and *why* it's important (occupant comfort and energy efficiency). This is a direct and actionable piece of feedback that will help the authors improve their draft by providing more context and detail about their datasets."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the ambiguity of using 'D' for both dimensionality and dilation factor. They also suggest a concrete solution: using different notation. This is an explicit and concrete action that the authors can readily understand and implement.", "grounding_specificity_rationale": "The reviewer refers to 'D' as the ambiguous term. However, they do not explicitly state *which* instance of 'D' in the paper is causing the confusion. The reviewer only mentions 'dimensionality of points' and 'dilation factor' generally, making the grounding somewhat weak. While the specificity of the issue (ambiguity of 'D') is clear, the lack of pinpointing the exact location of 'D' in the paper weakens the grounding.", "verifiability_rationale": "The reviewer makes a claim that 'D is used to represent both dimensionality of points and dilation factor. Better to use different notation to avoid confusion.' This is a claim that can be verified. The reviewer's suggestion to use different notation is a logical reasoning to avoid confusion. While the reviewer doesn't provide specific examples of where 'D' is used in different ways, the *reasoning* for why different notation would help is clear and plausible.", "helpfulness_rationale": "The reviewer's point is clear and directly addresses a potential source of error for the authors. Suggesting better notation is a constructive suggestion that is likely to be helpful for the authors in avoiding confusion. This review point provides a clear and actionable piece of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their understanding of 'state' and directly asks a question about the meaning of 'elements' in relation to 'state' or 'action'. This is a clear and direct action that the authors can take to clarify their understanding.", "grounding_specificity_rationale": "The reviewer explicitly refers to lines 186187, which indicates a strong grounding. They are also asking a specific question about the definition of 'elements', further emphasizing the specificity of their request.", "verifiability_rationale": "The reviewer makes a claim about the ambiguity of 'elements' and asks for clarification. While the paper defines 'state' and 'action', the connection to 'elements' is not explicitly stated, making it partially verifiable. The reviewer is seeking justification for their interpretation.", "helpfulness_rationale": "The review point identifies a potential point of confusion for the authors regarding the definition of 'elements' in the context of 'state' and 'action'. While it doesn't provide a direct solution, it encourages the authors to clarify their understanding, which can be helpful for their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment identifies a *potential weakness* (lack of clarity in comparisons) but doesn't explicitly state what needs to be improved or how the authors should address this weakness. It points to a *concept* (adaptive learning of GPRGNN) without explaining *how* the comparison is lacking.", "grounding_specificity_rationale": "The comment mentions 'adaptive learning of GPRGNN,' which provides some level of grounding by identifying a specific area. However, it doesn't pinpoint *exactly* which part of the comparison is unclear. It doesn't specify a *unique* section, table, figure, or element being addressed, making it not fully grounded.", "verifiability_rationale": "The comment states that the 'Theoretical comparisons to adaptive learning of GPRGNN is not clear.' This is a claim that needs verification. However, the review point itself doesn't provide any specific evidence or references to support this claim. It's an assertion of a lack of clarity without further explanation or justification.", "helpfulness_rationale": "The comment identifies a *potential weakness* (lack of clarity in comparisons) but doesn't offer any actionable feedback or suggestions for the authors. It doesn't guide the authors on how to improve their draft based on this observation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their intention to suggest an alternative to yes/no responses for measuring object hallucination. They propose using 'more nuanced methods' and providing 'explanations and justifications'. This indicates a clear and actionable suggestion for improvement.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify the specific aspect of the yes/no response method being criticized. While the concept of 'yes/no responses' is implied, the specific element within that method (e.g., the 'yes' or 'no' itself, or the process of generating such responses) is not clearly pinpointed. Therefore, the grounding is weak as the authors cannot precisely identify the referenced part of the paper or method being discussed.", "verifiability_rationale": "The reviewer makes a claim that 'Measuring object hallucination through only yes/no responses is not sufficient.' However, they do not provide any specific evidence, examples, or references to support this claim within the review point itself. The reasoning is stated as a general assertion rather than a logically derived conclusion.", "helpfulness_rationale": "The reviewer's comment, while suggesting an alternative evaluation method, lacks specific details on how this new method would be implemented or why the current yes/no approach is inadequate. The suggestion is present, but the accompanying justification is limited, making it 3 but not fully comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the 'verylongterm forecasting task is of limited practical significance' and provides concrete suggestions such as 'conducing experiments on more datasets' and training 'baseline models with the 'correct' forecast horizon'. These suggestions are direct and indicate actions the authors should take.", "grounding_specificity_rationale": "The reviewer refers to the 'verylongterm forecasting task' but does not explicitly identify a specific part of the paper or methodology within that task. While the reviewer suggests improvements to the 'discussion', the specific issue being addressed in the discussion is not clearly pinpointed.", "verifiability_rationale": "The reviewer makes a claim about the 'limited practical significance' of the 'verylongterm forecasting task'. This claim is supported by the suggestions to 'conducing experiments on more datasets' and training 'baseline models with the 'correct' forecast horizon', which provide logical reasoning and examples to back up the claim.", "helpfulness_rationale": "The review points out a limitation of the work ('the verylongterm forecasting task is of limited practical significance') and provides specific, actionable suggestions for improvement ('conducing experiments on more datasets' and training 'baseline models with the 'correct' forecast horizon'). This guidance is directly helpful for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing components of the ablation study: 'experiments and explanation regarding the different queries used in spatiotemporal representation' (spatial, temporal, and summary). It also asks a specific question: 'What if only have spatial one, or temporal and summary one?'. This clearly identifies an actionable step for the authors to take, specifying what kind of experiments are needed and why they are important. The reviewer provides a clear direction for improvement.", "grounding_specificity_rationale": "The review point explicitly mentions 'experiments and explanation regarding the different queries used in spatiotemporal representation' and specifies the types of queries: 'spatial, temporal, and summary'. This directly points to the relevant section of the paper and clearly identifies the issue. The reviewer does not leave any ambiguity about which part of the paper is being addressed. The grounding is explicit and precise.", "verifiability_rationale": "The review point makes a clear claim: 'Ablation  missing components: There should be experiments and explanation regarding the different queries used in spatiotemporal representation...'. This claim is supported by logical reasoning, as the reviewer explains why these different query types are important for understanding the model's behavior. The reviewer also asks specific questions ('What if only have spatial one, or temporal and summary one?') that require justification and analysis, indicating a clear understanding of the implications of these choices. The claim is wellsupported by the context of the research and the importance of understanding the contribution of different query types.", "helpfulness_rationale": "The review point is 5 as it directly points to a specific area for improvement in the authors' work (the ablation study). The reviewer not only identifies the missing components but also asks specific questions ('What if only have spatial one, or temporal and summary one?') that guide the authors on how to conduct these experiments. The suggestions are concrete and actionable, providing a clear path for the authors to address the identified weakness. The reviewer's feedback is not just a criticism but a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the proposed FRM is a 'simple combination' of channel attention and spatial attention and lacks 'indepth innovative detail'. This statement is explicit about the nature of the method and the desired level of detail. While it doesn't specify *how* it's a combination, it clearly indicates a lack of specific innovation.", "grounding_specificity_rationale": "The reviewer makes a general statement about the proposed FRM being a 'simple combination' of channel attention and spatial attention. They do not specify which part of the paper or section the FRM is being discussed in relation to. Furthermore, they do not specify what is lacking in detail (e.g., specific implementation, limitations, etc.).", "verifiability_rationale": "The reviewer makes a claim that the proposed FRM is a 'simple combination' of channel attention and spatial attention and lacks 'indepth innovative detail'. However, they do not provide any evidence or reasoning to support this claim. They do not explain why this combination is simple, how the innovation is lacking, or provide any examples or references to back up their assertion.", "helpfulness_rationale": "The reviewer points out a potential weakness in the proposed FRM (being a simple combination) and suggests the authors need to provide more detail about the 'indepth innovative detail'. This directly addresses a potential area for improvement in the FRM description and encourages the authors to be more specific about their innovative approach."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the authors' claim about the lack of negative social impact. However, it doesn't provide concrete steps on *how* to address this or what specific aspects of the work might be affected. The suggestion to discuss 'the social impact of increased automation' or 'the risks from the dual use of their method' is a suggestion for improvement rather than a direct action item.", "grounding_specificity_rationale": "The comment mentions 'social impact' as a general area of concern, which can be interpreted as grounding the reference to a specific aspect of the paper. However, it doesn't specify *which* part of the paper or *what specific* issue within 'social impact' is being addressed. The reviewer's suggestions are general and don't point to a concrete instance.", "verifiability_rationale": "The comment contains a claim: 'the authors state that they foresee no negative social impacts of their work (line 379)'. The reviewer expresses an opinion ('I do not believe this work has the potential for significant negative impact') and suggests areas for discussion ('the social impact of increased automation, or the risks from the dual use of their method'). This is presented as a point for consideration, not a verifiable claim based on existing evidence within the paper.", "helpfulness_rationale": "The comment raises a valid point about the lack of discussion on social impact. However, it doesn't provide specific, actionable feedback on how to address this. It suggests *what* to add but not *how* to integrate it or *why* it's important enough to be highlighted. The reviewer's suggestions are general and lack concrete details."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that there is no clear connection between the two concepts, which can be considered an explicit action or suggestion. However, the reviewer does not specify *how* these two concepts are related or what aspect of them is causing the issue. The suggestion to clarify the connection is vague and does not provide concrete steps for the authors to take.", "grounding_specificity_rationale": "The reviewer mentions the two concepts but does not specify *which* part of the paper or discussion these concepts are being referenced. The comment is general and does not point to a specific location. The reviewer's suggestion to clarify the connection is also general and does not specify where the confusion lies.", "verifiability_rationale": "The reviewer states a claim: 'At a highlevel, I don\u2019t see a clear connection...'. This is a statement of opinion or judgment. However, the reviewer does not provide any evidence or reasoning to support this claim. The lack of specific examples or references makes the claim 1.", "helpfulness_rationale": "The reviewer directly points out a potential issue in the paper (a perceived disconnect between two concepts) and suggests a way to improve understanding (clarification). This is a clear and actionable feedback that the authors can use to improve their work. While the suggestion to clarify is vague, the underlying point is helpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state what the authors should do or what changes they should make. It suggests future research directions but does not provide concrete, actionable feedback for the authors to improve their current draft. The reviewer proposes exploring *why* certain methods work better than others, but does not specify which aspects of the paper this analysis should focus on or what modifications the authors should consider implementing based on this suggestion.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or element that it is addressing. It makes a general statement about the need for more indepth analysis of the paper's findings. The reviewer does not specify which section, table, figure, or unique aspect of the paper they are referring to, making it difficult for the authors to pinpoint the area of improvement.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It is a suggestion for future research and does not critique or point out specific weaknesses in the current work that need evidence or justification. The reviewer proposes exploring *why* certain methods work better than others, but this is a suggestion for future work, not a claim that needs to be supported by evidence within the current paper.", "helpfulness_rationale": "The review point does not provide the authors with any specific, actionable feedback or suggestions. It is a suggestion for future research directions and does not offer immediate guidance on how to improve their current draft. The reviewer proposes exploring *why* certain methods work better than others, but this is a broad suggestion and does not provide the authors with concrete steps they can take to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is explicitly asking for information about the kmax problem and is providing a clear instruction to 'please provide a citation for this'. This is a direct and concrete request for action.", "grounding_specificity_rationale": "The reviewer is explicitly asking about the 'kmax problem', which is a specific aspect of the paper. They are also asking for a 'citation for this', which further specifies the type of information needed. This indicates strong grounding in both the aspect being addressed and the nature of the information required.", "verifiability_rationale": "The reviewer is not making a claim. They are asking a question. Therefore, it fits the 'X' category for 'X'.", "helpfulness_rationale": "The reviewer is asking for information that is likely relevant to the author's work, especially if they have used or are building upon the kmax problem. Providing a citation would likely be helpful in improving the relatedness of the submission. However, it's a request, not a direct action, so it's not 5 in itself."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states 'there is no information on how the function for the optimal sequence length was estimated (Equation 1)'. This clearly indicates an implicit action that needs to be taken \u2013 to understand the estimation process \u2013 but the information is missing. The reviewer also states 'how reliable we expect this model to be', which implies a need to understand the reliability, further supporting the implicit action. However, the reviewer does not provide any details on *how* the estimation was done or *why* they expect the model to be reliable, making the action vague.", "grounding_specificity_rationale": "The reviewer mentions 'Equation 1' and 'the function for the optimal sequence length' in their comment. This indicates that the reviewer has identified a specific part of the paper or a specific element being discussed. However, the reviewer does not specify *what* aspect of the function's estimation or reliability they are referring to. They simply state that there is no information on how the function was estimated and how reliable it is. Therefore, while the comment is implicitly grounded, it lacks specificity about the exact issue.", "verifiability_rationale": "The reviewer makes a claim by stating 'there is no information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable we expect this model to be'. This is a clear statement of a deficiency. However, the reviewer does not provide any evidence or justification for this claim. They simply state the problem without explaining why it's a problem or providing any context or references to support their assertion. There is no logical reasoning, common knowledge, or external references provided to back up their claim.", "helpfulness_rationale": "The reviewer's comment identifies a valid concern regarding the lack of information and the reliability of a model. However, the review does not offer any specific suggestions or actions that the authors can take to address this issue. The reviewer simply states the problem without providing any alternative information or context. While the comment highlights a potential problem, it lacks the necessary guidance to be truly helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point implicitly suggests an action: that the authors should correct the inaccurate description at location L006. While not explicitly stated, the reviewer's suggestion to 'maybe add 'on the subword level'' implies a desired outcome, guiding the authors towards a more precise description. However, the exact nature of the correction isn't fully detailed, making it less concrete than a fully explicit comment.", "grounding_specificity_rationale": "The review point explicitly mentions 'L006' and suggests a change related to the description of a quantity. The mention of 'L006' demonstrates strong grounding as the authors can easily identify the specific location being referred to. The suggestion to 'maybe add 'on the subword level'' further specifies the potential issue and a possible solution, indicating high specificity regarding the area of concern.", "verifiability_rationale": "The review point contains a claim: 'L006, as later written in the main text, 'thousands' is not accurate here.' This claim requires verification. While the suggestion to 'maybe add 'on the subword level'' offers a potential explanation, it doesn't definitively prove or disprove the inaccuracy of 'thousands'. There is no external reference or logical reasoning provided to support or refute the claim within the review point itself.", "helpfulness_rationale": "The review point is 5. It identifies a potential issue with the paper's description and offers a concrete suggestion for improvement. The reviewer directly points to a specific location and proposes a refinement, providing clear guidance for the authors to enhance their work. The suggestions are directly actionable and aimed at improving clarity and accuracy."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly points out the missing hyperparameters and suggests improvements related to them. While the reviewer doesn't provide specific details on *how* these hyperparameters should be set, the action of identifying their absence is clear and actionable. The reviewer also asks a question about the behavior of figures, which implies a need for clarification, although the exact action isn't fully specified. Therefore, the action is partially explicit and somewhat implicit.", "grounding_specificity_rationale": "The reviewer specifically asks about 'latent path figures (eg Fig 3)' and the behavior of the yvalue at x=0. This demonstrates strong grounding as the reviewer is pointing to a specific part of the paper and asking a specific question about it. The reviewer also mentions normalization, which further grounds the discussion. The request for clarification about figure behavior is also grounded in a specific element of the paper.", "verifiability_rationale": "The reviewer states that hyperparameters are missing and asks a question about the figure behavior. While the reviewer identifies a problem, they don't provide a logical reasoning or external references to support why these hyperparameters are missing or why the figure behavior is always 0 at x=0. The claim is made, but the supporting evidence is lacking. The request for further analysis is a suggestion but not a fully verified claim.", "helpfulness_rationale": "The reviewer provides specific points for the authors to consider, such as looking at hyperparameters and understanding figure behavior. These are actionable suggestions. The reviewer also suggests further analysis, which is a valuable direction for improvement. However, the reviewer doesn't explicitly explain *why* these hyperparameters are missing or *why* the figure behavior is always 0 at x=0, which limits the helpfulness of these suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies issues with the paper's organization and clarity, such as forward referencing and material placement. While they point out *what* is wrong, they don't explicitly state what the authors *should* do about these issues. For example, they mention 'The exact contribution(s) need to be written more clearly in the Introduction' but don't specify how to improve the writing. This indicates a lack of explicit, actionable suggestions.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 1' and also refers to 'deeprag algorithm' and 'high concurrency discussion'. This indicates a strong grounding as the reviewer can accurately pinpoint the specific parts of the paper being addressed.", "verifiability_rationale": "The reviewer makes claims about the paper's organization and clarity, stating that material is introduced without proper explanation and is explained in later sections, and that key components are in the appendix. This is a claim that can be verified by examining the paper's structure and content. The reviewer provides a logical reasoning for these claims, indicating verifiability.", "helpfulness_rationale": "The reviewer provides some information about issues and suggests potential improvements, such as 'The exact contribution(s) need to be written more clearly in the Introduction' and 'The material supporting the main contributions seems to be in the appendix and not the main sections'. While these suggestions are 3, they are vague and lack specific details about what needs to be done. The authors would need to spend significant effort to understand the issues and implement the suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the question about the effect on the full tensor error and asks 'Is there any error bound in terms of epsilon?'. This is an explicit action, as the reviewer is directly asking a question related to the paper's content. However, the action is somewhat vague because the specific type of error bound is not mentioned, requiring the authors to infer the desired level of detail. Therefore, it is Partially Actionable.", "grounding_specificity_rationale": "The reviewer mentions 'the paper it is mentioned that the obtained core tensors can be rounded...', which explicitly refers to a specific part of the paper. This indicates that the reviewer can identify the referenced part. Furthermore, the reviewer asks specifically about the 'error bound in terms of epsilon', which is a very specific request related to the mentioned rounding process. Therefore, the grounding is explicit, and the specificity is high. This makes it 5.", "verifiability_rationale": "The reviewer is asking a question about the theoretical effect of rounding and the existence of an error bound. There is X being made, as the reviewer is not stating an opinion or judgment. Therefore, it falls under 'X'.", "helpfulness_rationale": "The reviewer is asking a question directly related to the paper's content and seeks clarification on a specific implementation detail (rounding to smaller ranks with a given accuracy). This question is relevant to the authors and aims to improve their understanding and potentially their implementation. While it doesn't directly provide a solution to a problem, it seeks to clarify a point, which can be helpful in understanding the paper better. Therefore, it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'It's known that discriminative setting can not apply on real applications, what is the result on generative setting?'. The action is clear: identify the missing results for the generative setting. This action is directly stated and the information is concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'generative setting' as the part of the paper they are referring to. This is a clear and accurate identification, making the grounding fully grounded. The comment also specifies what is needed: 'the result', making it specific.", "verifiability_rationale": "The reviewer is making a suggestion or a request for information ('what is the result on generative setting?'). While this could be considered a claim in the sense that they are recommending improvement, it doesn't have external references or logical reasoning within the review point itself to support it. Therefore, it's not 5. The lack of a claim statement makes it not 'X' (X).", "helpfulness_rationale": "The reviewer provides a specific and actionable suggestion: 'what is the result on generative setting?'. This directly points the authors to a missing piece of information and encourages them to consider it. This is a clear and helpful suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what the author should do. It points out a missing piece of information (the effectiveness for other language families is unknown) but doesn't tell the author how to address it.", "grounding_specificity_rationale": "The reviewer mentions 'other language families' but doesn't specify which part of the paper or unique element this refers to. While the area can be inferred, it's not a precise identification. The issue is about the 'effectiveness' itself, which is a general concept, making it somewhat specific in the sense that it's a known issue with this general aspect.", "verifiability_rationale": "The review point states a fact ('the effectiveness of the proposed approach for other language families remains unknown') but doesn't provide any reasoning, common knowledge, or external references to support this claim. It simply points out a gap in information.", "helpfulness_rationale": "The information that the effectiveness of the proposed approach for other language families is unknown is a crucial piece of information for the author. It highlights a potential limitation or area for further investigation, making it 3 in guiding further research or experimentation."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states the desire for a description of 'p', indicating an intention to improve the draft. However, it does not specify *how* this description should be provided or where this information should be located within the paper. The action is present, but the implementation details are missing.", "grounding_specificity_rationale": "The comment implies a reference to the variable 'p' mentioned in the text, but it does not explicitly identify the specific section, table, figure, or unique aspect of the paper where this description should be provided. The grounding is weak because the exact location is not clearly specified.", "verifiability_rationale": "The comment contains a claim: 'It would help if the form of p was described somewhere near line 135.' However, it does not provide any justification or reasoning for why this is a necessary or beneficial change. There are no references to external works or logical arguments to support this suggestion. The claim is made without sufficient evidence or explanation.", "helpfulness_rationale": "The comment points out a potential area for improvement by suggesting that the form of 'p' should be described. This highlights a genuine concern about the completeness of the information in the draft. While the comment identifies a weakness, it lacks specific guidance on how to achieve this improvement. The suggestion is present, but it lacks actionable steps."}
{"actionability_label": "2", "grounding_specificity_label": "UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment states that 'Clarity: Related work could be improved' but does not specify what needs to be improved or how to achieve it. While it identifies a need for clarification, it lacks concrete actions. The reviewer knows related work needs clarification, but doesn't offer specific steps on *how* to clarify it (e.g., compare with a specific paper, reorganize sections).", "grounding_specificity_rationale": "The comment mentions 'some related works are mainly named but their differences are not described enough.' This indicates a lack of specific grounding in the *papers* being referred to. While the *area* of improvement (related work) is somewhat grounded, the specific *papers* are not explicitly named. However, the comment does specify what is missing regarding these related works (lack of description of differences), which adds a degree of specificity.", "verifiability_rationale": "The comment contains a claim: 'Related work could be improved.' This claim is verifiable by examining the existing related work section and assessing the level of detail and comparison provided. The reviewer provides a reason for their claim: 'Some related related works are mainly named but their differences are not described enough.' This offers some justification for the claim, even if it's not a complete solution.", "helpfulness_rationale": "The review point identifies a valid area for improvement ('clarity of related work') and provides some context ('some related related works are mainly named but their differences are not described enough'). This suggests that the reviewer has observed a potential weakness in the related work section. While it doesn't offer specific steps for improvement, it does point towards a concrete area of revision. The reviewer is essentially suggesting that the authors should be more specific in their literature review."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper does not explain what type of understanding one reaches by looking at the PPP maps. This is an implicit action that the reviewer believes is needed for the authors to improve their draft by adding this explanation. The reviewer does not explicitly state how they would implement this action, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'PPP maps' in their review point. This is a clear and specific reference to a particular part of the paper. The reviewer is also asking a question about what understanding one reaches by looking at these maps, which directly relates to the content of that section. Therefore, the grounding is specific.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are pointing out a missing element (explanation of PPP maps) rather than making a statement that needs to be supported by evidence. Therefore, it is not verifiable.", "helpfulness_rationale": "The reviewer's point is 5. They are suggesting that the authors explicitly explain the understanding derived from PPP maps. This is a clear and direct suggestion that, if implemented, would significantly improve the paper's clarity and impact. While the reviewer doesn't provide specific details on *how* to explain this understanding, the suggestion itself is concrete and actionable. The helpfulness score is high because the reviewer is directly pointing out a potential improvement to the paper's communication."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the authors do not compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. This directly points to a missing action for the authors. However, the comment doesn't specify how this lack of comparison impacts credibility or what specific comparisons would be beneficial, making the action somewhat vague.", "grounding_specificity_rationale": "The comment explicitly mentions 'other stateoftheart methods for spanrelated tasks' and names a specific example, 'SpanBERT'. This indicates that the authors can identify the specific area being addressed (the lack of comparison in the methods section) and the specific aspect within that area (the missing comparison with SpanBERT). Therefore, the grounding is strong.", "verifiability_rationale": "The comment contains a claim that the authors' work is 'lacking some credibility' due to the missing comparison. While the *reason* for this lack of credibility isn't explicitly stated, the suggestion to 'compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT' provides a basis for verification. The suggestion points to a potential improvement and offers a concrete action for the authors. However, it lacks specific justification or examples to fully support the claim.", "helpfulness_rationale": "The review point directly points to a potential weakness in the authors' work \u2013 the lack of comparison with stateoftheart methods. It suggests a concrete action for the authors to take \u2013 compare their methods with SpanBERT. This actionable feedback, even if it lacks detailed justification, is helpful for guiding the authors to improve their work. The suggestion provides a clear direction for further research and evaluation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitation of training only on rewarded actions in the RBI method. They also suggest that considering rewardless actions could be a significant factor in the success of FP+RBI over RBI alone. This indicates a clear and direct identification of a potential weakness or area for improvement. The reviewer provides a specific example ('\"No, the answer is Timothy Dalton.\" in Task 3) to illustrate the type of supervision that could be missed. The suggestion to provide a stronger baseline for the RBI method further strengthens the actionable nature of the comment.", "grounding_specificity_rationale": "The reviewer refers to 'RBI' and 'FP + RBI' in their review point. While they don't explicitly state section numbers or table references, the context implies a general understanding of these methods within the paper. The reviewer is specifically discussing the limitations of the RBI method, which is a defined concept. They are also pointing out a potential improvement to the method, which is a specific suggestion related to the method's description. Therefore, the grounding is strong as the reviewer is referring to specific methods and suggesting an improvement to them.", "verifiability_rationale": "The reviewer makes a claim about a potential factor contributing to the effectiveness of FP+RBI over RBI. They suggest that the omission of useful supervision from rewardless actions could be a key differentiator. However, they do not provide any specific evidence or references to support this claim within the review point itself. The reviewer presents this as a hypothesis for further investigation. While the claim is related to the paper's content (RBI and FP), the lack of immediate supporting evidence makes it '1' based solely on the provided text. The reviewer's suggestion to provide a stronger baseline for the RBI method is a request for improvement, not a claim that needs verification.", "helpfulness_rationale": "The reviewer raises a valid point about the potential benefits of considering rewardless actions in the RBI method. They suggest that this omission could explain the advantage of FP+RBI over RBI alone. This is a constructive criticism that points to a potential area for improvement in the understanding or implementation of the RBI method. The reviewer also suggests a stronger baseline for the RBI method, which is a concrete suggestion for improvement. The question about the usefulness of FP is a probing question that encourages further discussion and analysis. Overall, the reviewer provides a clear and relevant suggestion that could help the authors improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their understanding of the multiscale statement and provides a clear explanation of why they believe it's misleading (logical time scale rather than physical time scale). They also explicitly state the benefit of the slow RNN (reduced gradient path). This is a clear and direct statement of a potential misunderstanding or area for clarification.", "grounding_specificity_rationale": "The reviewer directly addresses the 'multiscale statement' without needing to infer what part of the paper they are referring to. They also clearly specify what they believe is the correct understanding (logical time scale) and what the benefit is (reduced gradient path). This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer presents a claim that the multiscale statement is misleading. They then provide a rationale for this claim, explaining their understanding of the underlying mechanism (logical time scale) and the benefit of the slow RNN. This rationale, while offering an alternative perspective, does provide some justification for the claim, making it 3.", "helpfulness_rationale": "The reviewer's comment is highly informative and directly addresses a potential point of confusion for the authors. They not only identify a potential issue with the authors' description but also offer a potential alternative interpretation and a benefit of the slow RNN. This makes the comment actionable and helpful for the authors to understand and potentially improve their work. While it's not a direct criticism of the authors' work, it's a valuable insight that can lead to better understanding and implementation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explains the difference between expected performance under observation noise and the stochastic noisy function but does not provide explicit instructions or actions for the authors to take. The point states: 'It would be good to make this distinction clearer upfront.' This is a suggestion for improvement but does not tell the authors what to do. Therefore, it is not actionable.", "grounding_specificity_rationale": "The review point uses general terms like 'formulation' and 'objective function' without specifying a particular section, table, figure, or unique aspect of the paper. It does not identify a specific part of the paper being addressed. Therefore, it is 1.", "verifiability_rationale": "The review point makes a claim about the difference between expected performance under observation noise and the stochastic noisy function. However, it does not provide any specific examples, references, or logical reasoning to support this claim. It simply states the difference without backing it up. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point raises a valid concern about the evaluation metric used for noisy functions and suggests an alternative (expected performance under observation noise). While this is a relevant point and could be helpful for guiding authors, the review point does not provide concrete steps or examples for the authors to implement this suggestion. It lacks actionable guidance. Therefore, it is 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests two potential improvements: first, exploring the use of a Vamp prior with VGAE, and second, suggesting an experiment to keep the generative model fixed while varying only the inference part. While the reviewer doesn't explicitly state how to implement these suggestions, they are direct actions that the authors could take to address the identified issues. The suggestions are clear and point towards specific experiments or model modifications.", "grounding_specificity_rationale": "The reviewer's suggestions are not entirely grounded. While the second suggestion explicitly mentions 'Figure 3' and proposes trying 'SIGVAE' or 'VGAE', the first suggestion refers to a 'doubly stochastic construction' without specifying the exact section or table where this is discussed. However, the suggestion to try a 'Vamp prior' implies a specific element within the model, adding a degree of specificity. Therefore, it can be considered '3'.", "verifiability_rationale": "The reviewer's comments are verifiable. The first suggestion proposes a specific model (Vamp prior with VGAE) and asks a question about its potential benefits, which can be verified through experimentation or literature review. The second suggestion proposes a specific experimental setup: keeping the generative model fixed and optimizing only the inference part with different inference models. This provides a clear basis for verification and analysis.", "helpfulness_rationale": "The reviewer's comments are 5. The suggestions directly address the potential ambiguity in attributing benefits to either the generative model or the inference method. The first suggestion offers a concrete experiment to investigate the impact of the Vamp prior, and the second suggestion provides a clear methodology for comparing representations when the generative model is held constant. These suggestions are actionable and provide a clear path for the authors to further their research."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer asks direct questions about the model's behavior, which can be considered explicit. However, the questions are general and do not specify what action the authors should take. The reviewer is asking 'Do you have a demonstration or result related to your model collapsing less than other methods?' and 'In line 159, you mentioned gradients become 0 and collapse; it was a good point, is it commonly encountered, did you observe it in your experiments?'. These questions are diagnostic and do not provide a clear action for the authors to follow.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'line 159' and 'your experiments'. This directly grounds the comment to a specific section of the paper and the authors' own work. The reviewer is asking about a phenomenon described in the paper (gradients becoming 0) and wants to know if it's common and observed in their own experiments. This points to a specific area of the paper.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are asking questions about the model's behavior and the paper's description. Therefore, it falls under the 'X' category (X). The questions are: 'Do you have a demonstration or result related to your model collapsing less than other methods?' and 'In line 159, you mentioned gradients become 0 and collapse; it was a good point, is it commonly encountered, did you observe it in your experiments?'. These are inquiries, not statements requiring evidence.", "helpfulness_rationale": "The reviewer is asking diagnostic questions to better understand the model's behavior and the paper's description. While this can be helpful for diagnosis, it doesn't directly suggest concrete improvements or actionable steps for the authors at this time. The questions are: 'Do you have a demonstration or result related to your model collapsing less than other methods?' and 'In line 159, you mentioned gradients become 0 and collapse; it was a good point, is it commonly encountered, did you observe it in your experiments?'. These are requests for information rather than critiques or suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states the action to be taken ('Conducting trials') and provides specific models to perform that action (OPT, BLOOM, or other alternatives). It's a clear instruction for the author.", "grounding_specificity_rationale": "The review point doesn't explicitly refer to a specific section, table, figure, or unique aspect of *this* paper. It's a general suggestion about experimentation.", "verifiability_rationale": "The review point is a suggestion for future work, not a claim about the current paper's shortcomings or validity. It doesn't require verification.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the author to conduct further experiments with different LLM families. It directly helps them improve their work by suggesting a concrete next step."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the potential misunderstanding between the reviewer's initial understanding of 'curve finding' and its actual implementation related to FGE. However, it doesn't provide concrete steps on how to implement the alternative approach, making it somewhat vague in terms of actionable steps.", "grounding_specificity_rationale": "The comment refers to specific concepts like 'curve finding,' 'FGE,' and 'the first part,' indicating a clear grounding in the paper's content. The reviewer also mentions 'take random weights,' which further pinpoints the area of confusion. The comment is fully grounded in the specific parts of the paper being discussed.", "verifiability_rationale": "The comment provides a clear description of the reviewer's understanding of 'curve finding' and then points out the discrepancy with how it relates to FGE. This allows the authors to verify the claim and understand the potential misunderstanding. The reasoning is logical, and the examples provided (like the difference between finding good weights and learning curves between weights) are sufficient to support the claim. The comment is fully supported by explicit and sufficient evidence.", "helpfulness_rationale": "The comment identifies a potential misunderstanding between the reviewer's initial understanding of 'curve finding' and its actual implementation related to FGE. It also suggests an alternative approach, which could be helpful for the authors. While the comment doesn't provide a definitive solution, it does point out a potential area of confusion and offers a different perspective, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing baseline (linear scalarization + Concorde) and clearly identifies the action: 'include results'. This is a direct and actionable suggestion for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'competitive baselines' and 'single objective TSP' in the context of suggesting the inclusion of Concorde. While the general area of improvement is relevant, the specific part of the paper being addressed is not explicitly pinpointed. The reviewer doesn't directly state 'which section or table' they are referring to, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer makes a claim that 'linear scalarization + Concorde should be included for a better comparison' and provides a reasoning based on the observed performance differences and the known strength of Concorde for singleobjective TSPs with nonconvex Pareto fronts. While the reasoning is logical, the suggestion lacks specific references or examples within the *review point itself* to fully support the claim.", "helpfulness_rationale": "The review point clearly identifies a potential weakness (heuristic solvers vs. linear scalarization for singleobjective TSPs) and provides a direct and constructive suggestion: 'include results'. This is a valuable piece of feedback that directly addresses a specific concern and guides the authors on the next step."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, not a direct instruction. While the question implies an action (discussing the overlap), it lacks specific details on what aspects of the overlap to explore. The reviewer asks, 'while it is interesting to see the grounding of the proposed method in neuroscience, some of the general ideas are already present in other methods for exploration...'", "grounding_specificity_rationale": "The reviewer mentions specific concepts like 'generalized Voronoi graph' and 'semantic maps' in relation to 'other methods for exploration'. This indicates some level of grounding as the reviewer identifies specific elements or ideas that might be relevant. However, the reviewer does not explicitly state which part of the paper these concepts relate to or how they specifically connect. The mention is highlevel and lacks a detailed explanation of the connection or a specific section in the paper where this overlap could be discussed.", "verifiability_rationale": "The reviewer states, 'some of the general ideas are already present in other methods for exploration...'. This statement is a claim that requires verification. The reviewer provides examples of existing methods ('generalized Voronoi graph', 'semantic maps', 'pose graphs', 'curiositydriven exploration') as evidence to support this claim. The presence of these examples serves as verification of the claim.", "helpfulness_rationale": "The review point is a question prompting a discussion about the overlap between the proposed method and existing methods. While this is a valuable suggestion for improving the paper's clarity and contextualization, it does not directly provide a concrete action for the authors to take. The reviewer does not specify what changes are needed or how the discussion should proceed. Therefore, while the comment is constructive, it lacks the direct helpfulness of a suggestion with specific implementation details."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "Not Verifiable", "helpfulness_label": "2", "actionability_rationale": "The review point asks 'Why are you using GRU for the Pyramid and LSTM for the sequential part? Is the combination of two architectures a reason for your improvements?' This is a question about the *reasoning* behind the architectural choices, not an explicit instruction on what actions the authors should take. The authors are being asked to justify their *why*, rather than being directed to perform a specific action. Therefore, it is implicit and lacks concrete action.", "grounding_specificity_rationale": "The review point asks 'Why are you using GRU for the Pyramid and LSTM for the sequential part? Is the combination of two architectures a reason for your improvements?'. The paper *mentions* the use of GRU and LSTM in the context of the Pyramid and sequential parts, respectively. However, it does not explicitly pinpoint the *specific aspect* of the Pyramid or the sequential part that makes it suitable for GRU or LSTM. The reviewer is asking for a deeper explanation of the *why* behind these choices, which is not fully addressed in the paper. Therefore, it is grounded but not specific.", "verifiability_rationale": "The review point is a question about the *reasoning* behind the architectural choices, not a claim that needs to be verified. It does not present a statement that requires logical reasoning, common knowledge, or external references to be considered valid. It's a diagnostic question, not a statement that can be proven true or false. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point is a question about the *reasoning* behind the architectural choices and whether the combination of GRU and LSTM is a reason for improvements. While it raises a valid point about the design choices, it does not directly suggest concrete, actionable improvements to the authors' draft. It is diagnostic, not prescriptive. Therefore, it is not 5 as it does not directly guide the authors on how to improve their work."}
{"actionability_label": "1", "grounding_specificity_label": "1: 2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment introduces the term 'active vertices' without providing an explicit definition or explaining its connection to the context of sparsity. While it implies that these vertices are somehow involved in the network's activity or function, the exact nature remains unclear. The reviewer would need to infer the meaning from the context or external knowledge, making the action implicit and vague.", "grounding_specificity_rationale": "The reviewer is asking for a definition of 'active vertices' in the context of line 135. The original text does not explicitly identify the section or line number where this term is introduced. While the context suggests it's within the discussion of network properties, the specific part of the paper being addressed remains ambiguous. Therefore, the grounding is weak. The comment also does not specify what constitutes an 'active vertex' within this context, making the specificity underspecific.", "verifiability_rationale": "The original text does not contain a claim in the sense of an opinion or assertion. It presents a factual statement: 'Initially the network only has a few active vertices, due to sparsity.' There is X being made that requires verification or justification. Therefore, it falls under the 'X' category.", "helpfulness_rationale": "The reviewer's request for a definition of 'active vertices' is a direct attempt to improve the clarity and understandability of the text. While it doesn't provide a solution to the sparsity issue itself, it directly addresses a lack of clarity, which is a form of helpfulness. It empowers the authors to understand the text better by defining key terms."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out two main issues: the lack of acknowledgment of the theory's inapplicability to the model and the underestimation of GNNs' societal impact. While the reviewer doesn't explicitly state what the authors should do, they highlight specific areas where improvements are needed. For instance, the reviewer suggests adding a sentence in the limitations about the theory not being applicable to the model. This implies an actionable step for the authors. However, the reviewer doesn't provide a direct link or specific example, making it less explicit. Therefore, while the reviewer identifies actionable areas, the instructions are somewhat implicit.", "grounding_specificity_rationale": "The reviewer mentions 'the limitations' and 'potential negative societal impact of graph neural networks in general.' While they don't point to a specific section by number, the concept of 'limitations' is a standard section in academic papers, indicating some level of grounding. Furthermore, the reviewer provides a clear description of the societal impact they are concerned about, which specifies the area of concern within the paper. The phrase 'in general' also helps to ground the discussion to the broader field of GNNs.", "verifiability_rationale": "The reviewer makes a claim: 'The fact that their theory does not seem to be applicable to the used model, is not honestly mentioned in the limitations.' The reviewer then provides a reason for this claim: 'To the contrary, the vagueness of unspecified 'structural assumptions', that are only given in the appendix, makes this theoretical limitation hard to find.' This reasoning, while not a direct quote, provides a logical explanation for why the limitation might be missed. Therefore, the claim is supported by reasoning and common knowledge, making it '3'.", "helpfulness_rationale": "The reviewer raises two important points that, if addressed, could significantly improve the paper. First, acknowledging the limitations of the theory in the context of the model would provide a more honest and transparent view of the work. Second, discussing the potential societal impact of GNNs would add valuable context and consideration. While the reviewer doesn't provide explicit instructions on *how* to address these points, they clearly identify areas where the authors could improve their work. Therefore, the review point is 3 in highlighting important considerations for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point states a fact: 'Only projection head (CNN layers) are affected but not classification head (FCN layer).' This is a direct observation and does not specify an action or how to apply it.", "grounding_specificity_rationale": "The authors can accurately pinpoint the section, table, figure, or unique aspect being addressed through the explicit mention of 'projection head' and 'classification head', and the specific types of layers 'CNN layers' and 'FCN layer'.", "verifiability_rationale": "The claim 'Only projection head (CNN layers) are affected but not classification head (FCN layer)' is a direct observation of the model architecture and does not require external references or complex reasoning to understand.", "helpfulness_rationale": "The review point identifies a specific area for further analysis and experimentation (the impact of only using CNN layers), providing a clear direction for the authors to explore and potentially improve their model."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue with Figure 8: 'fig 8 shows images with different focusing distance, but it only shows 1m and 5m, which both exist in the training data.' This clearly indicates an actionable point for the authors to address the missing focusing distances. The reviewer also poses a question about generalization, which implies a desire to improve the draft by addressing this gap. The actions to take are clear: add examples of other focusing distances and explain the model's ability to generalize.", "grounding_specificity_rationale": "The reviewer refers to 'fig 8', which is a specific figure in the paper. This demonstrates a clear grounding of the comment in the visual element. Furthermore, the reviewer specifies the focusing distances (1m and 5m) and asks a question about 'other distances', indicating a high level of specificity to the issue within that figure and the training data.", "verifiability_rationale": "The reviewer raises a question about the generalization of the model's performance based on the limited focusing distances in Figure 8. However, the reviewer does not provide any evidence, reasoning, or external references to support this claim. The comment is a statement of concern without any justification or suggestion of how to address it. There is no logical reasoning, common knowledge, or external references provided to back up the claim about generalization.", "helpfulness_rationale": "The reviewer's comment identifies a relevant issue regarding the generalization of the model's performance based on the limited data in Figure 8. However, the reviewer does not offer any specific suggestions or evidence to address this issue. The comment is a statement of concern but lacks actionable feedback or guidance on how to improve the draft based on this observation. The authors are left wondering if the model's performance is limited by the lack of diverse focusing distances in the training data, but there is no concrete advice on how to mitigate this."}
{"actionability_label": "1", "grounding_specificity_label": "1: 2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point primarily questions the authors' terminology and conceptual framework rather than providing explicit instructions on how to improve their work. It asks about the implications of their nonsequential model and the meaning of 'style' in their context. While it points to a potential area for clarification, it doesn't offer concrete actions or modifications to the draft.", "grounding_specificity_rationale": "The reviewer raises a general question about the authors' definitions of content and style in the context of their neural application. While they relate this to specific concepts like 'movement dynamic,' they do not explicitly identify a specific part of the paper or a specific issue that needs addressing. The question is about the conceptual framing rather than pinpointing a problem or area of confusion within the existing content.", "verifiability_rationale": "The reviewer makes a claim about the authors' conceptualization of content and style and their interpretation of 'style' in the context of a nonsequential model. However, this claim is presented as a question and a suggestion for clarification rather than a statement supported by evidence or logical reasoning within the review point itself. There is no external reference or logical argument provided to verify the claim.", "helpfulness_rationale": "The review point is more of a clarifying question and a prompt for the authors to reconsider their conceptual framework rather than a direct suggestion for improvement. While it might lead to a better understanding of the authors' work, it doesn't directly provide actionable feedback on how to enhance the draft itself."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues with the paper's claims about direct quantization and the proposed method's lack of improvement. They also identify areas for improvement, such as providing a deeper explanation and comparing with other methods. This makes the comment actionable and concrete.", "grounding_specificity_rationale": "The reviewer refers to 'vit quantification' and specifically mentions 'Line 45', 'Fig1(b)', 'Fig5(b)', 'Block.3', 'transformer quantization', and 'QBERT', 'Q8BERT', 'BinaryBERT', 'FullyBinaryBert', etc. This demonstrates that the reviewer can accurately pinpoint the relevant parts of the paper and provide context by referencing related work, indicating strong grounding specificity.", "verifiability_rationale": "The reviewer provides numerical values from the figures to support their claims about the variance difference. They also reference existing literature on quantization loss in NLP, providing external evidence to back up their criticism. This demonstrates that the claim is wellsupported by logical reasoning, common knowledge, or external references, making it 5.", "helpfulness_rationale": "The reviewer's comment is highly informative and identifies significant weaknesses in the paper's claims and the proposed method. They provide evidence to support their criticisms and connect them to existing research. While they don't propose specific fixes, their feedback is valuable and constructive, making the comment 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the similarity of the proposed method to STNs and the lack of comparison. It also mentions existing works that use STNs locally, further emphasizing the similarity. The reviewer clearly identifies a weakness related to technical novelty. The actions to be taken are to understand the relationship between the proposed method and STNs and to include a comparison in the paper. The specificity of the action is to understand the relationship and the concreteness is to include a comparison.", "grounding_specificity_rationale": "The reviewer identifies the weakness related to STNs and local application, which can be inferred from the context of existing works. While they don't explicitly name a section or table, the focus on 'spatial transformer networks (STN)' and 'local application' provides a clear indication of the area being addressed. The specificity is in pointing out the similarity and the lack of comparison. The grounding is present, though not perfect, as the reviewer implies the relevant parts without explicitly naming them.", "verifiability_rationale": "The comment contains a claim that the technical novelty is limited due to the similarity to STNs and the lack of comparison. The reviewer provides some justification by mentioning existing works that use STNs locally. However, the claim about the missing comparison is not fully supported by new evidence or references within the review point itself. The verification methods are logical reasoning (mentioning existing works) and the implication that a comparison is needed. The claim is present, and some justification is provided, but it lacks explicit new references or a detailed explanation of the missing comparison.", "helpfulness_rationale": "The review point identifies a significant weakness in the related work section by highlighting the similarity to existing STN methods and the absence of a comparison. This is a valuable piece of feedback as it guides the authors to expand their literature review and address a crucial gap. However, the review point does not offer concrete steps on how to improve their method based on this feedback. The helpfulness is moderate as it points to a necessary improvement in the related work section but lacks direct actionable steps for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides a clear and explicit action: correcting the figure number from 'Fig.7' to 'Fig.12'. Furthermore, the reviewer suggests a concrete action for improving the paper's clarity by linking proofs to each theorem and corollary. The action is directly tied to the identified issue and provides a clear path for the authors to follow.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'each theorem and corollary appearing in the main paper' and suggests a specific action: linking their corresponding proofs. This clearly identifies the relevant parts of the paper and provides a concrete instruction for improvement. The grounding is strong because the reviewer doesn't leave room for interpretation regarding which theorems/corollaries are being referred to.", "verifiability_rationale": "The reviewer's claim is that 'Fig.7' should be 'Fig.12' and that each theorem/corollary should have its proof linked. While the claim itself is a factual error, the reviewer doesn't provide any external references or logical reasoning to support this specific figure number. However, the suggestion to link proofs is a clear and actionable improvement that enhances readability. The claim is 3 in the sense that linking proofs is a generally accepted practice that would benefit the reader, making the suggestion somewhat selfjustifying.", "helpfulness_rationale": "The reviewer's comment is directly pointing out a factual error ('Fig.7' should be 'Fig.12') and offering a constructive suggestion to improve the paper's clarity by linking proofs to each theorem and corollary. This is a clear and actionable feedback that directly addresses potential confusion for the reader. The reviewer's belief in the paper's quality and novelty makes the impact of this feedback even more significant."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point asks questions about the choices made in Section 3, specifically about the selection of classes and action verbs. While the reviewer points out a potential issue with the definition of 'action verbs' and 'action frames', they do not explicitly state what the authors should do next. The questions are more about seeking clarification and understanding rather than providing direct instructions for improvement. Therefore, the review point is 1 as it does not directly tell the authors what to do or how to apply the comment.", "grounding_specificity_rationale": "The review point explicitly refers to 'Section 3' and then 'Section 3.306ff', clearly identifying the specific part of the paper being addressed. The reviewer also asks specific questions about the content of these sections, such as 'Which 50 classes do you pick' and 'Are the verbs that you pick all explicitly tagged as action verbs by Levin?'. This clear identification of the section and the specific questions asked demonstrate that the reviewer is grounded in the paper and understands the context of the discussion. The reviewer is not making general comments about the paper but is focusing on a specific section. Therefore, the review point is 5.", "verifiability_rationale": "The review point is a question about the content of Section 3 and Section 3.306ff. It does not make a claim that needs to be verified or supported by evidence. The reviewer is not stating 'This is wrong' or 'This needs to be explained better' in a way that requires logical reasoning, common knowledge, or external references. The point is a direct inquiry about the existing content. Therefore, the review point is 1 as it does not contain a claim that needs justification.", "helpfulness_rationale": "The review point asks questions about the content of Section 3 and Section 3.306ff. While these questions are not inherently harmful, they do not directly provide actionable feedback on how to improve the draft. The reviewer is seeking clarification and understanding of specific choices, but they are not suggesting concrete improvements or pointing out actionable weaknesses. The feedback is more about seeking information than providing direct guidance. Therefore, the review point is 3 as it provides some insight into the author's process, but it lacks direct actionable feedback. It helps the authors understand the existing work better, which can be helpful in formulating improvements, but it doesn't directly tell them what to do."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the typo ('Empiically') and provides the correct spelling ('Empirically'). This is a concrete action that the author can directly implement by correcting the spelling. The reviewer also identifies the specific location (Ln 32 on Page 1), making the action very clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Ln 32 on Page 1', which is a very specific location within the paper. This demonstrates strong grounding as the author can easily identify the referenced part. The reviewer also clearly identifies the issue ('should be') within that specific part, providing clear specificity.", "verifiability_rationale": "This review point does not contain a claim. It is a factual correction suggesting a change. Therefore, the concept of verifiability does not apply as there is no statement requiring justification or support.", "helpfulness_rationale": "This is a very minor, specific, and direct piece of feedback. It directly addresses a clear error and empowers the author to fix it. While it's not a major restructuring, it's a valuable, albeit small, contribution to the author."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the proposed invariant learning module focuses on mask selection and rawlevel features, and criticizes the 'former framework' for not being limited to rawlevel selection. This is a clear statement of a difference and a critique, indicating an actionable point for the authors. The reviewer also suggests considering representation learning as an improvement, which is a concrete action the authors can take.", "grounding_specificity_rationale": "The reviewer refers to 'Section 4.2' when identifying the limitation of the proposed module, indicating some level of grounding. However, the specific aspect of 'rawlevel features' is not explicitly mentioned within the review point itself, requiring the authors to infer its relevance. The reviewer's suggestion to consider representation learning is broad and doesn't pinpoint a specific, actionable improvement within the context of the current work.", "verifiability_rationale": "The reviewer presents a claim about the 'former framework' not being limited to rawlevel selection. While the reviewer argues that considering representation learning is a valuable suggestion, they do not provide explicit logical reasoning, common knowledge, or external references to support this claim within the review point itself. The connection to representation learning is implied but not thoroughly explained or justified.", "helpfulness_rationale": "The reviewer provides a clear criticism of a specific aspect of the method and offers a concrete suggestion for improvement by considering representation learning. This directly addresses a potential weakness and provides a clear direction for the authors to follow, making the review point 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a gap in information (some details are missing) and specifically mentions the lack of understanding regarding 'how to design the rewards'. While it points out a problem, it doesn't provide a concrete action or instruction on how to address it. The action is implicit, requiring the authors to infer the missing information and potentially seek clarification or guidance on the reward design process.", "grounding_specificity_rationale": "The comment mentions 'how to design the rewards' generally, without specifying which section or part of the paper this relates to. The missing details are also vague ('not fully understandable'). The authors cannot confidently determine which part the comment addresses, making the grounding weak. While it mentions 'details,' it doesn't specify *which* details are missing.", "verifiability_rationale": "The comment states 'some details are missing' and 'how to design the rewards is not fully understandable'. This is a statement of a problem or area for improvement, not a claim that requires verification. There is no assertion or suggestion that anything is wrong specifically about the reward design process itself, beyond the lack of clarity. Therefore, it does not contain a claim that needs to be supported by evidence.", "helpfulness_rationale": "The review point identifies a valid issue \u2013 the lack of clarity regarding reward design and the missing details. This is helpful in pointing out an area for improvement in the authors' work. However, it doesn't provide a specific action or suggestion on how to address this issue. It highlights a problem but doesn't offer constructive improvement, making it 3 but not fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the importance of discussing runtime for MLbased emulators and directly asks the authors to calculate and discuss the runtime of Prithvi WxC. This is an explicit action that the authors can directly implement by adding a calculation or discussion of the model's runtime.", "grounding_specificity_rationale": "The review point explicitly mentions 'Prithvi WxC' and 'runtime' in the context of MLbased emulators of climate model parametrizations. This clearly grounds the comment in the specific model and aspect being discussed, making it easily identifiable.", "verifiability_rationale": "The review point presents a claim about the importance of discussing runtime for MLbased emulators and provides a suggestion (calculating and discussing the runtime of Prithvi WxC). While it doesn't provide external references, the claim is generally verifiable based on common knowledge about the benefits of computational efficiency in machine learning applications. The suggestion is a logical next step.", "helpfulness_rationale": "The review point directly addresses a common justification for using MLbased emulators (computational cheapness) and provides a clear direction for the authors to improve their manuscript by discussing the runtime of their model. This is a 5 and relevant suggestion for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment identifies the potential issue of overselling the method within the framing of the paper but does not provide explicit instructions on how to address this. It lacks concrete steps for the authors to take.", "grounding_specificity_rationale": "The comment refers to the 'framing' of the paper and the 'method' within it. While it points to specific elements, it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper. The connection between 'framing' and a specific part of the paper could be interpreted in multiple ways.", "verifiability_rationale": "The review point is more of an observation or suggestion for improvement rather than a definitive claim that requires verification. It proposes a potential issue but doesn't state it as a fact that needs justification.", "helpfulness_rationale": "The comment raises a valid concern about the paper's presentation and suggests a way to improve it. While it doesn't offer a direct solution, it prompts the authors to consider how they communicate their work, making it a valuable piece of feedback."}
{"actionability_label": "Low", "grounding_specificity_label": "High", "verifiability_label": "Low", "helpfulness_label": "Low", "actionability_rationale": "The reviewer points out a problem but does not explicitly state what the authors should do about it. The comment is more about identifying an issue than providing a clear action.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'difference between the paraphrases and the original sentences' as the specific area of concern, providing clear grounding of the issue.", "verifiability_rationale": "The reviewer raises a concern about the quality of the paraphrases but does not provide any evidence or justification for why they are unclear. The claim is made without sufficient support.", "helpfulness_rationale": "The reviewer describes a problem (unclear paraphrase difference) but does not offer any suggestions or actionable steps for the authors. The feedback is primarily diagnostic rather than prescriptive."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly suggests improving the paper by identifying areas for specific improvement related to rationales. This is a clear and actionable suggestion.", "grounding_specificity_rationale": "The reviewer identifies a problem with Figure 2 and the 'bold' text but does not specify the exact section, table, or unique aspect being addressed. This makes the suggestion somewhat vague.", "verifiability_rationale": "The reviewer makes a claim about the difficulty of identifying rationales but does not provide direct evidence or references to support this claim. The suggestions for improving Figure 2 are helpful but do not verify the claim about the NLP task.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement related to both the content (rationales) and the presentation (cluttered figure). This suggests the review is actionable and directly addresses potential issues."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a problem with the writing but lacks specific, actionable steps. While it states that the writing could be improved, it doesn't specify *how* or *what* needs to be changed. The vagueness makes it less actionable.", "grounding_specificity_rationale": "The reviewer mentions areas they struggled with ('the main idea' and 'the theoretical analysis'), but they don't pinpoint a specific section, table, figure, or unique element. The lack of explicit grounding makes it difficult to know exactly where the issues lie.", "verifiability_rationale": "The reviewer states that the writing 'could be improved,' which is a claim. However, they don't provide any specific evidence, examples, or references to support this claim. The lack of verifiable reasoning makes it difficult to understand the basis of their criticism.", "helpfulness_rationale": "The review point identifies a weakness the author is experiencing (difficulty understanding), which is helpful. However, because it lacks specific, actionable advice, it doesn't provide the authors with a clear path to improvement. It's more of a statement of need rather than a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that the proposed method 'primarily builds upon a combination of existing methods' and that it 'doesn't present significant theoretical novelty'. While the reviewer identifies the *what* (the methods), the *how* of the combination and the specific novel aspect are not explicitly stated. The reviewer implies an action (identifying a weakness and suggesting improvement), but the details are missing, making it implicit and vague.", "grounding_specificity_rationale": "The reviewer explicitly names the methods 'ClopperPearson intervals' and 'Gaussian elimination' by name. This clearly indicates that the reviewer can identify the specific parts of the paper being addressed (the methods), thus achieving 'full grounding'. The reviewer also specifies what is being done with these methods ( 'a combination of existing methods'), contributing to 'specificity'. While the level of detail regarding the *implementation* of the combination is missing, the reviewer's identification of the methods is explicit.", "verifiability_rationale": "The reviewer states, 'I am willing to improve my score, if the authors can well address these concerns.' This statement is a claim that the authors will address the concerns. However, the reviewer does not provide any evidence or reasoning to support this claim. The statement is a statement of intent, not a verifiable fact. The reasoning, common knowledge, or external references provided by the reviewer are insufficient to support the claim that the authors will address the concerns.", "helpfulness_rationale": "The reviewer states, 'The proposed method primarily builds upon a combination of existing methods (i.e., ClopperPearson intervals 1, Gaussian elimination 2) and it doesn't present significant theoretical novelty.' While the reviewer identifies a weakness in the proposed method, they do not offer any specific suggestions or actions for the authors to take to improve their draft. The reviewer's comment is a critique of the paper's contribution, not a suggestion for improvement. Therefore, the helpfulness is not high."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment implicitly points to a potential issue with text input but doesn't explicitly state the next steps the author should take. It suggests the problem might be related to concatenating text elements, but doesn't provide a clear action on how to address it.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper or code the author is referring to. It is also not specific about what is wrong with the concatenation.", "verifiability_rationale": "The comment does not contain a claim that needs verification. It is a statement about a potential issue rather than a proposition that requires logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The comment is helpful in identifying a potential issue with text input and concatenation, which is a common problem. However, it lacks specific guidance on how to resolve the issue, making it 3 but not fully constructive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the issue ('cumbersome and can be made clearer') within the abstract and provides an implicit action by suggesting clarification. While the action isn't stated as explicitly as it could be, it's clear that the reviewer intends for the authors to rewrite the sentence for better clarity. The phrasing 'After multispan reannotation, MultiSpanQA consists of over a total of 6,0000 multispan questions...' is vague and could be made more precise.", "grounding_specificity_rationale": "The review point explicitly refers to 'the abstract' and then specifically mentions the sentence in lines 1217. This demonstrates strong grounding as the section and the exact location of the issue are identified. The suggestion to 'clarify' is also quite specific.", "verifiability_rationale": "This review point does not contain a claim in the sense of an opinion or judgment about the paper's quality. Instead, it presents a factual observation about the writing style in the abstract and suggests an improvement. Therefore, it doesn't fit the 'Claim Extraction' criteria for verifiability. The 'X' label is appropriate here as there's X being made.", "helpfulness_rationale": "The review point is 5 because it directly identifies a potential issue the authors might face when reading the abstract (cumbersome phrasing) and provides a clear and actionable suggestion to clarify the sentence. This directly addresses a practical concern for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3: 2", "verifiability_label": "6: X", "helpfulness_label": "4", "actionability_rationale": "The review points out a discrepancy in the experimental setup (Pix3D training and testing) and compares it to zeroshot methods. This doesn't directly tell the authors *what to do*. It highlights a potential flaw in their evaluation.", "grounding_specificity_rationale": "The reviewer mentions \"Pix3D training and testing\" and \"zeroshot singleimage 3D reconstruction models.\" While they identify the *parts* of the experiment being discussed, the *specificity* of the *issue* isn't clearly defined. Is the issue the unfair comparison, the lack of domain adaptation, or something else? The grounding is present, but the specificity of the *problem* is vague.", "verifiability_rationale": "The reviewer states a fact: \"The domainspecific model is trained on Pix3D. And the experiments are conducted on Pix3D.\" This is a factual statement. There's X being made, just a description of the experimental setup.", "helpfulness_rationale": "The reviewer points out a potential flaw in the experimental setup. While relevant, it doesn't directly provide a solution or actionable advice to the authors. It's a critique of the methodology."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "Partially Verifiable", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states 'relying on 4 OCR QA datasets' and 'More scenarios like the LLaVA benchmark would be expected.' These are direct statements of a limitation. While the reviewer doesn't suggest a specific action to improve the evaluation, they clearly identify a gap in the evaluation methodology.", "grounding_specificity_rationale": "The reviewer mentions '4 OCR QA datasets' and 'LLaVA benchmark' in their review. While they identify the *type* of datasets being criticized, they do not explicitly state which specific part of the paper's evaluation this relates to (e.g., 'the OCR accuracy analysis' or 'the generalization to new scenarios'). Furthermore, while they mention the limitations of relying on OCR datasets and the potential benefits of LLaVA, they don't specify *what* aspects of the evaluation are limited by this choice. Therefore, the grounding is weak, and the specificity is also weak.", "verifiability_rationale": "The reviewer states that the evaluation is 'limited, mostly relying on 4 OCR QA datasets' and 'As the authors admit in Fig 4(5), this evaluation may be unreliable.' This constitutes a claim about the evaluation methodology. The reviewer *admits* in Fig 4(5) that this evaluation may be unreliable, providing some justification for their criticism. However, they do not provide specific evidence or references within the paper to support their claim about the limitations of the OCR datasets or the potential benefits of LLaVA. Therefore, the verifiability is partially supported by the general admission of unreliability, but lacks specific evidence.", "helpfulness_rationale": "The reviewer's comment primarily focuses on criticizing the evaluation methodology, specifically mentioning the reliance on OCR datasets and the absence of LLaVAlike scenarios. While they offer a general suggestion ('More scenarios like the LLaVA benchmark would be expected'), this is a suggestion for improvement rather than a direct, actionable recommendation for the authors based on the current draft. The reviewer does not explicitly recommend specific changes or improvements to the authors' work based on the identified limitations. Therefore, the helpfulness is limited to pointing out a problem without offering concrete solutions for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two specific suggestions: (1) to change the notation for pi and (2) to address the dimension mismatch in equation (2) by assuming the first column of X_t is always 0. Both suggestions are direct and point to specific areas for improvement in the paper. The reviewer explicitly states what should be changed and why the current formulation might be problematic. This makes the suggestions actionable for the authors.", "grounding_specificity_rationale": "The reviewer explicitly points to equation (2) as the part of the paper being addressed. They state, 'In (2) you have X pi(X), but the dimensions do not match because you dropped the noop action.' This clearly indicates that the reviewer can identify the specific section and the issue within that section. Furthermore, they suggest a solution by assuming the first column of X_t is always 0, which is a concrete action the authors can take. The grounding is strong because the reviewer not only identifies the location but also explains the problem and proposes a fix.", "verifiability_rationale": "The reviewer makes a claim: 'In (2) you have X pi(X), but the dimensions do not match because you dropped the noop action.' This is a statement that needs to be verified. The reviewer provides a reason for the dimension mismatch, explaining that dropping the noop action leads to a mismatch between X and pi(X). While they don't provide external references, the reasoning is logical and points to a potential implementation detail. The reviewer's suggestion to assume the first column of X_t is always 0 is a potential solution that can be verified by the authors. Therefore, the claim is verifiable based on logical reasoning and a suggested solution.", "helpfulness_rationale": "The reviewer provides specific suggestions for improving the notation and addressing a potential implementation issue in equation (2). The suggestion to change the notation for pi is likely to be helpful for clarity. The suggestion to assume the first column of X_t is always 0 is a practical step to resolve the dimension mismatch. These suggestions are concrete and directly address a potential problem, making the review point 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies the *area of concern* as 'abstract visual reasoning tasks' and points out the *issues* they have with them, such as being 'intuitively confusing' and 'overly difficult'. While the reviewer doesn't explicitly state an *action* like 'improve the clarity of these tasks', the identification of the *area* and the *type* of issues can be considered a form of implicit action. The reviewer is essentially signaling that this area needs attention. However, the lack of specific details on *how* to improve makes it less actionable.", "grounding_specificity_rationale": "The reviewer mentions 'abstract visual reasoning tasks' as the part of the paper they are referring to. While they don't provide a specific section or table number, the mention of this *type* of task can be considered a form of weak grounding. The reviewer also mentions the *nature* of these tasks (being 'intuitively confusing' and 'overly difficult'), which provides some level of specificity about the issue. However, the lack of a precise reference point makes the grounding less strong.", "verifiability_rationale": "The reviewer states a *claim* that there is a lack of *proof* for the current formulation of abstract visual reasoning tasks and suggests exploring *simpler tasks* as a potential solution. However, the reviewer does not provide any *evidence* or *justification* for this claim. They simply state the problem without offering any logical reasoning, common knowledge, or external references to support their assertion. This makes the claim 1.", "helpfulness_rationale": "The reviewer explicitly states they have *problems* with the abstract visual reasoning tasks and express a lack of *proof*. This indicates a desire for improvement and suggests the review point is somewhat *helpful* in identifying an issue. However, the lack of concrete suggestions or a clear focus on a specific problem makes the helpfulness somewhat limited. The reviewer's expression of a lack of *proof* also contributes to a lower helpfulness score."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential weakness ('lack of') but doesn't explicitly state what needs to be added or how to implement the change. The criticism is about the absence of something rather than a specific action to take.", "grounding_specificity_rationale": "The reviewer mentions 'intermediate processes' and 'comparisons' generally, without specifying *which* processes or *what kind* of comparisons. This suggests weak grounding as the authors cannot confidently determine the referenced part. The specificity is also underspecific as it describes the *absence* of visualization rather than specific details within existing visualizations.", "verifiability_rationale": "The review points to a *lack* of something without offering a specific alternative visualization method or a concrete way to improve comparisons. The evidence is about the absence of something, not a claim about what should be there and how to achieve it. Therefore, it's not verifiable.", "helpfulness_rationale": "The review identifies a potential area for improvement (visualization) but doesn't offer concrete suggestions or actionable steps for the authors. It highlights a problem but doesn't provide guidance on how to address it, making it less helpful in guiding improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the action of including keypoint detection results in the experiments section and provides a clear instruction on where to place them. This makes the action very concrete and directly actionable for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions the 'experiments section' where the keypoint detection results should be included. This provides a clear and specific location, making the grounding fully grounded.", "verifiability_rationale": "The review point is a suggestion to improve the presentation of results by including keypoint detection results in the experiments section. While it doesn't introduce a new verifiable fact, it points to a logical next step for ensuring claims are supported by evidence, making it 3.", "helpfulness_rationale": "The review point directly addresses a valid need for authors to present their results clearly and ensure claims are supported by evidence. By suggesting the inclusion of keypoint detection results in the experiments section, the reviewer provides a practical and helpful guideline."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about a potential issue (grid search on the validation set) but doesn't explicitly state what needs to be done. While it points to an action (checking), the lack of a clear instruction makes it 2.", "grounding_specificity_rationale": "The review point explicitly asks 'is it done on the validation set?' which directly identifies the specific aspect of the grid search being questioned. This constitutes full grounding. It also specifies the location (validation set), making the issue very specific.", "verifiability_rationale": "The review point does not contain a claim or assertion. It is a question posed about a potential issue. Therefore, it fits the 'X' category, indicating no verifiability as there's no statement to verify.", "helpfulness_rationale": "The review point identifies a potential minor problem (grid search on the validation set) but does not offer any suggestions or guidance on how to address it. It simply asks a question, which is a form of identification but not a constructive suggestion, making it 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about a specific aspect of the data (racial/economic diversity) and its implications for generalizability. While the action of analyzing this diversity isn't directly stated, the request is clear about identifying a missing element. The reviewer doesn't provide a concrete action, making it less explicit than other aspects. The request is clear about the desired outcome (improving generalizability), but the method isn't specified, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'L393,' indicating they are pointing to a specific location in the text. This provides strong grounding. The comment also asks a specific question about a particular aspect of the data at that location (generalizability of results), further specifying the issue being addressed.", "verifiability_rationale": "The reviewer states a question about the generalizability of the results, which can be considered a claim. However, within the review point itself, there is no evidence or reasoning provided to support this claim. The reviewer is stating an observation or area for further investigation but doesn't offer any specific examples, references, or logical arguments within the review point itself.", "helpfulness_rationale": "The reviewer raises a very specific and relevant question about a potential limitation of the study \u2013 the lack of consideration for racial and economic diversity and its impact on the generalizability of the results. This directly points to a potential weakness and suggests a concrete direction for improvement. While the exact method of analysis isn't specified, the question itself is 5 and directly addresses a potential area for enhancement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a direction for improvement (higher output quality) but doesn't specify how to achieve it. The phrase \"there\u2019s still much room for improvement\" is a general statement, not a concrete action the authors should take. The suggestion is implicit, and the level of \"room for improvement\" is vague. Therefore, it's not actionable.", "grounding_specificity_rationale": "The review point refers to \"Recent GAN works\" and \"amazing quality in synthesized results\" in a general way. It doesn't pinpoint a specific section, table, figure, or unique aspect of the paper being criticized. The reference to \"output quality\" is also quite broad. Therefore, it's 1.", "verifiability_rationale": "The review point makes a claim about the \"output quality\" being \"reasonable, but still far from realistic\" and attributes this to the advancements in GANs. This is a claim that *can* be verified (by comparing the paper's output to stateoftheart GAN results). However, the *justification* is vague, stating \"Recent GAN works have shown amazing quality\" without specific examples or references. Therefore, it's partially verifiable.", "helpfulness_rationale": "The review point identifies a valid concern (output quality) but, like the actionability aspect, doesn't offer specific, actionable suggestions. The reviewer sets expectations for future work but doesn't provide concrete steps the authors *should* take to improve the output. Therefore, it's not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests adding evaluation for unseen words and recommends including translations. While this points towards an action, the explicitness of the action is not fully clear. The reviewer implies the addition of evaluation but doesn't explicitly state it as an action. The recommendation to include translations is also implied but not explicitly stated as an action to be taken. Therefore, while the reviewer points towards an improvement, the explicitness of the action is not fully clear.", "grounding_specificity_rationale": "The reviewer mentions 'unseen characters' and 'unseen words' and refers to 'Figure 6' and 'translations'. This indicates a clear identification of the specific part of the paper being addressed. The reviewer also implies the addition of evaluation as a goal, which is a specific direction for improvement. While the reviewer doesn't explicitly state 'add evaluation for unseen characters' as an action, the grounding is present as they identify the area and the type of improvement. The specificity is also present as they mention 'unseen characters' and 'translations'.", "verifiability_rationale": "The reviewer states a preference for adding evaluation for unseen words and suggests including translations. This is a suggestion, which can be considered a claim, but it lacks supporting evidence or justification. The reviewer does not provide any logical reasoning, common knowledge, or external references to support their suggestion. The suggestion itself is a claim that requires verification. The lack of justification makes it difficult to assess the validity of the claim.", "helpfulness_rationale": "The reviewer suggests adding evaluation for unseen words and recommends including translations. While this is a relevant suggestion for improving the handling of unseen characters, the review does not explain why this is a necessary or beneficial improvement for the reader. The reviewer does not provide any context or explanation of the impact of this suggestion. The suggestion is presented without any elaboration on its importance or how it would be implemented. Therefore, the helpfulness of the suggestion is limited."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential issue with the practical applicability of the proposed methods in highdimensional settings. While the reviewer doesn't explicitly state the exact steps the authors should take, they highlight a specific technical challenge: solving several LPs in high dimensions, where a crucial parameter is not easily calculable. This suggests an implicit action, but it lacks the concrete details needed for immediate implementation.", "grounding_specificity_rationale": "The reviewer mentions 'high dimensions' and a 'parameter that is not easily calculable' in the context of LPs. This indicates some grounding as the reviewer identifies a specific area and a specific challenge. However, the reviewer does not explicitly state which section, table, or unique aspect of the paper they are referring to, making the grounding somewhat weak. The specificity is present in the technical detail about the parameter, but the connection to a specific part of the paper is missing.", "verifiability_rationale": "The reviewer states that their algorithm requires solving several LPs in high dimensions, each involving a parameter that is not easily calculable. This statement itself can be considered a claim that needs verification. However, the reviewer does not provide any justification or references to support this claim. The reasoning is implied but lacks explicit support, making it 3.", "helpfulness_rationale": "The reviewer's point about the difficulty of calculating a parameter in high dimensions for practical applications is a significant concern for the authors. This directly highlights a gap between the theoretical framework and its practical implementation. While the reviewer doesn't offer specific solutions, they clearly identify a problem that needs addressing, making this a 5 comment for guiding the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The reviewer points out that the work uses an 'antiquated GNN model and method' and that 'the baseline algorithms/methods are also antiquated.' While this is a valid observation, the reviewer does not explicitly state what specific changes or improvements should be made. The criticism is general and lacks concrete suggestions. Therefore, the action is identified but not explicitly stated, making it 3 but lacking detail on how to apply it.", "grounding_specificity_rationale": "The reviewer refers to 'this framework' and 'baseline algorithms/methods' without specifying a particular section or table. This makes the grounding weak. However, the reviewer does mention the 'impact on performance,' which provides some clarity about the issue being addressed. The criticism is general and points to a broader problem rather than a specific element within the paper.", "verifiability_rationale": "The reviewer makes a claim stating that 'this work uses an antiquated GNN model and method' and that 'the baseline algorithms/methods are also antiquated.' However, the reviewer does not provide any evidence or justification to support these claims. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the models and methods are 'antiquated'.", "helpfulness_rationale": "The reviewer's comment is critical, pointing out the use of an 'antiquated GNN model and method' and the 'antiquated baseline algorithms/methods.' However, the reviewer does not offer any specific suggestions or propose alternative approaches. The comment is more of a critique than a constructive suggestion for improvement. The reviewer identifies a problem but doesn't provide a clear path forward for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the limitations of the experiment and suggests improvements. However, the specific actions or changes needed are not clearly defined. The reviewer points out that the difference between methods is only the number of perturbations, which is a vague way to suggest improvement. While the intent is clear, the lack of concrete steps makes the action implicit and somewhat vague.", "grounding_specificity_rationale": "The review point refers to 'an experiment' and 'pseudo feature importance' generally, without pinpointing a specific section, table, or unique aspect of the paper. While the reviewer mentions 'Prop 3.2' and 'large enough perturbation value,' these are described in a general way, and the specific part of the paper being addressed is not explicitly identified. The grounding is weak because the reviewer cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point makes claims about the limitations of the experiment and the need for stronger experiments. It also points out the lack of clarity in the difference between methods. The reviewer provides some implicit justification by mentioning 'Prop 3.2' and 'large enough perturbation value,' but these are not explained in detail, and there are no concrete examples provided to support the claims. The verifiability is partially met as there are elements of justification, but they are insufficient to fully support the claims.", "helpfulness_rationale": "The review point identifies weaknesses in the experiment and suggests improvements. It is generally helpful as it points out areas for enhancement. However, the suggestions are somewhat vague, and the specific improvements are not clearly articulated. The lack of concrete details makes it less helpful in providing a clear path for the authors to follow."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point is 1 because it describes the desired outcome (more comprehensive analysis) but does not specify the actions the authors should take to achieve it. The phrase 'much more comprehensive and dataintensive analysis' is general and lacks concrete steps.", "grounding_specificity_rationale": "The review point is 1 because it does not specify which part of the paper is being referred to. The comment is too general and does not point to a specific section, table, or figure.", "verifiability_rationale": "The review point is 1 because it makes a suggestion ('a much more comprehensive and dataintensive analysis') without providing specific evidence, examples, or references to support this claim.", "helpfulness_rationale": "The review point is 2 because it identifies a potential area for improvement (more comprehensive analysis) but lacks specificity and concrete guidance on how to achieve this."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the missing justification for excluding online learning and RL from the evaluation. They identify the specific issues: retraining costs, the lack of comparison, and the challenges of including them. This directly points out a gap in the paper's explanation of their methodological choices, making it actionable for the authors to understand the limitations of their current evaluation.", "grounding_specificity_rationale": "The reviewer provides specific examples of what is missing (retraining costs, comparison, challenges) and the type of comparison (evaluation results). They also point to the *section* where these comparisons are typically made (evaluation results). This indicates a clear understanding of the specific part of the paper being addressed, making it grounded. The comment specifies what needs to be addressed in this part (the exclusion criteria and the reasons behind it).", "verifiability_rationale": "The reviewer claims that the paper does not explain why online learning and RL are excluded. While they don't provide *external* references to support *why* these are important considerations, they offer logical reasoning within the context of the paper's limitations. They explain *what* is missing and *why* it's a problem, suggesting that the paper lacks a clear justification for its methodological choices.", "helpfulness_rationale": "The reviewer identifies a clear weakness in the paper: the lack of justification for excluding online learning and RL. By pointing out the specific issues (retraining costs, lack of comparison, challenges), they provide the authors with concrete feedback on areas for improvement. While the reviewer doesn't explicitly recommend specific changes, they highlight a gap in the paper's explanation of their methodological choices, which is directly helpful for the authors to understand the limitations of their current evaluation and potentially expand their analysis. The reviewer provides specific examples of what is missing, making the feedback actionable."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests actions to be taken by the authors, such as citing missing works and linking existing citations to the current work. The phrase 'as it seems to directly follow as an application to continual learning' provides a clear direction for the authors to take. The suggestions are direct and actionable.", "grounding_specificity_rationale": "The reviewer mentions 'metalearning' and 'works don't target continual learning directly' and 'RL for architecture search' as areas where the authors should act. While these are relevant areas, the reviewer does not explicitly state which specific paper or section within a paper is missing. The implications are clear, but the exact location of the gap is not pinpointed.", "verifiability_rationale": "The reviewer provides suggestions for the authors to improve their work, such as exploring metalearning and linking RL for architecture search. While the suggestions are generally verifiable, the reviewer does not provide specific examples or references to support these suggestions. The reasoning is present, but the level of detail and justification could be improved.", "helpfulness_rationale": "The review point provides clear and actionable suggestions for the authors. It tells them what to do, such as cite missing works and link existing citations. The suggestions are directly related to improving the draft and are easy to understand and implement. The reviewer also provides a clear motivation for these suggestions by highlighting the potential connection to metalearning and RL for architecture search."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "X", "actionability_rationale": "The review point is a question about the *process* of feedback and whether the reviewer intends to *turk* or *generate* feedback. It doesn't explicitly state what the author should do or what changes are needed. While it raises a valid point about the diversity of feedback, it doesn't directly translate to actionable steps for the author in terms of improving their paper. It's a question about the *method* of feedback, not suggestions for edits.", "grounding_specificity_rationale": "The review point is a general question about the feedback process and doesn't specify which part of the paper or element of the feedback it's referring to. It doesn't identify a specific section, table, figure, or unique aspect of the paper being addressed. The comment is about the *process* itself.", "verifiability_rationale": "The review point is a question about the *process* of feedback and doesn't make a claim that needs to be verified. It's a question about whether the feedback should be diverse and whether the reviewer plans to take specific steps. It doesn't contain a statement that requires logical reasoning, common knowledge, or external references to be considered verifiable.", "helpfulness_rationale": "While the review point raises a valid concern about the diversity of feedback, it doesn't directly provide the author with concrete feedback on how to improve their work. It's a question about the *review process* itself, not a suggestion for specific changes to the paper. It doesn't fall into any of the helpfulness categories (14) as it doesn't directly address the content of the paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests comparing the performance with two specific papers, which is a direct action for the authors to take. The phrase \"compare the performance with\" clearly indicates a concrete action to be performed.", "grounding_specificity_rationale": "The review point mentions specific papers ('Multilingual unsupervised neural machine translation with denoising adapters' and 'MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer') which allows the authors to identify the specific work being referenced. However, the reason for suggesting this comparison is not explicitly stated in the review point. The reviewer simply recommends the comparison without providing a detailed justification for why these specific papers are relevant.", "verifiability_rationale": "The review point makes a recommendation to compare performance with specific papers. This can be considered a claim that these papers are relevant. While the papers are specific, the reviewer does not provide explicit justification or references to support this claim within the review point itself. The implicit assumption is that these are wellknown or highly relevant papers in the field, but this is not explicitly stated.", "helpfulness_rationale": "The review point provides a clear recommendation to compare the performance with specific papers. This is a valuable suggestion that can help the authors improve their work by benchmarking against existing solutions. The action is explicit and directly addresses a potential area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out specific limitations of the approach ( needing a specific model, episodic setting, delayed reward) but doesn't explicitly state how the authors should address these limitations. While the implications are clear, the direct action isn't stated. The reviewer's question about extending the approach is a valid suggestion, but the current point doesn't provide actionable steps to achieve that.", "grounding_specificity_rationale": "The reviewer explicitly mentions aspects of the current approach that need to be addressed (model dependency, episodic setting, delayed reward). This demonstrates some level of grounding as the authors can identify these specific parts. However, the reviewer's questions are about broadening the scope rather than making specific changes within the current framework, making the grounding somewhat underspecific.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the current approach regarding generality. They provide a rationale based on the specific characteristics of the approach (model dependency, episodic setting, delayed reward). However, they don't provide external references or detailed explanations to fully verify their claim within the review point itself.", "helpfulness_rationale": "The reviewer's question about extending the approach is relevant and could be helpful for future work. However, the review point itself is a question rather than a direct suggestion with concrete implications. The helpfulness is limited because it's a question about future directions rather than a direct critique or suggestion for improvement within the current work."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer is asking for clarification on a specific detail (the feature extractor) but does not explicitly state how to apply this information or what action the authors should take next. While the information is likely relevant, the request itself is not an actionable step for the authors.", "grounding_specificity_rationale": "The reviewer explicitly asks 'using which feature extractor?' which directly points to a specific part of the paper where this information would be found. They can identify the section, table, or figure where this information is likely located.", "verifiability_rationale": "The reviewer is asking a question, which is a form of claim (i.e., stating that the information is missing). This claim is supported by the fact that the information is indeed missing from the paper. The reasoning is that the authors should look for the feature extractor information in the implementation or method section.", "helpfulness_rationale": "The question is directly relevant to the authors and likely to be helpful. By knowing which feature extractor was used, the authors can better understand the dimensionality reduction process and potentially replicate or build upon this work. While it's not a direct improvement suggestion, it's a question that, when answered, can significantly improve their understanding."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The motivation is implied (understanding the reasoning for using CMD), but the action to achieve this (e.g., a specific demonstration or explanation) is not explicitly stated.", "grounding_specificity_rationale": "The comment refers to \"CMD in federated learning\" generally without pinpointing a specific part of the paper.", "verifiability_rationale": "The review is a statement of observation, not a claim requiring verification.", "helpfulness_rationale": "The review identifies a valid weakness in the presentation (unclear motivation) but doesn't offer a concrete solution, making it 3 as it highlights an area for improvement."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Partially Grounded and Not Specific", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for 'analysis' of the data augmentation methods and a 'comparison' to other paraphrasing techniques. This indicates a clear intention to improve the paper. However, the reviewer does not specify *what* kind of analysis or *how* the comparison should be done, making the action implicit rather than explicit. The reviewer also does not provide concrete steps or examples of what constitutes 'actionable' feedback.", "grounding_specificity_rationale": "The reviewer mentions 'data augmentation methods' and specifically names 'EDA or LLMbased paraphrasing' as examples. This demonstrates a reasonable level of grounding as the reviewer refers to specific categories of techniques. However, the reviewer does not specify *which* exact methods within these categories should be analyzed or compared. The specificity is lacking in terms of concrete examples and procedures.", "verifiability_rationale": "The reviewer makes a claim that there is a 'lack of analysis' and a 'lack of comparison'. This is a claim that needs to be supported. The reviewer provides *some* justification by stating what *should* be done (analysis and comparison). However, the reviewer does not provide explicit references to external works, logical reasoning, or concrete examples to support this claim. The evidence for the lack of analysis and comparison is inferred rather than explicitly stated and justified.", "helpfulness_rationale": "The reviewer clearly identifies a need for improvement in the analysis and comparison of data augmentation methods. This feedback is relevant and addresses a specific aspect of the paper. However, the lack of specificity makes it difficult for the authors to act on this feedback. They don't know what analysis to perform or how to compare the methods. Therefore, while the feedback is valuable, its actionability is limited."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The action is explicitly stated: 'assign all negative samples to a distractor class'. This is a clear and direct instruction on what the reviewer suggests the authors do. The action is also concrete, as the authors know exactly how to implement this suggestion. Therefore, the review point is 5.", "grounding_specificity_rationale": "The reviewer does not explicitly mention a specific part of the paper (e.g., a section, table, or figure) when suggesting the baseline experiment. While the suggestion is specific in terms of the type of experiment, it doesn't ground the *experiment* within the paper's content. Therefore, the review point is 1 in a specific area of the paper.", "verifiability_rationale": "The review point does not contain a claim. It's a question about the performance of a baseline experiment, not a statement that requires verification. Therefore, the review point does not have verifiability.", "helpfulness_rationale": "The review point identifies a potential weakness by suggesting a baseline experiment that could reveal issues with the model's negative sampling strategy. While it doesn't directly tell the authors how to improve their draft, it provides a diagnostic tool that could be helpful for the authors to understand their model's limitations. Therefore, the review point is 3 in identifying a potential issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'lacks specific measurements or comparisons' as the weakness, which is an explicit and concrete action the reviewer is pointing out is missing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'quantitative analysis' and provides examples of what constitutes this analysis (GPU hours, memory usage, training time), indicating a strong grounding in the specific type of analysis needed. The reviewer also states 'lacks specific measurements or comparisons' which clearly identifies the missing information. The reviewer accurately pinpoints the type of data and metrics that would be required.", "verifiability_rationale": "The reviewer makes a clear claim that the paper 'lacks specific measurements or comparisons' regarding computational gains. While the paper itself isn't being evaluated for whether it *does* have these measurements, the reviewer's description of the paper's current state provides the basis for *how* this claim could be verified. The reviewer suggests specific metrics (GPU hours, memory usage, training time) that would serve as evidence. Therefore, the claim is verifiable based on the reviewer's description of the paper's current state.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'A quantitative analysis\u2014such as GPU hours, memory usage, or training time\u2014would provide stronger evidence of the efficiency improvements.' This directly addresses the identified weakness and offers a concrete way to improve the paper. The suggestion is specific and directly related to the problem."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of discussion and analysis regarding the 'filter manifold network' (FMN), which is a specific part of the technique. While the reviewer doesn't explicitly state what action they expect the authors to take, they imply that the authors should have included a more detailed discussion of the FMN and explored its properties. The action is implied rather than explicitly stated, making it 3 but not fully so.", "grounding_specificity_rationale": "The reviewer asks specific questions about the FMN, such as whether the authors experimented with other architectures and how the adaptive convolutions scale with the number of filter parameters. These questions directly target specific aspects of the FMN, indicating strong grounding. The reviewer is not just saying 'there's a lot of analysis needed,' but rather asking very specific questions about the methodology.", "verifiability_rationale": "The reviewer makes a claim that 'there is almost no discussion or analysis on the 'filter manifold network' (FMN)' and asks 'how does the adaptive convolutions scale with the number of filter parameters?'. This constitutes a claim that needs verification. The reviewer provides logical reasoning by asking specific questions about the scaling behavior, which can be used to support or refute the claim. The claim is verifiable through further investigation and analysis.", "helpfulness_rationale": "The review provides feedback on a specific aspect of the technique (FMN) and suggests improvements. While the feedback is valuable, it primarily asks for more information and analysis rather than directly suggesting a concrete, actionable change to the authors' work. The helpfulness is moderate as it points out a weakness and suggests improvements, but it's more of a request for more information than a direct solution."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the question: 'It is impossible to guess what brings the claimed performance boost  the fractional transform or the UNet operation in the fractional Fourier domain?'. This directly identifies a lack of clarity regarding the contribution of different components. The reviewer also suggests a concrete experiment: 'At least comparisons to UNets are therefore inevitable.' This indicates an action the authors can take to investigate the issue. The suggestion to compare against UNets is a specific action that can help clarify the contribution of the UNet part.", "grounding_specificity_rationale": "The review point explicitly identifies the 'UNet part after the fractional transform' as the source of ambiguity. It also suggests a 'specific alternative architecture (standard UNets)' as a way to investigate this. The reviewer clearly pinpoints a specific component of the model and proposes a specific alternative. This demonstrates strong grounding specificity.", "verifiability_rationale": "The review point proposes a specific experiment: 'comparing to UNets' to verify the claim about the source of performance boost. This provides a clear method for investigation. The reviewer also suggests 'UNets might perform worse on a regular grid', which is a specific prediction that can be tested. This provides logical reasoning and a specific suggestion for verification.", "helpfulness_rationale": "The review point directly addresses a potential ambiguity in the model's design by questioning the contribution of the UNet part. It suggests a concrete experiment (comparing against standard UNets) to investigate this. This is a valuable piece of feedback as it directly addresses a potential point of confusion for the authors and provides a clear path for them to further investigate their model. The suggestion to compare against a standard baseline is particularly helpful as it provides a point of comparison to understand the specific benefits of the proposed architecture."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states they don't understand the sentence and suggests rewriting it, indicating a need for a specific action.", "grounding_specificity_rationale": "The reviewer mentions specific locations in the paper (P. 5, p. 3, l.), indicating they are pointing to a specific part of the text.", "verifiability_rationale": "The reviewer states they don't understand the meaning of the sentence, which is a statement of confusion, not a claim requiring verification.", "helpfulness_rationale": "The reviewer clearly states their lack of understanding and offers a concrete action (rewriting) to address it, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point directly asks a question about a specific aspect of the methodology (handling entity disambiguation for DocRED) and points out that this information is missing from the manuscript. This clearly identifies an actionable area for the authors to improve their manuscript.", "grounding_specificity_rationale": "The review point explicitly mentions \"DocRED\" and \"entire sentence\" and the specific problem of \"multiple entity mentions referring to the same entity.\" This demonstrates a clear understanding of the paper's context and the specific issue being raised.", "verifiability_rationale": "The reviewer states that \"this information is currently missing from the manuscript.\" This is a claim that needs to be supported. While the reviewer claims the information is missing, they haven't provided any justification or examples within the review point itself to back this claim up. The verifiability relies on the authors potentially addressing this in a later version.", "helpfulness_rationale": "The review point effectively highlights a missing piece of information that the authors need to address to improve their manuscript. It directly points to a specific area where clarification is needed. While it doesn't teach the authors how to handle the issue, it identifies a clear gap in the current information."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states their opinion directly: 'The contribution looks marginal to me'. This indicates an explicit action or suggestion that the contribution is not significant. While the reviewer also provides a reason ('all the methods used in different stage are well designed and demonstrated'), this is presented as a critique of the overall contribution rather than a specific, actionable point. The reviewer implies that the combination of these methods doesn't constitute a major contribution.", "grounding_specificity_rationale": "The reviewer's comment is a general criticism of the paper's contribution without specifying which part of the paper or method is lacking. They state 'The contribution looks marginal to me' without pointing to a specific section, table, figure, or unique aspect of the work. This lack of specificity means the reviewer cannot confidently identify the issue, making the grounding weak.", "verifiability_rationale": "The reviewer makes a claim: 'The contribution looks marginal to me'. This claim is not supported by any specific evidence, examples, or references. While they provide a reason ('all the methods used in different stage are well designed and demonstrated'), this is a subjective assessment of the overall contribution and lacks logical reasoning or external references to validate the claim. The statement is presented as a personal opinion rather than a justified assertion.", "helpfulness_rationale": "The reviewer's comment is a negative assessment of the paper's contribution without offering any specific suggestions or improvements. They state 'The contribution looks marginal to me' and then provide a general reason ('all the methods used in different stage are well designed and demonstrated'). This criticism is a statement of opinion rather than a constructive suggestion. Since there are no concrete recommendations for improvement, the review point is not helpful for guiding the authors on how to enhance their work."}
{"actionability_label": "2 (2)", "grounding_specificity_label": "5 (5)", "verifiability_label": "3 (3)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer states a fact (''2 gives a tester for the spread parameter...') but doesn't explicitly say what the implication is or how it relates to an (\u03f5, \u03b4)identity tester. The connection is implied but not clearly stated. The reviewer also raises a specific concern about the (\u03c0, \u03d5) pairs, indicating a lack of clarity on the practical application and implications of the mentioned tester.", "grounding_specificity_rationale": "The review point explicitly refers to 'review point 2' and mentions 'a tester for the spread parameter', providing a clear reference to a specific part of the paper. The reviewer then asks a question directly related to the implications of this referenced content for (\u03f5, \u03b4)identity testers.", "verifiability_rationale": "The reviewer states a fact (''2 gives a tester for the spread parameter...') and poses a specific question (''For e.g., how is it dealing with...'), implying that the referenced content should be applicable. However, the reviewer does not provide any evidence or justification to support this claim.", "helpfulness_rationale": "The reviewer points out a potential gap in the connection between a specific testing procedure and its broader implications for a different type of testing. They are essentially suggesting that the paper could have been clearer about how the mentioned tester relates to (\u03f5, \u03b4)identity testing."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete change to be made. It identifies a problem (unclear distribution) but doesn't provide any guidance on how to address it.", "grounding_specificity_rationale": "The review point mentions 'the detailed distribution of the proposed dataset,' which points to a specific aspect of the paper. However, it does not explicitly identify the section, table, or unique element of the paper where this information is located. The reviewer infers the location but doesn't name it.", "verifiability_rationale": "The review point identifies a deficiency ('is unclear') but does not provide any evidence, examples, or references to support this claim. It lacks a logical reasoning or external references to back up the assertion that the distribution is unclear.", "helpfulness_rationale": "The review point identifies a missing detail in the dataset description. While this is a valid point, it doesn't provide specific guidance on how the author should go about improving the distribution or what steps they should take to clarify the information. The feedback is present but lacks concrete action."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a problem (the limitation of current experiments to simple tasks) and suggests a potential solution (LFF on harder tasks), but it does not explicitly state how the author should apply this change. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer refers to 'continuous control experiments' and 'LFF' generally, without pinpointing a specific section, table, or figure in the paper. While the issue of 'higher input dimensionality' is mentioned, it's not tied to a specific element within a section. The reviewer identifies a problem in a general area but doesn't specify the exact part of the paper that needs improvement.", "verifiability_rationale": "The review point contains a claim: 'most continuous control experiments are performed on simple and lowdimensional tasks' and 'it\u2019s important to show LFF can also help to solve more challenging DRL tasks with higher input dimensionality.' This claim is supported by the general understanding in the field and the common practice of starting with simpler tasks. However, it doesn't provide specific examples or references within this review point itself.", "helpfulness_rationale": "The review point is relevant to authors working on continuous control tasks, especially those focusing on simpler environments. It highlights a potential area for improvement by suggesting the use of LFF on more complex tasks. While it doesn't provide specific steps, it points towards a meaningful direction for research and demonstrates an understanding of the limitations of current experimental setups. The reviewer's comment is likely to be helpful in guiding authors towards more challenging problems."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer provides two suggestions. The first suggests adding a citation and a more specific measure of expressivity to the abstract. While the reviewer identifies an area for improvement, the suggestion is implicit, as they don't specify where in the abstract this change should be made. The second suggestion is to include learning curves for all experiments. This is also implicit, as the reviewer doesn't specify the type of learning curves or how they should be presented. Both suggestions are concrete in identifying what needs to be added, but lack the explicit action of 'how to implement it'.", "grounding_specificity_rationale": "The reviewer's comments do not explicitly refer to a specific part of the paper or concept. They are making general suggestions for improvement to the abstract and the experiments.", "verifiability_rationale": "The reviewer does not make a claim about the paper. They are suggesting improvements rather than critiquing or making assertions about the work.", "helpfulness_rationale": "The reviewer's suggestions are relevant and could be helpful to the authors in improving their work. However, the lack of specific details makes it difficult for the authors to directly implement the recommendations. The suggestions are vague and require further clarification from the authors to be fully understood and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that the paper's motivation is unclear and that the application of the proposed method is not apparent. While the reviewer doesn't provide specific details on *how* to apply the method, the act of identifying a lack of motivation and application is a direct action the authors could take. The reviewer also suggests demonstrating the method on actual domain adaptation tasks, which is a concrete action the authors could pursue. However, the initial statement about the lack of motivation and application is vague on how to address this action.", "grounding_specificity_rationale": "The reviewer states that the motivation is unclear and the application is not apparent. They do not explicitly identify a specific section, table, figure, or unique aspect of the paper that is lacking motivation or application. While they suggest demonstrating on actual tasks, they don't specify *which* part of the paper needs this demonstration. The grounding is weak because the reviewer cannot confidently determine which part of the paper they are referring to.", "verifiability_rationale": "The reviewer makes a claim that the paper's motivation is unclear and the application is not apparent. However, they do not provide any evidence, examples, or references to support this claim. The claim is stated without any logical reasoning, common knowledge, or external references. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the paper (lack of motivation and application) but does not offer any solutions or directions for the authors to explore. They suggest demonstrating the method on actual domain adaptation tasks, which is a potential improvement, but they don't explain *why* this demonstration is necessary or how it would clarify the motivation and application. The helpfulness is limited because the reviewer doesn't provide actionable suggestions or insights to address the identified weakness."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "4: 5", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the MULT baseline is outdated and suggests considering newer baselines. While the reviewer identifies a potential weakness in the baseline selection, they do not explicitly state what action the authors should take. They suggest considering newer baselines, which is a helpful direction, but not a specific action.", "grounding_specificity_rationale": "The reviewer mentions the year of the MULT paper (2019) and the relevant timeframe for deep learning baselines in 2022. This demonstrates a clear understanding of which specific paper is being criticized and the current state of the field. The reviewer also categorizes the baselines as 'deep learning' and mentions the year 2022, which further grounds the criticism in specific details.", "verifiability_rationale": "The reviewer makes a claim that the MULT baseline is 'out of fashion' and provides reasoning by stating it was published in 2019. This claim is supported by the provided information. While the reviewer doesn't explicitly cite external references, the claim is logically supported by the given context. The reasoning is clear and directly links the publication year to the notion of being 'out of fashion' in the context of current deep learning research.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the baseline selection by pointing out that the MULT paper, which is considered a deep learning baseline, is from 2019. They suggest considering other deep learning baselines from 2022. While the reviewer doesn't provide a specific action for the authors, they offer a helpful direction by suggesting a more relevant set of baselines. The criticism is relevant to the paper's content, and the suggestion is constructive. The reviewer provides specific information about the publication year and category of the baseline, making the criticism grounded and specific."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out a missing element (model parameter counts) and suggests a solution (including them). This is a clear indication of an actionable suggestion. The reviewer identifies the action: 'include model parameter counts' and the implication: 'allow for a fairer comparison'. The suggestion is direct and provides a clear path for the authors to improve their analysis.", "grounding_specificity_rationale": "The reviewer explicitly names the models (TT, TR, TW) and the issue (lack of clarity and missing parameter counts). This strong identification makes it highly grounded. The reviewer clearly states what part of the paper and what aspect of the analysis is lacking clarity.", "verifiability_rationale": "The reviewer provides a clear and actionable suggestion. While it doesn't offer a new *method* for comparison, it points to a *specific missing information* that, if provided, would significantly improve the analysis. This is verifiable if the authors *do* include the parameter counts. The reviewer's statement itself is a logical claim that can be verified.", "helpfulness_rationale": "The reviewer's suggestion to include model parameter counts is directly relevant to improving the fairness and clarity of the comparison between different models. By providing this information, the authors can make a more informed and robust conclusion about the superiority of TW. This suggestion directly addresses a potential weakness in the experimental analysis and offers a concrete way to improve it. Therefore, it is 5 in guiding the authors towards a better understanding of their results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer correctly identifies a lack of detail regarding the algorithm's mechanism for removing subdivision splines. While the reviewer understands the *goal* of pruning, the *how* is missing. The reviewer's question about the computational cost is a valid concern, but the review stops short of providing specifics. The reviewer understands that the algorithm should detail the removal process, making the lack of it an implicit action. The vagueness about computational cost makes it partially actionable but ultimately 1 as a concrete step.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'theoretical part' and 'algorithm' in their comment. These are specific sections and components of the paper. This constitutes full grounding as the reviewer can accurately pinpoint the area being addressed. The comment also clearly specifies the issue: the lack of detail in the algorithm for removing subdivision splines, making it 5.", "verifiability_rationale": "The reviewer makes a claim that the paper 'didn\u2019t provide how the proposed algorithm in detail to remove the subdivision splines.' This is a clear claim that requires verification. However, the paper does not provide any evidence or references to support this claim. The reviewer's questions about the algorithm's details and computational cost are valid but not addressed in the paper. Therefore, the claim is not supported by any logical reasoning, common knowledge, or external references, making it 1.", "helpfulness_rationale": "The reviewer's comments are constructive and point to specific areas for improvement in the paper. They identify a genuine gap in the paper by pointing out the lack of detail in the algorithm for removing subdivision splines. Their questions are relevant and likely to guide the authors in refining their work. The reviewer's comments are clearly aimed at helping the authors improve their draft, making the feedback highly valuable and actionable in terms of guiding the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that 'W1 and W2 are not defined'. While this points to a missing piece of information, it doesn't directly instruct the authors on what to do next. The reviewer identifies a gap in the provided information, but doesn't specify how to address it.", "grounding_specificity_rationale": "The reviewer points to a specific section of the paper (A4) where the undefined variables are used. This demonstrates that the reviewer can identify the relevant part of the paper. However, the reviewer does not specify what is wrong with the definition or how it should be corrected. The comment focuses on the *lack* of definition rather than the *meaning* of the undefined variables within that section.", "verifiability_rationale": "The reviewer makes a clear statement that 'W1 and W2 are not defined'. This constitutes a claim that needs to be supported. However, the reviewer does not provide any evidence, references, or logical reasoning to support this claim. The statement is presented as a fact without justification.", "helpfulness_rationale": "The reviewer's comment is diagnostic, pointing out a missing definition. While this highlights a problem in the paper, it does not offer any suggestions or guidance on how to resolve it. The reviewer does not propose any changes or improvements to the definition of W1 and W2."}
{"actionability_label": "3", "grounding_specificity_label": "1 and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests changing the comparison methodology, which implies an action (reevaluating the baselines). However, the suggestion lacks specific details on *how* to change the comparison. It's a call for reevaluation rather than a direct action on the part of the authors.", "grounding_specificity_rationale": "The reviewer's comment is a general question about the fairness of the comparison and doesn't explicitly identify a specific part of the paper or baseline that lacks prior knowledge or language embeddings. It's a broad concern rather than a targeted critique.", "verifiability_rationale": "The reviewer's claim that the baselines 'lack the prior knowledge of users or any language embedding computation' is a hypothesis and not a statement that can be definitively verified or falsified based on the information provided in the review point itself. There's no concrete evidence or reference to support this claim within the review point.", "helpfulness_rationale": "The reviewer's suggestion to reevaluate the comparison methodology is potentially helpful for the authors as it prompts them to consider alternative approaches and potentially gain a deeper understanding of the baselines. However, the suggestion is vague and doesn't provide specific guidance on how to proceed with the reevaluation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer raises several questions about why the outputside layers do not benefit from the proposed method. While the questions are not direct instructions, they clearly indicate a lack of explicit explanation regarding a specific aspect of the paper's findings. The reviewer is asking for clarification on a phenomenon observed in the experiments, which suggests a need for more actionable insights.", "grounding_specificity_rationale": "The reviewer asks for more details about the Pixelshuffle operation and the upsampling process. They are not explicitly pointing to a specific section of the paper, making the grounding somewhat weak. However, they are asking for specific details about these operations, making the specificity clear. The reviewer is asking for more information within the model description.", "verifiability_rationale": "The reviewer questions the clarity and completeness of the explanation regarding the Pixelshuffle and upsampling. They are asking 'why' the dimensionality remains the same after upsampling, indicating a lack of sufficient justification or reasoning in the paper. The claim that the details are not clearly presented is not directly supported by a reference to external sources, making the verifiability low.", "helpfulness_rationale": "The reviewer requests more information about the limitations and potential negative societal impact of their work. This is a direct request for additional information that would be highly beneficial for the authors to understand the broader implications of their research. The request for clarification on the model's behavior and the discussion of limitations and societal impact are valuable and directly address the authors' needs for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the state of negative chips and suggests an alternative training approach. While the reviewer points to a specific aspect of the RPN process, the lack of detail makes it 2. The reviewer *wants* more information, but the review itself doesn't provide it.", "grounding_specificity_rationale": "The reviewer refers to 'negative chips' and the 'RPN training process' generally. While they don't explicitly name sections or tables, the concepts are generally understood within the context of NLP and RPNs. However, without more context, it's hard to pinpoint the *exact* part of the paper being discussed, making the grounding weak. The reviewer also asks about the 'state' of the chips and suggests an 'alternative' training method, which goes beyond simply describing the current state, making the specificity also low.", "verifiability_rationale": "The reviewer makes a claim about the relationship between negative chips and RPN training. This is a claim. However, the reviewer *doesn't* provide any evidence or reasoning to support their claim. They are posing a question, not stating a verifiable fact. Therefore, the verifiability is 1.", "helpfulness_rationale": "The reviewer is asking a question and suggesting a potential improvement. While relevant, it doesn't directly address a specific weakness or provide actionable feedback on how to improve the draft. The request itself isn't inherently helpful without more context."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need to evaluate the approach differently for new and returning patients. This is an explicit action. The reviewer also identifies the groups (new and returning patients) as the context for this evaluation, making the action concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'new patients' and 'returning patients' as distinct groups. This directly identifies the specific parts of the paper being addressed, achieving 'Full Grounding'. The reviewer also points out the lack of historical reports for the firsttime visitors, which is a specific issue related to these groups, adding further specificity.", "verifiability_rationale": "The reviewer states a need to 'evaluate the proposed approach on new patients and old patients respectively'. This is a statement of a requirement or a suggestion for an evaluation, but it lacks specific details on how this evaluation should be conducted. There is no logical reasoning, common knowledge, or external references provided to support this suggestion. Therefore, it is not verifiable at this point.", "helpfulness_rationale": "The reviewer's point about evaluating the approach differently for new and returning patients is a valuable piece of feedback for the authors. It directly addresses a potential limitation in the current experimental design and provides a clear direction for future evaluation. This suggestion is directly actionable and addresses a specific concern, making it helpful."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies potential limitations in the \"computation offloading\" and \"gradient augmentation\" techniques used in the algorithm. However, it does not explicitly state what the authors *should* do to address this. While it points to a potential area for improvement, it lacks specific, actionable steps. It's a negative observation but doesn't provide clear directions for change.", "grounding_specificity_rationale": "The review point mentions \"the algorithm\" in a general sense. It doesn't specify *which* part of the algorithm or the specific implementation details are lacking novelty. It also doesn't explain *why* these techniques might not be novel in the context of the specific paper's contributions. The comment is too broad and doesn't pinpoint the exact location or issue.", "verifiability_rationale": "The review point makes a judgment about the potential lack of novelty in the techniques. It doesn't present a claim that can be verified with logical reasoning, common knowledge, or external references. It's a subjective assessment of the techniques' novelty. The comment is a statement of opinion and doesn't offer any specific evidence or logical reasoning to support or refute the claim.", "helpfulness_rationale": "The review point raises a valid concern about the potential lack of novelty in the techniques. While it doesn't offer concrete solutions, it prompts the authors to consider alternative approaches or more innovative techniques. It's a constructive point that encourages selfreflection and potentially leads to positive changes, even if it doesn't provide immediate fixes. It highlights a potential area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a potential limitation in the model's assumption about how observations are generated, specifically mentioning 'averaging over the corresponding support v'. While the reviewer identifies a potential issue with the model's formulation, they do not explicitly state what the authors should do next. The reviewer suggests alternative aggregation methods but does not provide a clear, actionable step for the authors to take based on this observation. The reviewer's comment is focused on critiquing the model's assumption rather than directly instructing on how to improve it immediately.", "grounding_specificity_rationale": "The reviewer mentions specific aggregation methods like 'averaging', 'summation', and 'population weighted average' in the context of the model's observation generation. They also implicitly refer to 'disease incident data' and 'count' or 'rate per the number of residents'. However, the reviewer does not explicitly state which of these is the correct or relevant alternative for the authors to consider. They are pointing out *potential* issues, not directly instructing the authors on what specific part of the paper needs to be addressed and what exactly should be done. The reviewer identifies some possibilities but doesn't pinpoint the exact relevant section or table.", "verifiability_rationale": "The reviewer states, 'I have understood that the integral in Equation (1) corresponds to bag observation model in Law et al., NeurIPS'18 or spatial aggregation process in 4. The formulation introduced by the authors assume that the observations are obtained by averaging over the corresponding support v.' This is a claim that needs to be verified. However, the reviewer does not provide any external references to support this specific assumption within the paper. The reviewer's statement is presented as a deduction rather than a clearly stated fact with supporting evidence. Therefore, the claim is not fully supported by explicit, sufficient, and robust evidence.", "helpfulness_rationale": "The reviewer's comment is primarily critical, pointing out a potential limitation in the model's assumptions and suggesting alternative aggregation methods. While the suggestions are relevant, the reviewer does not frame them as direct, actionable steps for the authors to take immediately. The comment is more about highlighting a potential issue than providing a clear path forward for improvement. The reviewer's comment is not framed as a direct request for clarification or a suggestion for improvement that the authors can readily implement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'No indepth analysis' and asks 'why?'. This directly points to a missing action and a specific question about it. While the action of 'providing analysis' is implied, the reviewer is asking for a specific type of analysis (indepth regarding inverse scaling with compute). This makes the action relatively concrete, even if the *content* of the analysis isn't fully specified yet.", "grounding_specificity_rationale": "The reviewer refers to 'the authors found inverse scaling happens over compute'. This is a specific observation related to their own findings. While they don't name a specific section or table, the context is clear. They are referring to a finding related to their experimental setup and results. The reviewer is also asking a specific question ('why?') about this finding, indicating they are seeking an explanation for a specific phenomenon.", "verifiability_rationale": "The reviewer is making a statement about a *lack* of analysis and a *need* for analysis. This isn't a direct claim about a fact or a prediction. It's a statement about the *state* of the paper. Therefore, it's classified as 'X' (X). While the reviewer is asking a question, the request itself isn't a claim that needs verification.", "helpfulness_rationale": "The reviewer directly points out a weakness ('No indepth analysis') and suggests a concrete improvement ('provides some analysis explaining such training dynamics'). This is a clear and actionable suggestion directly addressing a perceived lack."}
{"actionability_label": "Medium", "grounding_specificity_label": "High", "verifiability_label": "Low", "helpfulness_label": "Low", "actionability_rationale": "The reviewer points out a potential issue with a theoretical argument in the paper. While the criticism is specific about a missing assumption in a particular section, it doesn't directly instruct the authors on how to *actionably* improve their draft based on this critique. The reviewer is highlighting a flaw in the theoretical framework rather than providing a direct, actionable suggestion for improvement within the context of the paper's main content.", "grounding_specificity_rationale": "The reviewer explicitly states the location of the potential issue (Section 5.1) and the nature of the problem (the assumption that each individual's data is iid drawn from the same distribution). This provides a clear and specific reference point for the authors to understand and address the concern. The criticism is not vague or general but rather pinpoints the exact section and the specific assumption.", "verifiability_rationale": "The reviewer makes a claim about the unjustifiability of a specific assumption in a theoretical section. However, they do not provide any external references, logical reasoning, or examples to *support* this claim. The statement is presented as an opinion rather than a verifiable assertion based on evidence or logical deduction.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about a theoretical assumption. However, it doesn't offer a direct, actionable suggestion for the authors to improve their draft. The comment is more of a critique of the theoretical framework than a constructive suggestion for practical improvement. While it highlights a potential issue, it doesn't provide a clear path for the authors to address it within the scope of improving their current draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the relationship between fixed policies and a subset of reinforcement learning, and it poses a question about the complexity of tasks that might require a nonfixed policy. This is an explicit and concrete action, directly addressing the concepts of fixed policies and reinforcement learning.", "grounding_specificity_rationale": "The reviewer directly addresses the concepts of 'fixed policy' and 'reinforcement learning,' which are implicitly related to specific parts of a typical reinforcement learning paper. While not explicitly pointing to a section or table, the concepts are clearly implied and relevant. This can be considered '3' as the concepts are implied but the specific application isn't pinpointed.", "verifiability_rationale": "The review point contains a claim about the nature of fixed policies in reinforcement learning. This claim is supported by the understanding of how reinforcement learning works and the implications of a fixed policy. While not backed by explicit citations, the reasoning is based on established principles of RL. This can be considered '3' as the reasoning is present but could be strengthened with a brief explanation of why a fixed policy is a subset of RL.", "helpfulness_rationale": "The review point raises a valid concern about the limitations of fixed policies in reinforcement learning and suggests a relevant comparison with a reinforcement learning algorithm baseline. This is a helpful point as it highlights a potential area for improvement and provides a direction for future work. However, the point could be more specific about how this comparison would be made and what metrics would be used to evaluate the performance difference. This can be considered '3' as the point is relevant and suggests a useful comparison, but it lacks specific details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review points out a limitation of the paper's focus but doesn't specify how this limitation should be addressed or what changes are needed. It identifies a problem but lacks explicit and concrete suggestions.", "grounding_specificity_rationale": "The review refers to \"the paper\" and \"applicability,\" which are clear references. It also specifies the nature of the limitation (\"limits the applicability\"). This can be considered fully grounded as it explicitly mentions the paper and the issue of applicability, and it specifies what is meant by 'limits the applicability'.", "verifiability_rationale": "The review states a fact about the paper's focus and its potential limitation but doesn't provide evidence or reasoning to support this claim. It doesn't contain a claim that requires verification.", "helpfulness_rationale": "The review identifies a weakness, but it doesn't offer actionable advice or justification for improvement. It's a negative observation without clear direction for the authors. While it points out a problem, it doesn't guide the authors on how to address it, making it less helpful."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests including 'several papers' in the literature review and makes a claim about the performance of VRMARINA and DASHAMVR compared to QSGD. While the suggestion to include papers is explicit, the reviewer does not specify *where* these papers should be included (e.g., a specific section, table, or unique aspect of the paper). The claim about the performance difference is not actionable as it lacks supporting evidence or justification.", "grounding_specificity_rationale": "The reviewer suggests including 'several papers' in the literature review and makes a claim about the performance of VRMARINA and DASHAMVR compared to QSGD. However, the reviewer does not explicitly identify the specific section, table, figure, or unique element of the paper where these papers should be included. While the reviewer mentions 'several papers' and 'Assumption 2', this is not a direct, explicit reference. The claim about the performance difference is also 1 in the paper itself.", "verifiability_rationale": "The reviewer makes a claim about the performance of VRMARINA and DASHAMVR compared to QSGD but does not provide any supporting evidence, justification, or references to back this claim up. There is no logical reasoning, common knowledge, or external references provided to support the assertion that these algorithms have a better rate than QSGD in the stochastic regime. The claim is presented without sufficient grounding.", "helpfulness_rationale": "The reviewer provides suggestions for improving the literature review by including specific papers. However, the claim about the performance of VRMARINA and DASHAMVR compared to QSGD is not supported by any evidence or justification. Without this supporting evidence, the reviewer's suggestion regarding the performance difference is not particularly helpful for the authors. The helpfulness is limited by the unsubstantiated claim."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point asks questions about the performance of the algorithm on specific datasets. While these questions can be useful for further research or understanding, they do not provide explicit or implicit actions for the authors to take. The questions do not guide the authors on how to improve their draft based on the current results.", "grounding_specificity_rationale": "The review point asks questions about the performance of the algorithm on specific datasets. While these questions can be useful for further research or understanding, they do not explicitly or implicitly refer to a specific part of the paper, dataset, or figure that the authors should focus on. The questions are about general performance rather than specific issues within a particular section.", "verifiability_rationale": "The review point asks questions about the performance of the algorithm on specific datasets. These questions do not make any claims or assertions that require verification. They are inquiries about observed results, not statements that need to be proven or justified.", "helpfulness_rationale": "The review point asks questions about the performance of the algorithm on specific datasets. These questions do not provide any actionable feedback or suggestions for improvement to the authors. They are requests for more information rather than critique or recommendations based on the current results."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks for 'more detail' about the compared models and specifically requests information on the 'computation requirements' of the three methods. This directly points to a lack of explicit information in the paper. While the reviewer identifies the models (DMM, DVBF, KVAE) and their general differences with KVAE, the paper does not provide a detailed comparison of their computational costs. The request is clear and actionable in identifying this missing information. However, the reviewer does not offer any potential solutions or alternative approaches, making it 3 rather than fully actionable.", "grounding_specificity_rationale": "The reviewer's comment is general and does not explicitly refer to a specific part of the paper. While they mention 'the paper's differences with KVAE,' they do not specify which section or table this refers to. Similarly, the request for 'a comment on the computation requirements' is broad and doesn't pinpoint where this information should be located within the paper. The grounding is weak because the reviewer cannot confidently determine which part of the paper they are referring to. They are making an educated guess about the models but not providing a precise reference.", "verifiability_rationale": "The reviewer is asking for a 'presentation' of information regarding the computational requirements of the compared models. While the paper likely contains the information needed to infer these requirements (e.g., model descriptions, parameter counts), it does not explicitly state this information in a clear and verifiable way. The reviewer is asking for a specific presentation of this information, indicating that the paper's current presentation is insufficient. The need for this information is clear, but the paper does not provide a direct, verifiable statement about the computational costs. Therefore, it is 3 as the information is implicitly present but not explicitly stated and justified.", "helpfulness_rationale": "The reviewer's comment is clearly helpful. They are pointing out a gap in the paper's presentation by requesting more detail about the compared models and their computational requirements. This is a specific and actionable request that would likely benefit the authors. The reviewer is not asking for a critique or a different approach, but rather for more information to be presented in a certain way. The request is clear and identifies a specific area for improvement in the paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points to a 'main takeaway point' and a specific action ('query a cluster proportionally to the square root of its size'), but it doesn't explicitly state how to implement this action. The formula or algorithm isn't provided, making the action only implicitly suggested.", "grounding_specificity_rationale": "The review refers to 'theoretical results' and 'main takeaway point,' which are somewhat vague. While it hints at a specific area, it doesn't explicitly link it back to a specific section, table, figure, or a unique element of the paper. The connection to the 'square root of the size' is also not explicitly stated within the review itself.", "verifiability_rationale": "The review makes a claim about a potential takeaway, suggesting that 'querying a cluster proportionally to the square root of its size' is a 'main takeaway point.' This claim is somewhat supported by the reviewer's perspective. However, the 'ideal' aspect of the review, suggesting more takeaway points for practitioners, is subjective and lacks direct evidence from the paper.", "helpfulness_rationale": "The review offers some insight into the limitations of the theoretical work and suggests a potential practical implication. However, it doesn't explicitly state how to implement the 'querying' process or provide concrete examples of how practitioners could benefit from this. The 'ideal' aspect, while relevant, doesn't offer a concrete improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks for the reason behind the introduction of separators in section 4 and what additional information they provide beyond I/O. This is a direct request for clarification and explanation, which is an explicit and concrete action. The reviewer clearly identifies a missing piece of information and asks for it.", "grounding_specificity_rationale": "The reviewer specifically points to section 4 and asks a question about the purpose and additional benefit of separators within that section. The reference to section 4 makes the grounding explicit and clear. The request for the 'additional info beyond T/I/O' further specifies the nature of the information being sought.", "verifiability_rationale": "The reviewer is not making a claim. They are asking a question seeking information. Therefore, this review point does not contain a claim and falls under the 'X (X)' category. While the information about separators might be verifiable, the review itself does not present a judgment or opinion.", "helpfulness_rationale": "The reviewer's question directly addresses a potential point of confusion for the authors regarding the use of separators. By asking for the reason and additional information, they are seeking to improve the clarity and completeness of section 4. This is a direct and specific question that, if answered, could be helpful for the authors. While it doesn't offer a solution, it is a valuable piece of feedback that targets a specific aspect of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a desire to compare 'real search cost' in Table 3 and provides a concrete suggestion: 'in terms of GPU days'. This indicates a clear action to be taken and a specific method for implementation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 3' and the concept of 'search cost', directly identifying the specific part of the paper and the issue within it. They also suggest a specific metric ('GPU days') for measuring search cost.", "verifiability_rationale": "The reviewer suggests using 'GPU days' as a measure of 'real search cost'. While they don't provide a detailed justification for this choice, the suggestion is concrete and could be verified by referencing typical search cost measurements in machine learning.", "helpfulness_rationale": "The reviewer points out a specific weakness in Table 3 (lack of cost comparison) and provides a concrete suggestion for improvement ('in terms of GPU days'). This directly addresses a potential area for enhancement in the paper's evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer is implicitly asking for clarification on a missing detail (training details for VQGAN), which can be considered an actionable request. While not explicitly stating 'do something about it', the request points to a gap that needs addressing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'VQGAN' and '88,635 images from the Computer Vision Figures dataset', providing a clear and specific reference point within the paper. This indicates strong grounding.", "verifiability_rationale": "The reviewer is asking a question about a specific detail (training details for VQGAN), which can be interpreted as a claim that this information is missing or should be present. However, the claim itself is not supported by evidence within the review point.", "helpfulness_rationale": "The reviewer directly points out a missing detail (training details for VQGAN) that would be beneficial for the authors to know. They are asking a direct question about a critical detail, which is likely to be helpful."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point does not explicitly state what is wrong with the methods or how the authors should improve them. It only mentions that the performance in MSVD shows minor improvements, which is a statement of observation rather than a directive action.", "grounding_specificity_rationale": "The comment identifies the issue with the performance on the MSVD dataset, which is a specific part of the paper. However, it does not specify what aspects of the performance are improved or what needs to be done to address this improvement. The grounding is present but not fully specific.", "verifiability_rationale": "The claim that 'the performance in MSVD (Table 3) shows minor improvements' is supported by the referenced Table 3. However, the review point does not explain why these improvements are minor or provide any justification for this observation. The verifiability is present but lacks depth and explanation.", "helpfulness_rationale": "The review point highlights a specific experimental result (minor improvements in MSVD performance) and acknowledges the lack of genericity. While it points out a relevant finding, it does not offer concrete suggestions or guidance on how to address the identified issue or improve the methods. The helpfulness is limited to acknowledging a relevant finding without providing actionable insights."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a potential alternative (vanilla Adam with random restarts) and argues why it's a better approach (less computationally expensive, simpler). This is an explicit suggestion for improvement. The reviewer also points out the difference in implementation, highlighting the need to run a descent procedure for 40 different networks, which is a concrete detail.", "grounding_specificity_rationale": "The reviewer refers to the 'proposed algorithm' and 'training phase' without explicitly naming specific sections, tables, or unique elements of the paper. They are pointing to a conceptual difference in the experimental procedure. While the reviewer can infer the relevance, they cannot precisely identify the referenced part of the paper.", "verifiability_rationale": "The reviewer makes a claim about the experimental strengths of the approach and provides a justification for why a simpler alternative might be better. They offer a logical reasoning based on the idea that one of the 40 initial points might reach the global minimum. While they don't provide external references, the comparison to vanilla Adam is a common knowledge argument. The claim is supported by a clear reasoning.", "helpfulness_rationale": "The reviewer's tone is critical but constructive. They point out a potential flaw in the experimental design (the need to run 40 different networks) and suggest a simpler alternative. This highlights a potential issue with the proposed method and offers a solution, making the review point helpful for guiding improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the correct quotation mark and provides the exact location of the issue. The correction is also clearly stated. The reviewer is directly identifying the specific part of the paper that needs correction and providing the exact fix.", "grounding_specificity_rationale": "The reviewer mentions the location 'p.', which is a weak ground. However, the reviewer clearly specifies the issue ('inbetween' needs forward quotes) and the solution (corrected phrase). The specificity of the correction is high, but the grounding of the location is brief.", "verifiability_rationale": "The reviewer makes a claim about a specific issue on a particular page and provides the exact correction. This claim is easily verifiable by checking the quotation marks on that specific phrase. The reasoning is clear and the solution is concrete.", "helpfulness_rationale": "The review point is very specific, pointing to a clear typographical error and providing the exact correction. This is immediately actionable for the author. The location, while brief, is still specific enough to guide the author to the relevant part of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for the definition of 'Omega' and points out that 'OMD is a whole family of algorithms' and asks for more specificity regarding the 'link function' and the 'theorem in 32'. These are direct requests for information and actions the authors should take.", "grounding_specificity_rationale": "The reviewer asks about 'Omega' and 'OMD' without explicitly stating which section, table, figure, or unique aspect of the paper they are referring to. While the reviewer implies the relevance of these terms, the paper doesn't provide a clear and direct link to their specific location or detailed explanation.", "verifiability_rationale": "The reviewer states that the paper lacks clarity regarding 'Omega' and the details of the 'OMD algorithm' (link function and regret guarantee). This is a statement of a problem, but it doesn't provide a claim that can be verified using logical reasoning, common knowledge, or external references. The reviewer is observing a lack of information rather than making a claim that needs verification.", "helpfulness_rationale": "The reviewer's point directly suggests areas where the authors can improve their understanding and potentially their algorithm by clarifying the definition of 'Omega' and the specifics of the 'OMD algorithm'. This is a constructive suggestion that directly addresses potential areas of confusion."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states the problem as 'learned directly from pixels' and suggests a solution by 'learning models from pixels without a Markovian state'. This is an explicit action that is also concrete as it prescribes a specific change to the model architecture.", "grounding_specificity_rationale": "The review point refers to the 'model architecture' and specifically points out the 'lack of Markovian state'. While it doesn't explicitly name a section or table, it clearly identifies the part of the paper being addressed and the issue within it. This allows for weak grounding as the reviewer can infer the relevant part and the problem.", "verifiability_rationale": "The review point makes a claim about the current approach ('learned directly from pixels') and suggests an improvement ('without a Markovian state'). While it doesn't provide specific examples or references to support this suggestion, it clearly identifies a potential area for future research and improvement, making it 3.", "helpfulness_rationale": "The review point identifies a limitation of the current approach (lack of Markovian state) and suggests a way to address it (learning from pixels). This provides a clear direction for improvement and helps the authors understand a potential research direction, making it 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their surprise at the use of Hamming distance over entire parts of the sequence in the context of CRFs and requests references. This constitutes an explicit action (pointing out a potential inconsistency) and a concrete detail (asking for specific references).", "grounding_specificity_rationale": "The reviewer clearly identifies the specific aspect of the paper they are referring to: 'the context of CRF corresponding to using as a scoring loss the Hamming distance over entire parts of the sequence.' They also specify the specific detail they are questioning: 'I've never seen this type of approach and am only aware of works reporting the hamming loss defined node wise.' This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim about a potential inconsistency in the use of Hamming distance in CRFs and requests references to verify this claim. This fits the definition of a claim requiring justification or references.", "helpfulness_rationale": "The reviewer provides specific feedback about a potential issue in the paper's methodology (the use of Hamming distance) and directly asks for references. This is a clear and actionable point for the authors, making the review helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need to change the name of the 'Evaluation' element to 'Metrics'. They also specify that the content within this element should be moved to a separate section and that the feedback should be presented either by briefly mentioning the datasets or including them in the captions of the tables. These are all direct and concrete actions that the authors can readily implement.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific element being discussed, which is the 'Evaluation' element. They then explicitly state the desired change \u2013 renaming it to 'Metrics' and relocating its content. Furthermore, they provide details on how the feedback should be presented, either by briefly mentioning the datasets or including them in the captions of the tables. This demonstrates a strong grounding in the specific part of the paper and a clear specification of the action to be taken.", "verifiability_rationale": "The reviewer suggests renaming the 'Evaluation' element to 'Metrics' and recommends presenting the feedback in a specific way. While the reviewer doesn't provide explicit external references to justify why 'Metrics' is a superior or standard term, the suggestion itself implies that this terminology is a desirable or common practice within the field or community. The reviewer acts as the justification for the change. Therefore, the claim is 3 as it is based on a suggestion and an implied standard, even without direct citations.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: renaming the 'Evaluation' element to 'Metrics' and specifying how the feedback should be presented. This directly addresses a potential area of confusion or inconsistency in the paper's terminology. While it doesn't offer new insights into the *content* of the evaluation, it empowers the authors to make a concrete change that aligns with a more standardized terminology. This makes the review 5 in guiding the author towards a more consistent and potentially more widely understood approach."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggestion for the authors. It is a general suggestion to explore a new dataset. Therefore, it lacks the explicitness and concreteness required for actionability.", "grounding_specificity_rationale": "The review point does not specify where in the paper the DRRI dataset could be explored. It is a general suggestion and does not identify a specific section, table, figure, or unique aspect of the paper. Therefore, it is 1.", "verifiability_rationale": "The review point is a suggestion, not a claim that requires verification. Therefore, it does not fit into the verifiability categories and should be marked as 'X'.", "helpfulness_rationale": "The review point suggests exploring a new dataset. While relevant, it does not directly identify weaknesses in the current paper or provide actionable steps for improvement. It is a suggestion for future work rather than immediate feedback for the current draft. Therefore, it is not 5 in the context of improving the existing paper."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests using more objective terms and questions the use of 'remarkable'. While they don't explicitly state what to do, they imply a change in language. They do specify the desired outcome: 'not remarkable'.", "grounding_specificity_rationale": "The reviewer's comment focuses on the language used to describe the improvement ('remarkable') rather than a specific part of the paper (section, table, figure). They do not identify a particular element of the paper they are addressing.", "verifiability_rationale": "The reviewer makes a claim that the improvement is 'remarkable' and suggests looking at the axes as evidence. However, they acknowledge that the axes are 'squished' and therefore difficult to interpret objectively. The justification for the claim is not fully presented within this review point itself.", "helpfulness_rationale": "The review points out a potential issue with the authors' description of their results ('remarkable accuracy improvement') and suggests a more objective approach. While it identifies a weakness, it doesn't provide a concrete solution or actionable feedback on how to improve the description or make the results more objective."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the limitation of using short video sequences (e.g., 16 frames) and suggests a concrete improvement by exploring longer sequences. The reviewer also mentions specific issues observed in the synthesized results for UCF101, such as inconsistent motion, changing color, and object disappearing over time, which implies a clear action to be taken. The suggestion to 'run the LSTM over many time steps' provides a specific direction for implementing the improvement. Therefore, the review point is 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'short video sequences' and refers to the 'UCF101' dataset, which are specific aspects of the paper. The reviewer also describes specific visual artifacts ('inconsistent motion, changing color, or object disappearing over time') within the context of the UCF101 dataset. This demonstrates a strong grounding in the specific part of the paper being discussed and a clear identification of the issue. Therefore, the review point is 5.", "verifiability_rationale": "The reviewer makes a claim suggesting that exploring longer video sequences ('It would be interesting to videos with a longer duration') and running the LSTM over many time steps would address the observed issues ('One can see the problem in the synthesized results for UCF101: inconsistent motion, changing color, or object disappearing over time'). The reviewer provides a logical reasoning for this claim by linking the proposed solution to the observed problems. The claim is supported by the described issues and the suggested method. Therefore, the claim is thoroughly supported and the review point is 5.", "helpfulness_rationale": "The review point is 5, grounded and specific, and thoroughly supported. The reviewer provides a clear suggestion for improvement and connects it to observed limitations. The positive framing of the review, acknowledging the strengths of the paper while offering constructive feedback, makes it 5 for the authors. The reviewer's suggestions are concrete and directly address the identified weaknesses. Therefore, the review point is 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The review points out a limitation in the field of GPU pruning but does not provide explicit or concrete steps for the authors to take to address this limitation. It is a statement about the current state of the field rather than a direct instruction or suggestion for improvement.", "grounding_specificity_rationale": "The review makes a general statement about the limitations of GPU pruning in the field without specifying which part of the authors' work or paper this applies to. It lacks grounding in a specific section, table, figure, or unique aspect of the authors' research.", "verifiability_rationale": "The review states a generally accepted idea about the challenges of efficiency gains on GPUs in the field. While it is based on common knowledge, it lacks specific examples or references to external works to support the claim. It is a statement that is generally verifiable but lacks specific justification within the context of the authors' work.", "helpfulness_rationale": "The review identifies a valid issue in the field but does not provide specific, actionable feedback or suggestions for the authors to improve their draft. It highlights a general limitation without offering concrete directions or solutions for the authors' specific work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The criticism focuses on the limitations of the evaluation method rather than directly proposing actionable improvements within the review point itself. While the reviewer points out the use of synthetic data and the comparison with another method, these are critiques of the evaluation *process* rather than explicit actions or suggestions on how to improve the draft based on the review.", "grounding_specificity_rationale": "The reviewer criticizes the evaluation being based on 'synthetic data,' which implies a lack of grounding in realworld scenarios or specific parts of the paper. While the reviewer doesn't explicitly state the evaluation doesn't identify a specific part, the focus on the evaluation methodology and the comparison with another method suggest a lack of direct grounding in the paper's content.", "verifiability_rationale": "The reviewer claims the evaluation is 'not fully convincing' and provides reasons like the use of synthetic data and the comparison with another method. These reasons, while valid critiques of the evaluation's basis, don't directly verify or falsify claims within the review point itself. The reviewer is making a statement about the evaluation's quality rather than providing evidence for or against a specific claim within the review.", "helpfulness_rationale": "The reviewer's comment is a critique of the evaluation method and its potential impact on the authors. While it could be helpful for the authors to understand the limitations of the evaluation, the comment itself doesn't provide specific, actionable feedback on how to improve the draft. The criticism is more about the *process* than a direct suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1: Not Verifiable", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a question and suggests an experiment. This is an explicit action. While the action itself is not to directly modify the paper, it points towards a concrete next step for the authors to consider. The suggestion to ask a specific question about an existing experiment is clear and actionable.", "grounding_specificity_rationale": "The reviewer refers to 'numbers of bits in logits' and 'PGD attack,' which are specific concepts within the paper. While they don't explicitly name the section, table, or figure, the terms are highly specific. This can be considered 'Full Grounding' as the terms directly point to the relevant parts of the paper. The reviewer also asks a question about the *nature* of the experiment, which is a specific request for information about the existing setup.", "verifiability_rationale": "The reviewer does not explicitly state a claim. They are posing a question and suggesting an experiment. While the suggestion *could* be considered a potential claim (e.g., 'The paper should discuss the robustness of 32bit logits against stronger attacks'), the review point itself does not contain a claim, verification, or reference to external sources. Therefore, it is not '1' or '2'. The suggestion itself could be verifiable if the authors provided evidence from the experiment, but the review point itself lacks this.", "helpfulness_rationale": "The reviewer provides a clear question and a suggestion for an experiment. This directly addresses a potential area for improvement in the paper's discussion of robustness. The suggestion is relevant and builds upon the existing work. It encourages the authors to consider a more thorough analysis of their model's robustness. While it doesn't directly tell them *how* to run the experiment, it provides a concrete next step for them to consider."}
{"actionability_label": "2", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point asks a question about the outcome of applying a method. While it implies an action (analyzing costs), it doesn't specify how to do it or what data is needed. The action of 'applying the method' is assumed from the context of the paper, making the action implicit and vague.", "grounding_specificity_rationale": "The question refers to 'men' and 'women,' which are categories within a statistical analysis or data presentation. While it implies a focus on these categories, it doesn't explicitly name a specific section, table, figure, or unique element of the paper. It's not a literal mention, but it's also not a complete guess without context.", "verifiability_rationale": "The review point is a question about the outcome of a method, not a statement of opinion or judgment. Therefore, it doesn't contain a claim that can be verified.", "helpfulness_rationale": "The review point is a question about the outcome of a method, not a suggestion for improvement or a critique of the paper. It lacks actionable feedback and doesn't provide insights into why the result might be important or how it relates to the paper's core argument. It's purely a question, which doesn't contribute to the authors' ability to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a *methodological choice* (how the dataset was split) and highlights a *potential issue* (the presence of arXiv versions). While they identify a problem, the action is to 'fix' the splitting, which isn't a direct action the author can take immediately. It's more of a *criticism* of the methodology.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'publication years on the ACL anthology' and uses the 'BERT paper' as a concrete example to illustrate the issue. This demonstrates a clear identification of the specific part of the paper being addressed and provides a specific instance within that part.", "verifiability_rationale": "The reviewer states a concern about the data splitting method but does not provide any justification or evidence to support this claim. They identify the issue but don't explain *why* it's an issue or suggest an alternative. The reasoning is missing, making it 1.", "helpfulness_rationale": "The reviewer raises a valid point about the potential bias introduced by splitting the dataset based on ACL anthology publication years, given that many papers were available on arXiv earlier. However, the review lacks concrete suggestions for the authors to address this issue. It's a critique of the methodology rather than a direct, actionable improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their lack of understanding regarding the motivation for using \u03b2 instead of the true upper bound of the ratio p q and the difference between QRS and RS. This indicates a lack of explicit action or a lack of clarity on how to implement the action. The action of understanding the motivation and difference is not concretely explained in the review point.", "grounding_specificity_rationale": "The reviewer mentions algorithm 1 and the terms \u03b2 and rejection sampling, indicating some attempt to ground the comment in the paper. However, they could be more specific about which part of algorithm 1 they are referring to (e.g., a specific line or step). The issue is identified as a lack of clarity in the motivation for \u03b2 and the difference between QRS and RS, which are specific to the algorithmic details.", "verifiability_rationale": "The reviewer states that they fail to understand the motivation for using \u03b2 and the difference between QRS and RS. This constitutes a claim. However, the reviewer does not provide any external references or logical reasoning to support this claim. The claim is presented as a statement of lack of understanding without further justification.", "helpfulness_rationale": "The reviewer's comment highlights areas where the authors are struggling and points out a lack of clarity in the paper regarding the motivation for \u03b2 and the difference between QRS and RS. While the reviewer doesn't offer solutions, they identify a specific problem that needs to be addressed. The comment is focused on identifying a weakness rather than providing a solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment does not explicitly state what needs to be done. While it suggests 'further refinement,' it doesn't specify how to achieve this. The action is implied but not concrete.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper being addressed. It is a general statement about 'performance enhancements' and 'future.'", "verifiability_rationale": "The comment does not contain a claim. It is a statement of observation ('somewhat modest') and a suggestion ('further refinement'), but lacks supporting evidence or justification.", "helpfulness_rationale": "The comment points out a potential area for improvement ('modest performance enhancements') and suggests a direction ('further refinement'). However, it lacks specific actionable steps or concrete suggestions, making it 3 but lacking depth."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the lack of references and points to specific lines, making it clear what needs to be done. The request to add references is direct and actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions sections and lines, and asks for a definition of a term in a figure, indicating a clear understanding of where the information is needed. The references are specific and point to exact locations in the paper.", "verifiability_rationale": "The comment does not contain a claim; it identifies missing information or a lack of definition. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The feedback is helpful in improving the paper but doesn't directly improve the review content. The reviewer is pointing out areas where the paper could be better by adding references and defining terms."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the issue: 'a) The experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method'. This is an explicit statement of a problem. However, the reviewer does not provide a specific action or suggestion on how to improve the experiments. They identify the *problem* but don't offer a concrete step to address it. Therefore, while the issue is identified, the specific action to take is missing.", "grounding_specificity_rationale": "The reviewer mentions 'the experimental results on the last two datasets' and 'the performance is similar to IRM'. This demonstrates a clear grounding of the comment in specific parts of the paper and the performance metrics being compared. However, the reviewer does not specify *what* aspects of the experimental setup or results are causing this similarity. The grounding is present, but the specificity of the explanation is lacking.", "verifiability_rationale": "The reviewer makes a claim: 'the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method' and 'the performance is similar to IRM, which I wonder if it is caused by the problems mentioned above'. This is a claim that requires justification. The reviewer mentions IRM as a point of comparison but does not provide external references, logical reasoning, or specific examples to support their claim about the unconvincing results. The claim is stated, but the supporting evidence is missing.", "helpfulness_rationale": "The reviewer points out a specific issue with the experimental results and raises a question about the cause. While the reviewer identifies a problem, they do not offer any suggestions or insights on how to address it. The feedback is limited to identifying a weakness without providing actionable steps. Therefore, the feedback is present but lacks depth and practical value."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "5 (5)", "verifiability_label": "4 (4)", "helpfulness_label": "1 (1)", "actionability_rationale": "The reviewer is asking for an explanation, which implies an action, but the explanation itself is vague and doesn't explicitly state *why* both entities are needed. The action is implicit (asking for clarification) rather than explicitly stating it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 2', which clearly grounds their request to a specific part of the paper. The request also specifies the difference between 'knowing the long one' and 'knowing the short one', making it specific.", "verifiability_rationale": "The reviewer is making a claim about the difference between knowing the long and short entities. This claim is verifiable by stating the difference in length and its implications for entity disambiguation. The reasoning is clear and the reference to the length difference provides sufficient justification.", "helpfulness_rationale": "The review point is a question asking for clarification, not a statement of improvement or a suggestion for action. While the question is relevant, it doesn't directly help the authors improve their draft on its own. The helpfulness comes from the act of providing the explanation that the authors then use to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'I would like to see some experiments'. This indicates an action, although it is vague on the specifics of the experiments or the 'bounds' being validated. The action is present, making it at least 3.", "grounding_specificity_rationale": "The reviewer refers to 'some experiments' generally, without specifying a particular section, table, figure, or unique aspect of the paper. The grounding is weak as the specific part of the paper being addressed is not clearly identified.", "verifiability_rationale": "The reviewer states a desire to 'see some experiments'. This is a suggestion or judgment about the paper, but it lacks logical reasoning, common knowledge, or external references to support the claim. The statement itself is a claim that needs to be verified by the authors through experimentation.", "helpfulness_rationale": "The reviewer's point about the lack of empirical validation is a valid concern for the authors. However, the request for 'some experiments' is vague and lacks specific direction, making it less immediately helpful. While the desire for more empirical support is valid, the lack of specificity hinders actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer's question directly addresses a potential inconsistency in the paper's logic regarding Theorem 1 and isolated nodes. While the question itself doesn't explicitly state an action to be taken, it clearly points to a need for clarification or correction. The reviewer is prompting the authors to reconsider the theorem's implications for nodes with zero neighbors. This can be considered implicit actionability as the reviewer is prompting for a change in understanding or a correction to the theorem's application.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Theorem 1' and the concept of 'neighbors' in their review point. They are even specifying the scenario of a node with '0 neighbors'. This clearly indicates that the authors can identify the specific part of the paper and the issue being addressed. Therefore, the grounding specificity is high.", "verifiability_rationale": "The reviewer poses a question about the validity of Theorem 1 in the context of isolated nodes. This constitutes a claim that the theorem might be incorrect under certain conditions. While the reviewer doesn't provide immediate evidence or logical reasoning within the review point itself, the question implies a need for verification. Therefore, the verifiability is somewhat high, as the implication is that there is something to verify.", "helpfulness_rationale": "The reviewer's question directly points out a potential flaw or inconsistency in the paper's logic. They are asking the authors to explain a seemingly contradictory situation. This is a highly valuable piece of feedback as it directly challenges the authors' work and encourages them to reexamine their assumptions. The reviewer is prompting for a clarification or correction, which is a significant point of improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a relationship between training time reduction and parameter reduction ('most gradients are still computed for early downsampling layers (Discussion)') and suggests a potential area for further investigation ('This seems not to have been revisited in the Discussion'). While it doesn't directly tell the authors what to change, it points to a clear direction for improvement.", "grounding_specificity_rationale": "The comment explicitly refers to 'training time reduction,' 'parameter reduction,' and 'Discussion,' which are all specific parts of the paper. The reviewer clearly identifies the sections being discussed, making it fully grounded. The comment also specifies what it is explaining \u2013 the relationship between the two reductions.", "verifiability_rationale": "The comment contains a claim ('This seems not to have been revisited in the Discussion') and provides some justification by stating the reason for this observation ('most gradients are still computed for early downsampling layers'). However, it doesn't provide external references or definitive proof within the paper itself to support this claim.", "helpfulness_rationale": "The review points out a trend in the results that was initially presented but not further explored in the discussion. This highlights a valuable insight for the authors and suggests a specific area to investigate further. While it doesn't provide a direct edit instruction, it guides the authors to look for specific sections in the discussion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the question about the problem's applicability to other downstream tasks and its specificity to binding affinity prediction. This indicates an awareness of the potential ambiguity and a desire for clarification. While it doesn't directly propose an action, it identifies a specific area of concern, making it 3 in terms of guiding the authors to consider the scope of the problem.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'binding affinity prediction' and 'downstream tasks' when asking about the problem's scope. This clear identification of a specific aspect of the problem demonstrates strong grounding. The information provided is specific and directly related to the potential area of application.", "verifiability_rationale": "This review point does not contain a claim. It is a question about the scope of the problem. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The reviewer is asking a question about the scope of the problem, which could be helpful for the authors to understand the limitations or generalizability of their work. While it doesn't directly tell them what to do, it's a request for information that could improve their understanding and potentially their approach. The question is specific to the identified area, making it 3 in terms of addressing a potential area of confusion."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem ('the technical contribution is limited') and provides an example ('the contents of Section 4 are not about a formal and principled solution, but most about heuristics'). However, it does not explicitly state how to address this limitation or what specific changes are needed.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 4' as a specific part of the paper. It also specifies the nature of the content in that section ('not about a formal and principled solution, but most about heuristics'). This provides clear grounding and specificity.", "verifiability_rationale": "The review point makes a statement about the 'technical contribution being limited' and describes the content of 'Section 4'. However, it does not present a specific claim that requires verification or justification. It is more of an observation about the current state.", "helpfulness_rationale": "The review point identifies a valid limitation ('the technical contribution is limited') and provides a specific example ('Section 4 is not formal and principled, but more heuristics'). This gives the author a concrete area to reflect on and potentially improve. While it doesn't offer a direct solution, it highlights a direction for strengthening their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their desire to *explore other probability mass functions* in MixBoost. This is a clear and actionable suggestion. They also mention the current limitation of the quasiuniform distribution depending on a single parameter, which is a concrete detail. While they don't name specific alternative distributions, the intention is clear and points to a specific area for improvement.", "grounding_specificity_rationale": "The reviewer grounds their comment by specifically mentioning 'MixBoost,' 'probability mass function,' and 'quasiuniform distribution.' They also suggest exploring *different distributions*, indicating a clear understanding of the current implementation. The reviewer even hints at the potential benefit of exploring different distributions, showing a level of specificity beyond just stating the problem.", "verifiability_rationale": "The reviewer offers a suggestion for improvement ('explore other probability mass functions') but doesn't present a definitive claim that requires verification. While the reviewer critiques the current method (quasiuniform distribution), the suggestion itself isn't a claim that can be immediately verified. Therefore, it leans towards 'X' (X).", "helpfulness_rationale": "The reviewer provides a clear critique of the use of a quasiuniform distribution for the probability mass function in MixBoost. They identify a potential limitation and offer a concrete suggestion for improvement ('considering various probability mass functions'). This critique is actionable and constructive, providing a direction for the authors to explore. The reviewer's suggestion is specific and points to a potential enhancement of the experimental setting."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'Missing references: the references below are relevant to your topic, especially a...'. This is an explicit action. The reviewer also suggests 'Please discuss connections with a, which uses supervised learning in QBF solving, where QBF generalizes SMT, in my understanding.' This is an explicit action to discuss connections. While the action is stated, the reviewer does not explicitly state *how* the authors should go about discussing the connections. The suggestion is vague on the implementation. Therefore, while the action is explicit, the lack of a concrete instruction makes it somewhat vague in terms of implementation.", "grounding_specificity_rationale": "The reviewer explicitly states 'Missing references: the references below are relevant to your topic, especially a...'. This clearly identifies a specific part of the paper (the missing references) and how it relates to the current topic. The reviewer also mentions a specific paper a by name. This is a clear and explicit reference to a specific section, table, figure, or unique aspect of the paper. The reviewer further specifies the *nature* of the connection they are suggesting to explore ('supervised learning in QBF solving, where QBF generalizes SMT'). This specificity helps the authors understand what aspect of the cited work is relevant. Therefore, the reviewer provides clear and explicit references to specific parts of the paper and suggests a concrete area of discussion.", "verifiability_rationale": "The reviewer states a claim: 'Missing references: the references below are relevant to your topic, especially a...'. This is a claim that the authors should engage with. The reviewer then provides a justification for this claim by stating 'Please discuss connections with a, which uses supervised learning in QBF solving, where QBF generalizes SMT, in my understanding.' This justification provides a logical reasoning and specific examples (the use of supervised learning in QBF solving and the generalization from SMT) to support the claim. The reviewer is not just stating an opinion but providing a clear rationale and specific details to back up the suggestion. Therefore, the claim is thoroughly supported by explicit, sufficient, and robust evidence.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'Please discuss connections with a, which uses supervised learning in QBF solving, where QBF generalizes SMT, in my understanding.' This directly addresses a potential weakness in the paper (the lack of discussion on supervised learning in QBF solving) and provides a concrete next step for the authors. The reviewer is not just stating a general comment but offering a specific direction for improvement. The suggestion is welljustified and provides a clear path for the authors to follow. Therefore, this advice is 5 and directly empowers the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the comparison and the metric of interest ('computation cost / running time'). This is a direct, actionable instruction for the authors to compare their method in terms of efficiency.", "grounding_specificity_rationale": "The review point does not specify which comparison the authors should make. It is a general request about comparing in terms of computation cost / running time, without pinpointing a specific aspect of the paper or a specific issue.", "verifiability_rationale": "The review point itself does not contain a claim. It is a suggestion for the authors to perform a comparison, not a statement that requires verification.", "helpfulness_rationale": "The review point directly suggests a comparison that is relevant to the efficiency and practicality of the method. It encourages the authors to consider the computational cost and running time of their approach, which is a valuable piece of feedback for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides clear suggestions and questions regarding the paper's goal in the introduction and the relevance of samplingbased Bayesian methods. They explicitly state doubts about the significance of interprocess communication and suggest focusing on problems with nondecomposable loss functions and ERMbased distributed algorithms like Hogwild. These suggestions are direct and actionable, indicating a clear understanding of potential weaknesses in the current framing and examples.", "grounding_specificity_rationale": "The reviewer's suggestions are broad and focus on general areas where the paper could be improved, such as the introduction and the framing of examples. While they suggest focusing on 'problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms such as Hogwild,' they do not pinpoint specific sections, tables, or figures within the current paper that require improvement. The grounding is more about suggesting a different focus rather than identifying a specific element within the paper.", "verifiability_rationale": "The reviewer's points are wellsupported by logical reasoning and common knowledge. They explain why they believe the examples in the second paragraph are not representative of problems requiring significant interprocess communication. They also provide a clear reasoning for suggesting alternative problem areas. While they do not provide specific external references within the review point itself, the logical arguments and the understanding of distributed optimization principles make their claims verifiable.", "helpfulness_rationale": "The reviewer's comments are valuable and directly address potential weaknesses in the paper's framing and examples. They provide clear suggestions for improvement, such as focusing on nondecomposable loss functions and ERMbased distributed algorithms. These suggestions are actionable and could significantly enhance the paper's clarity and relevance. The reviewer's insights are not merely speculative but are grounded in their understanding of the field and the limitations of the examples provided in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer asks a question about the privacypreserving aspect of the approach and provides a specific example of a traffic signal scenario. While the question is clear, the reviewer does not explicitly state what needs to be improved or how to achieve it. The lack of a concrete action or suggestion makes it less actionable for the authors.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'privacypreserving aspect of the approach' and uses the 'traffic signal control' example to illustrate their concern. This clearly identifies the specific part of the paper and provides a unique context, making it fully grounded.", "verifiability_rationale": "The reviewer states a concern about the privacy implications of the traffic signal application, which can be considered a claim. However, they do not provide any evidence, references, or logical reasoning to support this claim. The comment lacks verification methods, making it 1.", "helpfulness_rationale": "The reviewer raises a valid point about the potential privacy issues in the traffic signal application. However, they do not offer any specific suggestions, solutions, or further information to address this concern. The comment is a critique without actionable feedback, making it 2 for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment does not explicitly state how to fix the hyperlink issue. It only identifies that the hyperlink for footnote 3 and 4 does not work. The reviewer points out a problem but does not provide a concrete action for the author to take.", "grounding_specificity_rationale": "The comment explicitly mentions 'footnote 3 and 4', which are specific parts of the paper. This allows the author to directly identify the location of the problem.", "verifiability_rationale": "The comment is a statement of a problem ('the hyperlink for footnote 3 and 4 do not seem to work') and does not make a claim that requires verification or justification.", "helpfulness_rationale": "The comment identifies a problem ('the hyperlink for footnote 3 and 4 do not seem to work') but does not offer any suggestions or guidance on how to resolve it. It is a symptom, not a solution."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need to revise the modeling section and provides specific examples like 'better formalization of the architecture,' 'external parameters,' and 'misleading figure.' These are direct statements of what needs to be changed, making it explicit. Once the action is identified (improving the modeling section), the specific areas for improvement (formalization, Label Embeddings, figure) are also clearly stated, making it concrete. The reviewer directly identifies the areas needing improvement, making the action explicit and the implementation concrete.", "grounding_specificity_rationale": "The reviewer explicitly identifies the problematic section as the 'modeling section.' This is a clear identification of the specific part of the paper being addressed. Furthermore, they pinpoint specific elements within that section: 'better formalization of the architecture,' 'Label Embeddings are external parameters,' and 'misleading figure.' These are specific details about what is unclear, indicating strong grounding and specificity.", "verifiability_rationale": "The reviewer points out specific issues within the modeling section, such as the lack of 'better formalization' and the unclear status of 'Label Embeddings.' However, the reviewer does not provide any evidence or justification for *why* the formalization is lacking or *why* the Label Embeddings are presented as output. The criticism is based on observation rather than a logical deduction or a reference to external knowledge. Therefore, while the 'what' is identified, the 'why' is missing, making it 3.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as 'better formalization of the architecture' and 'revising the figure.' These suggestions are directly related to the identified issues and are intended to help the authors improve their draft. The suggestions are concrete and actionable, directly addressing the areas highlighted by the reviewer. The reviewer's intent is to provide assistance, making the point 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a limitation ('It seems like the model is limited to CTC loss') and poses a clear question ('would it be possible to train them towards attention based encdec training?'). This directly points to an actionable suggestion for improvement, making it 5. The reviewer identifies a specific area for change and asks a direct question about exploring an alternative approach, which is a clear call to action for the authors.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'CTC loss' as the current limitation and 'attentionbased encdec training' as a potential improvement. This clearly identifies the specific parts of the model training process being addressed, demonstrating strong grounding specificity. The reviewer doesn't need to infer which part of the model or training process is being discussed, as the terms are quite specific.", "verifiability_rationale": "The reviewer makes claims about the current training method (CTC loss) and suggests an alternative (attentionbased encdec training). These claims can be considered verifiable, as attentionbased encdec training is a wellestablished and understood alternative in the field. While the reviewer doesn't provide specific examples or references within the review point itself, the suggestion is based on general knowledge of training methods. Therefore, it is 3 based on external knowledge of the field.", "helpfulness_rationale": "The reviewer identifies a limitation of the current approach (CTC loss) and offers a relevant and potentially beneficial alternative (attentionbased encdec training). This directly addresses a potential constraint or a desired improvement for the model. The suggestion is clear and actionable, providing the authors with a direction for further exploration. This feedback is constructive and guides the authors towards a potential improvement, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that 'mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality...'. This is an explicit statement of a potential issue. However, the reviewer does not specify *how* these methods affect the capabilities or what specific aspects of image quality are impacted. The action is identified, but the concrete steps or modifications the authors should apply are not explicitly stated. The reviewer points out a problem but doesn't detail the solution.", "grounding_specificity_rationale": "The reviewer refers to 'image generation capabilities of diffusion models' and states that 'mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality...'. The reviewer explicitly names the area of the paper being discussed, indicating full grounding. The reviewer also specifies the *nature* of the effect by stating 'which can lead to lower image quality...', although the *specific* nature of the lower quality is not detailed. The authors can infer the specific area and the general consequence, but not the precise details of the impact.", "verifiability_rationale": "The reviewer makes a claim that 'mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality...'. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. The statement is presented as a possibility or potential issue without any backing. The claim is identified, but it lacks supporting justification or references.", "helpfulness_rationale": "The reviewer points out a potential negative impact of mitigation methods on image generation capabilities. While the issue is clearly identified, the reviewer does not offer any suggestions, guidance, or diagnostic steps for the authors to take. The feedback identifies a problem but does not provide any actionable improvements or recommendations. The authors are left with a diagnosis but no prescription."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states: \"The incorporation of such prior knowledge raises concerns about the fairness of comparisons with existing SSL methods.\" The word \"raises\" indicates a suggestion or recommendation. It doesn't explicitly tell the author what to do or how to fix it.", "grounding_specificity_rationale": "The review point mentions \"prior knowledge\" but doesn't specify *which* prior knowledge or *how* it relates to the comparisons. It's vague and doesn't pinpoint a specific section or table.", "verifiability_rationale": "The review point states a concern (\"The incorporation of such prior knowledge raises concerns about the fairness of comparisons with existing SSL methods\"). This is a declarative statement expressing a potential issue. While it's a valid concern, the review point doesn't provide any specific evidence or justification for this claim. It's a hypothesis, not a verified statement.", "helpfulness_rationale": "The review point raises a valid concern about fairness in comparisons. It points to a potential methodological issue. While it doesn't offer a solution, it identifies a problem that the authors should be aware of. It provides context and highlights a potential area for further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their surprise and confusion regarding the dominance of function words in Japanese sentences. While they are implicitly asking for an explanation, the lack of a specific action or suggestion makes it vague. The reviewer is asking *what* is happening, but not *how* to apply this knowledge to improve the draft.", "grounding_specificity_rationale": "The reviewer mentions 'Figure 1' and the terms 'function words' and 'content words', indicating some grounding. However, they do not specify which part of Figure 1 they are referring to, nor do they provide a specific example of where this dominance is observed. The specificity of the request is limited.", "verifiability_rationale": "The reviewer makes a claim by stating their surprise at the dominance of function words. However, they do not provide any evidence, reasoning, or references to support this claim. The verifiability of this statement is low as there is no basis for verification.", "helpfulness_rationale": "The reviewer points out a potential area of confusion they are experiencing with Figure 1. While this highlights a potential weakness in the draft, the reviewer does not explicitly state what is wrong with the figure or how it should be improved. The helpfulness is limited as the reviewer is not providing a direct critique or actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'FLOT cost matrix in Algorithm 1 is not defined.' This clearly identifies an action the authors should take: find the definition of the FLOT cost matrix within Algorithm 1. While the comment doesn't specify *how* to define it, it clearly points to the location where the definition is missing, making it actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'FLOT cost matrix' and 'Algorithm 1.' This allows the reviewer to directly identify the specific part of the paper where the definition is claimed to be missing. This is strong grounding as the section and table are named explicitly.", "verifiability_rationale": "The comment contains a claim: 'FLOT cost matrix in Algorithm 1 is not defined.' However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The reviewer is stating an observation based on their examination of the paper, but there's no evidence provided within the review point itself to back up the assertion that the cost matrix is indeed undefined.", "helpfulness_rationale": "The comment identifies a specific location (Algorithm 1) where a crucial definition is missing. This is a clear pointer for the authors to go and check their algorithm description. While it doesn't tell them *what* the cost matrix should be, it directs them to the relevant part of the paper. This is moderately helpful as it highlights a specific area needing attention."}
{"actionability_label": "5", "grounding_specificity_label": "Highly Grounded", "verifiability_label": "Partially Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a question and asks for a 'proof' regarding the convergence of a specific term in a mathematical equation. This is a direct and clear request for action on a specific technical detail.", "grounding_specificity_rationale": "The reviewer directly references 'Eq. (30)' and 'Eq. (27)' from specific papers. This is a very precise and specific reference, indicating a clear understanding of the location of the issue within the paper being reviewed. The reviewer is not making a general comment but rather focusing on a specific mathematical expression.", "verifiability_rationale": "The reviewer makes a claim that the second term in Eq. (30) does not trivially converge to zero and asks for a proof. While the reviewer provides some justification for their claim ('The first term in Eq. (30) does converge to 0, but it is not trivial to derive that the 2nd term in Eq. (30) also converges to 0'), the request for a proof itself constitutes a claim that needs verification. The provided justification is not a full proof or a detailed explanation of why it's not trivial.", "helpfulness_rationale": "The reviewer's question is directly related to a mathematical detail in the paper. By asking for a proof, they are highlighting a potential area of uncertainty or a point that requires further clarification. This is a valuable piece of feedback for the authors to understand and address, as it directly relates to the correctness of their theoretical analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of clarity regarding the definition of sparsity and requests specific evidence. While the request is clear, the reviewer doesn't explicitly state what action the authors should take based on this lack of clarity. The request is more about identifying a problem than directly proposing a solution.", "grounding_specificity_rationale": "The reviewer refers to 'the specific definition of the sparsity of the residual term,' indicating they are identifying a specific aspect of the paper. They also ask for evidence 'across various noisy cases,' which specifies the context of the sparsity assumption. However, the reviewer doesn't explicitly state what aspect they are referring to within the paper (e.g., a specific section or table).", "verifiability_rationale": "The reviewer makes a claim that the definition of sparsity is unclear and requests evidence. They also implicitly suggest that demonstrating the advantages of their assumptions over existing methods would be beneficial. The claim is verifiable in the sense that it points to a lack of clarity and a need for evidence. However, the reviewer doesn't provide specific references or examples to support their claim about the lack of clarity or the advantages of their assumptions.", "helpfulness_rationale": "The reviewer's comment identifies a genuine area for improvement in the paper's clarity. They are pointing out a lack of specific information and requesting more evidence. However, the comment doesn't directly propose a solution or a new experiment. It's more of a request for more information and clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that 'connectivity' is misleading, which is a direct action the reviewer is taking. They are pointing out a specific issue with the terminology used in the paper.", "grounding_specificity_rationale": "The reviewer does not explicitly name a section or table, so the grounding is not fully explicit. However, the reviewer is pointing to a specific concept \u2013 the structural connections between the brain and body \u2013 which implies a grounding in the specific area of the paper being discussed. The specificity comes from the reviewer detailing *what* they believe 'connectivity' should refer to.", "verifiability_rationale": "The reviewer makes a claim that 'connectivity' is misleading. While they don't provide direct evidence or citations to support this claim, they are implying that the lack of clarity could hinder understanding. This is a form of implicit justification, making it 3 but lacking explicit examples or references.", "helpfulness_rationale": "The reviewer directly points out a potential source of confusion for the reader by highlighting the ambiguity of the term 'connectivity'. This is a clear and actionable feedback that is likely to be helpful for the author in refining their terminology and improving clarity."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies the need for 'missing details' in 'related work', 'experiments', and 'writing'. While it points to specific areas, it doesn't explicitly state what those missing details are or how they should be added. The action is implied (adding missing details), but the specifics are missing, making it 3 but not fully concrete.", "grounding_specificity_rationale": "The review point mentions 'related work', 'experiments', and 'writing', indicating some level of grounding. However, it doesn't specify *which* details are missing within these areas. The specificity is lacking, as it only broadly states 'missing details' without pinpointing the exact nature of the gaps. This aligns with 'Weakly Grounded and UnderSpecific' as the reviewer doesn't clearly identify the missing parts or their implications.", "verifiability_rationale": "The review point makes claims about the paper being 'not polished and not ready to publish' and having 'missing details'. However, it doesn't provide any evidence or reasoning to support these claims. There are no references to external sources, logical arguments, or examples to back up the criticism. This fits the '1' category as the claims are presented without sufficient justification.", "helpfulness_rationale": "The review point is critical and points out broad areas for improvement (related work, experiments, writing) without providing specific suggestions or guidance on how to address these issues. While it identifies weaknesses, it doesn't offer concrete steps for the author to take. This makes it not particularly helpful in providing actionable feedback."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "3", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states the lack of justification for using orthogonal matrices in steps 2 and 3 of the proposed method. They point out that step 2 can be done regardless of the orthogonality of the weight matrix and suggest that this raises questions about the necessity of using orthogonal matrices. The reviewer provides a clear action for the authors: to conduct a study validating the essentialness of using orthogonal matrices rather than just following the form. The action is explicit (conduct a study) and concrete (validate the essentialness).", "grounding_specificity_rationale": "The reviewer is highly specific about the part of the method they are criticizing (steps 2 and 3 of a local window MLP) and the potential issue with step 2 (it can be done regardless of orthogonality). They also suggest a specific study to validate the orthogonality, making it clear what needs to be addressed. The grounding is explicit (which part) and the implications are clear (the potential simplification and the need for validation).", "verifiability_rationale": "The reviewer presents a claim that step 2 of the method can be done regardless of the orthogonality of the weight matrix. They provide a logical reasoning for this claim by stating that the step involves transposing the matrix, which is a wellestablished mathematical operation. However, the reviewer does not provide any external references to support this claim. While the reasoning is logical, the lack of external references makes it partially verifiable. The claim is 3 because the reasoning is present, but the lack of references weakens the support.", "helpfulness_rationale": "The reviewer's criticism is directly aimed at improving the paper by prompting the authors to conduct a specific study to validate the use of orthogonal matrices. This is a clear and actionable suggestion for improvement. The reviewer identifies a gap in the paper's justification and proposes a concrete step to address it. This feedback is 5 as it directly points to a necessary improvement in the methodology. The reviewer's comment is not just a critique but a constructive suggestion for action."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking questions about the observed trend in Figure 5 but does not explicitly state the action they want to take or the steps they believe should be applied. The questions are about 'why' and 'if' overfitting is the cause, which are exploratory rather than prescriptive. While the questions are related to the figure, the specific part of the figure being referred to is not clearly identified, making the action implicit.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 5' but does not specify which part of the figure they are referring to. They mention 'accuracy' and 'order' generally, implying they are relying on the reviewer knowing the content of the figure. The questions are broad and do not pinpoint a specific issue or aspect of the model that needs addressing within the figure. Therefore, the grounding is weak. The specificity is also low as the reviewer is not detailing a specific problem or area within the figure that requires attention.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking questions about a phenomenon observed in a figure. The presence of a claim is a prerequisite for verifiability. Since X is made, there is no evidence to verify.", "helpfulness_rationale": "The reviewer's questions are relevant and aim to understand the behavior of the model and the reasons behind the accuracy drop. By asking these questions, the reviewer is encouraging the authors to investigate further and potentially identify the cause of the issue. While the review does not directly provide actionable steps, it prompts the authors to explore the model's behavior, which can be helpful in understanding and potentially addressing the problem. Therefore, it is 3 as it encourages further analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the models and datasets are 'toylike' and provides specific suggestions for improvement, such as 'CIFAR100', 'ResNet 34 or 50', and 'ViTtiny or small'. These are all concrete actions the authors can take to enhance their experiments. The reviewer also poses a question, which can be interpreted as a request for clarification on how to apply these changes, indicating an actionoriented comment.", "grounding_specificity_rationale": "The reviewer not only identifies the models and datasets as 'toylike' but also specifically names 'CIFAR100', 'ResNet 34 or 50', and 'ViTtiny or small'. This precise identification demonstrates strong grounding. Furthermore, the reviewer addresses the 'language tasks' aspect, showing they are pinpointing a specific area for improvement, adding to the specificity of the feedback.", "verifiability_rationale": "The reviewer makes a claim: 'The models and datasets are too toylike'. This claim is supported by the common understanding that CIFAR100, ResNet variants, and ViT variants are generally considered more challenging and representative of realworld scenarios than CIFAR10. While the reviewer doesn't provide external references, the suggestion is based on established benchmarks and model architectures in the field, making it 3. The reviewer also poses a question about the challenges of applying these to language tasks, which requires further justification and indicates a degree of verifiability through logical reasoning and common knowledge.", "helpfulness_rationale": "The reviewer's comment is 5. They explicitly state a problem ('toylike' models and datasets) and provide specific, actionable suggestions ('CIFAR100', 'ResNet 34/50', 'ViT tiny/small'). The reviewer's question about language tasks is also a valuable point that prompts the authors to consider the broader applicability of their work. The suggestions are concrete and directly address the lack of realism in the current experimental setup, making the feedback 5 and relevant."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out a missing model (Vision Transformer) and raises a question about its applicability to a larger dataset (ImageNet). Both are actionable suggestions or questions. However, the suggestions are somewhat general. While \"consider Vision Transformer\" is actionable, it doesn't specify *how* to consider it. The question about selfattention layers is good but could be more specific (e.g., \"What pruning strategies are typically used for selfattention layers?\").", "grounding_specificity_rationale": "The review mentions \"Vision Transformer\" and \"larger image dataset such as ImageNet\". These are specific parts of the paper. The reviewer can *identify* the relevance of these parts, even if the paper doesn't explicitly *name* these sections. The reviewer *cannot* specify *how* to consider the Vision Transformer or *what* pruning strategies might differ. The grounding is present, but the specificity is limited.", "verifiability_rationale": "The review states that \"it is unsure if such technique is still working for larger image dataset such as ImageNet.\" This is a claim requiring justification. However, the reviewer doesn't provide any evidence or reasoning to support this claim. They are raising a question without offering any analysis or references.", "helpfulness_rationale": "The review raises a valid point about a relevant SOTA model and questions the paper's scope. However, it lacks concrete suggestions or evidence to support its claims. It's raising a *detection* of a potential gap rather than a *suggestion* to improve. The reviewer doesn't offer any specific actions or evidence to address the uncertainty about the Vision Transformer's applicability to ImageNet."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the absence of efficiency metrics, which is an implicit action that needs to be addressed. While the reviewer doesn't directly ask 'how do you show it is more efficient?', the criticism itself implies a lack of concrete evidence to support the claim of improved efficiency.", "grounding_specificity_rationale": "The reviewer explicitly identifies the missing element as 'efficiency metrics' and specifies that the paper 'does not report any metric that shows it is more efficient to train with this proposed method'. This clearly points to a specific part of the paper (the metrics section) and details the issue (lack of efficiencyspecific metrics). This is strong grounding as the reviewer can confidently identify the area of concern. The specificity is high as the reviewer clearly states what is missing.", "verifiability_rationale": "The reviewer makes a claim about the paper's lack of efficiency metrics. This claim could be considered 3 if the reviewer had direct evidence (e.g., a statement from the paper itself) to support this claim. However, the reviewer is making an inference based on the absence of such metrics in the paper's content. While the implication is that the reviewers of the paper would have noticed this, the evidence is not directly provided within this review point. Therefore, it's 3 based on the implied lack of evidence.", "helpfulness_rationale": "The review point directly points out a significant weakness in the paper: the lack of evidence to support the claim of improved efficiency. This is a crucial piece of information for the authors and is likely to be 5 in guiding them to include the necessary metrics and analysis. The criticism is specific and actionable, directly informing the authors about a missing element."}
{"actionability_label": "2", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer does not explicitly state what information they are seeking regarding the statespace, actions, and theta. They simply ask for more details. This makes it difficult for the authors to know exactly what to improve or address. The request is implied rather than explicit.", "grounding_specificity_rationale": "The reviewer does not specify which part of the paper they are referring to when asking for more details. They are making a general request. While the information they are asking for might be relevant to a specific section, the paper containing that information is not identified. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim that the statespace is finite and asks for a justification for this assumption. However, the review point itself does not provide any evidence or reasoning to support this claim. The justification is missing from the review point itself.", "helpfulness_rationale": "The reviewer is clearly trying to improve the clarity and rigor of the description of the MDP. They are asking for more details to better understand the statespace, actions, and theta. This feedback is directly aimed at helping the authors improve their draft and is therefore highly valuable."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a difference in the method's effectiveness on different types of reasoning, which could be seen as an implicit action to highlight a potential area for improvement. However, it doesn't explicitly state what needs to be changed or how to implement the improvement, making it only 2. It points out a potential area for improvement, but doesn't provide concrete steps for the authors to take.", "grounding_specificity_rationale": "The review point mentions 'general reasoning tasks' and 'mathematic reasoning' but doesn't explicitly identify a specific section, table, figure, or unique aspect of the paper where the method performs differently. Therefore, it's 1. It also doesn't specify *why* the method performs differently, so it's not specific either. The reviewer is pointing out a difference in performance across types of reasoning, not a specific flaw in a particular part of the authors' work.", "verifiability_rationale": "The review point makes a claim about the method's performance on different types of reasoning ('...does not work very effectively on general reasoning tasks compared with mathematic reasoning') but provides no evidence, examples, or references to support this claim. It states a fact about the method's performance without providing any justification or evidence. The reviewer is simply stating an observation about the method's behavior without backing it up.", "helpfulness_rationale": "The review point identifies a limitation of the method (ineffective on general reasoning compared to math reasoning) but doesn't offer any specific advice or suggestions on how to address this limitation. It's a critique rather than a helpful suggestion. The reviewer is pointing out a problem with the method but doesn't provide any constructive feedback on how to improve it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'the proof relies on a special case where a contradiction arises as matrix norms approach infinity.' They also explicitly mention the inapplicability of Theorem 1 due to normalization. This is explicit and concrete, as the reviewer clearly identifies the problematic scenario and its consequences.", "grounding_specificity_rationale": "The reviewer refers to 'Appendix A,' 'Section 3,' and 'Theorem 1.' This is a clear and specific reference to the relevant parts of the paper. They don't just say 'Section X is unclear,' they name the specific section and theorem. The reviewer also specifies what needs to be addressed in this part, namely the special case with infinite matrix norms and the inapplicability of Theorem 1.", "verifiability_rationale": "The reviewer makes a claim: 'After reviewing Appendix A, I noticed that the proof relies on a special case...'. This is a claim that *something* is happening. The reviewer provides specific details about the issue: 'a special case where a contradiction arises as matrix norms approach infinity' and 'the inapplicability of Theorem 1 inapplicable'. While the reviewer doesn't provide a definitive proof of the inapplicability, they clearly indicate the conditions under which the proof breaks down and the reason for the inapplicability. This provides a reasonable level of verifiability.", "helpfulness_rationale": "The reviewer's point is directly relevant to the proof technique discussed in Appendix A. They are pointing out a potential flaw or limitation. The reviewer clearly identifies the *specific* area of concern (Appendix A) and highlights a *specific* issue (infinite norms, contradiction, inapplicability of Theorem 1). This is 5 as it guides the authors to investigate this specific aspect of their proof."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a concrete action: replacing the variable 't' with 'the size of T' in the histogram intersection kernel. This action is directly tied to a specific part of the method description, indicating a clear intention to improve the implementation.", "grounding_specificity_rationale": "The review point refers to 'histogram intersection kernel' and specifically suggests replacing the variable 't' with 'the size of T'. While it doesn't provide a literal section number, it points to a specific variable within the method description, allowing the reviewer to identify the relevant part of the paper. This demonstrates a good understanding of the method's implementation.", "verifiability_rationale": "The review point is a suggestion for improvement based on clarity, not a claim that something is wrong with the current implementation. There is no logical reasoning, common knowledge, or external references provided to support a claim. It's a suggestion, not a critique.", "helpfulness_rationale": "The review point directly addresses a potential area for improvement by suggesting a change to enhance clarity. The suggestion is specific and actionable, directly targeting a potential weakness in the implementation. The reviewer provides a clear idea of how to make the implementation clearer."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a concern about the assumption regarding DINO embeddings, which can be interpreted as an action or suggestion (pointing out a potential limitation). While not directly proposing a solution, they are identifying a potential area for improvement. Therefore, it is considered actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"DINO representations\" and distinguishes between \"geometrically distinctive concepts\" and \"concepts where class label correlates more with semantics.\" This clearly identifies the specific aspect of the paper they are referring to, making it fully grounded. They also specify *why* they are questioning the assumption, adding to the specificity.", "verifiability_rationale": "The reviewer states a belief about DINO representations without providing any external references or logical reasoning to support it within the review point itself. They are posing a question, which requires justification, but this justification is missing. Therefore, the claim is 1 based on the information provided in this review point.", "helpfulness_rationale": "The reviewer is asking a question to gain clarification on a potential limitation of DINO embeddings. While this is a relevant and potentially helpful question, it doesn't actively propose a solution or improvement to the draft. It's more of a request for more information rather than a direct suggestion of action. Therefore, it is 3 in identifying an area for further investigation but doesn't actively improve the draft."}
{"actionability_label": "4", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the issues with specific line numbers (e.g., 'Line 029: \u2018\u2026 as it a lightweight \u2026\u2019'), providing clear actions to the authors. The suggestions, such as 'Line 188: PLN > NLP' and 'Table 3, row 2, column 3: 72,0 > 72.0', are concrete and actionable. The reviewer also provides suggestions for clarification (e.g., 'Lines 995996: the DOI number is the same as the one at lines 10011002; the link behind the title at lines 992993 points to the next paper in the list'), which further enhances the actionability.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific line numbers (e.g., 'Line 029', 'Line 188', 'Table 3, row 2, column 3') and even provides examples of repeated words ('out of cookie out of the cookie'). This clearly identifies the specific parts of the paper being addressed, indicating strong 'Full Grounding'. The suggestions for clarification and the link issue are also directly tied to these identified sections.", "verifiability_rationale": "The review point presents observations and suggestions for improvement. While there isn't a claim in the traditional sense (e.g., 'This method is definitely flawed'), the suggestions are based on common knowledge about writing and terminology. For example, 'Line 264: \u2018out of cookie out of the cookie\u2019 \u2013 some words are repeated twice' is a valid observation. The technical comment about transcription norms and the specific line numbers for PLN are also verifiable. However, the reviewer doesn't provide external references or logical reasoning to *prove* these points are incorrect, making it 2.", "helpfulness_rationale": "The review point provides specific line numbers and examples of issues, which is generally helpful for the authors to locate and address the problems. The suggestions for clarification and the link issue are also actionable. However, the lack of a clear 'claim' or definitive statement might make it slightly less impactful in terms of directly guiding the authors to a specific conclusion."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'M and N are used without definition,' which is a clear indication of an actionable issue. While the reviewer also suggests solutions like 'Spell out F.L.T.R,' the core actionable point revolves around the lack of definition for M and N. The reviewer's suggestion to 'crossreference M and N' implies they understand the notation but lack clarity on its usage. This points to an actionable issue that needs further clarification.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 4' and 'Figure 1' by name, which demonstrates a clear grounding of the issues in specific parts of the paper. The suggestion to 'spell out F.L.T.R in figure 4' directly targets a specific element within a figure, indicating a strong grounding. The suggestion to 'crossreference M and N' also implies a connection to specific elements (M and N) within the figures, further enhancing grounding. The reviewer's comment is focused on specific, identifiable parts of the paper.", "verifiability_rationale": "The reviewer provides specific suggestions and examples. 'Spell out F.L.T.R' is a logical suggestion based on common practices. 'Figure 1 text is too small to see' is a verifiable claim that can be checked visually. The suggestion to 'crossreference M and N' is also a logical and verifiable action. The reviewer's statements are based on direct observation and common sense, making them 5.", "helpfulness_rationale": "The reviewer offers specific, actionable suggestions and even a concrete solution ('Spell out F.L.T.R'). This directly addresses the identified issue of confusing notation. The suggestions are practical and directly improve the clarity of the paper. The reviewer's comments are directly aimed at resolving the identified problem, making them 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a potential issue with the algorithm and suggests a solution by using different symbols. This is a direct and actionable piece of feedback.", "grounding_specificity_rationale": "The comment explicitly mentions 'Algorithm 1', 'phase mixing probability', and the 'dummy variable in Phase 2'. This provides clear grounding by identifying specific parts of the paper being addressed.", "verifiability_rationale": "The comment itself is not a claim. However, it suggests a change to the algorithm, implying a potential issue that the author can investigate. Therefore, it is 2 as it points towards something that can be verified.", "helpfulness_rationale": "The comment is clear, directly points out a potential issue, and suggests a concrete solution. It is immediately actionable for the author and provides a direction for improvement. Therefore, it is 5."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states weaknesses in the 'highlevel description' and suggests improvements like a 'mathematical formulation' and a 'figure depicting the WiC task.' While the exact implementation details are not provided, the *action* of adding these elements is clear and directly actionable for the authors.", "grounding_specificity_rationale": "The reviewer identifies the *area* of the paper where improvements are needed \u2013 the 'highlevel description' and the 'figure.' While they don't name specific sections or tables, they clearly point to the *type* of content and visual elements that require attention. This allows the authors to infer the specific location. The reviewer also describes the *nature* of the desired changes \u2013 a 'mathematical formulation' and a 'figure depicting the WiC task.' These are specific *types* of improvements, even if the exact implementation details are not provided.", "verifiability_rationale": "The reviewer makes a claim: 'a more detailed (e.g. mathematical) formulation, for example in the appendix, would be helpful as well as depicting sentiment analysis, it does not align with the main contribution of the paper, improvements on the WiC task. Maybe reworking the figure to depict the WiC task would help with both problems.' This is a clear statement of opinion and a suggestion for improvement. The reviewer suggests a mathematical formulation and a figure depicting the WiC task. While they don't provide external references for these specific improvements, they are logical suggestions based on common practices in the field (mathematical formulations for clarity and structure) and the paper's focus on the WiC task. The suggestion to *rework* the figure to align with the task is also a logical suggestion.", "helpfulness_rationale": "The reviewer provides clear suggestions for improvement, directly addressing potential weaknesses in the highlevel description and the figure. They suggest adding a mathematical formulation and redesigning the figure to depict the WiC task. These are concrete actions the authors can take to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment identifies the need for additional benchmarking tasks but does not specify the action to be taken or how to implement it. It is explicit about the *what* but lacks detail on the *how*.", "grounding_specificity_rationale": "The review point is very general and does not refer to a specific part of the paper or identify the issue clearly. It makes a broad suggestion without pinpointing the location or nature of the problem.", "verifiability_rationale": "The review point is a suggestion, not a claim that requires verification. It does not state something is correct or incorrect, better or worse.", "helpfulness_rationale": "The comment identifies a potential weakness (lack of diverse benchmarking tasks) and offers a suggestion to address it. While it lacks specific guidance, it points towards a valuable improvement and is better than *no* feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for a comparison of YOSO and Linformer on iterationwise convergence, which is a specific and actionable request. It also asks for an explanation of the performance difference in downstream tasks, which is a request for a specific analysis. While the request for the missing comparison in Figure 4 is actionable, the reviewer doesn't explicitly state what *should* be in the figure, making it only implicitly actionable. The request for an explanation is also implicitly actionable.", "grounding_specificity_rationale": "The reviewer refers to 'YOSO takes linformer as baselines' and 'Figure 4', indicating a clear identification of the specific part of the paper and the issue being addressed. They also point out a discrepancy in performance, further specifying the nature of the problem.", "verifiability_rationale": "The reviewer makes a claim that the pretraining experiment part does not provide steps vs ppl of Linformer with YOSO in Figure 4. They also claim that Linformer demonstrates better accuracy in downstream tasks and ask for an explanation. These are claims that require verification. The verification methods are logical reasoning (asking for the comparison) and common knowledge (referring to Linformer's performance).", "helpfulness_rationale": "The reviewer's questions directly address potential weaknesses in the paper (missing information in Figure 4, performance discrepancy) and suggests concrete actions (compare, explain). They also imply a need for a deeper understanding of the results. The request for an explanation is particularly valuable for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer poses questions about the optimality of the policy gradient method and suggests clarifying a point. While these questions are relevant, they do not directly instruct the authors on how to improve their draft. The reviewer is asking for a judgment and a request for clarification, which are implicit actions rather than explicit ones. Therefore, this review point is 2 as it requires the authors to take further steps to address the concerns.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Eq. 6' and 'Eq. 5' when questioning the optimality of the policy gradient method. They also mention 'Line 132' and 'd\u03c0(s)' when pointing out a potential ambiguity. This clear identification of specific parts of the paper demonstrates strong grounding specificity. The reviewer is not just stating a general concern but pinpointing where the potential issue lies.", "verifiability_rationale": "The reviewer asks a question about the theoretical properties of a method and suggests investigating it further. While the reviewer does not provide direct evidence or references within their review point, the act of asking a question that requires logical reasoning and common knowledge to address is a form of implicit verification. The reviewer is prompting the authors to consider the theoretical underpinnings, which can be supported by external knowledge or logical arguments. Therefore, this review point is 2 as it requires the authors to engage in some level of verification.", "helpfulness_rationale": "The reviewer's questions directly address a potential ambiguity in the paper and suggest clarifying a point. These questions are relevant to the content and aim to improve the clarity and understanding of the paper. While the reviewer doesn't provide a direct solution, they are asking specific questions that can guide the authors in addressing the identified issue. Therefore, this review point is 3 as it prompts the authors to engage with the content and clarify a specific point."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification on the difference between two specific types of Gaussian distributions (general vs. isotropic) within the proposed algorithm. While the request itself isn't an explicit instruction on what to do, it points to a potential ambiguity or lack of clarity in the paper's description of the algorithm. The reviewer is implicitly asking the authors to clarify this distinction in their paper. Therefore, while not directly actionable, it highlights a potential area for improvement in the paper's clarity and precision. The request is specific enough to be considered 3 in terms of identifying a need for clarification.", "grounding_specificity_rationale": "The reviewer is asking a specific question about a technical detail in the paper (the difference between general and isotropic Gaussian distributions). However, the paper itself doesn't explicitly identify the specific part of the paper where this distinction is made, nor does it clearly explain what this distinction entails. The reviewer is implicitly asking the authors to ground their discussion of this technical detail within the paper's content. Therefore, while the topic is specific, the grounding (the paper's explanation and identification of the relevant part) is lacking, making it weakly grounded.", "verifiability_rationale": "The reviewer is not making a claim or suggesting a change. They are simply asking a question about a technical detail. Therefore, according to the provided definitions, the 'verifiability' score would be 'X' as X is being made or verified.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific technical detail (the difference between general and isotropic Gaussian distributions). While this could be helpful for the authors to understand the algorithm better, it doesn't directly point them to a specific improvement they should make in their draft. The request is about understanding a specific methodological choice, which is helpful but doesn't directly guide an improvement. Therefore, it's 3 in identifying a potential area for improvement in the paper's clarity and precision, but not in directly suggesting an actionable change to the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the action of 'freezing the partitioning' and implies the need for a concrete action by suggesting 'discuss the limitations'. While it doesn't provide specific details on how to implement these actions, the action and the desired outcome are clearly identified, making it explicit and, to a degree, concrete in its intent.", "grounding_specificity_rationale": "The comment explicitly refers to 'Line 192', providing a specific location in the paper where the partitioning is discussed. This allows the authors to accurately identify the section being addressed, resulting in full grounding. The comment also clearly identifies the issue as a potential 'risk' and the desired action as 'discuss the limitations', making the specificity about the area of discussion clear.", "verifiability_rationale": "The comment itself does not contain a claim in the sense of presenting a definitive statement of truth. Instead, it points out a potential issue ('risky choice') and suggests an action ('discuss the limitations'). While the suggestion to discuss limitations can be seen as an implicit claim that the current approach needs improvement, the comment does not provide any logical reasoning, common knowledge, or external references to support this claim. Therefore, it is 1 in terms of providing concrete evidence for the need to discuss limitations.", "helpfulness_rationale": "The comment identifies a potential issue ('freezing the partitioning seems like a risky choice') and suggests a concrete action ('at least discuss the limitations'). While it doesn't provide specific details on *how* to implement this discussion or *what specific limitations* need to be addressed, it clearly guides the authors towards a specific area of improvement. The comment is actionable in the sense that it points to a problem and suggests a direction for the authors to take, making it 3."}
{"actionability_label": "Low", "grounding_specificity_label": "High", "verifiability_label": "Low", "helpfulness_label": "Low", "actionability_rationale": "The review point 'Section 5.2: What is the intent of this section' is not inherently actionable. While it implicitly suggests the authors should understand the purpose of this section, it does not provide a direct instruction or clear step for them to take based on this review. The reviewer is asking a question, not giving a command or a specific action to perform.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 5.2' and asks about its 'intent'. This directly identifies a specific part of the paper and the issue (lack of clarity about its purpose). The grounding is strong as the comment clearly pinpoints the section being discussed.", "verifiability_rationale": "The review point is not a claim that requires verification. It is a question about the intent of a section. Questions, by themselves, do not present a statement that needs to be proven true or false. Therefore, it lacks verifiability.", "helpfulness_rationale": "The review point is a question about the intent of a section. While asking about the intent can be helpful for the authors to understand the section's purpose, the review point itself does not provide concrete, actionable feedback or suggestions on how to improve the section. It's more of a request for clarification than a direct improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states several areas needing clarification: 'how the approach makes knowledge about objects interact with knowledge about verbs,' 'why it is a good idea,' and 'the overall approach.' While the reviewer identifies the *topics* for clarification, the *nature* of the problem and the *need for clarification* are not precisely defined. The request for 'how to implement the inferred action' is implicit, making it less actionable.", "grounding_specificity_rationale": "The reviewer refers to 'many aspects,' 'the interaction between object knowledge and verb knowledge,' 'the overall approach,' and 'why it is a good idea.' While these are specific areas, the reviewer does not pinpoint a specific section or table within the paper. The explanation of how these aspects interact and why the approach is a good idea is missing. The reviewer's comment is a general concern about the overall approach.", "verifiability_rationale": "The reviewer states a concern about the interaction between object knowledge and verb knowledge and the overall approach being a good idea. This constitutes a claim. However, the reviewer does not provide any evidence, examples, or references to support this claim. The statement is a question and a concern, not a claim that can be verified.", "helpfulness_rationale": "The reviewer points out a genuine gap in the paper's explanation by highlighting areas that need clarification. The reviewer identifies specific *topics* for improvement, indicating a clear *need* for better explanation. However, the *nature* of the missing information and the *benefits* of the approach are not wellexplained, making the feedback somewhat vague and less immediately actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer does not explicitly state what needs to be done, but rather asks for a definition of the threat model. While the reviewer implies that the authors should define the attacker's access, capabilities, and defender resources, this is not a direct instruction. Therefore, the action is implicit rather than explicit.", "grounding_specificity_rationale": "The reviewer explicitly states 'the threat model' as the area needing clarification, which is a clear grounding. They also specify the details they believe are missing, such as 'attacker's level of access,' 'capabilities,' and 'defender's available resources,' indicating a high level of specificity about the issue.", "verifiability_rationale": "The reviewer makes a clear claim that the threat model needs 'further clarification.' This is a verifiable statement. The reviewer also provides reasoning for this claim by stating that the current lack of definition makes it difficult to assess assumptions and suggests a solution ('defining the assumed threat model more explicitly'). This provides justification for the claim.", "helpfulness_rationale": "The reviewer's comment is 5. They clearly identify a weakness (lack of clarity in the threat model) and provide a specific suggestion for improvement ('defining the assumed threat model more explicitly'). The request for specific details about the attacker's access, capabilities, and the defender's resources makes the feedback actionable and directly addresses the authors' needs."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point directly asks a question about a specific implementation detail ('how to set a reasonable classimbalanced task?') and requests 'concrete details'. This is a clear call for action and a direct identification of a potential area of confusion. The reviewer is explicitly asking for information on how to implement something, which is a very actionable request. The request for 'concrete details' further enhances the actionability by specifying the type of information needed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'sampling classimbalanced tasks' and asks for 'concrete details'. This clearly targets a specific part of the paper and requests specific information. The request for 'concrete details' further enhances the grounding by specifying the type of information needed. The reviewer is not just pointing out a general issue but asking for specific guidance on a particular implementation aspect.", "verifiability_rationale": "The reviewer is asking for a *method* or *guidance* on setting up the experiment. While the *review point itself* doesn't present a claim that needs verification, the *act of providing concrete details* can be seen as a form of implicit verification. The request is clear and points to a specific area. The reviewer is not asking for a definitive truth but rather a practical guide, making it 2.", "helpfulness_rationale": "The reviewer is directly asking for clarification on a specific implementation detail ('how to set a reasonable classimbalanced task?') and requests 'concrete details'. This is a common and valuable type of feedback for authors. It directly addresses a potential point of confusion and provides a clear direction for the author to improve their understanding and implementation. The request for 'concrete details' makes it 5 and thus 5."}
{"actionability_label": "2", "grounding_specificity_label": "Full Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that 'we don't explain the detail on how the ground truth of sensitivity is achieved' and 'no details on how actual pruning was done'. While the reviewer identifies a missing element, the action of 'explaining the detail' is implicit rather than explicit. The reviewer points out a lack of information, but doesn't explicitly state that they are unsure how pruning was done or what the ground truth is. The action of 'identifying a missing element' is explicit, but the reviewer doesn't detail *how* this was identified. Therefore, it's borderline as the action is implicit, and the reviewer identifies a missing element but doesn't explicitly state the action of identifying it.", "grounding_specificity_rationale": "The reviewer mentions 'lines 238239' and specifically points out issues within that section. This indicates that the reviewer can identify the specific part of the paper being addressed. The reviewer doesn't mention any other parts of the paper, and the mention of lines 238239 suggests a clear understanding of the relevant section. The issues raised are also specific to the content of that section. Therefore, the reviewer can accurately pinpoint the section and the specific issues within it.", "verifiability_rationale": "The reviewer states that 'authors don't explain the detail on how the ground truth of sensitivity is achieved' and 'no details on how actual pruning was done'. This statement itself is a claim that needs to be addressed. However, the reviewer does *not* provide any evidence or justification for this claim. They are stating a problem without offering any examples, logical reasoning, or external references. Therefore, the claim is 1 as there is no supporting evidence provided.", "helpfulness_rationale": "The reviewer's comment clearly identifies a specific weakness in the paper: the lack of detail regarding the implementation of sensitivity analysis (pruning and ground truth). This is a concrete criticism that directly points to a missing piece of information crucial for understanding and potentially reproducing the work. While the reviewer doesn't offer a solution, they have highlighted a specific area needing clarification. Therefore, the comment is helpful in identifying a concrete issue."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies areas needing clarification but doesn't specify how to clarify them. The suggestions are vague.", "grounding_specificity_rationale": "The comment explicitly mentions which part of the paper it addresses (line 97 and lines 105106) and it is obvious to the authors. The comment specifies what needs to be addressed in this part (proper rotation matrix and nonpositive semidefinite).", "verifiability_rationale": "The review point identifies problems that need to be addressed but doesn't make a claim or suggestion requiring justification. It's a statement of what needs improvement, not an assertion about the paper's quality or correctness.", "helpfulness_rationale": "The review points to areas needing improvement, which is inherently helpful. It doesn't criticize the authors' work directly, but it highlights specific weaknesses that need addressing. While it lacks explicit actionability and a claim, it's not entirely useless."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests an alternative term ('binary operator') for the 'g' symbol. While the suggestion is directly stated ('not call g activation function'), it lacks a concrete explanation of why this change would be beneficial or how it would address any identified weaknesses. The reviewer proposes a specific alternative ('binary operator'), which is more concrete than simply suggesting a different term. However, the lack of a clear connection or benefit makes the action somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Cohen and Shashua, 2016' when suggesting the alternative term. This clearly grounds the suggestion in an existing work, making it easy for the authors to understand the context. The suggestion also specifies the alternative term ('binary operator'), which further enhances grounding.", "verifiability_rationale": "The reviewer proposes 'binary operator' as an alternative to 'g activation function'. This constitutes a claim that needs to be supported. The reviewer draws a parallel to 'activationpooling operator' in Cohen and Shashua, 2016, which provides some justification. However, the explanation of why 'binary operator' is a better or necessary change is brief and relies on the analogy. The connection to the specific weaknesses of the current work is not explicitly made, and the reasoning is not fully detailed.", "helpfulness_rationale": "The reviewer's comment primarily focuses on suggesting a change in terminology ('binary operator' instead of 'g activation function'). While this could potentially improve clarity for some readers, it does not directly identify a weakness in the authors' current work or propose a concrete improvement. The comment is more about suggesting an alternative way of thinking about the concept rather than providing actionable feedback for improvement. Therefore, it is not particularly helpful in guiding the authors to enhance their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action (identifying a missing citation) and provides concrete details on how to implement it (mentioning the specific paper).", "grounding_specificity_rationale": "The comment explicitly mentions the missing citation (Vidgen et al, 2021) and the potential similarity to the current dataset. It also identifies the issue as the absence of this dataset as a benchmark. The grounding is explicit as the paper is mentioned. The specificity is high as it clearly states the potential similarity and the missing benchmark status.", "verifiability_rationale": "The comment presents a claim (this dataset should be used as a benchmark) and provides a justification (potential similarity). The reasoning is logical, and the reference to the varying size is a supporting detail.", "helpfulness_rationale": "The review point identifies a missing citation and raises a valid question about the absence of a similar dataset as a benchmark. This provides the authors with concrete information and a point of discussion that could lead to a better understanding of their work's context and potential limitations. The reviewer is directly addressing a core aspect of their work (dataset selection and benchmarking) and offering actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a weakness in the proposed approach (reliance on traditional FEM components) and suggests an alternative (operator learning). While this points to a potential area for improvement, the criticism is somewhat general and doesn't pinpoint a specific actionable step within the proposed approach itself. The reviewer suggests operator learning as a more universal and adaptable method, but doesn't explicitly state how the proposed approach can be modified to incorporate these elements. Therefore, while the reviewer points out a limitation, the lack of concrete suggestions on how to improve the approach makes it 3 but not entirely clear on the next steps.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'basis functions,' 'meshes,' and 'stiffness matrix assembly' as components that the proposed approach still requires. These are specific technical terms within the context of Finite Element Methods (FEM). Furthermore, the reviewer mentions 'FEniCS,' a specific software used for FEM computations. This strong use of specific terminology clearly grounds the criticism in the technical details of the proposed approach. The reviewer also mentions 'operator learning methods' as an alternative, which is a specific concept within the field of machine learning for solving PDEs. This demonstrates a clear understanding of the specific context and techniques being discussed.", "verifiability_rationale": "The reviewer makes claims about the proposed approach, stating that it 'still requires carefully choosing basis functions and meshes and assembling stiffness matrices.' They also suggest that 'operator learning methods can not yet achieve the same accuracies as specialized numerical solvers.' While the reviewer doesn't provide specific examples or references to support these claims within this review point, the general understanding in the field is that traditional FEM implementations can be complex and require significant expertise. The comparison to operator learning methods is a generally accepted concept in the field. Therefore, the claims are generally verifiable based on common knowledge, although specific evidence is lacking within this review point itself.", "helpfulness_rationale": "The reviewer provides a critique of the proposed approach, highlighting its reliance on traditional FEM components and suggesting operator learning as a more universal alternative. They also point out the 'universality and adaptability' of operator learning as advantages. While this offers some guidance for improvement, it is primarily negative and focuses on what the approach *doesn't* offer rather than directly suggesting concrete, actionable improvements. The reviewer doesn't provide specific, detailed steps the authors should take to implement operator learning or adapt the current approach. Therefore, while the review points towards a potential direction for improvement, it doesn't offer a direct, constructive solution for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a fact and expresses an opinion. It's not a direct instruction on *what* to change. While the reviewer states a problem, they don't offer a specific *how* to address it. They don't suggest alternative datasets, methods, or analysis techniques. The reviewer points out a limitation but doesn't provide actionable steps to address it.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"realistic datasets\" and \"multiple aspects of variation.\" They also clearly specifies what is meant by \"multiple aspects of variation\". The reviewer also explicitly states the irrelevance of 'societal impact\". The author can accurately pinpoint the section, table, figure, or unique aspect being addressed.", "verifiability_rationale": "The reviewer makes a claim about the difficulty of using realistic datasets and a claim about the lack of societal impact. The reviewer doesn't provide any evidence or reasoning to support these claims. They are stating their opinion without backing it up. The comment contains a claim without any supporting evidence or justification.", "helpfulness_rationale": "The reviewer provides relevant information about the challenges of using realistic datasets and the lack of societal impact. However, they do not offer any concrete suggestions or actionable steps for the authors to improve their draft. The feedback is informative but lacks the necessary guidance to be truly helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the suggestion to mention the evaluation metric and its benefit for clarity. This is a direct and specific action. The reviewer is not inferring what needs to be done, but rather pointing out a potential improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'For clarity, it would be better if the evaluation metric is mentioned here'. This clearly identifies the specific part of the paper (the evaluation section) being addressed. The reviewer is not making an inference about what needs to be clearer.", "verifiability_rationale": "The reviewer makes a claim that mentioning the evaluation metric will improve clarity. However, the reviewer does not provide any specific evidence or references to support this claim. While the suggestion is reasonable, the lack of supporting evidence makes it 2. The reviewer could have provided examples of how mentioning the metric would help, but they did not.", "helpfulness_rationale": "The reviewer provides a suggestion aimed at improving clarity and understanding. While the suggestion is general, it directly addresses a potential area of confusion for the authors. The reviewer is not making a claim, but rather offering a potential improvement. The helpfulness is moderate because the suggestion could be more specific."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests 'studying the behaviour of the model under higher noise.' This is a clear and direct action that the authors can readily implement. The suggestion is not implicit but rather explicit about what needs to be done. Furthermore, the suggestion is concrete, indicating exactly how they should approach this by conducting the simulation study with higher noise levels.", "grounding_specificity_rationale": "The reviewer refers to 'the observations in the plot compared to the true trajectories.' This is a very specific reference point. The reviewer is directly pointing to a visual element (the plot) and comparing it to another element (the true trajectories). This allows the authors to precisely identify the area of concern.", "verifiability_rationale": "The reviewer states that the standard deviation of the noise is 3 but finds it 'not very high' based on the observations in the plot. While the reviewer identifies a potential issue (the perceived noise level), they do not provide any external references or logical reasoning to *prove* that the noise is indeed 'not very high'. The claim is based on an observation rather than verifiable evidence. Therefore, it is 3 as it has some justification but lacks key elements like examples or references.", "helpfulness_rationale": "The reviewer suggests a specific experiment ('studying the behaviour of the model under higher noise') that directly relates to the identified issue (the perceived noise level). This provides a clear direction for the authors to take. While the suggestion doesn't offer a definitive solution or quantify 'not very high', it is a valuable contribution that can help the authors improve their understanding of the model's behavior. The suggestion is actionable and directly addresses the identified problem."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point states a fact about the limitations of the approach (limited applications for arbitrarily long inputs). However, it does not provide any specific actions or clarifications for the authors on how to address this limitation. The reviewer identifies a problem but doesn't offer a solution or a clear direction for improvement.", "grounding_specificity_rationale": "The review point mentions 'arbitrarily long inputs' but does not specify which part of the paper or what exactly is problematic. The description is vague and lacks precise grounding in the paper's content.", "verifiability_rationale": "The review point makes a claim about the limitations of the approach for arbitrarily long inputs. However, the review point itself does not provide any evidence or justification for this claim. The lack of specific examples or references makes it difficult to verify the claim within the scope of just evaluating the given review point.", "helpfulness_rationale": "The review point identifies a limitation of the approach (limited applications for arbitrarily long inputs) but does not offer any suggestions or further analysis to address this limitation. The feedback is primarily a negative statement about the approach without any constructive recommendations for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1 and Specific", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point is a question prompting further investigation into the performance of DVP on video with different lengths. While it implicitly suggests exploring this aspect, it doesn't explicitly state an action or modification the authors should take. The authors would need to decide for themselves what to do next, making it not fully actionable.", "grounding_specificity_rationale": "The review point is a general question about the performance of DVP on video with different lengths. It does not specify which part of the paper is being referred to or what specific issue is being addressed. The authors would need to interpret the question and identify relevant sections, making it 1 specifically.", "verifiability_rationale": "The review point is a question, not a declarative statement that requires verification. It doesn't present a claim that needs supporting evidence. Therefore, it doesn't inherently meet the criteria for verifiability.", "helpfulness_rationale": "The review point is a relevant question for researchers working with video data and models. It prompts the authors to consider the impact of video length on DVP's performance, which can be a valuable direction for their work. While it doesn't directly provide a solution, it encourages further exploration and thought, making it 3 in guiding their research."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The reviewer's statement indicates a desire for clarification regarding the type of cloze queries the paper targets. While not explicitly stating an action, the confusion suggests the reviewer needs more information to understand the paper's scope. The lack of a clear statement on whether the paper focuses on singletoken or multitoken cloze queries creates an implicit action for the reviewer: to seek further clarification from the authors or the paper itself. This implicit action, while not directly stated, demonstrates a need for more information, making it 3.", "grounding_specificity_rationale": "The reviewer's statement about the paper targeting singletoken or multitoken cloze queries is 1 in a specific section or table of the paper. They are making a general statement about the paper's focus without providing a direct reference. The statement is also specific in its topic (cloze query type) but lacks grounding by referencing the relevant section or table where this information is typically found. Therefore, the grounding is weak as the authors would need to search the paper to find the relevant information.", "verifiability_rationale": "None", "helpfulness_rationale": "The reviewer explicitly states they were confused about the paper targeting singletoken or multitoken cloze queries and that this confusion wasn't resolved until reading the conclusion. This directly indicates that the review point was helpful in clarifying a key aspect of the paper for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue (ignoring the KLdivergence term) and provides a clear direction for improvement (calculate and check if it approaches zero). This is an explicit and concrete action that the authors can readily implement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3.3' and 'equation (3)', which allows the authors to accurately pinpoint the relevant part of the paper being discussed. This is a clear and direct grounding of the comment.", "verifiability_rationale": "The reviewer makes a claim about the proposed training objective ignoring the KLdivergence term. They also provide a specific method for verification: calculating the actual KLdivergence and checking if it approaches zero. This provides a clear and verifiable way to assess the claim, making it highly verifiable.", "helpfulness_rationale": "The reviewer identifies a potential issue in the proposed method and offers a constructive suggestion for improvement. By asking the authors to evaluate the approximation error of ignoring the KLdivergence term, the reviewer provides a concrete direction for the authors to assess the impact of this omission. This is a 5 and actionable comment for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of connection between Section 2 and the methodology. While this is a valid observation, the reviewer does not explicitly state how to improve the connection. The action is implied but not explicitly stated. The reviewer also mentions the 'simplistic theoretical analysis' but does not provide specific details on what makes it simplistic. The action is implied but not explicitly stated. Therefore, the comment identifies a problem but lacks specific guidance on how to address it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 2' and 'methodology section' when pointing out the lack of connection. This is a clear identification of the specific part of the paper being addressed. However, the reviewer does not specify *what* is wrong with the connection or the theoretical analysis. The grounding is explicit, but the specificity of the identified issue is low. The reviewer mentions the 'simplistic theoretical analysis' but does not provide specific examples of what is simplistic. The grounding is explicit, but the specificity of the identified issue is low.", "verifiability_rationale": "The reviewer makes the claim that 'Section 2 shows limited connection with the methodology section.' This is a claim that can be verified by examining the content of Section 2 and the methodology. The reviewer also states that the 'theoretical analysis is somewhat simplistic and closely related to 1'. The 'somewhat simplistic' claim is 3 by assessing the complexity of the analysis. The claim that it is 'closely related to 1' is verifiable by checking the cited work. Therefore, the claim is verifiable, but the level of verifiability depends on the interpretation of 'somewhat simplistic' and the need to verify the connection to 1.", "helpfulness_rationale": "The reviewer points out the 'lack of connection' between Section 2 and the methodology and the 'simplistic theoretical analysis.' While these are valid observations, the reviewer does not provide specific suggestions or actions on how to improve the connection or address the simplicity. The comment identifies weaknesses but lacks concrete guidance on how to fix them. The comment identifies weaknesses but lacks concrete guidance on how to fix them. The comment identifies weaknesses but lacks concrete guidance on how to fix them."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question and suggests a potential area of discussion. This seems *implicitly* actionable. The reviewer is prompting for more analysis of a specific scenario.", "grounding_specificity_rationale": "The reviewer *mentions* 'specular areas\" but doesn't explicitly point to a specific section, table, or figure in the paper. The connection to \"losses\" is also implied. Therefore, the grounding is weak. While the *topic* is 'specular areas\" and \"losses,\" the *specificity* within these topics is low. The reviewer doesn't indicate whether they're referring to surface normals, material properties, or specific loss functions.", "verifiability_rationale": "The review point asks a question and suggests a potential area of discussion. This does not contain a claim that needs verification. It is a suggestion for further exploration.", "helpfulness_rationale": "While the review point asks about \"losses\" and suggests discussing them in the context of 'specular areas,\" it doesn't provide a concrete, actionable step for the author to improve their draft. It's a helpful suggestion for *future work or deeper analysis*, but not a direct improvement to the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points to a problem but lacks a clear, actionable step. It's vague and doesn't specify how the authors should go about identifying the contributions. While the authors gain some insights, the feedback does not fully address their needs for improving the draft.", "grounding_specificity_rationale": "The review refers to \"major contributions\" generally without pinpointing a specific section or element of the paper. It specifies the *type* of contribution but not the *location* within the paper.", "verifiability_rationale": "The statement is an opinion without supporting evidence. While the authors gain some insights, the feedback does not fully address their needs for improving the draft.", "helpfulness_rationale": "The review raises a valid point but offers a suggestion that is likely to be confusing and unhelpful. While the authors gain some insights, the feedback does not fully address their needs for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment asks a question, 'Will the code be public available.' It does not explicitly state what the authors should do in response to this question. It is a question, not a directive that tells the authors what to do.", "grounding_specificity_rationale": "The comment is about the reproducibility of results and code availability. It does not specify a particular section, table, figure, or unique aspect of the paper that is being questioned. It is a general question about the research process.", "verifiability_rationale": "The comment is a question, not a statement that makes a claim. It does not present a judgment, suggestion, or require justification. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The comment raises a valid concern about code availability, which is relevant to the authors. However, it is a question and does not provide specific, actionable advice on how to address this concern. It lacks the explicit suggestions or concrete steps that would make it 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a concrete action: 'extend the protected feature A to a vector form'. This action is further specified by the suggestion to represent the feature as a vector, which implies a structured way to handle multiple attributes. This directly points to a modification the authors could make to their draft.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. While it refers to 'protected feature A', it does not pinpoint where this feature is defined or used within the paper. The suggestion is general and does not specify the context or implications of extending it to a vector form.", "verifiability_rationale": "The review point is a question, not a statement making a claim. It is asking for a suggestion rather than asserting something about the paper. Therefore, it does not have verifiability in the sense of supporting a claim.", "helpfulness_rationale": "The review point is 5 as it directly suggests a concrete modification to the authors' work. By proposing to extend a feature to a vector form, it provides a clear direction for potential improvement. While it doesn't explain *why* this is beneficial or how to implement it beyond the vector form, it is a valuable suggestion that empowers the authors to make a change."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification on the notation used for vector representations (x and t), and requests information about L2 normalization and the similarity metric (cosine or dotproduct) used in the process. This provides clear guidance on implementation details, making it actionable.", "grounding_specificity_rationale": "The review point explicitly mentions specific elements of the paper being addressed: 'x and t in this equation (and following ones)', 'L2normalized', and 'nearest neighbor\u2019 examples'. This demonstrates strong grounding as the reviewer can directly identify the referenced parts. It also specifies what is being asked about within those parts.", "verifiability_rationale": "The review point poses a question seeking information that is likely available in the paper's methodology section or would require external knowledge (like the definition of L2 normalization and cosine/dot product). While it doesn't directly state a fact, it points to areas where the authors might need to look for clarification, making it 3.", "helpfulness_rationale": "The review point is a question seeking clarification on implementation details. While this is valuable for the authors to understand the method better, it doesn't directly identify a weakness in the paper or suggest a concrete improvement. Therefore, it is 3 in the sense that it prompts the authors to seek more information, but it doesn't directly guide them on how to improve their work."}
{"actionability_label": "borderline actionability", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly names specific locations in the paper (Figure 2, Line 433, and Line 468). However, it does not specify the *action* to be taken at these locations. The reviewer asks the author to 'check' these locations, which implies the author needs to review or analyze them further, but the exact method of checking is not provided. Therefore, it is 2.", "grounding_specificity_rationale": "The review point explicitly names specific sections and lines of the paper (Figure 2, Line 433, and Line 468). This clearly grounds the issue within the document. The reviewer also states the action to be taken, which is to 'check' these locations. This action is specific to the identified parts. Therefore, it is 5.", "verifiability_rationale": "The review point does not contain a claim or assertion. It is a directive to the author to check specific locations. There is no logical reasoning, external references, or common knowledge being presented. Therefore, it is not verifiable, and the label is X.", "helpfulness_rationale": "The review point identifies potential issues by directing the author to specific locations and asking them to check them. This points to areas for further scrutiny and encourages the author to engage more deeply with the paper. While it doesn't provide explicit solutions, it highlights potential problems, making it 3. It lacks the detailed guidance of a more helpful review."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "Explicitly states an action (identifying a similarity) but is vague on how to execute it (how to address the similarity).", "grounding_specificity_rationale": "Authors cannot confidently determine which part the comment addresses. The comment is about the overall technical contribution, not a specific detail.", "verifiability_rationale": "The claim is subjective ('limited'). While the *reasoning* for this judgment (the similarity) is present, the conclusion itself is a subjective claim that lacks concrete evidence or justification within the review point itself.", "helpfulness_rationale": "Identifies weaknesses and offers some improvement area, but lacks depth or specific guidance on how to improve. The suggestion is vague and doesn't point to a specific area of improvement or how to differentiate the proposed method from existing ones."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out a potential issue but lacks explicit and concrete steps for improvement. It states a belief but doesn't provide actionable steps.", "grounding_specificity_rationale": "The review refers to a general concept without pinpointing a specific part of the paper. It doesn't explicitly mention a section, table, figure, or unique element of the paper.", "verifiability_rationale": "The claim about the source of the \"highlight\" lacks specific references or evidence. The reviewer offers a *possible* source but doesn't *prove* it.", "helpfulness_rationale": "The review raises a concern without providing concrete solutions or evidence. It doesn't offer actionable guidance or evidence to help the authors improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "1", "actionability_rationale": "The review point criticizes the statistical significance of the evaluation results but does not provide any explicit or actionable steps for the authors to take to address this issue. It points out that the results are not significant and that the deviations are likely due to the small sample size. However, it does not specify which statistical tests were used, which baseline was compared, or what specific aspects of the evaluation were performed. Therefore, the authors are left without clear guidance on how to improve their draft based on this feedback. The criticism is about the *outcome* of the evaluation rather than providing a *solution*.", "grounding_specificity_rationale": "The review point mentions 'evaluation results' and 'baseline' but does not specify which part of the paper or experiment is being questioned. It refers to the results in a general sense without pinpointing the exact area of concern. For example, it doesn't specify if the issue lies in the experimental setup, the data analysis, or the interpretation of the results. This lack of specificity makes it difficult for the authors to understand the exact nature of the problem. Therefore, while the comment identifies a potential issue, it doesn't clearly ground the criticism in a specific part of the paper or experiment.", "verifiability_rationale": "The review point makes a claim: 'statistically this is not significant' and 'that is why that in many cases the deviation is 0.' This claim is verifiable based on general statistical principles. Statistical significance is a wellestablished concept, and the reviewer is relying on the understanding of sample size requirements and the interpretation of standard deviations. The reasoning is based on the understanding that a small sample size can lead to results that are not statistically significant. Therefore, the claim is supported by logical reasoning and common knowledge in the field of statistics. The reviewer is not introducing new external references to support this claim.", "helpfulness_rationale": "The review point is critical and does not offer any constructive feedback or suggestions. It points out a potential problem with the evaluation but does not propose a solution or guide the authors on how to address it. The criticism is about identifying a flaw in the evaluation process rather than offering a path to improvement. Therefore, the review point does not provide any helpful information to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the need to compare with two relevant papers, making the action clear. However, it doesn't specify the exact features or methods for comparison, making it only partially actionable. The action is to identify the papers, but the concrete steps for comparison are missing.", "grounding_specificity_rationale": "The reviewer mentions 'two relevant papers' as the grounded part. While the specific sections, tables, or figures within those papers that are relevant are not explicitly identified, the paper itself is identified. Therefore, it can be considered weakly grounded as the authors can infer the need to look at prior work. However, the specificity within the grounded part is lacking as the exact sections or details are not mentioned.", "verifiability_rationale": "The comment contains a claim that a feature comparison is lacking. However, it doesn't provide specific examples of what is missing or suggest any external references to support this claim. The reasoning is present (identifying a weakness), but the evidence is lacking, making it only 3.", "helpfulness_rationale": "The comment identifies a clear weakness: the lack of a feature comparison with prior work. This is a relevant piece of feedback that could help the authors improve their draft. However, the comment doesn't provide specific suggestions on how to perform this comparison, making the help somewhat general and potentially less impactful. The feedback is present but lacks specific guidance."}
{"actionability_label": "3.2", "grounding_specificity_label": "3.2", "verifiability_label": "3.2", "helpfulness_label": "3.6", "actionability_rationale": "The reviewer identifies a problem (lack of understanding) and highlights the issue (dominance of one view). While they don't explicitly state what actions they would take, the identification of a gap in understanding is actionable. The reviewer suggests that the single empirical example might be expanded, implying a desire for more specific guidance on how to use the other views. However, the reviewer doesn't provide concrete steps on how to understand the approach or utilize the other views effectively.", "grounding_specificity_rationale": "The reviewer mentions 'almost all across the board, the paraphrase similarity view does significantly better than other views and their combination' and 'there is one empirical example of how the different views help in clustering paraphrases of the word 'slip', but there is no further analysis about how the different clustering techniques differ, except on the task directly.' While the reviewer mentions multiple views, they don't explicitly name the specific sections, tables, or unique aspects of the paper they are referring to. The lack of a clear connection to specific parts of the paper weakens grounding specificity. The reviewer also doesn't specify how the different clustering techniques differ, which is a key aspect of grounding.", "verifiability_rationale": "The reviewer states a fact: 'almost all across the board, the paraphrase similarity view does significantly better than other views and their combination.' However, they don't provide any logical reasoning, common knowledge, or external references to support why this is a problem or what we learn about the usefulness of the other views. The reviewer describes the *what* (the results) but not the *why* or *how* it relates to the core contribution (the other views). The lack of justification makes the claim somewhat underspecified.", "helpfulness_rationale": "The reviewer clearly states a problem: 'I don't understand effectiveness of the multiview clustering approach.' They also provide a limited empirical example of how the different views help in clustering paraphrases of the word 'slip'. While this example is informative, it's not comprehensive and doesn't offer significant guidance on how to improve the clustering approach beyond the single example. The reviewer expresses a lack of understanding and a desire for more analysis, but they don't offer concrete suggestions for improvement or further analysis beyond the existing example."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem ('it sounds unreasonable...') and suggests a concrete action ('providing more detail'). This is an explicit and actionable step for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions the discrepancy between their results and the paper by Ni et al., and also points to their 'Wikipedia experiments' as the relevant part of their own work. This is a fully grounded reference to a specific aspect of their paper. The reviewer also clearly specifies the nature of the discrepancy ('increasing model size can hurt the performance') and suggests a specific action ('providing more detail').", "verifiability_rationale": "The reviewer makes a claim ('It sounds unreasonable...') and provides a potential explanation ('as recent paper Ni et al. shows that the scaling law is also apply to dense retrieval model, so the preliminary experimental results on Wikipedia about model size should be provided in detail'). This claim is supported by suggesting a source of information ('Ni et al. paper') and a specific area of their own work ('Wikipedia experiments') to investigate the issue. While not a full, detailed explanation, the reviewer provides a path for the authors to explore the discrepancy.", "helpfulness_rationale": "This review directly addresses a potential issue the authors might be facing (performance decrease with increased size) and suggests a concrete next step (providing more detail). This is immediately helpful for the authors to understand and potentially resolve their experimental results."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly mentions specific elements of the paper that are problematic, such as 'Figs 1&2', 'tables with a \"\"', and the 'Dataset' column. While the reviewer doesn't provide specific instructions on *how* to fix these issues, they clearly identify the *areas* that need improvement. This indicates a degree of actionability, as the authors are pointed towards specific sections and elements.", "grounding_specificity_rationale": "The reviewer explicitly names specific parts of the paper, such as 'Figs 1&2', 'tables with a \"\"', and the 'Dataset' column, which are all unique and identifiable sections within the paper. This demonstrates strong grounding specificity, as the authors can directly locate the issues being referred to.", "verifiability_rationale": "The reviewer states that these presentation quality issues are 'a weakness for a high quality publication' and provides examples like 'Figs 1&2', 'tables with a \"\"', and the 'Dataset' column. This statement is a claim that can be verified by examining the paper's formatting, table structure, and dataset description. The reviewer provides evidence (the specific elements mentioned) that supports their claim.", "helpfulness_rationale": "The reviewer directly points out areas where the paper falls short for a highimpact venue, specifically mentioning presentation quality issues. This is a clear and actionable feedback that is intended to help the authors improve their draft. The reviewer's statements are not vague or general, but rather specific to certain parts of the paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their curiosity about 'related experiments' that the 'information axis tool' can help with. This directly suggests a concrete action the authors should take: investigate and design experiments related to the information axis tool. The suggestion is specific and actionable, indicating a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer refers to the 'conclusion' of the paper when discussing the justification for the information axis. While they express a desire for 'related experiments,' they don't explicitly point to a specific section, table, or unique aspect of the paper where the analysis of the information axis is detailed. The reviewer's statement is general and doesn't provide precise grounding within the paper's content.", "verifiability_rationale": "The reviewer's statement is a statement of interest and curiosity, not a claim that requires verification. They are not pointing out a specific flaw or missing element in the paper. Therefore, there is X to be evaluated for its verifiability.", "helpfulness_rationale": "The reviewer's suggestion to explore 'related experiments' that the 'information axis tool' can help with is a valuable direction for the authors to consider. While it doesn't directly identify a specific error or improvement, it encourages them to think about how the information axis tool can be applied in different experimental contexts. This suggests a helpful avenue for exploration and refinement of their work, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitation of considering only one truck and one drone and suggests extending the work to multiple trucks and drones. While the reviewer doesn't provide specific details on how this extension would be implemented, the action of identifying the limitation and suggesting a direction for improvement is clear and actionable for the authors. The reviewer also implies that this extension would be a more interesting and practical setting, which can guide the authors in their future work.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'ONE truck' and 'ONE drone' when describing the current scope of the work. This clearly identifies the specific part of the paper being addressed. The suggestion to 'extend to multiple trucks and drones' further specifies the area for improvement. The grounding is strong as the reviewer accurately pinpoints the sections being discussed, and the specificity is high as the suggestion directly relates to the identified parts.", "verifiability_rationale": "The reviewer makes a claim about the current limitation of considering only one truck and one drone and suggests that extending to multiple trucks and drones would be 'easy' and a more 'interesting and practical setting'. While the reviewer identifies a valid point for improvement, the claim about the 'easy' extension lacks specific justification or references. The reasoning is present but could be more detailed and supported by examples or citations. The claim itself is verifiable as it points to a logical progression in complexity, but the lack of concrete evidence makes the verifiability somewhat lower.", "helpfulness_rationale": "The reviewer's comment identifies a limitation in the scope of the work (focusing on a single truck and drone) and suggests a potential direction for future work (extending to multiple trucks and drones). This is a valuable observation that highlights an area for improvement. However, the reviewer does not provide specific reasons or evidence to support the claim that this extension would be 'easy' or a 'more interesting and practical setting'. Without this additional detail, the comment is helpful in pointing out a scope issue but lacks the immediate actionable guidance that would make it fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states 'limited novelty' and 'more or less just follows the strategies used in ELECTRA'. This indicates an action, which is to question the originality of the approach and compare it to ELECTRA's methods. However, the action is not very specific, as it doesn't detail *what* aspects are lacking novelty.", "grounding_specificity_rationale": "The comment refers to 'the strategies used in ELECTRA' which is a specific reference to a prior work. However, it does not specify *which* particular aspect or component of the ELECTRA strategy is being compared or where the lack of novelty is evident in their own approach. The grounding is present but not very specific.", "verifiability_rationale": "The comment makes a claim about the 'novelty' of the approach. However, it does not provide any specific evidence, reasoning, or references to support this claim. It presents an opinion without backing.", "helpfulness_rationale": "The comment identifies a potential weakness ('limited novelty') but does not offer any concrete suggestions or actions for the authors to take. It simply criticizes the approach without proposing improvements."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the perceived lack of motivation for the Newton algorithm in section 4 and provides a concrete suggestion for improvement by comparing it to a 1dimensional line search. While the reviewer doesn't provide specific details on *why* the Newton algorithm is needed in that context, they clearly identify a weakness and offer a direction for addressing it.", "grounding_specificity_rationale": "The reviewer mentions 'section 4' when discussing the Newton algorithm, indicating they have identified a specific part of the paper. However, the weakness they identify is a general characterization of the Newton algorithm as a '1dimensional line search on a convex function' rather than pinpointing a specific subsection or table. This makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer claims a weakness exists ('...the motivation/need...was somewhat lacking') and provides a reason ('...this is essentially just a 1dimensional line search on a convex function...'). However, they do not provide specific evidence or references to support their claim that a 1D line search *specifically* motivates the Newton algorithm in that context. The suggestion of experiments is a good direction, but the verifiability is limited by the lack of concrete evidence for the perceived lack of motivation.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the motivation for the Newton algorithm in section 4. They offer a general explanation ('...essentially just a 1dimensional line search on a convex function...') and suggest a direction for improvement ('...experiments along these lines would help motivate the need for the analysis/algorithm...'). While the reviewer points out a potential issue and suggests a way to address it, the explanation is somewhat highlevel and lacks specific details about *why* the Newton algorithm is needed in that specific context. The suggestions for improvement are good, but the underlying motivation for needing the Newton algorithm isn't fully elaborated."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a concrete action: 'add dynamic factors' to Equation 8. This action is clear and directly addresses a potential issue in the method. The reviewer provides a specific location (Equation 8) and a clear direction for improvement, making it actionable for the author.", "grounding_specificity_rationale": "The review point explicitly refers to 'Equation 8' as the specific part of the paper being addressed. This is a literal mention, indicating strong grounding. The reviewer clearly identifies the issue within this specific equation, making the grounding very precise.", "verifiability_rationale": "The review point identifies a potential issue in the method (Equation 8) and suggests a solution ('add dynamic factors'). While the reviewer doesn't provide a detailed analysis of why subtracting 's' might lead to a loss of information, the suggestion itself is a claim that can be verified by implementation and testing. The suggestion is concrete and directly addresses the identified problem, making it 3.", "helpfulness_rationale": "The review point directly addresses a potential issue in the method (Equation 8) and offers a clear, actionable suggestion to improve it. The reviewer's comment is specific, pointing to a particular equation and suggesting a concrete modification. This directly helps the author understand a potential flaw and provides a clear path for improvement, making it 5."}
{"actionability_label": "X", "grounding_specificity_label": "X", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, not a statement that directly tells the author what to do. It asks about the relationship between MC samples, performance, network structure, and empirical evidence, but doesn't provide a specific action or solution.", "grounding_specificity_rationale": "The review point doesn't explicitly identify a specific part of the paper or methodology being discussed. It's a general question about the relationship between different factors.", "verifiability_rationale": "The review point doesn't contain a claim that needs verification. It's a question prompting for information rather than a statement that requires evidence.", "helpfulness_rationale": "The review point identifies a gap in the author's knowledge and encourages them to explore the relationship between MC samples, performance, network structure, and empirical evidence. While it doesn't provide a direct solution, it points towards a valuable area of investigation and could guide the author's next steps. It's not entirely useless, but it's not a direct fix either."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a valid concern about the generalizability of the method to other domains. While the reviewer doesn't provide a specific action or suggestion, the question itself is a direct request for clarification on a methodological aspect. The lack of explicit action makes it less actionable compared to a point that directly suggests an improvement. However, the underlying question about applicability is relevant to authors.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or dataset where the generalizability issue arises. The reviewer is asking about the selection of event types, which is a metalevel question about the method's design rather than a direct critique of a specific section or table. Therefore, the grounding is weak because the authors cannot pinpoint the exact area being questioned. The question is about the *methodology* rather than a specific instance within the paper.", "verifiability_rationale": "The review point raises a question about the selection of event types from Freebase. While the reviewer doesn't provide a claim or suggestion, the question itself is a request for justification or clarification. The lack of a claim makes it difficult to assess verifiability. The reviewer is asking for *how* the 21 event types were selected, which implies a lack of transparency or justification in the original work. Without a clear explanation or citation, the selection process is unclear, making it difficult to verify the basis of the event type selection.", "helpfulness_rationale": "The review point raises a valid concern about the generalizability of the method to other domains. This is a relevant question for authors who might want to apply the method in different contexts. While the reviewer doesn't provide a specific suggestion, the question itself is a relevant inquiry that could lead to further discussion and clarification if the authors find the method's domain limitations important. The question is about the *potential* of the method, which is relevant to its usefulness. However, without a concrete suggestion, the helpfulness is limited."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The action is implicit ('improve the experimental setup') but the reviewer doesn't specify *how* or *what* needs to be improved. The action is also vague. Therefore, it's not actionable.", "grounding_specificity_rationale": "The reviewer *mentions* the specific parts of the paper (experimental setup, corpora, datasets). This indicates a degree of grounding. However, the reviewer doesn't specify *which* aspects within these broad categories are unclear or poorly motivated. Therefore, it's 2.", "verifiability_rationale": "The statement identifies a problem ('unclear or poorly motivated') but doesn't provide any specific evidence or justification for why these aspects are unclear or poorly motivated. Therefore, it's 1.", "helpfulness_rationale": "The comment points out issues in the experimental setup but doesn't offer any concrete solutions or directions for improvement. Therefore, it's 1."}
{"actionability_label": "5 (5)", "grounding_specificity_label": "3 (Somewhat Grounded and Specific)", "verifiability_label": "4 (4)", "helpfulness_label": "5 (5)", "actionability_rationale": "The review point explicitly identifies a missing detail: the size (number of parameters/depth) of each hourglass module. This is a concrete action the authors can take to clarify the model architecture. The reviewer directly points out what information is absent, making it 5.", "grounding_specificity_rationale": "The reviewer mentions 'competing approaches' and 'hourglass modules'. While the paper might not explicitly use the term 'hourglass modules', this is a reasonable inference based on the context of model architecture. The reviewer is pointing to a specific area in the paper where more detail is needed. The 'competing approaches' part is also somewhat vague as the specific approaches are not named. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim: 'The authors mention that the model consists of 4 hourglass modules, but do not say how big each hourglass module is.' This is a factual statement about the missing information in the paper. The reviewer identifies a gap in the provided details, making it verifiable.", "helpfulness_rationale": "This review point is highly likely to be helpful for the authors. By asking about the size of the model components, the reviewer is directly addressing a missing implementation detail that is crucial for understanding and potentially comparing the model to others. This is a direct and actionable question."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states a claim about PACE being a 'diagnostictype prediction' but doesn't explicitly ask the authors to verify this or provide a direct action. The implication is that PACE 'is' diagnostic, but this isn't stated as a clear instruction. While it identifies the type of prediction, it doesn't specify *why* this is important or what the authors should do with this knowledge. Therefore, the action is implied but not explicitly stated or detailed.", "grounding_specificity_rationale": "The review point directly names 'prior work (e.g. ClimateBench or ClimateSet)' as relevant context. This clearly identifies the specific area being addressed. The authors can easily identify the relevant prior work. The point also provides specific examples of relevant prior work.", "verifiability_rationale": "The claim extracted from the review point is 'prior work (e.g. ClimateBench or ClimateSet) does exactly this.' This claim is made without any supporting evidence or justification within the review point itself. The verifiability relies on the reader's prior knowledge or ability to search for these works. There is no explicit reasoning, common knowledge, or external references provided to support this claim within the review point.", "helpfulness_rationale": "The review point points out a potential mischaracterization of prior work. It highlights a lack of clarity in the paper's description of prior contributions. This is helpful for the authors to understand the context of their work relative to existing research and to potentially clarify their description of prior work. While it doesn't offer a direct solution, it identifies a potential area needing clarification and helps the authors understand the existing literature better."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the desired actions: 'move visual results from supplementary to the main paper' and 'condense architecture figures'. These are clear and direct actions that the authors can readily identify and implement.", "grounding_specificity_rationale": "The reviewer does not specify which particular figures or sections they intend to move or condense. They use general terms like 'visual results' and 'architecture figures'. This lack of specificity means the authors cannot confidently determine the exact area of the paper that needs adjustment.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement but does not provide any justification or reasoning for why moving visual results to the main paper or condensing architecture figures is beneficial or valid. There is no logical reasoning, common knowledge, or external references provided to support the claim that these actions are necessary or helpful.", "helpfulness_rationale": "The reviewer identifies a specific weakness in the current presentation of the paper (lack of visual results in the main paper for a key experiment). While the suggestion is actionable, the reviewer does not explain why this improvement would be beneficial for the reader or the research community. The rationale for the suggestion is missing."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests investigating a potential issue with a test example (the British patient in Figure 8) by using corpus residual value. While the reviewer doesn't explicitly state the action to be taken, the suggestion implies a need to analyze the corpus. The reviewer also mentions 'corpus residual value' which provides some detail on how to implement the suggested action. However, the reviewer doesn't specify the exact steps or criteria for determining if the British patient is indeed crucially different, making the action somewhat implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the patient of Figure 8' and specifies that 'the patient is 'British'' and that the 'American corpus' was used. This clearly identifies the specific section and the characteristics being discussed, demonstrating strong grounding. The reviewer also suggests investigating 'corpus residual value', which further specifies the method of investigation within this grounded context.", "verifiability_rationale": "The reviewer proposes using 'corpus residual value' to detect the difference between the 'British' patient and the 'American corpus'. This constitutes a claim that can be verified through logical reasoning and by examining the results of the corpus analysis. The reviewer provides a specific method (corpus residual value) to investigate the issue, making the claim verifiable. However, the reviewer doesn't provide a detailed explanation of how to perform the corpus residual analysis or cite any specific examples or references, making the verifiability somewhat incomplete.", "helpfulness_rationale": "The reviewer's point about the potential discrepancy in the test example and the explanation is likely to be helpful for the authors. It highlights a potential flaw in their analysis (using the wrong corpus) and suggests a concrete way to investigate it (corpus residual value). This directly contributes to improving the rigor and accuracy of their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests using a different dataset (WebQuestions) instead of the current one (WebQuestionsSP). While this is an implicit action of suggesting a change, it doesn't explicitly state what needs to be done or how to implement this change. The reviewer doesn't provide concrete steps or clarify the existing dataset (WebQuestionsSP).", "grounding_specificity_rationale": "The reviewer mentions 'most popular WebQuestions' and 'WebQuestionsSP'. This shows some grounding as they are referring to specific dataset names. However, they don't explicitly identify the section, table, figure, or unique aspect of the paper being addressed by these datasets. The grounding is implicit rather than explicit.", "verifiability_rationale": "The reviewer makes a claim that 'WebQuestions is the most popular benchmark set' and 'it could facilitate direct comparison with mainstream QA research'. This claim is 3 as the popularity of WebQuestions is a generally accepted fact in the field. However, the reviewer doesn't provide specific references or examples to support these claims within the context of the paper being reviewed. The verifiability is limited to general knowledge within the field.", "helpfulness_rationale": "The reviewer suggests using a different, more 'intuitive and straightforward' dataset. While this could be helpful for the authors to understand and compare their work, the review point lacks a clear explanation of why the current dataset (WebQuestionsSP) was chosen or what its limitations might be. The suggestion is presented without a strong justification for the current approach or the benefits of the alternative. The helpfulness is limited to the suggestion itself, but it lacks a deeper rationale."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states their opinion about the desirability of sparsity but does not explicitly tell the authors what they should do or how to apply this opinion. They are questioning the motivation behind introducing sparsity, which is a general comment rather than a specific action on the part of the authors.", "grounding_specificity_rationale": "The reviewer mentions sparsity but does not pinpoint a specific section, table, figure, or unique aspect of the paper where this issue is occurring. They are raising a general concern about the need for sparsity.", "verifiability_rationale": "The reviewer makes a claim about the lack of obviousness in the desirability of sparsity but does not provide any evidence or justification for this claim. They are stating an opinion without supporting it.", "helpfulness_rationale": "The reviewer raises a question about the motivation for sparsity without offering any concrete suggestions or guidance on how this relates to improving the draft. They are questioning the *why* rather than the *how*."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the novelty of the work but does not explicitly state what specific changes or improvements the authors should make. While it identifies a limitation, it lacks concrete action.", "grounding_specificity_rationale": "The review point mentions 'novelty,' 'attention mechanisms,' 'motion learning,' and 'video understanding' but does not specify which part of the paper is being criticized. It provides a general assessment of the work's contribution.", "verifiability_rationale": "The review point claims that the design is not novel because attention learning has been widely used in video understanding. This is a claim that can be supported by common knowledge and the existing literature on attention mechanisms in video analysis. However, it lacks specific examples or citations to back up the claim of 'widespread use' within the specific context of this work.", "helpfulness_rationale": "The review point identifies a valid limitation of the work, specifically the lack of novelty due to the use of existing techniques. While it doesn't offer specific, actionable suggestions, it points out a significant issue that needs to be addressed. Therefore, it is 3 in highlighting a problem."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer's point is clear and directly addresses a potential ambiguity in the paper. While the models are stated as models, their use in the experiments seems to treat them as datasets. This creates a discrepancy that needs clarification. However, the reviewer does not explicitly state what action the authors should take to address this, making it not fully actionable.", "grounding_specificity_rationale": "The reviewer points out a lack of clarity in how the BigFive and MBTI models are being used in the experiments. While they are stated as models, the reviewer suggests they are used as datasets. This is a valid observation, but the paper does not explicitly state which specific dataset or method is being used within these models. Therefore, the reviewer's point is not fully grounded in the specific parts of the paper detailing the experiments.", "verifiability_rationale": "The reviewer makes a claim about a potential inconsistency in the paper, stating that BigFive and MBTI are models but are used as datasets in the experiments. This claim is supported by the definitions provided in the paper. The reviewer provides a clear reasoning based on the initial definitions of the models. However, the paper does not provide external references to support this claim about the inconsistent use of the models.", "helpfulness_rationale": "The reviewer's suggestion to clarify the use of BigFive and MBTI is a helpful suggestion for the authors. However, the reviewer does not provide a concrete solution or actionable step for the authors to take. The suggestion is a good starting point for improvement, but it is not a full remedy, making it 3 but not entirely helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the absence of rejection rate information. This action is direct and identifies a specific area for improvement (the missing rejection rate).", "grounding_specificity_rationale": "The reviewer refers to 'experiments' generally, not a specific section, table, figure, or unique aspect. While they identify the *type* of information missing (rejection rate), they don't pinpoint the exact location within the paper. The grounding is present in identifying the broad area, but it's not as precise as it could be.", "verifiability_rationale": "The reviewer states a claim ('Rejection rate is not shown in any experiments') but does not provide any logical reasoning, examples, or external references to support this claim. They offer a suggestion ('One could view a misclassification as a rejection') but it's presented as a potential interpretation, not a justification for the initial statement.", "helpfulness_rationale": "While the reviewer identifies a valid issue (the missing rejection rate information), they do not provide any justification or explanation for why this is a problem or how it should be addressed. The suggestion ('One could view a misclassification as a rejection') is a potential interpretation but not a concrete solution or insight into the lack of rejection rate information itself."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer is explicitly asking for information about thresholds and hyperparameters. However, the action of identifying these parameters is not directly tied to improving the paper's content or addressing a specific weakness. The request is more about seeking information for reproducibility. Therefore, while the action is explicit, it lacks a clear connection to actionable improvements, making it 3 but ultimately less helpful for addressing specific issues in the paper.", "grounding_specificity_rationale": "The reviewer is asking about 'results' and 'hyperparameters'. While the reviewer names these specific aspects, they do not point to a specific section, table, figure, or unique element of the paper. The grounding is weak because the authors cannot confidently determine which part the comment addresses. However, the comment does specify what needs to be addressed (thresholds and hyperparameters), making it somewhat specific within that broad area.", "verifiability_rationale": "The reviewer is stating a request for information about thresholds and hyperparameters. This is not a claim or suggestion about the paper itself. It is more of a directive to the authors. Therefore, it does not contain a claim that can be verified, making it 1.", "helpfulness_rationale": "The request for information about thresholds and hyperparameters is highly relevant for ensuring the reproducibility of the results. This information is crucial for other researchers to validate and build upon the work. By providing this information, the reviewer is directly addressing a fundamental aspect of scientific research and improving the overall impact and utility of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential flaw in the paper's interpretation of its dataset analysis. While the reviewer's point is not explicitly stated as an action, it implicitly suggests that the authors should consider the impact of specific features used in their analysis on the relationship between readability and question difficulty. The reviewer's suggestion, while not a direct instruction, implies a need for the authors to refine their analysis or consider alternative methods. Therefore, while not explicitly stating an action, the reviewer's point is 3 in that it suggests a direction for improvement.", "grounding_specificity_rationale": "The reviewer's point is grounded in the paper's findings regarding dataset analysis. They directly reference the concept of 'dataset analysis suggested that the readability of RC datasets does not directly affect the question difficulty'. Furthermore, the reviewer provides specific examples of features (POS/dependency parse features) that could influence this relationship. This makes the grounding very strong as it directly relates to a key finding and offers a concrete example of a potential confounding factor. The reviewer is also specific about the concept of 'answer detection methods', which further clarifies the potential issue.", "verifiability_rationale": "The reviewer presents a claim: 'You say that your 'dataset analysis suggested that the readability of RC datasets does not directly affect the question difficulty', but this depends on the method/features used for answer detection, e.g. if you use POS/dependency parse features.' This claim is verifiable because the reviewer is suggesting a potential alternative interpretation of the paper's findings. While the paper might not have explicitly discussed featurebased analysis methods, the reviewer provides a plausible reason why the initial conclusion might be incomplete. The reviewer's suggestion is logical and points to a specific area that could be investigated further. Therefore, the claim is 3 as it offers a potential explanation for the observed results.", "helpfulness_rationale": "The reviewer's comment is 5 because it points out a potential flaw in the paper's interpretation of its results. By suggesting that the method of analysis might influence the conclusion, the reviewer is providing a valuable point of critique. The specific example of POS/dependency parse features makes the feedback concrete and actionable for the authors. This could lead the authors to reevaluate their analysis methods or consider alternative approaches to their study. The reviewer's comment is not just a criticism; it's a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'Figure 1 could be optimized to use less whitespace.' However, it lacks concrete details on how to achieve this optimization. The authors are informed about a potential improvement but not provided with specific steps or guidance on how to implement it.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1,' which is a specific part of the paper. However, it does not specify what is wrong with the whitespace or what kind of optimization is intended. The authors still need to infer the specific issue and the desired outcome.", "verifiability_rationale": "The review point itself does not contain a claim. It is a suggestion for improvement. Therefore, it does not have supporting evidence or justification.", "helpfulness_rationale": "The review point identifies a potential area for improvement ('Figure 1 could be optimized to use less whitespace') and suggests a direction for action ('less whitespace'). This points towards a concrete action the authors could take, even if the specifics are not detailed. It is a clear indication of a weakness and a way to address it."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies areas for improvement (writing quality, related work) but doesn't explicitly state the actions to be taken. While it implies improvement, the specific steps are not defined.", "grounding_specificity_rationale": "The comment doesn't explicitly identify the specific part of the paper being addressed for writing quality. For the related work, it identifies a general inefficiency but doesn't specify the unique aspect needing improvement. Therefore, it's 2.", "verifiability_rationale": "The comment makes claims about the writing quality and related work but doesn't provide any evidence or justification for these claims. There's no logical reasoning or references to support the suggestions.", "helpfulness_rationale": "The comment points out general weaknesses and suggests a restructuring of the related work. However, it lacks specific actionable steps or concrete suggestions for improvement, making it less immediately helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment implicitly suggests an action: 'If you haven't improved FLOPs or inference time, consider looking at accuracy or specific properties.' While not stated explicitly as 'do this', the intent is clear. However, the action itself (how to 'look at' accuracy or 'specific properties') is vague.", "grounding_specificity_rationale": "The comment explicitly states: 'I suggest looking at if there is any improvement on the accuracy or specific properties.' This clearly identifies the part of the paper being addressed (accuracy or specific properties). It also specifies what is being asked (improvement). The example given, 'For example, with the recurrent model, maybe the sequential relationship is easier to mode?', further specifies a unique aspect within a specific model type. This demonstrates strong grounding specificity.", "verifiability_rationale": "The comment provides a suggestion ('look at accuracy or specific properties') and offers an example ('For example, with the recurrent model, maybe the sequential relationship is easier to mode?'). While it doesn't provide a definitive answer or a specific method, it offers a direction for investigation and a concrete example to consider. This provides some basis for verification, although it might not be exhaustive or provide all necessary references. It's not a definitive 'yes, do this', but it's a suggestion with a direction.", "helpfulness_rationale": "The review point provides a clear alternative focus for the authors if their initial focus on FLOPs and inference time didn't yield improvements. It suggests a specific area to investigate (accuracy and specific properties) and even provides an example (recurrent model and sequential relationships). This offers a concrete next step and is directly relevant to guiding the authors' work. It's not a criticism, but a helpful suggestion for exploration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point directly asks a question about an assumption made in the paper. This is a clear and actionable question for the authors. The authors are being asked to consider the validity of a specific claim made in the paper. While the question itself is direct, the reviewer doesn't explicitly state how they would test the assumption, making it 3 rather than fully actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'd_e are good replacements for entity embeddings'. This clearly identifies the specific part of the paper being addressed, making the grounding fully grounded. It also specifies what is being compared ('d_e' vs. 'entity embeddings'), making the specificity high.", "verifiability_rationale": "The review point does not contain a claim that needs verification. It is a question about an assumption, not a statement that requires supporting evidence. Therefore, it does not fit into the 'Claim Extraction' or 'Verifiability Verification' steps defined in the prompt.", "helpfulness_rationale": "The review point is a clear question about a crucial assumption made in the paper. This directly points to a potential area of confusion or weakness for the authors. While it doesn't provide a solution, it identifies a key area that needs clarification, making it 3 in guiding the authors to investigate the assumption further."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, not a direct instruction on how to improve the draft. While it points to a potential area of confusion, the authors are not explicitly told what to do or how to address it. The question is about clarification, not action.", "grounding_specificity_rationale": "The review point directly asks about 'physical interaction' and the context is 'one simulation'. This is a specific reference to a part of the paper. The authors can likely identify the section discussing simulations and the specific type of interaction being questioned. The grounding is explicit.", "verifiability_rationale": "The review point is a question, not a claim that needs verification. It doesn't present a statement that requires logical reasoning, common knowledge, or external references to be considered valid. It's a request for information, not a judgment.", "helpfulness_rationale": "The review point is a question about a specific aspect of the simulation. It could be helpful for the authors if they were struggling to understand or describe their simulation setup. However, it doesn't directly tell them how to improve their draft. It's more of a diagnostic question than a direct improvement suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues and suggests concrete actions to be taken. The actions are direct and do not require further inference. For example, the reviewer suggests 'including categorical features' and 'using onehot encoding for a specific dataset'. These are clear actions the authors should perform.", "grounding_specificity_rationale": "The reviewer identifies specific aspects of the paper being criticized. They mention 'categorical features', 'numerical features', 'one hot encoding', and a specific dataset. This demonstrates strong grounding as the reviewer clearly points to the relevant parts of the paper and explains why they are problematic. The reviewer also states 'Only one of the datasets has categorical features. All other datasets have exclusively numerical features.' which directly pinpoints the issue.", "verifiability_rationale": "The reviewer makes a claim about the inadequacy of the dataset selection and the impact of encoding methods. They provide specific reasons for this inadequacy, such as the lack of categorical features and the omission of onehot encoding. While the reviewer doesn't provide extensive evidence or references within this review point, the reasons provided are plausible and based on common knowledge in machine learning. The impact of categorical features on model performance and the effect of onehot encoding are wellestablished concepts.", "helpfulness_rationale": "The reviewer provides two clear and actionable suggestions. The suggestions are specific and directly address the identified weaknesses related to dataset types and encoding. The reviewer suggests 'include categorical features' and 'use onehot encoding for a specific dataset'. These are concrete and actionable steps the authors can take to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out that the chosen IoT datasets are 'unpopular' and 'weird choices'. While this is a subjective assessment, the reviewer attempts to provide reasons for this perception, such as the recency and limited recent use of the FlatCam Face dataset and the age of the Headpose detection dataset. However, the reviewer does not explicitly state what action the authors should take based on this feedback. They identify a potential issue but don't provide a clear, actionable step for the authors to follow. The reviewer suggests better options, but doesn't detail how the authors should transition to those options.", "grounding_specificity_rationale": "The reviewer mentions 'Section 4' and the specific datasets 'FlatCam Face 26' and 'Headpose detection 11'. This indicates a clear identification of the specific part of the paper being addressed. The reviewer also states their *opinion* about the datasets being 'unpopular' and 'weird choices', which implies a judgment about the paper's content. However, the reviewer does not provide specific details about *why* these datasets are unpopular or what is specifically 'weird' about them. The grounding is present, but the specificity of the grounding could be improved by providing more details about the issues with the datasets.", "verifiability_rationale": "The reviewer states that the choice of the two IoT datasets makes the benchmarking results 'a bit hard to sense and evaluate'. This is a claim that requires justification. The reviewer then provides *suggestions* for better datasets, such as 'wearable health or mobile activity recognition data, or even some sets in UCI'. While the reviewer offers *reasons* for why the current datasets are problematic (popularity, recency, limited recent use), they do not explicitly cite external references or provide logical reasoning to *verify* the claim that the current datasets are indeed hindering the evaluation. The claim is presented as an opinion without strong supporting evidence.", "helpfulness_rationale": "The reviewer's point is likely to be *helpful* in guiding the authors towards considering different experimental setups. By highlighting the limitations of the chosen datasets, the reviewer encourages the authors to explore more relevant and widely used IoT datasets. While the reviewer doesn't provide explicit instructions on how to implement this suggestion, the critique of the datasets and the proposal of alternative datasets are valuable insights that can help the authors improve the significance and interpretability of their benchmarking results. The suggestions, though not fully concrete, point the authors in a useful direction."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment implicitly states an action by pointing out the need for larger annotations and suggesting further enlargement. However, it lacks explicit instructions on how to achieve this, making the action somewhat vague. The reviewer knows what needs to be done but not the exact steps to take.", "grounding_specificity_rationale": "The comment explicitly mentions 'annotations in Figure 4', which clearly identifies the specific part of the paper being addressed. This demonstrates strong grounding specificity as the reviewer can easily pinpoint the referenced element.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a suggestion for improvement rather than a statement of what is wrong or needs to be changed. Therefore, it does not fit into the verifiability categories as it lacks a claim to be supported.", "helpfulness_rationale": "The comment identifies a valid issue \u2013 the small size of annotations in Figure 4 \u2013 and suggests a solution ('further enlarged'). It directly points to a specific location, making it a helpful suggestion for improvement. While it doesn't provide a detailed explanation of why the annotations are small or how to enlarge them, it does offer a clear direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the incorrect assumption about the number of entities in sentences for relation classification. It also implicitly points out that the issue extends to documents and joint entity and relation extraction, providing an action (to consider broader contexts) and some details (multiple entities, documents, joint extraction).", "grounding_specificity_rationale": "The comment refers to general concepts like 'sentences,' 'relation classification,' 'documents,' 'entities,' and 'relation extraction.' While it doesn't explicitly point to a specific line number or table, it accurately identifies the issue within the context of relation classification. The grounding is weak because the authors can infer the relevance of these terms, but they would need to connect it back to the specific mention of lines 2627 themselves.", "verifiability_rationale": "The comment contains a claim: 'Lines 2627: Multiple entities typically exist in both sentences and documents...'. While it doesn't provide explicit justification or examples within the comment itself, the statement about multiple entities in sentences is generally verifiable through common knowledge of relation classification examples. The verifiability is somewhat lacking because it doesn't cite specific external references or provide a detailed logical reasoning within the comment.", "helpfulness_rationale": "The comment points out a factual observation about the nature of relation classification. While technically correct, it might not be immediately helpful to the authors if they are focusing on a specific sentencelevel task. It could be perceived as introducing unnecessary complexity or shifting the focus away from the immediate issue the authors are facing. The helpfulness is moderate because it highlights a potential misunderstanding or a broader context, but it lacks specific guidance on how to address it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a problem with the color bar in Fig. 4 and suggests a specific label ('worse'). This indicates a clear action the authors should take: investigate the color bar and consider labeling it 'worse' or a similar indicator of lower quality. The action is also concrete as it points to a specific visual element and a specific label.", "grounding_specificity_rationale": "The comment explicitly refers to 'Fig. 4' and suggests a specific label change ('worse') for a particular element within that figure. This demonstrates strong grounding as the authors can directly identify the section, table, figure, or unique aspect being addressed. The specificity is high as it not only identifies the figure but also pinpoints the exact issue and the desired change.", "verifiability_rationale": "The comment contains a claim: 'presumably one of the labels should say \u201cworse\u201d.' This is a statement of observation. However, it does not provide any explicit reasoning or evidence to support why 'worse' is the correct label. The suggestion is based on interpretation and potential mislabeling, but lacks concrete justification. Therefore, it is 3 as it states a point and implies a justification through the suggestion, but lacks explicit reasoning or references.", "helpfulness_rationale": "The comment is clear and directly points to a potential issue with the color bar in Fig. 4. It suggests a specific improvement by changing the label to 'worse' or a similar indicator of lower quality. This is actionable and provides a clear direction for the authors to improve their draft. The suggestion is directly related to the identified problem and empowers the authors to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the need to add 'sets' after 'validation/test' and clearly indicates the location in the supplementary material (Row 757 in Supp. Page 29). This provides a direct and concrete action for the authors to take.", "grounding_specificity_rationale": "The comment explicitly mentions 'Row 757 in Supp. Page 29', providing a precise location within the paper where the suggested addition should be made. This demonstrates strong grounding specificity as the authors can easily identify the referenced part.", "verifiability_rationale": "The comment does not contain a claim in the sense of an opinion or assertion. It is a suggestion for improvement. Therefore, the concept of verifiability does not apply as there is X to be verified.", "helpfulness_rationale": "The comment is clear, direct, and provides a specific action for the authors to take. It tells them exactly what is missing and where it should be added. While it doesn't delve into the reasons for the missing element or suggest alternatives, it is a very helpful and actionable suggestion."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point asks for clarification on a model's capabilities and specific technical details, which are indirect and require the authors to infer the actions. The reviewer doesn't explicitly state how to implement the model's limitations or the coefficient of the p(L, E | X) term. The request for hyperparameter details is implicit in the concern about the model's capabilities and the lack of confidence in baselines and ablation studies. The authors need to deduce the actions from the reviewer's questions.", "grounding_specificity_rationale": "The reviewer's questions and comments are not directly tied to a specific part of the paper. The questions about the model's capabilities are general, and the comment about writing quality is also broad. While the reviewer might be referring to their draft in their mind, the review itself doesn't pinpoint a specific section, table, figure, or unique element. The writing quality comment is a general statement about the paper as a whole, not a specific issue within a particular section.", "verifiability_rationale": "The reviewer makes a statement about the model's capabilities and then asks for specific technical details. This is a claim that requires justification. The reviewer states 'I don\u2019t think this is fatal though' which implies a judgment about the significance of the issue. The request for the coefficient of the p(L, E | X) term and the justification for it being 1 are specific requests for information, but the reviewer doesn't provide any logical reasoning or external references to support their claims about the model's limitations or the coefficient. The writing quality comment is also a subjective assessment without specific examples or references.", "helpfulness_rationale": "The review point asks for specific technical details and suggests improvements to writing quality. While these are helpful, they are more of a request for information and assistance rather than direct, actionable feedback on specific aspects of the authors' draft. The authors would need to infer how to implement the model's limitations and how to improve their writing based on the reviewer's comments. The lack of explicit instructions makes the feedback less directly helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem (the model is no longer stateoftheart) and suggests a general solution (replace it with a very high performing model). This makes the action explicit. However, the reviewer does not specify *how* to perform this action, such as suggesting a specific alternative or providing a process for choosing a new model. Therefore, the action is explicit but vague.", "grounding_specificity_rationale": "The reviewer refers to 'line 152' which is a specific part of the paper. This indicates that the reviewer can identify the specific part being addressed. However, the suggestion itself is very general and does not specify *what* kind of 'very high performing model' to use or a process for selecting one. Therefore, while the reviewer can ground the *reference* to the line, the *action* is not very specific.", "verifiability_rationale": "The reviewer makes a claim that 'the model by Dozat and Manning (2016) is no longer stateoftheart'. However, the reviewer does not provide any evidence or justification for this claim. They do not cite any papers or explain why the model is no longer stateoftheart. The claim is presented without supporting reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer's suggestion is relevant to the user's work, as it points to an issue with the example in line 152. However, the suggestion is very general and lacks specific details. The reviewer doesn't explain *why* the current model is a problem or *what* specific improvements a 'very high performing model' would offer. The feedback is helpful in identifying an area for improvement, but it lacks the specificity needed for immediate action."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'the proposed compression performs worse than PQ' which is an action or suggestion. It also identifies the condition 'when a small code length is allowed', providing a concrete action to take. Therefore, the action is both explicit and concrete.", "grounding_specificity_rationale": "The review point refers to 'the proposed compression' and 'PQ'. While it doesn't explicitly name a section, table, or figure, it refers to specific elements of the method being compared. This can be considered weak grounding as the authors would need to infer which compression method is being referred to. The comment also specifies what needs to be addressed ('worse than PQ'), making it somewhat specific.", "verifiability_rationale": "The review point contains a claim: 'the proposed compression performs worse than PQ'. This claim is 3 as it points to a practical side and the condition 'small code length', suggesting a potential area for investigation. However, it doesn't provide specific examples or references to external work within the review point itself.", "helpfulness_rationale": "The review point clearly identifies a weakness ('the proposed compression performs worse than PQ') and attributes it to a specific condition ('when a small code length is allowed'). It also states that this is the 'main weakness' and its 'practical side', providing a clear direction for improvement. This makes the review point 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point contains several claims, but they are not always explicit or concrete. The statement 'Some subjective statements are inappropriate' is implicit, as it doesn't specify which statements are subjective or why they are inappropriate. The statement 'Proofs and references are needed' is explicit and concrete, clearly stating the need for evidence. The statement 'One more daunting task of multiscale architecture design is unknown is that when to fuse the multiscale feature' is explicit and concrete, identifying a missing detail. The statement 'Besides these explicit multiscale methods, the models with skip connections 10 could also be regarded as using multiscale information in an implicit way' is explicit but the connection is not immediately obvious, making it slightly vague.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper it is addressing. While it implies a connection to multiscale methods and skip connections, it does not point to a specific section, table, figure, or unique aspect of the paper. However, the claims within the point are somewhat specific, such as the need for proofs and references, and the importance of fusion in multiscale architectures.", "verifiability_rationale": "The claim 'Some subjective statements are inappropriate' is not verifiable as it lacks supporting evidence or justification. The claim 'Proofs and references are needed' is 3 as it implies the need for evidence to back up subjective statements. The claim 'One more daunting task of multiscale architecture design is unknown is that when to fuse the multiscale feature' is 3 as it implies the difficulty of multiscale design and the missing detail of fusion. The claim 'Besides these explicit multiscale methods, the models with skip connections 10 could also be regarded as using multiscale information in an implicit way' is 3 as it implies a connection between skip connections and multiscale information.", "helpfulness_rationale": "The review point is 3 as it identifies potential areas for improvement and encourages the authors to be more objective. However, the vagueness of some statements makes it less impactful. For example, the statement about subjective statements being inappropriate is not specific enough to provide actionable feedback. The suggestions for proofs and references, and the importance of fusion, are more helpful but could be expanded upon."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point is a question about comparison, which is not an explicit instruction on what to do. It implies a comparison but doesn't specify how to perform it.", "grounding_specificity_rationale": "The review point is a general question about prior art and comparison, not specifically pointing to a section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The review point is a question, not a claim that needs verification. It doesn't state anything that requires justification or evidence.", "helpfulness_rationale": "The review point is a general question about comparison, which is relevant but lacks specific direction or actionable feedback on how to improve the authors' work based on this comparison. It doesn't directly guide the authors on what to do or how to address the comparison."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states an action: 'I was wondering whether there would be some interesting observations comparing them language/nationality.' This action is clear and directly addresses a potential improvement to the analysis.", "grounding_specificity_rationale": "The reviewer mentions 'language/nationality' and provides examples like 'Japanese, Chinese, English, Arabic, German... (~20 different types)'. This clearly grounds the suggestion in a specific aspect of the paper and provides concrete examples.", "verifiability_rationale": "The reviewer makes a claim: 'Some analyses can be more detailed. For example, in \"language/nationality\", the data includes Japanese, Chinese, English, Arabic, German... (~20 different types). Biases towards different languages/nationalities are different. I was wondering whether there would be some interesting observations comparing them.' This claim requires justification and examples to be 5.", "helpfulness_rationale": "The reviewer's point suggests a desire for improvement in the analysis by adding more detail on language/nationality. While it doesn't directly identify a flaw, it proposes a constructive suggestion that could lead to better insights. Therefore, it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point directly asks a question about alternative feature properties, which implies an intention to explore different options. However, it lacks specific details on how to identify or utilize these alternative properties.", "grounding_specificity_rationale": "The reviewer asks about 'other property of features' without specifying a particular section, table, figure, or unique aspect of the paper. The reference to 'features' is general, making it underspecific.", "verifiability_rationale": "The review point is a question, not a statement of a claim. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The review point is a question prompting the authors to consider alternative feature properties. While it encourages exploration, it doesn't directly instruct the authors on what changes or improvements to make, making it 3 but not fully actionable."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The questions directly address the behavior of F^\u2020 regarding conservation properties, which is an explicit action. The request for numerical illustrations is a concrete action outlining how to implement this action.", "grounding_specificity_rationale": "The reviewer mentions 'symplectic integrators' and 'Hamiltonian systems,' which are specific technical terms. The request for 'numerical illustrations' further specifies the area of investigation.", "verifiability_rationale": "The reviewer is suggesting an investigation into the conservation properties of F^\u2020, which can be considered a claim that requires verification. The request for numerical illustrations provides a method for verification.", "helpfulness_rationale": "The questions are directly relevant to understanding and improving the behavior of F^\u2020 regarding conservation. The request for numerical illustrations makes the review actionable and testable."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a direction for improvement ('beyond link predict') but doesn't explicitly state what needs to be changed or how to achieve this. While it implies a need for more diverse tasks, the specific actions are not clearly defined.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or the author's work. It is a general expectation about the field of Personalized Embeddings (PE). Therefore, it is 1 in the author's specific context.", "verifiability_rationale": "The review point contains a claim ('PE is important' and 'It is expected to see a variety of tasks'). However, it lacks specific justification or examples to support this claim. The reasoning is general and doesn't provide concrete evidence or references.", "helpfulness_rationale": "The review point raises a valid point about the scope of PE papers and encourages the author to consider a broader range of tasks. It is generally helpful in guiding the author towards a more comprehensive approach. However, it lacks specific details on how to achieve this variety, making it less impactful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests an alternative evaluation metric (using the minimum instead of the sum) but does not explicitly state how the authors should implement this change. While the suggestion is concrete about the metric, the practical steps for applying this change are not detailed.", "grounding_specificity_rationale": "The reviewer's comment is a general critique of the evaluation metric and does not specify which part of the paper or method they are referring to. They are not pointing to a specific section, table, or figure.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the summation metric and proposes the minimum as a better alternative. They provide a logical reasoning for their suggestion, explaining that the summation might mask poor performance on a subset of MDPs.", "helpfulness_rationale": "The reviewer's comment is highly relevant to authors who want a more robust evaluation of their policies. By suggesting the use of the minimum instead of the sum, they are providing a concrete alternative that could help identify weaknesses that might be hidden by the summation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the *lack* of zeroshot generation results and suggests a *discussion* about this. While the suggestion is specific, the action being pointed out is the absence of something, making it 2.", "grounding_specificity_rationale": "The reviewer refers to 'zeroshot generation results' which is a specific technical term. They are also implicitly referring to the lack of these results. The suggestion to discuss this is specific to the absence of a particular outcome. Therefore, it can be considered 5.", "verifiability_rationale": "The reviewer states their opinion that the inclusion of zeroshot generation results is 'a bit strange' without providing any specific justification or evidence. The claim is made without sufficient support.", "helpfulness_rationale": "The reviewer's point is more of a suggestion for improvement of the review process (discussing the lack of zeroshot results) rather than a direct critique of the paper or a clear action for the authors. While it highlights a missing piece of information, it doesn't directly guide the authors on how to improve their draft. It's more of a constructive suggestion for improvement of the review process itself, rather than a 5 critique for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer directly asks about Figure 3, indicating a need to address it. The lack of specification about \"OAA\" makes it less actionable than a direct suggestion.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"Figure 3\", demonstrating grounding. However, the issue raised (\"OAA not referenced\") is not a specific flaw within the figure itself, making the grounding somewhat specific but the issue unclear.", "verifiability_rationale": "The review point is a question about a figure and a missing element, not a claim requiring verification.", "helpfulness_rationale": "The reviewer raises a valid concern about a figure and points out a missing element, encouraging the authors to investigate. While it doesn't offer a solution, it highlights a potential area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the impact of the GS module on the effective receptive field, rather than providing a direct action or suggestion. While the question is relevant, it doesn't explicitly state what the authors should do next. The suggestion to look at 2 is a resource but not a concrete action.", "grounding_specificity_rationale": "The reviewer mentions 'GS module' and 'effective receptive field,' which are specific terms. However, they don't explicitly identify which section, table, or figure they are referring to. The issue of the receptive field being 'improved' is a general statement, not a specific point within the paper.", "verifiability_rationale": "The review point is a question, not a declarative statement that requires verification. Therefore, there is X to evaluate for its verifiability.", "helpfulness_rationale": "The reviewer is asking a relevant question about a potential improvement to the effective receptive field. While the review point doesn't provide a solution, it prompts the authors to consider the impact of the GS module and potentially look for external references. This makes it 3 in guiding further analysis and potential improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The suggestion to add another head to the network for value functions is an explicit action. However, the reviewer does not specify how this head would be implemented or what changes would be made to the network architecture. The lack of detail makes it somewhat vague and less concrete.", "grounding_specificity_rationale": "The reviewer suggests a modification to the LSTM architecture. While this modification is relevant to the reinforcement learning task, the paper does not explicitly mention any specific sections, tables, figures, or unique aspects of the paper where this change would be applied. The grounding is implied but not explicitly stated.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It presents a suggestion for an alternative approach. While the reviewer implies that the objective for the LSTM part is the same for pretraining and finetuning, this is not explicitly stated as a claim within the review point itself. The suggestion itself is a request for an alternative, not a claim requiring justification.", "helpfulness_rationale": "The review point offers a concrete alternative to retraining the LSTM from scratch, which could be helpful for the authors. The suggestion to add another head for value functions is a practical idea. However, the lack of specific details on how to implement this suggestion makes it less immediately helpful. The reviewer's point about the objective being the same is a potential point of clarification but doesn't provide a direct solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action: 'it would be good to acknowledge some of the older works too.' This action is concrete as it specifies 'older works' and even hints at the type of work: 'supervised, multilingual systems'. The reviewer is directly pointing out a potential improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the 'related works' section and the specific type of work within that section: 'supervised, multilingual systems'. The suggestion to acknowledge 'older works' further pinpoints a specific aspect within that subsection. The authors can easily identify the relevant part of the paper.", "verifiability_rationale": "While the comment itself doesn't contain a claim that needs verification, the suggestion to acknowledge 'older works' is 3. The reviewer is proposing a change that aligns with common academic writing practices (acknowledging contributions). The suggestion itself doesn't require external references to be considered valid, but it implies a desire for completeness and a potential lack of explicit mention of foundational work.", "helpfulness_rationale": "The comment is 5 as it directly points to a concrete improvement in the related work section. By suggesting the inclusion of 'older works', the reviewer is guiding the authors to consider a specific aspect of their work and its place within the existing literature. This is a valuable suggestion that can enhance the paper's context and completeness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer's confusion is not explicitly addressed by the paper in a way that provides actionable steps. While the paper explains the experimental setup and the expected outcome (that decaying sampling should perform better in the highperforming region), it doesn't delve into *why* the reviewer is confused or what they should do with this confusion. The paper focuses on presenting the results and the implications of the findings, rather than guiding the reader through potential misunderstandings or uncertainties. The reviewer is left to interpret the results in light of the paper's claims, but the paper doesn't offer specific guidance on how to proceed if the results are surprising or unclear.", "grounding_specificity_rationale": "The reviewer's confusion is tied to specific parts of the paper, namely 'Table 2' and 'Section 5.2' (implied). The paper presents the results in Table 2 and discusses the sampling methods in Section 5.2, which are directly relevant to the reviewer's point of confusion. The reviewer is specifically questioning the interpretation of the results presented in these sections.", "verifiability_rationale": "The paper provides sufficient information to understand the experiment and the expected outcome. The paper describes the linear/exponentialdecay sampling methods and explains the rationale for expecting them to perform better in the highperforming region compared to uniform sampling. The paper also provides the expected benefit of this approach. Therefore, the claim that the results are confusing is based on a reasonable interpretation of the paper's content.", "helpfulness_rationale": "The reviewer's confusion is a valid point of discussion and potential improvement. The paper explains the experimental setup and the expected outcome, but it doesn't explicitly address why the reviewer is confused or what they should do with this confusion. The paper focuses on the results and their implications, rather than guiding the reader through potential misunderstandings. While the confusion is valuable feedback, the paper doesn't provide specific guidance on how to address it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "Not Verifiable", "helpfulness_label": "4", "actionability_rationale": "The review point identifies potential issues related to time complexity. The statement 'The time complexity seems rather high' is a general concern and lacks specific details. However, the subsequent points, 'First, the authors use an itemoriented autoencoder, in which there may be lots of users associated with a typical item', 'Second, the elementwise function is expensive', and 'Third, the number of hidden units is much larger than a typical matrix factorizationbased method' are explicit and point to specific aspects of the method. While they don't provide concrete solutions, they identify areas that could be further explored or optimized. Therefore, the initial broad statement is somewhat vague, but the subsequent points are more actionable.", "grounding_specificity_rationale": "The review point begins with a general statement about time complexity, which is 1. However, the subsequent points explicitly mention specific components and aspects of the method: 'First, the authors use an itemoriented autoencoder', 'Second, the elementwise function is expensive', and 'Third, the number of hidden units is much larger than a typical matrix factorizationbased method'. These explicit mentions make the grounding fully grounded for those specific points.", "verifiability_rationale": "The review point starts with 'The time complexity seems rather high', which is a subjective assessment and lacks supporting evidence or justification. The subsequent points, 'First, the authors use an itemoriented autoencoder, in which there may be lots of users associated with a typical item', 'Second, the elementwise function is expensive', and 'Third, the number of hidden units is much larger than a typical matrix factorizationbased method', are statements that could potentially be supported by further analysis or comparisons to typical implementations. However, the reviewer does not provide any specific evidence or references to support these claims. Therefore, while the points themselves might be verifiable in a broader context, the lack of supporting information in this review makes the verifiability low.", "helpfulness_rationale": "The review point begins with a general statement about time complexity, which is not particularly helpful for the authors. However, the subsequent points, 'First, the authors use an itemoriented autoencoder, in which there may be lots of users associated with a typical item', 'Second, the elementwise function is expensive', and 'Third, the number of hidden units is much larger than a typical matrix factorizationbased method', are specific and actionable. These points directly point out potential areas where the authors could improve their method or consider alternative approaches. By highlighting these specific issues, the reviewer provides the authors with concrete information to consider, making these latter points 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests an action: 'improve the figures'. Furthermore, it provides a concrete action: 'say pretrained solution encoders & solution decoders'. This directly addresses how the authors should apply the feedback. The action is also explicit, as it clearly states the desired change.", "grounding_specificity_rationale": "The review point explicitly mentions 'figures' as the area needing improvement. It further specifies the *type* of autoencoder relevant to these figures: 'pretrained solution encoders & solution decoders'. This demonstrates a high level of grounding specificity as the authors can directly identify the referenced part and understand the specific issue.", "verifiability_rationale": "While the review point doesn't explicitly state a claim, it suggests a solution based on common knowledge about autoencoders. The suggestion is logical and aligns with established practices. Therefore, it can be considered 3.", "helpfulness_rationale": "The review point directly addresses a specific issue (clarity of figures) and suggests a concrete improvement (using specific types of autoencoders). This makes it 5 for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for an explanation of 'multiaspect' and questions the subscripts in Figure 1. Both are direct requests for information or clarification, making them actionable. The reviewer is prompting the authors to take specific actions: understand a concept and verify a detail.", "grounding_specificity_rationale": "The reviewer asks for an explanation of 'multiaspect.' They can *infer* what it likely means, but they don't have a precise understanding of the specific concept being referred to. Therefore, the grounding is weak. The request about the subscripts in Figure 1 is grounded because the reviewer is asking for specific values (1 and 2) for the subscripts 's' and 't'.", "verifiability_rationale": "The review point itself doesn't contain a claim that needs verification. It's a request for information or clarification. However, if the authors *respond* to the request about 'multiaspect' by providing a detailed explanation referencing relevant sections, that response would be considered highly verifiable. Similarly, a response confirming the subscripts are indeed 1 and 2 would also be highly verifiable. The current review point itself doesn't *require* any external references or logical reasoning to be considered useful.", "helpfulness_rationale": "The review point directly addresses potential areas of confusion for the authors. Requesting an explanation of 'multiaspect' is a common scenario where authors might need clarification. Similarly, questioning the subscripts in Figure 1 is a specific detail that could impact their understanding or implementation. These requests are directly aimed at improving the authors' ability to understand and work on their paper."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks how parts of sentences and documents are extracted, which implies a procedural request. While this could be considered an implicit action (inferring that the reviewer wants to understand the extraction process), the reviewer does not explicitly state what action the authors should take based on this information. The request is more about understanding the methodology rather than directly guiding an improvement on the authors' part.", "grounding_specificity_rationale": "The reviewer asks about the extraction of parts of sentences and documents. While the *review itself* doesn't explicitly identify a specific part of the paper being addressed (like a particular section or table), the question is directly related to understanding how the *review process itself* extracts information. The reviewer is asking about a methodological detail, not a specific weakness in the current draft. Therefore, the grounding is weak because the authors can't confidently determine the *specific* part being discussed in the context of the current draft. However, the question is about a general methodology, which could be considered somewhat grounded in the context of the review process.", "verifiability_rationale": "The reviewer is asking a question about how parts of sentences and documents are extracted. This is a request for information, not a declarative statement that makes a claim or assertion. There is no explicit claim being made, and therefore, it's not verifiable.", "helpfulness_rationale": "The reviewer is seeking clarification on a methodological detail related to how parts of sentences and documents are extracted. While this information can be helpful for understanding the review process, it doesn't directly identify a weakness in the authors' current draft or provide a concrete action for the authors to take based on this information. It's a request for understanding, not a direct improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for information about the computation required to implement the experiments, specifically the time taken, hardware used, and experimental setup. While this information can be useful for reproducibility and understanding the effort involved, it does not directly identify an actionable issue or suggestion for improvement within the draft itself. The request is for data rather than a critique or solution.", "grounding_specificity_rationale": "The reviewer is asking for information related to the experiments described in the draft. However, the request is broad and does not specifically point to a particular part of the paper or methodology that needs improvement. It's more about the context and implementation details of the experiments rather than a targeted critique of a specific section or figure. Therefore, while related to the draft, the grounding is not explicit.", "verifiability_rationale": "The review point itself does not contain a claim or opinion. It is a request for information about the implementation of the experiments. Verifiability applies to claims made in the review, and this point is primarily a question seeking details.", "helpfulness_rationale": "The review point asks for information about the computation required to implement the experiments, specifically the time taken, hardware used, and experimental setup. While this information can be useful for reproducibility and understanding the effort involved, it does not directly critique or suggest improvements within the draft itself. The request is for implementation details, not a critique or solution for the draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point directly asks for clarification on a specific implementation detail: 'Do the authors only apply the meta sampler in a decoupled way?'. This is an explicit request for information, making it actionable. The reviewer is asking for details on how the meta sampler is applied, which is a direct action the authors could take to clarify their methodology.", "grounding_specificity_rationale": "The review point refers to 'the meta sampler' and 'linear classifier', which are specific components of the method. While it doesn't explicitly name a section or table, the context strongly implies a specific part of the paper being addressed. The reviewer is asking about a specific implementation detail, indicating they can infer the relevant part of the paper.", "verifiability_rationale": "The review point is a question, not a declarative statement containing a claim. While it points to a potential area of confusion for the authors, it doesn't present a claim that needs verification. However, it does identify a potential weakness or area for improvement in the authors' presentation by asking about a specific implementation detail. Therefore, it can be considered 3 as it points to a lack of clarity.", "helpfulness_rationale": "The review point highlights a potential area of confusion for the authors regarding the application of the meta sampler. It asks for clarification on a specific implementation detail, which is a direct request for information. While it doesn't propose a solution, it identifies a potential point of weakness in the authors' presentation and encourages them to seek clarification. This makes it 3 as it points to a potential area where the authors might be struggling."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the section (L107114) and suggests a concrete action: 'this should be stated as a remark, or an aside in a Discussion section, or removed'. This directly points to a specific area for improvement and provides a clear action to take.", "grounding_specificity_rationale": "The reviewer not only identifies the section (L107114) but also specifies the nature of the issue: 'seems speculative or overly opinionated'. This demonstrates a clear understanding of the content and the specific problem, indicating full grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim: 'this should be stated as a remark, or an aside in a Discussion section, or removed'. This claim is supported by the reasoning: '7. L107114 seems speculative or overly opinionated'. While the level of opinion is subjective, the reviewer provides a reason for their suggestion, making it verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'this should be stated as a remark, or an aside in a Discussion section, or removed'. This directly helps the authors understand how to improve their draft by either removing the content or moving it to a different section. The suggestion is specific to the identified section and its perceived issue."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment suggests considering baselines, which implies a need to verify performance, but it doesn't explicitly state what action needs to be taken. The action is implicit.", "grounding_specificity_rationale": "The comment does not specify which part of the paper it is referring to. It is a general suggestion about how to verify performance, not a critique of a specific section or element.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a suggestion for an additional step in the verification process.", "helpfulness_rationale": "The suggestion to consider baselines as a way to verify performance is a valuable and helpful piece of advice for the authors, as it directly addresses a common concern in research validation."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the importance of the neighborhood size 'h' and its influence on the model's performance, which is an explicit action. It also suggests investigating the use of a constant set of parameters, which is another explicit action. However, the action of analyzing the influence of 'h' is somewhat vague as it doesn't specify the type of analysis or the expected outcomes. The action of investigating a constant set of parameters is also somewhat vague as it doesn't define what constitutes a 'constant' set or how this analysis would be conducted. Therefore, while the review points identify areas for improvement, the specific actions are not entirely concrete.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. It is a general comment about a missing element and a potential issue with the experimental setup. Therefore, the grounding is weak as the authors cannot confidently determine which part of the paper the comment refers to. The comment is also vague and does not specify what is missing or the nature of the issue with different hyperparameter sets.", "verifiability_rationale": "The review point identifies a key parameter ('h') and its potential influence, which can be considered a claim. It also suggests investigating a constant set of parameters, which can be seen as a suggestion for improvement. However, the claim about the influence of 'h' is not supported by any logical reasoning, common knowledge, or external references. The suggestion to investigate a constant set of parameters is also not verifiable as it lacks specific details on how this investigation would be conducted. Therefore, the claims made in the review point are not wellsupported.", "helpfulness_rationale": "The review point raises several important questions and suggestions regarding the value and influence of the neighborhood size 'h'. It points out a potential gap in the reporting of hyperparameters and suggests a valuable way to improve the understanding of the method's robustness. The request for insights into how performance varies with a constant set of parameters is a direct and actionable question that would be beneficial for the authors. The reviewer also highlights the importance of the neighborhood size 'h', which is a key parameter. Therefore, the review point identifies meaningful weaknesses and suggests concrete improvements, making it 5 for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer's suggestion is a general comment about the SST dataset and its properties, rather than a direct instruction or explicit action to be taken on the submitted work. There is no specific action or modification to the authors' draft implied by this point.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'SST dataset' and 'negation or intensity words', providing a clear reference point within the paper. However, they do not specify *which* part of the paper or section of the dataset they are referring to, nor do they indicate which specific analysis they want to perform. The grounding is implied but not fully explicit.", "verifiability_rationale": "The reviewer is making a suggestion about the dataset, not a claim about a flaw or error in the authors' work. There is X being made that requires verification. This point is more of a suggestion for further analysis rather than a critique or recommendation with supporting evidence.", "helpfulness_rationale": "The reviewer is suggesting an analysis that could potentially provide valuable insights into the dataset. While it doesn't directly address a specific weakness in the authors' current draft, it points out a potential area for improvement in their understanding and modeling of the SST dataset. This could indirectly help them train better models in the future. However, it doesn't provide immediate actionable steps for improving their current work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests alternative methods (freezing layers, LoRA) but does not explicitly state how to implement them or what specific aspect of the model they would address. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The review point mentions 'freezing some layers of the model' and 'LoRA' without explicitly identifying a specific section, table, figure, or unique aspect of the paper being addressed. The grounding is weak as the reviewer doesn't clearly pinpoint the issue.", "verifiability_rationale": "The review point proposes alternative methods without providing evidence or justification for why they would be beneficial in the context of the BERT embedding or SVD. The claim is that these methods *could* provide a basis for comparison, but this is not verified.", "helpfulness_rationale": "The review point offers suggestions for improvement (exploring alternatives) but lacks immediate actionable steps or concrete justifications for why these methods would be beneficial. It's a forwardlooking suggestion rather than a direct critique or solution."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The action is explicit (Expand the related work section, Compare to the strong baselines that use the coordinates), but the implementation is vague. The reviewer doesn't specify how to expand the related work or how to compare to the baselines. This makes the action partially actionable as the 'what' is clear, but the 'how' is missing.", "grounding_specificity_rationale": "The reviewer mentions the 'related work section' and 'strong baselines that use the coordinates,' but they do not explicitly identify a specific part of the paper being addressed. The reviewer can infer the section, but the specifics are lacking. The mention of 'coordinates' is vague and doesn't pinpoint a specific paper or aspect.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion to expand and compare. There is no logical reasoning, common knowledge, or external references provided to support these suggestions. Therefore, it falls under 'X'.", "helpfulness_rationale": "The review point suggests adding context and comparisons to related work. This is a valuable direction for improving the paper's positioning and benchmarking. However, the lack of specific details makes it less immediately actionable. While the general idea is helpful, the missing 'how' reduces its immediate impact on the author's ability to improve their draft. Therefore, it is '2'."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests an action: 'train on multiple seeds' and identifies a problem with the current approach: 'The experiments in the paper are limited to training on a single seed, making it difficult to assess the significance of performance differences...'. The action is both explicit and concrete, directly instructing the authors on how to improve their experimental setup.", "grounding_specificity_rationale": "The review point refers to 'Single Seed Experiments' and 'Multiple seed experiments.' While the suggestion is specific about the type of experiment (multiple seed), the review does not explicitly identify the section, table, or unique aspect of the paper where these experiments are described. The grounding is implied but not directly pointed to.", "verifiability_rationale": "The review point contains a claim: 'The experiments in the paper are limited to training on a single seed, making it difficult to assess the significance of performance differences...'. This claim is supported by the statement that the experiments are 'limited to training on a single seed'. While the *justification* for this being a problem (robustness, statistical significance) isn't explicitly stated within the review point itself, the *action* to address it ('train on multiple seeds') is clear and verifiable.", "helpfulness_rationale": "The review point is 5 as it directly identifies a limitation in the experimental setup (single seed experiments) and provides a concrete suggestion for improvement (training on multiple seeds). This empowers the authors to address a specific issue and enhance the reliability and significance of their results."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that an entire multiGPU setup is required for the optimizations in the proposed method. While this identifies a problem, it does not provide any specific actions or suggestions for the authors to take to address this issue. The reviewer points out a limitation but doesn't offer any concrete steps to overcome it.", "grounding_specificity_rationale": "The reviewer mentions 'multiGPU setup' as the specific part of the paper being addressed. This indicates a degree of grounding as the reviewer is referring to a specific component of the method. However, the reviewer does not specify what is wrong with this multiGPU setup or what needs to be improved within it. The issue is stated as a need, not a specific problem.", "verifiability_rationale": "The review point states that an entire multiGPU setup is required for the optimizations. This is presented as a fact or a claim. However, the reviewer does not provide any evidence, justification, or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that a multiGPU setup is required.", "helpfulness_rationale": "The review point criticizes the requirement for a multiGPU setup, stating it makes the method not very accessible for many potential users. This feedback is primarily critical and focuses on a negative aspect of the method. While the feedback is valid in pointing out a limitation, it does not offer any actionable improvements or suggestions for the authors to make the method more accessible. The feedback is directed at the outcome (lack of accessibility) rather than providing constructive alternatives."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the problem: 'Missing citation for the public skipgram data set'. While it doesn't specify *how* to fix it, it clearly identifies the action needed: adding the citation. This makes it more than just a general comment.", "grounding_specificity_rationale": "The comment explicitly mentions 'skipgram data set' and its location 'L425'. This clearly identifies the specific part of the paper being addressed, making the grounding very strong. It also specifies the type of citation needed ('public'), adding to the specificity.", "verifiability_rationale": "The comment points to a specific location in the paper ('L425') where the missing citation is supposedly located. This provides a clear target for the authors to investigate and potentially verify the absence of the citation. While it doesn't provide a detailed explanation of why it's missing, it does point to a specific area, making it verifiable but not fully justified.", "helpfulness_rationale": "The comment directly identifies a clear omission: the missing citation. By pointing to a specific line number, it guides the authors to the relevant section of the paper. While it doesn't provide a solution, it significantly improves the authors' process by directing them to investigate the missing citation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The suggestions provided are general and do not specify a particular aspect of the system or the proposed improvement. The reviewer is offering a direction for improvement rather than a concrete action to be taken.", "grounding_specificity_rationale": "The comparison between the current system and the system that captures semantics is general and does not specify which part of the system is being compared or which specific aspect of semantic understanding is being discussed. The reviewer is making a broad comparison without pinpointing a specific area of the paper or method.", "verifiability_rationale": "The reviewer is suggesting Ref2 as a strong baseline but does not provide any specific claim or assertion about the current system or Ref2 being superior or inferior. The suggestion is presented as a potential improvement rather than a statement requiring verification.", "helpfulness_rationale": "The suggestions for improvement are vague and lack specific details. While the comparison to Ref2 is a potential helpful addition, the lack of concrete steps makes the overall review point less helpful for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states potential reasons for the model's failure: 'Is one of the assumptions not satisfied? Are there learning difficulties?'. These are direct statements of what might be causing the issue, making the action clear.", "grounding_specificity_rationale": "The reviewer mentions 'the triangle dataset' and 'the model's performance' as the specific parts of the paper being addressed. This is a clear identification of the specific section or aspect being discussed.", "verifiability_rationale": "The reviewer makes a claim: 'It is unclear why the model does not fully succeed in identifying the true sources.' They also suggest potential explanations: 'Is one of the assumptions not satisfied? Are there learning difficulties?'. While they identify a problem and offer possibilities, they do not provide concrete evidence or references to support these claims within the review point itself.", "helpfulness_rationale": "The reviewer points out a potential issue with the model's performance on a specific dataset. They also suggest areas for investigation: 'Is one of the assumptions not satisfied? Are there learning difficulties?'. While this highlights a problem, the suggestions for investigation are vague and lack specific steps or references to make them actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly asks for clarification on how the SE framework can help and why it's relevant. While it implies a connection to the authors' work, it doesn't specify *which* aspects or provide concrete actions. The request is for information, not a direct instruction. Therefore, it lacks explicitness and concreteness.", "grounding_specificity_rationale": "The reviewer doesn't explicitly identify the 'specific part' of the paper they are referring to. They use general terms like 'improve' and 'why and how'. While the request is about the SE framework, it doesn't pinpoint where in the authors' work this framework is intended to be applied. The grounding is weak because the target is vague.", "verifiability_rationale": "The review point is a request for information, not a claim that something is true or false. It doesn't present any assertion that needs verification. Therefore, it doesn't contain a claim that can be evaluated for verifiability.", "helpfulness_rationale": "The review point is a request for clarification and explanation. While it could be helpful for the authors if they receive a detailed response, the review point itself doesn't provide actionable feedback or suggestions. It's a question, not a critique or improvement suggestion. Therefore, it's not helpful in its current form."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks 'Why... only uses the information till time step t'. This is a direct question about a specific implementation detail of the decoderdecoder model, making it an explicit action. The reviewer is directly identifying a modification they believe should be applied (understanding the temporal information flow).", "grounding_specificity_rationale": "The reviewer is asking 'Why... only uses the information till time step t'. This implies an understanding of the current architecture (decoderdecoder) and a desire to understand a specific component (the decoder at time step t). The reviewer is also asking for a reason, which implies they can identify the referenced part (the decoder at time step t) and are seeking clarification on what needs to be addressed (the use of only past information). While the reasoning isn't explicitly stated, the question clearly points to a specific part of the model.", "verifiability_rationale": "The review point states a claim: 'It is not clear why does the user decoder at time step t uses only the information till time step t from the agent decoder and why not use the information from all the time steps?'. This is a subjective statement expressing a lack of understanding. While the *effect* of this design choice (loss of future context) is generally verifiable, the *reasoning* behind this specific choice in the *particular* architecture being reviewed is not provided. The reviewer is asking for justification, indicating a desire for a clearer explanation.", "helpfulness_rationale": "The review point is asking for clarification on a specific aspect of a decoderdecoder model. While the question is valid for someone seeking to understand the temporal information flow, it doesn't offer a concrete suggestion or identify a clear weakness in the model being reviewed. The reviewer is asking a question rather than making a suggestion, which makes it 3 for understanding but not for guiding improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that a section is missing, which is an explicit action. However, it doesn't specify how this section should be implemented, making it somewhat vague. Therefore, the comment is explicitly stated but lacks concrete details on how to apply it.", "grounding_specificity_rationale": "The comment explicitly mentions 'synonym identification section,' which clearly identifies the specific part of the paper being addressed. This is literal mention and implies the unique aspect being addressed. Therefore, the comment is fully grounded. While it doesn't specify the *content* of the section, it clearly identifies where it should be found. The lack of specification about the *approach* makes it less specific in terms of the content, but the section itself is grounded.", "verifiability_rationale": "The comment does not contain a claim. It is a request for information about a missing section. Therefore, it falls under the 'X' category, which is inherently 1.", "helpfulness_rationale": "The comment provides a clear direction for the authors to look for the missing section. While it doesn't provide a solution, it guides them to a relevant part of the paper. This makes it 3 as it directs their attention to a potential area of improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "6: X", "helpfulness_label": "4", "actionability_rationale": "The comment states that an overview is 'needed,' which implies an action (providing an overview). However, the specifics of what constitutes this overview are not explicitly stated, making the action implicit and the details vague.", "grounding_specificity_rationale": "The comment refers to 'the workflow and the model' generally, without specifying a particular section, table, figure, or unique element within the paper. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point is a statement of need ('an overview is needed') rather than a claim that requires verification. There is no assertion of something being correct, incorrect, or requiring justification.", "helpfulness_rationale": "The review point requests an 'overview of the workflow and the model.' While this is generally helpful for understanding, it is a broad request that does not specifically address identified weaknesses or propose concrete improvements. It lacks the specificity and actionable nature of a 5 comment."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem with Figure3, indicating that the authors can identify the issue. Furthermore, the suggestion to 'redefine the figure' is a clear action that the authors can take to improve their draft. The action is also concrete, as the authors know exactly what needs to be done.", "grounding_specificity_rationale": "The review point explicitly mentions 'figure3', which allows the authors to identify the specific part of the paper being addressed. The comment also clearly specifies the issue with this figure, stating that 'expected quantities are scalars but shown as a vector'. This provides a clear indication of what needs to be corrected.", "verifiability_rationale": "The review point makes a judgment about the figure, stating that 'expected quantities are scalars but shown as a vector'. While the reviewer doesn't provide explicit evidence or references to support this claim, the suggestion to 'redefine the figure' implies a clear understanding of what constitutes a correct representation. The lack of explicit evidence makes it less 5, but the suggestion itself provides a clear direction for improvement.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for improving the clarity of Figure3. The authors can directly implement the suggestion to 'redefine the figure' to address the identified issue. The feedback is directly relevant to the figure and offers a concrete improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the issue: \"The ablations seem to deserve better experiment setup.\" This indicates a direct concern and a suggestion for improvement. However, it lacks specific details on what aspects of the ablation or setup are unclear, making it vague on how to apply this action.", "grounding_specificity_rationale": "The reviewer refers to \"the ablations\" and \"experiment setup\" generally, without pinpointing a specific section, table, figure, or unique element within the paper. The reference is broad and lacks specificity, meaning the authors cannot confidently determine which part the comment addresses. The reviewer also mentions \"many questions arise,\" which is general and doesn't specify what needs to be addressed.", "verifiability_rationale": "The reviewer makes a claim: \"The ablations seem to deserve better experiment setup.\" This is a statement that needs to be addressed. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. The statement is presented as a desire for improvement without justification.", "helpfulness_rationale": "The reviewer points out a potential issue with the ablations and suggests improvements by recommending better experiment setup. While the reviewer offers a suggestion, the lack of specific details about the current ablation setup and the nature of the questions that arise makes it difficult to fully grasp the impact and how to implement the suggested improvement. The helpfulness is limited by the vagueness of the suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of empirical evidence for the sememe mapping hypothesis and suggests looking 'deeper' into this. This is a clear and actionable suggestion with a concrete next step.", "grounding_specificity_rationale": "The reviewer mentions 'mapping words to a smaller set of sememes' and 'word similarity data sets'. While they don't explicitly point to a specific section or table, they clearly identify the area of the paper being discussed (the proposed models and the type of data used). This can be considered weak grounding as the connection is implied but not explicitly stated. However, the specificity is high as the reviewer clearly identifies the area of the paper being discussed (the proposed models and their potential benefits).", "verifiability_rationale": "The reviewer makes a claim that 'no empirical evidence is provided to test the hypothesis' and then suggests that 'the word similarity data sets contain frequent word pairs' might explain the improvements, contradicting the potential benefit of the sememe mapping. This constitutes a claim. The reviewer provides logical reasoning but lacks specific examples or references to support this claim. Therefore, the verifiability is somewhat supported.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the authors to 'look deeper' into the empirical evidence. This is 5 as it directly points to a missing piece of their work. While the second part raises a concern without concrete guidance, the overall impact is positive due to the actionable first part."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks for the resolution of the 3D voxel and suggests comparing different resolutions. This is an explicit action. However, the reviewer also states their observation about the 1x1x1 resolution being equivalent to a single global feature, which is not an action but an implicit statement of interest or a deduction. The lack of clarity on how to apply the resolution comparison makes it somewhat vague.", "grounding_specificity_rationale": "The reviewer asks 'What is the resolution of the 3D voxel' and 'does it introduce unnecessary overhead to the whole network?'. These are explicit actions and the resolution is likely mentioned in the paper, making it fully grounded. The reviewer also observes the 1x1x1 resolution, which is an implicit statement but can be inferred as a logical consequence of the voxel concept, making it 3.", "verifiability_rationale": "The reviewer asks 'What is the resolution of the 3D voxel' and 'does it introduce unnecessary overhead to the whole network?'. These are claims that can be supported by logical reasoning and common knowledge about computational costs. The reviewer also observes the 1x1x1 resolution, which is a deduction based on the concept of a voxel. While not explicitly citing external references, the reasoning is generally accepted.", "helpfulness_rationale": "The reviewer asks for the resolution of the 3D voxel, which is a concrete piece of information that could be very helpful for the authors. The suggestion to compare different resolutions is a constructive idea that could lead to a deeper understanding of the impact of voxel resolution. The observation about the 1x1x1 resolution is interesting but doesn't directly propose an action. The questions are clear and directly address implementation details, making them 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing 'error analysis on the movie dataset' and the 'cases that such model fails'. These are direct statements about what is needed, making the action clear and actionable. The reviewer directly implies the authors should provide this information.", "grounding_specificity_rationale": "The review point explicitly mentions 'the movie dataset' and specifies the need for 'error analysis' and 'cases that such model fails'. This clearly identifies the specific part of the paper and the exact nature of the missing information, making it 5.", "verifiability_rationale": "The review point makes a claim about the missing 'error analysis on the movie dataset' and its consequence for 'other researchers to continue on this task'. While it doesn't provide a direct citation, the implication is that the lack of this information hinders progress, making the claim 3 through logical reasoning and the stated need.", "helpfulness_rationale": "The review point is 5 as it directly identifies a specific weakness ('missing error analysis') and its practical impact ('hinders other researchers from continuing'). It provides a clear and actionable suggestion for the authors to 'provide this error analysis and detail the failure cases'."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential issue with Table 3 and suggests investigating the interaction of PM+CL. While it implies the need to develop set trends, it doesn't explicitly state the steps to take, making it partially actionable.", "grounding_specificity_rationale": "The comment directly references 'Table 3' and mentions 'PM+CL', 'PM', and 'CL'. This allows the authors to pinpoint the relevant information and understand the specific behavior being described, making it 5.", "verifiability_rationale": "The comment describes an observation about Table 3 and suggests an action for future analysis. It does not contain a claim that requires verification, thus scoring as 'X (X)'.", "helpfulness_rationale": "The comment points out a potential area for improvement by suggesting the analysis of development set trends related to Table 3. While it doesn't provide a complete solution, it offers a relevant direction for further investigation, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out two issues: (1) difficulty understanding Figure 5 and (2) the metrics being compared to remaining weights. For (1), the reviewer explicitly states the figure is 'difficult to understand' and describes the visual clutter with 'a lot of lines on top of each other.' This is an explicit action as the reviewer identifies a problem. However, the reviewer does not specify *how* the figure is difficult to understand or *what* changes should be made. For (2), the reviewer explicitly states the metrics are 'compared to remaining weights' and suggests reporting 'flops or model size.' This is also an explicit action. While the reviewer identifies the issue, they do not provide concrete steps on how to improve the figure or the metrics. Therefore, both issues are explicit but lack concrete, actionable steps, making them 2.", "grounding_specificity_rationale": "For the issue with Figure 5, the reviewer explicitly mentions 'Figure 5' as the problematic element, making the grounding fully grounded. However, the reviewer does not specify *what* is wrong with the figure or *how* it needs to be improved. The description 'a lot of lines on top of each other' is underspecific. For the issue with metrics, the reviewer mentions 'the main metrics' and 'remaining weights' without specifying *which* metrics or weights are being referred to. This makes the grounding weakly grounded. The reviewer also does not specify *what* flops or model size represent in the context of the metrics, making the suggested metrics underspecific.", "verifiability_rationale": "For the issue with Figure 5, the reviewer makes the claim that the figure is 'difficult to understand.' This is a claim as it expresses an opinion about the figure's clarity. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no explanation of *why* the figure is difficult to understand or *how* it could be improved. For the issue with metrics, the reviewer states that the metrics are 'compared to remaining weights' and suggests reporting 'flops or model size.' While the reviewer is making a claim about the metrics, they do not provide any justification for why comparing to 'remaining weights' is a problem or why 'flops or model size' would be a better alternative. There are no logical arguments, common knowledge, or external references provided to support these claims. Therefore, both claims are 1.", "helpfulness_rationale": "The reviewer points out two areas for improvement: the clarity of Figure 5 and the metrics being reported. For the clarity of Figure 5, the reviewer identifies a genuine issue that could hinder understanding. However, the reviewer does not offer specific, actionable suggestions for improvement. While they point out the problem, they don't provide concrete steps on how to make the figure clearer. For the metrics, the reviewer identifies a potential gap in the information provided. They suggest reporting 'flops or model size,' which are concrete metrics. However, they do not explain *why* the current metrics are insufficient or *how* reporting flops and model size would address the limitations. The reviewer's suggestions are vague and lack specific guidance on how to implement them. Therefore, the helpfulness of the review point is borderline helpful as it identifies potential issues but lacks concrete, actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states, 'Some details of the proposed method are missing, as noted in the questions section below.' This is a general statement pointing to a location where missing details are mentioned. While the *location* of the missing details is explicit (the 'questions section'), the *nature* of the missing details themselves is not. The reviewer *mentions* the missing details (implicitly) and *implies* they need to be addressed in the 'questions section' (which is a pointer, not a direct instruction). Therefore, it is 2. It points to a problem but doesn't give a clear, direct action.", "grounding_specificity_rationale": "The review point refers to 'the proposed method' generally and then specifically mentions 'as noted in the questions section below.' The reviewer is *implying* the missing details relate to the proposed method, but they don't explicitly name a specific section, subsection, or even a type of detail within the method. They point to a location where *potential questions* about missing details might arise. The grounding is at the level of the 'questions section,' not a specific element within the paper.", "verifiability_rationale": "The review point is a statement of fact: 'Some details of the proposed method are missing, as noted in the questions section below.' There is no explicit claim being made. It's a factual statement about missing information. While the reviewer *implies* the missing details are important, the review point itself doesn't state *why* they are missing or what their impact might be. There is no logical reasoning, common knowledge, or external references provided within the review point itself to support the claim of missing details.", "helpfulness_rationale": "The review point points out the absence of some details in the proposed method. While this identifies a problem for the authors, it doesn't offer any specific guidance on what those details are or where they should be located. The reviewer *mentions* the missing details but doesn't provide a concrete action or a direction for improvement. The feedback is limited to pointing out a gap, not suggesting a specific course of action."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'it would be interesting to see how the EIGNN performs...' which indicates a direct request for an evaluation of the EIGNN method in the context of oversmoothing. The action is clear: evaluate performance. The request is also concrete, specifying the method (EIGNN), the problem (oversmoothing), and suggesting a comparison with GCNII. The reviewer is asking for a specific analysis.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the evaluation on oversmoothing' and then further specifies 'in standard settings on realworld datasets, especially in comparison with variants focusing on dealing with oversmoothing, such as the setting used in GCNII.' This clearly identifies the specific part of the paper being addressed. The reviewer provides literal mentions of sections, tables, figures, etc., and even a specific comparison point (GCNII), demonstrating strong grounding.", "verifiability_rationale": "The reviewer's suggestion is based on a concrete experiment with defined parameters (standard settings, realworld datasets) and a clear comparison point (GCNII). The request is logically sound and based on established methodologies for evaluating oversmoothing in graph neural networks. The reviewer is not just stating an opinion but proposing a specific analysis to be performed.", "helpfulness_rationale": "The reviewer's comment directly addresses a relevant issue (oversmoothing) and proposes a specific and actionable experiment (evaluating EIGNN in standard settings on realworld datasets compared to GCNII). This is a highly constructive and helpful suggestion for the authors, as it provides a clear direction for further investigation and comparison."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the missing element: \"a separate part or subsection\". It also clearly identifies the actions needed: \"introduce the inference strategy\" and \"how to use the multiple prompts in the test stage\". The actions are concrete, outlining exactly what needs to be done.", "grounding_specificity_rationale": "The comment explicitly refers to \"the approach method\", which is a specific part of the paper. The reviewer is pointing out a lack of detail *within* that section. The grounding is strong because the section is clearly identified. The specificity is high because the comment pinpointed the exact actions needed: introducing the inference strategy and explaining the use of multiple prompts in the test stage.", "verifiability_rationale": "The comment does not contain a claim or assertion. It is a request for more information or clarification. Therefore, it does not have verifiability in the sense of supporting a claim. The output \"X\" indicates X.", "helpfulness_rationale": "The comment is 5 because it directly addresses a potential area of confusion or lack of clarity in the paper. It points out a specific section and suggests a concrete improvement (adding a subsection and explaining the inference strategy). This directly empowers the authors to address a potential weakness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests discussing the experiment results and clarifying the realworld applications and computational complexity. While these are valid suggestions for improvement, they are not explicitly stated as concrete actions with clear 'how to' instructions. The reviewer implies these are areas for the authors to focus on, but doesn't provide specific steps or modifications they should make to their draft.", "grounding_specificity_rationale": "The reviewer mentions 'experiment results' and 'realworld applications' and 'computational complexity' as areas for improvement. However, they do not explicitly point to a specific section, table, or unique aspect of the paper where these improvements should be made. The reviewer uses general terms, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer does not make any claims or assertions in their review point. They are simply suggesting improvements and areas for clarification. There is X that requires verification or support from external references.", "helpfulness_rationale": "The reviewer's review point suggests improvements and areas for clarification. While these are valid points, they are not presented as direct, actionable steps for the authors to follow. The suggestions are somewhat vague and lack specific guidance on how the authors should approach these improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'I wonder why the results are so low...' and 'More explanations can be given.' This indicates a clear intention to understand the discrepancy in the ablation study results. The request to 'give more explanations' is a direct action the authors could take.", "grounding_specificity_rationale": "The reviewer mentions 'ablation experiments' and names two specific methods 'fCLSWGAN' and 'fVAEGAND2.' While they don't point to a specific table or section within the paper, they clearly refer to a defined set of experiments and baselines. This indicates a degree of grounding.", "verifiability_rationale": "The reviewer states that the results are 'even lower than some simple early methods.' This is a claim that requires justification. The reviewer is making a statement that needs to be supported by reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer's comment directly points to a perceived issue (low ablation study results) and requests further explanation. This is a clear and actionable feedback that can help the authors understand and potentially address the problem. It's a request for information that is likely to be helpful."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the problem ('lack of ablation analysis') and proposes a solution ('it makes it easier to pinpoint the source of performance gain'). The action is clearly stated and directly addresses the identified issue.", "grounding_specificity_rationale": "The reviewer mentions 'lack of ablation analysis' but doesn't specify a unique section, table, figure, or element of the paper where this analysis is missing. The grounding is weak as the authors can only make an educated guess about the location of the problem.", "verifiability_rationale": "The reviewer claims that the lack of ablation analysis makes it difficult to pinpoint the source of performance gain. This claim is supported by common knowledge within the field, as ablation studies are a standard technique for isolating the impact of changes. However, the reviewer does not provide specific examples or references to back up this claim within the context of the 'main paper'.", "helpfulness_rationale": "The review point identifies a valid weakness in the paper's analysis by pointing out the absence of ablation studies. The reviewer's suggestion to include ablation studies is a constructive and actionable piece of feedback that directly addresses the lack of clarity regarding the source of performance gains."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests two specific actions: comparing the model trained on the original dataset with the model trained on the mixture of original and adversarial examples, and highlighting the impact of the augmented adversarial examples. These are both clear and actionable steps that the authors should take to improve their draft. The reviewer provides concrete guidance on what experiments to conduct and how to interpret the results, making the suggestions directly implementable.", "grounding_specificity_rationale": "The review point explicitly mentions 'the base model is trained on the adversarial set only' and 'the model trained on the original dataset'. These are very specific references to parts of the paper, clearly identifying the sections where these training scenarios are described. The reviewer does not need to make any educated guesses to pinpoint these sections; they are directly stated in the paper. This level of specificity ensures the authors can easily locate the relevant information.", "verifiability_rationale": "The review point contains a claim: 'This experiment is not well verified by the designed experiment' and 'It is better to compare the model trained on the original training set in addition to the generated adversarial examples'. The reviewer suggests a specific comparison as a way to improve the verification of the experiment. While the paper itself isn't being verified, the reviewer's suggestion provides a clear justification for why the current comparison is insufficient. The claim is supported by the reviewer's reasoning and the suggested improvement offers a concrete way to address the identified gap in the experimental design. Therefore, the claim is verifiable through the proposed comparison.", "helpfulness_rationale": "The review point is 5. It directly addresses a potential weakness in the experimental design \u2013 the lack of comparison with a model trained on the original dataset \u2013 and suggests a concrete improvement. The reviewer's suggestion is specific, actionable, and directly relevant to the paper's claims. The overall tone is positive and constructive, indicating a desire to help the authors improve their work. The reviewer provides clear guidance on what experiments to conduct and how to interpret the results, making the feedback directly applicable to the paper."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state what is wrong with the CNN experiments or what needs to be changed. It only expresses an opinion that the experiments are 'not fully convincing'. There is no clear action or instruction for the authors to follow.", "grounding_specificity_rationale": "The reviewer refers to 'the CNN experiments' generally, without specifying which particular experiments or aspects of the CNN are being discussed. This lack of specificity makes it difficult for the authors to pinpoint the issue.", "verifiability_rationale": "The review point expresses an opinion ('The CNN experiments are not fully convincing') without providing any specific examples, references, or logical reasoning to support this claim. There is X that can be verified.", "helpfulness_rationale": "The review point is a subjective opinion ('The CNN experiments are not fully convincing') without offering any concrete suggestions or pointing out specific weaknesses. The authors are left without actionable feedback to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point encourages the authors to doublecheck the results in Table 1, but it doesn't explicitly state *how* to verify the discrepancy or *what* the expected outcome should be. While it implies a potential issue, the specific action isn't clearly defined.", "grounding_specificity_rationale": "The review point mentions \"Table 1,\" \"model (3) (Chung et al. 2016),\" and \"CsEn,\" which provides some grounding by identifying the specific part of the paper being referenced. However, it doesn't specify *which* result within Table 1 is incorrect or *what* the discrepancy is. The authors still have to infer the location of the issue.", "verifiability_rationale": "The review point makes a claim that the results for model (3) were not taken from the papers and that the authors might have computed them. This claim *could* be considered verifiable if the authors provided evidence of their computation or if the cited papers explicitly stated they didn't report these results. However, the reviewer doesn't provide specific examples or references to support this claim.", "helpfulness_rationale": "The review point identifies a potential inconsistency in the reported results and asks the authors to clarify. This is a helpful feedback point as it points out a discrepancy that needs attention. However, it doesn't offer a definitive solution or a specific direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing with SoTA approaches, which is a valid piece of advice. However, it doesn't explicitly state *how* to go about comparing or what specific comparisons would be beneficial. It's a *suggestion* but lacks the *concrete steps* needed for action. Therefore, it's 3 but not fully actionable.", "grounding_specificity_rationale": "The review point is a general suggestion about comparing with SoTA approaches. It doesn't mention any specific section, table, figure, or unique aspect of the paper. It's a broad statement about the need for comparison, lacking specificity about *where* the comparison should occur.", "verifiability_rationale": "The review point is a suggestion to compare with SoTA approaches. It doesn't make a claim that *something is wrong* with the current approach or propose a solution. It's a suggestion, not a statement that needs verification.", "helpfulness_rationale": "The review point suggests comparing with SoTA approaches, which is a relevant and helpful direction for improvement. It provides a potential way to enhance the work by staying current with the field. While it's a general suggestion, it's still a valuable direction for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "Partially actionable. The reviewer points out a missing justification, but doesn't provide a specific, actionable step for the authors to take.", "grounding_specificity_rationale": "1. The reviewer doesn't pinpoint the exact location or detail within the paper.", "verifiability_rationale": "Partially verifiable. The reviewer makes a claim about a lack of clarity, but doesn't provide evidence to support it.", "helpfulness_rationale": "Partially helpful. The review points out a potential issue and offers a related idea, which could lead to further discussion and potentially improvements. However, it doesn't provide a direct solution or actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks 'is this issue solved in the proposed knowledgeCLIP model?' which is a direct question prompting the authors to check a specific aspect of their model. While it doesn't directly tell them *how* to solve it, it identifies a specific area for investigation. The suggestion to perform an analysis is a logical next step, making it 3 in guiding further investigation. However, it doesn't provide a concrete action or solution, making it not fully actionable in terms of directly improving the draft.", "grounding_specificity_rationale": "The review point refers to 'the proposed knowledgeCLIP model' and 'the specific issue'. While it names the model, it doesn't explicitly identify the *section*, *table*, or *unique aspect* of the paper where the model is described. It also doesn't specify the *exact nature* of the 'specific issue'. Therefore, the grounding is weak. However, once the authors identify the model and the issue, the suggestion to perform an analysis is quite specific, indicating some level of specificity in identifying the content to be analyzed.", "verifiability_rationale": "The review point contains claims: 'is this issue solved in the proposed knowledgeCLIP model?' and 'Some existing work that combines text and KG... It would be very interesting if the authors perform such analysis on the proposed knowledgeCLIP model...'. The first claim asks a direct question about the model's performance. The second claim suggests an analysis based on existing work. While it doesn't provide a definitive answer or cite a specific example within the review point itself, the logical reasoning and reference to existing work make it 3. The suggestion to perform the analysis provides a clear direction, making it 3.", "helpfulness_rationale": "The review point directly addresses a potential weakness in the model by asking if a specific issue is solved. It then suggests a concrete analysis to investigate the model's robustness. This directly points the authors to a specific area for improvement and provides a clear next step. The suggestion to perform the analysis is a helpful and actionable suggestion for the authors to take. Therefore, the review point is 5 in guiding the authors to improve their draft by investigating the model's performance and robustness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "None", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the issue: 'For clarity, consider explaining a bit more how novel values in the test set are handled.' This clearly indicates an action the authors should take (explain) and what aspect they are referring to (novel values in the test set). The phrasing is direct and leaves no ambiguity about the intended action. The authors are asked to provide more detail on a specific implementation aspect.", "grounding_specificity_rationale": "The review point explicitly refers to 'novel values in the test set.' This is a very specific part of the paper being addressed. The reviewer is not making a general comment about the test set, but rather focusing on a particular characteristic ('novel values'). The mention of 'test set' also implies a specific section or aspect of the paper. The reviewer is pointing to a concrete detail that needs clarification.", "verifiability_rationale": "X", "helpfulness_rationale": "The review point identifies a potential area of confusion for the authors by pointing out the lack of clarity regarding 'how novel values in the test set are handled.' While it doesn't directly identify a weakness in the authors' work, it highlights a missing explanation that could hinder their understanding and ability to reproduce or build upon the research. It encourages the authors to provide more detail, which can be helpful for their clarity. However, it doesn't offer a solution or directly address a problem, so it's not fully helpful in improving the draft itself."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The comment includes an implicitly stated action but is vague on how to execute it.", "grounding_specificity_rationale": "The authors cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part.", "verifiability_rationale": "The claim contains a claim (i.e., an opinion, judgment, or suggestion) or, if so, how well that claim is supported using logical reasoning, common knowledge, or external references. The comment states \"the writing is too confusing I cannot be sure if that is the case or not.\" This is a statement of opinion and common knowledge, but the reviewer expresses uncertainty, making it 1.", "helpfulness_rationale": "The review point provides a suggestion for improvement (using a generic external knowledge base) but lacks specific details on how to implement it. The phrase \"I cannot be sure if that is the case or not\" indicates a lack of clarity and impact on the authors. The helpfulness is low because the specific steps for using the generic knowledge base are not provided, and the confusion about writing clarity is a significant point for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking specific questions about the choice of 0.6 for glove embedding similarity and whether kcrossvalidation was used. While not explicitly stating an action to be taken, the questions prompt the authors to provide more detail about their methodology and hyperparameter selection, which can be considered an implicit action. The reviewer is also asking about the potential impact of other loss functions, which again encourages the authors to elaborate on their choices.", "grounding_specificity_rationale": "The reviewer is directly asking about the 0.6 value for glove embedding similarity and whether kcrossvalidation was used. This shows a clear attempt to understand specific parts of the paper (the GloVe embeddings and the evaluation procedure). The questions are also specific to the potential impact of other loss functions, indicating a focus on specific aspects of the method.", "verifiability_rationale": "The reviewer is asking questions that require the authors to provide more detail about their choices and methodology. For example, they are asking about the rationale behind choosing 0.6 for GloVe embeddings and whether kcrossvalidation was used. These are requests for justification and evidence, which aligns with the concept of verifiability. The questions about the potential impact of other loss functions also imply a need for more information to support their claims.", "helpfulness_rationale": "The reviewer is asking for clarification on specific implementation details, such as the choice of the 0.6 value for GloVe embeddings and whether kcrossvalidation was used. These questions directly aim to improve the authors' understanding and the reproducibility of their work. The reviewer is also asking about the potential impact of other loss functions, which encourages the authors to provide more context and justification for their choices."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a weakness: 'Missing indepth analysis on experimental results' and provides an example: 'For example, why the improvements of models are limited on offense detection dataset and are significant on coarse stereotype set?'. This indicates a clear area for improvement. While the reviewer doesn't explicitly state the exact steps the authors should take, they provide a clear direction for the authors to explore the inconsistencies in their results. The reviewer implies a need for a more detailed investigation into the factors contributing to these differences.", "grounding_specificity_rationale": "The reviewer mentions 'experimental results' generally and provides a general example of inconsistencies. They do not specify which tables, figures, or sections of the paper contain these results. They also do not point to a specific calculation or analysis that is missing. The reviewer's statement is broad and lacks pinpointing of the exact issue.", "verifiability_rationale": "The reviewer makes a claim: 'Missing indepth analysis on experimental results'. They also provide evidence for this claim by asking a question: 'For example, why the improvements of models are limited on offense detection dataset and are significant on coarse stereotype set?'. This question serves as a form of justification for their claim, indicating that the reviewer has observed these inconsistencies and considers them a significant gap in the analysis. While they don't cite external literature, the example itself acts as a form of internal evidence.", "helpfulness_rationale": "The reviewer clearly identifies a weakness: the lack of indepth analysis of experimental results. They provide a specific example to illustrate this weakness, highlighting the inconsistency in performance across different datasets. This makes the feedback actionable and guides the authors to explore the reasons behind these differences. While the reviewer doesn't offer specific solutions, they highlight a significant area that needs attention, which is valuable for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the recommendation to use modern backbone baselines (Resnet50 or DenseNet121) and provides a concrete reason (3 conv layers being too small). Both the explicit action and the concrete details make this 5.", "grounding_specificity_rationale": "The review point explicitly mentions specific modern backbone baselines (Resnet50 and DenseNet121) and a specific size (3 conv layers) as being relevant. This allows for precise identification of the parts of the paper being addressed, resulting in full grounding and specificity.", "verifiability_rationale": "The review point contains the claim 'I have to say that even given this version of the idea, I am skeptical this would work', which requires justification. While the reviewer provides a general reason ('lots of such robustness/domain invariance interventions have been proposed and have failed'), this justification is not specific to the *review point itself* and is expressed as a general opinion, making it 3.", "helpfulness_rationale": "The review point provides a clear recommendation to use modern backbone architectures, which is an actionable suggestion. However, the reviewer's expressed skepticism, framed as advice, reduces the overall helpfulness. While the point is valid, the uncertainty makes it 3 rather than 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action (tuning the baseline) but is vague on how to execute it (e.g., what constitutes 'similar resources').", "grounding_specificity_rationale": "The comment explicitly mentions which part of the paper it addresses (the baseline) and mentions specific hyperparameters, making the grounding explicit. However, it doesn't specify the method of tuning or the exact nature of 'similar resources'.", "verifiability_rationale": "The comment contains a claim (suggesting tuning the baseline) and provides a logical connection (ensuring fair comparison). However, it lacks specific references to external works.", "helpfulness_rationale": "The comment offers a relevant suggestion (tuning the baseline) that is important for ensuring fair comparisons, but it lacks specific details on how to achieve this."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two explicit statements that directly identify potential errors in the paper's description of perplexity and its relation to crossentropy. The first statement directly challenges the definition of perplexity, and the second statement challenges the association of Eq1 with perplexity. Both statements are clear and point to specific issues, making them concrete.", "grounding_specificity_rationale": "The reviewer provides specific line numbers (L259) and an equation reference (Eq1) to support their claims about the incorrect definition of perplexity and its relation to crossentropy. This demonstrates strong grounding specificity as the reviewer accurately identifies the location of the potential error within the paper.", "verifiability_rationale": "The reviewer's claim about the incorrect definition of perplexity and the incorrect association of Eq1 with perplexity is verifiable based on established definitions in natural language processing. Perplexity is a measure of how well a probability model predicts a sample. Crossentropy is a loss function used to train models. Eq1, if it represents the crossentropy loss, would be more appropriate than the perplexity definition provided. The reviewer's claim is either correct or incorrect based on these definitions.", "helpfulness_rationale": "The reviewer's point is likely to be 5 for the authors. By directly pointing out potential errors in the paper's description of perplexity and crossentropy, the reviewer is providing specific and actionable feedback that could help the authors correct their understanding of these key concepts. This is a valuable contribution to the review process."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'In the graph classification task, the compared baseline is not sufficient' and provides concrete suggestions: 'such as MVGRL4, gptgnn5 are missing'. The suggestions are directly tied to the identified problem and offer clear actions the authors should take. The reviewer also points out the *lack* of these baselines, which is an implicit action that needs to be addressed by adding them.", "grounding_specificity_rationale": "The reviewer clearly identifies the 'graph classification task' as the area being discussed and specifies the type of baselines 'graph contrastive learning' as the issue. The suggestions to 'add MVGRL4, gptgnn5' directly address the identified area and type of baselines. While the reviewer doesn't pinpoint a specific part of a method, they clearly identify the *category* of missing baselines and suggest specific examples within that category.", "verifiability_rationale": "The reviewer makes a clear claim: 'In the graph classification task, the compared baseline is not sufficient, such as MVGRL4, gptgnn5 are missing.' This is a factual statement that doesn't require external references or logical reasoning to understand. The reviewer is stating an observation about the current baselines used in the graph classification task.", "helpfulness_rationale": "The reviewer's comment directly points out a weakness in the experimental setup (insufficient baselines) and provides concrete suggestions for improvement (adding specific methods). This directly addresses a potential bottleneck for the authors who might be evaluating their own graph classification methods. The feedback is clear, actionable, and directly relevant to improving their understanding of the field."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an *additional* evaluation scenario but doesn't explicitly state *what* action the authors should take or *how* they should implement this new evaluation. While it implies a connection to the 'purify the input image' strategy, this connection is not made explicit. Therefore, while relevant, it lacks the explicit actionability required to directly guide the authors' next steps.", "grounding_specificity_rationale": "The review point mentions 'edge map based defense strategies' and 'minimal structural alterations' as key aspects of the proposed evaluation. However, it doesn't specify *which particular edge map defense strategy* the authors are targeting or *how* to measure or define 'minimal structural alterations'. This lack of specificity makes it weakly grounded.", "verifiability_rationale": "The review point contains a claim: 'It is crucial to evaluate the proposed defense against an adversarial attack which craft the adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions.' However, it does not provide any justification or reasoning for why this claim is crucial or how it can be verified. It lacks the logical reasoning, common knowledge, or external references needed to assess its verifiability.", "helpfulness_rationale": "The review point raises a valid concern about the limitations of the current evaluation strategy and suggests an *additional* evaluation scenario. While relevant to the field of adversarial attacks and defense mechanisms, it lacks concrete details and actionable steps for the authors. It doesn't explain *how* this new evaluation would help them improve their 'purify the input image' strategy or provide any guidance on *how* to perform this evaluation. Therefore, while relevant, it is not sufficiently detailed to be 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing theoretical aspects (existence and smoothness of SDE solutions, discretization guarantees) that need to be addressed. This provides clear and actionable feedback for the authors to strengthen their analysis.", "grounding_specificity_rationale": "The reviewer mentions 'theoretical work on sampling and particlebased optimization methods' which is a general concept tied to the paper as a whole, not a specific section or element. However, the reviewer also explicitly names 'existence and smoothness of the solution of SDE (2a)(2d)' and 'any guarantees of the discretization (in time and space)' as specific issues. This indicates a degree of specificity in the identified problems.", "verifiability_rationale": "The reviewer presents a claim that the analysis is 'somewhat weak' and then identifies specific areas lacking theoretical backing. This constitutes a claim that is partially supported by the absence of explicit theoretical discussions and proofs in the mentioned aspects.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors to strengthen their analysis by referencing existing theoretical work on sampling and particlebased optimization methods. They specifically point out the missing aspects of SDE solutions and discretization guarantees, making the improvement concrete and verifiable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states 'Quality of generated images by proposed method is limited.' This indicates a clear problem. However, the reviewer does not specify *how* the quality is limited, making the actionable suggestion 'improve the realism of generated results' somewhat vague. Therefore, the comment is 3 as it points out a weakness and suggests an improvement, but lacks specific details on what needs to be addressed.", "grounding_specificity_rationale": "The reviewer refers to 'generated images by proposed method' and 'realism of generated results.' While they identify the area of concern, they do not explicitly point to a specific section, table, or figure in the paper. However, they do specify the *quality characteristic* being discussed, which is 'realism.' This makes the grounding somewhat weak as the exact location is not pinpointed, but the issue being addressed is clearly defined.", "verifiability_rationale": "The reviewer makes a claim that 'While good continuous control is achieved, the realism of generated results showed in paper and supplemental material is limited.' This is a statement of observation. The reviewer provides a reason ('While good continuous control is achieved') which offers some justification. However, they do not provide specific examples from the paper or external references to support their claim about the limited realism. Therefore, the claim is 3 as it is supported by a reason, but lacks concrete evidence.", "helpfulness_rationale": "The reviewer clearly identifies a problem with the generated images ('Quality of generated images by proposed method is limited') and suggests a direction for improvement ('improve the realism of generated results'). This provides authors with a clear goal to work towards. While the suggestion is somewhat vague, it is still a constructive direction. Therefore, the comment is helpful as it points out a weakness and suggests a way to address it, even if the specifics are not fully detailed."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The reviewer provides a clear and explicit request for information about the graph G. They specify *how* they built G using the human skeleton and ask for the size, elements, and dimensions of G, X, and W. These are concrete details that the authors can directly use to understand the methodology and the DGCN model's operation. The reviewer directly identifies an area where the authors might be struggling and offers a clear path to clarification.", "grounding_specificity_rationale": "The reviewer explicitly points to Section 3.3 as the location of the issue. They then provide specific requests for information within that section, such as the size and elements of G, and the dimensions of G, X, and W. This demonstrates strong grounding as the authors can directly identify the problematic section and the exact information needed to understand it.", "verifiability_rationale": "The reviewer's comment can be seen as a claim that the explanation of G in Section 3.3 is lacking. They then provide a clear request for additional details to make the explanation more verifiable. They are not just stating a problem; they are also providing a specific path to understanding it by asking for the size, elements, and dimensions of the relevant variables.", "helpfulness_rationale": "This review point is 5 because it directly addresses a specific area of confusion (Section 3.3) and provides clear, actionable steps for the authors to take. By asking for the size, elements, and dimensions of the variables, the reviewer is guiding the authors to the exact information they likely need to understand the construction of G and the DGCN model's application. This is a very direct and useful piece of feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a specific detail about the implementation of the Cycle Consistency loss, stating that the backpropagation process involves two separate standard backpropagation processes. While the authors' description might be implicit, the reviewer provides a concrete detail about the implementation. The reviewer is suggesting a specific correction to the authors' understanding of the method. This suggests an explicit action is being pointed out, even if the overall description might be implicit. The reviewer is also providing a concrete detail about the backpropagation process.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Lines 559560' of the paper, providing a specific location. They also refer to 'Cycle Consistency loss' and 'two phases of the reconstructions (ABA and BAB)'. While 'Cycle Consistency loss' is a general term, the specific phases are also mentioned, further pinning down the location. The reviewer is specifying the *type* of backpropagation involved (two separate standard backpropagation processes). This level of detail indicates that the reviewer has identified a specific aspect of the method being discussed.", "verifiability_rationale": "The reviewer makes a claim that the authors' description of the Cycle Consistency loss is 'not entirely true'. This is a claim that requires verification. The reviewer then provides a specific detail about the implementation, stating that the backpropagation process involves two separate standard backpropagation processes. This detail can be verified by examining the method description or implementation details of the Cycle Consistency loss. The reviewer is providing a specific piece of information that can be used to verify the authors' claim.", "helpfulness_rationale": "The reviewer is providing a correction based on their understanding of the method. They are pointing out a specific detail that they believe is missing or inaccurate in the authors' description. This correction is likely to be helpful for the authors in understanding the implementation details correctly. The reviewer is providing a specific and actionable feedback that directly addresses a potential misunderstanding of the method."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the issue: \"calling 'hyperspectral' is confusing.\" This indicates an implicit action or suggestion that the reviewer understands the term 'hyperspectral' might be confusing for others and is calling out this potential issue. However, the reviewer does not provide a concrete action or suggestion on how to address this confusion, making it only implicit and lacking detail on how to apply it.", "grounding_specificity_rationale": "The reviewer mentions \"hyperspectral\" generally but does not explicitly identify a specific part of the paper where this confusion arises. They do not mention a specific section, table, figure, or unique aspect of the paper related to 'hyperspectral'. Therefore, the grounding is weak as the reviewer cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point is a statement of observation: \"calling 'hyperspectral' is confusing.\" It does not contain a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support this statement. Therefore, it lacks a claim and cannot be considered verifiable.", "helpfulness_rationale": "The review point identifies a valid issue: the potential confusion surrounding the term 'hyperspectral'. However, it does not offer any actionable suggestions or improvements. The reviewer simply points out the problem without providing any concrete steps or insights on how to address it. Therefore, it lacks helpfulness as it does not propose any solutions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The request is clear and directly asks for information about the contribution of each component to the final performance. It is explicit about what information is needed (contribution to performance) and it is concrete, specifying the components involved (Linformer, Window Attention, BigBird, Contrition). The reviewer is asking for a breakdown of how each component contributes, which is a direct request for action.", "grounding_specificity_rationale": "The request mentions the components (Linformer, Window Attention, BigBird, Contrition) but does not explicitly state where in the paper this information should be found. While the components are named, the reviewer doesn't specify a particular section, table, figure, or unique aspect of the paper that this information relates to. The connection to the ablation studies in Section 3 and 4 is implied but not explicitly stated as the location of this information.", "verifiability_rationale": "The request itself is not a claim or assertion. It is a request for information about the contribution of components. Therefore, it does not fall under the definition of verifiability, which involves evaluating whether a claim is supported by evidence.", "helpfulness_rationale": "The request is clear and directly asks for information that would be valuable to the authors. It identifies a gap in the current analysis (the ablation studies) and asks for a breakdown of how each component contributes to the final performance. This information would directly help the authors understand the impact of each component and potentially guide future improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states what is missing ('grammar over kernels is not explained in any detail') and provides a clear action for the authors ('explain how this approach is applied in practice'). This is a direct and actionable suggestion.", "grounding_specificity_rationale": "The reviewer specifically mentions 'grammar over kernels' as the missing detail and asks 'how is this approach applied in practice'. This clearly identifies the specific part of the paper and the issue within it, making it 5.", "verifiability_rationale": "The reviewer makes a claim about the missing details of 'grammar over kernels' and asks specific questions about their implications ('how does this affect the hypothesis space? How is inference performed?'). This claim is supported by logical reasoning and specific examples, making it 5.", "helpfulness_rationale": "The reviewer's point directly addresses a potential weakness in the paper (lack of detail on a specific modeling aspect) and offers concrete suggestions for improvement. This is a 5 comment for the authors."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "Partially Verifiable", "helpfulness_label": "5", "actionability_rationale": "The review point implicitly suggests that the ablation study is missing crucial information about the effectiveness of the perception module. While the reviewer points out the similar performance in the ablation, they don't explicitly state how to implement the 'w/o perception' condition, making the action implicit.", "grounding_specificity_rationale": "The reviewer mentions 'the ablation study' and 'Table 10', providing some grounding. However, they do not explicitly state which table or provide details on the implementation of the 'w/o perception' module, making the grounding only 'Weakly Grounded'. While the reviewer identifies a potential area for clarification, the grounding itself is not fully specific.", "verifiability_rationale": "The reviewer claims the ablation study is inconclusive and the results are questionable, providing some justification for the claim. However, they do not offer new verifications or references to support their claim about the inconclusiveness of the ablation. The reasoning is present, but the lack of further support makes it 'Partially Verifiable'.", "helpfulness_rationale": "The review point is 5 as it directly addresses a potential issue in the authors' experimental setup and results. The reviewer encourages the authors to reexamine their ablation study and consider the possibility of a flawed methodology or inconclusive results. This provides actionable guidance and raises critical questions, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that 'previous works on Lasso screening are not cited or compared' and suggests that this omission is a weakness. This is a clear and direct criticism of a specific aspect of the paper's presentation. The action is to acknowledge the missing citations, and the method is to compare the performance of Transfer Lasso with existing Lasso screening methods. This is a concrete action as it specifies the comparison to be made.", "grounding_specificity_rationale": "The review point explicitly identifies the specific issue as 'Transfer Lasso showed the best accuracy in feature screening' and then directly points out the lack of citations to relevant prior work on Lasso screening. The authors can easily identify the specific part of the paper being addressed (the claim about Transfer Lasso's accuracy and the need for comparison), and the issue within that part (missing citations). This is fully grounded. Furthermore, it clearly specifies what is wrong (lack of comparison) and what needs to be improved (citations). This is 5.", "verifiability_rationale": "The review point contains a claim: 'previous works on Lasso screening are not cited or compared'. While it identifies a gap in the paper's presentation, it doesn't provide specific examples or references to support this claim within the review point itself. Therefore, it is not 5. The claim is that previous work exists and is missing, but the review point doesn't delve into specific examples or provide a logical reasoning for *why* these works are missing or why their comparison is important.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper's presentation by pointing out the lack of citations and comparison to previous Lasso screening work. While it doesn't directly tell the authors what to cite, it encourages them to look into prior work and compare their method. This is a 3 suggestion as it points towards a direction for improvement, even if it doesn't provide a complete solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that 'the model has many components whose hyper parameters are not fully provided.' This indicates an explicit action or suggestion that the authors should provide details about these hyperparameters. However, the comment does not specify which components are affected or what specific information is missing, making the action somewhat vague.", "grounding_specificity_rationale": "The comment 'the model has many components whose hyper parameters are not fully provided' does not identify a specific part of the paper being addressed. It refers to 'many components' generally without pinpointing a section, table, figure, or unique element. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The comment points out a potential issue ('many components whose hyper parameters are not fully provided') but does not offer any justification or reasoning for why this is a problem or how it should be addressed. It is a statement of a deficiency without supporting evidence or a proposed solution. Therefore, the claim is 1 as there is no logical reasoning, common knowledge, or external references provided to support the statement.", "helpfulness_rationale": "The comment identifies a valid concern about the lack of information regarding hyperparameters in the model components and suggests that the authors should provide this information to improve their work. While the comment doesn't specify *how* this information is missing or *why* it's important, it does point out a actionable area for improvement and suggests the authors take steps to address it. Therefore, the comment is 3 in guiding the authors towards a solution, even if the solution is not fully specified."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'The notation for results is not clear. The paper claims the improvement for CIFAR10 is 3%p but it is not clear what %p stands for.' This is a direct and clear action identified by the reviewer.", "grounding_specificity_rationale": "The reviewer points to a specific result ('CIFAR10') and a specific metric ('improvement') and even a specific notation ('3%p') as unclear. This demonstrates strong grounding as the reviewer can accurately identify the referenced part of the paper and specify the exact detail causing confusion.", "verifiability_rationale": "The reviewer makes a claim: 'the paper claims the improvement for CIFAR10 is 3%p but it is not clear what %p stands for.' This claim is verifiable as the paper is indeed making this claim without defining the percentage notation, creating a gap in the information that needs justification or clarification.", "helpfulness_rationale": "The reviewer provides a clear and actionable criticism. They are directly pointing out a specific, actionable issue in the paper's reporting, which is 5 for the authors to understand and address."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states their desire to understand *why* TSS was used, indicating a clear action the authors should take (clarification). While the action is stated, the *details* of how to apply this action (the reasoning behind TSS) are missing, making it partially actionable.", "grounding_specificity_rationale": "The reviewer refers to 'style control' generally, without specifying the exact aspect of style control being evaluated. This implies a lack of precise identification of the referenced part, making it 3.", "verifiability_rationale": "The reviewer raises a valid concern about the justification for using TSS, stating they 'don\u2019t understand why'. This indicates a lack of supporting evidence or justification for the claim that TSS is an appropriate metric for style control in this context, making it 1.", "helpfulness_rationale": "The reviewer's comment directly impacts the authors' understanding and the perceived rigor of the human evaluation. The lack of clarity regarding the choice of TSS weakens the convincingness of the evaluation process, making it 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a weakness ('The paper does not evaluate the magnitude of interpretability tax associated with the method.') but does not provide a direct action or suggestion for improvement. While it identifies a problem, it doesn't tell the authors what to do to address it. Therefore, it is 2 as it points to a weakness but lacks a direct action.", "grounding_specificity_rationale": "The comment refers to 'the paper' in general and mentions 'the interpretability tax' without specifying which part of the paper or what aspect of the tax is being evaluated. It lacks precision in identifying the specific section, table, figure, or unique element of the paper being addressed. Therefore, it is 1.", "verifiability_rationale": "The comment contains a claim ('The paper does not evaluate the magnitude of interpretability tax associated with the method.') but does not provide any logical reasoning, common knowledge, or external references to support this claim. It simply states the observation without further explanation or evidence. Therefore, it is not verifiable as it lacks supporting evidence or justification.", "helpfulness_rationale": "The comment identifies a potential area for improvement by highlighting the lack of evaluation of the interpretability tax. However, it does not provide any specific suggestions or actions for the authors to take. It points out a weakness but doesn't offer concrete guidance on how to address it. Therefore, it is 3 as it points to a weakness, but it lacks actionable suggestions."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out that the LUQ design is 'straightforward to design' and that the approaches in Sec. 5 are 'standard and to some extent explored in previous literature'. While the reviewer identifies a potential weakness in the novelty of the approach, the action is to point out this lack of novelty, which is actionable for the authors to consider alternative approaches or framing. However, the reviewer doesn't specify *how* the authors should adjust their approach.", "grounding_specificity_rationale": "The reviewer refers to 'the LUQ design' and 'the approaches in Sec. 5'. While they mention a section, they don't pinpoint a specific subsection, table, figure, or unique aspect of the paper. The reference to Sec. 5 is broad.", "verifiability_rationale": "The reviewer makes a statement about the LUQ design being 'straightforward' and the methods being 'standard'. These are claims that could be supported by pointing to the underlying principles of uniform quantization and the general nature of quantization techniques. However, the reviewer doesn't explicitly state *why* they are straightforward or standard, nor does they provide specific references.", "helpfulness_rationale": "The reviewer's main point is that the contribution is 'showing that such a simple combination of existing techniques is sufficient to achieve (surprising good) accuracy, rather than proposing novel techniques.' This is a valid point, but it's a critique of the contribution rather than a direct guide on how to improve the LUQ design itself. While it prompts the authors to consider the novelty of their work, it doesn't directly offer concrete steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their wish to see training losses, which is a direct action. However, the specifics of how they envision seeing these losses are not detailed, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'deep localization network' and 'Sinkhorn' which are specific terms. However, they do not explicitly identify which part of the paper or their work this comment refers to. The grounding is weak because the reviewer cannot confidently determine the referenced part.", "verifiability_rationale": "The review point is a question about the feasibility of training a deep localization network with Sinkhorn and the desire for training losses. This is not a claim that can be verified with logical reasoning, common knowledge, or external references. It's a request for information.", "helpfulness_rationale": "The reviewer's request for training losses is a concrete piece of information that could be valuable for someone implementing or researching deep localization networks. The desire for clarification also indicates a need for more specific guidance. While not a direct claim, the request provides a clear direction for the authors to seek more detailed information."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer criticizes the effectiveness and cost of automatic scores, implying a suggestion to use human evaluation instead. This is an implicit suggestion, making it 2. The reviewer does not explicitly state an action or suggestion, but rather criticizes the *potential* action of using automatic scores. The suggestion to use human evaluation is implied but not directly stated as an action to be taken.", "grounding_specificity_rationale": "The reviewer mentions the 'abstract section' and 'FLAMEbased evaluation systems (like Chatbot Arena)'. While they identify the *type* of evaluation system, they don't explicitly point to a specific component within it as being problematic. The grounding is present but not pinpointed to a concrete part of the system or paper. The reviewer's statement is general and doesn't specify which part of the FLAME system is being criticized.", "verifiability_rationale": "The reviewer makes a statement about the limitations of automatic scores and the nature of FLAMEbased evaluations. While they state these points, they don't provide specific examples or citations to back them up. The claim is present, but the supporting evidence is lacking. The reviewer states their opinion about the limitations without providing concrete examples or references.", "helpfulness_rationale": "The reviewer explicitly criticizes the proposed method (automatic scores) and the applicability of arenabased evaluation systems (like Chatbot Arena) to single dialogue system evaluation. They express a strong negative opinion about their effectiveness and the lack of alternatives for evaluating a single dialogue system. This directly addresses the value and usefulness of the proposed approach for the authors. The reviewer's statement is a direct critique of the value of this approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the computational cost (2x samples) and the resulting performance impact (1.5x slower). This is a clear and direct statement of an action and its consequence. The reviewer also implies a suggestion regarding the fairness of comparisons.", "grounding_specificity_rationale": "The reviewer directly refers to 'RegMixup' and its 'training' process. This is a clear and specific reference to the method being discussed. The reviewer also specifies the impact of the 2x sample usage on the 'running speed'.", "verifiability_rationale": "The reviewer makes a claim about the computational cost of RegMixup and its impact on speed. They provide a logical connection between the 2x samples and the slower speed. While they don't provide specific experimental data within this review point, the claim is supported by a clear reasoning.", "helpfulness_rationale": "The reviewer provides a specific example of a potential issue with a method (RegMixup) and highlights a potential flaw in comparisons. This is valuable information for the authors. While they don't provide a complete solution, they point out a concrete aspect of RegMixup's training that could impact its practical application and comparison with other methods. This implicitly guides the authors to consider this factor."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the observation about the BLEU1 scores (a bit worse) and directly suggests a verification step (statistically significant). This is a clear indication of an explicit and concrete action the authors should take. While the action itself isn't immediately actionable without further detail, the request for verification is a direct instruction.", "grounding_specificity_rationale": "The reviewer refers to specific parts of the paper (table 6, row 3 and 4) and a specific metric (BLEU1). This demonstrates strong grounding as the authors can easily identify the referenced part. The explicit mention of 'statistically significant' also implies a clear understanding of the issue.", "verifiability_rationale": "The reviewer makes a claim about the statistical significance of the improvements based on the numerical observation in the table. They also provide a method for verification by suggesting 'statistically significant'. While the specific statistical test isn't mentioned, the suggestion itself serves as a form of justification and reasoning. The claim is supported by the data presented in the table.", "helpfulness_rationale": "The reviewer clearly identifies a potential issue (the lack of statistical significance) and provides a concrete next step (verify the statistical significance). This is a helpful comment as it guides the authors towards a specific investigation. The suggestion is actionable and directly addresses a potential weakness."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "2 (2)", "verifiability_label": "3 (3)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer explicitly states they are asking for clarification and suggestions (\"what do you think can be done\") and poses a predictive question (\"what would happen if you partially cover them?\"), indicating an intention to guide improvement. However, the suggestions are general and lack specific details on how to achieve the relaxation or what the implications of partial coverage would be.", "grounding_specificity_rationale": "The reviewer is asking a question related to a specific concept (ballaction pairs) but doesn't explicitly identify the specific part of the paper being addressed. The question is general about relaxing a requirement and predicting outcomes, rather than a specific critique of a defined section.", "verifiability_rationale": "The reviewer is offering suggestions and predictions about the algorithm's behavior. While these could potentially be verifiable if the context and algorithm are known, the review point itself doesn't contain a clear claim that can be directly supported or refuted based on the information provided.", "helpfulness_rationale": "The reviewer is asking a question that, on its own, doesn't directly point to a specific weakness or improvement needed in the draft. It's a question about a potential improvement. The helpfulness depends on whether the authors find the suggestions and predictions useful for improving their draft. Without knowing the context and the actual algorithm, it's hard to definitively say if this is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question, making it explicit. However, they do not provide specific details on how to implement the suggested change, making it vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'a better encoder' as a potential improvement, clearly identifying the specific part of the paper (encoder). However, they do not specify *which* better encoder or *how* the current encoder (BERT) could be improved. The grounding is explicit, but the specificity is underdefined.", "verifiability_rationale": "The review point is a question, not a claim that requires verification.", "helpfulness_rationale": "The review point directly asks a question about a potential improvement, which is inherently helpful for the authors. While it lacks specific details, it points to a relevant area for exploration."}
{"actionability_label": "4", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests 'Include more datasets on traditional multilingual tasks like XNLI, XTREME...'. This is a clear and direct action for the authors to take. The suggestion is not implicit but rather stated directly. Once the authors understand the suggestion, the action is also somewhat concrete, as they know they need to incorporate these specific dataset types. While it doesn't tell them *how* to select or use these datasets, it points them in a clear direction.", "grounding_specificity_rationale": "The review point mentions 'traditional multilingual tasks' and specifically names 'XNLI, XTREME' as examples. This allows the authors to identify the specific area of the paper being addressed, providing grounding. The comment also specifies what the suggestion is about ('include more datasets'), which adds to the specificity. However, it doesn't explicitly state which part of the authors' draft needs improvement in relation to these datasets.", "verifiability_rationale": "The review point doesn't explicitly make a claim or assertion. It's more of a suggestion or recommendation. Therefore, it doesn't fit into the 'verifiability' category, which focuses on claims and their justification. The underlying value of the suggestion (improving generalization) is a reasonable hypothesis, but it's not explicitly supported or refuted within the review point itself.", "helpfulness_rationale": "The review point provides a suggestion that is relevant to improving the generalization capabilities of the proposed technique. It directly addresses a potential limitation (lack of diverse datasets) and offers a concrete direction for improvement. The suggestion is clear and easy to understand, making it helpful in guiding the authors. However, it lacks specific details on *how* to implement the suggestion or *why* these specific datasets are particularly beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests *multiple* specific baselines for different parts of the work, indicating an understanding of the need for comparison. While the suggestion is not a direct action, it implies an action to compare and potentially adopt these baselines. The reviewer does not explicitly state how to implement this action, making it somewhat vague on how to execute it.", "grounding_specificity_rationale": "The reviewer directly addresses specific aspects of the work (appearance decomposition and larger outdoor scenes) and suggests specific baselines (RefNeRF and MipNerf). This demonstrates strong grounding as the reviewer can accurately pinpoint the sections and areas being discussed. The suggestions are also specific, mentioning the names of the relevant methods.", "verifiability_rationale": "The reviewer is not making a claim that needs to be verified. They are simply suggesting improvements. The suggestion itself is a form of verification \u2013 if the authors adopt these baselines, it confirms the reviewer's point. Therefore, it's not strictly 'verifiable' in the sense of providing a justification for a claim, but it's a suggestion that can be verified by the authors.", "helpfulness_rationale": "The reviewer provides concrete suggestions for improving the appearance decomposition and potentially the generalizability of the method by comparing to relevant baselines. This directly addresses potential weaknesses and offers clear, actionable steps for the authors. The suggestions are specific and targeted, making them highly useful for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a lack of implementation details as a concern. While it doesn't explicitly state what is missing or how to implement it, the reviewer clearly points to the area where these details should be (Section 4.1). This implies an action, making it 3.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 4.1' as the location where implementation details should be. This is a clear and precise identification of the specific part of the paper being addressed, indicating full grounding. The comment also specifies what is missing ('lack of implementation details of the proposed methods'), making it specific as well.", "verifiability_rationale": "The review point identifies a specific weakness ('lack of implementation details of the proposed methods') and recommends a specific location ('Section 4.1') where this weakness should be addressed. While it doesn't provide a justification for why these details are missing, it clearly states a problem and a target for improvement, making it 3. The claim is that Section 4.1 should contain these details, and the reasoning is that their absence hinders understanding and implementation.", "helpfulness_rationale": "The review point directly addresses a potential weakness in the authors' draft (lack of implementation details). By specifying that these details should be in Section 4.1, the reviewer provides a clear direction for the authors to improve their work. This makes the review point 5 as it directly points to a concrete area of improvement and provides a specific target for the authors to focus on."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the absence of empirical evaluation, comparisons with other methods, and a lack of practical value. This directly informs the authors of specific areas for improvement. The reviewer clearly identifies what is missing, which is actionable information.", "grounding_specificity_rationale": "The reviewer criticizes the lack of empirical evaluation, which is a specific aspect of the paper. While the reviewer doesn't pinpoint a specific section or table lacking this evaluation, the focus is on a concrete and identifiable weakness. The criticism is directed at the *content* of the paper rather than a vague general area. Therefore, it can be considered somewhat grounded in the type of evaluation missing.", "verifiability_rationale": "The review point makes claims about the absence of empirical evaluation and the lack of practical value. These are statements that could be true but are not explicitly supported or refuted within the review itself. The reviewer presents a critique and a suggestion for improvement, but doesn't provide concrete evidence to back up these claims. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The review point identifies a significant weakness in the paper: the lack of empirical evaluation and the absence of practical value. This is a crucial criticism that directly points to areas where the authors can improve their work. The reviewer provides a clear direction for the authors to take, which is highly beneficial for their development and impact of the research."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: \"P mostly represents a probability but sometimes for a cumulative distribution function (e.g., Eqs. (3) and (4) and L44, all in Appendix), which leads to confusion.\" This clearly indicates an implicit action that the authors should be aware of the dual meaning of P and potentially adjust their interpretation or notation accordingly. The action is implicit because the authors need to infer the intended meaning of P from the context.", "grounding_specificity_rationale": "The reviewer directly points out the specific issue: \"P mostly represents a probability but sometimes for a cumulative distribution function (e.g., Eqs. (3) and (4) and L44, all in Appendix).\" This clearly identifies the specific part of the paper where the confusion arises, making it fully grounded. The reviewer also specifies the *nature* of the confusion: the dual meaning of P. The comment clearly specifies what needs to be addressed in this part.", "verifiability_rationale": "The review point describes a factual inconsistency in the manuscript, not a claim that requires verification. While it could lead to a suggestion (e.g., \"Clarify the notation for P\"), the statement itself doesn't contain a claim that can be supported by evidence. Therefore, it fits the 'X' category.", "helpfulness_rationale": "The reviewer clearly identifies a problem in the manuscript (confusion due to inconsistent use of P) and provides a direct suggestion for improvement (being more precise with notation). This is a 5 and constructive feedback that is likely to be helpful for the authors in understanding the equations and avoiding potential misinterpretations. The suggestion is concrete and directly addresses the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'Ideally other baselines would also be included, such as the other works discussed in related work 29, 5, 6'. This is an explicit statement of a missing element. While the reviewer also states 'All unclear parts have been answered The authors' explained why the chosen baseline makes the most sense. It would be great if this is added to the final version of the paper.' This suggests the authors have addressed the question, making the *action* of addressing the question concrete. However, the reviewer's initial point about the missing baselines is a clear indication of a potential area for improvement, making it 3.", "grounding_specificity_rationale": "The reviewer refers to 'other baselines' and specifically mentions 'the other works discussed in related work 29, 5, 6'. This clearly identifies the specific parts of the paper being addressed (the related work section and the specific works mentioned). The reviewer also mentions 'specific works discussed in related work' which further grounds the comment. The reviewer even states 'it would be great if this is added to the final version of the paper' which implies a clear understanding of the relevant context. The mention of 'implementation details' also suggests a focus on specific aspects within those works.", "verifiability_rationale": "The reviewer makes a claim by stating 'Ideally other baselines would also be included, such as the other works discussed in related work 29, 5, 6'. This claim is supported by the reasoning that these baselines address similar tasks and provide context. The reviewer also mentions 'specific works discussed in related work' which implies a logical reasoning and precise explanations. The reviewer provides examples of why the suggested baselines are relevant, making the claim verifiable.", "helpfulness_rationale": "The reviewer criticizes the lack of comparison to other baselines, which is a valid weakness. The reviewer provides specific suggestions for improvement, such as including the mentioned works and explaining the authors' choice. While the authors have addressed the question, the reviewer's initial point about the missing baselines is a clear indication of a potential area for improvement. The suggestions are concrete and actionable, making the review 3, but the fact that the authors have already addressed the question makes it somewhat less helpful than it could have been if the authors had not responded."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the inconsistency between the naming conventions used for the task loss (L_task) in the text and the class loss (L_class) in Figure 1. This is an explicit action or suggestion, even if it doesn't directly tell the author what to do, but it points to a potential issue that needs attention. The action is also concrete as it identifies the specific terms and locations where the discrepancy exists.", "grounding_specificity_rationale": "The review point mentions 'L_task' in the text and 'L_class' in 'figure 1', which can be considered a weak grounding as it identifies the specific terms but doesn't explicitly point to a specific section, table, or figure within the paper. The specificity is also weak as it doesn't detail what is wrong with the naming or suggest a specific correction.", "verifiability_rationale": "The review point itself doesn't contain a claim or suggestion. It's a statement of observation about the naming conventions. Therefore, it doesn't have verifiability as it doesn't present a claim that needs to be supported.", "helpfulness_rationale": "The review point points out a potential source of confusion or error for the author by highlighting the inconsistency in naming conventions. While it doesn't directly tell the author what to do, it identifies a potential issue that needs to be addressed. The helpfulness is moderate as it points to a potential problem but doesn't provide a clear solution or actionable step."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point is a question prompting the authors to consider other limitations of the method and specifically asks if the shallow network issue from the graph case extends to this work. While it encourages reflection, it doesn't explicitly state an action or provide concrete steps on how to identify these limitations or assess the network depth. Therefore, it is 3 in the sense that it prompts action (reflection), but lacks specific guidance on *how* to act.", "grounding_specificity_rationale": "The review point is a general question about the limitations of the method and doesn't specify which part of the paper or method it refers to. It doesn't identify a specific section, table, figure, or unique aspect of the paper. Therefore, it is 1 at all.", "verifiability_rationale": "The review point itself does not contain a claim or assertion that requires verification. It is a question. Therefore, it does not have verifiability as it lacks a statement that needs to be supported by evidence.", "helpfulness_rationale": "The review point is a question that prompts the authors to consider the limitations of the method. While it encourages critical thinking, it doesn't directly provide actionable feedback or suggestions on how to improve the work based on the identified limitations. Therefore, it is 2 as it doesn't offer direct guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The criticism focuses on the *evaluation methodology* being 'close to open domain' and suggests machine translation as a more suitable 'close domain' task. While the reviewer points out a potential improvement in the evaluation approach, the criticism itself doesn't explicitly state a lack of actionability in the *review point itself*. The reviewer could have directly suggested the change in evaluation without criticizing the current one as 'close to open domain'. However, the criticism is clear about a desired action (change evaluation method). Therefore, while not explicitly stating a lack of actionability in the *review point*, the underlying intent is to improve the *review point* by making it more actionable by specifying the desired evaluation method.", "grounding_specificity_rationale": "The reviewer criticizes the evaluation methodology as being 'close to open domain' and suggests machine translation as a more suitable 'close domain' task. The reviewer does not explicitly identify a specific part of the paper or methodology being addressed in the criticism itself. The criticism is a general statement about the nature of the evaluation. Therefore, the criticism is 1 in a specific aspect of the paper. However, the criticism is specific to the *type* of evaluation being used. The reviewer is specific about suggesting machine translation as a better alternative. Therefore, while not fully grounded, the criticism has a clear focus on the *methodology* of evaluation, making it somewhat specific to that aspect.", "verifiability_rationale": "The reviewer makes a claim: 'This work would be more convincing if it is also evaluated in machine translation...'. This claim is that machine translation is a more suitable evaluation method. However, the reviewer does not provide any specific evidence or justification for this claim within the review point itself. They present it as a suggestion without explaining *why* machine translation would be better or providing references to support this assertion. Therefore, the claim is not wellsupported by evidence or logical reasoning within the review point.", "helpfulness_rationale": "The reviewer's point is about suggesting a change in the evaluation methodology. While this is a constructive suggestion, it does not directly instruct the authors on how to improve their method. The reviewer is pointing out a potential improvement but doesn't provide concrete steps or guidance on how to implement the suggested evaluation in their work. Therefore, the review point itself is not inherently helpful in terms of providing actionable feedback to the authors. It's more of a suggestion for improvement than a direct action item."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer is asking for specific values (the dropping rate and the number of masks) which are concrete actions. However, the request itself is somewhat vague as it doesn't explicitly state that these values are missing, implying they might exist elsewhere in the paper.", "grounding_specificity_rationale": "The reviewer is asking about a specific aspect of the paper (the dropout mechanism). While the paper might describe dropout in general, it doesn't explicitly name the section or table where this specific implementation is described. However, the reviewer is very specific about the details they are looking for (dropping rate and number of masks).", "verifiability_rationale": "The reviewer is making a claim that the paper lacks specific details about the dropping rate and the number of masks. This claim can be verified by examining the paper and checking if these specific parameters are mentioned. Assuming the paper does not explicitly state these values, the reviewer's claim is verifiable.", "helpfulness_rationale": "The reviewer's questions are directly actionable and identify specific areas for improvement in the paper's description. They are asking for concrete information that would help the authors understand and potentially replicate the dropout mechanism. Therefore, the review point is 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of the current evaluation and suggests specific improvements, indicating a clear action. They point out the lack of justification for the twostage approach and the need for comparisons with other singlestage attacks, which are concrete actions to be taken.", "grounding_specificity_rationale": "The reviewer refers to the 'performance drop on fusion models' and the 'comparisons with other singlestage attacks' as specific areas needing improvement. They identify the 'twostage optimization approach' as the specific part of the paper being addressed, making the grounding quite explicit.", "verifiability_rationale": "The reviewer makes a claim about the lack of 'proper benchmarks and comparisons with other SOTA algorithms' and argues that this makes it 'hard to justify the effectiveness of the technical contributions'. This claim is supported by logical reasoning and the identified gaps in the evaluation.", "helpfulness_rationale": "The reviewer directly addresses a potential weakness in the paper's methodology and provides specific suggestions for improvement. They clearly articulate *why* the current evaluation is insufficient and *what* needs to be done to strengthen it. This makes the review point highly constructive and actionable."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment identifies a missing piece of information (type of GPUs and inference time) but does not specify how the author should go about obtaining or incorporating this information. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The comment refers to 'this paper' in a general sense, indicating a lack of specific details about the author's paper. It does not point to a specific section, table, figure, or unique aspect of the paper. The grounding is weak as the author cannot confidently determine which part the comment addresses. The specificity is also low as the comment does not detail what is missing or how it should be addressed.", "verifiability_rationale": "The comment is a statement of a problem, not a claim that *something is wrong*. It doesn't suggest an alternative or ask a question. It's a factual observation about the missing information.", "helpfulness_rationale": "The comment points out a factual omission in the author's paper. While it highlights a potential issue for the author's work, it doesn't *help* the author improve their current draft. It's a critique of their own work, not a suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "Part 1 of the review point is not actionable as it's a question about the significance of certain parts, not a suggestion for improvement. Parts 2 and 3 are slightly actionable as the reviewer identifies specific notational issues, but the implications or how to fix them are not explicitly stated.", "grounding_specificity_rationale": "Part 1 of the review point is 1 as the reviewer doesn't specify which 'less important points' they are referring to. Parts 2 and 3 are fully grounded as the reviewer explicitly mentions the specific sections or notations (Page 3, Line 2 and Line 4, paragraph D4PG) where the issues occur.", "verifiability_rationale": "Part 1 of the review point is not verifiable as it's a hypothesis about the impact of \u03bb values. Part 2 is verifiable as the reviewer claims the variables \u03c4 and \u03b7 are missing in the bracket of the objective function. Part 3 is verifiable as the reviewer claims the Qfunction definition is incorrect regarding the next state s'.", "helpfulness_rationale": "Part 1 of the review point is not helpful as it's a speculative question. Parts 2 and 3 are 5 as they point out specific, actionable issues in the paper's formulation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a confusing sentence, making the comment explicit in terms of identifying a problem. However, the specific action of clarifying the mechanism is implicit, making it 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions a specific sentence and line numbers, demonstrating strong grounding. However, the specificity of the issue within that sentence is not identified, making it only 2.", "verifiability_rationale": "There is X made by the reviewer, so the comment is not verifiable.", "helpfulness_rationale": "The reviewer's comment is helpful because it directs the author to a specific location and encourages them to seek clarification, even though it doesn't provide a solution."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitations of previous work and provides concrete actions to improve upon them. For example, they state \"Previous work has tried to tackle... but with limited success\" and \" we can always sample more efficiently using different samplers from the literature that trade off sample quality.\" These statements are direct actions the authors can take. While the reviewer doesn't explicitly state how to implement these actions, the actions themselves are clear.", "grounding_specificity_rationale": "The reviewer mentions general concepts like \"diffusion models,\" \"GANs,\" \"previous work,\" and \"literature\" without pinpointing specific sections, tables, figures, or unique aspects of the paper. While they are referring to specific areas of research, they don't provide a clear reference to a specific part of the paper being criticized or a specific element within that part. The reviewer is making general statements about the field rather than focusing on a particular aspect of the submitted work.", "verifiability_rationale": "The reviewer states facts about the capabilities and efficiency of diffusion models and the limitations of previous work. However, they do not provide specific citations or references to support these claims within the review point itself. Therefore, while the information might be verifiable through external knowledge, the reviewer does not provide the necessary evidence within their comment.", "helpfulness_rationale": "The reviewer provides some information about the strengths and weaknesses of different approaches. They point out that diffusion models outperform GANs and are more compute efficient. They also acknowledge the limitations of previous work. While the information is generally accepted in the field, the reviewer doesn't provide specific, actionable feedback on how the authors should modify their draft based on these observations. The lack of specific grounding and actionable steps makes the information less helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the inconsistency between Fig 1 and Fig 2 and identifies the difference in the number of encoderdecoder models. While it doesn't provide specific guidance on how to resolve this, it clearly points to a discrepancy that needs attention. The action is explicit (identifying the difference), but it is somewhat vague on how to apply this action.", "grounding_specificity_rationale": "The comment explicitly refers to 'Fig 1' and 'Fig 2', clearly identifying the specific parts of the paper being addressed. This is strong grounding as the authors can directly locate the sections being discussed. The comment specifies what is wrong: \"Fig 1 shows a single shared encoderdecoder for multiple tasks\" and \"Fig 2 shows a single encoderdecoder per auxiliary task\".", "verifiability_rationale": "The comment contains a claim: \"Fig 1 is not consistent with Fig 2\". However, it does not provide any justification or evidence to support this claim. There are no logical reasoning steps, common knowledge references, or external citations provided to back up the inconsistency. The claim is stated, but the supporting evidence is missing, making it 1.", "helpfulness_rationale": "The comment is clear and identifies a potential issue (the inconsistency in the figures). However, it does not provide any specific guidance or suggestions on how to address this issue. It simply points out a discrepancy, which can be helpful for the authors to identify a problem, but it lacks the actionable steps needed for improvement. The helpfulness is limited because the comment doesn't offer a solution or direction for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer raises a valid point about the clarity of the attention mechanism. While the reviewer's question is framed as a concern about grounding specificity, the underlying issue is that the action of attending to 'lowerlevel representations' is not explicitly defined or linked to the described mechanism. The reviewer's question about nonneighboring nodes highlights a lack of clarity in the action being taken. The reviewer is essentially asking for a more explicit statement of the action, which is currently implicit.", "grounding_specificity_rationale": "The reviewer's comment is primarily about grounding specificity. They are questioning the specificity of the comment referring to 'lowerlevel representation' and implicitly asking if this refers to a specific part of the paper. The comment lacks a clear reference point, making it difficult to understand what 'lowerlevel representation' means in the context of the paper. The reviewer is asking for a more specific reference to a part of the paper or a clear explanation of what this term means.", "verifiability_rationale": "The verifiability of the comment is unclear. The comment itself does not contain a claim. It is a question about the scope of the attention mechanism. Therefore, it does not have verifiability in the sense of supporting a claim. The comment is more of a clarification request than a statement that needs verification.", "helpfulness_rationale": "The helpfulness of the comment is low. The comment is a question about a specific aspect of the paper's methodology, which is not particularly novel or insightful. It does not provide actionable feedback or insights that would significantly improve understanding or implementation of the method. It is more of a clarification request than a helpful critique or suggestion."}
{"actionability_label": "Implicit", "grounding_specificity_label": "Full Grounding", "verifiability_label": "Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a gap in the logical flow by asking how a specific inequality follows from a previous lemma. While the reviewer explicitly asks for clarification on *how* Lemma 7 is used, the core action the authors need to take is to infer this connection. They are not given an explicit instruction on what steps to take to bridge this gap. The authors would need to analyze the lemma and see how its result can be applied to the inequality at line 433. This requires some effort and understanding of the mathematical context.", "grounding_specificity_rationale": "The reviewer explicitly asks about the inequality at line 433 and refers to 'Lemma 7'. This direct reference to a specific line number and a specific piece of information strongly indicates full grounding. The authors can precisely identify the section and the element being discussed.", "verifiability_rationale": "The reviewer poses a specific question about a mathematical derivation. This is a verifiable claim because the answer can be found by examining the surrounding text and the lemma referenced. The authors can, in principle, follow the logical steps to understand how the inequality at line 433 follows from Lemma 7, although the exact steps might not be explicitly laid out.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific point in the paper. This is generally helpful as it seeks to improve understanding and potentially address a potential weakness the authors might be facing when trying to follow the derivation. While it doesn't provide a direct solution, it points in the direction of where the authors need to look to understand the connection."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the issues: \"unclear main contribution,\" \"not wellsupported,\" \"not clear main idea,\" and \"not clear how automation is achieved.\" While the reviewer identifies the *area* of problems, the lack of specific actionable steps makes it difficult for the authors to know *exactly* what to work on. The reviewer doesn't provide concrete suggestions on how to make the contribution clearer or how to support the properties better.", "grounding_specificity_rationale": "The reviewer mentions \"the main contribution,\" \"the proposed method,\" \"dynamic largescale multitasking,\" and \"automation.\" While they don't explicitly name *sections* or *figures*, they point to specific *aspects* of the paper. The reviewer clearly specifies what needs to be addressed in these aspects (e.g., \"how the automation is achieved\").", "verifiability_rationale": "The reviewer makes claims such as \"the main contribution of this paper is unclear,\" \"they either somewhat overstated the ability or applicability of the proposed method or were not wellsupported,\" \"the main idea of how the proposed method copes with dynamic largescale multitasking is not clear,\" and \"How the automation is achieved is also unclear.\" However, the reviewer does not provide any evidence, references, or logical reasoning to support these claims. The claims are presented as statements of opinion without any backing.", "helpfulness_rationale": "The review point primarily criticizes the paper's main contribution and the novelty of its properties without offering any specific suggestions for improvement. The reviewer points out areas that are unclear or not wellsupported but does not provide concrete steps on how to make them clearer or better supported. The review is essentially a critique without constructive feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the weakness: 'the author only compare their method to the BERTbaseline.' This is a clear and direct statement of the missing comparisons. The reviewer identifies the specific type of baseline that is missing (token pruning and token combination). While the point doesn't provide concrete suggestions on how to implement these baselines, it clearly identifies the action the authors *should* take. The action is also explicit in the sense that the authors are aware of the missing baselines.", "grounding_specificity_rationale": "The review point explicitly mentions 'token pruning' and 'token combination' as missing baselines. This directly identifies the specific aspects of the paper being addressed (the experimental comparison). The grounding is strong because the reviewer names specific techniques that are relevant to the evaluation of the method.", "verifiability_rationale": "The review point makes a claim about the weakness of the experimental comparison. While it doesn't provide external references or logical reasoning to *prove* that the comparison is weak, it presents a clear statement that the authors should have included these specific baselines. The claim is supported by the lack of these specific types of baselines in the described comparison.", "helpfulness_rationale": "The review point is clear and directly points out a deficiency in the experimental evaluation. It provides a specific suggestion for improvement (adding token pruning and combination baselines). While it doesn't elaborate on *why* these baselines are important, it clearly identifies a actionable step for the authors, making it helpful in guiding their work."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action: 'A comparison to coordinateaware methods, such as TFN or SchNet seems appropriate.' This indicates the reviewer is suggesting a specific type of comparison. However, the action is not concrete as the reviewer does not specify how this comparison should be implemented (e.g., adding a new experiment, modifying existing parameters).", "grounding_specificity_rationale": "The comment explicitly mentions 'coordinateaware methods' and names 'TFN or SchNet'. This clearly identifies the specific area of the paper being addressed (the methods section, specifically the type of methods) and provides details about what is being compared. While it doesn't pinpoint a specific subsection or detail within these methods, it clearly specifies the *type* of method.", "verifiability_rationale": "The comment contains a claim: 'A comparison to coordinateaware methods, such as TFN or SchNet seems appropriate.' This is a suggestion for improvement. However, the verifiability verification process requires a claim to be supported by logical reasoning, common knowledge, or external references. The comment itself doesn't provide any justification for *why* this comparison is appropriate or what specific aspects of the current methods should be compared to TFN or SchNet.", "helpfulness_rationale": "The comment identifies a specific weakness in the experimental section \u2013 the lack of comparison to coordinateaware methods. This is a valuable piece of feedback for the authors as it directly points to a missing element in their evaluation. While the comment doesn't suggest a specific way to implement this comparison, it clearly highlights an area that needs improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a potential weakness but does not specify any actions or modifications the authors should make to address it. It's a diagnosis, not a prescription with action steps.", "grounding_specificity_rationale": "The comment is very general and doesn't point to any specific part of the paper or model. It's a broad statement about potential flaws.", "verifiability_rationale": "The comment states a problem but doesn't provide any evidence, examples, or references to support the existence of these weaknesses. It's an assertion without justification.", "helpfulness_rationale": "The comment identifies a valid concern but offers no concrete steps or information to help the authors address it. It's a diagnosis without a prescription."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states their intention to ask a question and compare their system to previous methods, but the review point itself does not explicitly state the action or provide the details of the comparison. The action is implied but not explicitly stated and performed.", "grounding_specificity_rationale": "The reviewer asks a question about related work and compares their system to a category of methodologies, but does not identify a specific part of the paper or the proposed method. The grounding is implied but not explicitly stated.", "verifiability_rationale": "The reviewer makes a claim about the troublesome nature of the question but does not provide any evidence or justification for this claim within the review point itself. The verifiability is based on the lack of supporting evidence for the claim.", "helpfulness_rationale": "The review point provides a general direction for the authors (asking about related work and comparing to extractthengenerate), but lacks specific details or concrete examples. The helpfulness is limited by the lack of specific information."}
{"actionability_label": "No", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests \"more work on GLN\" and \"reflect the advantages or difference of the proposed method, such as the difference from BGLN\". This is an explicit suggestion, but the action is broad, lacking specific guidance on what needs to be added or how to compare the methods.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"related work,\" \"GLN,\" and \"BGLN\" by name, indicating a clear understanding and focus on specific sections and concepts.", "verifiability_rationale": "The reviewer makes claims about the insufficient related work and the need for more GLN. However, these claims are not supported by verifiable evidence or reasoning within the review point itself.", "helpfulness_rationale": "The reviewer identifies a valid weakness in the introduction (insufficient related work) and suggests a relevant improvement (more GLN and comparison to BGLN). However, the suggested action lacks specific details, making it less helpful for direct implementation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer asks for largerscale experiments, which implies a desire for more information or guidance. While the reviewer doesn't explicitly state the action of implementing largerscale experiments, the request itself is a form of actionable feedback, suggesting the authors should consider expanding their experiments. However, the *why* behind the lack of largerscale experiments isn't directly addressed, making it not fully actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"largerscale experiments\" and asks \"why were there no experiments with larger stateaction spaces and nontrivial dynamics included (at least gridworlds with walls, and other nontrivial tiles)?\". This clearly grounds the discussion in a specific aspect of the paper (the experimental setup) and specifies the area of concern. The reviewer is not just saying \"there's something missing,\" but rather pinpointing a specific missing element.", "verifiability_rationale": "The reviewer states \"Currently it is hard to judge whether this was simply due to a lack of time or because the method has severe scalability issues.\" This statement expresses a lack of justification or evidence for the experimental choices made. While the reviewer is raising a concern, they are not providing concrete reasoning or references to support their claim about the method's scalability or the time involved. The reviewer is expressing uncertainty, which points to a lack of verifiable information.", "helpfulness_rationale": "The reviewer provides specific suggestions for improving the experimental setup, such as mentioning \"very convincing experiments would be e.g. on simple videogame domains...\" and \"comparison against other approaches would be easier.\" They also ask a direct question to seek clarification, \"why were there no experiments with larger stateaction spaces...\". These suggestions and the question directly address the identified weaknesses and offer concrete improvements. The feedback is specific and actionable, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests adding a quantitative measurement for occupation bias, which implies an action. However, the suggestion is vague and doesn't specify how to implement this measurement. Therefore, it's not fully actionable as it stands.", "grounding_specificity_rationale": "The reviewer's comment is 1 in a specific part of the paper. They are making a general comment about the methodology of the authors.", "verifiability_rationale": "The reviewer's comment is not a claim that requires verification. They are pointing out a potential improvement to the authors' work by suggesting a specific type of analysis, but without any specific evidence or references.", "helpfulness_rationale": "The reviewer's comment suggests a potential improvement to the authors' work by proposing a quantitative measurement for occupation bias. This is generally helpful, as it gives the authors a direction for future work. However, the lack of specifics makes it less immediately helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer implies an action by asking about the impact, but the action is not explicitly stated.", "grounding_specificity_rationale": "The reviewer mentions 'adaptive gradient methods' and 'hard features,' which are specific concepts. However, the exact nature of the hard features and the specific way adaptive methods might affect them are not clearly defined.", "verifiability_rationale": "The reviewer poses a question, which can be considered a claim that requires justification. However, the reviewer does not provide any evidence or reasoning to support their claim about the potential impact of adaptive methods on hard features.", "helpfulness_rationale": "The review point is relevant as it raises a question about a key methodological choice (optimizer). It encourages the author to consider the implications of this choice on their findings. While it doesn't offer a direct solution, it prompts a deeper analysis of their experimental setup."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states 'no information from 2hop neighbors is included' and suggests 'again' (implying a previous consideration or mention of something similar). This indicates a clear action the authors should take: include the information from 2hop neighbors in their method.", "grounding_specificity_rationale": "The comment directly refers to '2hop neighbors', a specific technical term within the context of graphbased methods. This clearly identifies the part of the method being addressed, making the grounding fully explicit. It also specifies what is missing: 'no information from 2hop neighbors is included'.", "verifiability_rationale": "The comment contains claims, such as 'this method is simple' and 'it is highly unclear why it is effective'. While these are valid observations, they are not explicitly supported by evidence or reasoning within the provided text. The lack of explicit justification makes it partially verifiable.", "helpfulness_rationale": "The review points out a specific missing element ('no information from 2hop neighbors is included') and suggests a concrete improvement ('again', implying the need to include this information). This constructive critique provides clear guidance for the authors to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "6", "helpfulness_label": "4", "actionability_rationale": "The comment states 'ProtPainter just provides an empirical conformation estimation.' This is a statement of observation or limitation. It doesn't present a claim that requires further justification or evidence. While it identifies a potential area for improvement, it doesn't specify *how* to achieve this. It doesn't offer specific techniques, tools, or experimental designs. Therefore, it's 1 as it doesn't provide explicit or concrete steps for improvement.", "grounding_specificity_rationale": "The comment refers to 'ProtPainter' and 'binder design' without specifying *which* aspect of ProtPainter or *which* binder design it's referring to. It mentions 'empirical conformation estimation' but doesn't pinpoint where this estimation occurs within ProtPainter's methodology. The reviewer doesn't explicitly name a section, table, figure, or unique aspect of the paper. The comment is vague about the specific part of the paper being addressed. Therefore, it's 1 at all regarding the specific aspect of ProtPainter or binder design.", "verifiability_rationale": "The comment states 'ProtPainter just provides an empirical conformation estimation.' This is a statement of observation or limitation. It doesn't present a claim that requires further justification or evidence. There's no 'I think this is wrong' or 'I suggest this should be done differently.' The comment identifies a potential area for improvement but doesn't provide any external references or logical reasoning to support this observation. Therefore, it contains X that requires verification.", "helpfulness_rationale": "The comment points out a limitation of ProtPainter: it only provides 'empirical conformation estimation' and suggests further optimization and validation are needed. While it identifies a potential area for improvement, it doesn't *how* to achieve this. It doesn't offer specific techniques, tools, or experimental designs. The comment is more of a pointer to a potential issue rather than a concrete suggestion for improvement. Therefore, it's 2 as it lacks concrete suggestions for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a potential flaw in the experimental comparisons by pointing out that different pairs of experiments use varying amounts of data. They identify the specific comparisons (e.g., H>N vs. H>N+B) and suggest that comparisons should ideally be done with equal data. This is an explicit statement of a potential issue that can be directly addressed by the authors.", "grounding_specificity_rationale": "The reviewer explicitly names the specific experiments involved in their critique (e.g., H>N, H>B, H>N+B, H>N>H). This demonstrates strong grounding specificity as the authors can easily identify the referenced parts of the paper and the specific experimental setups being discussed.", "verifiability_rationale": "The reviewer makes a claim about a potential issue (unequal data affecting comparisons) and provides specific examples of the experiments involved (e.g., H>N and H>N+B). This claim is verifiable based on the described experimental setups. The reviewer provides the necessary information to understand the potential flaw.", "helpfulness_rationale": "The reviewer provides specific information about a potential issue in the experimental design (unequal data) and identifies the relevant experiments. This is helpful for the authors as it directly informs them about a potential flaw and suggests a desirable experimental setup. The reviewer's comments are actionable and informative."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out potential issues with the algorithm's iteration and the missing citation for Laplacian eigenmaps. While they identify a problem (T > 2) and a missing reference, they don't explicitly state how the authors should modify the algorithm or what the implications of the missing citation are for their implementation. The suggestions are present, but the actionable steps are not fully detailed.", "grounding_specificity_rationale": "The reviewer mentions 'Alg 1 either with one iteration T=1 or with two iterations T=2' and 'Laplacian eigenmaps'. This indicates they are specifically referring to elements within the paper. They identify the algorithm and a specific concept (Laplacian eigenmaps) as areas of concern. While they don't point to a specific line number, they are grounded in the content of the paper.", "verifiability_rationale": "The reviewer suggests that the algorithm should run until a 'criterion is fulfilled' with T >> 2, implying a lack of justification for using only T=1 or T=2. They also point out the missing citation for Laplacian eigenmaps. This constitutes a claim that requires verification. The reviewer provides a general suggestion but lacks specific examples or references to support their claim about the stopping criterion. The missing citation is also a claim requiring justification.", "helpfulness_rationale": "The reviewer raises valid points about the potential limitations of the algorithm with a small number of iterations and the missing citation. They suggest that the algorithm might not converge and that the implementation is incomplete. These are actionable comments that could help the authors improve their work. However, the reviewer does not explicitly state the *exact* changes the authors should make, leaving some ambiguity in the helpfulness. The suggestions are relevant, but the precise implementation steps are not fully elaborated."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the reason for including Section 2.1 and provides a clear, actionable suggestion to remove the ResNet description and focus on CBN. The reviewer identifies a potential point of confusion for the authors regarding the relevance of the ResNet architecture to the proposed Conditional Batch Normalization (CBN).", "grounding_specificity_rationale": "The reviewer identifies Section 2.1 as the problematic section, but the underlying issue is the perceived disconnect from the core contribution (CBN) rather than a lack of clarity within the section itself. While the reviewer points to a specific section, their *why* is more about the *conceptual* connection than a precise element within that section causing the confusion. The reviewer *does* specify the *type* of confusion: the inclusion of the ResNet description and its disconnect from the CBN motivation. However, the *how* of this disconnect isn't deeply elaborated.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement, not a claim that needs to be supported by evidence. The reviewer isn't making a statement that requires verification, such as 'Batch Normalization is *not* a general technique'.", "helpfulness_rationale": "The reviewer provides a very helpful comment by directly pointing out a potential area of confusion for the authors and suggesting a concrete action to improve the paper's structure and clarity. The reviewer's suggestion is actionable and directly addresses a potential point of confusion for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of clarity regarding the sparsity of the resulting matrix after a matrix multiplication. While they identify a problem (unclear sparsity), they do not provide a concrete action or suggestion on how to achieve this sparsity. The reviewer only states the issue, which is a specific part of the paper (related to equation 1 and the resulting matrix), but doesn't specify how to make it sparse.", "grounding_specificity_rationale": "The reviewer refers to 'equation (1)' and 'the resulting matrix' in their review point. This allows the authors to identify the specific part of the paper being discussed. The reviewer can infer the specific section or mathematical element being addressed, making the grounding explicit. However, the reviewer does not specify *how* the multiplication leads to a sparse matrix, making the specificity underdeveloped.", "verifiability_rationale": "The review point is a question: 'it is unclear how the resulting matrix is expected to be sparse'. This is a statement of uncertainty, not a definitive claim requiring evidence. There are no explicit opinions, suggestions, or judgments made by the reviewer. Therefore, there is X to be verified.", "helpfulness_rationale": "The review point highlights a potential area of confusion for the authors regarding the sparsity of the resulting matrix. While it doesn't provide a solution, it points out a missing piece of information that could hinder their understanding or implementation. This makes the review point relevant to the authors, as it identifies a potential issue in their work. However, it doesn't offer a concrete solution, making it less directly helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their opinion that 'Initialization plays a role' and 'Solving NGF is an initial value problem (IVP) in this setting.' They then provide a concrete suggestion that 'Initialization should play a role such as pretraining.' This clearly indicates an explicit action and a concrete detail on how to implement it.", "grounding_specificity_rationale": "The reviewer mentions 'initial value problem (IVP)' which implies a connection to a specific concept within the paper's context. However, they do not explicitly state which part of the paper they are referring to (e.g., a specific section, table, or figure). The suggestion of 'pretraining' is specific, but the grounding of this suggestion back to a concrete part of the paper is not explicitly stated.", "verifiability_rationale": "The reviewer makes a claim that 'Initialization plays a role' and 'Solving NGF is an initial value problem (IVP) in this setting.' While they provide a suggestion ('pretraining'), they do not explicitly verify the claim about initialization being related to an IVP with logical reasoning or external references. The suggestion of pretraining lacks detailed justification within the review point itself.", "helpfulness_rationale": "The reviewer provides a clear point of feedback, criticizing a statement in the paper and suggesting a potential improvement. They propose a specific action ('pretraining') to address the issue of initialization. This provides actionable feedback for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the implication of 'for every arm a' and provides a concrete interpretation. The reviewer suggests that the parameter depends on the context or arm, making the meaning clear.", "grounding_specificity_rationale": "The comment does not explicitly name a specific section, table, or figure where the definition of the optimistic parameter is located. The reviewer implies the dependence on 'a' but doesn't point to a precise location.", "verifiability_rationale": "The comment provides a clear explanation of why the point is valid, linking the ambiguity to potential confusion and suggesting a clearer interpretation. The reasoning is logical and directly addresses the issue.", "helpfulness_rationale": "The comment identifies a lack of clarity in the description of the optimistic parameter and suggests a specific interpretation. This directly helps the author understand the parameter correctly."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "6", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states that more experiments are needed, making it an explicit statement. However, it lacks specific details about which experiments to add, why more are needed, or how to conduct them, making it vague and therefore '3'.", "grounding_specificity_rationale": "The comment does not specify which part of the experimental section is weak or suggest improvements to a particular element. It is a general statement about the entire section, lacking grounding in a specific aspect of the paper. Therefore, it is '1'.", "verifiability_rationale": "The comment does not contain a claim. It is a suggestion for improvement, not a statement of opinion or judgment. Therefore, it falls under 'X' which is represented as 'X'.", "helpfulness_rationale": "The comment identifies a valid weakness in the experimental section and suggests improvement by adding more experiments. However, it lacks specific details, making it vague and less directly actionable for the authors. This makes it '2' as it provides a direction but lacks the necessary specifics."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "Each bullet point explicitly identifies the location of the error (line number) and the nature of the error (e.g., 'compact'), making the feedback very direct and actionable. The reviewer clearly states what needs to be corrected.", "grounding_specificity_rationale": "Each bullet point explicitly refers to a specific line number (e.g., 'line 2', 'line 56', 'line 158') and provides a concise description of the error. This makes it very clear to the author where the issue lies and what needs to be changed.", "verifiability_rationale": "The review point does not contain any claims or judgments. It simply points out errors in the text. Therefore, it does not meet the criteria for verifiability, which requires a claim to be supported by evidence.", "helpfulness_rationale": "The feedback is very specific and actionable. By pointing out the exact line number and the nature of the error, the reviewer provides clear guidance for the author to make the necessary corrections. This level of detail is likely to be very helpful for the author."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks a question: \"Does the proposed method perform better in pure combinational logic (without register)?\". It also suggests an action: \"it seems it may be much easier to model without state related registers, it would be interesting to see a comparison between sequential design and combinational design.\" This action is directly tied to the question and provides a clear direction for the authors to investigate. The action is also concrete, as it suggests a specific comparison. Therefore, the review point is actionable and provides a clear next step for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions \"the proposed method\" and \"pure combinational logic (without register)\". This clearly identifies the specific part of the paper being addressed. The use of specific terminology like \"combinational logic\" and \"registers\" indicates strong grounding. The reviewer also implies a comparison between 'sequential design\" and \"combinational design\", which further pinpoints the area of interest. The grounding is explicit and the section is clearly identified.", "verifiability_rationale": "The review point contains a claim: \"it would be interesting to see a comparison between sequential design and combinational design.\" While this is a suggestion for an experiment, it lacks explicit justification or evidence for why this comparison is particularly important or necessary. There are no references to external knowledge or logical reasoning to support this claim. Therefore, the claim is suggestionally verifiable but lacks strong supporting evidence.", "helpfulness_rationale": "The review point raises a valid question about exploring a different design approach (combinational vs. sequential) and provides a plausible reason (easier modeling without registers). This suggests a valuable experiment or further investigation that the authors could undertake. While it doesn't directly pinpoint a specific weakness in the current method, it offers a potential direction for improvement and highlights an area that requires further exploration. Therefore, the review point is 3 in guiding the authors towards a potentially fruitful area of research."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer is directly asking for the performance of the LDA+LSTM baseline in terms of a specific metric (topic switch percent). This is a clear and explicit request for information that directly relates to the described baseline. The reviewer is not inferring anything, but rather stating their need for this specific data point. The action is to look for the performance of this specific baseline and this specific metric.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the topic switch percent metric' and 'the LDA+LSTM baseline' by name. This provides a very precise reference point for the information they are seeking. The paper section or table where this metric is reported would need to be identified to fully ground the reference. However, the reviewer has clearly identified the specific part of the paper they are interested in.", "verifiability_rationale": "The request is a direct question about the performance of a specific baseline on a specific metric. While the metric itself is a standard measure in some fields, the *performance* is not inherently verifiable without access to the results presented in the paper. However, the request itself is a clear and logical question that could be answered with the right information. The reasoning to answer this question would involve looking for the reported performance of LDA+LSTM on the topic switch percent metric in the experimental results section.", "helpfulness_rationale": "The reviewer is asking for a specific performance metric that is directly relevant to evaluating the effectiveness of the LDA+LSTM baseline. Understanding the topic switch percent helps assess how well the model maintains topic coherence over the text. This information is valuable for the authors to understand the strengths and weaknesses of their baseline implementation and to compare it against other methods. The information directly addresses a potential gap in their understanding of the baseline's performance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests including experiments with GPT3.5 as a potential alternative to GPT4. While this points towards a need for further evaluation, the reviewer does not explicitly state what steps should be taken or what the expected outcome should be. The suggestion is vague and lacks specific actionable steps for the author.", "grounding_specificity_rationale": "The reviewer suggests including experiments with GPT3.5 but does not specify which part of the paper or concept this refers to. The suggestion is general and does not pinpoint a specific section, table, figure, or unique aspect of the work. Therefore, the reviewer's comment is 1 at all.", "verifiability_rationale": "The review point is a suggestion for an alternative approach (using GPT3.5) rather than a claim that identifies a specific issue or weakness in the current work. There is no logical reasoning, common knowledge, or external references provided to support the suggestion itself. It's a recommendation, not a critique.", "helpfulness_rationale": "The review point offers a suggestion for an alternative approach. While this could be helpful for the author to consider, the review point itself does not actively critique the current work or provide evidence that the suggested approach would be beneficial. It's a suggestion, not a critique or a solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue with Table 4 and provides a clear action: 'Please also include bold numbers for the baselines of previous work. Specifically for WMT17WIKT the best result in terms of BLEU is actually in the baselines.' This action is concrete as the reviewer identifies the exact location (Table 4) and the specific problem (missing bolded baselines, incorrect best result for WMT17WIKT).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 4' and then specifically points out the issue with 'WMT17WIKT'. This demonstrates strong grounding specificity as the reviewer can accurately pinpoint the table and the specific baseline where the error occurs.", "verifiability_rationale": "The reviewer makes a claim: 'the best result in the baselines for WMT17WIKT is not in the baselines'. This claim is verifiable as the reviewer states a specific observation that can be checked against the presented data. While the reviewer doesn't provide external references, the claim is logically inferable from the comparison of results presented in the table.", "helpfulness_rationale": "The reviewer's comment is 5 as it directly points out a specific formatting issue ('bold numbers') and a factual error ('the best result in the baselines for WMT17WIKT is not in the baselines') in a relevant table (Table 4). This information is likely to be directly useful for the authors in improving the presentation and accuracy of their results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer states the claim is 'insufficiently backedup'. While this doesn't explicitly demand an action, it points to a lack of information, which could be interpreted as a need for more explicit or concrete suggestions. The reviewer *could* be more actionable by stating *what* is insufficiently backed up, such as the missing discussion of TD3GA or the lack of clarity in the synergy claim.", "grounding_specificity_rationale": "The reviewer explicitly states the paper 'does not even mention the TD3GA algorithm' and that the discussion of RL algorithms is 'vague'. This clearly indicates a lack of grounding regarding a specific algorithm and a lack of specificity in the discussion. The comment identifies a specific area that is not addressed and the nature of the missing information.", "verifiability_rationale": "The reviewer makes a claim about the 'insufficient backingup' of the synergy between DQD and PPO. They then provide reasons *why* it's insufficiently backedup, mentioning the missing TD3GA discussion and lack of clarity in the algorithm comparison. This demonstrates an attempt to verify the claim by providing supporting evidence or logical reasoning. The reviewer provides specific reasons and examples to support their claim.", "helpfulness_rationale": "The reviewer states the comment is '1' because it points out a deficiency in the paper. While the comment identifies a lack of information, the reviewer's strong negative framing suggests they feel the comment is primarily critical and lacks actionable suggestions beyond pointing out a gap. The comment *does* provide information about what's missing, which is helpful, but the reviewer's overall assessment is negative."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly lists several concrete actions the authors can take to improve their paper. For example, they can add axis labels to figures, mask out irrelevant portions of curves, run multiple seed experiments, and expand their datasets and architectures. Each of these suggestions is directly actionable and provides a clear path for improvement.", "grounding_specificity_rationale": "The review point identifies specific areas within the paper where issues exist. For instance, it mentions 'axis labels' within the figures, 'curves' in the results section, 'section one' in the introduction, 'small scale datasets' in the experimental setup, and 'single architecture type' in the model description. The reviewer explicitly names these parts, making the grounding very clear.", "verifiability_rationale": "The review point makes a claim about the impact of the identified issues on the clarity and confidence in the empirical results. The reviewer provides specific examples to support this claim, such as how missing axis labels can make interpretation difficult and how randomly masked portions can skew perception. While the reviewer doesn't provide external references, the reasoning is based on wellestablished principles in data visualization and experimental design.", "helpfulness_rationale": "The review point is 5 because it directly points out concrete issues that are likely to affect the authors' confidence and the clarity of their results. By addressing these points, the authors can significantly improve the rigor and interpretability of their work. The suggestions are specific and actionable, making it easy for them to implement the changes."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review states \"novelty is limited\" and provides a reason (\"tighter CIs with finetuning are expected\"). While it identifies a potential issue, it doesn't explicitly *suggest* *how* to address the limited novelty or the expected behavior of CIs. The explanation is a hypothesis, not a concrete action.", "grounding_specificity_rationale": "The reviewer makes general statements about novelty and expected behavior without referring to specific parts or elements of the paper. The implications are broad and not tied to a concrete element.", "verifiability_rationale": "The review states an expectation and a potential issue (limited novelty) but doesn't present a definitive claim that requires verification. It's more of a constructive criticism pointing towards areas for improvement rather than directly instructing how to fix the work.", "helpfulness_rationale": "The review points out a valid concern (limited novelty, expected CI behavior) but lacks specific, actionable suggestions for the authors to improve their work. It's more of a constructive criticism than direct instruction."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'It would make for a stronger case if the paper reports the numbers observed when the label noise experiment is performed on imagenet with 1000 classes as well...'. This is a clear and direct action the authors should take. The reviewer identifies a specific experiment and a specific reason for why this would be beneficial, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer implies that the paper's experimental section or results are relevant to this suggestion. While the reviewer doesn't explicitly say 'Look at the results section,' the context of the request strongly suggests they are referring to the findings of the label noise experiment on ImageNet. The grounding is present but could be more explicit.", "verifiability_rationale": "The reviewer is not making a claim that needs verification. They are suggesting a specific experiment that, if included, could provide valuable insights. This is more of a suggestion for improvement than a claim requiring justification. The reviewer is offering a *wish* or a *suggestion for improvement*, not a statement that needs to be proven true.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors. They are pointing out a specific experiment that, if included, could significantly strengthen the paper's claims and provide valuable insights. The suggestion is directly relevant to the authors' work and is easy to understand and act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question and provides a suggestion ('Provide additional feedback'). While the suggestion is vague, the act of asking is a clear action. The reviewer also mentions 'weight updates' and 'network updates,' which are specific concepts, although the connection isn't fully explained.", "grounding_specificity_rationale": "The reviewer mentions 'weight updates' and 'network updates,' which can be considered grounded as they refer to specific concepts within the paper. However, the reviewer does not specify *which* parts of the paper these updates relate to, making the grounding weak. The suggestion 'Provide additional feedback' is not directly tied to these updates, further weakening the grounding of the specific issue being raised.", "verifiability_rationale": "The reviewer states a claim: 'Given that the brain does everything in parallel, why is the number of weight updates a better metric than the number of network updates?'. This claim is not supported by any evidence, reasoning, or references within the review point itself. The reviewer is making a statement without providing a justification or explanation.", "helpfulness_rationale": "The reviewer's point is clear and directly addresses a potential issue with the paper's metrics. The request to 'Provide additional feedback' is a direct and helpful suggestion for improvement. However, the *reason* for suggesting this alternative metric is missing, making the feedback less helpful in its current form."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks a 'why' question about the use of adversarial prediction accuracy, which is a valid point for discussion but does not directly instruct the authors on how to improve their draft. While it identifies a potential area of confusion, it lacks explicit guidance on concrete actions to be taken. The reviewer is prompting the authors to consider a different objective function, but doesn't specify how to implement or evaluate this change.", "grounding_specificity_rationale": "The review point asks a question about a general concept (adversarial prediction accuracy) without specifying which part of the paper or model this concept is being applied to. It does not identify a specific section, table, figure, or unique aspect of the paper. The question is about the *objective* of adversarial training, not a specific problem within the model or data.", "verifiability_rationale": "The review point does not contain a claim or assertion. It is a question posed to the authors, asking them to consider a different objective function. There is no logical reasoning, common knowledge, or external references provided within the review point itself.", "helpfulness_rationale": "The review point raises a valid question about the rationale behind using adversarial prediction accuracy. While this question can be helpful for the authors to understand their model better, it does not provide a concrete solution or actionable advice on how to improve their draft. It is more of a diagnostic question than a prescriptive one, lacking specific guidance on how to implement or evaluate the suggested alternative objective function."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out several implicit actions. While they mention 'the experiment setup' and 'the number of different sets of incontent examples,' they don't explicitly state what is missing or how to address it. The reviewer also mentions 'varying the number of InContext Examples' and 'relying solely on one dataset' without providing concrete actions or suggestions. The lack of explicitness makes it difficult for the authors to directly apply the feedback.", "grounding_specificity_rationale": "The reviewer's comment is general and doesn't pinpoint a specific section or table in the paper. They are referring to the 'experiment setup' and the 'dataset used' in a general sense. This makes it difficult for the authors to identify exactly where the issue lies, leading to weak grounding.", "verifiability_rationale": "The reviewer's comment contains claims about the evaluation being 'not sufficiently comprehensive' and 'lacking transparency.' However, these claims are not supported by specific examples, references, or logical reasoning within the review point itself. The reviewer states what they believe is missing but doesn't explain *why* or *how* this information should be presented. Therefore, the verifiability is 1.", "helpfulness_rationale": "The review point identifies specific areas where the authors should improve their evaluation process, such as providing more details about the experiment setup and evaluating on multiple datasets. While the reviewer points out concrete issues, they don't offer specific, actionable steps for the authors to take to address these issues. The feedback is informative but lacks concrete suggestions for improvement, making it 3 in identifying problems but not fully empowering the authors to resolve them."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the 'lack of comparative experiments' in Section 4.3. This is an explicit action that the authors should take to improve their experiments. The reviewer also names specific types of nonlinear blocks, providing a concrete action for the authors to consider.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 4.3', indicating a clear grounding of the issue. While it doesn't specify which exact experiment or figure lacks the comparison, it clearly identifies the location. The reviewer then suggests comparing with 'bottleneck in ResNet or linear bottleneck in MobileNetV2', providing a concrete action to take within that section.", "verifiability_rationale": "The review point contains a claim: 'In Section 4.3, there lack of comparative experiments with other nonlinear blocks...'. This claim is supported by the reviewer's statement of fact about the content of Section 4.3. While the reviewer doesn't provide specific examples of the lack of experiments or references to external works, the claim is clearly stated and verifiable based on the reviewer's knowledge of Section 4.3.", "helpfulness_rationale": "The review point is 5 as it directly identifies a specific weakness in the experimental section (lack of comparative experiments) and provides concrete suggestions for improvement by naming specific types of nonlinear blocks. This actionable feedback empowers the authors to understand the limitations of their current experiments and how to strengthen their evaluation."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point suggests improving the paper by ' paying attention to related work'. While this indicates a direction, it lacks a specific action on how to achieve this. The authors are not told what specific aspect of related work to focus on or how to integrate it into their current work. The suggestion is general and lacks concrete steps.", "grounding_specificity_rationale": "The review point explicitly mentions 'related work (such as 1,2,3)'. This directly identifies the specific area of related work being addressed by name. The authors can easily pinpoint the referenced works.", "verifiability_rationale": "The review point states 'the submission would benefit from additional attention to related work'. This is a statement of opinion or judgment about what the authors should do, not a claim that can be verified. There is no logical reasoning, common knowledge, or external references provided to support this suggestion. It's a suggestion, not a verifiable statement.", "helpfulness_rationale": "The review point suggests focusing on 'related work' as a way to improve the submission. While this is a valid suggestion and could be helpful in guiding the authors, it is a general, broad piece of advice. It doesn't pinpoint specific weaknesses or provide concrete steps to take. The feedback is about a general area of improvement rather than a specific, actionable fix."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential weakness (lack of algorithmic focus) and suggests a general improvement (focusing on algorithms). While the authors can infer the need for more algorithmic content, the specific steps or actions to take are not explicitly stated. The suggestion is broad and lacks concrete details.", "grounding_specificity_rationale": "The reviewer mentions 'the algorithmic aspects of the solution' and 'the Blackwell winner is proposed.' While they touch on the concept of the Blackwell winner, they don't explicitly point to a specific section, table, figure, or unique element in the paper where this weakness is present. The connection to the Blackwell winner is implied, and the suggestion is general.", "verifiability_rationale": "The review expresses an opinion about the paper's focus and novelty, stating 'I believe the paper should have also focused on the algorithmic aspects of the solution' and 'the novelty of the paper seems limited.' This is a statement of opinion and judgment, not a claim that requires verification or evidence. There are no specific examples or references provided to support this opinion.", "helpfulness_rationale": "The reviewer identifies a potential area for improvement (lack of algorithmic focus) and suggests a general direction for the authors (focusing on algorithms). However, they do not provide specific, actionable steps or examples for the authors to take. The suggestion is broad and lacks concrete details, making it less immediately helpful."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly names the elements of Figure 5 that are causing confusion ('valid' and 'orig') and directly asks for clarification on their difference. This constitutes an explicit action that is also concrete, as the authors know exactly what needs to be understood.", "grounding_specificity_rationale": "The comment explicitly refers to 'Fig. 5', a specific part of the paper. It then directly asks about the difference between 'valid' and 'orig' within that figure, providing a clear and specific indication of the issue being addressed.", "verifiability_rationale": "While the comment itself is not a claim, it implicitly suggests a need for clarification regarding the difference between 'valid' and 'orig' in Figure 5. This implies a potential issue that needs verification or explanation. The reasoning provided is that the reviewer needs to understand this difference to improve their draft. The comment is not a direct claim but points to a potential area for improvement by clarifying a specific aspect of a figure.", "helpfulness_rationale": "The comment is directly helpful because it clarifies the meaning of 'valid' and 'orig' in Figure 5, which is crucial for understanding and potentially improving the draft. The explicit request for clarification directly addresses a specific point of confusion for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing to 'a method mentioned in the computer vision setting,' which is a general category. While it implies a comparison, it doesn't explicitly state the steps or criteria for this comparison, making it somewhat vague in its actionable steps. The reviewer contrasts this with comparing to 'lossbased sampling,' indicating a preference for a different type of comparison. However, the action itself (comparing) is clear, but the specifics are not.", "grounding_specificity_rationale": "The reviewer mentions 'a method mentioned in the computer vision setting.' While they identify the *category* of methods, they don't specify which particular method or section of the paper this refers to. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer doesn't make a claim that *this specific method is better* or *lossbased sampling is worse*. They offer a perspective on the utility of different comparison types. There is X being verified in this review point.", "helpfulness_rationale": "The review point offers a suggestion to compare against computer vision methods and contrasts it with lossbased sampling. This provides a perspective on how to approach a problem and guides the authors towards a specific type of analysis. While it doesn't provide a definitive answer or a concrete method, it offers a valuable insight into potential comparison strategies, making it 3 in guiding future work."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the connection to the 'properties of universal kernels' and refers to 'chapter 4 of Steinwart and Christmann'. This clearly indicates an intention to point out a relevant concept or area of research. While it doesn't specify the exact issue, the action is identifiable.", "grounding_specificity_rationale": "The reviewer mentions 'properties of universal kernels' and specifically points to 'chapter 4 of Steinwart and Christmann'. This provides a clear indication of the section or area of external work being referenced, demonstrating strong grounding. However, the reviewer doesn't specify *which* property or *which* aspect of the paper this should relate to, making the specificity somewhat underdefined.", "verifiability_rationale": "The reviewer makes a suggestion or recommendation: 'See in particular chapter 4 of Steinwart and Christmann...'. This constitutes a claim that there's a connection. However, the reviewer does not provide any specific justification or evidence *within this review point* to support this claim. The reference to external literature is a suggestion for the authors to explore, but not a verified claim within this review itself.", "helpfulness_rationale": "The reviewer's comment suggests a potential area of investigation by pointing to a relevant theoretical concept. While this is a valuable suggestion and could guide the authors, it doesn't provide a concrete, actionable fix or a clear next step. The reviewer is offering a *potential* direction rather than a direct solution."}
