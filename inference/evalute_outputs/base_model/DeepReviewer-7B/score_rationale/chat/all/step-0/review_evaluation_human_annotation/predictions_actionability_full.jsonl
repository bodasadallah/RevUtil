{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The reviewer points out a potential issue (noise in the dataset). This is an observation, not a direct action. It suggests an action: 'Check the dataset for noise.' However, the review itself doesn't explicitly state this action or provide details on how to do it. Therefore, while it *could* be actionable, the review point itself is not explicit or concrete enough to be considered actionable.", "grounding_specificity_rationale": "The reviewer mentions 'artificially created,' 'noise,' 'misinformation,' and 'outofcontext images.' These are specific aspects of the dataset. However, the reviewer does not explicitly state which part of the dataset (e.g., specific tweets, images, metadata) these issues relate to. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer states the 'possibility' of noise but does not provide any evidence, reasoning, or references to support this claim. There is X extracted from this review point. Therefore, it is 1.", "helpfulness_rationale": "The reviewer expresses a desire to understand the dataset's quality. While this is a valid concern for the authors, the review point itself does not directly instruct or request improvements to the draft. It's a desire for information, not a direct request for actionable feedback on the draft itself. Therefore, it is not helpful in terms of directly improving the authors' current draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the lack of 'dig into the theory' and 'show the convergence properties' of the proposed algorithm. These are direct and clear actions or suggestions that authors can directly identify modifications they should apply to their draft. The language is direct and doesn't require inference.", "grounding_specificity_rationale": "The review point mentions 'theory profs' and 'convergence properties' of the algorithm. This provides a specific area within the paper where the lack of detail is being pointed out. While it doesn't pinpoint a specific section or table, it clearly identifies the *nature* of the missing information. Therefore, it can be considered weakly grounded in terms of identifying the *section* but specific in identifying the *type* of information missing.", "verifiability_rationale": "The review point makes a claim about the paper's lack of theoretical analysis and convergence demonstration. While it states a fact, it doesn't provide any logical reasoning, common knowledge, or external references to support this claim. It's a statement of opinion or judgment about the paper, requiring further justification to be considered verifiable.", "helpfulness_rationale": "The review point identifies a significant area for improvement by pointing out the lack of theoretical analysis and convergence demonstration. This is generally helpful for authors as it highlights a key deficiency. However, it lacks specific suggestions on *how* to address this deficiency, making it less impactful than a more detailed comment."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the methodology used to calculate the overall score in the results section. This directly points to a lack of clarity in the description of the calculation method. While the reviewer doesn't explicitly state what is unclear, the question itself indicates a potential ambiguity or lack of detail in the explanation of how the scores were aggregated. Therefore, the review point is considered actionable as it identifies a specific area of the paper (the results calculation) where further clarification is needed.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper being addressed. The reviewer is asking a question about the methodology used elsewhere in the paper, not about a specific element within that methodology. While the method is used in the 'results' section, the review point itself doesn't pinpoint a specific element within that section that needs clarification. Therefore, the grounding is weak, as the authors cannot confidently determine which part of the paper the comment addresses.", "verifiability_rationale": "The reviewer states a claim ('why you did not consider...') without providing explicit evidence or justification within this review point. They are asking a question, which implies a belief that the current method is better, but they do not provide any logical reasoning, common knowledge, or external references to support this claim within the review itself. Therefore, the verifiability is low, as the claim is made without sufficient supporting evidence within the review point.", "helpfulness_rationale": "The reviewer's question directly relates to the clarity and usefulness of the feedback for the authors. They are asking for a justification of a methodological choice, which directly impacts the authors' ability to understand and act upon the feedback. While the review point itself doesn't provide the justification, the question directly prompts for it, making it 3 in identifying a potential area where the feedback could be improved for the authors. Therefore, the helpfulness is considered 3 as the question directly relates to the authors' ability to understand and act upon the feedback."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential issue with the description of HIERENC's input calculation but doesn't explicitly recommend a solution or provide a concrete alternative. While they point out a potential problem (averaging all entity instantiations), they don't offer a clear improvement or a different approach. The reviewer's point focuses on the *what* (the averaging) and *why it might be a problem* (noise), but lacks a direct suggestion of what should be done instead.", "grounding_specificity_rationale": "The reviewer mentions 'HIERENC' and describes the process of calculating its input. They state that each input (h_i) is the average of representations of all instantiations of context filled by every possible entity in the vocabulary. This demonstrates an attempt to ground the discussion by referencing a specific component (HIERENC) and describing its input. However, the reviewer doesn't explicitly state which part of the paper they are addressing (e.g., the description of HIERENC itself, or the overall method). The grounding is present, but the clarity of the referenced part could be improved.", "verifiability_rationale": "The reviewer states that the description of HIERENC's input calculation introduces 'a lot of noise' due to averaging all possible entity instantiations. While the reviewer provides a claim (the averaging introduces noise), they don't explicitly provide external references or logical reasoning to *verify* this claim. The reviewer's statement is an inference based on their understanding of the potential issues with the averaging process, but lacks direct evidence or citations to support the claim of noise.", "helpfulness_rationale": "The reviewer's point directly addresses a technical detail of the method (the description of HIERENC's input calculation) and raises a potential issue (the introduction of noise). This point is relevant to the authors who are trying to understand or implement the method. By highlighting a potential flaw in the description, the reviewer provides a suggestion for improvement, which could be helpful for the authors."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "1", "verifiability_label": "Not Verifiable", "helpfulness_label": "4", "actionability_rationale": "The review point is a question, not a statement that explicitly calls for an action. While the reviewer is expressing a desire for clarification, the point itself doesn't dictate what needs to be done with it. Therefore, it doesn't directly provide actionable feedback.", "grounding_specificity_rationale": "The review point is about the methodology of selecting answers, not about a specific part of the paper being criticized. Therefore, it doesn't identify a specific section, table, figure, or unique element of the paper. It's about the evaluation process itself.", "verifiability_rationale": "The review point is a question about the evaluation process, not a claim that needs verification. While it implies a process exists, it doesn't explicitly state a claim that requires justification. Therefore, it doesn't fit the 'X' category (X). The verifiability of the process itself is unclear due to the lack of detail in the question.", "helpfulness_rationale": "The review point directly questions the evaluation process and its potential impact on performance estimation. This is a clear indication of a helpful review point, as it points out a potential issue with the methodology. It asks for clarification and justification of a process, which is valuable information for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests a change in how the data is described, implying an action to make the description clearer. While the current comment could be interpreted as actionable (the authors could try to understand the description as contradictory), the reviewer's suggestion for improvement adds a layer of explicitness. Therefore, it's 3 as the authors can act upon the suggestion to improve clarity.", "grounding_specificity_rationale": "The reviewer points out that the description of the data used is not precise and lacks explicit mention of Li et al. (2019a) earlier. The authors can infer the data source but cannot confidently determine the specific part of the paper being addressed without the explicit mention. This aligns with the definition of '2'.", "verifiability_rationale": "The reviewer identifies a potential contradiction in the description of the data and suggests citing Li et al. (2019a) to verify the syntactic information. The comment itself identifies a weakness (the potential contradiction) and suggests a way to verify it. While not 5 within the comment itself, the reviewer's point about verification points towards '3'.", "helpfulness_rationale": "The reviewer's comment is informative about a potential issue with the data description and suggests a way to improve it. While the comment provides some information, the reviewer's point about clarity makes it '3' as the authors can improve the feedback's impact."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a lack of explanation regarding the purpose of the average duration in Table 1. While the reviewer doesn't explicitly state an action, the question about understanding the table's content implies an action on the part of the authors. The lack of explicitness makes it 3, as the authors would need to infer the meaning.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 1' and asks a specific question about the 'average duration'. This demonstrates a clear grounding of the reference. The request for clarification about whether waiting time is included further specifies the area of concern.", "verifiability_rationale": "The reviewer makes a claim about the lack of supporting explanation for the table and asks for clarification. This claim is verifiable by checking the table's caption or surrounding text. The request for clarification is also a verifiable action for the authors.", "helpfulness_rationale": "The reviewer's question directly addresses a lack of clarity and understanding, which is a significant point for the authors. The request for clarification is a direct and actionable improvement. This feedback is 5 as it guides the authors on how to better understand and potentially improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to clarify Table 4, which is an action. The request is also concrete, asking for the specific splits used, meaning the authors know exactly what needs to be done (obtain the splits and understand how they relate to the ATIS numbers).", "grounding_specificity_rationale": "The reviewer's comment directly refers to 'Table 4' and 'ATIS numbers,' indicating a clear identification of the specific part of the paper being addressed. This is a strong form of grounding as the comment pinpoints the exact location of the issue.", "verifiability_rationale": "The reviewer is asking a question about the methodology used to generate the results in Table 4. There is no explicit claim being made, nor is there any suggestion or judgment being offered. The request is a question that should ideally be answerable by referring to the paper's methodology section. The lack of justification makes it 1 in the sense that the authors cannot independently confirm the validity of the information presented without further information from the reviewer.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential weakness in the paper (lack of clarity on Table 4). By asking for clarification on the splits used, they are providing a concrete suggestion for improvement. This directly helps the authors understand and reproduce the results. The request for clarification is a valuable contribution to the paper's clarity and reproducibility."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests a specific way to phrase the results, implying an action to improve clarity. However, the exact action or change is not explicitly stated, making it somewhat vague. The reviewer's suggestion is a general improvement rather than a concrete, actionable step like 'rewrite section X to be clearer'.", "grounding_specificity_rationale": "The reviewer makes a general comment about the results being 'on par or better' and suggests a specific interpretation. They do not explicitly identify a specific part of the paper or result that needs improvement. The comment is about the overall interpretation of the results, not a specific detail within the paper.", "verifiability_rationale": "The reviewer's comment is a subjective opinion about the interpretation of the results. They do not provide any evidence, reasoning, or references to support their claim. The statement is purely an interpretation and lacks any verifiable basis.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by recommending a specific way to phrase the results. They explain their reasoning, stating that this wording would make the results clearer and easier to understand. This actionable feedback directly addresses a potential weakness in the presentation of the results."}
{"actionability_label": "2 (2)", "grounding_specificity_label": "4 (4)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer asks a question about interpreting results in Table 3, which implicitly suggests an action (understanding the implications). However, the reviewer does not explicitly state how to interpret the overlapping 95% confidence intervals or provide concrete guidance on what these results mean for the models.", "grounding_specificity_rationale": "The reviewer refers to specific results in Table 3, specifically mentioning 'Chinese MOSQ', 'Chinese MOSV', and 'English MOSV'. This demonstrates a clear identification of the specific part of the paper being addressed. The reviewer also explicitly states 'For results shown in Table 3', which indicates a strong grounding of the comment.", "verifiability_rationale": "The reviewer states the findings about the comparability of models in Table 3 without providing any justification, reasoning, or external references. The statement is purely descriptive and lacks any supporting evidence.", "helpfulness_rationale": "The reviewer's question about interpreting results in Table 3 is relevant to understanding the findings. However, the review point does not offer any solutions or guidance on how to proceed based on this interpretation. It simply asks a question."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a flaw in the presentation of results but does not provide a specific action or suggestion on how to improve the spacing. It points out a problem but doesn't tell the authors what to do about it.", "grounding_specificity_rationale": "The comment explicitly mentions 'Table 2 and Table 3', which are specific sections of the paper. This allows the authors to identify the relevant part of the paper being addressed.", "verifiability_rationale": "The comment makes a judgment about the presentation of results being inconsistent, which can be considered a deduction or observation. However, it doesn't provide specific examples or references to support this claim.", "helpfulness_rationale": "The comment points out a valid issue regarding the formatting of tables. It highlights a potential problem for the authors' work, which is a form of constructive feedback. However, it doesn't offer a solution or a broader discussion on the implications of this formatting issue."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "2 (2)", "verifiability_label": "X (X)", "helpfulness_label": "3 (3)", "actionability_rationale": "The comment explicitly states 'antecedent missing', which indicates a problem with something preceding 'both tasks'. This is an explicit action, but it lacks specific details on what is missing.", "grounding_specificity_rationale": "The comment refers to 'both tasks' without explicitly identifying the specific part of the paper being addressed. It does not name a section, table, figure, or unique element. Therefore, the grounding is weak. While it points out a potential issue, it doesn't specify what is missing within 'both tasks'.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It points out a potential issue ('antecedent missing') but does not formulate a statement that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The comment identifies a potential issue ('antecedent missing'), which is valuable feedback. However, it does not offer a solution or suggest how to address the problem. It is diagnostic but lacks prescriptive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point states a lack of novelty and points out prior work on adversarial attacks. While it identifies a *related* area (videotext models), it doesn't explicitly *recommend* an action or suggest a *specific* improvement. It's more of a statement of fact.", "grounding_specificity_rationale": "The review point mentions \"many NLP models and imagetext models\" and \"prior work on adversarial attacks.\" The reviewer also mentions \"videotext models\" as the target area. While it names the *types* of models and the *area* of application, it doesn't pinpoint a *specific* model, paper, or aspect within these categories. The grounding is implied but not explicit.", "verifiability_rationale": "The review point contains a claim: \"Lack of novelty\". This is a statement of opinion or judgment about the work. The reviewer *summarizes* related work in the related work section of the paper. This provides some justification for their claim. However, they don't provide *new* evidence or *specific* examples of how these attacks are applied to NLP or imagetext models to demonstrate the lack of novelty in the *videotext* context.", "helpfulness_rationale": "The review point is more of a statement of the authors' perception of the novelty of their work. While it identifies a relevant area of research, it doesn't directly guide the authors on *how* to improve their work. It's more of a negative comment rather than a constructive suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem ('confusing') and provides a clear action ('more separate paragraphs'). The suggestion is concrete, indicating a direct understanding of what needs to be improved. The reviewer knows what they want to achieve (clarify Section 3.2) and how to do it (reorganize the content).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3.2' and then specifies the content to be separated ('lexical features' and 'sentencelevel features'). This demonstrates a clear understanding of the location and the specific elements within that section that require clarification. The reviewer provides a precise target for their feedback.", "verifiability_rationale": "The reviewer is making a suggestion for improvement rather than stating a claim that requires verification. The suggestion is about the organization and clarity of information, which is a constructive feedback but doesn't inherently require external references or logical reasoning to be considered valid. The reviewer is proposing a change based on their interpretation of the confusion.", "helpfulness_rationale": "The reviewer directly addresses a potential issue authors might face with Section 3.2 and provides a clear and actionable suggestion to resolve it. This is highly likely to be helpful for the authors who might be struggling with the same confusion. The suggestion is specific and directly targets the identified problem."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses an opinion about the space allocation but does not propose a concrete action or improvement. The reviewer states, 'I find that dedicating a whole section of the paper plus experimental results is a lot of space,' which is a subjective assessment, not a directive for the authors to make changes.", "grounding_specificity_rationale": "The reviewer refers to 'a whole section of the paper' and 'experimental results' generally, without pinpointing a specific part of the paper or detailing what is problematic within that section or results. The reference is vague and lacks precision.", "verifiability_rationale": "The review point is an opinion and does not contain a claim that requires verification. The reviewer states, 'I find that...,' which is a subjective statement, not a claim that can be supported or unsupported. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point is primarily a critique of the space allocation and lacks specific guidance on how to improve the paper based on this critique. While it highlights a potential inefficiency, it doesn't offer concrete suggestions for the authors to follow. The reviewer's statement is more of an observation than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that using integrated gradients has been studied and that the paper proposes postprocessing steps. These are direct statements of what the paper contains, making the action clear and explicit. The reviewer also mentions 'falsepositive neurons' and 'ablation study' without specifying which postprocessing steps or how the ablation study would be conducted, making the action somewhat vague on how to implement it.", "grounding_specificity_rationale": "The reviewer refers to 'postprocessing steps' and 'ablation study' generally. While they imply the existence of these steps, they don't specify which section, table, or unique aspect of the paper they address. The reviewer also doesn't clearly detail what is wrong with the postprocessing or how the ablation study would be performed, making the grounding weak. However, the reviewer does identify the specific area of the paper being questioned (the method section and its postprocessing steps), which can be inferred from the context of the review.", "verifiability_rationale": "The reviewer states that the paper 'lacks an ablation study to demonstrate the importance of these postprocessing steps.' This is a claim that the paper is missing supporting evidence. The reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. While the reviewer suggests an ablation study might be needed, this is a suggestion, not a claim that is being verified or unverified by the paper itself.", "helpfulness_rationale": "The reviewer points out a potential weakness in the paper (the lack of an ablation study) and suggests a potential improvement (an ablation study). This is a constructive comment that identifies a missing element and proposes a solution. While the reviewer doesn't explicitly recommend performing the ablation study, their comment is directly aimed at improving the paper's rigor and providing more comprehensive evidence. This makes the review helpful for the authors in understanding the limitations and potential improvements of their work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer proposes a method and then identifies a specific limitation: 'It\u2019s not clear how to handle the situation when the head word is not a pronoun.' While the reviewer suggests *matching the head of noun phrases* as a solution, they don't specify how this would work in practice for nonpronoun heads. This is an implicit action that requires further clarification.", "grounding_specificity_rationale": "The reviewer proposes a specific method (matching the head of noun phrases) to identify the antecedent. This demonstrates strong grounding as the specific part of the paper being addressed is clearly identified.", "verifiability_rationale": "The reviewer states a concern about the proposed method's clarity when the head is not a pronoun. However, they do not provide any justification or evidence to support this claim. The statement itself is a claim that requires verification.", "helpfulness_rationale": "The reviewer raises a valid concern about the proposed method's limitations. While they suggest a potential solution, they do not elaborate on it or provide a clear path forward. The comment primarily expresses a concern about the method's clarity."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer's point is somewhat implicit. While they clearly state the comparison is 'unclear' and suggest including 'more baselines,' the exact action the authors should take is not explicitly stated. The suggestion is more of a call for clarification and addition rather than a direct instruction on how to perform a specific action. The action is vague, as it doesn't specify *how* the comparison should be made or what criteria should be used to select the additional baselines.", "grounding_specificity_rationale": "The reviewer refers to 'models that only consider different senses but not sememes' and suggests the MST baseline as an example. However, they do not explicitly state where in the paper this baseline is located or how it is described. The reviewer's suggestion to include 'more baselines based on related work' is a general suggestion and not a specific reference to a particular part of the paper. While the reviewer points to a potential gap in the comparison, the grounding is in the *review itself* pointing out a potential issue, not in the specific sections or tables of the paper being reviewed.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity regarding the comparison to models considering only senses and suggests baselines based on related work. This claim could be considered 3. The reviewer points to the emphasis on 'soft vs. hard word sense disambiguation' as the current discussion's focus, potentially supporting their claim about the lack of clarity regarding sememes. However, the reviewer does not provide specific references or examples to support this claim within the review point itself.", "helpfulness_rationale": "The reviewer's suggestions for including more baselines based on related work are relevant and directly address potential weaknesses in the comparison. This provides useful information to the authors. However, the initial part of the review, stating the comparison is 'unclear,' is somewhat vague and could be expanded with more specific suggestions or questions. The helpfulness is moderate as the suggestions are relevant but could be more concrete and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point contains two claims. The first, 'The abstract is written well and invokes intriguing early', is a positive statement and does not provide explicit or concrete actions for the author. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', explicitly states an action and provides a concrete suggestion for improvement. Therefore, the review point is partially actionable.", "grounding_specificity_rationale": "The review point contains two claims. The first, 'The abstract is written well and invokes intriguing early', does not explicitly identify a specific part of the paper being addressed, making it weakly grounded. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', explicitly refers to the inconsistency between gold and human evaluations and provides a specific example, making this part 5. Therefore, the review point has somewhat specific grounding.", "verifiability_rationale": "The review point contains two claims. The first, 'The abstract is written well and invokes intriguing early', is a subjective statement and does not provide any evidence or justification, making it 1. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', points to a wellknown issue in the field (the inconsistency between gold and human evaluations) and provides a specific example, making this claim 5. Therefore, the review point has 3 claims.", "helpfulness_rationale": "The review point contains two claims. The first, 'The abstract is written well and invokes intriguing early', is a positive comment and does not offer specific actionable feedback, making it not very helpful. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', identifies a specific area for improvement (the abstract) and provides a concrete suggestion for improvement, making this part 5. Therefore, the review point is 3 as it contains both not helpful and 5 elements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states that the selection process for 'frame similarity factors' and 'attributes similarity factors' is unclear. This directly points to an actionable area for the authors to seek clarification or further explanation.", "grounding_specificity_rationale": "The review point explicitly mentions 'frame similarity factors' and 'attributes similarity factors', which are specific components of the model. This demonstrates strong grounding as the authors can identify the specific part of their work being addressed. The comment also states that the selection of these factors is unclear, which is a specific issue within the methodology.", "verifiability_rationale": "The review point does not contain a claim. It is a statement of a deficiency in the clarity of the methodology. Therefore, verifiability is not the primary aspect to evaluate here.", "helpfulness_rationale": "The review point identifies a lack of clarity in the methodology. While it points to a potential area for improvement, it doesn't directly suggest *how* to improve the clarity. It's a diagnostic statement rather than a prescriptive one."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need for a discussion on the convergence of the joint learning process and its connection to obtaining stable points in probabilistic metric space. This implies an action: to explain or elaborate on this mechanism. The reviewer identifies a missing element (discussion of convergence and stable points) and specifies what needs to be discussed (convergence, stable points, probabilistic metric space). This makes the comment explicit and concrete, providing a clear action for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'convergence of the proposed joint learning process' and then further specifies the 'stable points in probabilistic metric space' as the context for this convergence. This direct identification of the specific part of the paper being addressed demonstrates strong grounding. The reviewer also clearly states what is missing: a 'discussion' or 'explanation' of this process. This makes the comment 5 about the missing information.", "verifiability_rationale": "The reviewer is not presenting a claim that needs verification. They are requesting information or an explanation about a specific technical aspect of the method. This falls under the 'normal statements' category, where the purpose is to provide information rather than assert an opinion or require justification. There is no logical reasoning, common knowledge, or external references being introduced to support a claim.", "helpfulness_rationale": "The reviewer is asking for clarification on a core technical aspect of the method, specifically the convergence of the joint learning process and its relation to stable points in probabilistic metric space. This is directly relevant to the authors' understanding and ability to reproduce their work. While it might not provide a *new* insight, it addresses a fundamental point for clarity and correctness, making it a valuable piece of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states actions to be taken. It says '681 as mentioned above, you should discuss the results for the task of inferring knowledge on objects, and also include results for model (B)' and '778 \"latent in verbs\": why don't you mention objects here?'. These sentences directly tell the authors what needs to be done and how to do it. The first part clearly indicates the action of discussing and including results, while the second part asks for a correction regarding the mention of objects. The actions are also quite concrete, specifying the tasks to be performed.", "grounding_specificity_rationale": "The review point refers to specific elements of the paper. It mentions 'the results for the task of inferring knowledge on objects' and 'results for model (B)'. This indicates that the authors are expected to have identified these results and are pointing out a need for discussion and inclusion. While it doesn't explicitly point to a specific section or table, it refers to specific *outputs* of the model. The second part of the review, '778 \"latent in verbs\": why don't you mention objects here?', directly refers to a specific term ('latent in verbs') within the paper's methodology or explanation. This makes the grounding quite specific, as it identifies a particular element that needs attention.", "verifiability_rationale": "The review point makes claims about the paper's content and methodology. It states that there's a need to discuss the results for the task of inferring knowledge on objects and include results for model (B), which is a claim that requires these actions. It also points out an inconsistency in terminology ('latent in verbs' and 'objects'). While it doesn't provide external references to support these claims, the reasoning is logical and based on the observed inconsistencies. The claim about the missing mention of objects is directly inferred from the observation of the term 'latent in verbs' being used without the corresponding 'objects'.", "helpfulness_rationale": "The review point provides clear and actionable feedback to the authors. It directly points out potential weaknesses in the paper's analysis and methodology, specifically the need to discuss and include results for model (B) and the inconsistency in terminology. The suggestions are concrete and directly address potential areas for improvement. The reviewer is asking the authors to take specific actions, which is 5 in refining their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out the incorrect sentence in line 212 and provides a clear alternative description based on their interpretation of Figure 2. The reviewer states, 'The correct way would be to say that you do a bidirectional encoder that encodes the source sentence into a set of vectors... at least, that's what's seen in Figure 2.' This is an explicit statement of an error and a suggestion for improvement, making it actionable.", "grounding_specificity_rationale": "The reviewer explicitly references 'line 212' in the paper, providing a very specific point of reference. They also explain what is *incorrect* in that line and what the *correct* interpretation should be based on Figure 2. This strong grounding makes it clear to the authors where the issue lies and what needs to be addressed.", "verifiability_rationale": "The reviewer points out a factual discrepancy between the text in line 212 and their interpretation based on Figure 2. If the paper *accurately* describes a bidirectional encoder producing a set of vectors, then the reviewer's correction is verifiable. The reviewer is not making a subjective judgment but rather highlighting a difference between the text and the visual representation. This makes the feedback actionable and verifiable.", "helpfulness_rationale": "The reviewer provides a clear and specific correction to a potential point of confusion for the authors. By highlighting the difference between a single vector and a set of vectors, the reviewer is directly addressing a specific implementation detail that could lead to misunderstandings. This is a 5 and constructive suggestion that empowers the authors to improve their draft."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the nature of the work ('fairly straightforward extension of existing retrofitting work') and implies an improvement ('would be nice to see some additional baselines'). However, it does not specify *how* to implement this improvement or what specific aspects of the extension are lacking. The action is implied but not explicitly stated in a concrete manner.", "grounding_specificity_rationale": "The comment explicitly mentions 'existing retrofitting work,' which grounds the feedback to a specific area of the paper. However, the suggestion to 'see some additional baselines' is general and lacks specificity. The reviewer does not identify a particular section, table, figure, or unique element within the 'existing retrofitting work' that requires improvement.", "verifiability_rationale": "The comment contains a claim ('would be nice to see some additional baselines') that suggests a potential improvement. However, it does not provide any justification or evidence for why these additional baselines would be beneficial, how they should be implemented, or provide any references to support this suggestion. The claim is stated but not wellverified.", "helpfulness_rationale": "The comment identifies a potential area for improvement (testing with additional baselines) but does not provide specific details on what these baselines should be, how they should be compared, or what specific aspects of the current draft would be improved by this. The suggestion is general and lacks actionable steps, making it less helpful for the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states weaknesses in the baseline models and suggests improvements, although it doesn't specify *how* to address these weaknesses. The suggestions are general and could be interpreted in multiple ways. For example, 'Weak Baseline Models' could mean adding more comparisons, but it doesn't detail which models to compare or how to justify their weakness. The suggestion to 'Rephrase Sentence' is vague and doesn't provide specific guidance on which sentence or how to rephrase it. The suggestion to 'Add Citation' is also vague and doesn't specify *where* in the paper this citation should go. The suggestion to 'Compare to Domain Adaptation Methods' is a general direction but lacks specific examples or criteria for comparison.", "grounding_specificity_rationale": "The review point identifies general areas for improvement, such as 'Weak Baseline Models' and 'Missing Domain Adaptation Comparisons,' but it does not explicitly point to a specific section, table, figure, or unique aspect of the paper where these weaknesses are located. The suggestions are broad and could apply to various parts of the paper. For instance, when suggesting 'Rephrase Sentence,' the review doesn't specify *which* sentence. Similarly, when suggesting 'Add Citation,' it doesn't indicate *where* in the paper this citation should be added. While the concepts are clear, the specific application is not welldefined.", "verifiability_rationale": "The review point makes claims about the weakness of baseline models and the lack of comparison to domain adaptation methods. However, it lacks specific evidence or references to support these claims. For example, when stating 'Weak Baseline Models,' the review doesn't provide any examples of how these models are weak or cite any specific performance metrics that demonstrate this weakness. Similarly, when suggesting 'Compare to Domain Adaptation Methods,' it doesn't provide any criteria for comparison or cite relevant works in this area. The claim 'The may be attributed...' is a hypothesis but lacks sufficient justification or evidence.", "helpfulness_rationale": "The review point identifies areas where the author's work could be improved, specifically regarding the choice of baseline models and the comparison to domain adaptation methods. The suggestions to 'Rephrase Sentence' and 'Add Citation' are directly actionable and address specific formatting and clarity issues. However, the criticism of 'Weak Baseline Models' and 'Missing Domain Adaptation Comparisons' is more of a general observation than a specific, actionable suggestion. While it points to areas for improvement, it doesn't provide concrete steps for the author to take. The lack of specific examples or criteria for comparison makes it less helpful than suggestions like rephrasing or adding a citation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action: 'may use'. This indicates a suggestion for improvement. The action is to replace the label on the yaxis of figure 5. This action is clear and directly addresses a potential issue with the figure. The reviewer is directly pointing out a potential improvement.", "grounding_specificity_rationale": "The comment explicitly mentions 'figure 5' when suggesting a change to the yaxis label. This clearly identifies the specific part of the paper being addressed. The comment is specific about the suggestion, which is to change the label. The grounding is literal and precise.", "verifiability_rationale": "The comment contains a claim: 'may use'. This claim suggests that the current label might not be the most appropriate or accurate. While the comment doesn't provide explicit justification or evidence for this claim, it implies a potential issue with the current label. The suggestion to use a different label implies a belief in the exact match ratio as a more suitable metric, although this isn't explicitly stated or verified within the review point itself. The claim is not fully supported by explicit reasoning or references within the review point.", "helpfulness_rationale": "The comment provides a clear and actionable suggestion: to replace the label on the yaxis of figure 5 with 'Exact Match ratio'. This is a direct and specific improvement that the authors can easily implement. The suggestion is welldefined and directly addresses a potential issue with the figure's clarity. The reviewer is empowering the authors to make a concrete change."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer points out a relevant concern (societal biases) and suggests a general approach (reasoning chains). However, the lack of specific implementation details makes it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions broad terms like 'societal biases\" and \"knowledge bases\" without specifying a particular aspect or component.", "verifiability_rationale": "The reviewer states a concern about the effectiveness of reasoning chains and points to a figure as evidence of their lack of conviction. However, this is a subjective statement and lacks any logical or factual basis within the review point itself.", "helpfulness_rationale": "The reviewer raises a valid concern about societal biases in knowledge bases, which is a relevant issue for authors to be aware of. Suggesting the use of reasoning chains is a relevant suggestion. However, the lack of specific guidance on how to implement this makes it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the difficulty of proving attention works and suggests changing the attention mechanism. This is a clear indication of an actionable point, as it directly points towards a potential improvement. However, the suggestion lacks specific details on *how* to change the attention mechanism, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer discusses the general difficulty of proving attention works in seq2seq MTL and suggests focusing on understanding *why* it fails. While this is a relevant point, the comment does not explicitly identify a specific part of the paper, model, or data where this issue manifests. The discussion is general and doesn't pinpoint a concrete area for investigation.", "verifiability_rationale": "The reviewer makes a claim about the difficulty of proving attention works in seq2seq MTL and suggests focusing on understanding *why* it fails. While this is a valid observation, the comment does not provide any specific evidence, examples, or references to support this claim. It is presented as a general statement without any backing.", "helpfulness_rationale": "The reviewer raises a pertinent point about the common practice of focusing on negative results (showing something is not working) in research. They suggest exploring the reasons *why* attention fails in this context. While the suggestion is broad and lacks specific details, it offers a potentially valuable direction for future research and could guide the authors in improving their draft. This makes the comment 3 as it points towards a potentially fruitful area of investigation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly states the missing strong baselines and asks for justification. The action is to identify the missing baselines, which is clear and direct.", "grounding_specificity_rationale": "The comment explicitly mentions 'Table 3' and 'MCNC', which are specific parts of the paper. The grounding is strong as the section and concept are clearly identified.", "verifiability_rationale": "The comment contains a claim ('MCNC should have many strong baselines...') but does not provide any evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the statement about the missing baselines.", "helpfulness_rationale": "The comment identifies a weakness in the paper (missing strong baselines and lack of justification) but does not offer any suggestions or reasoning to address this weakness. It simply states the problem without providing any actionable steps for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a problem (paper dependence on supplementary material) but doesn't explicitly recommend a specific action to address it. While the problem is clear, the lack of a direct solution makes it 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific sections/figures (S3.1, Sup. Fig. 6) within the paper, demonstrating strong grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the paper's independence and provides evidence (mention of supplementary references) to support it. While the evidence is present, it could be more robust with direct examples or citations, making it 3.", "helpfulness_rationale": "The reviewer raises a valid and important point about the paper's structure and reliance on supplementary material, which directly impacts the paper's selfsufficiency. This is a 5 critique for improving clarity and rigor."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two suggestions. The first suggests adding word embeddings to the BiLSTMCRF model, which is an explicit action. The second suggests clarifying the meaning of 'KNs' in Figure 3, which requires the authors to take an action (clarify) but lacks specific guidance on how to do so. Therefore, the reviewer's point is partially actionable.", "grounding_specificity_rationale": "The reviewer's first suggestion explicitly mentions 'section 2.3', providing strong grounding. The second suggestion mentions 'Figure 3', which is also a specific part of the paper. However, the second suggestion is more about identifying a lack of clarity rather than explicitly pointing to a specific element within the figure. Thus, the grounding is good but not perfect.", "verifiability_rationale": "Neither of the reviewer's suggestions contain explicit claims that require verification. The first suggestion is a recommendation, and the second is a critique leading to a request for clarification. Therefore, the reviewer's point is not verifiable.", "helpfulness_rationale": "The first suggestion is directly actionable and provides a concrete improvement. The second suggestion is a constructive critique that encourages the authors to clarify a point. Both suggestions are helpful in guiding the authors. Therefore, the reviewer's point is 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The review point does not explicitly state an action or suggestion for the authors. It raises a question about the necessity of a separate task and offers a potential reason based on the scalability of concept maps. While the underlying implications could lead to actions, the point itself lacks direct instructions on how to improve the draft.", "grounding_specificity_rationale": "The claim is somewhat general. It refers to 'concept map extraction' and 'node number' without specifying *which* concept maps or *how* the node numbers are increasing. It's also a bit vague in terms of the 'node number' \u2013 is it the number of nodes in the graph, or some other measure? The claim implies a general issue with concept maps and their scalability, but doesn't pinpoint a specific part of the paper being addressed.", "verifiability_rationale": "The claim 'Is it necessary to treat concept map extraction as a separate task?' is supported by the reasoning that 'many generic summarization systems build a similar knowledge graph and then generate summaries accordingly' and 'with the increase of the node number, the concept map becomes growing hard to distinguish.' These statements provide logical reasoning and a potential explanation for why a separate task might be needed. While it doesn't cite specific papers, the arguments are presented clearly and logically.", "helpfulness_rationale": "The review point raises a valid concern about the necessity of a separate concept map extraction task and provides a potential reason related to scalability. However, it primarily critiques the approach and doesn't offer concrete, actionable suggestions for the authors on how to address this issue or what alternative approaches they could consider. It raises a question but doesn't provide a clear path forward for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks for 'more about the traits of the experts' and 'justify why annotation must be carried out by the experts.' While not explicitly stating an action, the request directly points to an area where the authors need to take action (provide more detail and justification). The action isn't fully defined yet, making it 3.", "grounding_specificity_rationale": "The reviewer asks very specific questions about the experts' qualifications ('were the linguistic experts or domain experts?') and the annotation process ('did it introduce any linguistic challenges?'). This directly addresses the 'where' and 'how' of the information, indicating strong grounding. The questions are precise and target specific details.", "verifiability_rationale": "The reviewer states that annotation 'must be carried out by the experts, outside its commercial values.' This is a claim that needs justification. While the reviewer doesn't provide external references, the request itself is a logical step towards verifiability. The claim is supported by a logical reasoning (commercial values) but lacks specific examples or references, making it 3.", "helpfulness_rationale": "The reviewer's request for more detail about the experts and justification for expert annotation is generally helpful for the authors. It clarifies a process and its rationale, which can improve the quality and understanding of the annotation. While it doesn't directly fix a problem, it provides valuable information that can enhance the authors' understanding and potentially the validity of the annotation process."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point points to a specific location in the paper (lines 102106) and criticizes the writing style ('misleading'). While the reviewer identifies the area of concern, they do not specify what is misleading or how to address it. The criticism is general to the writing style in that area, lacking specific details on how to improve the clarity or precision.", "grounding_specificity_rationale": "The authors can identify the specific part of the paper being addressed (lines 102106). However, the reviewer does not explicitly detail what is misleading about the discussion in that specific part. The criticism is general to the writing style in that area, lacking specific details on what needs to be addressed within that section.", "verifiability_rationale": "The reviewer states 'such distribution' cannot refer to the discussion in the above. This is a claim that there is a disconnect between the concept of 'distribution' and the preceding discussion. The reviewer does not provide any evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up this assertion.", "helpfulness_rationale": "The reviewer points out a potential issue with the writing style ('misleading'). While they identify a problem, they do not offer any suggestions or propose a solution. The comment is diagnostic rather than prescriptive, failing to provide actionable feedback that would empower the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests including examples but doesn't specify how to create them or where to find information about this feature. It lacks concrete actions or methods.", "grounding_specificity_rationale": "The comment refers to 'the system' and 'actual texts' generally, without specifying which part of the paper or where these texts are located. The reference is broad and lacks specificity.", "verifiability_rationale": "The review point is a suggestion for improvement, not a declarative statement that makes a claim about the system or the paper. It doesn't present a judgment or assertion about the current state of the system or the need for examples.", "helpfulness_rationale": "The review point suggests a valuable improvement (including examples), but it's very general and lacks specific details. It doesn't pinpoint where these examples should come from or how the comparison to 'other components & models' would be done. This makes it less helpful than it could be."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that 'A number of claims from this paper would benefit from more indepth analysis.' This clearly indicates an intended action: to analyze the claims more thoroughly. However, the comment does not provide specific guidance on *how* to perform this analysis. The reviewer suggests a direction for improvement but leaves the implementation details open. Therefore, while the action is explicit, the lack of concrete steps makes it 3.", "grounding_specificity_rationale": "The comment states 'A number of claims from this paper would benefit from more indepth analysis.' While it identifies the *type* of analysis (more indepth analysis), it does not specify *which* claims are benefiting from this analysis. The reviewer is referring to 'claims' in general, not a specific section, table, figure, or unique element of the paper. Therefore, the grounding is weak as it does not pinpoint the exact location of the claims being analyzed. It is underspecific because it does not identify the nature of the problem with the claims or suggest a specific way to address them.", "verifiability_rationale": "The review point does not contain a claim in the sense of an opinion or judgment that requires verification. It is a suggestion for improvement: 'A number of claims from this paper would benefit from more indepth analysis.' There are no explicit references to external knowledge, logical reasoning, or specific examples provided within this statement. The reviewer is making a recommendation, not stating a verifiable fact. Therefore, according to the provided definitions, this comment does not contain a claim that needs to be supported.", "helpfulness_rationale": "The review point identifies a valid area for improvement: suggesting more indepth analysis of claims. However, it lacks specific guidance on *how* to achieve this. The reviewer suggests a direction for improvement but does not provide concrete steps or criteria for what constitutes 'more indepth analysis.' This vagueness limits the potential impact of the suggestion on the author. While the point points out a need, the lack of actionable steps makes it less helpful than a more specific suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer raises two distinct questions: (1) about the pooling method for embedding features and (2) about the definition and role of E_i in equation (7). Both questions directly point to specific areas where the authors could benefit from clarification and improvement. The reviewer explicitly states the desire for improvement in the presentation of the model, indicating a clear action the authors should take. The questions are direct and require the authors to identify and address specific issues or areas of confusion.", "grounding_specificity_rationale": "The reviewer explicitly asks about the pooling method for embedding features (line 397) and the definition of E_i in equation (7) (line 472). These are specific requests that directly target particular aspects of the paper. The mention of 'line 397' and 'equation (7) in line 472' indicates a clear understanding of the location of the relevant information within the paper. The reviewer is asking the authors to identify specific areas that need clarification or improvement.", "verifiability_rationale": "The reviewer asks for clarification on the pooling method for embedding features and the definition of E_i in equation (7). These are requests for information that, if provided, would directly address the authors' needs. While the reviewer doesn't explicitly state that the pooling method is incorrect or that E_i is not welldefined, the questions themselves act as implicit verifications: 'Is the pooling method correct?' and 'What does E_i represent?' These are questions that require the authors to engage with the paper and identify potential areas for improvement.", "helpfulness_rationale": "The reviewer's questions directly address areas where the authors could benefit from clarification and improvement. The request for information about the pooling method and the definition of E_i are both actionable and would directly impact the authors' understanding and implementation of the model. The reviewer's desire for improvement in the presentation of the model makes these requests highly valuable and helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper 'does not really study these hypotheses' (lines 078086). This is a clear and direct statement of a gap in the paper's content. The reviewer identifies the *area* of the hypotheses as the issue, which is an explicit action the authors should take. While the reviewer doesn't specify *how* to study them, the act of identifying the missing study is actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions the hypotheses in lines 078086, providing a clear grounding of the issue. While the reviewer doesn't pinpoint a specific *part* of those hypotheses that needs more study, the reference to the section where the hypotheses are stated demonstrates a degree of grounding. The reviewer identifies the *area* of the hypotheses as the problem, which is a specific enough reference to guide the authors.", "verifiability_rationale": "The reviewer makes a clear claim: 'the paper actually does not really study these hypotheses (nor are they even mentioned/discussed again).' This claim is directly supported by the paper's structure and content. The hypotheses are stated in lines 078086, and there's no further discussion or analysis of them. The reviewer provides a logical reasoning to support their claim, making it 5.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors: 'I would have also liked the paper to go deeper into the respective topics, at least to some extent.' This is a helpful suggestion because it directly points to a specific area for improvement. The reviewer doesn't criticize the *methodology* of studying the hypotheses but rather encourages *more* study. This actionable feedback is 5 to the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3 (3)", "grounding_specificity_label": "3 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer desires an action (learning how the CS is used), but the comment doesn't provide it.", "grounding_specificity_rationale": "The comment doesn't explicitly identify the *specific* part being addressed (the data split).", "verifiability_rationale": "The paper doesn't explicitly state the data split used for the CS, making the reviewer's question unanswerable based on the provided information.", "helpfulness_rationale": "The reviewer expresses uncertainty about the explanation, indicating the comment isn't entirely clear or helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states their opinion about the substructure representation and the appropriateness of the term \"knowledge.\" They also provide a specific alternative ('sequence of words,\" \"constituent parse\"). This clearly indicates an actionable suggestion for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"the substructure has to be represented as a sequence of words\" and provides an example (\"constituent parse\"). This clearly identifies the specific part of the paper being addressed and offers a concrete alternative, demonstrating strong grounding specificity.", "verifiability_rationale": "The reviewer states a claim about the paper's terminology (\"knowledge\") and provides a logical argument against using it, suggesting a sequence of words or constituent parse. While they don't provide external references, their reasoning is clear and logical, making it 3.", "helpfulness_rationale": "The reviewer's comment directly challenges a key claim of the paper (\"the model claims the model generalizes to different knowledge\"). They propose an alternative interpretation and suggest a more precise term. This is likely to be helpful for the authors in refining their terminology and understanding the scope of their model's generalization capabilities. The suggestion to consider 'syntax\" or 'semantics\" (if AMR is used) is also a valuable point for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'The relatively poor performance on nouns makes me uneasy' and 'the fact that the oracle GAP for PPDBClus is higher than most clustering approaches is disconcerting'. These statements directly identify an issue and indicate the reviewer's intention to investigate it. The reviewer also asks a question ('I would like to understand the gap better'), which further encourages the authors to take action. The reviewer points to a specific part of the paper (nouns) and a specific dataset (PPDBClus) as the area of concern, making the action quite explicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'nouns' as the area of concern and 'PPDBClus' as the dataset where the performance is particularly high. This direct identification of the specific part of the paper and the specific result makes the grounding very clear and precise. The reviewer also asks a question ('I would like to understand the gap better') which directly relates to the identified issue, further emphasizing the grounding of the comment.", "verifiability_rationale": "The reviewer states a concern: 'the fact that the oracle GAP for PPDBClus is higher than most clustering approaches is disconcerting'. This is a claim that needs to be verified. However, the reviewer does not provide any specific evidence or justification for why this is a significant issue or how it relates to the general claim about clustering approaches being generalizable to all parts of speech. The statement is presented as a question ('I would like to understand the gap better') rather than a definitive claim requiring evidence. While the concern is valid, the lack of supporting evidence makes the verifiability somewhat limited.", "helpfulness_rationale": "The reviewer's comment directly points out a specific weakness ('poor performance on nouns') and asks a question ('I would like to understand the gap better') that encourages the authors to investigate this issue. This is a valuable piece of feedback that directly addresses a specific problem. The reviewer's comment is clear, concise, and directly actionable for the authors. The authors are explicitly told where to look and what to investigate. The comment is not vague or general, making it 5 in guiding the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they need 'examples of spurious structures' to understand the discussion in section 5.2. This is a direct and specific request for action, indicating a clear need for concrete guidance. The request is not vague or inferred, making it 5.", "grounding_specificity_rationale": "The reviewer asks for 'examples of spurious structures' without explicitly stating which part of their paper this relates to. While they mention section 5.2, the core request is about clarifying the concept of spurious structures through examples. They are not pointing to a specific section *within their own paper* and then asking for an example of something within that section. Therefore, it's not fully grounded. However, the request is quite specific about the type of example needed.", "verifiability_rationale": "The reviewer states that the discussion in section 5.2 is 'so abstract that I don't get the insights why the new model is better than MH'. This is a claim about the lack of clarity and the need for examples. While the reviewer might have *read* the section, they are stating that it was not helpful for them. They are not providing external references to support their claim about the abstractness of the discussion within their own paper. Therefore, it is not 5. However, the claim is clear and directly related to the lack of information, making it 3.", "helpfulness_rationale": "The reviewer directly suggests improving the discussion in section 5.2 by providing 'examples of spurious structures'. This is a very specific and actionable suggestion that directly addresses a stated weakness. The reviewer is not just pointing out a problem; they are offering a concrete solution. This makes the suggestion 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a clear and explicit description of the baseline they are proposing. They state the goal is to add a baseline smaller PCFG and detail the method of creating it by parameterizing matrices of specific dimensions. The use of 'under this setting' indicates a clear understanding of the context and the purpose of the suggestion. The reviewer explicitly states the potential impact on parsing F1 and perplexity, making the action quite direct.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'parsing F1' and 'perplexity' as the metrics affected by the proposed baseline. They also explain how the smaller PCFGs can be used to evaluate the 'impact of PCFG size on parsing performance'. The mention of 'parameterized as learned matrices' provides specific details about the construction of the smaller PCFGs. The reviewer's statement that 'parsing F1 might not be directly comparable, but perplexity can still be compared' shows a clear grounding in the relevant metrics and the goal of the suggestion.", "verifiability_rationale": "The reviewer makes a claim about the proposed baseline 'can help evaluate the impact of PCFG size on parsing performance'. They provide a rationale for this claim by explaining that the smaller PCFGs can be used to observe the impact on parsing metrics like F1 and perplexity. The reviewer also specifies the type of PCFGs being created ('smaller PCFG with state size being r, but where H, I, J, K, L are directly parameterized as learned matrices of specific dimensions'). This provides the necessary information to understand and verify the claim.", "helpfulness_rationale": "The reviewer's suggestion is clear, relevant, and directly addresses the problem of comparing parsing performance across different PCFG sizes. The suggestion is specific about the type of baseline to create and the metrics to consider. The reviewer explicitly states the potential impact on parsing F1 and perplexity, making the suggestion constructive and actionable. The reviewer's statement that 'this baseline can help evaluate the impact of PCFG size on parsing performance' is a clear and verifiable claim based on the proposed method."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the suggestion and provides concrete details on what needs to be added (maximum number) and where it should be added (in the table). The action is directly identifiable and the method of implementation is clear.", "grounding_specificity_rationale": "The reviewer implies the table being referred to, as they are suggesting an improvement *to* the table. However, they do not explicitly name the table, section, or figure. The information provided is sufficient to infer the relevant part of the paper.", "verifiability_rationale": "The reviewer makes a claim by suggesting an improvement to the table. This claim is 3 because the reviewer can check the table themselves to see if this information is already present. While the reviewer doesn't provide external references, the suggestion is based on their own understanding of the table's content.", "helpfulness_rationale": "The reviewer provides a specific and actionable suggestion for improving the table. This directly addresses a potential area of weakness (if the table is missing this information) and provides a clear direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that they found it difficult to understand the 'whole picture' and how the 'different pieces of the puzzle' fit together. They suggest that the authors should clarify the connection between the experiments and the research question/hypothesis. This is an explicit action that is also concrete, as the reviewer clearly identifies the missing link.", "grounding_specificity_rationale": "The reviewer identifies a specific area of confusion for the authors: the connection between the experiments and the research question/hypothesis. They ask about the 'overall picture' and how the 'different pieces of the puzzle' fit together. This directly points to a specific section or aspect of the paper, making the grounding explicit. Furthermore, the reviewer specifies *what* is unclear, making the specificity high.", "verifiability_rationale": "The reviewer states that it was 'difficult to get the whole picture' which is a claim that needs to be addressed. While the reviewer doesn't provide specific evidence *why* it's difficult, their suggestion to clarify the connection between experiments and the research question is a direct suggestion for improvement. The lack of clarity itself is a verifiable issue that the reviewer is pointing out.", "helpfulness_rationale": "The reviewer's comment directly addresses a need for the authors to better understand the connection between their experiments and their research question. Their suggestion to clarify this connection is a clear and actionable piece of feedback. This directly helps the authors improve their paper by making the research question and experimental results more cohesive and understandable."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests a concrete action: including a 'hard prompt baseline' in Table 1. However, it does not provide specific details on *how* to implement this baseline or what specific aspects of the methods this baseline is intended to highlight. The action is implied but not explicitly stated with sufficient detail.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper being addressed. It is a general suggestion about improving Table 1. Therefore, the grounding is weak as the authors cannot pinpoint the exact location or aspect of the paper the comment refers to.", "verifiability_rationale": "The comment suggests including a 'hard prompt baseline' but does not provide any justification or reasoning for why this would be beneficial or how it would be implemented. There are no references to external works or logical reasoning provided.", "helpfulness_rationale": "The comment suggests a potential improvement to Table 1 by including a 'hard prompt baseline'. While this could be helpful for authors to understand performance gains, the suggestion lacks specificity and lacks a clear explanation of *why* this baseline is important or how it would be implemented. The lack of detail makes it less helpful as a concrete piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the 'lack of numerical results' as a problem, which is a direct identification of an issue. However, the reviewer does not explicitly state how to apply the work to popular algorithms or compare their performance with existing DP algorithms. The suggestion is implied but not explicitly stated as an action to be taken.", "grounding_specificity_rationale": "The reviewer mentions 'numerical results' and 'algorithms' as areas where more information is needed. However, the reviewer does not specify the *nature* of the numerical results (e.g., specific metrics, datasets) or the *specific* popular algorithms to be considered. The suggestion to compare with existing DP algorithms is also a general direction.", "verifiability_rationale": "The reviewer identifies a 'lack of numerical results' as a problem and suggests 'applying it to some popular algorithms and their performance compared with existing DP algorithms' as a way to address it. This is a clear claim with a suggested method, making it 3.", "helpfulness_rationale": "The reviewer points out a significant omission ('lack of numerical results') and provides a concrete suggestion ('apply it to some popular algorithms and their performance compared with existing DP algorithms') to improve the work. This is a clear and actionable feedback that directly addresses a practical concern."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer states \"I don't think the probabilistic connection is drawn very well.\" This is a statement of opinion about the quality of the connection, not a specific action the authors should take. The comment lacks explicit instructions or suggestions for improvement. It's a critique of the connection itself, not a call to action regarding it.", "grounding_specificity_rationale": "The reviewer refers to \"the probabilistic connection,\" which is a specific part of the paper. However, the comment itself is a general statement about the connection being 'drawn very well' and lacks specific details about what is wrong with it or how it should be improved. The grounding is present in identifying the section, but the specificity is limited to the critique of the connection without concrete suggestions.", "verifiability_rationale": "The review point is a statement of opinion: \"I don't think the probabilistic connection is drawn very well.\" This is not a claim that requires verification or justification. It's an expression of concern, not a proposition that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer's comment is a critique of the probabilistic connection. While it points out a potential issue, it does not offer any specific actions or suggestions for improvement. The helpfulness is limited because the comment identifies a problem but doesn't provide a solution or direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'It would be good to show some empirical evidence...'. This is an explicit action suggesting the authors should add empirical evidence. However, the specifics of *where* to find this evidence or *what* kind of evidence is not detailed, making it somewhat vague.", "grounding_specificity_rationale": "The review point mentions 'the third contribution of the paper' and 'the Column Subset Selection problem'. This indicates the reviewer can identify the specific part of the paper being addressed, making it fully grounded. Furthermore, the suggestion is specific to the 'Column Subset Selection problem', adding to the specificity.", "verifiability_rationale": "The review point is a suggestion for *new* empirical evidence, not a claim that the paper is flawed or needs correction. There is no logical reasoning, common knowledge, or external references provided to *support* the suggestion itself. It's a request for future work, not a critique that needs verification.", "helpfulness_rationale": "The review point identifies a gap in the paper (lack of empirical evidence for a contribution) and suggests a concrete way to address it (adding empirical evidence). While it doesn't *do* the empirical work, it points towards a logical next step for improvement. It's a constructive suggestion aimed at improving the paper."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment implies an action (the applicability of the robust training scheme might not scale) but doesn't explicitly state what needs to be done or how to implement it.", "grounding_specificity_rationale": "The comment explicitly mentions 'practical datasets' and 'highdimensional domains', which are specific parts of a potential experimental setup or discussion. However, it doesn't specify *why* the accuracy would scale unfavorably in these areas.", "verifiability_rationale": "The comment contains a claim ('the applicability of the robust training scheme seems unlikely to scale') and provides a logical reasoning ('it seems like the accuracy would scale unfavorably unless the size of V scales exponentially with the dimension'). However, it lacks specific examples or external references to support this claim.", "helpfulness_rationale": "The review point is critical, highlighting a potential limitation of the proposed method. It prompts the authors to consider the scalability of their approach and the potential impact on practical datasets and highdimensional domains. This raises concerns and encourages further investigation, which is valuable feedback."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a gap in the study of style shifts but doesn't explicitly recommend a specific action or provide a concrete next step for the authors. They raise a question, which could be seen as an implicit action, but it's not very actionable.", "grounding_specificity_rationale": "The reviewer *identifies* a lack of clarity regarding the *nature* of style shifts within a 4year timeframe. They point to a missing element in the authors' analysis. This can be considered weak grounding as the authors cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part (the lack of clarity on style shifts).", "verifiability_rationale": "The reviewer makes a claim about the *insufficiency* of a 4year timeframe and the *lack of understanding* of style shifts. This claim could potentially be supported by examples or references, making it potentially verifiable. However, within the scope of *this* review point, there is no explicit verification provided.", "helpfulness_rationale": "The reviewer raises a crucial question about the validity of the authors' dataset analysis, which directly impacts the model's training and performance. This is a valuable point for the authors to consider. While it doesn't provide a direct solution, it prompts the authors to critically examine their methodology and potentially reevaluate their dataset or analysis approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the incorrect table (Table 3) and the issue with Figure 6's callout (it's not directing properly). This provides a clear target for the author and a concrete action to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific tables (Table 3 and Table 5) and the figure (Figure 6) and its callout. This indicates a high level of grounding as the author can directly identify the referenced parts. The comment specifies what needs to be addressed in these parts (the correct table for the callout and the issue with the figure callout).", "verifiability_rationale": "The reviewer makes a claim about the incorrect table and the issue with Figure 6's callout. While they don't provide explicit evidence or reasoning to *verify* these claims, they present a factual observation that the author can investigate. The lack of explicit verification makes it less than 5.", "helpfulness_rationale": "The reviewer points out specific errors in the tables and the figure callout. This directly informs the author's revisions and provides actionable feedback, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'comparisons with SketchRNN' as a suggestion for improvement, which is a concrete action. It directly tells the authors what they should do to enhance their draft.", "grounding_specificity_rationale": "The review point refers to 'the experiments' as the area needing improvement. While it doesn't pinpoint a specific subsection or table within the experiments, it clearly identifies the *type* of comparison (SketchRNN) that should be made. Therefore, it is '3' in identifying the *method* of comparison, but the 'grounding' is at the broader level of 'the experiments'. However, if we interpret 'grounding' as the specific element within the paper being referenced, it's not specific. If we interpret it as the *type* of comparison being suggested, it is specific. Given the prompt's focus on the paper being reviewed, it's more about the specificity of the *comparison* being suggested. Therefore, it's '3' in the *method* of comparison, but the prompt asks for 'grounding specificity' of the paper, which is broader. Let's consider 'grounding' as the specific element within the paper being referenced. In that case, it's '1' as the specific element isn't identified. However, if 'grounding' refers to the *type* of comparison, it's 'Specific'. Given the ambiguity, and considering the prompt's intent, it leans towards '3' as it specifies the *method* of comparison, even if the *specific element* within the experiments isn't pinpointed.", "verifiability_rationale": "The review point makes a claim by stating 'The paper reports only self comparisons' and 'In a generative setting comparisons with SketchRNN could be performed'. It provides a justification for the claim by suggesting a relevant baseline (SketchRNN) for comparison.", "helpfulness_rationale": "The review point is 5 as it directly addresses a clear weakness in the paper (lack of external comparisons) and provides a concrete suggestion for improvement (comparisons with SketchRNN). It guides the authors on what specific aspect to focus on and what baseline to use for comparison."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a disagreement with the authors' conclusion about the performance trends of ViTs and CNNs in Figure 3. It provides specific observations about the performance of different DeiT models on various datasets, indicating a clear intention to analyze and compare the results. The reviewer directly addresses a point made in the original paper, making the action clear and actionable.", "grounding_specificity_rationale": "The review point explicitly refers to 'Figure 3' and discusses the performance of 'DeiTB', 'DeiTT', 'DeiTS', and 'CNNs' on specific datasets ('APTS2019', 'ISIC2019', 'CheXpert'). This direct reference to a specific part of the paper and the discussion of performance on these datasets clearly identifies the issue being addressed and specifies what is being analyzed. The mention of 'almost consistent model improvements' further clarifies the nature of the observed differences.", "verifiability_rationale": "The review point contains a claim: 'I disagree with authors' viewpoint that 'Both CNNs and ViTs seem to benefit similarly from increased model capacity'. The reviewer then provides specific observations from Figure 3, such as 'DeiTB does not outperform DeiTT in APTOS2019' and 'DeiT models do not consistently outperform smaller DeiT models across all datasets'. These observations serve as evidence to support the claim that the performance gains are not similar for CNNs and ViTs. While the reasoning behind these observations could be more explicit, the claim is stated, and supporting data points are provided.", "helpfulness_rationale": "The review point provides specific observations about the performance of different models in Figure 3 and explicitly disagrees with the authors' interpretation. This suggests that the reviewer has identified a potential issue or area for further investigation in the original paper's analysis. While the point doesn't offer concrete suggestions for improvement, it highlights a discrepancy and provides data to support the reviewer's claim, making it a relevant and helpful feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a general issue ('several places may cause confusion') but does not specify which parts of the paper are problematic or how to address them. It lacks explicitness and concreteness, requiring the authors to infer the areas needing improvement.", "grounding_specificity_rationale": "The comment does not identify specific parts of the paper that are causing confusion. It uses the vague phrase 'several places,' indicating a lack of precision in pinpointing the problematic areas. Therefore, the grounding is weak as the authors cannot confidently determine the scope of the issue.", "verifiability_rationale": "The comment does not contain a claim that needs verification. It is a statement of observation about the clarity of the paper. Therefore, verifiability is not applicable, and the label is 'X'.", "helpfulness_rationale": "The comment identifies a valid issue ('several places may cause confusion') that authors would likely find helpful. While it doesn't specify the exact nature of the confusion or provide concrete solutions, it points to an area for improvement, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a fact, 'However, there is no corresponding set of tools for the reinforcement learning setting.' This is an explicit statement but lacks an implied action. The authors are not told what to do based on this statement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'tools for the reinforcement learning setting' as the specific area being addressed. This is a strong indication of good grounding.", "verifiability_rationale": "The reviewer makes a claim: 'However, there is no corresponding set of tools for the reinforcement learning setting.' This is a claim that could be supported by external references or by checking the paper's own description of tools. The *review point itself* doesn't contain supporting evidence within it.", "helpfulness_rationale": "The reviewer identifies a potential inconsistency in the paper by pointing out the absence of tools for the reinforcement learning setting, despite claiming this is false. This highlights a potential gap in the paper's description of available tools or a need for clarification. This information could be valuable for the authors to understand the state of the field and potentially identify relevant tools or areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states: \"The results, while mostly based on 'standard\" techniques, are not obvious a priori, and require a fair degree of technical competency (i.e., the techniques are really only 'standard\" to a small group of experts).\" While the reviewer points out a potential area for improvement (comparing the authors' work to 'standard\" techniques and noting the expert audience), they don't *specifically* suggest *how* to do this comparison or what aspects to focus on. The comparison itself is vague.", "grounding_specificity_rationale": "The review point discusses the general nature of the results and the level of technical competency required. It doesn't explicitly refer to any specific section, table, figure, or unique aspect of the paper. The comment is about the overall interpretation and audience for the results, not a specific flaw within a particular section.", "verifiability_rationale": "The review point contains a claim: \"The results, while mostly based on 'standard\" techniques, are not obvious a priori, and require a fair degree of technical competency (i.e., the techniques are really only 'standard\" to a small group of experts)\". The reviewer provides a definition of this claim: \"require a fair degree of technical competency (i.e., the techniques are really only 'standard\" to a small group of experts)\". This provides a reason *why* the results might not be immediately obvious. While it doesn't cite specific external references, it offers a logical explanation.", "helpfulness_rationale": "The review point identifies a potential weakness in the authors' work (that it relies heavily on techniques understood by a limited audience). It clearly states this potential issue. While it doesn't offer concrete *suggestions* on how to improve the work to broaden the audience, it highlights a *problem* that the authors might face. This can be helpful in prompting them to consider alternative approaches or clearer explanations."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need to distinguish between hard prompt updates and model updates, which is a clear and direct action. They also suggest citing specific papers as a way to clarify this distinction, further specifying the action.", "grounding_specificity_rationale": "The reviewer explicitly names the areas of confusion: 'hard prompt work updates the frozen model' and 'the frozen model'. This demonstrates strong grounding as the specific parts of the paper are identified. While the reviewer doesn't explain *why* these areas are confusing, they clearly pinpoint the relevant sections.", "verifiability_rationale": "The reviewer provides a claim by suggesting citing specific papers to clarify the distinction between hard prompt updates and model updates. This claim is 5 as the suggestion directly points to a concrete method for providing additional information and context.", "helpfulness_rationale": "The reviewer offers a clear and actionable suggestion for improving clarity by citing specific papers. This directly addresses a potential point of confusion for the authors and provides a concrete path for them to gain more information."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a potential issue with the experimental setup, specifically the difference in training data between the two systems. While it concludes that the direct model might be better despite this difference, it doesn't explicitly state what specific changes or improvements the authors should implement based on this finding. The actionable aspect lies in considering the impact of training data, but the exact steps are not prescribed.", "grounding_specificity_rationale": "The comment explicitly mentions 'the text disambiguation model' and 'the endtoend system', identifying the specific parts of the paper being discussed. It also refers to the 'difference between the two proposed systems', which points to a specific comparison within these systems. This demonstrates a clear identification of the relevant parts and their characteristics.", "verifiability_rationale": "The comment presents a claim that the direct model might be better despite the smaller training data difference. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a possibility based on intuition rather than verifiable evidence.", "helpfulness_rationale": "The comment raises a valid concern about the experimental setup and its potential impact on the conclusions. It highlights a potential flaw in the direct model's performance due to the data difference. While it doesn't directly tell the authors what to do, it points out a potential area for improvement and a factor to consider in future experiments, making it 3 in terms of guiding further research or discussion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the lack of motivation for GaRare and the need for a more detailed algorithmic presentation. However, it does not specify what the advantages of GaRare are over GaLore or how the algorithmic presentation will be improved. The action is implicit (the need for a more detailed presentation) but not explicitly stated in detail.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper being addressed regarding the motivation for GaRare. It makes a general statement about the lack of motivation. However, when discussing the algorithmic presentation, it mentions 'projected gradients,' which implicitly points to a specific concept. Therefore, the grounding is weak for the motivation but potentially stronger for the algorithmic part.", "verifiability_rationale": "The comment makes a claim about the lack of motivation for GaRare and the need for a more detailed algorithmic presentation. However, it does not provide any evidence or justification for these claims. The reasoning is purely based on the reviewer's observation, lacking external references or logical reasoning to support the criticism.", "helpfulness_rationale": "The comment identifies areas for improvement (lack of motivation and algorithmic detail) but does not offer any specific suggestions or guidance on how to address these issues. The feedback is present but lacks actionable steps, making it less helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the goal of conducting an ablation study on the VisDial dataset and specifically requests the performance of ATT(+H) without attention retrieval. This is a clear and direct action the authors should take. The request is also quite concrete, asking for a specific experiment to be performed.", "grounding_specificity_rationale": "The reviewer mentions 'visDial dataset' and 'ATT(+H)', which indicates they can identify the specific part of the paper being addressed. The request to conduct an ablation study and evaluate ATT(+H) without attention retrieval is also quite specific.", "verifiability_rationale": "The reviewer's underlying claim is that the paper lacks sufficient experimental validation, specifically regarding the contribution of attention retrieval. While the paper doesn't explicitly state this lack of validation, the reviewer's request implies a need for more evidence to support the importance of attention retrieval. The request itself provides a justification for the claim.", "helpfulness_rationale": "The reviewer provides a clear and specific request for an ablation study. They are asking for a concrete experiment to be performed to assess the impact of attention retrieval on the VisDial dataset. This directly addresses a potential weakness in the paper's experimental validation and provides a clear direction for the authors to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the names of the relevant works and highlights the key similarities between the proposed method and the Continuous Conditional Random Fields (CCRFs) and Continuous Conditional Neural Fields (CCNFs). The reviewer suggests that incorporating or discussing these related works would improve the paper's related work section and provide context. The action is explicit, and the details are concrete.", "grounding_specificity_rationale": "The review point explicitly mentions the names of the specific works, Ristovski 2013 and Baltrusaitis 2014, which directly correspond to the Continuous Conditional Random Fields and Continuous Conditional Neural Fields. This clearly identifies the specific part of the literature the reviewer is referring to, making the grounding fully grounded. The reviewer also specifies the relevance of these works based on their 'similar structure of the CRF' and 'ability to perform exact inference', adding specificity to the identified area.", "verifiability_rationale": "The review point contains a claim that the related work section should include a discussion of similar works on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. This claim is supported by the reviewer's statement that these works have a 'similar structure of the CRF' and an 'ability to perform exact inference', which are verifiable characteristics. While the review point itself doesn't cite external works to support these claims, the information provided is sufficient to verify the existence and relevance of these works.", "helpfulness_rationale": "The review point is 5 as it directly points out a specific area for improvement in the related work section of the paper being reviewed. The reviewer provides concrete examples of relevant works and their features, suggesting that incorporating or discussing these would enhance the paper's context and potentially enable exact inference. This is a clear and actionable suggestion for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides actionable information by asking specific questions about WPA's behavior and performance. It identifies the need to understand WPA's predictions with `np.ones` input, its ability to serve as a 'white paper' input, and why it performs better than Gaussian noise. These are concrete questions that the authors can directly address in their draft.", "grounding_specificity_rationale": "The review point is highly specific about the aspects of WPA being questioned. It directly asks about the input requirements (specifically `np.ones` and the concept of 'white paper' input) and the mechanism behind its performance compared to Gaussian noise. This strong focus on specific parts of the paper enhances grounding specificity.", "verifiability_rationale": "While the review point raises valid questions about the rationale behind certain choices (e.g., why `np.ones` is a good 'white paper' input and why Gaussian noise is a relevant comparison), it doesn't provide explicit justifications or references for these choices. The reviewer's questions highlight the need for clearer explanations and evidence within the paper to support these design decisions. The lack of explicit backing makes the claims somewhat underjustified.", "helpfulness_rationale": "The review point is highly relevant and addresses a gap in the paper. It asks insightful questions about the internal workings of WPA and its design choices, which are crucial for understanding its effectiveness and for inspiring future research. By highlighting this lack of insight, the review effectively points out an area where the paper could be significantly improved."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a similarity between the method and a specific related work. While this is an explicit statement, it lacks concrete details on how the method is similar to the cited work. The reviewer does not provide any suggestions or actions on how to address this similarity, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions a 'related work cited in the paper: Generating Adversarial Disturbances for Controller Verification'. This indicates a strong grounding as the reviewer can identify the specific part of the paper being addressed. However, the reviewer does not specify what aspects of the method are similar to this related work, making the specificity low.", "verifiability_rationale": "The reviewer states that 'It seems that the method part is very similar to the related work cited in the paper'. This is a claim that requires verification. However, the reviewer does not provide any logical reasoning, examples, or external references to support this claim. The statement is presented as an observation without further justification.", "helpfulness_rationale": "The reviewer's point about the similarity to related work is relevant and constructive for the authors. It highlights a potential area for improvement or a need for better differentiation. However, the reviewer does not offer any specific actions or suggestions to address this issue, making the overall impact on the authors' work somewhat limited."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer raises two main points: the fairness of comparing against other methods and the potential of the proposed technique to promote existing class incremental semantic segmentation methods. While these are valid concerns, the review point does not explicitly state what the authors should do based on these observations. The reviewer asks questions but doesn't provide concrete actions or suggestions for the authors.", "grounding_specificity_rationale": "The reviewer's comment is 1 in the specific aspects of the paper being discussed. While the comment raises concerns about the comparison and the potential impact, it does not explicitly identify which part of the paper is being referred to. The reviewer makes general statements about the comparison and the technique without pinpointing the exact section or table.", "verifiability_rationale": "The reviewer's comment is not verifiable as it does not contain a claim that can be supported by evidence. The reviewer raises concerns about the fairness of the comparison and the potential impact of the technique, but these are presented as questions and observations rather than statements that require justification. There is no logical reasoning, common knowledge, or external references provided to support these concerns.", "helpfulness_rationale": "The reviewer's comment is not helpful as it does not provide actionable feedback or insights for the authors. The reviewer raises concerns about the fairness of the comparison and the potential impact of the technique, but these are presented as questions and observations rather than specific suggestions or guidance on how to improve the paper. The reviewer's comments are more about potential negative societal impact and limitations of the work itself, rather than providing actionable feedback on how to improve the current submission."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies the missing information about the minimum cluster size and conductance threshold parameters and their impact on performance. While it points out a gap in the experimental section, it doesn't explicitly state how to set these parameters or provide concrete guidance on their adjustment. The suggestion is implicit, as it implies the need for this information but doesn't directly instruct the authors on how to obtain or use it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'minimum cluster size' and 'conductance threshold' by name, indicating a degree of grounding. However, the point only identifies the *existence* of these parameters and their *impact* on performance, lacking specific details on *how* they are set or *why* they are important. The grounding is present, but the specificity regarding the parameters themselves is limited.", "verifiability_rationale": "The reviewer states that the experimental section does not mention or discuss how the parameters are set and how sensitive the performance is with respect to these parameters. This is a factual statement about the missing information in the paper. The claim is that the paper lacks this information, and the verifiability is low because the reviewer is pointing out a factual gap without providing evidence or justification for why this is a problem.", "helpfulness_rationale": "The review point highlights a factual omission in the paper: the absence of information regarding the setting of key parameters and their impact on performance. While this omission could potentially lead to confusion or difficulties for the authors attempting to reproduce or understand the work, the review point itself does not offer any suggestions or guidance on how to address this gap. It points out a problem but doesn't provide a solution or direction for the authors."}
{"actionability_label": "borderline actionability", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential area for improvement (Section 4 being terse) but does not explicitly state the action to be taken. While it suggests 'slower development,' it lacks specific details on how to achieve this. Therefore, it is 2.", "grounding_specificity_rationale": "The review point explicitly names Section 4 and states that it is 'very tersely written.' This clearly identifies the specific part of the paper being addressed. Therefore, it is 5.", "verifiability_rationale": "The review point makes a claim about Section 4 being 'very tersely written' but does not provide specific evidence to support this claim. Therefore, it is 3.", "helpfulness_rationale": "The review point identifies a potential improvement area (Section 4) and suggests a way to improve it (slower development), making it a relevant suggestion. Therefore, it is 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states a potential weakness (reinforcement learning might be less dataefficient for static VQA) but does not specify how to address it or what part of the approach needs adjustment. The suggestion is vague and lacks concrete steps.", "grounding_specificity_rationale": "The reviewer criticizes the approach in general, not a specific section, table, figure, or detail within the paper. The connection to the paper's content is implied but not explicit.", "verifiability_rationale": "The reviewer states a potential weakness (reinforcement learning might be less dataefficient for static VQA) but does not provide any specific evidence or reasoning *within the review point itself*. They are making an assumption about the data efficiency of RL for static VQA tasks.", "helpfulness_rationale": "The reviewer raises a concern about the approach but does not offer any concrete suggestions or point to specific flaws in the paper's methodology. The feedback is speculative and lacks actionable steps for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential issue with the assessment of reasoning ability due to the missing information on video length distribution. While it doesn't explicitly state how to improve the draft, it points to a specific area that needs attention. The action is implicit  the reviewer suggests the authors should be aware of this potential issue and consider the video length distribution when evaluating reasoning. However, the reviewer doesn't provide specific steps on how to improve the draft based on this observation.", "grounding_specificity_rationale": "The review point explicitly mentions 'video length distribution within the benchmark' and '11 categories'. It accurately identifies the specific aspect of the paper being discussed. This can be considered fully grounded as the reviewer clearly pinpoints the relevant section and elements.", "verifiability_rationale": "The review point makes a claim that the distribution of video lengths is crucial for the assessment of reasoning ability and robustness. It provides a reason for this claim by stating that the paper does not provide relevant explanations. While it doesn't offer specific external references, the reasoning about the impact of video length on reasoning ability is generally accepted knowledge within the field of video understanding and reasoning. The claim is supported by logical reasoning and the implication of a lack of explanation in the paper.", "helpfulness_rationale": "The review point identifies a specific issue related to the dataset description and its potential impact on the assessment of reasoning ability. It points to a concrete area where the authors might need to make adjustments or considerations. While it doesn't directly instruct the authors on how to improve their draft, it highlights a potential weakness that could affect their work. The feedback is relevant and points to a specific area for the authors to investigate or adjust their evaluation process. The helpfulness is moderate as it doesn't provide direct actionable steps but highlights a potential problem."}
{"actionability_label": "3", "grounding_specificity_label": "2: Weakly Grounded and Explicit", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for a clarification on a specific implementation detail (the bilinear layer) and how it differs from other approaches. This is a direct request for information that could be considered an implicit action. The reviewer is not explicitly stating how to apply this information to improve the draft, but rather seeking understanding of an existing component.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'bilinear layer' and 'other approaches,' indicating a clear identification of the specific part of the paper being addressed. However, the reviewer does not specify *where* in the paper this is discussed or what specific issue is being addressed beyond the difference from other methods. The request is for clarification rather than a direct instruction on how to apply this knowledge.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking for clarification on how something was implemented. There is no assertion of correctness or improvement needed based on this review point.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific implementation detail. While this can be helpful for the authors, it is not a direct suggestion of how to improve the draft. It's a request for understanding an existing component rather than a critique or a proposed change."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states a fact (the dataset isn't available) but doesn't instruct the author on what to do. There is no explicit action or suggestion for improvement.", "grounding_specificity_rationale": "The comment refers to 'the promised dataset' which is vague and doesn't pinpoint a specific section, table, figure, or unique element of the paper. The author cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The comment is a factual statement about the dataset's availability, not a claim that requires verification or justification.", "helpfulness_rationale": "The comment identifies a relevant limitation (the dataset not being available) but doesn't provide concrete guidance on how the author should address this gap or make specific changes to their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out the similarity of the proposed method to existing attentional modules and the connection to ResNeSt. While this identifies a potential weakness, it doesn't explicitly state what the authors should do to address this. The reviewer suggests the paper should discuss these connections, but doesn't provide specific, actionable steps on how to implement or improve the method based on this insight. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer mentions specific prior works 1, 2, 3 and ResNeSt 4 by name, indicating a clear identification of the referenced part of the paper (the existing attentional modules and ResNeSt). They also point out the structural similarity, which specifies the issue. However, the reviewer doesn't explicitly state the *specific* aspects of the proposed method that need improvement based on this grounding. The grounding is present, but the specificity of the suggestion is missing.", "verifiability_rationale": "The reviewer makes a claim about the limited novelty and similarity of the proposed method to existing work. This is a verifiable statement. However, the reviewer does not provide specific evidence or justification to support this claim. There are no references to external works or logical reasoning to back up the assertion of similarity. The claim is present, but the verifiability is lacking.", "helpfulness_rationale": "The reviewer's comment primarily identifies a weakness in the paper (limited novelty) but does not offer concrete, actionable advice on how to improve the method. While it points out a potential area for discussion, it doesn't provide specific steps or suggestions for the authors to follow. The comment is diagnostic rather than prescriptive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a logical consequence of the preactivation values being the same and suggests an alternative visualization. While they don't explicitly state an action to take, the suggestion is direct and implies a change in how the results are presented. The reviewer identifies the implication of equal preactivations and proposes an alternative visualization strategy.", "grounding_specificity_rationale": "The reviewer specifically refers to 'Fig. 3 e.' and discusses the cosine similarity of 'two networks with the same membrane potentials.' This indicates a clear identification of the specific part of the paper and a specific property being discussed. The reviewer is not making a general comment but rather focusing on a particular aspect of the results.", "verifiability_rationale": "The reviewer provides a logical explanation for why the cosine similarity would be high (due to equal preactivations) and poses a question about an alternative visualization of the 'latter loss term of Eqn 13'. This demonstrates a clear understanding of the underlying concepts and suggests a constructive improvement. The reviewer is not just stating an observation but also proposing a potential improvement in how the results are presented.", "helpfulness_rationale": "The reviewer's suggestion to directly illustrate the results of the 'latter loss term of Eqn 13' is a concrete and actionable suggestion. It directly addresses the observation about the high cosine similarity and proposes a specific way to improve the presentation of the results. This feedback is directly aimed at enhancing the authors' understanding and the clarity of their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the missing comparison with testtime adaptation (TTA) methods and clearly outlines the difference in approach (model parameter adjustment vs. input data processing). This provides a concrete and actionable suggestion for the authors to consider. The reviewer also asks for experimental justification, which is a direct request for action.", "grounding_specificity_rationale": "The reviewer mentions 'testtime adaptation (TTA) methods' by name, which indicates a level of grounding. They also explain the general goal of TTA (adapting to outofdistribution data) and the difference in approach (model parameters vs. input data). However, the reviewer does not specify the exact section or table where these methods are discussed or provide specific examples of TTA methods within the paper, making the grounding somewhat implicit.", "verifiability_rationale": "The reviewer poses a question about how to prove the superiority of data processing over model parameter adjustment. This constitutes a claim that requires justification. However, the reviewer does not provide any specific evidence, reasoning, or references to support this claim. The request for 'experimental results' highlights the lack of verifiable support for their assertion.", "helpfulness_rationale": "The reviewer identifies a potential area for improvement by highlighting the absence of a comparison with TTA methods. While the suggestion is valid, it primarily points out a gap in the paper rather than offering a direct solution. The request for 'experimental results' is a request for action, but the suggestion itself is more about identifying a problem than providing a concrete remedy."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the incorrect expression for J(\u03b8) and provides the correct expression, Q(s<sup>t</sup><sub>0</sub>, \u03c0<sub>\u03b8</sub>(s<sub>t</sub><sub>0</sub>)). They also indicate that the current expression is an expected value and the correct one is an actionvalue. This provides a clear and direct action for the authors to take.", "grounding_specificity_rationale": "The reviewer not only identifies the section (Section 3.2.1) but also specifies the exact formula and explains why the current expression is incorrect. They provide the correct formula, Q(s<sup>t</sup><sub>0</sub>, \u03c0<sub>\u03b8</sub>(s<sub>t</sub><sub>0</sub>)), and explicitly state that it should replace the current one. This level of detail and precision makes the grounding very clear.", "verifiability_rationale": "The reviewer makes a claim that the first expression for J(\u03b8) is incorrect and provides the correct formula, Q(s<sup>t</sup><sub>0</sub>, \u03c0<sub>\u03b8</sub>(s<sub>t</sub><sub>0</sub>)). While they don't provide a detailed proof of the mathematical equivalence, they offer a replacement that is generally accepted in the field (actionvalue vs. expected value). This provides a basis for the authors to potentially verify the correctness.", "helpfulness_rationale": "The reviewer directly points out an error in a specific section and provides the correct formula. This is a clear and actionable feedback that directly helps the authors improve their draft by correcting a specific mathematical expression."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states actions such as 'improving the paper' and lists specific actions like 'correcting capitalization errors in references'. The actions are clear and directly address the identified issues. The reviewer also mentions 'various words in many of the references need capitalization' and lists specific examples like 'ai' in Amodei et al. (2016), 'bayesian' in many papers, and 'Advances in neural information processing systems' in several papers. These are concrete actions with clear targets.", "grounding_specificity_rationale": "The reviewer mentions 'references' generally and points to specific pages (p.8 and p. 13) where capitalization errors might be located. However, they do not explicitly state which *part* of the paper (e.g., section, table, figure) contains these errors. While the pages are mentioned, the *specificity* of the section or table within those pages where the capitalization issues occur is not clearly identified. The reviewer also lists the *words* that need capitalization but doesn't specify *why* these are problematic or how they affect the paper.", "verifiability_rationale": "The reviewer states a claim: 'This paper needs to be revised to correct capitalization errors in references'. However, they do not provide any logical reasoning, common knowledge, or external references to support this claim. They simply state the problem exists without explaining *why* these errors are problematic or how correcting them would benefit the paper. They also list the specific words that need capitalization but do not provide any justification or evidence for why these are indeed errors.", "helpfulness_rationale": "The reviewer provides a list of actions to take, such as 'correcting capitalization errors in references'. While these actions are clear and actionable, the reviewer does not explain *why* these corrections are necessary or how they will improve the paper. The feedback is presented as a list of actions without any justification or reasoning behind them. The reviewer does not explain the impact of these errors on the paper's clarity, professionalism, or scientific rigor."}
{"actionability_label": "High", "grounding_specificity_label": "Weakly Grounded", "verifiability_label": "X", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states what information is missing: 'I didn't find all parameter values' and 'What are the model parameters for task 1? What lambda was chosen for the Boltzmann policy.' This indicates a lack of specific details. However, the reviewer also implies an action: 'But more importantly: How were the parameters chosen?' This suggests the reviewer desires to understand the methodology behind the parameter selection. The criticism is not just about missing information, but also about the lack of justification for the absence of this information. The reviewer's request for clarification on parameter selection points to a potential area for improvement in the paper's transparency and reproducibility.", "grounding_specificity_rationale": "The reviewer does not explicitly state which part of the paper is being addressed with the question 'What are the model parameters for task 1?'. While the context might suggest the reviewer is referring to the model parameters discussed in the paper, the specific section or table is not mentioned. Therefore, the grounding is weak. The reviewer also does not specify *what* is wrong with the parameters or the parameter selection process, making the grounding less specific.", "verifiability_rationale": "The reviewer's criticism is primarily about the *lack* of information and the *lack of justification* for that lack of information. While the reviewer identifies specific *parameters* (model parameters, lambda for Boltzmann policy), the *process* of choosing them is not described or justified. There is X being made, only a question about where to find information and how it was obtained. Therefore, this criticism does not fit the definition of a claim requiring verifiability.", "helpfulness_rationale": "The reviewer provides specific examples of what information is missing and *why* it would be helpful for the authors. They are asking for details about model parameters and the selection process, which are directly relevant to understanding and potentially reproducing the work. The criticism is not about the truth of a statement, but about the *lack* of information and the *lack of justification* for that lack. While the *information* itself might be verifiable elsewhere, the *review itself* points out a concrete gap in the paper's clarity and completeness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points to a potential weakness in the authors' approach by suggesting the strong performance might stem from the first step. While it raises a valid concern, it doesn't explicitly state what the authors should do to address this. The reviewer implies a need to investigate the first step further but doesn't provide concrete, actionable steps. The suggestion is more of a question or a pointer to an area of concern rather than a direct instruction on how to improve the draft.", "grounding_specificity_rationale": "The reviewer refers to the authors' claim about 'stateoftheart results' and their 'first step'. While this points to a general aspect of their work, it doesn't specifically identify a particular section, table, figure, or unique element of the paper that needs improvement. The reference is more general and doesn't pinpoint a concrete location within the authors' submission.", "verifiability_rationale": "The review contains a claim: 'the authors claim to achieve stateoftheart results on challenging scene text recognition tasks, even outperforms the deeplearning based approaches, which is not convincing.' However, this claim is not supported by any evidence or logical reasoning within the review point. There are no references to external works, data, or specific examples to back up the authors' performance claims. The reviewer states the claim but doesn't provide any justification or supporting evidence.", "helpfulness_rationale": "The review raises a valid concern about the authors' claim of achieving stateoftheart results and suggests that the performance might be due to the first step. While it doesn't provide direct solutions, it points to a crucial area for further investigation and challenges the authors' confidence in their findings. By highlighting this potential issue, the review encourages the authors to be more critical of their results and potentially conduct additional experiments or analyses. Although it doesn't offer explicit instructions, it prompts a valuable reflection and potential improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a question about the performance of the model with a specific architectural change. While the reviewer points out the performance difference, they don't explicitly state what action the authors should take or how to address the issue. The authors would need to infer the potential problem and seek clarification or further investigation. Therefore, it is 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 2' and the specific layers (2, 3, and 4) when describing the experiment. This clearly identifies the specific part of the paper being addressed. However, the reviewer does not specify *why* the performance deteriorates. They are stating a fact (performance difference) but not explaining the underlying cause. Therefore, it is 2.", "verifiability_rationale": "The reviewer is making a claim about the performance of the model under a specific condition ('Table 2, applying Conditional Batch Norm to layer 2 in addition to layers 3 and 4 deteriorates performance for GuessWhat?! compared to when CBN is applied to layers 4 and 3 only'). However, the reviewer does not provide any reasoning, common knowledge, or external references to support this claim. The claim is presented as a statement without justification. Therefore, it is 1.", "helpfulness_rationale": "The reviewer is pointing out a performance issue with a specific architectural modification. This is a common type of feedback that can be helpful for authors, as it highlights a potential problem and encourages them to investigate further. While the review doesn't offer a solution, identifying a weakness is a valuable piece of information. Therefore, it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the 'lack of comparison with a highly relevant method' and suggests 'including the method comparison or its ensemble strategies'. This is an explicit action with concrete details about the method and its components (intertask ensemble, intratask ensemble).", "grounding_specificity_rationale": "The reviewer explicitly mentions a 'highly relevant method' and its specific components ('intertask ensemble', 'intratask ensemble'). This clearly grounds the suggestion to a specific part of the paper and a specific issue.", "verifiability_rationale": "The reviewer makes a claim that 'the lack of comparison with a highly relevant method is a problem' but does not provide any logical reasoning, common knowledge, or external references to support this claim. The justification is based on the *what* (lack of comparison) rather than the *why*.", "helpfulness_rationale": "The reviewer identifies a specific area for improvement ('lack of comparison') and suggests a concrete action ('include the method comparison or its ensemble strategies'). However, they do not provide any guidance on *how* to perform this comparison (e.g., which datasets, metrics, specific aspects to compare)."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point asks for clarification, which is an implicit action. However, it doesn't specify what needs clarification, making it vague and not fully actionable. To be actionable, it should explicitly state the action and provide details on how to apply it.", "grounding_specificity_rationale": "The review point mentions 'Witness oracle' without specifying which part of the paper it refers to. This lack of identification makes the comment weakly grounded. Additionally, it doesn't detail what is wrong with the Witness oracle, so it is not specific.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It is a request for clarification, which falls under the 'X' category.", "helpfulness_rationale": "The review point is a request for clarification, which, on its own, does not directly improve the draft. It lacks specificity and doesn't identify any potential weaknesses or suggest concrete actions. Therefore, it is not helpful in its current form."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a limitation of the proposed method (handling headpose) and suggests an alternative approach (conditioning headpose like Gafni et al.). They ask 'why' this is not possible. While the reviewer identifies a potential issue, the suggestion to condition headpose is presented as a possibility, not a direct criticism of what the method *should* do. The 'why' part of the question implies a desire for clarification rather than a direct actionable point.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed method' and 'headpose' when discussing the limitation. They also specify the *potential* solution (conditioning headpose like Gafni et al.). This indicates a clear identification of the specific aspect of the paper being addressed and the nature of the issue.", "verifiability_rationale": "The reviewer states that the proposed method cannot handle headpose and suggests a similar technique was used in another work. However, they do not provide any evidence or justification within this review point to support the claim that the proposed method *cannot* handle headpose. The suggestion is presented as a possibility, not a definitive limitation of the method itself.", "helpfulness_rationale": "The reviewer points out a limitation of the proposed method and asks a question about it. While this can be helpful in identifying areas for improvement, the lack of verifiable evidence within the review point makes it difficult for the authors to definitively understand the issue or how to address it. The question is somewhat openended, as it doesn't provide a clear path forward or a definitive answer."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue with the spurious features and suggests investigating their similarity to backdoor triggers. While the reviewer identifies a problem, they do not explicitly state the exact action the authors should take to address it. The suggestion is more of an observation and a direction for further analysis rather than a direct instruction on how to modify the model or data.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3.1 and 3.2,' which clearly identifies the specific part of the paper being addressed. This demonstrates strong grounding as the reviewer can accurately pinpoint the section being discussed.", "verifiability_rationale": "The reviewer makes a claim about the impact of spurious features on the model, stating that 'It is wellknown that a few training examples with such triggers (rare spurious examples in this paper) would have a large impact on the trained model.' This claim is supported by the reviewer's knowledge and the examples provided (Chen et al. (2017), Gu et al. (2019)). While not a direct citation in the review point, the context and the established knowledge in the field make this claim verifiable.", "helpfulness_rationale": "The reviewer provides a clear explanation of a potential issue and suggests a direction for investigation. By pointing out the similarity to known harmful patterns, the reviewer provides valuable context and encourages the authors to explore the impact of these spurious features. This feedback is helpful as it highlights a potential problem and guides the authors towards further analysis."}
{"actionability_label": "3", "grounding_specificity_label": "1: 2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the optimization algorithm is 'directly from some previous works'. This is a clear and direct statement of what they believe, making it explicit. However, the reviewer does not specify *which* previous works or *how* it's directly taken from them, making it less concrete.", "grounding_specificity_rationale": "The reviewer mentions 'optimization algorithm' in the context of the structural optimization component. However, they do not explicitly identify the specific part of the paper where this information is relevant. They do not mention a particular section, table, figure, or unique aspect of the paper where this information is pertinent. Therefore, the grounding is weak. While the reviewer identifies a potential issue, they do not specify *what* needs to be addressed in this part.", "verifiability_rationale": "The reviewer makes a claim that the optimization algorithm is 'directly from some previous works'. However, they do not provide any evidence, citations, or logical reasoning to support this claim. The statement is presented as a statement of belief rather than a wellsupported assertion. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer's point about the algorithm's origin impacting the contribution is a valid concern for the authors. It highlights a potential weakness in the work's novelty. While the reviewer's point is clear and directly addresses a potential issue, framing it as a question about contribution might be slightly less helpful than a direct suggestion for improvement. The reviewer identifies a problem, but the presentation could be more actionable."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the 'pipeline style method including two models' does not give better average results for both XVNLI and MaRVL. This directly points to a specific area of the method that needs improvement. The reviewer suggests that the authors should investigate the performance of this specific pipeline on these datasets.", "grounding_specificity_rationale": "The reviewer mentions 'pipeline style method including two models' as the basis for the criticism. While this identifies a general methodological aspect, it doesn't pinpoint the exact section, table, or unique element within the paper where this method is described. The reviewer can infer the relevant part but cannot precisely identify it.", "verifiability_rationale": "The reviewer states that the 'pipeline style method including two models' does not give better average results for both XVNLI and MaRVL. However, the reviewer does not provide any logical reasoning, examples, or references to support this claim. The statement is presented as an observation without further justification.", "helpfulness_rationale": "The review identifies a potential issue with a specific experimental setup ('pipeline style method including two models') and suggests investigating its performance on specific datasets (XVNLI and MaRVL). This provides a clear direction for the authors to take. However, the lack of grounding and verifiability means the authors do not know *why* this issue exists. The criticism of the baseline models' introduction is also vague and does not offer specific improvements, making the overall feedback less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests using a 'more sophisticated methodology' to address the issue of reproducing known results. While this indicates a desire for improvement, the review lacks specific details on how to implement this 'more sophisticated methodology'. Without concrete steps, the suggestion remains at a high level, making it somewhat general and lacking actionable details.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the 'coarse' (their description) methodology of passing a binary stance classifier over ChatGPT's output' as the problematic aspect. This clearly identifies a specific part of the methodology being criticized, making it grounded. However, the reviewer does not specify a particular section or table within the paper where this methodology is detailed, making it only weakly grounded as the exact location is not pinpointed.", "verifiability_rationale": "The reviewer states that the observation about bias reproduction has been made at each step of LLM evolution and criticizes the authors' 'coarse' methodology. This constitutes a claim that the authors' methodology is redundant given prior findings. The reviewer provides a logical reasoning (redundancy of finding) and a common knowledge aspect (the progression of bias observation in LLMs) to support this claim, making it verifiable.", "helpfulness_rationale": "The reviewer points out a valid concern regarding the authors' methodology and suggests a potential improvement by using a 'more sophisticated methodology'. While this is a relevant point, the suggestion is quite general and does not offer specific implementation details. Without concrete steps, it is difficult for the authors to directly apply this feedback, making it 3 but lacking the depth needed for significant improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that 'When discussing related work it is crucial to mention related work on modular networks for VQA such as A' and 'otherwise the introduction right now seems to paint a picture that no one does modular architectures for VQA.' This directly tells the authors what to do and why it's important. The action is explicit, and the details are concrete.", "grounding_specificity_rationale": "The review point explicitly mentions 'A' as a specific example of related work on modular networks for VQA and links this to the 'introduction' of the paper. This allows the authors to precisely identify the section and the specific type of related work being referred to.", "verifiability_rationale": "The review point makes a claim: 'When discussing related work it is crucial to mention related work on modular networks for VQA such as A'. It also provides a justification: 'otherwise the introduction right now seems to paint a picture that no one does modular architectures for VQA.' This justification is logical and points to a specific area for improvement in the introduction.", "helpfulness_rationale": "The review point is highly specific, telling the authors exactly what to do (mention related work on modular networks for VQA, specifically A) and where to do it (the introduction). It also explains why this is important (the introduction seems to misrepresent the use of modular architectures). This makes the feedback actionable and directly addresses a potential issue."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the authors' focus on SSC and suggests a comparison with other methods, indicating an implicit action: to contrast their method with TSC and greedy subspace clustering. While it doesn't explicitly say 'improve your introduction by including a discussion of TSC...', the implication is clear.", "grounding_specificity_rationale": "The comment explicitly mentions 'TSC' and 'greedy subspace clustering', which are specific methods. It also implies a comparison with these methods given the authors' focus on SSC. The authors can infer the need to discuss and compare their method with these specific techniques.", "verifiability_rationale": "The comment makes a claim about the authors' focus on SSC and provides information about the properties of TSC and greedy subspace clustering. It logically infers that a comparison with these methods would be beneficial. The properties of TSC and greedy subspace clustering serve as supporting evidence.", "helpfulness_rationale": "The comment points out a potential gap in the authors' discussion and suggests a relevant comparison. It highlights the relevance of TSC and greedy subspace clustering given the computational efficiency and similar guarantees. However, it doesn't explicitly tell the authors *how* to improve their method or where exactly in the paper they should make this comparison. The helpfulness is indirect, suggesting a direction for improvement rather than a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a specific area of confusion in the paper (the distinction between weak and semisupervised training) and proposes a concrete solution (clearer column names and structure in Table 1). While the reviewer doesn't explicitly state *how* to implement the solution, the suggestion is quite specific and actionable. The reviewer also points out that the current presentation in Table 1 is unclear, which is a concrete observation about the paper's content.", "grounding_specificity_rationale": "The reviewer explicitly states what information is missing (clarity on weak vs. semisupervised training) and how the authors can identify the missing part (by looking at Table 1 and the descriptions of the methods). The reviewer also suggests a specific way to ground the information (adding new columns to Table 1). This demonstrates a strong understanding of where the information should be and how to find it. The suggestion is quite specific and would likely make the information clear to the authors.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity in the paper regarding the training regimes. They then provide a method for verifying this claim (by examining Table 1 and the method descriptions). The reviewer also offers a solution (clearer column names and structure) which directly addresses the identified issue. The claim is verifiable through direct examination of the paper, and the proposed solution is also quite concrete.", "helpfulness_rationale": "The reviewer provides a clear and specific point of confusion for the authors. They directly address a potential ambiguity in the paper's description of the training process. The suggestions for improvement (clearer column names and structure) are actionable and would likely significantly enhance the authors' understanding of the proposed method. This makes the review point very helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states the perceived similarity to previous methods ('mostly good engineering') and the difficulty in differentiating the contribution ('seems hard to differentiate'). This constitutes an explicit action (identifying a weakness) but lacks specific details on how to address it, making it 3.", "grounding_specificity_rationale": "The reviewer names specific prior works (NCNet 6 and Sparse NCNet 21) and generally refers to the 'previous methods' and the 'contribution'. This grounds the comment by referencing specific parts of the paper. However, the reviewer also generally describes the weakness ('seems hard to differentiate') without pointing to a specific technical detail or experimental result where the similarity is evident, making it somewhat specific.", "verifiability_rationale": "The comment contains a claim ('Small contributions... mostly (good) engineering. And despite that it seems hard to differentiate it from its predecessors, as it performs very similarly in practice.') that the paper's contribution is small and lacks clear distinction from previous work. However, the reviewer does not provide any evidence or reasoning to support this claim. The statement is an opinion without backing, making it 1.", "helpfulness_rationale": "The reviewer expresses a negative sentiment about the paper's contribution, suggesting it's not a significant advancement. While they identify a potential weakness ('small contributions'), they don't offer any specific suggestions or analysis to address it. The comment is primarily a critique without actionable improvements, making it 2 in terms of providing concrete feedback for improvement. The lack of specific examples makes it difficult for the authors to act on this feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the characterization of semantic segmentation as a 'lowlevel cue' is incorrect and should be removed. This is a direct and actionable suggestion. The authors know exactly where in their paper (likely the section describing semantic segmentation) they need to make the change and what the correct characterization should be (likely 'highlevel' or 'pixelbased'). The action is clear: remove the incorrect statement and replace it with the correct one.", "grounding_specificity_rationale": "The review point directly refers to 'semantic segmentation' and its characterization as a 'lowlevel cue'. The terms are specific to the paper's content. The reviewer can confidently identify the section or concept being addressed. The grounding is explicit.", "verifiability_rationale": "The review point contains a claim: 'the statements about semantic segmentation being a lowlevel cue should be removed from the paper.' While the reviewer doesn't provide extensive justification *within the review point itself*, the statement itself implies a degree of verification. The reviewer understands the pixelbased nature of semantic segmentation categories and recognizes that 'lowlevel cue' is an inaccurate characterization. The evidence for this claim is implicit but present.", "helpfulness_rationale": "The review point is 5. It directly identifies a factual error in the paper (the characterization of semantic segmentation) and provides a clear, actionable suggestion for improvement (remove the incorrect statement). This directly guides the authors to a specific part of their paper and the exact change they need to make. The impact on the authors' work is clear and direct."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a discrepancy in the ablation experiment results and notes the absence of specific cases in the tables. While the reviewer identifies a problem, they do not explicitly suggest concrete actions or modifications the authors should make based on this observation. The action is implied but not stated directly.", "grounding_specificity_rationale": "The reviewer refers to 'the ablation experiment' and 'the two tables,' indicating that they are identifying a specific part of the paper where information is lacking. However, they do not specify *which* element within the tables is missing or what exactly is not listed. The grounding is present, but the specificity is limited to the general area.", "verifiability_rationale": "The reviewer makes a claim that 'the two tables do not list the cases where dependency tree and RL are not used.' This is a verifiable statement as it refers to the content of the tables. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support why this omission is problematic or what should be listed in those cases. The claim is stated, but the verification is missing.", "helpfulness_rationale": "The reviewer identifies a discrepancy in the ablation experiment results and points out the missing information in the tables. This observation highlights a potential issue for the authors. However, the reviewer does not offer any specific suggestions or guidance on how the authors should address this problem or update the tables. While the feedback identifies a need, it lacks concrete steps for improvement, making it 3 but lacking actionable value."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the 'experiments section' as the main weakness and provides concrete examples of missing information, such as the specific dataset 'CIFAR10' and mentions 'other datasets from Federated learning benchmarks (e.g., LEAF)'. They also name specific papers (FedProx and FedMAX) that highlight the importance of these benchmarks. This clearly indicates an explicit action and concrete details on how to implement it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the experiments section' and then further specifies the lack of evaluation on 'CIFAR10 dataset and other datasets from Federated learning benchmarks (e.g., LEAF)'. They also name specific papers (FedProx and FedMAX) that provide relevant context and examples. This indicates a strong grounding in the specific part of the paper and a high level of specificity about the missing information.", "verifiability_rationale": "The reviewer makes a claim about the 'main weakness of this paper being the experiments section' and then provides specific evidence to support this claim by stating that 'the results are presented only on CIFAR10 dataset and do not consider many other datasets from Federated learning benchmarks (e.g., LEAF)' and by naming specific papers (FedProx and FedMAX) that highlight the importance of these benchmarks. This provides clear verification of the claim.", "helpfulness_rationale": "The reviewer provides a clear and actionable feedback on the 'experiments section' by pointing out the limited dataset usage and suggesting the inclusion of more comprehensive evaluations on other federated learning benchmarks. They provide specific examples (CIFAR10, LEAF, FedProx, FedMAX) to support their suggestion, making the feedback very concrete and helpful for the authors to improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out that the authors consider a single vulnerability at a time, which is an implicit action. While the reviewer doesn't explicitly say 'You should consider multiple vulnerabilities,' they highlight a limitation in the methodology that could be actionable for the authors. However, the reviewer doesn't provide concrete steps on how the authors should address this limitation, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'vulnerability discovery methodology,' 'ingle vulnerability at a time,' 'ecological validity,' 'Previous work,' and 'interpretability.' These are all specific aspects of the paper being discussed. The reviewer clearly identifies the *specific* area of the paper and the limitations within that area. This indicates strong grounding specificity.", "verifiability_rationale": "The reviewer states facts about previous work and the challenges in interpreting the results. This is supported by common knowledge about research methodologies and the nature of interpretability. The reviewer provides logical reasoning and references (even if implicit) to support their claims. This is 5.", "helpfulness_rationale": "The reviewer provides a clear critique of the methodology and raises a specific question. While this points to a significant limitation, it doesn't offer a direct solution or actionable advice on how the authors should improve their draft based on this critique. The helpfulness is moderate as it highlights a weakness but doesn't provide a complete fix."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for an explanation of how the method achieves degree bias. While the paper claims this, it doesn't explicitly state the mechanism or provide a clear, stepbystep guide on how to implement it. The reviewer needs to understand the underlying process to apply this understanding. The paper focuses on the *outcome* (degree bias) and the *proven properties* (intracommunity concentration and intercommunity scatter) but doesn't explicitly explain the *how*. Therefore, the actionability is borderline as the reviewer needs to infer the action.", "grounding_specificity_rationale": "The reviewer is asking for a clear identification of the specific part of the paper where degree bias is achieved and a clear explanation of what is wrong or missing in that part. The paper mentions intracommunity concentration and intercommunity scatter, which are relevant, but it doesn't explicitly state *how* GCL achieves degree bias or *how* these properties relate to it. The grounding is weak because the authors can't confidently pinpoint the exact mechanism or the specific connection to degree bias. While the concepts are mentioned, the explicit link is missing, making it not fully grounded.", "verifiability_rationale": "The reviewer is asking for a clear justification of the claim that GCL conforms to a clearer community structure via intracommunity concentration and intercommunity scatter and its relationship with degree bias. While the paper provides logical reasoning and potentially external references (though not explicitly requested in this case, it's a good implicit check), the connection between these properties and degree bias is not intuitive enough. The reviewer needs a more detailed explanation of *why* these properties lead to degree bias and *how* GCL facilitates this. The explanation is somewhat vague, making it partially verifiable but not fully robust. The paper proves the properties but doesn't fully explain the intuitive link to degree bias.", "helpfulness_rationale": "The reviewer is asking for feedback that empowers them to improve their understanding of how GCL achieves degree bias. While the paper claims this and provides some justification, the explanation is not clear enough for the reviewer to fully grasp the mechanism and its implications. The feedback is 3 as it points towards a need for a clearer explanation, but it doesn't immediately provide actionable steps beyond understanding the mechanism. The reviewer needs more guidance on how to apply this understanding to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer's question is explicit about the missing information regarding the construction of 'clean exemplar manifolds' for ResNet50 and ATResNet50. While the action is explicit (asking for information), the lack of concrete details on how this 'action' is to be carried out makes it somewhat vague. The reviewer is asking for a specific clarification that is not immediately provided in the paper.", "grounding_specificity_rationale": "The reviewer explicitly points to lines 182183 as the source of their confusion. This demonstrates strong grounding as they are directly referencing a specific section of the paper. The reviewer also clearly states what they are asking for \u2013 the construction of clean manifolds and the calculation of the denominator in Figure 2c \u2013 making the specificity high within that referenced section.", "verifiability_rationale": "The reviewer is not making a claim about the paper itself. Instead, they are highlighting a potential inconsistency or lack of clarity in the description of how manifold capacity is measured. This could be considered 'underjustified' as the paper doesn't explicitly address how the 'clean' manifold is constructed or how the denominator in Figure 2c is calculated, especially for nonperturbed networks. Without this information, the reproducibility of the results could be hindered.", "helpfulness_rationale": "The reviewer's question is highly specific and directly addresses a potential source of confusion for the authors. By clarifying how 'clean' manifolds are constructed and how the denominator in Figure 2c is calculated, the authors would gain a crucial piece of information that could significantly improve their understanding and ability to replicate the experiments. This directly helps them interpret the results and potentially identify issues in their own models."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the confusion regarding the variables 'S' and 'Xt' and suggests adding more information. While the paper likely contains information about static and temporal features, it doesn't explicitly define 'S' and 'Xt' in the context of this split. The reviewer's suggestion to clarify this is an implicit action the authors should take, making it 3 but potentially vague as the paper might provide the necessary information elsewhere or in a more detailed form.", "grounding_specificity_rationale": "The reviewer identifies the issue as being related to the distinction between static and temporal features. While the paper likely discusses these concepts, the reviewer doesn't explicitly point to a specific section, table, or figure. However, they *mention* the variables 'S' and 'Xt' as the source of confusion, providing some level of specificity to the problematic area.", "verifiability_rationale": "The reviewer presents the confusion about 'S' and 'Xt' as a problem without explicitly stating why it's a problem or providing a claim. There's no logical reasoning, common knowledge, or external references provided to support the statement. Therefore, it can be considered a statement requiring justification or an opinion, but without any backing.", "helpfulness_rationale": "The reviewer's comment directly points to a potential improvement in the paper's clarity by explicitly defining the variables 'S' and 'Xt'. This is a clear and actionable suggestion that would benefit the authors by making the paper easier to understand. While the paper likely contains the information, the lack of explicit definition is a concrete weakness that the authors can address."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the paper should provide a rationale for the formula, indicating an implicit action (providing justification) that is not directly stated. The lack of a clear explanation makes it difficult for the authors to understand the basis for this specific choice.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific part of the paper (Theorem 3) where the formula appears and points out the lack of motivation. This demonstrates strong grounding specificity as the authors can easily locate the referenced part and the issue.", "verifiability_rationale": "The reviewer claims the paper lacks justification for the formula, forming a claim that needs verification. While the paper states the formula is empirical, it doesn't provide the reasoning behind this choice, making it difficult to verify the claim.", "helpfulness_rationale": "The reviewer finds the current explanation lacking and suggests it could improve the paper. This indicates that the feedback is not entirely missing but is incomplete or unclear, making it less helpful for the authors to understand and implement the suggested change."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the need for 'more details' and provides specific suggestions for 'definitions of the resistance distance' and 'more explanations on Alg. 1 with brief sentences defining A_t, Y_t,...'. These suggestions are direct and actionable, indicating the reviewer is directly pointing out areas where the authors should apply changes.", "grounding_specificity_rationale": "The review point mentions 'many graph notions' generally, which is a broad category. While it then specifies 'definitions of the resistance distance' and 'more explanations on Alg. 1 with brief sentences defining A_t, Y_t,...', it doesn't explicitly state the exact section, table, or unique aspect where these are addressed. The grounding is present but not as precise as it could be.", "verifiability_rationale": "The review point states 'the writing is generally good though more details could sometimes be provided'. This statement expresses a judgment about the paper's quality and the need for more information. While it implies a potential issue, the reviewer doesn't provide specific citations or references to external sources to support this claim about the writing being 'generally good'. The claim is present, but the justification is not strongly supported by verifiable evidence within the paper itself.", "helpfulness_rationale": "The review point directly identifies areas where the authors can improve their paper by providing more details and explanations. The suggestions are concrete and actionable, clearly indicating what the authors should do to enhance their work. The reviewer is directly aimed at helping the authors address specific weaknesses."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The statement is explicit about the limited originality, making it somewhat explicit. However, it lacks concrete details, making it somewhat vague. For example, it doesn't specify which aspects of variable splitting or the algorithm are not new.", "grounding_specificity_rationale": "The reviewer *mentions* the concepts of \"variable splitting\" and \"algorithm,\" which provides some grounding. However, they don't explicitly point to a specific section, table, figure, or unique aspect of the paper being addressed. The mention is general, like a literal mention of sections, tables, figures, etc., which can be considered weak grounding.", "verifiability_rationale": "The statement itself is not a direct criticism or suggestion for improvement. It's an observation about the originality. Therefore, there is no evidence of verifiability in this aspect.", "helpfulness_rationale": "The statement is helpful in informing the authors that their work might not be groundbreaking. It sets expectations and helps them focus their efforts. While it doesn't provide specific actionable steps, it is informative and empowers the authors to understand the context of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the limitation of using training image transformations to prove shape model invariance and clearly identifies the action of looking at quantitative results on testing images. This makes it a concrete and actionable point.", "grounding_specificity_rationale": "The comment explicitly refers to the 'shape model invariance study' and specifically asks about quantitative results on 'testing images'. This demonstrates strong grounding and specificity as the authors can easily identify the referenced part of the paper and the issue being addressed.", "verifiability_rationale": "While the comment itself doesn't contain a claim, it implicitly points to a need for further evidence on testing images. If the paper does not provide this, the reviewer's point is 1. However, if it does, the point is verifiable. Therefore, it can be considered 3 as it highlights a gap in the presented evidence.", "helpfulness_rationale": "The comment clearly identifies a potential limitation in the experimental setup and prompts the authors to consider results on testing images. This is a constructive and actionable suggestion, making the point helpful, although it doesn't explicitly propose a solution."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly names a specific paper (Ghoshdastidar and Dukkipati, AAAI 2015) and suggests a concrete action: 'discuss and compare against'. This directly points the authors to a relevant work and tells them what to do with it. The action is both explicit ( naming the paper) and concrete (suggesting comparison).", "grounding_specificity_rationale": "The review point explicitly names the paper (Ghoshdasticiarid and Dukkipati, AAAI 2015) and provides a brief explanation of its relevance by mentioning its focus on hypergraphs and tensors, which aligns with the reviewer's mention of tensors. This allows the authors to identify the specific paper being discussed and understand the context of the suggested comparison.", "verifiability_rationale": "The review point contains a claim: 'This AAAI 2015 paper deals with hypergraph data with tensors as well so it should be discussed and compared against to provide a better understanding of the stateoftheart.' While the reviewer doesn't provide a detailed proof within the review point, the statement itself is verifiable by examining the mentioned paper. The claim is supported by the stated relevance of the paper to hypergraphs and tensors.", "helpfulness_rationale": "The review point is 5 because it directly identifies a relevant piece of related work and provides a clear action for the authors: 'discuss and compare'. This is a specific and actionable suggestion that directly addresses the authors' need to understand the stateoftheart. The reviewer is not just pointing out a related work but also guiding the authors on how to engage with it."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point presents several questions and statements related to the computational cost and scalability of the optimal transport method. While the questions are direct and point to specific areas for improvement, they lack explicit instructions on how to address them. The reviewer asks about scalability on normal machines and the transition from the Sinkhorn output to the exact optimal transport matrix, but doesn't provide concrete steps or guidance on how to investigate these aspects. The statements about the expense of optimal transport are generally true but don't directly suggest improvements to the authors' draft.", "grounding_specificity_rationale": "The review point explicitly mentions 'normal machines with a couple of cores' and 'Sinkhorn method gives you a doubly stochastic matrix'. These phrases directly identify the specific aspect of the method being discussed (scalability and the nature of the Sinkhorn output). The reviewer is asking about the behavior of the method under specific conditions and about a specific technical detail of the algorithm. This provides a clear target for the authors to investigate and address.", "verifiability_rationale": "The review point contains claims that could be considered verifiable. The statement about optimal transport being expensive is generally verifiable through common knowledge in the field. The question about scalability on normal machines requires understanding the algorithm's complexity and how it scales with the number of cores, which can be verified through logical reasoning or by referencing relevant literature. The question about the Sinkhorn output to exact optimal transport also points to a verifiable aspect of the algorithm, although the exact method to achieve this might require external references.", "helpfulness_rationale": "The review point is 5. The questions directly address potential limitations of the method (scalability) and a specific technical detail (Sinkhorn output to exact transport). These questions empower the authors to investigate and potentially improve their draft by considering these aspects. The reviewer is actively engaging with the method and pointing out areas that need clarification or further investigation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'Some ablation study is missing...' and further specifies 'the hyperparameters in the RBF kernel' (\u03c3, \u03b7, \u03c4). This is a clear and actionable criticism.", "grounding_specificity_rationale": "The reviewer mentions 'the hyperparameters in the RBF kernel' and explicitly names them (\u03c3, \u03b7, \u03c4). This demonstrates both grounding (referring to a specific part of the paper) and specificity (identifying the exact elements).", "verifiability_rationale": "The reviewer makes a claim ('no analysis is given') about a specific area (the hyperparameters in the RBF kernel). This claim is verifiable by pointing to the existence of these hyperparameters and the potential impact they have on the model's performance. While the reviewer doesn't provide the analysis, the claim about the missing analysis is supported by the knowledge of machine learning and the context of the paper.", "helpfulness_rationale": "The reviewer's suggestion to analyze the hyperparameters in the RBF kernel is a relevant and likely beneficial piece of feedback for the authors. It points them towards a specific area of investigation that could improve their model. While it's not a direct fix, it's a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states that the paper was 'extremely hard to follow' and points to 'experimental procedures' and 'evaluations' as areas of difficulty. While it identifies a problem, it does not explicitly state what needs to be changed or how the issues should be addressed. The authors are left to infer the necessary steps, making the action implicit rather than explicit.", "grounding_specificity_rationale": "The comment mentions 'the paper' generally and then points to 'experimental procedures' and 'evaluations' as areas of difficulty. While it identifies broad categories, it doesn't specifically name sections, tables, figures, or any unique elements within those categories that are causing confusion. The grounding is present but not fully precise.", "verifiability_rationale": "The comment is a statement of opinion ('The paper was extremely hard to follow') rather than a claim that requires verification. There are no references to external works or logical reasoning to support this statement. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The comment identifies a significant issue ('extremely hard to follow') and points to specific areas within the paper ('experimental procedures' and 'evaluations') that need clarification. While it doesn't provide specific solutions, it clearly indicates where the authors should focus their attention and what information is lacking. This makes it 3 in guiding the authors to the relevant parts of their own document."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The statement 'Finally, INRs operate on a perdatainstance basis, meaning that one timeseries instance is required to train an INR' is explicit in identifying the mechanism of INR operation. However, the reviewer's suggestion to clarify that this applies to *each instance* within a batch is a specific, actionable improvement. While the initial statement is explicit, the reviewer's point highlights a potential lack of clarity for the reader, making it 3 if explicitly stated.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly point to a specific section, table, figure, or unique aspect of the paper being addressed. They are commenting on a general statement about how INRs operate. However, the reviewer does specify what they find unclear: 'A model that can only handle a single time series data is almost useless.' This provides some level of specificity in their feedback, making it somewhat grounded.", "verifiability_rationale": "The reviewer makes a factual claim: 'Finally, INRs operate on a perdatainstance basis, meaning that one timeseries instance is required to train an INR'. This claim is verifiable based on the definition of 'perdatainstance basis'. While the reviewer doesn't provide external references or complex reasoning, the statement itself is a clear assertion supported by the definition they provided. Therefore, it is **3** as it is verifiable but could benefit from more explicit justification.", "helpfulness_rationale": "The reviewer's point directly addresses a potential misunderstanding of INRs and their limitations. By highlighting that a model handling only single timeseries data is practically useless, the reviewer provides a clear and actionable piece of information for the reader. This directly helps them understand the practical implications of the model's capabilities and guides them to consider the limitations. Therefore, it is **5**."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the missing information: 'certain parameters are bounded on one side (acceleration and scaling parameters)'. This provides a clear target for the authors to address. The reviewer also suggests a concrete action: 'Consider introducing the aspects of the specific model that are specific to this example model'. This indicates a direct and actionable improvement the authors should consider.", "grounding_specificity_rationale": "The reviewer refers to 'the specific model' and mentions 'acceleration and scaling parameters'. This provides some grounding as the parameters are specific to the model. However, the review point does not explicitly point to a unique section, table, or figure within the paper, making the grounding less precise than fully grounded. The parameters are mentioned, but not in a way that clearly identifies a specific part of the paper.", "verifiability_rationale": "The review point makes a statement about the paper's content: 'it should be clear from the beginning that we are not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters)'. This is a claim based on the paper's description. However, the review point itself does not provide explicit evidence or justification within its own text to verify this claim about the bounded parameters. The reviewer's suggestion is more of a constructive improvement than a verifiable claim about the paper's current state.", "helpfulness_rationale": "The review point identifies a potential area for improvement by pointing out the lack of clarity regarding parameter bounds in the specific model. The reviewer suggests a concrete action: 'Consider introducing the aspects of the specific model that are specific to this example model'. This suggests a helpful and actionable improvement. However, the review point itself does not explicitly state *why* this boundedness is a problem or how it affects the model's behavior. It's more of a suggestion for clarification and improvement rather than a direct critique of a flaw."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'It is important to investigate whether the results can be generalized to differences in model size, objective function, and architecture (i.e., encoder, encoderdecoder, or decoder)'. It also provides a specific suggestion: 'In particular, it is worthwhile to include more analysis and discussion for GPT2. For example, I would like to see the results of Figure 2 for GPT2.'", "grounding_specificity_rationale": "The comment explicitly mentions 'other models adopting learnable APEs' and specifically suggests investigating 'GPT2' and 'differences in architecture (encoder, encoderdecoder, or decoder)'. This clearly identifies the specific parts of the paper being addressed.", "verifiability_rationale": "The comment makes a claim: 'Most of the experiments (excluding Section 4.1.1) are limited to RoBERTabase only, and it is unclear if the results can be generalized to other models adopting learnable APEs.' It does not provide any logical reasoning, common knowledge, or external references to support this claim.", "helpfulness_rationale": "The comment identifies a limitation in the experiments and suggests specific areas for improvement (testing on other models, analyzing different architectures). While it points in a productive direction, it doesn't provide specific instructions or expected results for the suggested experiments. For example, it doesn't specify how to analyze the results for GPT2 or how to compare encoder, encoderdecoder, and decoder models."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a limitation in the scope of the method (ViT and image data) and suggests exploring other areas (NLP) and simpler models. This is an implicit suggestion for improvement, indicating a lack of explicit actionability on the part of the authors. The reviewer doesn't directly tell the authors *what* to do, but rather points out a gap in their current approach.", "grounding_specificity_rationale": "The reviewer explicitly states the limitations of the method to ViT and image data. While they don't pinpoint a specific section or table, the mention of 'parameters in Table 1' and 'state of the art performance' suggests a general lack of applicability. The reviewer's suggestion to explore NLP and simpler models indicates a lack of specific grounding in the current work or alternative approaches. The weakness is in identifying a concrete area of the paper that needs improvement.", "verifiability_rationale": "The reviewer's comment is a question about the generalizability of the method. It doesn't contain a claim that requires verification. The reviewer is asking for clarification or a request for changes, which falls under the 'Normal Statements' category in the verifiability definition. There's no assertion that something is correct or incorrect, just a question about applicability.", "helpfulness_rationale": "The reviewer's comment is highly critical of the method's limited scope and suggests concrete ways to improve it by exploring other areas and simpler models. This demonstrates a desire for the method to be more broadly applicable and impactful. While the comment doesn't explicitly state a solution, it clearly identifies a significant limitation and proposes actionable steps for the authors to consider. The reviewer is not just pointing out a problem, but also suggesting a path towards a more general solution, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a problem (nonstandard benchmarks breaking TTA methods) but does not provide a specific action or suggestion on how to address it. It is a statement of observation rather than a directive for improvement.", "grounding_specificity_rationale": "The review point mentions 'TTA methods' and 'natural distribution shift, like WILDS 9'. While it mentions WILDS, it does not explicitly identify a specific part of the paper being addressed. The grounding is weak because the connection to the paper's specific content is not clear.", "verifiability_rationale": "The review point makes a claim ('This is an interesting observation...') but does not provide any evidence or reasoning to support it within the review itself. The claim is presented as an observation without justification.", "helpfulness_rationale": "The review point identifies a potential issue with the evaluation methodology (nonstandard benchmarks) and suggests an alternative (WILDS). While this points to a potential problem, it does not offer a concrete solution or actionable steps for the authors to address this. It is a suggestion for further investigation rather than a direct solution."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states their belief that the authors' understanding of the learning rate scaling condition is unrealistic and contradicts practical experience. While the reviewer clearly states their opinion, they do not explicitly identify a specific action or suggestion for the authors to take. They are critiquing the authors' assumptions rather than providing a direct path for improvement. Therefore, the comment is explicit in its statement but lacks a concrete action for the authors.", "grounding_specificity_rationale": "The reviewer refers to the 'required condition on the learning rate (scaling with the number of samples)' mentioned by the authors. While they do not provide a specific section number, the reviewer's criticism is directly related to a concept discussed in the paper. They are implicitly pointing to the discussion of learning rate scaling. However, the reviewer does not specify *what* aspect of the learning rate scaling is causing the issue or what specific part of the paper needs to be addressed. The grounding is weak because the authors cannot confidently pinpoint the exact location of the problem. The specificity is also lacking because the reviewer does not detail *what* is wrong with the scaling or how it should be adjusted. Therefore, the comment is 2.", "verifiability_rationale": "The reviewer makes a claim about the authors' understanding of the learning rate scaling condition being unrealistic and contradicting practical experience. This is a clear claim. However, the reviewer does not provide any evidence, reasoning, or external references to support this claim. They state their belief without backing it up. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer's comment is primarily critical of the authors' understanding and the practical implications of a stated condition. They do not offer any specific suggestions or actionable steps for the authors to take to improve their draft. The comment is more of a critique than a helpful suggestion. Therefore, the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the paper does not explain how the results are useful to machine learning algorithms or how they analyze the algorithms. This directly points to an implicit action that needs to be taken by the authors to understand the significance of their work. While the reviewer doesn't provide specific steps on how to improve this, they clearly identify a missing link in the explanation.", "grounding_specificity_rationale": "The reviewer mentions 'tensor networks,' 'PMF,' and 'machine learning algorithms' in their critique, which suggests they have identified a specific area in the paper that needs clarification. However, they do not explicitly state which part of the paper is unclear or what specific aspect of the connection between these concepts is missing. This indicates a weak grounding as the authors cannot confidently pinpoint the referenced part.", "verifiability_rationale": "The reviewer makes a claim that 'the significance of this paper is poor' based on the lack of clarity regarding the connection between tensor networks, PMFs, and machine learning algorithms. While they provide a reason for this claim, they do not offer specific examples or external references to support their assertion about the poor significance. Therefore, the claim is not fully justified by explicit reasoning or external evidence.", "helpfulness_rationale": "The reviewer's comment directly points to a significant issue in the paper \u2013 the lack of explanation regarding the significance of the results for machine learning. While they do not offer specific suggestions for improvement, their critique highlights a crucial gap that the authors need to address to make their work more impactful. The criticism is clear and identifies a problem, making it 3 in highlighting the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'The unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version) is perfectly balanced, which is impractical in realworld applications.' This is a clear and direct identification of a problem. The reviewer also suggests a solution: 'Since we cannot control the label distribution of unlabeled data during training, the author should also use a more convinced setting as did in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018, which directly samples unlabeled data from millions of reviews.' This suggests a concrete improvement. Both the problem and the solution are clearly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version)' and 'perfectly balanced'. This clearly identifies the specific part of the paper being addressed. The reviewer also names a specific paper, 'Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018', which further grounds the reference to a specific technique. The reviewer also suggests 'directly sampling unlabeled data from millions of reviews', which is a concrete alternative approach.", "verifiability_rationale": "The reviewer provides a clear explanation of why the statement about the perfectly balanced dataset is true: 'impractical in realworld applications' and suggests a more 'convincing setting' based on 'Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018'. While the reviewer doesn't provide a direct citation *in this specific point*, the reasoning is wellestablished in the field. The suggestion to use 'unlabeled data from millions of reviews' is a logical and verifiable alternative approach.", "helpfulness_rationale": "The reviewer directly points out a limitation of the authors' experimental setup: the use of a perfectly balanced unlabeled dataset, which is unrealistic. The reviewer then provides a concrete suggestion for improvement: 'the author should also use a more convinced setting as did in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018, which directly samples unlabeled data from millions of reviews.' This is a clear and actionable suggestion that can help the authors improve their work by making it more relevant to realworld scenarios."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a problem: 'It's not clear how to sample from the DPP if the eigenfunctions e_n's are inaccessible (Eq (10) line 130)' and draws a parallel to a similar problem with leverage score sampling: 'This seems to be the same problem with sampling from the leverage score in 3'. While it doesn't offer a direct solution, it clearly identifies a gap in understanding and highlights a potential area of confusion.", "grounding_specificity_rationale": "The review point explicitly mentions 'Determinantal Point Process (DPP)' and 'eigenfunctions e_n's and refers to a specific equation (Eq (10) line 130). This clearly identifies the technical concepts being discussed, demonstrating strong grounding.", "verifiability_rationale": "This review point is primarily a question asking for clarification. It doesn't present a claim that requires verification. The reviewer is seeking information about a specific technical detail, not making a statement that needs to be proven or supported.", "helpfulness_rationale": "The review point identifies a specific technical issue related to sampling from a DPP, which is likely relevant to the authors' work. The reviewer's explicit question about the connection to leverage score sampling indicates a desire for more information and a potential point of confusion. While it doesn't provide a direct solution, it highlights a potential area where the authors might need further guidance. The reviewer's engagement suggests it's at least 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point states a limitation of the study. While it points out a *potential* area for future work, it doesn't directly instruct the authors on *what* to do or *how* to address it. Therefore, it's not explicitly actionable in its current form.", "grounding_specificity_rationale": "The review point refers to \"fewshot learners beyond Prototypical Networks.\" This is a specific area, but it's a bit vague. While it mentions a specific term, it doesn't pinpoint a *specific section* or *unique aspect* within that field. The grounding is more general than fully specific.", "verifiability_rationale": "The review point is a statement of a limitation, not a claim requiring verification. It's a suggestion for future work, not a critique that needs evidence. Therefore, it doesn't contain a claim that can be verified.", "helpfulness_rationale": "The review point identifies a limitation and suggests a direction for future research. While it's constructive, it doesn't directly guide the authors on how to improve their current submission. It points to a gap in the understanding of episodic training, which is valuable for the field, but it doesn't provide concrete steps for the authors to take *now* with their current work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a potential solution (distinguishing strong vs. weak modal subsets) and provides a detailed procedure for implementing it. They suggest identifying instances where one modality performs significantly better than another and then creating separate subsets for these instances. This provides a clear action for the authors to take. The reviewer also mentions 'Equation 3' which, while not fully defined, suggests a connection to existing methods, adding further detail to the implementation.", "grounding_specificity_rationale": "The reviewer refers to 'different modalities,' 'instances,' and 'Equation 3' in their review. While they imply a connection to the original paper, they do not explicitly identify a specific section, table, figure, or unique aspect of the paper where this problem is occurring. They discuss the modalities and instances in a general way. The connection to 'Equation 3' is also not explicitly stated as referring to a specific equation in the paper. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer presents a claim: 'Equation 3 directly removes the modal subset of all instances, how to deal with the problem mentioned above.' They then propose a solution: 'We can distinguish the strong modality and weak modality subsets, and then create separate subsets for instances where one modality performs significantly better than another.' This claim is supported by suggesting a specific method (distinguishing and separating instances) to address the problem. While they don't provide a citation, the suggestion of creating subsets is a logical and verifiable approach.", "helpfulness_rationale": "The reviewer's point is very specific and directly addresses a potential issue with how modalities are handled in the paper. They propose a concrete solution (distinguishing strong and weak modal subsets) to ensure fair treatment of different modalities. This is a valuable and actionable suggestion that would likely improve the clarity and fairness of the analysis. The reviewer's feedback is clear and directly tackles a potential weakness."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states the abstract is good but lacks description of how the idea was evaluated and what was the outcome. This points out a missing element, but doesn't directly instruct the author on what to do. Therefore, it's not fully actionable. It identifies a gap, but doesn't fill it by providing explicit instructions on how to address it.", "grounding_specificity_rationale": "The review point talks about the abstract lacking evaluation and outcome. It doesn't explicitly mention a specific part of the paper (e.g., methodology section, results table) being lacking detail. Therefore, it's 1 at all. The comment is highly unspecific.", "verifiability_rationale": "The review point is a statement of observation (' The abstract does a good job explaining the proposed idea') followed by a criticism (' lacks description of how the idea was evaluated and what was the outcome'). The criticism is a claim that needs to be supported. However, the review point itself doesn't provide any evidence or reasoning to support why the abstract lacks this description. It's a statement of opinion, not a claim that is verifiable based on the provided text. Therefore, it's 1 as it stands.", "helpfulness_rationale": "The review point identifies a weakness in the abstract (lack of evaluation details) but doesn't offer any suggestions or actions for the author. It points out a gap, but doesn't provide any constructive feedback on how to address it. Therefore, it's 1. It identifies a problem but doesn't offer any solutions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer expresses a lack of confidence in the experimental results and provides specific examples of POMDP problems with nonconvex value functions. However, the reviewer does not explicitly state what specific action or improvement they would like the authors to take based on this feedback. The comment is more of a critique of the motivation and the lack of specific experimental instances rather than a direct instruction on how to improve the experiments. Therefore, while the feedback is relevant, it lacks the explicit actionability required to be 5.", "grounding_specificity_rationale": "The reviewer mentions specific POMDP examples (surveillance in museums with thresholded rewards; privacy preserving data collection) to motivate the experiments. However, they do not explicitly identify a specific part of the paper (e.g., a section, table, or figure) where these examples are discussed or where the lack of experiments is being pointed out. The reviewer's point is more general, criticizing the *type* of motivation used rather than pinpointing a specific location in the paper. Therefore, the grounding is weak because the reviewer cannot confidently determine which part of the paper they are addressing.", "verifiability_rationale": "The reviewer's comment is not a claim requiring verification. They are expressing a concern about the experimental setup and motivation, but they are not stating that something is wrong with the paper's results or providing external references to support their critique. The comment is more of an opinion or a suggestion for improvement rather than a verifiable claim. Therefore, the claim extraction would result in 'X' (X).", "helpfulness_rationale": "The reviewer's comment is clearly aimed at improving the paper. They identify a perceived weakness (lack of specific experiments) and suggest a potential improvement (including experiments on the mentioned POMDP settings). While the actionable aspect might be low, the reviewer provides a concrete suggestion for improvement, making the review quite helpful in terms of guiding the authors towards better experimental design. The reviewer is not stating something is wrong with the paper's results, but rather pointing out a lack of specific evidence to support their motivation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of clarity in the description of the MFDA setting, which implies an implicit action of identifying a problem. However, the action is vague, making it less concrete.", "grounding_specificity_rationale": "The reviewer highlights the unlabeled nature of the target domain notation (\tau) and questions the use of source domain data. This indicates a lack of full grounding as the specific part of the paper being addressed is unclear, and the reviewer doesn't specify what needs to be addressed in this part.", "verifiability_rationale": "The reviewer raises a concern about the consistency of the problem setting description with the original MFDA paper, questioning the accuracy and clarity of the description. This suggests the claim is somewhat supported by the reviewer's reasoning but lacks definitive verification or references.", "helpfulness_rationale": "The confusion about the method description likely makes the information less helpful for the authors to understand and potentially implement changes. The lack of clarity and grounding reduces the potential impact of the feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a *type* of analysis (epochwise) and *specific investigations* (batch size, sampling, deterministic/stochastic comparison). However, it does not explicitly state what specific part of the paper needs to be analyzed or what concrete action the author should take. The reviewer implies the usefulness of this analysis but doesn't provide explicit instructions on how to perform it.", "grounding_specificity_rationale": "The review point suggests a *general* approach to analysis (epochwise) but does not specify which particular section, table, figure, or unique element of the paper this analysis should focus on. The reviewer mentions *what* to investigate (batch size, sampling, deterministic/stochastic comparison) but not *where* in the paper this investigation should be conducted. Therefore, the grounding is weak as the target part of the paper is not clearly identified.", "verifiability_rationale": "The review point contains a claim: 'I think epochwise analysis, especially for finite sum settings, could help provide insights into behaviors of optimization algorithms.' It also provides reasoning and potential examples to support this claim, such as investigating the effect of batch size or different sampling strategies. The claim is logically reasoned and supported by potential examples.", "helpfulness_rationale": "The review point offers a suggestion for improvement by proposing a *specific type of analysis* (epochwise) that could enhance the understanding of optimization algorithm behavior. While it doesn't provide concrete implementation details, it clearly indicates a direction for the author to focus their work. The suggestion is not critical but rather a constructive idea for improvement, offering potential insights and comparisons. Therefore, it is helpful in guiding the author towards better analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies potential issues such as missing key baselines and missing citations. These are explicit statements about what is missing. However, the reviewer does not explicitly state how the authors should address these issues. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer mentions specific missing works (GraphRAG papers) and a potentially relevant area (MedRetriever). This grounds the feedback to specific parts of the field. However, the reviewer does not explicitly point to a specific section, table, or figure in the submitted paper that needs improvement. The issue is more general.", "verifiability_rationale": "The reviewer makes claims about the contribution being incremental and the potential GraphRAG connection. These claims lack strong justification within the review point itself. They point to what might be missing, not why it's missing or how it impacts the work. There is X being verified.", "helpfulness_rationale": "The reviewer points out potential issues with the authors' workload, the incremental nature of the contribution, and suggests missing key baselines and citations. While these are valuable observations, the review point does not directly instruct the authors on how to improve their draft. The feedback is more about what is missing from the work rather than how to address the identified weaknesses."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a problem (the difficulty in differentiating between types of extreme speech) and provides a specific example. While the reviewer doesn't explicitly state how to solve the problem, they prompt the authors to consider the distinction. This suggests a level of action, but it's not as explicit as a direct instruction on how to modify the draft. The reviewer is asking the authors to consider a specific instance, which implies an action, but it's not a clear, stepbystep guide.", "grounding_specificity_rationale": "The reviewer mentions the issue (difficulty in differentiating) and refers to the 'Paper Summary,' implying they've read it. They also provide a specific example to illustrate the ambiguity. However, they don't explicitly state which section, table, or unique aspect of the paper they are referring to. The reference to 'Paper Summary' is general, and they don't pinpoint the exact location of the definitions they are questioning.", "verifiability_rationale": "The reviewer makes a claim about the ambiguity of the distinction between the two types of extreme speech and provides a potential explanation (local regulations) for this ambiguity. They ask a question to elicit clarification. While the claim is present, the reviewer doesn't provide sufficient justification or evidence to support their claim about local regulations. The connection between the example and the regulation is implied but not explicitly stated or supported by external references.", "helpfulness_rationale": "The reviewer clearly identifies a problem (the lack of clarity in distinguishing between extreme speech types) and provides a concrete example to illustrate this point. They also ask a question, which is a helpful prompt for the authors. While the feedback is focused on a specific issue, it is clear and actionable in terms of highlighting a potential area for improvement. The reviewer is not providing a solution, but they are prompting the authors to consider a specific problem."}
{"actionability_label": "4", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states what the reviewer wants the authors to do: 'show a graph showing the plot of T vs number of images, and Expectation(T) over the imagenet test set.' This is a clear and direct instruction. While it doesn't specify *how* to create the graph, it identifies the key elements and the context. The reviewer is suggesting a specific analysis to understand the source of performance improvement.", "grounding_specificity_rationale": "The comment explicitly mentions 'T', 'number of images', and 'Imagenet test set'. These are specific parts of the paper and unique elements within them. The reviewer is referring to a general concept 'T' and a dataset 'Imagenet test set'. While it doesn't pinpoint a specific section *within* the 'network design' or 'Imagenet dataset', it clearly identifies the *types* of information needed for the analysis. The grounding is weak but not nonexistent.", "verifiability_rationale": "The comment is not making a claim or assertion. It is a request for a specific analysis and visualization. There is X that needs to be verified or supported with evidence.", "helpfulness_rationale": "The review point is highly specific and directly addresses a potential concern about the source of performance improvement. It tells the authors exactly what analysis they should perform and on what data. While it doesn't provide the exact methodology for creating the graph, it provides a clear direction for further investigation. This information is valuable for the authors to understand the factors contributing to their results."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states two areas for improvement: 'mathematical correctness' and 'notation clarity'. While the reviewer doesn't label them as 'explicit' or 'concrete', the suggestions are directly pointing to specific actions the authors should take. The reviewer also provides a preference, which can be interpreted as an implicit suggestion to improve clarity. However, the lack of a specific example for the preference makes it less actionable. Overall, the reviewer provides clear directions for improvement, making it 4.", "grounding_specificity_rationale": "The reviewer refers to 'L_l' and 'Fig.', which implies they are referring to a specific section or figure in the paper. While they don't explicitly name it, the use of 'Fig.' suggests they can identify the relevant part. The reviewer also points to a preference for better notation, which can be argued as implicitly referring to a specific aspect of the notation. Therefore, while not fully 'fully grounded', the reviewer can identify the specific area they are referring to, making it somewhat grounded.", "verifiability_rationale": "The reviewer is stating a preference for better notation and a desire for mathematical correctness. This is a statement of opinion rather than a claim that something is definitively wrong. Therefore, it doesn't fall under the 'X' category (X). While the reviewer provides suggestions, they are not supported by external references or logical reasoning within the review point itself. The reviewer is making a statement about what they believe is best practice, not a verifiable fact. Therefore, it is 1.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, including 'change to be mathematically correct' and 'why is it L_l instead of just L?'. These are actionable and directly address potential weaknesses in the paper. The reviewer also suggests that the notation should be introduced beforehand, which is a constructive suggestion. While the suggestion 'Fig.' is incomplete, the preceding statements clearly indicate a desire for clarification and improvement. The reviewer's comments are focused on providing concrete feedback to guide the authors' work, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitation of sequential ensembling in the context of homomorphic encryption, identifying 'noise accumulation' as the issue. This provides a clear direction for improvement by highlighting a specific problem with the method.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'sequential ensembling' and its relation to 'homomorphic encryption,' providing a clear reference to specific parts of the paper. They also explain the problem ('noise accumulation') within this context, making the grounding specific.", "verifiability_rationale": "The reviewer identifies a limitation ('It is important to study...') and provides a justification ('This limitations prevents the use...') based on the impact on the usability of the technique. While it doesn't provide a citation, the reasoning is logical and directly related to the mentioned issues.", "helpfulness_rationale": "The review points out a specific limitation of a particular technique ('sequential ensembling') in a specific context ('homomorphic encryption'). This is helpful as it guides the authors to consider the challenges and potential drawbacks of this approach, encouraging them to think critically about their methodological choices."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the observation about similar performance ('Figure 5 shows similar performance') and identifies the scenario ('when trained and evaluated with the same timestep'). While the reviewer also suggests a potential implication ('This makes the effectiveness of the proposed methods questionable') and a potential benefit ('maybe under some scenarios where the training timestep and evaluation timestep are different'), the core observation and the identified scenario are clearly stated. The reviewer does not provide concrete steps on how to improve the method based on this observation.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 5' and discusses 'timestep' as specific elements. While they don't explicitly state 'Section X of the paper discussing the experimental setup,' the reference to 'Figure 5' implies they are referring to a specific part of the paper. The concept of 'timestep' is also a specific concept within the context of the paper. However, the reviewer does not explicitly identify a specific element within Figure 5 or the 'timestep' concept itself.", "verifiability_rationale": "The reviewer presents an observation ('Figure 5 shows similar performance') and then offers an interpretation ('This makes the effectiveness of the proposed methods questionable'). While the observation itself could potentially be verifiable by examining Figure 5, the interpretation is not directly supported by evidence within the review point itself. The reviewer also suggests a potential alternative scenario ('maybe under some scenarios where the training timestep and evaluation timestep are different'), but this is a suggestion for future exploration rather than a direct verification of the current observation.", "helpfulness_rationale": "The reviewer points out a potential issue (similar performance) and raises a question about the method's effectiveness in that specific scenario. They also suggest a potential benefit in a different scenario. This highlights a limitation or a point of confusion regarding the method's current application. While it doesn't directly *improve* the paper, it does point out a relevant point that could guide further work or clarification. The reviewer does not offer concrete steps to improve the method based on this observation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the problem: 'it is not clear how disentanglement is guaranteed.' It then provides a suggestion: 'the authors want more detail on the mechanism or conditions that ensure disentanglement.' This is an explicit statement of a problem and a direct suggestion for improvement, making it 5. The reviewer clearly knows what action they want the authors to take.", "grounding_specificity_rationale": "The reviewer directly references 'disentanglement' and 'Broader Impacts and Limitations' sections. This is a clear and specific identification of the area being discussed. Furthermore, the reviewer asks a very specific question: 'how the disentanglement is realized and guaranteed without certain bias types.' This specificity points to a particular aspect within the mentioned section, making it highly specific.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification in the sense of logical reasoning, common knowledge, or external references. It's a request for more information. Therefore, it's not strictly 'verifiable' in the defined sense. While the request implies a need for verifiable information if the paper lacked it, the point itself doesn't make a claim that needs to be supported.", "helpfulness_rationale": "The reviewer has identified a genuine gap in their understanding \u2013 the mechanism behind disentanglement. They provide a clear suggestion for improvement: providing more detail in the 'Broader Impacts and Limitations' section. This is a valid and actionable feedback point that would likely help the authors improve their work by clarifying a crucial aspect of their methodology or findings."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states 'it should be used standard regularization trick.' This is a direct action. However, the specific type of regularization trick is not mentioned, making it less concrete. Therefore, it is an explicit but somewhat vague action.", "grounding_specificity_rationale": "The review point mentions 'stronglyconvex concave case.' This clearly identifies the specific aspect of the paper being addressed, making the grounding strong. However, the suggestion itself, 'standard regularization trick,' is not fully specific regarding the *implementation* of the regularization. Therefore, it is weakly grounded and somewhat specific.", "verifiability_rationale": "The review point suggests a 'standard regularization trick' for comparison. This is a suggestion or recommendation, which can be considered a claim that this method is appropriate. However, the review point does not provide any logical reasoning, common knowledge, or external references to support this claim. Therefore, it is a claim that is not verifiable.", "helpfulness_rationale": "The review point suggests using a 'standard regularization trick' for comparison in a 'stronglyconvex concave case.' While this points to a relevant method for comparison, it does not explain why this comparison would be beneficial or how it would be implemented. The suggestion is procedural but lacks a clear rationale or justification. Therefore, it is not 5."}
{"actionability_label": "4  4", "grounding_specificity_label": "5  5", "verifiability_label": "5  5", "helpfulness_label": "5  5", "actionability_rationale": "The comment explicitly states the action of 'including the learning curve for a model without any mean teacher or pi regularization for comparison' and implies the desired outcome is to understand the impact of mean teacher and pi regularization. While the action is clear, the level of detail on *how* to improve the graph is not explicitly stated.", "grounding_specificity_rationale": "The comment explicitly mentions 'fig 3' and specifies the purpose of the graph as 'learning curve for a model without any mean teacher or pi regularization'. This clearly identifies the specific part of the paper being addressed. The comment also clearly specifies what needs to be addressed in this part, which is the inclusion of a specific graph and a comparison.", "verifiability_rationale": "The comment contains a claim (a suggestion for improvement) and provides sufficient justification by stating the purpose of the graph and the model being considered. The suggestion is verifiable by showing the intended result (the learning curve). The claim is wellsupported by the reasoning and common knowledge about model training.", "helpfulness_rationale": "The comment provides a clear and actionable suggestion for the authors to improve their understanding of the impact of mean teacher and pi regularization. The suggestion is directly relevant to the authors' work and provides a concrete next step. The comment is not vague or lacking in detail."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points to a specific aspect of the method (Equation 2 and the optimization problem) and raises a question about the implications for the number of parameters compared to AlignFlow. While the reviewer doesn't explicitly state an action or a concrete step, the question directly relates to a specific implementation detail of the proposed method. The reviewer is essentially asking for clarification on how the optimization over both parameters is handled and how it differs from prior work in terms of parameter count. This falls under the category of 'Explicit' as the reviewer is directly addressing a specific part of the method (Equation 2). However, the action is not a direct instruction but a question about a specific aspect, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'AlignFlow (Grover et. al. 2019)' in the context of comparing the number of parameters. This directly grounds the criticism in existing literature. The reviewer is asking a question about a specific comparison, making the grounding quite clear. The criticism is focused on a specific aspect of the method (parameter count) and a specific prior work, making the grounding strong.", "verifiability_rationale": "The reviewer states that the effect on the number of parameters vs. prior work has not been discussed clearly. This constitutes a claim that there is a lack of sufficient justification or explanation regarding the parameter count comparison. The reviewer is making a statement about the absence of a specific type of evidence (clear discussion). While the reviewer doesn't provide evidence *why* it's unclear, they are stating that this is the case. This fits the definition of a 'Claim' as it identifies a specific aspect (parameter count) and its relation to prior work. The lack of explicit discussion makes the verifiability somewhat low.", "helpfulness_rationale": "The reviewer finds the point relevant to understanding the method's parameter handling and its relation to AlignFlow. The question directly addresses a potential concern or gap in the understanding of the proposed method compared to existing work. This makes the point potentially helpful for readers trying to understand the method's practical implications. The point raises a valid question that could inform implementation decisions or comparisons with other methods."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or provide concrete guidance on how to address the issue of different input types. While it suggests discussing and presenting solutions, it lacks a direct instruction for the author.", "grounding_specificity_rationale": "The review point explicitly mentions 'different types of inputs (e.g., biomedical signals or speech)' and suggests discussing and presenting solutions. This clearly identifies the specific aspect of the paper being addressed.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It presents a suggestion for future discussion rather than a definitive statement about what the author needs to do.", "helpfulness_rationale": "The review point raises a valid concern about the paper's scope and suggests a direction for improvement. However, it does not provide specific, actionable steps or concrete guidance on how to address the issue, making it less immediately helpful for the author."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer directly asks a question about the relationship between two equations (Eq. 4 and Eq. 3). This is an explicit request for clarification on how one equation implies the behavior of another. The reviewer is asking the authors to identify modifications they should apply to their draft based on the equations.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Eq. 4' and 'Eq. 3' and then mentions 'Table 5' and specifically the 'OfficeHome dataset'. This demonstrates a clear identification of the specific parts of the paper being addressed. The reviewer is not just stating a general weakness but pinpointing the equations and the numerical results in Table 5 as evidence of a lack of significant improvement.", "verifiability_rationale": "The reviewer makes a claim about the significance of the results in Table 5, stating that the improvement is 'not significant on some datasets'. This claim is verifiable by looking at the numerical data provided in Table 5. The reviewer then asks a question related to the equations, which is a logical followup to the claim, asking for an explanation of the implication of one equation on another based on the observed results. The claim is supported by the numerical data, making it '3'.", "helpfulness_rationale": "The reviewer points out a lack of significant improvement in the results presented in Table 5 for certain datasets. This is a valid observation that could be helpful for the authors to know. While the reviewer doesn't explicitly ask for a solution or a specific change, identifying this lack of significance is a constructive feedback point that can guide the authors in interpreting their results and potentially exploring further improvements. The feedback is directly related to the presented data and is therefore helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing reference 'Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" and compares the reported LFW accuracy (98.65%) to the result in Table 3 of the paper. This provides a concrete action for the authors to investigate the missing reference and potentially improve their results by adopting the betterperforming method. The action is clearly defined and the metric for comparison is provided.", "grounding_specificity_rationale": "The review point begins by explicitly mentioning 'the experiment of face recognition' and then specifically names the missing reference 'Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\". This demonstrates strong grounding as the authors can easily identify the specific part of the paper being addressed. The specificity is further enhanced by comparing the result to a metric (accuracy on LFW) reported in another paper, making it clear what needs to be investigated.", "verifiability_rationale": "The review point contains a claim that the missing reference represents a better stateoftheart with a higher accuracy on LFW. It provides external evidence (the cited paper and its reported accuracy) to support this claim. The reasoning is logical and the reference is specific, making the claim 5.", "helpfulness_rationale": "The review point is 5 as it identifies a clear weakness (missing references) and provides a concrete suggestion for improvement (investigating the betterperforming method from the cited paper). The specific comparison of accuracy makes the direction of improvement clear and actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential limitation of the method, suggesting it might not generalize well to questions that are not 'Whtypes'. While the reviewer doesn't propose a specific action, they are highlighting a potential consequence of the current action (transforming all questions). The actionability here is implicit \u2013 the reviewer is suggesting a potential flaw in the approach. The action being pointed out is 'transforming all questions into masked statements'. The reviewer is indicating that this might not be universally applicable. However, the reviewer doesn't explicitly state how to address this limitation, making the actionability somewhat implicit and not fully actionable.", "grounding_specificity_rationale": "The review point does not explicitly state which part of the paper it is addressing. The reviewer is making a general comment about the limitations of the question answering method. Therefore, the grounding specificity is low as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer states a concern about the method's potential limitations without providing any evidence or justification. They are expressing an opinion about the generalization issue. The verifiability here is low because the reviewer is not presenting a claim that can be supported by logical reasoning, common knowledge, or external references. The statement is a critique, not a claim requiring verification.", "helpfulness_rationale": "The reviewer's comment is a critique of the method and a suggestion for improvement (handling nonWhtype questions). While valuable feedback, it doesn't directly provide actionable steps for the authors to improve their draft. The helpfulness is limited as the reviewer is not proposing a concrete solution or guidance for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that using volumetric representations in the deformation field isn't a novel idea and names a specific prior work (VolumeDeform). This is a clear and direct statement, making it 5 for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'volumetric representation in the deformation field' but doesn't specify a particular section, table, or unique element. While the context strongly links it to the 'realtime dynamic reconstruction task' and 'VolumeDeform 1', the exact location isn't pinpointed, making the grounding weakly specific.", "verifiability_rationale": "The reviewer makes a claim about the lack of novelty and mentions VolumeDeform as a related work. However, they don't provide a detailed explanation of why it's not novel or cite specific aspects of VolumeDeform that make it relevant. The evidence is present but not fully developed, making the claim 3.", "helpfulness_rationale": "The reviewer informs the authors about a potential lack of novelty and points to a related work. While this information is relevant, it doesn't directly guide the authors on how to improve their current draft. It's an observation rather than a constructive suggestion, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a problem (ICLHAR hindering accuracy) and suggests a discussion. While the *cause* (ICLHAR) is mentioned, the *specific steps* or *how* to take action are not explicitly stated. The suggestion to discuss implies an action, but it's not a direct, actionable instruction.", "grounding_specificity_rationale": "The review point explicitly mentions 'ICLHAR' and 'accuracy scores,' clearly identifying the specific part of the paper and the issue. It also specifies what is wrong ('dropping from 70.4 to 55.6 on TRIP'). This indicates strong grounding as the specific element and the problem within it are welldefined.", "verifiability_rationale": "The review point states a fact ('dropping from 70.4 to 55.6 on TRIP') and offers a potential explanation ('has greatly impedes the accuracy scores'). However, it lacks explicit justification for *why* ICLHAR might cause this drop, nor does it provide specific examples or citations to support this claim. The explanation is present but lacks robust backing.", "helpfulness_rationale": "The review point directly points out a problem ('ICLHAR, while improving consistency and verifiability, has greatly impedes the accuracy scores') and suggests a discussion ('should be discussed or at least acknowledged in the main text in more detail'). This directly helps the authors understand an issue with their method and encourages them to investigate further. The suggestion to discuss is a clear and actionable step for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "Not Verifiable", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point states a fact ('The rockpaperscissors example is clearly inspired by an example that appeared in many previous work') but does not provide any instructions or suggestions on how to improve the paper based on this observation. There is no explicit action or concrete steps to be taken.", "grounding_specificity_rationale": "The review point explicitly mentions 'the rockpaperscissors example,' clearly identifying the specific part of the paper being criticized.", "verifiability_rationale": "The review point makes a claim ('The rockpaperscissors example is clearly inspired by an example that appeared in many previous work') but does not provide any evidence or justification within the review point itself to support this claim. It's a statement of opinion without backing.", "helpfulness_rationale": "The review point criticizes the use of a rockpaperscissors example without providing any specific feedback on how this is a problem or what the authors should do about it. It's a critique without actionable suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "2", "actionability_rationale": "The review points out a limitation and attributes it to the performance of the oracle expert. While this is a valid observation, it does not provide the author with explicit or concrete steps to improve their network architecture or constraint embedding.", "grounding_specificity_rationale": "The review explicitly mentions 'innovations of network architecture design' and 'constraint embedding,' which are specific areas within the paper. It also clearly states that 'performance is limited by the performance of the oracle expert,' providing a specific issue within these areas.", "verifiability_rationale": "The review contains claims such as 'The innovations of network architecture design and constraint embedding are rather limited' and 'The performance is limited by the performance of the oracle expert.' While the connection to the 'discussed' part of the original text implies these points, the reviewer does not provide external references or logical reasoning to support these claims within the review itself.", "helpfulness_rationale": "The review identifies a limitation and attributes it to the oracle expert. However, it does not offer any suggestions or actionable steps for the author to address this limitation or improve their work."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the limitation of the current evaluation setup (pretraining only on synthetic data) and proposes an alternative (pretraining on synthetic, finetuning on realworld with different losses). This directly addresses a potential weakness in the authors' current approach. The reviewer also clearly states the goal of the alternative evaluation: to demonstrate the importance of the proposed projection errors. The reviewer identifies a specific area for improvement and suggests a concrete method to achieve it. Therefore, the review point identifies a clear action for the authors to take, making it actionable.", "grounding_specificity_rationale": "The reviewer explicitly states the *why* of the suggestion \u2013 to demonstrate the importance of the proposed three projection errors. The reviewer also clearly identifies the alternative evaluation strategy (pretraining on synthetic data but finetuned on realworld datasets with different losses). This shows a clear understanding of what aspect of the model needs improvement. The reviewer grounds the suggestion in a specific area of the model (the projection errors) and proposes a specific method to evaluate them. Therefore, the reviewer provides a clear target for the authors to focus on, making the grounding specific.", "verifiability_rationale": "The reviewer proposes an alternative evaluation strategy (pretraining on synthetic data but finetuned on realworld datasets with different losses) to demonstrate the importance of the proposed three projection errors. While the reviewer doesn't provide specific examples of which losses to use, the suggestion is logically sound and points to a relevant area for further experimentation. The reviewer provides a clear *method* for investigation, making the claim 3. Without specific details, it's not 5, but the underlying logic is sound. Therefore, the reviewer provides a suggestion that can be followed, making it 3.", "helpfulness_rationale": "This review point is 5 for the authors in several ways. First, it critiques the authors' current evaluation setup (pretraining only on synthetic data), highlighting a potential flaw in their methodology. This provides valuable information for the authors to consider when revising their work. Second, the reviewer offers a concrete suggestion for an alternative evaluation strategy (pretraining on synthetic data but finetuned on realworld datasets with different losses). This provides a clear direction for the authors to take their work further and potentially gain a deeper understanding of the importance of the proposed projection errors. The suggestion is specific enough to guide the authors in their next steps, making it actionable and helpful. Therefore, the review point provides valuable insights and guidance, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the alternative method ('average over the subword representations') and provides a citation. This is a clear and direct suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions 'the embedding of the first subword token' and 'average over the subword representations,' clearly identifying the specific parts of the paper being addressed. It also specifies the alternative method, making it 5.", "verifiability_rationale": "The comment presents a suggestion ('It is also quite common...') but provides a clear justification by stating the difference from the proposed method ('...what is common in cases like that...') and cites a specific paper and footnote. This makes the suggestion wellsupported and verifiable.", "helpfulness_rationale": "The comment offers a concrete alternative implementation, which can be helpful for the authors to consider and potentially improve their method. While it might not be a major flaw, it provides a valuable point of comparison and suggests a different, common approach, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of using AUC for assessing the consistency between predicted scores and actual risk, which is a clear action. They then suggest conducting calibration curves as a solution, which is a concrete action with a clear goal. The reviewer also mentions proving the feasibility of the generated scoring system and discussing the difference between traditional and their method, further elaborating on the action.", "grounding_specificity_rationale": "The reviewer identifies the specific area for improvement as 'calibration' and specifies the issue as 'the consistency between predicted score and actual risk'. They also specify the type of scoring system as 'clinical scoring system' (differentiated from classification). Furthermore, the reviewer suggests conducting calibration curves and discussing the difference between traditional and their method, providing concrete actions and context. The reviewer even mentions 'proving the feasibility of the generated scoring system', which is a specific action related to demonstrating the practical value.", "verifiability_rationale": "The reviewer makes a claim that 'related studies are encouraged to conduct calibration curves to show the agreement' and further suggests that 'it would be better to prove the feasibility of the generated scoring system?'. The reviewer provides a justification for this claim by stating that 'consistency may be more crucial to the clinical scoring system'. The reviewer also suggests discussing the 'difference between the traditional method and our method', providing a specific action and a reason for it. The claim about conducting calibration curves is directly linked to the aspect of verifiability, as it aims to verify the claim about the importance of consistency.", "helpfulness_rationale": "The reviewer provides a clear suggestion to 'conducted calibration curves' and explains the 'importance of showing the agreement' and the 'consistency between predicted score and actual risk'. The reviewer also suggests 'proving the feasibility of the generated scoring system' and 'discussing the difference between the traditional method and our method', providing concrete actions and a clear rationale for why these actions are helpful. The reviewer's suggestion directly addresses the limitations of relying solely on AUC for evaluating scoring systems, particularly in clinical contexts."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific issue (no change in ID/OOD ranges/mean) and questions the implementation of conditions for DICE. This directly suggests a potential problem the authors should address. The implicit nature lies in the need for the authors to *check* if their sparsification method is correctly implemented and if their analysis of Lemma 2 is thorough. However, the reviewer doesn't explicitly state the action to take, making it somewhat implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 4,' 'ID,' 'OOD,' 'Lemma 2,' and 'DICE' when describing the issue. This clear identification of the specific part of the paper being addressed makes the grounding very explicit. The reviewer is not making an educated guess; they are directly referring to specific elements of their work.", "verifiability_rationale": "The reviewer makes a claim: 'From Figure 4, the range of ID and OOD seems not to be changed much by sparsification.' and 'Similarly, Lemma 2 requires approximately identical mean as the assumption. These conditions are crucial for DICE, but is not well discussed, eg., how to ensure DICE meet these conditions.' This claim is supported by the observation of Figure 4 and the statement about Lemma 2. While the reviewer doesn't provide *external* references, the *fact* that they are pointing out this discrepancy suggests it's a verifiable concern within their own work. The logical reasoning is that if the ranges didn't change and the conditions are crucial, this is a significant point that needs verification.", "helpfulness_rationale": "The reviewer's point is likely to be helpful for the authors. They are directly pointing out a potential issue in the implementation or analysis (lack of change in ranges/mean and missing discussion of conditions for DICE). This provides a clear direction for the authors to investigate and potentially improve their work. The implicit nature is that the authors need to *find* where the problem lies (check Figure 4, analyze Lemma 2, and verify the DICE conditions). However, the reviewer doesn't explicitly state the solution, making it somewhat implicit."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a clear and actionable list of suggestions. They explicitly state *what* is missing and *why* it's a problem. For example, they state 'besides, the experiments seem not too strong and fair to me' and 'I don't understand why all the baselines use the position kernels'. They also suggest *what* to do, such as 'use default settings of these baselines in the literature' and 'include missing baselines related to BO with discrete & categorial variables'. The reviewer's suggestions are not just general observations but specific, actionable steps for the authors to take.", "grounding_specificity_rationale": "While the reviewer points out several weaknesses in the experimental setup and the lack of certain baselines, the criticism remains somewhat general. The reviewer doesn't explicitly state which specific part of the paper (e.g., a particular section, table, or figure) is affected by these issues. For instance, while they mention 'position kernels', they don't specify *which* baseline uses them or *where* in the paper this is relevant. Similarly, they suggest 'missing baselines related to BO with discrete & categorial variables' but don't point to a specific area in the paper where these are supposed to be. The criticism is about the *type* of issue rather than pinpointing the exact location.", "verifiability_rationale": "The reviewer makes several claims in the review point. For example, they state 'Besides, the experiments seem not too strong and fair to me' and 'I don't understand why all the baselines use the position kernels'. These are statements that require justification and explanation. The reviewer also suggests improvements, such as 'use default settings of these baselines in the literature' and 'include missing baselines related to BO with discrete & categorial variables'. While the reviewer doesn't provide explicit citations for these claims, they offer logical reasoning and suggestions, indicating an attempt to verify the issues. The claims are not purely subjective opinions but are supported by the reviewer's analysis of the experimental setup and the suggested improvements.", "helpfulness_rationale": "The reviewer's review point is highly relevant to the paper's content. They clearly identify several weaknesses in the experimental methodology, the lack of certain baselines, and the absence of a discussion on limitations and societal impacts. The reviewer provides concrete suggestions for improvement, such as using default settings, including missing baselines, and addressing limitations and societal impacts. These suggestions are directly actionable and would significantly help the authors improve their draft. The reviewer's comments are not just a critique but also a roadmap for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point describes the observed trend of correlation after training but does not provide explicit or implicit instructions on how to *action* or improve the model based on this observation. It states what happened, not what to do next. Therefore, it lacks the explicit action or guidance needed for actionability.", "grounding_specificity_rationale": "The review point mentions 'training' and 'correlation' but does not specify *which part* of the paper or model this refers to. It lacks the precision needed to identify a specific section, table, figure, or unique element. While it identifies a general area of concern, it doesn't pinpoint the exact location of the issue.", "verifiability_rationale": "The review point describes an observed trend ('correlation after a short period of training, which goes up with more training iterations') but does not make a claim that requires verification. It's a descriptive statement about the training process, not a claim that needs supporting evidence or references. Therefore, it doesn't present a verifiable statement in the sense of the aspect definition.", "helpfulness_rationale": "The review point points out a potential issue (decreasing correlation initially) and a positive outcome (increasing correlation with more training). This could be helpful for the authors if they are tracking performance and see a similar trend. It highlights a potential area for concern and a positive development, which can guide further investigation. While it doesn't directly tell them *how* to fix it, it provides context and direction for their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a discrepancy or lack of insight, prompting the authors to seek more information. While the reviewer identifies a potential issue ('sparsity patterns do almost equally well'), they don't explicitly state what needs to be done next. The request for clarification ('Is this something unique to the sparsity detection problem or is this true for GNN in general?') indicates an intention to investigate, but not a specific action to take on their part. Therefore, while the reviewer identifies a problem, the lack of explicit instructions on how to address it makes the actionability borderline.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 4.3: presentation bits > representation bits.' This is a very specific reference within the paper, indicating that the reviewer has located the relevant section. Furthermore, the reviewer directly asks a question related to the content of this section ('presentation bits > representation bits'), specifying the area of concern. This demonstrates a clear understanding of the section and the specific aspect being discussed within it.", "verifiability_rationale": "The review point is a question, not a claim that requires verification. The reviewer is asking for clarification and context, not making a statement that needs to be supported by evidence. Therefore, verifiability is not applicable to this point.", "helpfulness_rationale": "The reviewer directly asks a question to improve the authors' understanding of a specific aspect of their work. The request for clarification and the focus on the relationship between 'presentation bits' and 'representation bits' are directly aimed at helping the authors improve their draft. The reviewer is providing context and asking a question that is directly relevant to the authors' work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4. This directly points out a specific, actionable omission in the mathematical steps. The reviewer clearly identifies what is missing and how it should be included, making this a concrete and actionable piece of feedback.", "grounding_specificity_rationale": "The reviewer refers to specific equations (Eqn. 3 and Eqn. 4) in their comment. This indicates that the authors can accurately pinpoint the section or part of the paper being addressed. While the *content* of the criticism (the missing \u03c4) is the primary focus, the explicit reference to equations provides a level of grounding.", "verifiability_rationale": "The reviewer makes a claim: 'The derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4'. This is a verifiable statement. If the authors were to check the derivation, they would likely find that the temperature parameter is indeed missing, supporting the reviewer's claim. While no external references are provided in this specific point, the claim itself is logically verifiable.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for improvement: '\u03c4 should be shown in a rigorous way or this paper mention it'. This actionable feedback directly addresses a potential weakness in the paper's presentation of the derivation. By pointing out the missing parameter and suggesting how it should be included, the reviewer provides valuable guidance for the authors, making this a 5 comment."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "1 (1 and Not Specific)", "verifiability_label": "X (X)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point explicitly states an action: 'add a citation' and provides a method: 'e.g. one of the standard works like 2'. While it doesn't specify the exact location, the phrasing strongly implies it relates to the current discussion on differential privacy, making it 3.", "grounding_specificity_rationale": "The review point mentions 'differential privacy' and suggests 'adding a citation'. However, it does not explicitly identify a specific section, table, figure, or unique aspect of the paper where this citation is needed. The reference is general and lacks precision on the paper's part.", "verifiability_rationale": "The review point is a suggestion to improve the paper by adding a citation. It does not make a claim about what is wrong with the current draft or provide a basis for verification. It is a suggestion, not a claim.", "helpfulness_rationale": "The review point suggests adding a citation to the topic of differential privacy. While it is a helpful suggestion that could improve the paper, it lacks specific details on how to implement this action. It does not provide guidance on where to add the citation, how to choose the citation, or how to integrate it into the text. Therefore, it is 3 but not highly detailed."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the *specific* additional assumption being referred to in the methodology section. This is explicit. The reviewer also points out the *wrong sign* in an inequality, which is a concrete action to take. Therefore, the reviewer provides clear guidance on how to improve the paper.", "grounding_specificity_rationale": "The reviewer doesn't explicitly *mention* a specific section or table in their criticism. They refer to \"the methodology section\" generally. While the *content* of the criticism is relevant to a specific part of the methodology, the reviewer doesn't pinpoint the exact location (section, table, line number) of where this assumption is clearly stated in the methodology. Therefore, it's not fully grounded. It's also not weakly grounded because the *content* of the criticism is relevant to a specific part of the methodology.", "verifiability_rationale": "The reviewer presents two distinct points as claims: \"this methodology requires significant additional assumptions\" and \"The only additional assumption is that the test set be drawn from the same distribution as the query set\". These are clear statements that could be argued as opinions or suggestions. The reviewer then provides specific evidence to support their claims: \"The only additional assumption is that the test set be drawn from the same distribution as the query set, which is natural for many machine learning settings where the train, validation, test sets are typically assumed to be from the same iid distribution.\" This provides justification.", "helpfulness_rationale": "The reviewer explicitly names the *section* they are referring to when making the assumption claim (\"the methodology section\"). This makes the criticism directly actionable. The reviewer clearly states the *specific* assumption they are referring to, making it easy for the author to understand the concern. The reviewer points out a potential issue with the assumptions, which could lead to a discussion or clarification in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a *lack of* something (experimental comparison and discussion) but doesn't directly instruct the authors on what to do or why they should do something. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer mentions specific methods and dimensionality reduction techniques (Shapely value explanations, CaCE, raw gradients, different dimensionality reduction techniques). However, the connection to the authors' specific work is not explicitly stated, and the reviewer doesn't clearly identify which part of their work is being addressed.", "verifiability_rationale": "The reviewer makes a claim about the paper lacking experimental comparison and discussion on dimensionality reduction. This claim needs to be verified by examining the paper. The reasoning for this claim is present, but the evidence (lack of comparison and discussion) is not explicitly stated within the review point itself.", "helpfulness_rationale": "The reviewer provides a clear critique of the paper, highlighting significant omissions. While the feedback is constructive, it doesn't directly provide concrete, actionable steps for the authors. The helpfulness lies in pointing out weaknesses rather than offering immediate solutions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the action of comparing Section 6 to prior work. While it doesn't specify the *how*, it clearly indicates the *what*. This makes it actionable as the authors know they need to perform a comparison.", "grounding_specificity_rationale": "The review point refers to 'Section 6' and 'prior efforts' without explicitly identifying specific parts or providing details. The authors have to infer the intended sections, making the grounding somewhat weak.", "verifiability_rationale": "The review point presents a claim that comparison is beneficial but lacks any supporting evidence or justification within this specific review. There are no logical arguments, references, or examples provided to back up the claim.", "helpfulness_rationale": "The review point is a clear suggestion to compare Section 6 to prior work. It identifies a potential improvement and guides the authors to take action. While it doesn't provide detailed steps on how to compare, it offers a clear direction."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states an assumption about the relationship between performance and the number of training scenarios and suggests an experiment to examine this relationship. This constitutes an explicit action with clear instructions on how to proceed. The action is also concrete, specifying the purpose of varying the number of scenarios.", "grounding_specificity_rationale": "The reviewer refers to 'scenarios used for training' and 'number of scenarios'. While not explicitly pointing to a specific section or table by number, the concept is reasonably clear within the context of the paper's description of the experimental setup. The reviewer implicitly refers to the fixed number (200) as the baseline for comparison. The suggestion to vary the number is also clear.", "verifiability_rationale": "The reviewer presents an assumption ('I would assume') about the relationship between performance and the number of scenarios. This can be considered a claim that needs to be supported. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to back up this assumption within the review point itself. The suggestion to examine the performance with different numbers is a potential verification method, but the claim itself lacks external justification.", "helpfulness_rationale": "The reviewer raises a relevant point about the potential impact of the number of training scenarios on performance. This is a valid concern for the authors and could guide their understanding and potential improvements. However, the review point lacks specific details on which scenarios to vary or how to analyze the performance changes. The suggestion is general and doesn't offer concrete steps for the authors to take, making it less immediately helpful."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what the authors should do. It raises a question about the impact of training data disturbances on the quality label, but it doesn't provide a direct action or suggestion on how to address this.", "grounding_specificity_rationale": "The review point mentions 'training data disturbances' and 'quality label' but does not specify the *nature* of the disturbances or the * aspect of the quality label that might be affected. It's a general statement rather than a precise identification of a specific part of the paper or a clear indication of what needs to be changed.", "verifiability_rationale": "The review point presents a question and a hypothesis but does not make a clear claim that can be verified. It's a speculative statement about potential issues rather than a definitive assertion supported by evidence or reasoning.", "helpfulness_rationale": "The review point raises a valid concern and asks a relevant question. It prompts the authors to consider the impact of potential disturbances on their model's performance. While it doesn't provide a direct solution, it is a relevant piece of feedback that can guide further investigation and experimentation."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point describes the experiments conducted but does not suggest specific actions or improvements the authors should take based on these experiments. It's a report of achievements, not constructive criticism.", "grounding_specificity_rationale": "The review point mentions the scope of the experiments (various settings, architectural mismatch, crossdomain imitation) but does not explicitly identify a specific part of the paper being addressed. It lacks the precision required for grounding.", "verifiability_rationale": "The review point is a factual statement about the authors' experiments and does not contain a claim that requires verification or justification.", "helpfulness_rationale": "The review point summarizes the authors' work but does not offer any constructive feedback, suggestions for improvement, or identify any weaknesses. It lacks the value needed to be considered helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential improvement area ('make the setting more fully strategic') but doesn't provide a specific, actionable step. While it implies the opponent isn't strategic, it's more of an observation than a direct instruction. The level of detail is missing, making it less actionable.", "grounding_specificity_rationale": "The review mentions 'strategic predictions' (l28) and 'opponent doesn't behave strategically,' indicating a specific concept and a critique of behavior. However, it doesn't explicitly pinpoint a specific part of the paper being addressed. The grounding is weak because it relies on implied understanding rather than direct references. The specificity is present in identifying the opponent's lack of strategic behavior, but the *specific aspect* of the model lacking this is unclear.", "verifiability_rationale": "The review point makes a judgment about the current state of the work ('this seems like only a very first step...') and the opponent's behavior ('...opponent doesn't behave strategically...'). However, it doesn't provide any evidence or reasoning to support these claims. It presents an opinion without backing, making it 1.", "helpfulness_rationale": "The review point identifies a potential improvement area ('make the setting more fully strategic') and points out a limitation in the current approach ('opponent doesn't behave strategically'). While it doesn't offer specific *howto* instructions, it does highlight a direction for improvement. It's not completely devoid of value, as it suggests a more comprehensive approach. The weakness is that it lacks concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential issue in Appendix A.2 but does not explicitly state what needs to be done or how to address it. It points to a lack of clarity, which is a vague and implicit action.", "grounding_specificity_rationale": "The comment specifies that Appendix A.2 does not illustrate the state space representation clearly. This identifies the specific part of the paper being addressed, making it fully grounded. It also specifies what is unclear (lack of illustration and clarity of state space representation), making it specific.", "verifiability_rationale": "The comment is a claim that Appendix A.2 does not illustrate the state space representation clearly. This claim is not supported by any evidence or reasoning within the review point itself. Therefore, it is 1.", "helpfulness_rationale": "The comment points out a potential area for improvement in the clarity of Appendix A.2. While it doesn't explicitly state how to improve it, it identifies a concrete issue that could hinder understanding. This suggests it could be helpful if the authors take action to improve the clarity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the authors' approach is limited to small or mediumscale problems and identifies the scalability issue as a key limitation. This is a clear and direct action the authors should take to address this problem, such as exploring decomposition techniques or alternative optimization methods. The action is also concrete in identifying the problem area (scalability of the approach).", "grounding_specificity_rationale": "The comment is a general statement about the limitations of the authors' approach regarding problem scale and solver performance. It does not specify a particular section, table, figure, or unique aspect of the paper where this limitation manifests. Therefore, the authors cannot confidently determine which part of the paper is being affected, making the grounding weak. However, the comment does specify what needs to be addressed (scalability issues), making it somewhat specific in that regard.", "verifiability_rationale": "The comment states a limitation of the authors' approach without providing any evidence, reasoning, or references to support this claim. It is a statement of observation, not a claim that requires verification. Therefore, it is not verifiable as it lacks supporting evidence or justification.", "helpfulness_rationale": "The comment identifies a practical limitation of the authors' approach, specifically its scalability issues. This is valuable information for the authors as it helps them understand the boundaries of their current method and plan for potential modifications. While it doesn't offer specific guidance on how to overcome the limitation, it does point to a relevant area for improvement, making it 3."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the bounded noise assumption and suggests broader alternatives but does not explicitly state an action or provide concrete steps for the author to take. The reviewer points out that the bounded noise assumption is somewhat restrictive and provides examples of alternative noise conditions, but the review does not directly instruct the author on how to modify their work based on this information.", "grounding_specificity_rationale": "The review point criticizes the bounded noise assumption in general and does not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. While it mentions stochastic optimization literature, noise conditions, and provides citations, it doesn't pinpoint where the bounded noise assumption is used in the author's work. The grounding is at a high level regarding the assumption itself, not a specific instance in the paper.", "verifiability_rationale": "The review point criticizes the bounded noise assumption and suggests broader alternatives. It does not make a claim that requires verification or justification. The reviewer is pointing out a limitation and offering a different perspective, but it doesn't present a statement that needs to be proven or supported with evidence within the context of the review itself. The comment is more of an observation and suggestion rather than a verifiable claim.", "helpfulness_rationale": "The review point identifies a potential limitation of the bounded noise assumption and offers broader alternatives. It provides citations, which can be helpful for the author to explore further. While it doesn't immediately tell the author how to address the bounded noise assumption, it points towards a relevant area of research and provides context. The feedback is relevant and points towards a direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue with the clarity of the motivation but does not explicitly state what action the authors should take to address this. While it points to a problem, it doesn't provide a clear, actionable step for the authors to improve their work.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or methodology. It is a general statement about the overall motivation, making the grounding specificity weak. The authors cannot pinpoint the exact location of the issue based on this review point.", "verifiability_rationale": "The review point expresses an opinion about the clarity of the motivation. While it could be supported by examples of unclear writing, the review point itself doesn't provide a logical reasoning or external reference to justify the claim. It's an assertion, not a claim that is 5.", "helpfulness_rationale": "The review point identifies a potential area for improvement (clarity of motivation) but does not offer specific suggestions or guidance on how to achieve this. It's a diagnostic statement rather than a prescriptive improvement suggestion, making it less helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the combination of existing techniques might be incremental. While this is a clear observation, it doesn't directly instruct the authors on what to do next. The reviewer identifies a potential area for improvement (combining techniques) but doesn't provide a specific action or method for achieving this. Therefore, while the observation is present, it lacks the explicit action required for high actionability.", "grounding_specificity_rationale": "The review point mentions specific techniques (Lykouris et al., 2018; weighted version of OFUL/Zhou et al., 2021; contextual linear bandits) and the concept of combining them. This provides some grounding as the authors can identify the specific parts of the paper being referenced. However, the reviewer doesn't pinpoint a specific section, table, or figure within the paper where this combination is being discussed or evaluated. The grounding is present but not fully precise, making it 3.", "verifiability_rationale": "The review point contains a claim: 'The fact that these results can be combined together is not surprising'. This is a statement of opinion. The reviewer provides specific references (Lykouris et al., 2018; Zhou et al., 2021; contextual linear bandits) to support the idea that these are existing techniques. These references serve as sufficient justification for the claim. Therefore, the claim is thoroughly supported by explicit and sufficient evidence, making it 5.", "helpfulness_rationale": "The review point offers a comment on the combination of existing techniques. While this is a relevant observation, it doesn't provide specific, actionable feedback on how the authors should improve their draft based on this combination. The reviewer points out a potential limitation but doesn't offer concrete steps or suggestions for the authors. The feedback is relevant but lacks the constructive nature needed for high helpfulness. Therefore, the feedback is 3 as it identifies a potential area for improvement, but it lacks specific guidance."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer identifies a potential area for improvement in the paper ('Multiscale modeling' and the 'aggregation operation after 'Integration') but does not provide specific details on how the authors should apply this feedback. The request is general and lacks concrete steps for the authors to take. The reviewer states 'The aggregation operation after \"Integration\" needs further clarification' without specifying what is unclear or how the authors should implement the aggregation. This makes the feedback less actionable.", "grounding_specificity_rationale": "The reviewer mentions the 'Integration' section within the 'Multiscale modeling' section, indicating some level of grounding. However, the reviewer does not specify the exact part of the 'Integration' section or table that needs clarification. The reference is somewhat vague, as the reviewer only mentions 'Integration' without pinpointing the specific element within it. The reviewer states 'The authors cannot confidently determine which part the comment addresses' which aligns with the definition of 'Weakly Grounded'.", "verifiability_rationale": "The reviewer makes a claim by stating that the aggregation operation after 'Integration' needs further clarification. However, the reviewer does not provide any evidence, examples, or logical reasoning to support this claim. The statement is presented as a suggestion for improvement without any backing. The reviewer states 'The comment contains a claim without any supporting evidence or justification', which aligns with the definition of '1'.", "helpfulness_rationale": "The reviewer identifies a potential issue in the paper ('Multiscale modeling' and the 'aggregation operation after 'Integration') which suggests a meaningful weakness. However, the feedback is presented as a general suggestion without providing specific details on how the authors should address the lack of clarity. While the feedback points to a relevant area for improvement, the lack of concrete suggestions limits its helpfulness. The reviewer states 'The comment fails to identify meaningful weaknesses or suggest improvements, leaving the authors with no actionable feedback' which aligns with the definition of 'Not Helpful'."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies the *type* of issues (writing, grammatical errors, mathematical symbol abuses) but does not provide explicit or concrete actions for the authors to take. It states the *problem* but lacks specific steps to address it. For example, it doesn't suggest rewriting a specific sentence or section, which would be necessary for actionability.", "grounding_specificity_rationale": "The review point broadly refers to the *entire paper* having writing issues and does not pinpoint a specific section, table, figure, or unique element of the paper where the problem lies. While it mentions 'grammatical errors' and 'abuses of mathematical symbols,' it doesn't specify *where* these occur within the paper. The grounding is weak because the authors can only *guess* where the issues are.", "verifiability_rationale": "The review point makes a claim about the paper containing 'severe writing issues such as grammatical errors, abuses of mathematical symbols, unclear sentences, etc.' This is a claim that requires verification. While the reviewer doesn't provide specific evidence *within the review point* to support this claim, the existence of grammatical errors and unclear sentences in a paper is generally verifiable through direct observation or feedback from others. The claim is 3 because it's based on observable characteristics of writing, even if the reviewer doesn't provide specific examples within their review.", "helpfulness_rationale": "The review point identifies a significant issue with the paper's writing quality but does not offer any specific guidance or suggestions for improvement. It points out the *problems* but doesn't provide actionable steps for the authors to take. For example, it doesn't suggest specific areas for clarification, potential revisions, or how to improve the flow of the text. While it highlights a need for change, it doesn't directly instruct the authors on how to make those changes, making it less directly helpful than a review with more specific suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification on the meaning of the dotted lines in the figures, which implies an implicit action: to understand how the untrained network results are represented. However, the reviewer does not provide concrete steps on how to interpret these lines or suggest concrete improvements to the figures themselves. The request for additional experiments (running untrained networks) is a concrete action, but the initial phrasing focuses on clarification.", "grounding_specificity_rationale": "The review point explicitly mentions 'Fig 3c' and 'Fig 3', indicating a clear grounding of the issue in specific parts of the paper. It also asks for clarification on whether the network was trained on random data and the normalization of the nonrandom data, which are specific aspects of the methodology. The phrasing 'Clarify: Random data (Fig 3c)' and 'Clarify: Random data (Fig 3)' clearly points to specific elements within the figures. The suggestion to show examples in the appendix is also a specific request for improvement.", "verifiability_rationale": "The review point contains claims about the interpretation of the figures and the methodology. For example, it claims that the dotted lines represent results for untrained networks. The 'verifiability' of this claim depends on whether the authors can provide evidence or justification. The request to run untrained networks and add the results to the figures and Table 1 is an attempt to verify this claim. However, the initial phrasing focuses on clarification rather than directly challenging or verifying the existing interpretation.", "helpfulness_rationale": "The review point is primarily focused on clarifying aspects of the figures and methodology. While the request to run untrained networks is a concrete suggestion, the initial phrasing emphasizes clarification rather than directly addressing a perceived weakness or providing actionable feedback on the presented results. The suggestions for clarification aim to improve understanding but don't directly resolve any identified issues with the current data or analysis. The request for examples in the appendix is a suggestion for improvement in presentation."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a lack of clarity regarding the meaning of '100 steps' in the context of the search model comparison. While the action is to clarify this ambiguity (an explicit action), the specific action of 'identifying the meaning of 100 steps' is not explicitly stated, making it somewhat vague. Therefore, it is not fully actionable as the action itself is not fully defined.", "grounding_specificity_rationale": "The review point asks a question about the meaning of '100 steps' without explicitly stating what part of the paper or what aspect of the search model comparison this '100 steps' refers to. The authors cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part, which is the clarification of the meaning of '100 steps'. Therefore, it is UnderSpecific.", "verifiability_rationale": "The review point itself does not present a claim that needs verification. It's a request for clarification. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point highlights a lack of clarity in the original text regarding the search model comparison. This lack of clarity makes it difficult for the authors to understand the experimental setup and potentially replicate or build upon the work. While the action is to clarify, the current phrasing doesn't explicitly state the conclusion (e.g., 'The 100 steps refer to 100 sampled strategies'). Therefore, it is 3 in identifying an issue but not fully resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the similarity to a prior VAE paper, indicating a weakness. However, the lack of specific details about the *how* makes it not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions \"motivation and goals\" and draws a parallel to a \"prior VAE paper.\" While they don't give a precise section number, the connection to a prior work is a strong indicator of some level of grounding. However, they don't specify a section, table, or unique element, making it weakly grounded.", "verifiability_rationale": "The reviewer makes a claim about the similarity to a prior VAE paper. However, they provide no evidence, reasoning, or references to support this claim, making it 1.", "helpfulness_rationale": "The reviewer raises a concern about the lack of novelty. While potentially helpful in highlighting limitations, the lack of specifics makes it 3 as it guides the authors to consider alternative approaches or focus areas."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the improvement is 'small' and suggests actions such as 'repeat the experiments' and 'conduct statistical significance analysis'. While the reviewer identifies an area for improvement and suggests actions, the lack of specific details on how to repeat the experiments or conduct the statistical analysis makes the action somewhat vague. The reviewer's suggestion to repeat experiments and conduct statistical analysis implies an action, but the current review point lacks the specifics needed to be fully actionable.", "grounding_specificity_rationale": "The reviewer mentions 'previous methods', 'Table 1 and Fig.5', and 'statistical significance'. While the reviewer identifies elements of the paper that are relevant to the criticism, they do not explicitly pinpoint a specific section, table, figure, or unique aspect. The reviewer's mention of 'Table 1 and Fig.5' and 'statistical significance' suggests they understand the context, but without explicitly naming the table or figure, the grounding is weak. The reviewer also claims the results are 'not reported' and the improvement is 'hard to know', which lacks specific details about the data and analysis.", "verifiability_rationale": "The reviewer makes a claim that the results are 'not reported' and the improvement is 'hard to know'. This constitutes a claim that needs verification. The reviewer suggests repeating experiments and conducting statistical significance analysis as ways to verify this claim, providing a path to verification. However, the claim itself, as stated in the review point, lacks immediate supporting evidence or justification within the review point itself.", "helpfulness_rationale": "The reviewer suggests repeating experiments and conducting statistical significance analysis as ways to improve the results. These suggestions are actionable and directly address the identified issue of limited statistical significance. While the suggestions are general, they provide a clear direction for improvement. The reviewer's suggestion to improve the paper's quality is constructive and aims to address a specific weakness. The reviewer's suggestions are directly related to improving the paper's quality and addressing the identified limitations."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"The method is evaluated only on the tasks from Meta World...\" This is an explicit statement about the evaluation scope and implies a clear action: to evaluate the method on Meta World. The reviewer also states \"I strongly recommend running experiments on a different benchmark such as Atari...\" This is a direct suggestion based on the identified limitation, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer mentions \"Meta World, a robotic manipulation domain.\" While this provides some grounding, it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper or method being evaluated. The reviewer argues that this lack of specificity makes it difficult to judge the generalizability of the results. The reviewer implies that the evaluation is *over* the entire Meta World benchmark, not a specific aspect of it.", "verifiability_rationale": "The reviewer makes the claim \"Hence, it is difficult to judge whether the results will generalize to other domains.\" The reviewer then provides a suggestion as evidence: \"I strongly recommend running experiments on a different benchmark such as Atari...\" This suggestion directly addresses the lack of generalizability and provides a concrete next step. The claim is supported by the reasoning provided.", "helpfulness_rationale": "The reviewer states \"The method is evaluated only on the tasks from Meta World...\" This is a clear statement of a limitation. The reviewer then suggests \"I strongly recommend running experiments on a different benchmark such as Atari...\" This is a direct and actionable recommendation based on the identified limitation. The reviewer's point is directly aimed at improving the method's robustness and generalizability."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a weakness ('a bit of analysis on what the model does is missing') and suggests a concrete action to take ('check the feedback/suggestions'). This directly tells the authors where to find the missing information, making it 5.", "grounding_specificity_rationale": "The review point mentions 'what the model does' and 'feedback/suggestions'. While it points to a general area, it doesn't specify a particular section, table, or unique element of the paper. The grounding is weak because the authors have to infer the specific part being referred to.", "verifiability_rationale": "The review point makes a claim by stating a weakness ('a bit of analysis on what the model does is missing') and provides a suggestion ('check the feedback/suggestions') as a form of justification. While not a direct citation, the suggestion points to a location where the information might be found, making it 3.", "helpfulness_rationale": "The review point is 5 because it directly identifies a potential weakness ('a bit of analysis on what the model does is missing') and provides a clear and actionable suggestion ('check the feedback/suggestions') for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a lack of clarity in the 'task setup'. It implies that the author needs to clarify how the EHR data is used and how far away the outcomes are from the input notes. This constitutes an explicit action, as the reviewer directly points out a missing element. However, the action is vague, as it doesn't specify the exact nature of the EHR data used (e.g., current admission, all previous admissions) or the timeframe for the outcomes.", "grounding_specificity_rationale": "The review point is 1 at all. It does not identify a specific part of the paper or methodology being addressed. The reviewer is broadly criticizing the 'task setup' without pointing to a particular section, table, or figure. Therefore, the grounding is weak as the authors cannot confidently determine which part of the paper is being discussed.", "verifiability_rationale": "The review point contains a claim in the form of a suggestion for improvement: 'The task setup is not described clearly.' However, this claim is not wellsupported. While the reviewer implies that the lack of clarity hinders understanding, there is no explicit justification or evidence provided to support this claim. The reasoning is implied but not explicitly stated, making it 3 but lacking strong supporting evidence.", "helpfulness_rationale": "The review point is 5. It directly points out a specific area where the author's work needs improvement \u2013 the clarity of the task setup. This is a concrete and actionable feedback that empowers the author to revisit their methodology description and ensure all necessary information is provided for others to understand and replicate their work. The feedback is directly linked to improving the quality of the draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the difference in convergence rates between the proposed algorithm (DMLCBO) and existing methods (SUSTAIN and MRBO). They then ask for an explanation of *why* DMLCBO does not achieve the same convergence rate. This is an implicit action, as the reviewer does not directly tell the authors to explain the theoretical difference. However, the request is very clear and actionable, prompting the authors to provide a justification for the observed discrepancy.", "grounding_specificity_rationale": "The reviewer points out a discrepancy in the convergence rate of the proposed algorithm. While they do not explicitly name a specific section, table, or figure in the paper, they are referring to a general issue with the algorithm's theoretical convergence rate. The connection to a specific part of the paper is implied but not clearly established. Therefore, the grounding is somewhat weak.", "verifiability_rationale": "The reviewer makes a claim: 'the authors are encouraged to discuss the reason why DMLCBO does not achieve it' (referring to the convergence rate). This claim requires justification. The reviewer is asking for an explanation, which is likely to be based on theoretical reasoning. This reasoning can be supported by citations to relevant literature, making the claim verifiable.", "helpfulness_rationale": "The reviewer's comment is focused on a specific theoretical aspect of the proposed algorithm and asks a direct question about it. They are suggesting that the authors should provide an explanation for the observed convergence rate. This is a focused and actionable suggestion that directly addresses a potential area for improvement or clarification in the authors' work. While not a broad critique, it is very helpful in guiding the authors to consider the theoretical underpinnings of their algorithm."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the 'approach section' is missing. While they don't specify what is missing within the section, the absence of a section dedicated to describing the methodology is a clear indication of an actionable omission. The reviewer implies the authors should look for this section in the main paper.", "grounding_specificity_rationale": "The reviewer points to the 'approach section' as the missing element. While they don't specify *what* is missing within this section, they clearly identify its location in the main paper. This implies a level of grounding as the authors can infer the section where the information should be. However, without specific details about the missing content, the specificity is limited.", "verifiability_rationale": "The reviewer's comment is a factual statement: 'The approach section is missing.' There is X being made or judgment being offered. The comment is a description of a factual absence, not a claim that requires verification.", "helpfulness_rationale": "The reviewer's comment highlights a significant omission in the main paper: the absence of a section detailing the approach. This omission is a valid concern for the authors trying to understand the paper. While the comment doesn't provide specific feedback *within* the missing section, it points to a crucial missing piece of information that could hinder the authors' understanding and ability to build upon the work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the weakness in the introduction and provides a clear suggestion for improvement. The action is to strengthen the statement about biological plausibility, and the implementation is to make the statement more impactful.", "grounding_specificity_rationale": "The reviewer accurately identifies the specific claim in the introduction regarding the biological plausibility of backpropagation and pinpoints the exact section where this claim is made. The grounding is 'Full Grounding' as the section is explicitly mentioned. The specificity is high as the reviewer clearly states that the statement is 'too weak' and lacks clarity.", "verifiability_rationale": "The reviewer makes a claim that the statement in the introduction is 'too weak' and lacks clarity. While the reviewer doesn't provide a direct citation in this review point, the context implies that the lack of clarity stems from the ongoing debate about biological plausibility, which is a generally accepted concept. Therefore, the claim is 3 as it points to a lack of clarity that can be supported by the existing understanding of the topic.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement in the introduction. They identify a specific weakness (the statement being too weak) and offer a constructive suggestion (make the statement more impactful). This directly helps the authors address the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement is explicit about the heuristic design of the modulator but does not provide concrete actions or guidance on how to improve it. It implies a potential issue with scalability and hyperparameter tuning but does not specify how to address these.", "grounding_specificity_rationale": "The review mentions 'modulator' and 'hyperparameter tuning' without explicitly identifying the specific part of the paper or model these relate to. It also does not specify what is wrong or missing in that part.", "verifiability_rationale": "The review contains claims about the modulator being 'heuristically designed' and a potential issue with 'scalability and hyperparameter tuning' but does not provide any logical reasoning, common knowledge, or external references to support these claims.", "helpfulness_rationale": "The review points out a potential issue with a 'modulator' and suggests it might be related to 'scalability and hyperparameter tuning' but does not offer any specific advice or guidance on how to address this."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The statement about 'practical amount of data' implies a limitation of directly using f_R/f_P, but it doesn't explicitly state an action or provide details on how to improve.", "grounding_specificity_rationale": "The review refers to 'f_R and f_P' generally and doesn't specify a particular section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer makes a claim about the limitations of less informed f_R/f_P, which could be supported by evidence, though the specific evidence isn't provided in the review point itself.", "helpfulness_rationale": "The review identifies a potential issue with f_R/f_P but doesn't offer concrete, actionable advice or insights on how to improve the draft based on this information."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the necessity of obtaining labeled data for imitation learning and mentions the lack of experiments on the difficulty of obtaining this data and the impact of its size. This provides a clear action for the authors to take, which is to conduct such experiments. While the reviewer doesn't provide specific details on *how* to obtain the data, the need for it is clear.", "grounding_specificity_rationale": "The review point mentions 'labeled data' and 'imitation learning' in general terms. It does not explicitly refer to a specific part, table, figure, or unique aspect of the paper being addressed. The reviewer is discussing a general gap in the application of imitation learning, not a specific issue within a particular section of the paper.", "verifiability_rationale": "The review point clearly identifies a claim: 'there are no experiments on whether there are any difficulties in obtaining the corresponding data, and how the performance changes depending on the size of the labeled data.' This claim is not explicitly supported by any examples or references. While the reviewer points out a gap in the experimental evaluation, they do not provide specific evidence to back up their assertion about the difficulties or the impact on performance.", "helpfulness_rationale": "The review point is specific about a missing experimental component related to the application of imitation learning. It highlights the lack of experiments on labeled data and its size, which is a concrete area for improvement. While the reviewer doesn't provide specific suggestions for the experiments, they clearly point out a gap in the current evaluation process, which is valuable information for the authors."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a gap in the paper's discussion by questioning the connection between overparameterization, memorization, and generalization, specifically regarding the implications for generalization bounds. While the reviewer identifies a problem in the paper's argument, they do not explicitly suggest a concrete action or modification to address this gap within the review itself. The reviewer is highlighting a missing piece in the paper's narrative.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'generalization bounds' and questions the connection between the paper's findings on overparameterized networks and robust memorization to robust generalization. They identify a specific area in the paper (the connection to generalization bounds) and highlight a lack of clarity regarding this connection. The reviewer can accurately pinpoint the area of discussion and clearly identifies the issue.", "verifiability_rationale": "The reviewer does not make a claim that can be verified. They are raising a question about the implications of existing knowledge (the connection between memorization and generalization) for the paper's theoretical framing. The reviewer is not presenting a claim that requires logical reasoning, common knowledge, or external references to be supported. The statement is a question about the interpretation of existing results.", "helpfulness_rationale": "The reviewer's point is highly relevant to the paper's theoretical framing. They question a potential weakness in the paper's argument regarding the connection between memorization and generalization, and they highlight the importance of considering generalization bounds. This raises a valuable point for the authors to consider and potentially address in future revisions or discussions about the paper's theoretical underpinnings. The reviewer's question is directly related to the paper's core arguments and could guide future research directions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states, \"it does not thoroughly explore the implications of their proposed method for other NLP tasks.\" This indicates a lack of clear action. The authors are informed about a limitation but not given a specific next step.", "grounding_specificity_rationale": "The comment refers to \"their proposed method\" generally, without pointing to a specific section, table, or figure. The issue is broad (\"thoroughly explore the implications...for other NLP tasks\") rather than pinpointing a specific element within the method's description.", "verifiability_rationale": "The review states, \"this somewhat limits the generalizability of the results.\" This is a statement of a problem or limitation, which can be considered a *judgment* about the paper. However, it doesn't *explain* *why* this limits generalizability or *suggest* *how* to address it. There's no external reference or logical reasoning provided.", "helpfulness_rationale": "The review points out a valid limitation: the narrow focus of the experiments. However, it doesn't suggest concrete improvements or alternative experimental setups. The impact is limited to informing the authors of a potential weakness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential ambiguity related to the term \"certificate\" and specifically mentions a location (line 267). This constitutes an explicit action or suggestion, as the reviewer identifies a potential issue that the authors should be aware of. However, the action itself is vague as it doesn't specify how to resolve the ambiguity or what changes are needed.", "grounding_specificity_rationale": "The reviewer explicitly mentions the term \"certificate\" and its location (line 267) within the paper. This demonstrates a clear identification of the specific part of the paper being addressed, which is a key aspect of grounding specificity. However, the comment does not specify what is wrong with the use of \"certificate\" or what alternative interpretations might exist, making it somewhat specific in identifying the *what* but less specific in explaining the *why* or *how*.", "verifiability_rationale": "The reviewer states that the use of \"certificate\" might be misinterpreted due to its meaning in complexity theory. This constitutes a claim that requires verification. The reviewer provides a logical reasoning by connecting the potential ambiguity to the established meaning of \"certificate\" in a specific field. While the reviewer doesn't provide external references, the logical connection to a wellknown concept makes the claim verifiable. The reasoning is present, making it 3.", "helpfulness_rationale": "The reviewer identifies a potential source of confusion related to the terminology \"certificate\" and its potential misinterpretation. This is a valuable piece of feedback as it highlights a fundamental aspect of clarity in academic writing. While the reviewer doesn't offer specific solutions, pointing out a potential ambiguity is helpful for the authors to ensure their message is understood correctly. The impact is significant as it addresses a core principle of effective communication."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the relevance of untrained networks and suggests a comparison, which is an explicit action. However, the reviewer does not specify *which* untrained networks to compare with or *how* to implement the comparison, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'untrained NNs (like deep image prior Ulyanov et al., CVPR 2018)' and 'inverse problems', providing specific examples and a general area of comparison. However, the reviewer does not explicitly point to a specific section, table, or unique aspect of the paper where this comparison should be made, making the grounding somewhat underspecific.", "verifiability_rationale": "The reviewer makes a judgment about the relevance of untrained networks for inverse problems and suggests a comparison, which constitutes a claim. The reviewer provides a citation for a relevant work ('deep image prior Ulyanov et al., CVPR 2018'), which supports the claim. However, the reviewer does not provide detailed reasoning or examples of how this comparison would be made or what the implications would be, making the verification somewhat incomplete.", "helpfulness_rationale": "The reviewer points out a relevant area (OOD generalization) and suggests a comparison with a class of methods (untrained networks) that could potentially improve the paper's contribution or address a potential weakness. While the suggestions are broad, they offer a valuable direction for improvement. The reviewer does not provide specific details on which untrained networks to compare or how to implement the comparison, which limits the immediate helpfulness for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point suggests *what* experiments to conduct (deeper networks and other network structures) but does not explicitly state *how* to conduct them. While it implies further experimentation, the specific steps or modifications needed are not detailed. The references provided are relevant but do not constitute a direct action for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions 'deeper networks' and 'other network structures' and provides specific examples like 'ResNet50' and 'MobileNet'. This clearly identifies the specific aspect of the paper being addressed and the nature of the suggested improvement. The authors can directly infer the need for experiments with these specific architectures.", "verifiability_rationale": "The review point contains a claim (a need for more experiments) and provides supporting references to justify the suggestion of exploring different network architectures. The reasoning is logical, and the references are relevant to the field, making the claim verifiable.", "helpfulness_rationale": "The review point directly addresses a common need for more comprehensive experimentation in machine learning papers. Suggesting specific architectures like ResNet50 and MobileNet provides concrete directions for improvement. While it doesn't offer *how* to implement the experiments, it clearly identifies a weakness and offers a clear improvement path, making it helpful for the authors to understand where their current experiments might be limited."}
{"actionability_label": "1", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point states a lack of clarity but does not provide any explicit or concrete actions for the authors to take. The reviewer is pointing out a problem, not suggesting a solution.", "grounding_specificity_rationale": "The review point refers to 'the proposed sample selection mechanism' and 'label distribution' without specifying which section or table of the paper these concepts relate to. The authors cannot identify the specific part of the paper being addressed.", "verifiability_rationale": "The review point states a lack of clarity regarding the proposed mechanism's effect on the label distribution. There is X made, let alone any supporting evidence or logical reasoning.", "helpfulness_rationale": "The review point identifies a problem (lack of clarity) but does not offer any suggestions or guidance on how to improve the draft. The authors are left with an unaddressed issue without any proposed solutions."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the limitation of evaluating only 'two relatively old and small models'. This clearly identifies a specific aspect of the evaluation that needs improvement. The reviewer directly points out a concrete issue that can be directly addressed by expanding the scope of the evaluation.", "grounding_specificity_rationale": "The comment refers to the 'results/analysis' in general, without specifying a particular section, table, or figure. While it identifies the *models* being evaluated, it doesn't pinpoint the exact part of the paper or analysis being limited. Therefore, the grounding is weak as the authors cannot confidently determine which specific aspect is being addressed beyond a general area.", "verifiability_rationale": "The comment identifies a limitation in the evaluation scope but doesn't provide a claim that requires verification or justification. It's more of a statement of fact about the current evaluation. There's no explicit claim being made that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The comment provides a clear direction for improvement by highlighting the limited scope of the evaluation. It suggests expanding the evaluation to include more models. This is helpful as it guides the authors on a specific area to focus on to enhance their work. While it doesn't offer a specific solution, it points towards a concrete action."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their belief that the proxlinear subproblem can be reformulated using the conjugate function. They also suggest that this reformulation makes the motivation of Algorithm 1 unclear. This indicates a direct identification of a potential improvement and its connection to Algorithm 1, making it explicit. While the reviewer doesn't provide the reformulation details, the suggestion itself is a concrete action.", "grounding_specificity_rationale": "The reviewer directly addresses the proxlinear subproblem mentioned in Algorithm 1, which is a specific part of the paper. They also mention 'Eq.(1)' to pinpoint the location of the problem being discussed. The reviewer further elaborates on the implications of the suggested reformulation for the motivation of Algorithm 1. This demonstrates a clear and precise identification of the relevant part and its implications, indicating high grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the relationship between the proxlinear subproblem and the conjugate function. They also provide a reasoning for why this reformulation might make the motivation of Algorithm 1 unclear. While the reviewer doesn't provide a detailed proof or external reference within the review point itself, the claim and the accompanying reasoning constitute a verifiable statement based on logical reasoning and the provided context. The suggestion of a reformulation implies a logical connection to the motivation of Algorithm 1.", "helpfulness_rationale": "The reviewer points out a potential simplification in the proxlinear subproblem using the conjugate function. They argue that this simplification could make the motivation of Algorithm 1 less clear. This directly addresses a potential weakness or area for improvement in Algorithm 1 and provides a clear rationale for why it might be helpful. The reviewer's comment is directly actionable and addresses a specific aspect of the algorithm's motivation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the relationship between Knowledge Distillation (KD) and Label Smoothing (LS) and provides specific conditions under which this relationship holds. While the connection is presented as a fact ('I believe'), the reviewer implies it's a relevant observation for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions 'Knowledge Distillation (KD)', 'Label Smoothing (LS)', and even the specific conditions 'uniformly distributed teacher network' and 'temperature is set at 1'. This provides clear grounding for the statement.", "verifiability_rationale": "The review point makes a claim ('KD can be viewed as a special form of LS'). However, it does not provide a detailed explanation, proof, or specific citation to support this claim. While the conditions are mentioned, the reviewer doesn't elaborate on how the equivalence holds under these conditions. The phrasing 'I believe' indicates uncertainty about the claim's validity.", "helpfulness_rationale": "The review point offers a conceptual insight into the relationship between KD and LS. While it's not a direct instruction on how to improve the authors' draft, understanding this relationship could potentially guide the authors in their own analysis and choices when applying these techniques. It provides a higherlevel understanding rather than a concrete, actionable step."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem (outofdate methods, small datasets) but does not explicitly state how the authors should address it. While the direction is implied (using more recent methods and larger datasets), the specific actions or modifications are not detailed. The reviewer suggests improvements but doesn't provide a clear path forward for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions 'dynamicpruning methods' and 'ImageNet', indicating a clear reference to specific parts of the paper. It also states the goal of 'further verify the effectiveness', which further grounds the comment. The reviewer accurately identifies the area of concern and the desired outcome.", "verifiability_rationale": "The review point contains a claim that 'No.3. 2021. Competing dynamicpruning methods are kind of outofdate. More recent works should be included. Only results on small scale datasets are provided. Results on large scale datasets including ImageNet should be included to further verify the effectiveness of the proposed method.' This claim requires justification. While the reviewer states the need for more recent work and larger datasets, they do not provide logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a suggestion for improvement rather than a claim that needs verification.", "helpfulness_rationale": "The review point raises a valid concern about the limitations of the current evaluation and suggests improvements. It points out the need for more recent methods and evaluation on larger datasets. This is a relevant point for the authors to consider and can guide their future work. However, the review point lacks specific suggestions on how to implement these changes or what specific experiments to conduct. It identifies a problem but doesn't provide concrete steps for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'can authors please throw light on why the performance degrades' and asks for an explanation of this phenomenon. This is a direct request for action, making it 5. The reviewer identifies the specific area of the results (FBN, table 5) and the characteristics of the data (missing/wrong/redundant) as the basis for the performance degradation, making the action explicit.", "grounding_specificity_rationale": "The reviewer refers to 'FBN results (table 5)' and specifically asks about 'missing/wrong/redundant' information. This direct reference to a specific part of the paper and the characteristics of the data demonstrates strong grounding. The reviewer can confidently identify the section and the relevant aspects being discussed.", "verifiability_rationale": "The reviewer states 'performance degrades' and asks for an explanation. This is a claim that requires verification. While the review point itself doesn't provide evidence, the request implies a logical connection and a need for justification. The reviewer is asking 'why' this happens, which requires reasoning and potentially references within the paper's methodology or experiments to understand the mechanism.", "helpfulness_rationale": "The reviewer is asking for an explanation of a phenomenon they observed (performance degradation) in the FBN results. This is a clear and direct request for improvement, making it 5. The reviewer is specifically asking about the impact of certain data characteristics on the model's performance, highlighting a potential area of confusion or lack of understanding."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'Make the captions more descriptive' which is a direct and clear action for the authors to take. They know exactly what needs to be improved.", "grounding_specificity_rationale": "The reviewer specifically mentions 'the captions' and states 'more descriptive', indicating a clear understanding of the part of the paper being addressed and the nature of the desired improvement.", "verifiability_rationale": "The reviewer does not make a claim about what is wrong with the captions or the paper. Instead, they suggest improvements. Therefore, it fits the 'X' category as defined in the provided guidelines.", "helpfulness_rationale": "The reviewer provides specific feedback on the figure captions, indicating a clear understanding of what needs improvement. While they don't explicitly claim the captions are wrong, the suggestion to make them more descriptive directly points to an area for authors to enhance their work. The location discrepancy and the need to explain the 'scramble network' also implicitly suggest areas for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their concern: \"Why is this particular dimension of difficulty interesting?\" This is a clear and direct identification of a lack of motivation for the chosen background images. The reviewer also points out that the choice is \"not well motivated,\" providing a specific reason for their dissatisfaction. This explicitness and the clear direction for improvement make the comment actionable.", "grounding_specificity_rationale": "The reviewer mentions \"CIFAR images\" and \"difficulties,\" which grounds the criticism somewhat in the paper's content. However, the reviewer does not explicitly state which part of the paper (e.g., a specific section or table) is being criticized for using these images as backgrounds. The criticism is more general, focusing on the *effect* of this choice rather than a specific instance. Therefore, while the topic is grounded, the specific element being addressed is not clearly identified.", "verifiability_rationale": "The reviewer states that the choice is \"not well motivated\" and asks \"Why is this particular dimension of difficulty interesting?\" This is a statement of opinion without providing any specific evidence or examples to support their claim. There is no logical reasoning, common knowledge, or external references provided to back up their assertion. The claim itself is that the motivation is lacking, but there's no verification of *why* it's lacking.", "helpfulness_rationale": "The reviewer's comment is relevant to the paper's goals as it points out a potential flaw in the experimental setup (using random CIFAR images as backgrounds). However, the comment is not particularly helpful because it does not offer a concrete suggestion or alternative for what *should* be used instead. The reviewer asks \"Why is this particular dimension of difficulty interesting?\" but does not propose a different dimension of difficulty that *would* be interesting or relevant. Without a specific direction for improvement, the comment is more of a critique than a constructive suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'minimizing the averaged loss across the noise injected models does not ensure the flatness of the minima.' This is a clear and direct criticism. The reviewer also provides a concrete suggestion: 'To claim that the minima found by minimizing the loss in Eq (3), the analysis on the losses of the noiseinjected models after training is required.' This indicates a clear next step for the authors. Therefore, the comment is 5 as it directly identifies a problem and suggests a solution.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the noiseinjected models' and refers to the loss function in Eq (3). This clearly identifies the specific part of the paper being addressed. The comment is fully grounded as it accurately pinpoints the section and equation being discussed. The reviewer also specifies 'the losses of the noiseinjected models after training' as the necessary analysis, making the grounding very specific.", "verifiability_rationale": "The reviewer makes a clear claim: 'minimizing the averaged loss across the noise injected models does not ensure the flatness of the minima.' This is a statement that can be verified. The reviewer provides a logical reasoning for this claim: 'The reviewer argues that minimizing the average loss might not guarantee flatness in the context of noiseinjected models.' While the reviewer doesn't provide external references, the reasoning is based on the understanding of flat minima and the described training process. The claim is thoroughly supported within the context of the paper. Therefore, the claim is 5.", "helpfulness_rationale": "The reviewer clearly identifies a gap in the analysis regarding flatness. They provide a specific suggestion: 'To claim that the minima found by minimizing the loss in Eq (3), the analysis on the losses of the noiseinjected models after training is required.' This is a valuable suggestion that directly addresses the identified issue. The reviewer's point is clear, concise, and directly actionable for the authors. It guides the authors to perform additional analysis that is directly relevant to the claim being made. Therefore, the comment is 5 as it directly points to a flaw in the methodology and offers a clear next step for the authors to take to validate their claims about flat minima."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'the text inside the figure and the labels are too small to read without zooming'. This is a direct and actionable statement. The reviewer also provides a concrete solution: 'This text should be roughly the same size as the manuscript text'. This clearly indicates an action the authors should take.", "grounding_specificity_rationale": "The reviewer directly references the 'text inside the figure and the labels'. This is a very specific reference, indicating strong grounding. They are not making an educated guess or referring to a general concept; they are pinpointing a specific part of the paper.", "verifiability_rationale": "The reviewer points out a factual issue: 'the text inside the figure and the labels are too small to read without zooming'. This is a verifiable observation. While the reviewer doesn't offer a solution or justification for *why* this is a problem, the statement itself is verifiable. The underlying issue is the lack of consistency in text size, which is a verifiable problem in the presentation.", "helpfulness_rationale": "The reviewer clearly identifies a significant issue: the readability of the text in the figure. They provide a direct and actionable suggestion to make it the same size as the manuscript text. This is a clear and constructive piece of feedback that directly empowers the authors to improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a potential weakness ('lack of clarity in motivation') but does not specify *how* the motivation should be improved or what specific aspects are unclear. It's a general statement about the introduction, lacking concrete action items for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'the motivation' in relation to the introduction, which can be interpreted as implicitly referring to a specific part. However, the comment does not explicitly state which specific section or element of the introduction is unclear. The grounding is weak because the authors cannot confidently determine the referenced part. The comment also does not specify what needs to be addressed in this part, making it not specific.", "verifiability_rationale": "The comment 'The motivation is not clear at all' is a statement of opinion or judgment about the paper's introduction. It does not contain a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support or justify this statement.", "helpfulness_rationale": "The comment identifies a potential area for improvement ('lack of clarity in motivation') but does not provide any specific suggestions or guidance on how to address this issue. The authors are left with a general observation rather than concrete feedback on how to revise the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a difference in feature positions but doesn't explicitly state what needs to be changed or how to implement the change. It's a statement of observation rather than a direct instruction.", "grounding_specificity_rationale": "The review discusses 'features' and 'categories' without specifying which part of the paper or element is being referred to. It lacks explicit identification of the specific area being addressed.", "verifiability_rationale": "The review states a claim about the inconsistency of feature positions but provides no evidence, logical reasoning, or references to support this observation.", "helpfulness_rationale": "The review identifies a potential issue with feature organization but offers a general observation without specific suggestions or actionable steps for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the problem (insufficient validation) and the goal (validate the alignment). However, it lacks specific details on how this validation should be performed, making it vague on the implementation.", "grounding_specificity_rationale": "The comment explicitly mentions 'relabelled reward data' and 'human annotator judgments', accurately pinpointing the specific parts of the paper being addressed. It also clearly identifies the issue as 'insufficiently validated'. This indicates strong grounding and specificity.", "verifiability_rationale": "The review point itself is a statement of a problem ('alignment of relabeled reward data with human annotator judgments remains insufficiently validated') and does not contain a claim that requires verification. Therefore, it is classified as 'X'.", "helpfulness_rationale": "The comment identifies a crucial issue (alignment validation) that is directly relevant to the authors. It highlights a potential weakness in their work and points towards an area that needs attention. While it doesn't offer a solution, it effectively highlights a problem that needs addressing."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states actions the authors should take, such as replacing natural language descriptions with notation and adding breakout diagrams showing attention mechanisms. These are direct and actionable suggestions for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'section 4' as the area needing improvement, which provides some grounding. However, they do not specify the exact part within section 4 (e.g., a particular table, figure, or unique element) that requires improvement. The suggestion to add 'breakout diagrams showing the attention mechanisms' is a general improvement suggestion rather than a specific fix for a known issue within that section.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement, framed as helpful feedback. It does not contain a claim that requires verification. There is no logical reasoning, common knowledge, or external references being offered. It is a constructive suggestion based on the reviewer's understanding of the paper's presentation.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as replacing natural language descriptions with notation and adding breakout diagrams showing attention mechanisms. These suggestions are directly actionable and likely to be beneficial for the authors. The reviewer's tone is constructive and suggests a desire to help the authors improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a limitation in the method's generalizability due to the limited number of molecules used for training. While it points out a potential issue, it doesn't explicitly state what action the author should take or how to address it. The reviewer mentions 'indistribution testing' as a limitation, which is a specific detail, but the suggested solution of 'training for each molecule individually' is not a concrete, actionable step that the author can directly implement. The reviewer identifies the *problem* but doesn't provide a clear, actionable path to solve it.", "grounding_specificity_rationale": "The review point explicitly mentions 'a very limited number of molecules' and 'indistribution testing' as specific aspects of the paper being addressed. These are clear references to specific sections, tables, or unique elements within the paper. The reviewer also explains *why* these are limitations, connecting them to the need for individualized training. This demonstrates a clear understanding of the specific part of the paper being discussed and the issues within it.", "verifiability_rationale": "The review point contains a claim: 'I think the value of this method would be limited if it needs to train for each molecule individually.' This is a statement of opinion. The reviewer then provides a logical reasoning to support this claim by connecting it to the 'limited number of molecules' and 'indistribution testing.' They explain *why* training individually would be a limitation, providing a clear justification for their claim.", "helpfulness_rationale": "The review point raises a valid concern about the method's value given the limited training data and indistribution testing. While it doesn't offer a solution or specific advice on how to improve the method, it highlights a potential limitation that the author should be aware of. Understanding these limitations is helpful for assessing the scope and potential biases of the method. The reviewer's point contributes to a critical evaluation of the method, but it doesn't directly guide the author on how to proceed. Therefore, it's 3 as it points out a potential issue without providing a complete solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly states that 'symbols are a little bit complicated'. This indicates an explicit action or suggestion that the authors should make the symbols easier to understand. However, the point is vague about *which* symbols are complicated and doesn't provide specific guidance on how to improve their clarity. Therefore, while it suggests an actionable step, the specifics are lacking.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or the symbols being discussed. It makes a general statement about the complexity of 'symbols' without pinpointing their location or nature. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part. The specificity is also weak because the point does not detail what is meant by 'complicated' or how the symbols are used. This aligns with the definition of '3' where the authors cannot confidently identify the referenced part and the issue is not clearly specified.", "verifiability_rationale": "The review point contains a claim: 'symbols are a little bit complicated'. However, it does not provide any evidence or reasoning to support this claim. There are no references to external works, logical arguments, or common knowledge to back up the assertion that symbols are complicated. Therefore, the claim is not verifiable based on the information provided.", "helpfulness_rationale": "The review point identifies a potential issue ('symbols are a little bit complicated') but does not offer any suggestions or actions to address it. It is a diagnosis without a cure. The authors are left wondering what the problem is and how to fix it, but the review point doesn't provide any concrete steps. Therefore, it does not help the authors improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer requests an explanation for a red line in Figure 3. This is an explicit request for action, as the reviewer wants to understand how to interpret or address the line. However, the review point itself does not contain the explanation or the action of identifying the source of the test data and the concept of ground truth.", "grounding_specificity_rationale": "The reviewer explicitly asks 'Where does the test data come from?' and 'Do you have a ground truth?'. These are very specific questions directly addressing the source and nature of the data being used. This indicates a high level of grounding specificity as the reviewer is asking about the concrete elements of the data used in the analysis or experiment represented by the red line.", "verifiability_rationale": "The reviewer is making a statement (a request for clarification) rather than making a claim that needs verification. While the request implies a need for information, the review point itself does not contain a verifiable claim. The *ability* to answer the question is what would make it verifiable, not the question itself in its current form.", "helpfulness_rationale": "The reviewer's request to understand the red line in Figure 3 is directly related to improving the draft. Understanding visual elements is crucial for a thorough review and constructive feedback. However, the review point itself does not contain the explanation or the action of identifying the source of the test data and the concept of ground truth, which are necessary for the reviewer to understand the figure."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about the role of periodicity, which is a direct and actionable request. They also suggest adding periodicity to the spectral kernel as a way to test this hypothesis, providing a concrete target for investigation. While the action of identifying the question is implicit, the question itself is clear and points towards a specific area of improvement.", "grounding_specificity_rationale": "The reviewer clearly identifies 'periodicity' and 'compositionality' as the key concepts being discussed. They explicitly compare the model's ability to capture periodic relationships with its ability to capture relationships more generally. This strong grounding makes it clear which specific aspects of the model they are referring to.", "verifiability_rationale": "The reviewer presents a question about the extent to which periodicity is sufficient, rather than requiring the full framework of compositionality. While the question itself doesn't provide a definitive answer, it is a clear and verifiable claim that the authors can investigate through experimentation. The reviewer is asking a question that can be directly addressed by further analysis of the model's performance on periodic tasks.", "helpfulness_rationale": "The reviewer's comment is 5. They directly ask a question that is relevant to the authors' work and provide a specific suggestion for an experiment (adding periodicity to the spectral kernel) to investigate this question. This is a clear direction for the authors to take their research forward and helps them focus their efforts on a specific aspect of their model's capabilities."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment is a general statement about the paper's writing quality and does not specify any particular aspect or section of the paper that needs improvement. While it identifies a problem, it lacks the explicit and concrete instructions necessary for actionability. The reviewer suggests the paper is 'not very wellwritten' and 'possibly hurriedly written,' but does not indicate what needs to be changed or how to achieve better writing quality.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper or element that needs improvement. It is a general statement about the overall writing quality. While the reviewer can infer that the issue lies in the writing, they cannot pinpoint the exact section, table, figure, or unique aspect being addressed. The comment lacks the specificity required to guide targeted changes.", "verifiability_rationale": "The comment contains a claim ('The paper is not very wellwritten...') but does not provide any supporting evidence, logical reasoning, or external references. The reviewer states a negative assessment of the paper's writing quality but does not explain *why* they believe this or provide any context or examples to support their claim. The verifiability is low because there is no justification for the statement.", "helpfulness_rationale": "The comment identifies a weakness in the paper ('not very wellwritten') but does not provide any specific suggestions or actions for improvement. While the reviewer points out a problem, they do not offer concrete steps or guidance on how to address it. The comment is vague and lacks actionable feedback, making it less helpful for the authors to improve their draft. It's better than nothing, but it doesn't provide the necessary direction for change."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests the introduction to orthogonality in Part 2 could be 'more detailed'. This is an implicit suggestion, as the reviewer does not explicitly state what should be added or changed. While the reviewer identifies a potential area for improvement, they do not provide specific actions or concrete steps for the authors to take. The suggestion is vague and lacks direction.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Part 2' when stating that the introduction to orthogonality 'could be more detailed'. This clearly identifies the specific section of the paper being addressed, indicating strong grounding. However, the reviewer does not specify *what* is missing or unclear in that introduction. The claim is about the introduction being 'could be more detailed', which is a general statement about the level of detail, not a specific problem or issue within that section.", "verifiability_rationale": "The reviewer states that the introduction to orthogonality in Part 2 'could be more detailed'. This is a claim made by the reviewer. However, the reviewer does not provide any evidence, reasoning, or external references to support this claim. The statement is presented as an observation or suggestion without justification.", "helpfulness_rationale": "The reviewer's suggestion that the introduction to orthogonality in Part 2 could be 'more detailed' is a constructive comment aimed at improving the clarity and completeness of the paper. This suggestion directly addresses a potential weakness and offers a positive direction for the authors to consider. While it doesn't provide specific details, it is a helpful suggestion that encourages the authors to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the paper's contribution as the removal of double descent under specific conditions *in relation* to prior work. This is an explicit action. Once the action is identified (identifying the paper's contribution), the authors can deduce how to apply this feedback by focusing on the anisotropic settings and optimal regularization. The reviewer also suggests a way to improve the paper's framing, which is a concrete action. Therefore, the review point is 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'samplewise multiple descent\" and \"optimal regularization can remove double descent even in certain anisotropic settings.\" These are specific technical terms and concepts. The reviewer also connects these specific concepts to existing theoretical work, indicating an understanding of the context. The reviewer's comment is grounded in existing knowledge and is specific about the type of double descent and the conditions being considered. Therefore, the review point is 5.", "verifiability_rationale": "The reviewer states that the paper's contribution is \"the result that optimal regularization can remove double descent even in certain anisotropic settings.\" This is a clear claim about the paper's novelty. The reviewer also provides a justification for their belief that the paper should highlight this novelty, stating they cannot verify the claims due to a lack of familiarity with the techniques. This justification, while based on a lack of expertise, is a logical reasoning process. Therefore, the review point is 4.", "helpfulness_rationale": "The reviewer clearly identifies a key contribution of the paper and provides a constructive suggestion for improving the paper's framing. The reviewer suggests that the paper should explicitly highlight the novelty of their result in relation to prior results. This is a clear and actionable suggestion for the authors. The reviewer's point is directly helpful for the authors in improving their paper. Therefore, the review point is 5."}
{"actionability_label": "1", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the two methods are independent. While this is a true statement, it does not provide any actionable advice or suggestions for the authors on how to connect or utilize these methods. The authors are not guided on how to modify their approach based on this observation.", "grounding_specificity_rationale": "The review point explicitly mentions 'contrastive training objective' and 'contrastive search' by name. This directly identifies the specific methods being discussed. It also specifies the relationship between these methods as 'little inner connection' on both 'intuition' and 'algorithm'. This provides a clear and specific reference point for the reviewer.", "verifiability_rationale": "The review point presents a claim that the two methods are independent. However, it does not provide any evidence, reasoning, or references to support this claim. There is no logical argument or citation to back up the assertion that these methods have little inner connection.", "helpfulness_rationale": "The review point is a critique pointing out a potential area for further exploration. It does not offer any suggestions, solutions, or actionable steps for the authors. It is a negative comment about the relationship between the methods without proposing any concrete improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a gap in the paper's comparison to existing DAS models but doesn't explicitly state how the authors should address this gap. While it points out the existence of PhaseNetDAS and similar models, it doesn't provide a clear action on how to compare or justify the proposed method against them. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The comment explicitly mentions the existence of DAS models and the lack of comparison, which grounds the feedback to a specific part of the paper. It identifies the area where the paper is lacking. The comment specifies what needs to be addressed: the benefit of the proposed method against existing methods. The action is implicit but the grounding and specificity are clear.", "verifiability_rationale": "The comment contains a claim about the existence of DAS models and the lack of justification for the proposed method. It is supported by the reviewer's knowledge and the potential content of the paper. However, it lacks specific examples or references to back up the claim about the lack of justification. The evidence is general and could be strengthened with specific instances of where the justification is missing. It is 3 but could be more robust with supporting evidence.", "helpfulness_rationale": "The comment identifies a valid criticism regarding the lack of comparison to existing DAS models and the need for clearer justification. It suggests that if the claim is about a foundation model, future applications should be highlighted. This provides some direction for the authors to consider. However, it doesn't explicitly state *how* the authors should make this comparison or *why* they should prioritize this justification. It points out a gap but doesn't provide a direct path to improvement. It is 3 in identifying an area for improvement but lacks concrete guidance on how to achieve it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a specific question about the discrepancy between Table 6 and Table 1, which implies an actionable request to understand why this difference exists. However, the reviewer does not explicitly state the action to be taken or the expected outcome, making it partially actionable.", "grounding_specificity_rationale": "The reviewer asks about the results of Table 6 in relation to Table 1, specifically for MCTpairs. This implies a clear identification of the specific aspect of the paper being addressed. The reviewer also asks about ablation studies of MCT without adaptive metrics, which clearly specifies the component being questioned. Therefore, the grounding is strong.", "verifiability_rationale": "The reviewer states a claim: 'Why the results of Table 6 is not aligned with Table 1 (MCTpair)'. This claim requires justification. The reviewer also asks for 'ablation studies of MCT without the adaptive metrics', which is a request for additional information, not a claim requiring verification. Therefore, the verifiability is partially verifiable.", "helpfulness_rationale": "The reviewer asks 'Why the results of Table 6 is not aligned with Table 1 (MCTpair)' and 'what about the ablation studies of MCT without the adaptive metrics'. These are both clear and actionable questions aimed at improving the understanding of the results and the methodology. The request for ablation studies is particularly direct and valuable for the authors. The 'why' question, while not immediately actionable, points to a potential area of confusion and encourages clarification."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point identifies a pattern in existing research but doesn't explicitly state how the authors should use this information to improve their model. The action is implied but not directly stated.", "grounding_specificity_rationale": "The review point is a general statement about the robustness of models and the existence of prior work, not a specific reference to a part of the authors' paper.", "verifiability_rationale": "The review point is an observation about the existence of prior work and findings, not a definitive claim that needs verification.", "helpfulness_rationale": "The review point is insightful and relevant, connecting the authors' work to existing research. However, it doesn't provide direct, actionable steps for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests 'more discussions' as a way to improve the paper. While this is a suggestion, it's not explicitly tied to a specific action on the part of the authors. The criticism of the subtasks' simplicity is vague. Therefore, it's '2'.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the 10 subtasks' and 'bAbi,' which are specific parts of the paper. This demonstrates good grounding.", "verifiability_rationale": "The reviewer makes a claim ('The 10 subtasks are rather simplistic for bAbi') but doesn't provide any evidence or justification within the review point itself. Therefore, it's '1'.", "helpfulness_rationale": "The reviewer criticizes the simplicity of the subtasks and suggests more discussion. While this has the potential to be helpful, the review point lacks a specific, verifiable claim about the subtasks' simplicity. The suggestion for more discussion is a general call for improvement rather than a concrete action item. Therefore, it's '2'."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about the limitation of the approach (the restriction to triplets) rather than providing a direct instruction on how to address it. While it identifies a problem, it doesn't offer a concrete action or suggestion on how to overcome this limitation. The action is implicit in the question itself, suggesting an exploration of longer subsequences, but without specific guidance on how to do so.", "grounding_specificity_rationale": "The review point is a general question about the restriction to triplets and does not specify which part of the paper or method this limitation refers to. It doesn't mention any specific section, table, figure, or unique aspect of the paper. Therefore, it doesn't ground the issue in a specific part of the work.", "verifiability_rationale": "The review point is a question, not a statement that requires verification. It doesn't present a claim that needs to be supported by evidence or reasoning. It's a diagnostic question about a limitation.", "helpfulness_rationale": "The review point identifies a limitation of the approach (the restriction to triplets) but doesn't offer any suggestions or insights on how to overcome this limitation. It's a diagnostic question rather than a constructive suggestion for improvement. While it highlights an area for potential extension, it doesn't provide concrete guidance on how to implement such an extension."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point primarily asks for clarification on a term and suggests a connection between two concepts. It does not explicitly state an action or provide concrete steps for the authors to take. While it implies an area for improvement, the action is not directly identified or detailed.", "grounding_specificity_rationale": "The reviewer uses specific terminology like 'sequence of episodes' and mentions 'practice' and 'evaluation' as types of this sequence. This suggests an attempt to pinpoint the area of concern. However, the exact section or part of the paper being addressed is not explicitly stated, making it only somewhat grounded.", "verifiability_rationale": "The review point is a question seeking clarification and does not contain a claim that requires verification. Therefore, it does not have verifiability in the sense of supporting a statement with evidence.", "helpfulness_rationale": "The review point is a question seeking clarification on a specific term and suggesting a missing related work. While this points to potential areas for improvement, it does not directly guide the authors on how to improve their draft. The feedback is more about understanding the current terminology rather than providing actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the issue: 'I don't think the study about different subdomain sizes is an \"ablation\" study since they aren't removing a component of the method.' This directly identifies a potential mischaracterization of the study. The reviewer is stating an opinion about the nature of the experiment. While it doesn't provide a concrete action to improve the draft, it points to a specific area where the authors might have misunderstood the experimental setup. The reviewer is stating a judgment about the paper (something is unclear, not wellwritten), as deduced or inferred observations that go beyond merely stating facts.", "grounding_specificity_rationale": "The comment explicitly mentions 'subdomain sizes' and 'ablation study' as the key elements being questioned. The reviewer uses precise terminology and clearly identifies the specific part of the paper or concept being referred to. The comment specifies what needs to be understood about the experiment. The authors can easily identify the referenced part (the description of the experiment with varying subdomain sizes) and the issue (the lack of component removal). This falls under the category of '5' as the reviewer can accurately pinpoint the section and identify the issue.", "verifiability_rationale": "The comment contains a claim: 'I don't think the study about different subdomain sizes is an \"ablation\" study since they aren't removing a component of the method.' This claim is supported by the reasoning that an ablation study typically involves removing a component, which is not the case here. The reviewer provides a logical explanation of why the study is not an ablation study. The reasoning is clear and directly supports the claim. The comment uses logical reasoning to explain why the study is not an ablation study. This falls under the category of '5' as the claim is thoroughly supported by explicit, sufficient, and robust evidence (the definition of an ablation study).", "helpfulness_rationale": "The comment is highly relevant and directly addresses a potential misunderstanding or mischaracterization of the study. It provides clear information for the authors to understand that the experiment is not a traditional ablation study. This information is actionable in the sense that it guides the authors to reevaluate their understanding of the experimental setup and potentially the related literature. The comment is clear and directly points out a specific area of confusion. The reviewer is stating a judgment about the paper (something is unclear, not wellwritten), as deduced or inferred observations that go beyond merely stating facts. The comment is not just a criticism but also a suggestion for clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests adding AccNet as part of a larger predictor and mentions the context of semantic segmentation and similar operators. This indicates a clear action or suggestion, making it actionable.", "grounding_specificity_rationale": "The review point mentions specific terms like 'AccNet,' 'larger predictor,' 'semantic segmentation,' and 'similar operators.' This demonstrates an attempt to identify the specific aspect of the paper being addressed, indicating grounding. While it doesn't explicitly state which part of the paper this refers to, the terms are directly related to the potential extension.", "verifiability_rationale": "The review point presents a suggestion for future work but doesn't provide concrete evidence or justification for why this would be a good idea or how it would be implemented. It lacks logical reasoning, common knowledge, or external references to support the suggestion. Therefore, it is not 5.", "helpfulness_rationale": "The review point offers a potential avenue for future research by suggesting the inclusion of AccNet in a larger predictor for semantic segmentation. While this is a valuable direction to explore, it doesn't directly address a specific weakness or improvement needed in the current work. It's more of a suggestion for future development than a direct critique or actionable improvement for the current draft. Therefore, it is 3, as it encourages the authors to think about their work in a broader context, but it doesn't immediately resolve any immediate issues."}
{"actionability_label": "4", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitation of the metric's testing and suggests improvement by testing on more datasets. This is an explicit action, and while the concreteness could be debated (it doesn't specify *how* to expand testing), the action itself is clear.", "grounding_specificity_rationale": "The reviewer refers to 'the new proposed metric' and 'a single dataset'. While not a direct section reference, it clearly identifies the scope of the metric and the dataset being discussed. This can be considered partially grounded as the topic is quite specific. However, it doesn't pinpoint a specific part of the metric or the dataset itself, only the general area.", "verifiability_rationale": "The reviewer states a fact about the metric's testing limitation. While the claim is verifiable (it's a factual statement), there is no further justification or reasoning provided for why this is a problem or what should be done about it. It's a statement, not a reasoned argument.", "helpfulness_rationale": "The reviewer points out a limitation of the metric's testing. While this is a valid observation and a helpful piece of feedback for the authors to know the metric's scope, it doesn't offer specific suggestions for improvement or how to address this limitation. It identifies a problem but doesn't provide a constructive solution beyond acknowledging it."}
{"actionability_label": "High", "grounding_specificity_label": "Low", "verifiability_label": "High", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states a desire to compare the base DA methods with and without AutoDial and AdaBN, which are direct competitors to TN. This clearly indicates an action the authors should take.", "grounding_specificity_rationale": "While the reviewer suggests comparing TN with AutoDial and AdaBN, they do not explicitly state where this comparison should be made in the paper or why these baselines are relevant. The reasoning is implied but not stated within the review point itself.", "verifiability_rationale": "The reviewer provides a clear justification for why the comparison with AutoDial and AdaBN is important, stating it would strengthen the evaluation. This demonstrates logical reasoning.", "helpfulness_rationale": "The reviewer's suggestion is directly aimed at improving the understanding of TN's performance relative to relevant baselines, which is a valuable contribution to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states actions the authors should take, such as 'move the definition to L73' and 'clarify the superscript in Eq 6'. While the reviewer doesn't explicitly state *how* to define 'NE' or clarify the superscript, the actions are clear and direct. The reviewer is prompting the authors to take specific actions to improve the paper.", "grounding_specificity_rationale": "The reviewer explicitly refers to specific locations in the paper, namely 'L73' and 'Eq 6', when pointing out the issues. This indicates a high level of grounding specificity as the reviewer is directly identifying the parts of the paper that need attention.", "verifiability_rationale": "The reviewer makes claims about the paper, specifically stating that 'Some abbreviations are not defined' and 'Superscript notation in Eq 6 is not defined until much later'. The reviewer also provides suggestions ('move the definition to L73' and 'clarify the superscript in Eq 6') as actions to be taken. The grounding (referring to L73 and Eq 6) makes it easier to verify the claims, and the suggestions provide a basis for verification.", "helpfulness_rationale": "The reviewer clearly identifies specific weaknesses in the paper (undefined abbreviations and undefined superscript) and provides concrete suggestions for improvement ('move the definition to L73' and 'clarify the superscript in Eq 6'). The suggestions are directly relevant to the identified issues and are actionable for the authors. The reviewer's comments are not just observations but also constructive recommendations."}
{"actionability_label": "3", "grounding_specificity_label": "1 and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement 'the evaluation is weak' is an explicit action, as it directly identifies a deficiency. However, it is somewhat vague as it doesn't specify what aspects of the evaluation are weak. The statement 'the baselines used in the paper are not even designed for fair classification' is also explicit, identifying a specific issue with the baselines. It is somewhat vague as it doesn't detail *why* the baselines are not designed for fair classification.", "grounding_specificity_rationale": "The comment 'the evaluation is weak' does not identify a specific part of the paper or methodology being evaluated. It is a general statement about the evaluation. The comment 'the baselines used in the paper are not even designed for fair classification' also does not identify a specific part of the paper or methodology. It is a general statement about the baselines.", "verifiability_rationale": "The statement 'the evaluation is weak' does not contain a claim that can be verified. It is a subjective assessment. The statement 'the baselines used in the paper are not even designed for fair classification' is a claim. However, the review point does not provide any evidence or justification for this claim. It is presented as a statement of opinion without supporting references or explanations.", "helpfulness_rationale": "The review point is a critique of the evaluation's quality and the baselines used. It does not provide specific, actionable feedback or suggestions for improvement. It is not a direct instruction on how to revise the work, but rather a metacomment on the evaluation process itself."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the action they want to see: 'spelling out the setting'. This action is both explicit (the reviewer names the action) and concrete (they specify what needs to be spelled out: the setting).", "grounding_specificity_rationale": "The reviewer identifies the specific part of the paper they are referring to: 'the first three paragraphs of section 2'. This is strong grounding as the authors can directly identify the referenced part. The reviewer also specifies what needs to be spelled out: 'the setting', which clearly identifies the issue.", "verifiability_rationale": "The reviewer makes a claim that the authors might be misinterpreting the generality of their work and that spelling out the setting would improve clarity. However, the reviewer does not provide any evidence or justification for why spelling out the setting would necessarily make the exposition clearer or address the perceived generality issue. The reasoning is presented as a suggestion rather than a verifiable claim.", "helpfulness_rationale": "The reviewer's comment suggests a potential improvement to the authors' work by clarifying the exposition. However, the comment itself does not provide any specific information or guidance on how to 'spell out the setting' or how this would lead to a clearer exposition. The comment is a suggestion, not a constructive critique that offers concrete help."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue with the baselines ('The experiments are not quite convincing') and suggests an alternative ('...or compared to these approaches, what is the advantage of the proposed method?'). While the reviewer doesn't provide a concrete stepbystep action, they clearly identify a problem and propose a solution. The explicitness of the suggestion could be debated, but it leans towards explicit.", "grounding_specificity_rationale": "The reviewer doesn't explicitly point to a specific section or table in the paper. They refer to the general 'experiments' and suggest improvements related to the choice of baselines. While the intent is clear (improving the experimental section), the lack of a precise reference point makes the grounding somewhat weak. It's not obvious which part of the paper needs improvement, but it's not so vague that it's 1 at all.", "verifiability_rationale": "The reviewer makes a claim ('The experiments are not quite convincing') and provides a justification ('The authors choose the old baseline like R3D and C3D. To reduce computation complexity, many papers have been proposed in 3D CNN (X3D, SlowFast, etc)') as evidence. While the claim itself is subjective ('not quite convincing'), the reviewer attempts to support it with reasons related to the choice of baselines and the existence of more advanced models. This suggests an attempt to provide logical reasoning, even if the claim is ultimately subjective. The lack of direct references makes the verifiability somewhat limited.", "helpfulness_rationale": "The reviewer raises valid concerns about the experimental setup and encourages further discussion. They point out a potential weakness in the baselines and suggest exploring more advanced models. This feedback is relevant to the authors and highlights areas for improvement. However, the reviewer doesn't provide specific, actionable steps *on how* to improve the method or the experiments. The feedback is more about suggesting alternatives than providing concrete implementation guidance. Therefore, it's helpful in identifying areas for improvement but lacks the detailed guidance of a '4' or '5' comment."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for specific details about the implementation of the attention module within the ResNet20 architecture. While the action of seeking clarification is explicit, the lack of concrete details makes it only partially actionable. The reviewer could infer that the attention module is integrated within the ResNet20 blocks, but this is not explicitly stated.", "grounding_specificity_rationale": "The reviewer is referring to the 'attention module' and the 'backbone ResNet20 architecture'. They are asking for details about their integration. The authors can infer that the attention module is part of the ResNet20 architecture, but they cannot confidently determine the exact part being addressed without further clarification.", "verifiability_rationale": "The reviewer is stating a fact: 'It is not very clear how exactly is the attention module attached to the backbone ResNet20 architecture when performing the search.' This statement is verifiable as it is a direct observation about the lack of clarity.", "helpfulness_rationale": "The reviewer is providing valuable information to the authors by clarifying the lack of clarity regarding the attention module's integration. This information is likely to be helpful for the authors in understanding the method better."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a performance difference between high and low bitrates, which is an explicit action. However, it lacks specific guidance on how to improve the low bitrate performance, making it somewhat vague on the action to be taken. The suggestion to discuss or compare with a related work is also an explicit action but lacks specific guidance on how to apply this suggestion.", "grounding_specificity_rationale": "The comment discusses performance at different bitrates but does not explicitly identify the specific bitrate range or the section of the paper where this comparison is made. The suggestion to discuss a related work is also 1 to a specific aspect of the proposed method.", "verifiability_rationale": "The comment makes a claim about the performance difference at different bitrates but does not provide any evidence or justification for this claim within the review point itself. Similarly, the suggestion to discuss a related work is a claim that lacks specific examples or references within the review point.", "helpfulness_rationale": "The comment points out a potential area for improvement (low bitrate performance) but does not offer concrete steps or guidance on how to address it. The question about the bitrate range is also not helpful as it does not provide any actionable feedback. The suggestion to discuss a related work is helpful as it points to a relevant area for further research or comparison, providing a concrete resource for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review suggests a distinction but doesn't provide explicit steps on how to achieve it.", "grounding_specificity_rationale": "The review refers to general concepts without explicitly naming the section or part of the paper where this distinction is discussed. It also doesn't specify what these bounds are.", "verifiability_rationale": "The review contains a claim about the lack of distinction but doesn't provide sufficient justification, examples, or references to support this claim.", "helpfulness_rationale": "The review points out a potential area for improvement in the authors' understanding or application of statistical concepts, encouraging them to think more critically."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'marginal' and 'further analysis,' which are direct actions the authors should take. The reviewer points to specific areas ('three tasks', 'previous works', 'baselines'), making the action more concrete than a vague general statement.", "grounding_specificity_rationale": "The comment explicitly mentions 'improvements on three tasks' and 'previous works and baselines,' which allows the authors to accurately pinpoint the referenced parts. However, the comment does not specify *why* these improvements are marginal or *what* aspects of the tasks, previous works, or baselines are lacking. The specificity is limited to identifying the areas of concern, not explaining the shortcomings or suggesting specific improvements.", "verifiability_rationale": "The comment contains a claim: 'improvements on three tasks over the previous works and selfimplemented baselines are marginal' and 'further analysis beyond the main experiments is not sufficient.' However, it does not provide any logical reasoning, common knowledge, or external references to support these claims. The reviewer states a problem but doesn't explain why it's a problem or how it should be addressed.", "helpfulness_rationale": "The comment identifies a valid concern (marginal improvements) and suggests an improvement (further analysis). However, it lacks specific details on what the improvements are marginal on, why they are marginal, and how further analysis should be conducted. The suggestions are very highlevel and lack concrete guidance, making the review less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that all linear convergence rates *rely* on Theorem 8. This indicates an explicit action the authors should take: identify the theorem and understand its role in their analysis. However, the reviewer does not provide specific guidance on *how* to use Theorem 8 or what aspects of their work it addresses, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'Theorem 8' but does not specify *where* in the paper this theorem is located or *what specific part* of their work it relates to. The comment is general and does not pinpoint a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer states that 'Theorem 8 which is burried at the end of the appendix and which proof is not clear enough'. This comment itself is a claim that requires justification. The reviewer provides some justification by stating the theorem is 'buried' and the 'proof is not clear enough', but they do not provide specific examples or references to external works to support this claim about the theorem's location or lack of clarity.", "helpfulness_rationale": "The reviewer points out a potential issue (clarity of Theorem 8) that could hinder the authors' understanding and implementation of their analysis. While the reviewer suggests moving Theorem 8 to the main body, this is a suggestion and not a concrete action the authors can take based on the current review point alone. The reviewer does not provide specific steps the authors can follow to address the lack of clarity or location information."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides specific details about the Walkman algorithm's relation to ADMM and critiques the paper's generalization about SGD. It also points out a lack of clarity in Section 3 regarding a comparison between SGDbased algorithms and ADMM. These are direct and actionable criticisms.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Walkman algorithm (Mao et al., 2020)' and details its relation to ADMM. In Section 3, while the pronoun 'it' makes the reference less explicit, the context strongly suggests 'SGDbased Algorithm 1'. The criticism of SGD is also tied to the mentioned algorithm. While the exact algorithm isn't named in the general statement, the context makes it clear.", "verifiability_rationale": "The first part of the review point provides specific information about Walkman's relation to ADMM and argues against a general statement about SGD. This information can be verified. The second part points out a lack of clarity in Section 3, which is a valid observation but doesn't present a claim that can be verified or falsified.", "helpfulness_rationale": "The review point directly identifies issues in the related work section (incorrect generalization about SGD) and highlights a lack of clarity in Section 3. These are actionable and provide valuable feedback to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the limitation of the theoretical result regarding the Gaussian assumption and provides a clear suggestion to not use this assumption. It also implies a comparison to existing rates, which can be inferred as a concrete action. The action is explicit and the comparison is implied, making it 5.", "grounding_specificity_rationale": "The review point explicitly refers to the 'main (and only) theoretical result' and mentions specific elements of that result, such as 'features and noise are Gaussian'. It also refers to 'previous algorithms' and 'rates achieved by their procedure'. This indicates a strong grounding as the reviewer can easily identify the specific part of the paper being addressed. The comparison to existing rates further specifies the area of concern within the result.", "verifiability_rationale": "The review point contains a claim about the limitations of the theoretical result regarding the Gaussian assumption. It also implicitly suggests that this is a strong requirement and implies a need to compare the rates. The claim about the Gaussian assumption can be verified by examining the stated assumptions of the theoretical result. The suggestion to compare rates can be verified by looking at the derived utility guarantees and the existing literature on similar problems. The claim is supported by logical reasoning and common knowledge about the importance of assumptions in theoretical analysis.", "helpfulness_rationale": "The review point is 5 as it directly points out a limitation of a key theoretical result and provides a concrete suggestion for improvement (not using the Gaussian assumption). It also highlights a gap in the comparison to existing work, which is a valuable piece of feedback. The suggestions are clear and actionable, providing the authors with a direction for future work and a comparison to related research."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment suggests a comparison with a prior work, which can be seen as an implicit action to help the authors understand the context of their extension. However, it doesn't explicitly state how to perform this comparison, making it somewhat vague on the action to be taken.", "grounding_specificity_rationale": "The comment explicitly mentions 'Schiratti et al. (2015)' and 'simulated data', which grounds the reference to a specific paper and the type of data to be used. It also implicitly suggests that this comparison is relevant, indicating an understanding of the context. While it doesn't explicitly state *how* to compare, it clearly identifies the target of the comparison.", "verifiability_rationale": "The comment identifies a potential improvement or area for validation by comparing with a prior work. While it doesn't provide explicit justification for *why* this comparison is important, the suggestion itself acts as a form of justification, indicating that the authors believe this comparison would be beneficial. It lacks external references or detailed reasoning about the specific aspects of the extension that need to be validated.", "helpfulness_rationale": "The comment suggests a comparison with a relevant prior work, which is generally a valuable piece of feedback for authors. It points towards a specific area for further analysis and validation, which could help the authors better understand their extension and its relationship to existing methods. While it doesn't provide explicit instructions on how to perform the comparison, it offers a clear direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of the experimental setup (only two baselines) and provides concrete suggestions for improvement (adding more baselines 1, 2, 3). This indicates both explicit and concrete aspects of the review.", "grounding_specificity_rationale": "The reviewer identifies the specific area of the paper needing improvement (the 'experimental section') and provides specific examples of what should be added (1, 2, 3). This demonstrates both grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the experimental setup and provides a logical argument for why adding more baselines is beneficial. While they don't provide specific references in this point, the underlying principle is generally accepted.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the experimental section and offers concrete suggestions to improve it. This is a valuable piece of feedback for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer's point is a critique of the evaluation methodology, specifically the use of the development set for both hyperparameter tuning and model selection. While this is a valid concern in machine learning, the reviewer does not propose a specific action or improvement within the paper itself. They are suggesting a change in the experimental setup, not an actionable item within the paper's content. Therefore, the point lacks explicit and concrete actions that the authors should take.", "grounding_specificity_rationale": "The reviewer criticizes the evaluation process, stating that the authors do not know what they should do after reading the comment. They are pointing out a lack of clarity in the evaluation methodology. While the criticism is valid, the reviewer does not specify *which* aspects of the evaluation are unclear. They are broadly criticizing the use of the development set for tuning and selection, but not pinpointing a specific section or detail within the paper that is missing. Therefore, the grounding is weak as the authors can infer the problem but not the specifics of the issue.", "verifiability_rationale": "The reviewer makes a claim: 'I strongly suggest that the paper should present the average results on the test set with clearly defined error bars under different random seeds.' This claim is based on a standard practice in machine learning. While the reviewer doesn't provide a detailed justification for *why* this is a problem in their specific case, the suggestion itself is a verifiable statement. The claim is supported by the common practice of using the test set for final evaluation and reporting performance with error bars. Therefore, the claim is verifiable, but the reviewer doesn't provide a detailed reasoning or examples to fully support it.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement: 'I strongly suggest that the paper should present the average results on the test set with clearly defined error bars under different random seeds.' This suggestion directly addresses a potential weakness in the current evaluation methodology. While the reviewer doesn't provide a detailed explanation of *why* this is necessary or *how* to implement it, the suggestion is a concrete and actionable piece of feedback for the authors. It points them towards a specific area for improvement in their experimental setup. Therefore, the point is helpful in guiding the authors towards a better evaluation process."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification on how topicword parameters were obtained and the size of the AG news dataset. While the paper mentions 'topicword parameters' and uses the 'AG News dataset', it does not explicitly state the method used to obtain the topicword parameters or the vocabulary size of the dataset. The questions are implicit, requiring the reader to infer the missing information. The action is present (identifying missing information), but it is not explicitly stated, making it implicit.", "grounding_specificity_rationale": "The review point asks for clarification on how topicword parameters were obtained and the size of the AG news dataset. The paper mentions 'topicword parameters' and uses the 'AG News dataset', which can be considered a form of grounding. However, it does not explicitly state the section of the paper where this information is located or provide the specific details requested (parameter estimation method and vocabulary size). The information is present but not explicitly identified, making the grounding somewhat weak.", "verifiability_rationale": "The review point does not contain a claim. It is a question seeking information. Therefore, verifiability does not apply to this review point.", "helpfulness_rationale": "The review point raises valid questions about the data generation process and dataset characteristics. While the information is not explicitly stated in the paper, it is not necessarily unhelpful. The reviewer is pointing out missing information that would be beneficial for the authors to understand the experimental setup and potentially reproduce the results. The lack of explicit information makes it less helpful than a review that directly criticizes a flaw in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states \"it only compares against 3 basic alternatives and ignores some other NAS (e.g. supernet/oneshot approaches, etc...).\" This is an explicit statement of a weakness, identifying the lack of comparison with specific NAS methods. While the reviewer doesn't specify *how* these alternatives should be included, the action is clear: the authors should compare against these other NAS approaches. The reviewer also mentions \"basic alternatives\", which, while not explicitly defined, implies a lack of depth or sophistication in the comparisons.", "grounding_specificity_rationale": "The reviewer mentions \"other NAS (e.g. supernet/oneshot approaches, etc...).\" This shows the reviewer is providing specific examples of NAS methods that are missing. However, the reviewer does not explicitly state which part of the BRPNAS analysis is lacking these comparisons. The grounding is weak because the reviewer is mentioning the *type* of alternative NAS methods but not pinpointing a specific aspect of the BRPNAS analysis that needs improvement.", "verifiability_rationale": "The reviewer states \"it only compares against 3 basic alternatives and ignores some other NAS (e.g. supernet/oneshot approaches, etc...).\" This is a claim that can be verified by examining the BRPNAS analysis. However, the reviewer does not provide any logical reasoning, external references, or examples to *justify* why these are \"basic alternatives\" or why they are \"ignored\". The claim is stated, but the verification is lacking.", "helpfulness_rationale": "The reviewer states \"it only compares against 3 basic alternatives and ignores some other NAS (e.g. supernet/oneshot approaches, etc...).\" This is a clear statement identifying a weakness in the BRPNAS analysis. The reviewer also implicitly suggests that the authors should include these missing comparisons, providing a direction for improvement. While the suggestion is somewhat general, it directly points towards a concrete action the authors can take."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X (X)", "helpfulness_label": "None", "actionability_rationale": "The reviewer's point is subjective and offers a general aesthetic critique of the paper's presentation, specifically mentioning the zeroshot version and connection to density estimation as potentially distracting. While they identify a *area* of concern (presentation), they do not explicitly state a concrete action the authors should take to address this. The criticism is about the *how* rather than the *what*.", "grounding_specificity_rationale": "The reviewer mentions 'the zeroshot version' and 'density estimation' but does not explicitly identify a specific part of the paper (e.g., a section, table, figure, or unique aspect) that is being criticized. The reference to these concepts is general and does not pinpoint a specific element of the paper being addressed. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment refers to.", "verifiability_rationale": "The review point is a subjective statement expressing an opinion about the paper's presentation. It does not present a claim that can be verified through logical reasoning, common knowledge, or external references. The reviewer is stating what they perceive is distracting, not a factual assertion about the paper's content. Therefore, there is no verifiable claim in this review point.", "helpfulness_rationale": "The review point is not actionable and is a subjective opinion about the paper's presentation. Since it does not provide specific, concrete feedback that the authors can use to improve their draft, it is not particularly helpful. The lack of a clear action for the authors to take diminishes its potential usefulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that 'details around the filtering process used to create the Arabic climate change QA dataset are lacking.' This indicates an explicit action that needs to be taken \u2013 to provide more information on the filtering process. However, the action itself is vague as it doesn't specify what exactly is missing or how it should be described. Therefore, while the reviewer points to a need for information, the specific action is not clearly defined.", "grounding_specificity_rationale": "The review point explicitly mentions 'filtering process' and 'Arabic climate change QA dataset.' This provides a clear grounding of the comment to specific aspects of the paper. However, it does not specify a unique section, table, figure, or element within the dataset that needs to be addressed. The grounding is present, but it is not fully explicit.", "verifiability_rationale": "The review point contains a claim: 'More information on the translation and filtering methodology is needed.' This claim is 3 because it points to a lack of detail. However, it lacks specific examples or references to make it 5. The reviewer states a need for more information, implying that the current information is insufficient to assess the dataset quality.", "helpfulness_rationale": "The review point clearly identifies a lack of detail regarding the filtering process and translation methodology as a barrier to assessing the dataset quality. This is a direct and actionable comment for the authors. The reviewer is asking for specific information that is currently missing, which is likely to be helpful for the authors in evaluating their work. The request for more information directly addresses a potential weakness."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states two specific shortcomings: 'lack of attacks with different strength' and 'lack of influence of different thresholds on detection performance.' These are direct actions the authors should take to improve their draft.", "grounding_specificity_rationale": "The reviewer mentions 'attacks with different strength' and 'different thresholds' as specific types of attacks and parameters. While they don't name the exact section or table, they clearly identify the *nature* of the deficiencies, indicating a degree of grounding.", "verifiability_rationale": "The reviewer states the problems ('lack of attacks with different strength' and 'lack of influence of different thresholds on detection performance') without providing any logical reasoning, common knowledge, or external references to support these claims. The verifiability is low as the reasoning is missing.", "helpfulness_rationale": "The reviewer points out specific areas where the experiment could be improved ('lack of attacks with different strength' and 'lack of influence of different thresholds on detection performance'). However, they do not offer concrete suggestions or explain the consequences of these deficiencies for the authors. The helpfulness is limited as the reviewer identifies problems without providing solutions."}
{"actionability_label": "4", "grounding_specificity_label": "Mostly Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need to 'train a discriminator on generations from the learned model' to confirm the model's ability to reduce exposure bias. This is a direct action. While the reviewer also mentions 'in a way similar to Figure 1' and the difference from 'Figure 4', these are clarifications of the *method* and a *potential issue*, rather than implicit actions that need to be inferred. The core action is clear: train a discriminator.", "grounding_specificity_rationale": "The reviewer explicitly states the need to 'train a discriminator on generations from the learned model'. This directly targets the output of the learned model, making it grounded. The reviewer also mentions 'Figure 1', which likely refers to a specific visualization or analysis of the generated text, further grounding the action in a specific aspect of the output. The comparison to 'Figure 4' highlights a specific aspect of the evaluation, indicating a focus on a particular detail of the generated text.", "verifiability_rationale": "The reviewer makes a claim that 'training a discriminator on generations from the learned model is needed to confirm if it is the case, in a way similar to Figure 1'. The reviewer also provides a justification by stating that 'it is different from Figure 4, since during training the discriminator is coadapting with the generator, and it might get stuck at a local optimum'. This justification provides a logical reasoning for the claim, making it verifiable.", "helpfulness_rationale": "The reviewer suggests a specific method ('training a discriminator') to validate the model's claim. This directly addresses the core claim of the paper. While the suggestion is present, the reviewer could have provided more specific details about the discriminator's architecture, the training process, and the evaluation metrics. The mention of 'Figure 4' highlights a potential issue, suggesting an awareness of a specific challenge, which adds some depth to the helpfulness."}
{"actionability_label": "Low", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point does not explicitly state what the authors should do. The reviewer is asking for information about the impact of specific experimental choices, which requires the authors to interpret and analyze the results themselves. There is an implicit suggestion that understanding this impact is important, but the point does not demand a specific action.", "grounding_specificity_rationale": "The reviewer mentions 'it' in relation to 'L170', suggesting they have located something in the paper. However, they do not explicitly identify the specific part of the paper being addressed (e.g., a section, table, or figure). The reference is weak and does not pinpoint the exact location. The comment also does not specify what is meant by 'performance difference'.", "verifiability_rationale": "The review point does not contain a claim or assertion that needs verification. It is a question seeking information, not a statement that requires logical reasoning, common knowledge, or external references to be considered valid.", "helpfulness_rationale": "The review point is not inherently harmful to the authors. However, it does not provide direct, actionable feedback on how to improve their draft. It asks for information that could be helpful for understanding the experimental setup, but it does not identify a weakness or suggest a concrete improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment states that the algorithm should be presented and described in detail. While this is an explicit instruction, it lacks specific guidance on *how* to achieve this. The reviewer doesn't specify which aspects of the algorithm need more detail or what the desired format should be. Therefore, it is partially actionable as it points out a need for more detail, but lacks concrete steps on how to implement it.", "grounding_specificity_rationale": "The comment 'The Algorithm should be presented and described in detail' is a general suggestion and does not specify which part of the paper the algorithm is located in. There is no mention of a specific section, table, figure, or unique element of the paper. Therefore, the comment does not ground the feedback in a specific part of the paper, making it 1.", "verifiability_rationale": "The review point 'The Algorithm should be presented and described in detail' is a suggestion or recommendation. It does not contain a claim that requires verification or justification. There are no explicit opinions, judgments, or suggestions about what is incorrect or missing. Therefore, it does not meet the criteria for verifiability, which focuses on supporting claims.", "helpfulness_rationale": "The review point suggests providing more detail about the algorithm. While this can be helpful for understanding, it is a general suggestion and does not directly address a specific weakness or issue in the authors' work. It lacks specific direction on how to improve the algorithm's description. Therefore, it is 3 as it points out a potential area for improvement, but lacks specific guidance on how to achieve it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'it would have been interesting to see a runtime comparison at test time.' This action is concrete, telling the authors exactly what they should do and where to perform the comparison.", "grounding_specificity_rationale": "The review point refers to 'the paper mentions the possibility to use Chebyshev polynomials to achieve a speedup.' While it doesn't explicitly name a section or table, the reference to a specific idea within the paper implies a degree of grounding. The authors can infer the relevant part of the paper where this speedup potential is discussed. The suggestion 'runtime comparison at test time' is also specific, indicating a clear area for improvement.", "verifiability_rationale": "The review point contains a claim: 'it would have been interesting to see a runtime comparison at test time.' This claim is 3 because the authors can infer the relevance of a runtime comparison based on the mention of Chebyshev polynomials as a potential speedup. While it doesn't provide a definitive proof of benefit, it points to a logical next step to explore that potential.", "helpfulness_rationale": "The review point is 5. It directly suggests a concrete and actionable improvement: conducting a runtime comparison at test time. This encourages the authors to perform a specific experiment and analyze the results, directly addressing the potential speedup mentioned in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The reviewer explicitly states that the proposed method 'seems only works for digit or text images'. This is an explicit statement of a limitation, indicating that the action the method can take is restricted to these specific types of images. The reviewer is directly identifying a constraint on the applicability of the method, making the review point actionable in identifying a limitation.", "grounding_specificity_rationale": "The reviewer's comment, 'The proposed method seems only works for digit or text images, such as MNIST and SVHN. Can it be used on natural images, such as CIFAR10...', does not explicitly and accurately identify a specific part of the paper (e.g., a section, table, or figure). While the reviewer implies a concern about the method's applicability to different types of images, they don't point to a specific element within the paper that the method is intended for. Therefore, while the reviewer is pointing out a limitation, they are not precisely identifying the 'where' of the issue. The specificity of the comment is about the *type* of data, not a specific element within the paper. Thus, it can be considered weakly grounded.", "verifiability_rationale": "The reviewer makes a clear claim: 'The proposed method seems only works for digit or text images...'. This claim is verifiable based on the information provided. The reviewer is stating their understanding or observation about the method's limitations. The reasoning is direct and doesn't require external references to be considered valid. The claim is about the scope of the method, which can be assessed by examining the method's description or implementation details (if available). Therefore, the claim is verifiable.", "helpfulness_rationale": "The reviewer's comment, 'The proposed method seems only works for digit or text images, such as MNIST and SVHN. Can it be used on natural images, such as CIFAR10...', is a question directed at the authors. While it identifies a limitation, it doesn't offer a constructive suggestion or actionable advice on how to adapt the method or address this limitation. The reviewer is pointing out a boundary rather than proposing a solution or improvement. Therefore, while the review points out a limitation, it doesn't actively help the authors improve their draft. It's more of a *detection* of a problem than a *helpful* suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer states the *problem* ('prompts are not wellorganized') and provides *specific references* ('Table 6, 7'). However, the reviewer does not explicitly state *how* the organization is lacking (e.g., lack of clear headings, separation of related prompts). The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 6, 7' by name, indicating a strong ability to identify the specific part of the paper being addressed. However, the reviewer does not specify *what* is wrong with the organization of these tables (e.g., lack of clear separation, unclear instructions). The issue is implied but not explicitly stated.", "verifiability_rationale": "The reviewer makes a claim ('prompts are not wellorganized') and provides supporting information by describing the issue ('all sentences squeeze together'). While they do not cite external references, the descriptions themselves serve as implicit support for the claim.", "helpfulness_rationale": "The reviewer identifies a potential issue ('prompts are not wellorganized') and points to the formatting of the text ('all sentences squeeze together'). However, the reviewer does not explicitly state the *consequences* of this disorganization for the authors or suggest *specific ways to improve* the organization. The feedback is present but lacks concrete action."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the figures are 'not clear' and provides a specific example of confusion with the subfigures in Figure 2. They also identify the missing modules (CMAF, L_BT, VoLTA). This indicates that the authors should be able to directly identify modifications they should apply to their draft by understanding the specific issues with the figures.", "grounding_specificity_rationale": "The reviewer specifically mentions 'figure 2' and the 'relation of 3 subfigures' and the 'modules CMAF, L_BT, VoLTA'. This demonstrates that the authors can identify the specific part of the paper being addressed, making the grounding fully grounded. The reviewer also specifies what needs to be addressed in this part (clarity of subfigures and labels), making the specificity high.", "verifiability_rationale": "The reviewer states that the figures are 'not clear' but does not provide any specific evidence or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the claim that the figures are unclear. The reviewer claims the figures are unclear, but doesn't explain *why* or provide *examples* of what makes them unclear.", "helpfulness_rationale": "The reviewer provides a clear description of the issue (figures are unclear) and points to specific elements within the figure that are missing or confusing (CMAF, L_BT, VoLTA). This directly helps the authors identify areas for improvement. The reviewer's statement is actionable and specific, providing concrete feedback that the authors can readily use."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'While FFNs are omitted because a linear decomposition cannot be obtained' and suggests a solution: 'maybe a line or two should be added that there exists no solution for this, and it is an open (hard) problem.' This provides a clear direction for the authors to improve their draft.", "grounding_specificity_rationale": "The reviewer refers to 'FFNs' and 'linear decomposition,' which are specific terms used in the paper. They also mention 'as mentioned in the paper,' indicating they have located this information. The reviewer also suggests a specific type of solution ('approximation'), making the grounding quite specific.", "verifiability_rationale": "The reviewer points out a factual omission ('FFNs are omitted') and provides a reason ('a linear decomposition cannot be obtained'). While they suggest further research ('is there existing work that offers a way around'), the core point about the omission and the reason for it are verifiable based on the paper's content. The suggestion for further research could be seen as a recommendation for the authors to explore, which isn't directly verifiable but is a consequence of the identified issue.", "helpfulness_rationale": "The reviewer directly addresses a specific issue related to the clarity of the paper's limitations regarding FFNs. They provide a concrete suggestion for improvement ('maybe a line or two should be added') which is directly actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies 'some questionable design choices' and mentions 'perplexity is used as a measure of the model retaining semantic information after finetuning'. While this points to a potential issue, the reviewer does not explicitly state what specific action needs to be taken or how the design choice should be altered. The implications are about 'catastrophic forgetting' and 'domain drift', but the reviewer doesn't provide concrete steps to address these. The action is implied but not explicitly stated, making it partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'perplexity' and its relation to 'semantic information retention', 'catastrophic forgetting', and 'domain drift'. However, they do not explicitly and precisely identify 'which specific aspect' of perplexity or the 'entire process' of finetuning is potentially flawed. The references are more conceptual than pointing to a specific, identifiable part of the model or process. The grounding is present but not fully precise, making it 3.", "verifiability_rationale": "The reviewer presents a claim: 'Some questionable design choices. Perplexity is used as a measure of the model retaining semantic information after finetuning, and while that does relate to the original task, there are also aspects of domain drift which are possible and separate from catastrophic forgetting. How are such factors controlled?'. The reviewer mentions perplexity and its connection to semantic information, and they mention domain drift as a separate issue. However, they do not provide specific evidence or references to support their assertion about the 'questionable design choice' or how these factors are controlled. The reasoning is more speculative than verifiable.", "helpfulness_rationale": "The reviewer raises a valid concern about the use of perplexity as a metric and points out the potential for 'domain drift' as a separate issue from 'catastrophic forgetting'. This highlights a potential limitation in the evaluation process. However, the reviewer does not offer specific, actionable suggestions or propose concrete solutions to address these issues. The point is relevant but lacks the depth and specificity needed to be fully helpful. The helpfulness is moderate as it identifies a problem but doesn't provide a clear path forward."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks two questions: 'How does the number of images impact the model performance?' and 'Do more training images make the performance worse or better?'. While the second question is phrased as a claim, the intent is to understand the relationship between data quantity and performance. The reviewer is seeking direct action, specifically how the number of images affects performance. The phrasing is direct and explicit about the desired outcome.", "grounding_specificity_rationale": "The reviewer mentions 'the cluster structure is defined by the identity' in the context of the BYOL model. This provides a clear and specific reference point for discussing the model's components. The grounding is explicit and literal, directly identifying a specific aspect of the model. The specificity is moderate as the reviewer doesn't delve into the details of how the identity is implemented or its impact, but the reference is clear.", "verifiability_rationale": "The review point poses a question: 'Do more training images make the performance worse or better?'. This is framed as a claim, but the review point itself does not provide any evidence, reasoning, or references to support this claim. The verifiability is based on the expectation that the reviewer has encountered this question in the context of BYOL and can infer or recall relevant information. Without external context or evidence within the review point itself, the verifiability is low.", "helpfulness_rationale": "The review point raises a relevant question about the impact of a key parameter (number of images) on the performance of a core component (BYOL). This is generally helpful for understanding the behavior and potential limitations of the model. However, the question is broad and lacks specific details about which performance metric is being considered. The helpfulness is moderate as it points to a relevant area for investigation but lacks specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the reasoning behind the method's effectiveness, particularly regarding the L_pixel component, is unclear. While this implies an implicit action (the authors should understand why it works), the lack of specific guidance on *how* it works makes it vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'L_pixel' component, indicating a clear identification of a specific part of the paper. They also ask about its effectiveness, specifying what needs to be addressed within that component. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer states that the reasoning behind the method's effectiveness, particularly regarding the L_pixel component, is unclear. This statement itself is a claim that requires justification. However, the reviewer does not provide any evidence or reasoning to support their claim about the unclarity of the reasoning. Therefore, it is 1 based on the information given.", "helpfulness_rationale": "The reviewer provides a clear and specific request for clarification regarding the effectiveness of the L_pixel component. This directly addresses a potential weakness in the paper and guides the authors to improve their understanding. While it doesn't offer a solution, it is 5 in identifying areas for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the 'lack of details' in the Related Work section and provides a list of specific methods (longcontext language models, sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods) and their 'limitations'. This is an explicit statement of a problem that needs to be addressed.", "grounding_specificity_rationale": "The reviewer mentions specific methods by name (1, 2, 3, 4, 5, 6, 7) when describing the shortcomings of the Related Work section. While it doesn't pinpoint a specific section, it clearly identifies the type of information that is lacking, grounding the feedback to a specific area of the Related Work.", "verifiability_rationale": "The reviewer makes a claim about the 'lack of details' in the Related Work section and provides specific examples of methods and their limitations. This claim is supported by the logical reasoning and the examples provided, making it verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable feedback on the Related Work section, pointing out its shortcomings and suggesting specific areas for improvement. This feedback is directly aimed at helping the authors enhance their draft."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "Medium", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states the concern about the sufficiency of 44k dialogues and suggests that datasets in the trillions of tokens are needed. This indicates a clear action the authors should take: acquire or create a larger and more diverse training dataset.", "grounding_specificity_rationale": "The reviewer mentions '44k dialogues' and discusses its ability to capture 'a wide range of user traits and personalities across different content topics'. This clearly identifies the specific part of the paper (training data) being addressed. The reviewer also provides specific details about the desired range of traits and personalities. This demonstrates strong grounding as the authors can identify the specific aspect they are concerned about.", "verifiability_rationale": "The reviewer presents a claim about the insufficiency of 44k dialogues, which requires some form of justification. While the reviewer doesn't provide a direct comparison or specific evidence within the review point itself, the subsequent suggestion about the trillions of tokens used for other LLMs provides implicit support. Therefore, it's not '1' or '1 and not specific'. The claim is somewhat supported by general knowledge about LLM training data size, making it 'underspecified' in terms of providing concrete evidence within the review point itself.", "helpfulness_rationale": "The reviewer's point directly addresses a practical limitation in the training data and offers a concrete suggestion for improvement: increasing the dataset size. This is a clear and actionable feedback that directly helps the authors understand their data limitations and what they need to do. The reviewer's statement is a direct criticism and a call for more data, which is actionable for the authors. Therefore, it's considered '5' because it directly addresses a practical limitation and offers a concrete solution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The binary classification label itself doesn't provide any specific action or guidance on how to improve the text. It simply states whether the classification is correct or incorrect, without explaining *why* it's wrong or what kind of error it is. Therefore, it's not actionable in the sense that a more detailed feedback would be.", "grounding_specificity_rationale": "The binary classification label does not specify *which* part of the text or which aspect of the text is being classified. It only indicates whether the classification is correct or incorrect. Therefore, it is 1 in a specific section or detail of the text.", "verifiability_rationale": "The binary classification label, while verifiable in the sense that it's a clear decision, does not provide any justification or explanation for why the classification is correct or incorrect. It lacks the reasoning or references needed to understand the basis of the classification. Therefore, it is 1 in terms of providing insights into the model's decisionmaking process.", "helpfulness_rationale": "The binary classification label is not helpful for authors because it does not provide any insights into *why* the classification is correct or incorrect, nor does it suggest any specific ways to improve the text. It's a simple correctness judgment without any deeper understanding or actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the method is 'not clear if the method is applicable to real and categorical features too.' This is an implicit suggestion that the method has limitations with these feature types. While the reviewer points out a potential area for improvement, they do not explicitly state what steps the authors should take to address this. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer mentions 'real and categorical features' without specifying which part of the paper or method they are referring to. They are not pointing to a specific section, table, or figure. The grounding is weak because the reviewer cannot confidently determine which part of the paper is being addressed. The comment is vague and does not clearly identify the issue.", "verifiability_rationale": "The reviewer states 'not clear if the method is applicable to real and categorical features too.' This is a statement of uncertainty, not a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support this statement. It's a question about the method's applicability, not a verifiable claim.", "helpfulness_rationale": "The reviewer points out a limitation of the method but does not offer any suggestions or ask clarifying questions. While they identify a potential area for improvement, they do not provide any actionable feedback to the authors. The feedback is a statement of a problem without any constructive elements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment is a general statement about the writing needing improvement. It doesn't specify *which* parts are unclear or *how* the writing should be changed. Therefore, it lacks actionable steps for the author.", "grounding_specificity_rationale": "The comment doesn't mention any specific section, table, figure, or unique element of the paper. The phrase 'some points' is vague and doesn't help the author pinpoint the issue. Thus, it's 1.", "verifiability_rationale": "There is X being made. The comment is a suggestion, not a statement of fact that requires verification. Therefore, it's 'X (X)'.", "helpfulness_rationale": "The comment is relevant in that it points out a general weakness (unclear writing). However, it lacks specificity, making it difficult for the author to know exactly what to do. It's more of a broad suggestion than a detailed critique that would be 5."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The suggestion to 'use other metrics' is an explicit instruction on what the authors should do. However, it lacks specific details on which metrics to use and how to apply them, making it somewhat vague.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. It is a general suggestion about evaluation metrics, making the grounding weak. Furthermore, it does not specify what is wrong with the current evaluation methods, making the specificity low.", "verifiability_rationale": "The review point is a suggestion, not a claim. It does not make any assertion or judgment about the paper or the suggested metrics. Therefore, there is X to verify.", "helpfulness_rationale": "The suggestion to use other metrics is relevant and could be helpful for the authors to improve their evaluation of the results. However, it is a general suggestion without specific guidance, making it 3 but not very informative. It does not actively harm the authors by providing misleading information."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests looking at 'LLM evaluation' and points to a specific paper 2. While the reviewer doesn't provide a direct action, they implicitly suggest that the comparison of SynTextBench with other metrics, like MMLU and Big Bench, is a relevant area for improvement. The suggestion to 'see what conditions should one use SynTextBench over other metrics' is a clear indication of a desired action. However, the lack of specific details about the comparison makes it difficult to pinpoint the exact action the authors should take, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'LLM evaluation' and a specific paper 2. While they don't explicitly state the section or table within the paper, the reference to a specific paper is a strong indicator of grounding. The reviewer is referring to a concrete piece of work. However, the reviewer does not specify *which* aspect of LLM evaluation they are referring to, nor does they specify *which* section of paper 2 they are referring to. The request to compare SynTextBench with other metrics is also general and lacks specificity.", "verifiability_rationale": "The reviewer states that 'there has been a large amount of work on LLM evaluation' and that 'it would still be good to see how SynTextBench metric compares to the other metrics proposed in the literature.' This statement is a claim. The reviewer mentions a specific paper 2 as an example of work on LLM evaluation, which provides some grounding and justification for the claim. However, the reviewer does not provide a clear explanation of *why* they think SynTextBench might be better or under what conditions they are considering the comparison. The request is vague and lacks specific reasoning.", "helpfulness_rationale": "The reviewer raises a relevant point about the lack of clarity on when to use SynTextBench over other metrics like MMLU and Big Bench, especially in the context of language generation. This is a valuable observation for researchers in the field. However, the reviewer's suggestion to 'see what conditions should one use SynTextBench over other metrics' is vague and lacks specific details. The lack of concrete suggestions or criteria makes the review less actionable and therefore less helpful."}
{"actionability_label": "High", "grounding_specificity_label": "Full Grounding and Specific", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that the algorithm for construction of coresets is not novel and points to the extension of existing coreset frameworks to the kernelized setting. This provides a clear action for the authors to consider, namely the potential lack of novelty of their algorithm.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'algorithm for construction of coresets' and 'existing coreset frameworks for classical kmeans and (k,z) clusterings'. This provides clear grounding as the reviewer accurately pinpoints the specific parts of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim about the lack of novelty of the algorithm. While the reviewer provides a reason for this claim (the extension of existing frameworks), they do not provide specific evidence or references to support this assertion. The reasoning is present, but lacks concrete backing.", "helpfulness_rationale": "The reviewer points out a potential weakness in the paper's contribution by suggesting that the algorithm for construction of coresets is not novel and that existing frameworks have been extended to the kernelized setting. While this raises a valid concern, the reviewer does not provide specific, actionable feedback on how this lack of novelty should be addressed or how the authors can improve their work based on this feedback. The comment is present but lacks concrete suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment 'Poor writing and annotations are a little hard to follow' identifies a problem but does not specify what needs to be done to improve the writing or annotations. It lacks explicit and concrete actions. The comment is vague and does not provide guidance on how to make the writing or annotations clearer. Therefore, it is 1.", "grounding_specificity_rationale": "The comment 'Poor writing and annotations are a little hard to follow' does not identify a specific part of the paper or annotation that is difficult to follow. It is a general statement about the overall writing and annotations. The comment lacks grounding specificity as it does not point to a particular section, table, figure, or unique element of the paper. Therefore, it is 1.", "verifiability_rationale": "The comment 'Poor writing and annotations are a little hard to follow' does not make a claim or assertion. It is a statement of observation about the writing and annotations. Since there is X, there is no verifiability to evaluate. Therefore, it is X (X).", "helpfulness_rationale": "The comment 'Poor writing and annotations are a little hard to follow' identifies a valid issue but does not provide any specific suggestions or guidance on how to improve the writing or annotations. It is a diagnosis without a prescription. Therefore, it is 1."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that only 8 out of 14 evaluation metrics achieve SOTA performances in Table 2. This is a clear and direct statement of a weakness. The reviewer also points out that under the setting of 'Twitter2017 > Twitter2015', the proposed method achieves the best overall F1, while not achieving the best F1 in all single types. This is an implicit action suggesting the authors should investigate why the overall performance is better despite the lack of improvement in singletype evaluations. While the action is not stated explicitly, the reviewer provides the necessary information to identify the action.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Table 2', '8 of the total 14 evaluation metrics', 'SOTA performances', 'Twitter2017 > Twitter2015', and mentions 'overall F1' and 'best F1 in all single types'. These are all specific references to the paper's content and the results being discussed. The reviewer clearly identifies the specific aspect of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim about the results in Table 2, stating that only 8 out of 14 metrics achieve SOTA. This is a claim that needs verification. The reviewer also makes a claim about the discrepancy in F1 scores, stating that the best overall F1 is achieved while not achieving the best in all single types. This claim also needs verification. The reviewer provides the necessary information to potentially find evidence to support or refute these claims, although they do not provide external references or detailed reasoning beyond the observed numbers.", "helpfulness_rationale": "The review point directly identifies a weakness in the reported results of the authors' work. By pointing out that only a portion of the evaluation metrics show SOTA performance, the reviewer highlights a potential issue with the authors' evaluation process or implementation. Furthermore, the reviewer points out a discrepancy in the F1 scores, suggesting that the authors need to investigate why the overall performance is better despite the lack of improvement in singletype evaluations. This encourages the authors to delve deeper into their results and potentially identify areas for improvement. The reviewer's questions also prompt the authors to consider the validity of their evaluation methodology and its impact on the reported metrics."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about a specific methodological choice, which can be interpreted as an implicit request for justification. While they don't explicitly state 'How do you decide to only consider ECG segments with one label assigned?', the implication is clear. Therefore, it's not entirely 1, but it's also not explicitly stated. The reviewer can infer the reason for this filtering, making it 3.", "grounding_specificity_rationale": "The reviewer directly asks a question about a specific aspect of the methodology: 'Why do you only consider ECG segments with one label assigned to them?'. They are referencing the 'one label assigned' criterion, indicating a clear grounding in the methodological details. The question is also specific about the *reason* behind this selection, making it highly specific. Therefore, it's 5.", "verifiability_rationale": "The reviewer expresses an expectation about the difficulty of including all reports compared to those with one label assigned. While this is a reasonable assumption, the paper itself doesn't explicitly state *why* including all reports would be harder. The reviewer is making an inference based on their understanding of the task. Therefore, it's not 1, but it's also not fully justified by evidence within the paper. The claim is based on a reasonable assumption but lacks direct evidence from the paper being reviewed, making it partially verifiable.", "helpfulness_rationale": "The reviewer is pointing out a potential issue with the methodology by questioning the filtering of ECG segments. While they are asking a question about a specific aspect, they are not actively proposing a solution or improvement to the authors. They are more of a critique of the methodological choice. Therefore, it's not unhelpful, but it doesn't actively guide the authors towards a better approach. The question highlights a potential problem, but doesn't offer a concrete next step for the authors, making it 3. It points to a potential flaw in the methodology, but doesn't actively propose a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The statement is somewhat explicit in identifying the proposed solution as an 'incremental step' considering Guzman's work and mentioning 'minor suggestions'. However, it lacks specific details on how the solution is incremental or what the suggestions entail. The actions are implied rather than explicitly stated and detailed.", "grounding_specificity_rationale": "The comment refers to 'the proposed solution' and 'Guzman et. al.' generally. It doesn't explicitly point to a specific section, table, figure, or unique aspect of Guzman's work. The specificity of the referenced element is unclear. The comment also doesn't specify what is meant by 'incremental step' or 'minor suggestions'.", "verifiability_rationale": "The comment is an evaluative statement about the nature of the proposed solution, stating it's an 'incremental step' and mentioning 'minor suggestions'. It doesn't present a claim that requires verification or support. There are no logical reasoning, common knowledge, or external references provided within the comment itself.", "helpfulness_rationale": "The comment is evaluative and doesn't provide specific actionable feedback or insights that would empower the authors to improve their draft. It's more of a comment on the *process* of proposing solutions than a direct critique or suggestion for improvement. There are no concrete steps or guidance provided for the authors to follow."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the absence of a 'thorough exploration' of 'scalability bounds,' 'memory requirements,' and 'computational complexity.' These are direct and specific criticisms of the paper's content, making the action clear. While the point doesn't suggest *how* to explore these aspects, it clearly identifies the need for such an exploration, making it actionable in terms of identifying a missing element and suggesting a direction for improvement.", "grounding_specificity_rationale": "The review point explicitly mentions 'scalability bounds' as the area lacking discussion. While it doesn't point to a specific section, table, or figure, the reference to 'scalability bounds' itself can be considered a clear indication of the paper section being addressed. Furthermore, the review point clearly specifies the issues within this area: 'memory requirements' and 'computational complexity.' This makes the grounding 'Full' and the specificity 'Highly Specific'.", "verifiability_rationale": "The review point implies that the lack of discussion on 'scalability bounds,' 'memory requirements,' and 'computational complexity' constitutes a weakness in the paper. While it doesn't provide a definitive statement of opinion, the conclusion drawn about the paper's state is generally accepted within the field of federated learning. The limitations of algorithms, especially concerning scalability and resource requirements, are common knowledge. Although the point doesn't provide specific citations, the general understanding is widely held, making it '3'.", "helpfulness_rationale": "The review point is helpful because it directly identifies a clear weakness in the paper \u2013 the limited discussion of scalability aspects. It provides a specific area for improvement by suggesting a 'thorough exploration' of 'scalability bounds,' 'memory requirements,' and 'computational complexity.' While it doesn't offer a solution, it clearly guides the authors on what needs to be addressed, making it '4'."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The statement explicitly states a limitation of LLMs in handling problems with more than 7 variables, which is a direct and clear action. The reviewer directly points out a specific issue with LLM capabilities.", "grounding_specificity_rationale": "The statement is about a general limitation of LLMs, not a specific part of a paper. There is no explicit mention of a section, table, figure, or unique element of the paper. The grounding is weak because the authors cannot confidently determine which part the comment addresses. The comment specifies what needs to be addressed (LLMs' limitations with variable count), but it doesn't pinpoint a specific part of the paper being discussed.", "verifiability_rationale": "The statement contains a claim about LLMs' limitations. It does not provide specific evidence or references to support this claim within the review itself. The reasoning is that it's a forwardlooking statement about LLM capabilities, and without external references, it's not 5 within the given context.", "helpfulness_rationale": "The statement identifies a potential issue with the types of problems LLMs can handle. While it highlights a limitation, it doesn't offer specific advice or actionable steps for the authors on how to address this limitation. It's a critique of the problem space rather than a direct solution or improvement suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point does not explicitly state an action or suggest a change to the paper. It is a critique of the presentation of results.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 2 and 3', clearly identifying the specific part of the paper being addressed.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a statement of observation and suggestion.", "helpfulness_rationale": "The suggestions in the review point directly address the clarity and representation of the results, which can be beneficial for the authors in understanding and interpreting their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a direct question about the mechanism of NodeSort and its impact. While they are asking for clarification, the underlying action is to understand how the base node affects the sorting, which is an explicit request for information about the implementation. The reviewer is also implicitly asking how this affects key nodes and performance, which can be inferred. Therefore, while not explicitly stating an action, the reviewer is prompting for information that would allow them to take action (understand and potentially improve the model).", "grounding_specificity_rationale": "The reviewer uses terms like 'NodeSort,' 'nodes,' 'base node,' and 'key nodes for attention,' suggesting they are familiar with these concepts. However, the *specific section* or *table* where this information is detailed is not explicitly mentioned in the review point. The reviewer is inferring the relevance of these terms based on their understanding of the model. Therefore, the grounding is weak, as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point is a question, not a claim that can be supported or unsupported. The reviewer is asking 'Does this mean...' which is a question about the interpretation of the paper's description. There is no explicit claim being made that requires verification. Therefore, it is not verifiable in the sense of supporting a claim. However, the underlying question is about understanding a mechanism, which *could* be verifiable if the paper provided the necessary details. Since there's X, the closest fit is '1'.", "helpfulness_rationale": "The reviewer is asking a specific question about a technical detail of the model. This is likely to be helpful for the authors who are trying to understand the implementation and potentially improve their own work based on this understanding. The question is about a specific aspect of the model's behavior and its potential impact, making it a relevant and potentially useful piece of feedback. While it's not a direct suggestion, it's a question that, if answered, could significantly improve the authors' understanding and potentially their model's performance."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the diagram, which implies a desire for clarification. While they don't explicitly state 'You should explain this arrow to me,' the act of asking a question about a specific part of the paper or diagram can be considered an implicit action. However, the action is vague, as the reviewer doesn't specify *how* the arrow is supposed to be interpreted or what problem it solves. The lack of explicitness makes it less actionable than a direct instruction.", "grounding_specificity_rationale": "The reviewer explicitly points to the Gaussian space and the latent space in Figure 2 and asks a question directly related to their relationship. They identify the specific parts of the diagram being discussed, demonstrating strong grounding specificity. They are not making an educated guess or leaving it ambiguous which parts they are referring to.", "verifiability_rationale": "The reviewer asks a question about the purpose of the arrow in Figure 2. This constitutes a claim that the diagram element has a specific function (influencing n^(i)). The verifiability of this claim depends on whether the paper adequately explains the diagram's construction and the role of the arrow. If the paper provides a clear and logical explanation of how the arrow represents a causal relationship or information flow, then the claim is verifiable. However, if the explanation is lacking or ambiguous, the claim remains 1 or 2.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific aspect of the paper. While they are not directly criticizing the methodology or suggesting a concrete improvement, their request can be helpful for the authors in understanding the diagram better. This understanding could potentially lead to improvements in future iterations of the work. Therefore, it is 3 in the sense that it addresses a potential area of confusion and promotes a deeper understanding of the method."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that 'AR' stands for 'domain adaptation tasks and algorithms'. This provides a clear and direct action for the authors to take: define 'AR' in the paper. The action is also concrete as the meaning is fully specified.", "grounding_specificity_rationale": "The reviewer explicitly states 'In Table 5', which clearly identifies the location of the undefined abbreviation. This provides strong grounding for the authors to locate the relevant information. The specificity is also high as the reviewer provides the exact meaning of 'AR' as 'domain adaptation tasks and algorithms'.", "verifiability_rationale": "The reviewer makes a claim that the lack of definition for 'AR' is a weakness. This is a verifiable claim as the meaning of 'AR' is generally understood within the field of domain adaptation. The reviewer provides a clear and logical explanation for why defining 'AR' is beneficial.", "helpfulness_rationale": "The reviewer identifies a clear weakness in the paper: the undefined abbreviation 'AR'. The reviewer's suggestion to define 'AR' is a direct and actionable improvement that will help the authors communicate their work more clearly and precisely."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states 'Although using advantage instead of q value is more common in practice,' which points to a specific technical aspect and asks a question about it. This constitutes an explicit action or suggestion, even if it's not a direct instruction on what to do. The reviewer is indicating an area needing further consideration.", "grounding_specificity_rationale": "The reviewer mentions 'advantage' and 'q value' but does not explicitly identify which part of the paper or concept they are referring to. The reference is weak, as the reviewer can only make an educated guess about what these terms relate to. The specificity of the comment is also limited as the connection between these terms and 'analysis' is not clearly explained.", "verifiability_rationale": "The reviewer poses a question: 'I'm wondering if there is other technical consideration for conducting the analysis with advantage instead of q value.' This statement implies a claim that there are other considerations, but it does not provide any evidence or references to support this claim. The claim is subtle and lacks verification.", "helpfulness_rationale": "The review point is a question posed without providing any actionable feedback or guidance. It does not identify a specific weakness or suggest a concrete improvement. The reviewer is simply asking for more information, which is not helpful in the context of providing feedback for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer is pointing out a potential discrepancy or a lack of clarity in the description of the 'Unsupervised Online Adaptation' setting. While the method might be intended to be unsupervised, the description implies the need for annotated data (documents, quires, and labels), which is a characteristic of supervised learning. This makes the action (identifying the issue) implicit rather than explicit. The reviewer is essentially stating an expectation that is not clearly articulated in the description.", "grounding_specificity_rationale": "The reviewer is highlighting a lack of clarity in the grounding of the comment. The terms 'documents,' 'quires,' and 'labels' are mentioned, which could be interpreted as providing some level of grounding. However, the reviewer's core point is about the *supervision* aspect. The paper's description might not clearly distinguish between the *terms* used and the *implied level of supervision*. The comment specifies what the adaptation process uses, but not necessarily the underlying supervision status in a clear and unambiguous way.", "verifiability_rationale": "The verifiability of the reviewer's claim depends on the clarity and completeness of the paper's description of the 'Unsupervised Online Adaptation' setting in Sec 3.1. If the paper explicitly states that this adaptation method does not require annotated data and the reviewer's interpretation of the terms 'documents,' 'quires,' and 'labels' as implying supervision is correct, then the claim is wellverified. However, if the paper's description is ambiguous or could be interpreted as requiring annotations, then the claim is only 2.", "helpfulness_rationale": "The helpfulness of this review point depends on the interpretation of the paper's Sec 3.1. If the paper's description of 'Unsupervised Online Adaptation' is indeed misleading or ambiguous regarding the requirement of annotated data, then this review point is 5 as it points out a crucial misunderstanding. However, if the paper is already clear and the reviewer has misunderstood the distinction between terminology and supervision, the helpfulness is lower. Given the directness of the criticism, it leans towards being helpful if the paper is indeed ambiguous."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that VINS uses different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights to 1. This is an explicit statement of a difference in implementation, which is a concrete action the authors should consider.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. It is a general comment about the experimental setup in Table 1. The authors cannot confidently determine which aspect of the comparison the reviewer is referring to.", "verifiability_rationale": "The claim is that the comparison in Table 1 is unfair due to different sample weights. However, the review point does not provide any justification or evidence for why this difference makes the comparison unfair. There is no logical reasoning, common knowledge, or external references provided to support this claim.", "helpfulness_rationale": "The review point identifies a potential flaw in the experimental setup of the comparison in Table 1. However, it does not offer any specific, actionable suggestions or propose alternative experimental designs to address this issue. It is a critique of the methodology rather than a constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point states: \"The time complexity will be too high if the reply buffer is too large.\" This is a statement of a potential problem, not an actionable suggestion. It identifies a *problem* related to a *component* (reply buffer) but doesn't tell the authors *how* to fix it.", "grounding_specificity_rationale": "The review point refers to \"reply buffer\" without specifying which part of the paper or context this relates to. It also doesn't pinpoint the specific algorithm or component within the PRMRL framework.", "verifiability_rationale": "The review point is a statement of a potential problem: \"The time complexity will be too high if the reply buffer is too large.\" It doesn't make a definitive claim about *why* this will happen or *how* to solve it. It's more of an observation.", "helpfulness_rationale": "The review point identifies a potential performance bottleneck (time complexity) related to the reply buffer. While it highlights a problem, it doesn't offer any specific solutions or directions for improvement. It's a symptom, not a cure."}
{"actionability_label": "5", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point suggests 'display the performance of accelerating SGMs by involving some other baselines'. This is an explicit action that the authors should take. The suggestion is also concrete, specifying 'some other baselines' and providing examples of what those baselines could be ('optimizing the discretization schedule or by modifying the original SGM formulation 16, 15, 23, 36, 31, 37, 20, 10, 25, 35, 45'). This provides clear guidance on how to improve the evaluation.", "grounding_specificity_rationale": "The review point does not explicitly refer to any specific part of the paper (e.g., a section, table, or figure) when making its suggestion. While it mentions 'performance of accelerating SGMs' and 'baselines', it does not specify *where* in the paper these should be evaluated or compared. The grounding is weak because the authors are not told to look at a specific element.", "verifiability_rationale": "The review point makes a claim that 'It is better for authors to display the performance of accelerating SGMs by involving some other baselines'. This is a claim that the authors should do. The suggestion provides specific examples of *how* to do this ('optimizing the discretization schedule or by modifying the original SGM formulation 16, 15, 23, 36, 31, 37, 20, 10, 25, 35, 45') and suggests a comparison against existing methods. This provides sufficient evidence and justification for the suggestion, making it verifiable.", "helpfulness_rationale": "The review point suggests 'display the performance of accelerating SGMs by involving some other baselines'. This is a helpful suggestion because it provides a concrete way for the authors to improve their evaluation. By comparing against other baselines, the authors can gain a more comprehensive understanding of the performance of their SGM and identify potential areas for improvement. While it doesn't pinpoint a specific weakness, it offers a valid direction for enhancing the evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests improvements but lacks specific instructions on how to implement them, making it 3 but not fully so. While it implies adding a conclusion and summary, it doesn't specify where, what format, or what to include.", "grounding_specificity_rationale": "The review point refers to the entire paper without specifying a particular section or element, making it 1. It doesn't identify a specific part of the paper being addressed.", "verifiability_rationale": "The review point is a suggestion, not a claim that requires verification. It doesn't present an opinion or judgment that needs supporting evidence.", "helpfulness_rationale": "The suggestion to add a conclusion and summary is relevant but lacks specific details, making it 3 but not fully so. It doesn't specify where the conclusion should be, what format it should have, or what aspects of the contributions to summarize."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks 'how to explain that the data distribution illustrated in Figure 1 is inseparable from the network model?'. This is a direct question, making it explicit. However, the reviewer does not provide a concrete action or suggestion on how to approach this explanation. The action is 'to understand the explanation,' which is somewhat vague. It's not concrete in the sense of 'what to do' but rather a request for clarification.", "grounding_specificity_rationale": "The reviewer refers to 'the data distribution illustrated in Figure 1' and 'the network model'. This clearly identifies specific parts of the paper being addressed. The references are literal and specific, indicating strong grounding. The comment also specifies what needs to be explained \u2013 the relationship between the data distribution and the model's ability to handle nonlinearity in the context of separability.", "verifiability_rationale": "The reviewer does not explicitly state a claim or assertion that requires verification. They are posing a question to seek clarification. Therefore, it falls under the 'X' category of 'X'. There is no evidence to evaluate for verifiability.", "helpfulness_rationale": "The reviewer is asking a question to clarify a point of confusion regarding the relationship between the data distribution, the model's nonlinearity, and the concept of nonseparability. While the question doesn't directly provide actionable steps or solutions, it aims to improve the authors' understanding of a potentially problematic aspect of the experiment. This can be considered helpful as it addresses a potential area of confusion, though it doesn't actively resolve the issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the suggestion: 'the authors can further compare the proposed framework with a method that is designed to defend against multiple attacks'. This is a clear indication of an actionable next step for the authors. The reviewer identifies a specific area for improvement in the evaluation.", "grounding_specificity_rationale": "The reviewer suggests 'a method that is designed to defend against multiple attacks' as a basis for comparison. While the *type* of defense is specific, the reviewer does not identify a *specific* paper or method within that category. Therefore, the grounding is weak as the authors cannot confidently determine the exact part of the paper being addressed. However, the issue (defending against multiple attacks) is clearly specified, making it somewhat specific.", "verifiability_rationale": "The reviewer makes a claim: 'the results would be more meaningful if the authors could present this comparison in their paper'. This is a clear claim. However, the reviewer does not provide specific evidence or reasoning to support why this comparison would be more meaningful. The claim is present, but the verification is lacking. The reasoning is present but lacks concrete examples or references.", "helpfulness_rationale": "The reviewer's suggestion to compare against a defense against multiple attacks is relevant to the paper's goal of defending against malicious perturbations. This suggestion directly addresses a potential limitation in the evaluation and provides a concrete direction for improvement. While it doesn't provide a complete solution, it is a valuable and actionable suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies the presentation of results as 'convoluted' and the 'disregard' of safety violations in the first 1000 episodes. While it points out specific information being missing, it doesn't explicitly state what the authors should do to improve the presentation or address the issue of disregarding safety violations. The actionable aspect is present, but the guidance on how to implement the suggested changes is lacking.", "grounding_specificity_rationale": "The comment criticizes the presentation of results and the handling of safety violations. However, it does not explicitly identify the specific part of the paper being addressed (e.g., the results section, a particular table or figure). The grounding is weak because the authors cannot confidently determine which part the comment refers to.", "verifiability_rationale": "The comment contains a claim that the results are 'convoluted' and that safety violations in the first 1000 episodes were 'disregarded.' However, the reviewer states that the reason for presenting the results in this way is 'unclear.' Without a clear justification or reference for this claim, it is difficult to verify the accuracy or significance of the criticism. The claim is present, but the supporting evidence is lacking.", "helpfulness_rationale": "The comment identifies potential issues with the clarity of the results and the handling of safety violations. While it points out a potential area for improvement, it does not provide specific, actionable steps for the authors to take. The feedback is present, but the guidance on how to address the identified issues is minimal. The comment is not vague or lacking clarity in identifying a problem, but it lacks concrete suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer is asking for a definition of a specific term (\tau_i^l) which is crucial for understanding the 'timewarp function'. This is a direct and explicit request for information. The reviewer clearly identifies the missing information and states their need for clarification. Therefore, this is a 5 request as the authors can directly use the definition to understand the function.", "grounding_specificity_rationale": "The reviewer is asking for a definition of a specific term (\tau_i^l) which is directly related to the 'timewarp function'. The authors can accurately pinpoint the section or concept being addressed by understanding the definition of this term. This request is fully grounded as the reviewer explicitly mentions the importance of this term for understanding the function. The authors can deduce the missing information and understand the specific aspect being addressed.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are simply asking for a definition, which is a statement of fact. There are no logical reasoning, common knowledge, or external references required to understand the need for defining \tau_i^l. Therefore, this comment does not contain a claim and is not verifiable.", "helpfulness_rationale": "The reviewer is asking for a definition of a term (\tau_i^l) that is crucial for understanding the 'timewarp function'. This is directly beneficial to the authors as it will help them grasp a key aspect of their work and potentially improve their understanding or implementation of the function. Therefore, this is a 5 comment for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies the specific instances of writing errors ('informative informative' and 'performance') and points to their locations on specific pages. While the reviewer explicitly states the *what* (the errors), they do not explicitly state the *how* to fix them. The authors would need to infer that 'informative' should be changed to something else and 'performance' needs a title. Therefore, the action is explicitly stated, but the implementation is not.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific pages where the errors are located ('on page 5' and 'on page 1'). This clearly identifies the specific part of the paper being addressed. Furthermore, the reviewer describes the *nature* of the errors ('writing errors,' 'repetitive word,' 'missing title') and provides specific examples of the problematic text ('informative informative,' 'performance'). This clearly specifies what needs to be addressed in that part.", "verifiability_rationale": "The review point makes a claim about the existence of writing errors in the paper. It provides specific examples of these errors ('informative informative' and 'performance'). While it doesn't explicitly recommend a fix, the presence of these errors and their locations serve as verification of the claim. The claim is supported by logical reasoning (the presence of the errors) and examples.", "helpfulness_rationale": "The review point identifies specific writing errors and suggests they are 'lacking in clarity and precision'. While it points out the *what* (the errors and their nature), it does not explicitly tell the authors *how* to fix them. The authors would still need to infer the necessary changes. Therefore, while the review provides valuable information, it lacks explicit guidance on the next steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the difference between the standard sigmoid and the sigmoid used in URNNs regarding the maximum slope. It also points out that Theorem 4.1 is relevant to this difference. While the reviewer doesn't explicitly state an action or how to implement it, the identification of a specific technical detail and its connection to a theorem can be considered an implicit action. However, without further clarification from the authors on how this information is useful, the actionability is somewhat limited.", "grounding_specificity_rationale": "The review point explicitly mentions 'standard sigmoid', 'URNN's sigmoid', 'Theorem 4.1', and the concept of 'maximum slope'. It also mentions the relevance of 'RNN convergence' and 'URNN convergence' to understanding Theorem 4.1. This strong grounding makes it clear which parts of the paper the reviewer is referring to.", "verifiability_rationale": "The review point presents a claim: 'Theorem 4.1: Would be useful to elaborate a bit more in the main text why this holds (intuitively, since the RNN unlike the URNN will converge to the nearest FP).' The reviewer provides a rationale for why this claim is valid: 'intuitively, since the RNN unlike the URNN will converge to the nearest FP)'. This provides a logical reasoning for supporting the claim.", "helpfulness_rationale": "The review point identifies a specific technical detail (the difference in sigmoid and its connection to Theorem 4.1) and suggests a concrete improvement: 'elaborate a bit more in the main text why this holds (intuitively, since the RNN unlike the URNN will converge to the nearest FP)'. This directly addresses a potential area where the authors might need more clarity and provides a suggestion for improvement. The reviewer is directly pointing out a specific point of potential confusion and offering a clear path for the authors to understand it better."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a weakness ('inefficiency') but doesn't specify *how* to improve pairwise matching or provide concrete steps for the authors to take. It suggests the area of improvement (practical application systems) but lacks specific actionable feedback.", "grounding_specificity_rationale": "The comment does not specify which pairwise matching methods are inefficient. It broadly refers to 'such pairwise matching' without identifying a specific part of the paper or method. Therefore, it is 1.", "verifiability_rationale": "The comment contains a claim ('the efficiency of such pairwise matching is very low') but does not provide any evidence, reasoning, or references to support this claim. It lacks logical reasoning, common knowledge, or external references to back up the assertion of low efficiency. Therefore, it is 1.", "helpfulness_rationale": "The comment identifies a clear weakness ('inefficiency') and suggests a broad area for improvement ('practical application systems'). While it points out a problem, it doesn't offer specific, actionable steps or concrete suggestions for how the authors can address this inefficiency. It is more of a reminder than a constructive suggestion to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment criticizes the 'allocation of Figure 1' and suggests making 'edits the main paper space more wisely'. While the comment identifies a specific part of the paper (Figure 1) and suggests an improvement, the action of 'edits the main paper space more wisely' is vague and lacks specific details on how to achieve this. The reviewer points out a weakness and offers a general direction for improvement, but doesn't provide concrete steps or criteria for what constitutes 'more wisely' or how to allocate the space differently. Therefore, while the comment identifies a specific area and suggests an improvement, the lack of concrete actionability makes it 2.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1' and refers to the 'allocation' of space for it. The reviewer uses specific terminology ('Figure 1') to point to a particular element of the paper. This indicates a clear identification of the specific part being addressed. The comment does not rely on general statements or inferences about the paper's layout. The reviewer directly names the element they are commenting on.", "verifiability_rationale": "The comment states 'Minor weaknesses The allocation of Figure 1 is too naive' and 'edits the main paper space more wisely'. The first part is a statement of judgment about the figure's allocation. The second part, 'edits the main paper space more wisely', is vague and lacks specific examples or references. There is X that this allocation is incorrect based on external knowledge or logical reasoning. The criticism is based on the reviewer's perception of the allocation's naivety, but it doesn't provide a clear justification or evidence for why it is naive or what constitutes 'more wisely'. Therefore, the claim is not fully supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review points out a weakness (' allocation of Figure 1 is too naive') and suggests an improvement ('edits the main paper space more wisely'). While the reviewer identifies an area for potential improvement, the suggestion lacks specific details on how to achieve this. The comment is somewhat critical ('naive') but offers a general direction rather than concrete steps. Without specific actionable steps, the feedback is not particularly helpful in guiding the authors on how to make the necessary changes. The reviewer's intent is there, but the lack of clarity and specificity limits its helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states that the planbased method requires manually designing a plan based on the ground truth in advance. This implies an explicit action (designing a plan) that needs to be taken. However, the reviewer also points out that the learned plan methods are not comparable to the methods with predefined plans based on Table 2, suggesting that the proposed method may be difficult to generalize to a new dataset without the ground truth summary. This implies a vague outcome or a lack of concrete guidance on how to handle new datasets without ground truth. Therefore, while an action is mentioned, the specifics of how to implement it are not clear, making it 3 but also somewhat vague.", "grounding_specificity_rationale": "The review point mentions 'ground truth in advance' and 'without the ground truth summary'. This indicates that the reviewer is not explicitly identifying the specific part of the paper being addressed (the 'ground'). The comment focuses on the *need* for ground truth information but doesn't pinpoint where in the paper this information is relevant or how it should be used. The comment also clearly specifies what needs to be addressed (the manual design of the plan), making it somewhat specific within that context, but the lack of clear grounding makes it not fully grounded. Therefore, the grounding is not explicitly stated, making it 3.", "verifiability_rationale": "The review point contains a claim: 'The planbased method requires manually designing a plan based on the ground truth in advance...'. This is a statement of opinion or judgment. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The justification is present (the manual design), but the lack of further explanation or references makes it 3. Therefore, the claim is present but lacks sufficient justification or references, making it 3.", "helpfulness_rationale": "The review point critiques the manual design of plans in planbased methods and their impact on generalizability. While this highlights a potential limitation of the proposed method, it does not offer specific, actionable feedback or suggestions on how to improve the draft in this area. The reviewer points out that the proposed method may be difficult to generalize to a new dataset without the ground truth summary, indicating a lack of clear guidance for improvement. Therefore, the review point identifies a problem but does not provide a clear path forward for the authors to improve their draft based on this feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the action needed: 'needs to be rewritten'. This is a direct instruction for the author to rewrite the first sentence of the abstract.", "grounding_specificity_rationale": "The comment explicitly mentions 'the first sentence of the abstract', providing a clear and precise reference point within the paper.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a suggestion for improvement.", "helpfulness_rationale": "The comment is a clear and direct suggestion to rewrite the first sentence of the abstract. This is a 5 and helpful piece of feedback for the author."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a problem: 'It appears that in nearly all experiments, the results are reported for a single heldout test set.' They also suggest a concrete solution: 'Standard practice in most papers on GPs involves using a number of train/test splits or folds which give a more accurate illustration of the method\u00e2\u0080\u0099s performance.' This indicates a clear understanding of a potential limitation and a direct suggestion for improvement.", "grounding_specificity_rationale": "The reviewer's comment is about the general methodology of reporting results across all experiments. They do not explicitly identify a specific section, table, figure, or unique aspect of the paper that is being addressed. While they imply the issue is with the *Reporting* of results, they don't pinpoint a specific element within the paper being critiqued.", "verifiability_rationale": "The reviewer makes a claim: 'Standard practice in most papers on GPs involves using a number of train/test splits or folds which give a more accurate illustration of the method\u00e2\u0080\u0099s performance.' This claim is supported by the general understanding of best practices in machine learning, particularly in areas where robust evaluation is crucial. While the reviewer doesn't provide specific citations within this review point, the claim is based on common knowledge and widely accepted standards in the field.", "helpfulness_rationale": "The reviewer's comment is relevant to the typical concerns of researchers, especially those working with limited data or focusing on robust model evaluation. They identify a potential limitation in the experimental design (single test set) and suggest a standard improvement (multiple splits/folds). This is a valuable piece of feedback that directly addresses a likely area of concern for the authors and offers a clear direction for potential improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point is a question and a statement of suspicion, lacking a clear, explicit, and concrete action for the authors to take. It's a hypothesis, not a directive.", "grounding_specificity_rationale": "The review refers to the \"method\" generally, without specifying a particular section, table, figure, or unique aspect. The grounding is weak because the authors can't confidently identify the referenced part.", "verifiability_rationale": "The review contains a statement that could be interpreted as a claim (\"One would suspect,\"), but it lacks supporting evidence or logical reasoning to back up this suspicion. It's not definitively a claim that needs verification, but it's also not a purely factual statement.", "helpfulness_rationale": "The review points out a potential issue with the method but doesn't offer any concrete suggestions or actionable steps for the authors to improve it. It's a speculative observation, not a helpful critique."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states 'Adding a method on the top of other methods to improve transferability is good but cannot be considered a significant contribution.' This indicates an explicit action (adding a method) but lacks specific details on how to do this and the limitations of the suggestion. The negative comment about significance makes it not fully actionable.", "grounding_specificity_rationale": "The comment does not specify which method is being referred to or where this method addition would take place. It lacks a clear reference to a specific part of the paper or a unique element. The comment is a general suggestion without pinpointing the exact location or type of method.", "verifiability_rationale": "The comment contains a claim: 'Adding a method on the top of other methods to improve transferability is good but cannot be considered a significant contribution.' This claim is not 5 because the judgment about its significance is subjective and not supported by concrete evidence or logical reasoning within the review point itself.", "helpfulness_rationale": "The review point offers a suggestion (adding a method) but immediately critiques its significance ('cannot be considered a significant contribution'). This creates a potential conflict and reduces the helpfulness of the comment for the authors. While the suggestion itself might be helpful in certain contexts, the immediate negative judgment makes it less so overall."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential weakness in the hGRU architecture but does not explicitly state an action or suggestion for improvement. It simply states that the architecture seems adhoc and not wellmotivated.", "grounding_specificity_rationale": "The comment refers to 'the hGRU architecture' generally, without specifying a particular section, table, or figure of the paper. It does not identify the specific part of the paper being addressed.", "verifiability_rationale": "The comment contains a claim ('the hGRU architecture seems pretty adhoc and not very well motivated') but does not provide any supporting evidence or justification within the review point itself. It is presented as an observation rather than a claim supported by reasoning, common knowledge, or external references.", "helpfulness_rationale": "The comment points out a potential issue with the hGRU architecture, which could be helpful for the authors to consider. However, it does not provide specific, actionable suggestions or guidance on how to address the identified weakness. It is a constructive critique but lacks concrete recommendations for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment points to a specific line in the algorithm (Algorithm 1, Line 8) and asks for clarification, suggesting an actionable point of improvement. However, the action is not explicitly stated, requiring the authors to infer what needs to be done with s_n and s_t.", "grounding_specificity_rationale": "The comment refers to a specific line in the algorithm (Algorithm 1, Line 8), indicating some level of grounding. However, it also asks for clarification on two distinct aspects (asymptotic performance and experimental results), making the grounding less specific than fully specified.", "verifiability_rationale": "The comment asks for clarification and requests for information (asymptotic performance and experimental results) that are likely available to the authors. While not explicitly stating a claim, the request is a form of implied feedback that could be supported by evidence.", "helpfulness_rationale": "The comment raises a specific technical point (potential error in using s_n instead of s_t) and requests information that would be valuable for the authors (asymptotic performance and experimental results). While the specific action isn't stated, the reviewer points to concrete areas for improvement and asks for crucial information, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly identifies the area of confusion regarding the challenges of analyzing Adam under (L0, L1)smoothness and suggests a specific direction for clarification: explaining the differences from Zhang et al.'s work. This is an explicit statement of a problem and a suggestion for a solution, making it actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions the (L0, L1)smoothness condition and Adam, and even suggests comparing it to Zhang et al.'s work. This provides a clear grounding of the comment in the specific technical details of the paper, making it 5.", "verifiability_rationale": "The reviewer is making a claim: 'standard analysis on the (L0, L1)smoothness condition is not sufficient for analyzing Adam.' This claim requires verification by explaining the specific challenges and differences, which can be supported by logical reasoning and references to existing literature, making it verifiable.", "helpfulness_rationale": "The reviewer's request for clarification on a specific technical point (challenges of Adam under (L0, L1)smoothness) is directly aimed at improving the authors' understanding and addressing a potential area of confusion. This is a 5 suggestion for the authors, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point 'force the neural network to memorize them' is somewhat vague. While it suggests an issue with the neural network's behavior, it doesn't explicitly state *what* needs to be done to achieve this memorization or how to implement it. The reviewer also suggests toning down the statement, implying the original statement was too strong and lacked specificity in its action. Therefore, it's not fully actionable as it doesn't provide clear steps for the authors to take. The minor point about the method section being wordy also lacks specific action, making it less actionable.", "grounding_specificity_rationale": "The review point 'force the neural network to memorize them' generally refers to the neural network. While the reviewer later clarifies their understanding to be about a 'critical point,' the initial phrasing doesn't pinpoint a specific section, table, figure, or unique aspect of the neural network being addressed. The minor point about the method section is also general, lacking specific grounding. Therefore, the initial phrasing is weakly grounded, and while the clarification adds specificity, the initial point lacks it.", "verifiability_rationale": "The review point contains a claim: 'I would tone down this statement, in my understanding, the neural network does not memorize an exact \"critical point\" as such in TopoNet 24.' The reviewer provides a justification for their understanding, stating their interpretation of how neural networks operate in the context of TopoNet. This justification, while based on their understanding, could be considered verifiable as it relies on the reviewer's interpretation of external knowledge (TopoNet). However, it doesn't provide a direct citation or evidence within the review point itself to support this claim. Therefore, it's 3 as it relies on the reviewer's interpretation of external knowledge.", "helpfulness_rationale": "The review point is helpful in identifying a potential issue with the neural network's behavior and suggests a way to tone down the statement. The reviewer also points out areas for improvement in the method section and grammar. While the initial phrasing could be more specific, the reviewer provides clear feedback and actionable suggestions for the authors. The suggestions for the method section and grammar are concrete and directly address potential weaknesses. Therefore, it's 4 as it provides clear feedback and actionable suggestions."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the existence of pedestrian detectorbased twostep methods and endtoend methods, which are implicit actions or suggestions that imply limitations of the former. However, it doesn't provide concrete steps on how to implement these suggestions or modify the current draft. The action is implied but not explicitly stated or detailed.", "grounding_specificity_rationale": "The comment discusses the general basis of person reidentification methods and mentions 'twostep method' and 'endtoend method' without specifying which part of the paper or section it is referring to. It doesn't identify a specific section, table, figure, or unique aspect of the paper. The grounding is at a high level, not pointing to a specific element of the paper.", "verifiability_rationale": "The comment presents factual information about existing methods but does not make any claims or judgments that require verification. It states what is known about the twostep and endtoend methods without providing logical reasoning, common knowledge, or external references to support its statements. It's a descriptive summary, not a claim.", "helpfulness_rationale": "The comment provides context and highlights alternative approaches to person reidentification, which could be helpful for readers to understand the evolution of the field and the potential limitations of the twostep method. However, it doesn't directly address the authors' specific draft or provide actionable feedback on how to improve it. It offers a broader perspective rather than specific, constructive suggestions for the authors' work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of 'add a first sentence' to the specified section, making it a clear and direct instruction. It does not require the authors to infer what needs to be added, thus being explicit. The action is also very concrete, specifying the exact location (Section 3.2) and the nature of the addition (a first sentence).", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 3.2', which is a specific part of the paper. The reviewer clearly identifies the section where the suggestion is directed. The comment also specifies what the suggestion is for this section ('introduce what this section is about'), making it specific to the identified part.", "verifiability_rationale": "The review point is a suggestion or recommendation, not a claim that requires verification. It proposes an improvement to the paper without making a statement that needs to be supported by evidence or reasoning. Therefore, it does not fit into the 'Claim Extraction' step for verifiability verification.", "helpfulness_rationale": "The review point is a clear and specific suggestion to improve the paper by adding a first sentence to a section. This is a direct and actionable piece of feedback that is likely to be helpful for the authors in improving the clarity and structure of their work. The suggestion is concrete and does not require further elaboration or justification within the review point itself."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment \"Line 44: What is meant by the initial rationale selector is perfect?\" is a question about the current state of the rationale selector, not an instruction or suggestion for improvement. It doesn't point to a specific problem or propose a concrete change. It's more of a metacomment about the existing review process.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper or concept being discussed. It's a general statement about the \"initial rationale selector.\" Therefore, the grounding is weak. It also doesn't specify what is meant by \"perfect,\" making it underspecific.", "verifiability_rationale": "The comment contains a claim (\"It seems if it were perfect no additional work needs to be done\"), but it doesn't provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a question and observation, not a verifiable assertion.", "helpfulness_rationale": "The comment is a question about the current state of the review process and doesn't directly provide actionable feedback on how to improve the draft. It doesn't identify a specific weakness or propose a concrete solution. It's more of a reflection on the process rather than a helpful critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the definition of uncertainty is unclear and provides a general suggestion for improvement. While the reviewer identifies a lack of clarity, they don't specify *how* the definition is unclear or what specific aspect needs improvement. The suggestion is to clarify the relationship between the posterior and different types of uncertainty, but it doesn't offer concrete steps on how to do this. Therefore, while the reviewer points out a problem, the lack of specific details makes it 3 but not fully actionable.", "grounding_specificity_rationale": "The reviewer's comment explicitly mentions 'uncertainty is defined based on the posterior distribution.' This directly points to a specific part of the paper and how it's being discussed. However, the reviewer doesn't specify *which* aspect of the posterior distribution is causing confusion. They suggest a different interpretation involving priors and epistemic model uncertainty, but don't link it back to the current definition. Therefore, the grounding is present, but the specificity is limited.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement rather than a claim that can be verified. They are stating that the current definition of uncertainty is unclear and proposing a different explanation. There is no logical reasoning, common knowledge, or external references provided to support this claim. It's a suggestion for clarification, not a verifiable statement about the paper.", "helpfulness_rationale": "The reviewer is attempting to improve the clarity of the paper by suggesting a different interpretation of uncertainty. This is a helpful goal. However, the suggestion is very general and lacks specific details. The reviewer doesn't provide concrete examples of where the current definition is unclear or how their proposed explanation would address those specific issues. Therefore, while the intent is helpful, the lack of specificity makes it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about whether domain ontologies were used, which implies a potential area for improvement. However, the reviewer does not explicitly state what should be done if ontologies were not used, making the action somewhat vague. The reviewer also asks for clarification on a specific implementation detail (line 211), but does not suggest an alternative approach, making the action less explicit.", "grounding_specificity_rationale": "The reviewer asks two questions. The first question, 'It is not clear if authors also experimented with the usage of domain ontologies...', does not explicitly identify a specific part of the paper being addressed. The second question, 'Line 211: How many questions were created for this zeroshot intent classifier and what is the accuracy of this system?', explicitly refers to a specific line in the paper. However, the reviewer is asking for information rather than making a judgment about what should be done, so the specificity is limited to the request for details.", "verifiability_rationale": "The reviewer asks two questions. The first question, 'It is not clear if authors also experimented with the usage of domain ontologies...', implies a claim that the authors did not use ontologies, but the paper does not explicitly state whether they did or did not. The second question, 'Line 211: How many questions were created for this zeroshot intent classifier and what is the accuracy of this system?', implies a claim about the missing information on line 211. However, the paper does not provide any evidence to support or refute these claims.", "helpfulness_rationale": "The reviewer asks two questions. The first question seeks clarification on a potential alternative method (using ontologies) and the second question seeks clarification on a specific implementation detail. While these are valid questions that could help the authors improve their understanding, they do not directly suggest concrete actions or improvements. The reviewer is asking for information rather than providing actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the missingness of citations to recent MARL work. While it doesn't directly tell the authors *what* to cite, it clearly identifies a gap in the related work section. This makes it partially actionable as it points to a specific area for improvement.", "grounding_specificity_rationale": "The review point identifies the relevance of MARL, exploration, and coordination to the paper's content. While it doesn't pinpoint a specific section or element within the paper, it provides a strong indication of where the missing citations are most likely needed. This makes it somewhat grounded.", "verifiability_rationale": "The review point is a statement of a problem (missing citations) rather than a claim that requires justification or support. It doesn't present any logical reasoning, common knowledge, or external references to back up the statement. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper's context of related work. By highlighting the lack of citations to relevant recent MARL papers, it provides the authors with a direction for further research and a better understanding of the current state of the field. While it doesn't offer specific citations, it guides the authors towards important areas of the literature. Therefore, it is 3 in identifying areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a comparison with other selfsupervised learning methods, which can be interpreted as an implicit action to explore alternative approaches. While not explicitly stated as an action, the suggestion implies a desire for improvement by comparing different methods. However, the action is vague and lacks specific details on how to perform the comparison.", "grounding_specificity_rationale": "The review point explicitly mentions 'other selfsupervised learning methods that are not based on contrastive learning.' This clearly identifies a specific aspect of the paper (the related work section or a discussion of different selfsupervised techniques) and what the suggestion is about. This is a strong example of 'Full Grounding' as it pinpoints a specific section and provides a clear target for the suggestion.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a suggestion for improvement rather than a statement of fact or opinion. Therefore, it fits the 'X' category as it doesn't present any verifiable information.", "helpfulness_rationale": "The review point suggests comparing with other selfsupervised learning methods, which could be a valuable direction for the authors to explore. This suggests a potential improvement or alternative approach, which can be helpful in the development of their method. While it might not be the only or most critical issue, it provides a concrete suggestion for further investigation. Therefore, it is better than '2' or '3'."}
{"actionability_label": "3  3", "grounding_specificity_label": "3  3", "verifiability_label": "2  2", "helpfulness_label": "3  3", "actionability_rationale": "The reviewer is asking a question, which is an explicit request for clarification. They are not suggesting a specific action to take based on the information given. The request is clear and directly addresses a potential ambiguity in the implementation of the abstention process. It seeks a definition and a comparison.", "grounding_specificity_rationale": "The reviewer is asking about the 'abstention process,' 'prediction probability threshold,' and 'decision threshold.' These are specific technical terms related to the model's behavior. They are not asking for a general explanation of these concepts. The reviewer is asking about the *relationship* between these specific concepts in the context of their system. They are seeking a comparative explanation.", "verifiability_rationale": "The reviewer is stating a question, which is not a claim in itself. However, the *answer* to the question will be a claim (e.g., \"The abstention process is based on a prediction probability threshold\"). Once the answer is provided, its verifiability can be assessed. The reviewer is asking a question that can be answered with information available to them and the model.", "helpfulness_rationale": "The reviewer is asking for clarification on a mechanism that directly affects how their draft is processed by the model. Understanding this process is valuable for authors who want to optimize their submissions. The question seeks a definition and a comparison, which are concrete pieces of information that would benefit the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point makes a direct statement about Megatron's performance being 'overrated' compared to other models. This is an explicit action or suggestion that the authors should reevaluate Megatron. However, the reviewer does not explicitly state how to improve Megatron or what specific aspects need adjustment. The suggestion is implicit, making it somewhat vague and lacking detail on how to apply it.", "grounding_specificity_rationale": "The reviewer compares Megatron's performance to other models but does not explicitly identify a specific part of the paper being addressed. The comparison is general and does not point to a particular section, table, or figure. The reviewer mentions 'other approaches' like RoBERTa, ELECTRA, and DeBERTa but does not specify which aspect of these models is being compared to Megatron. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer makes a claim that Megatron's performance is 'overrated' and suggests a comparison with other models. However, this claim is not supported by any specific evidence or justification within the review point itself. The reviewer does not provide logical reasoning, common knowledge, or external references to back up this assertion. Therefore, the verifiability is low as the claim is not wellsupported.", "helpfulness_rationale": "The review point raises a question about the impact of switching BPE vocabulary types on performance. While this is a valid question for the authors, it is framed as a question rather than a direct critique or suggestion for improvement. The reviewer also makes a general statement about Megatron's performance being 'overrated,' which is somewhat vague and lacks specific guidance. The overall helpfulness is limited as the points are not strongly constructive or actionable."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point is a critique of the authors' analysis and does not directly suggest any specific actions the authors should take. It questions the interpretation of the results and offers an alternative explanation. Therefore, it lacks explicit and actionable feedback.", "grounding_specificity_rationale": "The reviewer refers to 'lines 128 to 149' and 'Fig 3' but does not explicitly identify which part of the paper is being analyzed or how the observation relates to that specific part. The connection to the paper is implied but not clearly established. The reviewer's statement is general and does not pinpoint a specific section, table, or figure. The mention of external references does not ground the comment within the paper's content.", "verifiability_rationale": "The reviewer provides an alternative interpretation of the results based on established concepts in deep learning (class selectivity and context). This interpretation challenges the authors' hypothesis. While the reviewer does not explicitly claim that 'additional context may allow the network to reduce its dependency' is a fact, the alternative explanation provides a basis for verification. The reviewer's statement is a claim that requires justification, and the alternative explanation serves as a form of logical reasoning. However, the reviewer does not provide specific examples or references to support their alternative interpretation within the context of the paper being reviewed.", "helpfulness_rationale": "The review point is valuable because it identifies a potential flaw in the authors' analysis and offers a plausible alternative explanation based on established literature. This directly helps the authors understand the limitations of their approach and potentially improve their model. The reviewer's comment provides a constructive critique that can lead to further investigation and refinement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a weakness in the paper's conclusions regarding the impact of continuous learning with unlabeled data on representation quality. While the reviewer doesn't provide explicit, detailed steps on how to improve the draft, they *imply* an action: investigating alternative combination methods. The suggestion to explore rehearsalfree and featurereplay methods is a clear direction for improvement, even if the paper doesn't explicitly mention these methods. Therefore, the action is implied and points towards concrete actions.", "grounding_specificity_rationale": "The reviewer mentions 'continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality' as a belief. While this is a general statement, the reviewer doesn't explicitly point to a specific section, table, figure, or unique aspect of the paper where this belief is discussed. The grounding is implied but not precise. The suggestions about rehearsalfree and featurereplay methods are also not explicitly linked to specific parts of the paper. Therefore, the grounding is weakly specific.", "verifiability_rationale": "The reviewer makes a claim: 'The results might come from the limited exploration of combination methods.' They then provide specific suggestions for improvement, namely rehearsalfree methods (like R1 and R2) and featurereplay methods. They also mention a 'recent work R3 also employs feature replay.' These specific methods and references directly support the claim and provide a clear path for the authors to address the identified issue. The reasoning is logical, and the evidence is present in the form of suggested methods and related work. Therefore, the claim is 5.", "helpfulness_rationale": "The reviewer clearly states a problem ('Some conclusions are not convincing') and offers concrete solutions ('The results might come from the limited exploration of combination methods. In rehearsalfree continual learning, featurereplay methods have shown great potential...'). The suggestions are directly related to the identified weakness and provide a clear direction for improvement. The reviewer doesn't just point out a problem; they offer a path towards resolution. The suggestions are actionable and provide specific methods to explore. Therefore, the review point is 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the weakness 'lack of meaningful baselines' and proposes a specific action to address it: 'comparing with a chainofthought prompting approach'. This directly points to an actionable recommendation.", "grounding_specificity_rationale": "The review point refers to 'various model criticism techniques' mentioned in Section 2. While it identifies a general area of concern, it does not explicitly name a specific technique or location in the paper where this lack of baselines is an issue. The reviewer is making a general statement about the experimental setup.", "verifiability_rationale": "The review point states a weakness ('lack of meaningful baselines') and suggests a *solution* ('comparing with a chainofthought prompting approach'). It doesn't explicitly claim that *this specific comparison* is a valid or justified approach. The focus is on identifying the problem of lacking baselines.", "helpfulness_rationale": "The review point clearly identifies a weakness in the experimental design (lack of meaningful baselines) and provides a specific suggestion for improvement (comparing with chainofthought prompting). This directly addresses a practical issue for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about the pretraining dataset but doesn't provide a direct answer or suggest any actions for the authors. It's a question posed without context, leaving the authors without a clear direction. The implicit suggestion is to clarify the training procedure, but it's not explicitly stated or actionable.", "grounding_specificity_rationale": "The review point doesn't explicitly identify a specific aspect of the paper being addressed (e.g., 'Section 3.2', 'Figure 4'). It's a general question about the pretraining process. Therefore, it's 1 in a specific part of the paper. The question is about the *entire* dataset or the *training set*, which are general terms.", "verifiability_rationale": "The review point poses a question about the generalization of the model without providing any evidence, logical reasoning, or external references. There is X being made, so the verifiability scale doesn't apply.", "helpfulness_rationale": "The review point asks a question about the pretraining dataset and the model's generalization ability. While this is relevant information for the authors, the question is posed without providing any context or potential solutions. It doesn't directly answer what the authors should do or how to improve their model based on this information. It's a question without a clear direction or actionable suggestion."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "1 (1)", "verifiability_label": "X (X)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point states a fact about hardware and software dependence but does not specify any action the authors should take. It is a statement of observation rather than a directive.", "grounding_specificity_rationale": "The review point is a general statement about potential hardware and software dependencies and does not specify which part of the paper or unique element this refers to. It lacks grounding specificity as it does not identify a specific section, table, figure, or unique aspect of the paper being addressed.", "verifiability_rationale": "The review point is a statement of fact, not an opinion or suggestion. It does not contain a claim that requires verification. Therefore, it does not have verifiability to evaluate.", "helpfulness_rationale": "The review point highlights a potential limitation of the work related to hardware and software dependencies. While it doesn't directly tell the authors what to change, it points out a potential issue that they should consider for future work, making it 3 in identifying potential areas for improvement and future research."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a small performance difference in an ablation study but does not provide any guidance on how to interpret or act upon this difference. The comment lacks explicit or implicit suggestions on what this discrepancy means for the model or the ablation strategy. The reviewer is essentially stating the existence of a difference without offering any action or interpretation.", "grounding_specificity_rationale": "The reviewer's comment is 1 in the paper itself. They are referring to the results of an ablation study (Tab. specific table number if provided, otherwise implied) without explicitly linking this finding back to a specific section, table, figure, or unique aspect of the paper being discussed. The grounding is implicit, referring to external results rather than directly to the paper's content. The specificity is also low as the reviewer is not detailing what needs to be addressed in this part (the ablation study results) based on their observation.", "verifiability_rationale": "The reviewer's statement about the 'little difference between the results reported for the ablation study in Tab.' is a claim that needs verification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as an observation without any justification or evidence within the review point itself.", "helpfulness_rationale": "The reviewer's comment is 3 in identifying a potential issue or area for further investigation (the small performance difference in the ablation study). However, the lack of grounding and verifiability makes the comment unhelpful in terms of providing actionable guidance or justification for the observed difference. The reviewer is pointing out a problem but not providing a solution or explanation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'No new evaluation metrics are proposed. Only existing evaluation metrics are proposed.' This is a clear, direct statement of what the reviewer is suggesting. The action of not proposing new metrics is also explicitly stated, and the suggestion to focus on existing metrics is clear. Therefore, this comment is 5 as it directly identifies a potential limitation and suggests a specific course of action.", "grounding_specificity_rationale": "The comment refers to 'evaluation metrics' in general, which is a somewhat broad term. While it mentions 'new' and 'existing,' it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper where this concern arises. The grounding is not as precise as it could be. However, the comment does specify the *type* of metric (new vs. existing) and the area of concern ('indepth exploration of experimental results'), which adds a degree of specificity. Therefore, the grounding is weak but not entirely absent.", "verifiability_rationale": "The comment contains a claim: 'No new evaluation metrics are proposed. Only existing evaluation metrics are proposed.' This is a statement of intent or a suggestion. However, the comment does not provide any justification or reasoning for why only existing metrics should be used or why new ones aren't proposed. There are no logical arguments, common knowledge, or external references provided to support this claim. Therefore, the verifiability of this claim is low.", "helpfulness_rationale": "The comment raises a valid point about the limitations of relying solely on existing evaluation metrics and suggests a potential improvement by exploring them in more depth. However, the comment lacks specific suggestions on how to conduct this indepth exploration. It doesn't specify which experimental results need exploration or provide any guidance on the nature of this exploration. While the reviewer identifies a potential area for improvement, the lack of concrete suggestions makes the comment less helpful than it could be. The impact is limited."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out the problem of the dual use of 'K' and provides specific line numbers (L166 and L176) where this occurs. This makes the action clear and allows the authors to directly address the issue.", "grounding_specificity_rationale": "The reviewer not only identifies the problem but also explicitly pinpoints the exact locations in the paper where the dual use of 'K' occurs (L166 and L176). This strong grounding allows the authors to precisely understand where the issue lies.", "verifiability_rationale": "The reviewer makes a clear claim about the notational abuse of 'K'. While they don't provide explicit evidence of the consequences of this abuse (like potential confusion), they do point to specific instances where the problem exists (L166 and L176). This provides strong support for their claim.", "helpfulness_rationale": "The reviewer clearly identifies a problem (notational ambiguity) and provides specific locations where it occurs. This is a direct and actionable feedback that can help the authors improve their paper by ensuring consistent notation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitation of the work being primarily of theoretical interest and the AMP algorithm's unclear utility for nonGaussian problems. This directly implies an action: 'improve the understanding of AMP for nonGaussian problems'. However, the reviewer does not provide specific steps or details on how to achieve this improvement.", "grounding_specificity_rationale": "The reviewer refers to 'the weak recovery problem studied here' and 'the AMP algorithm'. While they identify the area of concern, they do not specify a particular section, table, figure, or unique aspect within these broad categories. The reference remains general.", "verifiability_rationale": "The reviewer makes a claim about the 'limited practical impact' of the work. They support this claim by stating that the 'weak recovery problem studied here is primarily of theoretical interest, and it is not clear if the AMP algorithm is useful for nonGaussian problems'. This provides a logical connection between the identified problem and the claimed limitation, making the claim 3.", "helpfulness_rationale": "The reviewer identifies a potential limitation of the work's scope and applicability, specifically regarding its theoretical focus and the AMP algorithm's performance on nonGaussian data. They suggest focusing on nonGaussian problems as a direction for improvement. While the comment doesn't offer a concrete solution, it points towards a specific area for future work and helps the authors refine their focus, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a point of confusion regarding the relevance of human cognition and asks a direct question about its potential impact. The language is clear and directly identifies the area needing clarification. The reviewer provides a concrete action: 'Perhaps the interaction between cognitively basic adaptation mechanisms and the structure of the CPR itself has more of an effect on whether selforganization will fail or succeed than previously appreciated.' This is a clear statement of what is unclear.", "grounding_specificity_rationale": "The reviewer directly references a specific part of the paper ('Perhaps the interaction between cognitively basic adaptation mechanisms and the structure of the CPR itself has more of an effect on whether selforganization will fail or succeed than previously appreciated.') using literal mention. They also provide further details about the point of confusion ('unclear whether bringing connections to human cognition makes sense' and 'previously appreciated'). This demonstrates a clear understanding of the section and the specific claim being made.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question and making a request for clarification. The point is a question, not a statement that needs to be proven or supported. Therefore, it falls outside the scope of verifiability.", "helpfulness_rationale": "The reviewer identifies a potential area for improvement in the authors' work by suggesting the inclusion of citations to support 'previously appreciated' findings. While the suggestion itself isn't a concrete fix, it is a valuable piece of feedback that directly addresses a potential weakness in the authors' presentation. The reviewer is actively engaging with the authors' work and suggesting a specific improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the issue ('wording is overly exaggerated') and points to a specific section ('conclusion'). However, it does not provide concrete steps on how to fix the exaggerated wording. The reviewer identifies the *problem* but not the *specific action* to address it.", "grounding_specificity_rationale": "The comment explicitly mentions the 'conclusion' and the specific phrase '... our pioneering contributions herald a new era in robotic adaptability ...'. This allows the reader to precisely identify the referenced part of the paper. The comment also generally points to 'word choice being flamboyant' in the writing, which, while not specific to a single phrase, still identifies a clear area for improvement within the paper.", "verifiability_rationale": "The comment contains a claim ('wording is overly exaggerated') and identifies an issue ('word choice is flamboyant'). While it doesn't provide external references or logical reasoning to *prove* the exaggerated wording, the claim itself is a statement that can be verified by reading the conclusion. The reviewer's statement is a reasonable assessment of writing style.", "helpfulness_rationale": "The comment identifies a specific area for improvement ('the conclusion') and points to a specific issue ('overly exaggerated wording'). It also highlights a general problem ('word choice is flamboyant'). This provides a clear direction for the author to focus their revision efforts, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point implicitly suggests an action by mentioning the need for ablation experiments. However, it doesn't explicitly state what needs to be done to perform these experiments or how the results should be interpreted. The action is present but needs to be inferred.", "grounding_specificity_rationale": "The review point explicitly mentions the need to compare the proposed method with TubeR in terms of learnable parameters and GFLOPs. This clearly identifies the specific part of the paper (comparison with TubeR, metrics: learnable parameters, GFLOPs) that needs attention. The grounding is strong and specific.", "verifiability_rationale": "The review point makes a claim that 'the authors need to perform ablation experiments to compare the proposed method with other methods (e.g., TubeR) in terms of the number of learnable parameters and GFLOPs.' This claim is supported by the specific comparison method (TubeR) and metrics (learnable parameters, GFLOPs) mentioned. The evidence is clear and directly related to the point being made.", "helpfulness_rationale": "The review point identifies a valid and relevant area for improvement by suggesting ablation studies to understand the tradeoffs between performance and efficiency compared to a relevant baseline (TubeR). While it doesn't provide specific details on *which* aspects to ablate or *how* to interpret the results, it provides a clear direction for the authors to take, which is helpful in guiding their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the absence of comparison to simple feature acquisition baselines as a weakness. This directly implies an actionable step for the authors: conduct this comparison. While the action is not fully specified (e.g., which metrics to use), the reviewer clearly identifies a missing component that they believe is necessary for proving the effectiveness of their approach. The phrase \"The biggest weakness of the paper is that it does not compare to simple feature acquisition baselines like expected utility or some such measure...\" directly points to a specific area for improvement.", "grounding_specificity_rationale": "The review point mentions 'simple feature acquisition baselines\" and specifically names \"expected utility\". This indicates that the reviewer has identified a specific aspect of the paper (the comparison to a particular type of baseline) and is pointing out a deficiency in this area. The grounding is achieved by naming a specific type of baseline, which provides a clear target for the authors to address. The specificity is also evident as the reviewer names a concrete example of the baseline.", "verifiability_rationale": "The review point makes a claim: \"The biggest weakness of the paper is that it does not compare to simple feature acquisition baselines...\". This is a claim that requires verification. However, the review point itself does not provide any evidence or reasoning to support this claim. The reviewer is stating their assessment of the paper's content, but they are not explaining *why* they believe this is a significant weakness or providing any references to back it up. Therefore, the verifiability is low because the claim is made without sufficient justification or evidence within the review point itself.", "helpfulness_rationale": "The review point identifies a general weakness in the paper's evaluation methodology \u2013 the lack of comparison to feature acquisition baselines. While this is a valid point, the review point itself does not offer any specific suggestions or guidance on how the authors should approach this comparison. The reviewer points out a missing piece but doesn't provide a concrete solution or explain *why* this missing piece is so crucial. The writing style issue is also vague and doesn't provide actionable feedback. The helpfulness is limited because the reviewer identifies a problem but doesn't offer a clear path forward for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out areas for improvement such as 'how about other bit operations?' and 'please give more explanations'. These are explicit actions, but they lack specific details on how to achieve these improvements. The reviewer also suggests improvements related to DVS input handling and energy consumption analysis, which are implicit actions.", "grounding_specificity_rationale": "The reviewer mentions 'Fig. 5 a' which is a specific element of the paper, indicating some level of grounding. However, the reviewer also mentions 'aer format' which is ambiguous and does not clearly identify a specific part of the paper. While the paper element is identified, the broader context is not fully specific.", "verifiability_rationale": "The reviewer states 'Fig. 5 a seems strange' and 'If you can analyze the energy consumption as reference15 did'. The first statement is a claim that is not supported by any evidence or reasoning within the review point. The second statement, while suggesting an improvement, does not provide a clear justification or method for analysis.", "helpfulness_rationale": "The review points out potential issues with Figure 5a and suggests improvements in handling DVS input and analyzing energy consumption. While these suggestions are relevant, they lack specific details on how to address the identified issues or how to implement the suggested improvements. The reviewer's comments are focused on areas that need clarification or further work, but without concrete steps, their helpfulness is limited."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a lack of clarity in how the embeddings are combined and fed into the CSCM. While the paper mentions 'separate embedding and addition with positional encoding,' it doesn't explicitly state the mechanism for combining these embeddings before being used as input for the CSCM. This leaves the reviewer needing to infer the combination method, making the action implicit rather than explicit. The reviewer expects a clear explanation of the combination process to apply the suggested improvement.", "grounding_specificity_rationale": "The review point focuses on a specific aspect of the method: the combination of embeddings and their input to the CSCM. The paper mentions 'separate embedding and addition with positional encoding,' which can be considered a specific part of the method. The reviewer then clarifies that they need to know how these are combined and fed into the CSCM. This specificity allows the authors to identify the exact area they need to improve. The grounding is also specific as the reviewer is asking about a particular implementation detail.", "verifiability_rationale": "The review point identifies a specific technical detail about the method (how embeddings are combined and fed into the CSCM). However, the paper does not provide any justification or evidence for this specific combination method. The reviewer is left to infer the intended process, which makes the claim 1. There are no logical reasons, common knowledge, or external references provided to support this specific combination method.", "helpfulness_rationale": "The review point clearly identifies a lack of clarity in a specific technical detail of the paper. The reviewer explicitly states that the paper mentions 'separate embedding and addition with positional encoding' but fails to explain how the embeddings are combined and fed into the CSCM. This lack of clarity makes it difficult for the authors to understand and potentially implement the suggested improvement. The feedback is specific but lacks the necessary details to be fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of innovation and the similarity to object detection algorithms. They also point out that many MLMs can already accomplish the object detection task by themselves. This provides a clear direction for the authors to address the novelty of their approach.", "grounding_specificity_rationale": "The reviewer doesn't explicitly name a specific section or table, but they refer to 'the article itself' and 'the field of MLMs' generally. They also mention 'multigranularity and multiscale' and 'object detection algorithms,' which provides some level of specificity, although not pinpointing a single section.", "verifiability_rationale": "The reviewer makes a claim that the approach is not innovative and is a common approach migrated from object detection. They support this claim by stating that 'many MLMs can already accomplish the object detection task by themselves nowadays.' This provides logical reasoning and an example, making the claim verifiable.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper's contribution \u2013 the lack of novelty in applying multigranularity and multiscale approaches from object detection to MLMs. They also suggest comparing their approach to object detection algorithms, which is a concrete and helpful suggestion for the authors to consider."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer poses a question about the expressiveness of 'fast SMP' compared to 'SMP' and requests more discussion on the 'power of different architectures'. While the question is specific, it doesn't explicitly state what action the authors should take. The desire for more discussion is general and doesn't point to a specific part of the paper or a concrete issue. Therefore, while the reviewer points to a potential area for improvement, they don't directly instruct the authors on how to address it. The question is openended and doesn't provide a clear action for the authors to follow.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly refer to a specific part of the paper or a specific issue within 'fast SMP' or 'SMP'. The comment is a general question about the 'power of different architectures'. There is no mention of a particular section, table, figure, or unique element of the paper. Therefore, the comment is 1 at all.", "verifiability_rationale": "The reviewer's comment is a statement of desire and a question, not a claim that requires verification. There is no assertion of something being true or false. Therefore, it does not contain a claim that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer's comment raises a relevant question about the expressiveness of 'fast SMP' and requests more discussion on the 'power of different architectures'. This is a pertinent topic that could be beneficial for the authors, especially if they have experience with these concepts. The comment is clear and directly points to a potential area for improvement. While it doesn't offer a solution, it identifies a specific topic that could lead to valuable insights. Therefore, it is a helpful comment that prompts further consideration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests evaluating across different splits, which is an action the authors can take to potentially improve their results. While the action is not explicitly stated, the reviewer implies it. The authors can infer that they should change their evaluation strategy. This suggests the comment is 3 as it points towards a concrete step, even if not directly stated.", "grounding_specificity_rationale": "The reviewer refers to the 'evaluation' section or process, which is a broader concept. While the reviewer implies it's about the evaluation, the authors need to infer that the relevant part is the evaluation section or process. This suggests the comment is 4 as the authors can deduce the area of concern, but it's not explicitly pointed out. The phrasing 'not simply different initialisation seeds' helps to ground it to the evaluation aspect.", "verifiability_rationale": "The reviewer is making a suggestion for improvement, not stating a claim that needs verification. The reviewer is proposing a different experimental design to potentially get better results. This is a proposition, not a verifiable statement. Therefore, it falls under 'X' or 'X' as there is X requiring justification.", "helpfulness_rationale": "The reviewer points out a potential limitation in the current evaluation methodology and suggests an alternative approach that could lead to better results. This is a valuable suggestion for researchers as it highlights a potential area for improvement in their experimental design. While it doesn't directly tell the authors what to do, it guides them towards a potentially better evaluation strategy, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'can be combined together'. This action is also concrete, as it clearly indicates what needs to be done (combine the first two bullets) and where it should be done (the introduction). The reviewer provides a clear instruction on how to implement this action.", "grounding_specificity_rationale": "The review point explicitly refers to 'the first two bullets about contributions (at the end of the intro)'. This is a very specific reference to a particular section of the paper, making the grounding fully specific.", "verifiability_rationale": "The review point is a suggestion for improvement, not a claim that requires verification. There is no statement that needs to be supported by evidence or references. It is a constructive suggestion, not a claim of fact.", "helpfulness_rationale": "The review point identifies a specific, actionable improvement (combining redundant bullets) in the introduction. This is a clear and actionable suggestion that is likely to be helpful for the author in streamlining their work."}
{"actionability_label": "2", "grounding_specificity_label": "1 and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a weakness in the paper by stating that the types of situations/social norms are not clear. While this is a valid observation, the reviewer does not explicitly state what needs to be done to address this weakness. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer refers to 'the main paper' generally, without specifying a particular section, table, figure, or unique element. The issue is broad and doesn't pinpoint the exact location of the lack of clarity.", "verifiability_rationale": "The reviewer makes a claim that 'the types of situations/social norms are not clear in the main paper.' This is a verifiable statement, as the lack of clarity is a factual observation. However, the reviewer does not provide any external references or logical reasoning to support why this lack of clarity is a problem.", "helpfulness_rationale": "The review point identifies a valid weakness in the paper, which can be helpful for the authors to understand. However, the reviewer does not provide any concrete suggestions or actions for the authors to take. The feedback is present but lacks actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests the authors 'do need to refer to more recent trends in the vision community'. While this points towards a direction for improvement, it doesn't explicitly state the steps or how to implement this reference. The action is implied rather than clearly defined.", "grounding_specificity_rationale": "The reviewer mentions 'more recent trends in the vision community' as a potential improvement area. However, they do not specify which part of the paper this refers to or how it directly relates to the algorithm's performance. The grounding is present at a high level but lacks specificity to a particular section or issue.", "verifiability_rationale": "The reviewer makes a claim about the importance of closed contours and robustness to weak boundaries as key tasks. They also suggest referring to 'more recent trends in the vision community' as a way to improve this. This claim is logically connected to the suggested improvement, making it 3. However, it lacks specific references or examples to back up the claim about 'more recent trends'.", "helpfulness_rationale": "The reviewer raises a valid point about the paper's scope and suggests looking into 'more recent trends in the vision community' to demonstrate improvement. This directly addresses a potential ambiguity for the authors regarding the paper's contribution and provides a concrete direction for improvement. The suggestion is clear and relevant."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need for more baselines and domains, making it actionable. While the *why* is missing, the *what* is clear.", "grounding_specificity_rationale": "The reviewer explicitly identifies the need for more baselines and domains, which is a specific request. However, the *section* where this improvement should be reflected isn't explicitly named, making the grounding slightly weak.", "verifiability_rationale": "The reviewer states a desire for more information but doesn't provide any logical reasoning, external references, or examples to support this desire.", "helpfulness_rationale": "The reviewer clearly states a desire for more information, which directly points towards concrete improvements the authors can make. While it doesn't provide *specific* suggestions, it's a helpful direction."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment implicitly suggests an action (defining the dashed lines) but lacks specific details on how to achieve this, making it less directly actionable. Authors can infer the need to understand the purpose and usage of these lines but not the exact definition or how to obtain it.", "grounding_specificity_rationale": "The comment explicitly refers to specific parts of the paper (figures 2AB and 4B), indicating good grounding. However, it doesn't specify what information needs to be defined about these figures, making it less specific. Authors cannot confidently determine what information is missing or needs clarification about the dashed lines in these figures.", "verifiability_rationale": "The comment is not a claim requiring verification. It's a request for clarification. There are no logical reasoning, common knowledge, or external references provided to support the request.", "helpfulness_rationale": "The comment points to a potential area for improvement (clarity on the figures) but doesn't provide direct, actionable feedback or a claim to verify. It's more of a suggestion for the authors to clarify their own figures rather than providing specific instructions or verifiable information to the reviewers."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The statement identifies a potential issue (lack of comparability) but does not explicitly instruct the authors on what to do next. It's a critique of the results rather than a direct action the authors should take based on this review point.", "grounding_specificity_rationale": "The comment does not specify which results or methods are not comparable. It is a general statement about the significance of the results, not tied to a specific part of the paper or analysis.", "verifiability_rationale": "The statement expresses an opinion about the significance of the results without providing any supporting evidence or logical reasoning. It lacks the verification methods required to make the claim verifiable.", "helpfulness_rationale": "The statement is critical and raises concerns, but it does not directly suggest how the authors can improve their method based on this review. It's a statement of concern rather than a constructive suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the perceived lack of novelty and the similarity to DeCorr. While the reasons for this assessment are provided, the reviewer does not offer concrete suggestions for improvement beyond stating the problem. The action is identified (perception of limited novelty), but the lack of specific guidance makes it partially actionable.", "grounding_specificity_rationale": "The reviewer broadly characterizes the work as 'limited novel' and 'straightforward application' without pinpointing a specific section, table, or figure that needs improvement. While they mention 'DeCorr' and 'graph collaborative filtering,' they don't specify which part of the paper is affected. The grounding is general and doesn't clearly identify the issue.", "verifiability_rationale": "The reviewer makes a claim about the paper's perceived lack of novelty and similarity to DeCorr. However, they do not provide any evidence, references, or logical reasoning to support this claim. The statement is presented as an observation rather than a welljustified assertion.", "helpfulness_rationale": "The reviewer's comment is primarily critical, pointing out a perceived weakness (lack of novelty) without offering any concrete suggestions for improvement. While they mention 'different datasets and backbones' and 'lack of unique insights,' they don't translate these into actionable recommendations for the authors. The feedback is presented as a critique rather than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two potential issues. The first, 'the Figure 2 is a little ambiguous, where some symbols are not explained clearly,' is 3. The reviewer could ask for clarification on specific symbols. However, the phrasing is general, making it difficult to pinpoint the exact action needed. The second issue, 'And the reviewer is curious about that whether there is information redundancy and interference in the multisphere icosahedral discretization process,' is also 3. The reviewer could ask for clarification or further explanation on this process. However, the phrasing is general and doesn't specify what kind of redundancy or interference is being referred to.", "grounding_specificity_rationale": "The review point identifies issues related to Figure 2 and the multisphere icosahedral discretization process. However, it does not explicitly state which specific part of the paper is being addressed. The reviewer is generally referring to these areas but doesn't provide precise references. For example, they don't specify 'Section 3.2, Figure 2' or 'Section 4.1, Method, Discretization Process'. This lack of specificity makes it difficult to determine the exact area the reviewer is referring to.", "verifiability_rationale": "The review point contains claims that can be verified. For the first part, 'the Figure 2 is a little ambiguous, where some symbols are not explained clearly,' the reviewer is claiming a lack of clarity. While the verifiability of *fixing* the figure depends on the authors' ability, the *claim* itself is based on an observation. For the second part, 'And the reviewer is curious about that whether there is information redundancy and interference in the multisphere icosahedral discretization process,' the reviewer is making a claim about a potential issue. However, the verifiability of this claim depends on the authors' ability to identify and explain the potential redundancy and interference. Therefore, the claims are 3 as they are based on observations or questions that can be investigated by the authors.", "helpfulness_rationale": "The review point raises two potential issues. The first, 'the Figure 2 is a little ambiguous, where some symbols are not explained clearly,' is 3. The reviewer is pointing out a potential area for improvement in the paper's presentation. The second part, 'And the reviewer is curious about that whether there is information redundancy and interference in the multisphere icosahedral discretization process,' is also 3. The reviewer is expressing a curiosity about a specific aspect of the method, which can prompt the authors to investigate and clarify this further. While the phrasing is general, it still points to specific areas of potential improvement or clarification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the limitation regarding Matern kernels and their polynomial decay, contrasting it with the assumed subgaussian spectrum. This is an explicit statement of a problem that can be directly addressed by the authors. The reviewer provides a clear explanation of why this assumption is restrictive, making the actionable.", "grounding_specificity_rationale": "The reviewer directly mentions \"Matern kernels\" and explains why they are not covered by the 'subgaussian spectrum\" assumption. This is a clear and specific identification of the relevant concept. The reviewer explicitly states the type of decay (polynomial) and how it differs from the assumed type of decay (subgaussian). This is a highly specific explanation of the issue.", "verifiability_rationale": "The reviewer makes a clear claim: \"The results of the paper could be restrictive\" due to the limited assumption about kernel spectra. The reviewer provides a reason for this claim: \"The authors assume that the spectrum of a kernel is subgaussian. This is OK, as the popular Gaussian kernels are in this class. However, another popular class of kernels such as Matern kernels are not included, since their spectrum only decay polynomially.\" This reasoning is logical and provides a basis for understanding the limitation. While it doesn't provide a direct example of how this restricts the results, it clearly explains the difference between the assumed property and the property of a relevant class of kernels.", "helpfulness_rationale": "The reviewer clearly identifies a potential limitation in the paper's methodology and suggests that this limitation could affect the generality of the results. This is a valuable piece of feedback for the authors. The reviewer points out a specific assumption that needs to be considered, which can guide the authors in either broadening their analysis or explicitly acknowledging the limitations of their current approach. This feedback is focused on improving the understanding and scope of the work, rather than simply pointing out a flaw."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the importance of unsupervised pretraining based on their analysis of Table 4. They also suggest focusing more on this aspect, which is a clear action for the authors to take. The reviewer identifies the specific aspect (unsupervised pretraining) and provides a reason for its importance, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer mentions 'unsupervised pretraining' and refers to 'Table 4' to support their claim. While they don't specify the exact section, the reference to a table implies they can identify the relevant part of the paper. The reviewer also specifies how the unsupervised pretraining is important based on the data in Table 4, adding detail to the identified aspect.", "verifiability_rationale": "The reviewer makes a claim about the lack of detailed discussion on unsupervised pretraining in the main paper. They support this claim by referencing the experimental results in Table 4, which they argue indicate its key factor in performance gain. While the claim itself isn't directly verifiable within the paper, the evidence provided (Table 4) supports the implication that there's a gap in the discussion. The reviewer also connects this to the ablation study in Table 5, further strengthening the basis for the claim.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper: the lack of detailed discussion on unsupervised pretraining, which they connect to the significant performance gains observed in the experiments. They also provide a concrete suggestion for improvement: focusing more on the pretraining method in the main paper. This actionable feedback is directly helpful for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question: 'How would we choose which ELM to pick (male/female)?' This constitutes an implicit action or suggestion. However, the reviewer does not provide a concrete solution or guidance on how to make this choice. The action remains to be inferred.", "grounding_specificity_rationale": "The reviewer's question is general and does not specify a particular part of the paper or a unique element within it. They are asking about the process of choosing an ELM in general. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses. The specificity is also low as the comment does not detail what needs to be addressed in this general process.", "verifiability_rationale": "The review point is a question seeking information rather than a claim requiring verification. Therefore, it does not contain a claim that needs to be supported by evidence. This fits the 'X' category where the comment is a factual statement without claims, judgments, or suggestions.", "helpfulness_rationale": "The reviewer raises a practical concern about the ELM selection process and its impact on accuracy within a pipeline. This directly addresses a potential user's concern and provides a clear direction for improvement (understanding the pipeline implications). The question is directly relevant to the ELM selection process and highlights a potential issue in a realworld application, making it 3 in identifying a problem area."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem ('difficult to follow') but does not explicitly state the next action the authors should take. While it suggests improvement, it lacks the specificity of how to achieve it.", "grounding_specificity_rationale": "The comment does not specify which part of the paper is difficult to follow. It refers to the writing in general terms, without pointing to a specific section, table, figure, or element.", "verifiability_rationale": "The comment does not make a claim that can be verified. It is a suggestion for improvement rather than a statement requiring evidence or justification.", "helpfulness_rationale": "The comment identifies a valid issue (difficult to follow writing) but does not provide a concrete solution or actionable steps for the authors to take. It is a helpful observation but lacks the necessary guidance to be fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out a lack of technical substance and the addition of a new loss. While the reviewer suggests adding a new loss to 31, they don't specify how this addition should be implemented or what benefits it would bring. The action of adding a new loss is mentioned, but the details of how to do it are missing.", "grounding_specificity_rationale": "The reviewer mentions '31' but doesn't specify which part of the paper this loss is intended for. They also don't explain why this specific citation is relevant to the addition of a new loss. The reviewer can make an educated guess about the section where the loss might be added, but the connection between the citation and the specific part of the paper is not explicit.", "verifiability_rationale": "The review states that the paper is 'incremental and does not have much technical substance' and that it 'just adds a new loss to 31'. This statement can be considered a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The suggestion to add a new loss is presented without any justification or evidence.", "helpfulness_rationale": "The review is critical, stating that the paper is 'incremental and does not have much technical substance' and that it 'just adds a new loss to 31'. While the suggestion to add a new loss is present, the review lacks any specific details on how this addition would be beneficial or what steps the authors should take to implement it. The criticism is not balanced by a clear and actionable suggestion that would empower the authors to improve their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for 'intuition' regarding Theorem 1, which implies a request for a clearer explanation or understanding of the underlying concepts. They also ask 'how certain distributions P* make it easier to determine f*,' which is a specific question about the relationship between the distribution and the function. Finally, they ask 'In practice, how should you determine which P* to fix?' This is a direct request for guidance on how to implement or apply the concept. These explicit requests for clarification and practical guidance make the review point 5.", "grounding_specificity_rationale": "While the reviewer doesn't explicitly name 'Theorem 1' or the 'invertible function f*,' the context strongly suggests these are the parts of the paper being referred to. The reviewer is implicitly pointing to these elements when asking for 'intuition' about Theorem 1 and how it relates to the invertible function. Therefore, the grounding is not 3, but rather weakly grounded and underspecific, as the exact section or table is not mentioned, but the concept is implied.", "verifiability_rationale": "The reviewer states that the paper lacks clarity regarding the intuition behind Theorem 1 and the role of the invertible function f*. This statement is a claim that needs to be addressed. The reviewer then provides suggestions for how to address this lack of clarity, such as 'asking for intuition' and 'exploring specific distributions.' While these suggestions are not direct external references, they provide some level of support by indicating a direction for further investigation. Therefore, the claim is 3, as there is a suggestion for how to verify it, but it lacks a direct citation.", "helpfulness_rationale": "The reviewer directly asks for clarification and explores the properties of a specific function, which is highly beneficial for the authors. They are seeking to understand a theoretical concept and its practical implications. The suggestions to seek intuition and explore specific distributions are concrete steps that the authors can take to improve their understanding. Therefore, the review point is 5 as it directly addresses a need for clarification and provides actionable steps for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a question seeking clarification, which is an implicit request for action. While they don't explicitly state 'fix this,' they are pointing to a potential issue (the difference between equations) that needs addressing. However, the request itself doesn't provide a concrete action for the author to take. The reviewer is asking *what* is different, not *how* to make them the same or *why* they are different.", "grounding_specificity_rationale": "The reviewer explicitly refers to equations (7) and (10) and the terms X and H^(1). This demonstrates strong grounding specificity, as the reviewer can accurately pinpoint the relevant parts of the paper and the specific elements within those parts that are causing confusion.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question, which is a request for information rather than a statement of opinion or assertion of a problem. Therefore, verifiability is not the primary aspect being evaluated here.", "helpfulness_rationale": "The reviewer's comment is a question seeking clarification. While it is relevant to the author's work and points to a potential area of confusion, it does not directly instruct the author on how to improve their draft. It is more of a request for information than a direct suggestion or critique. Therefore, it is helpful but not as directly impactful as a critique or suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a problem (lack of realworld applicability) but does not explicitly state a concrete action the authors should take to address it. While the reviewer suggests 'providing empirical evidence,' this is a general suggestion and doesn't detail how the authors should go about obtaining or presenting this evidence. The reviewer's statement is a statement of a problem, not a direct instruction on how to solve it.", "grounding_specificity_rationale": "The reviewer mentions 'the applicability of the model to realworld diffusion process' as a problem. While this is a specific area, the reviewer does not pinpoint a specific part of the paper or a specific detail within that process that needs improvement. The suggestion of 'providing empirical evidence' is general and doesn't specify where or how this evidence should be provided. The reviewer identifies a general area of weakness but doesn't specify the exact location or detail within the paper that needs improvement.", "verifiability_rationale": "The reviewer states a problem ('the main concern with the paper is the applicability of the model to realworld diffusion process') and suggests a solution ('providing empirical evidence'). However, the reviewer does not make a claim that requires verification. The statement of the problem is a general observation, and the suggestion of providing evidence is a proposed solution, not a claim that needs logical reasoning, common knowledge, or external references to support. The reviewer points out a limitation but doesn't make a claim that needs verification.", "helpfulness_rationale": "The reviewer identifies a relevant and important area for improvement (the realworld applicability of the model). They highlight a gap in the current work and suggest a general direction for improvement (providing empirical evidence). While the reviewer doesn't provide specific, actionable steps on how to achieve this, they do point out a significant weakness in the paper. This makes the review point 3 in identifying a problem and suggesting a general solution, even if the solution isn't fully detailed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the method is only tested on two datasets. While it doesn't directly imply a need for more datasets, the statement is clear and points to a limitation in the experimental scope. Therefore, it can be considered explicit. However, it is vague because it doesn't specify which datasets were used or why only two were chosen. It also doesn't suggest concrete actions to improve the performance based on this limitation.", "grounding_specificity_rationale": "The comment explicitly mentions 'two datasets' but does not identify which specific datasets were used. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses. However, the comment does specify what is being addressed \u2013 the number of datasets \u2013 and how this relates to the performance evaluation. Thus, the specificity is somewhat clear.", "verifiability_rationale": "The comment contains a claim: 'The method is only tested on two datasets.' However, it does not provide any justification or evidence for this claim. There are no logical reasoning, common knowledge, or external references provided to support this statement. Therefore, the verifiability is 1.", "helpfulness_rationale": "The comment identifies a limitation in the experimental setup (only two datasets) and asks for more information. This points to a need for the authors to provide more details about their current testing. While it doesn't directly ask for a solution, it highlights a missing piece of information that is crucial for evaluating the method's performance. Therefore, it is 3 in identifying a gap in the provided information."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The statement identifies a potential issue (lack of novelty) but doesn't specify how to address it or what concrete changes are needed. It's a critique, not a solution.", "grounding_specificity_rationale": "The reviewer doesn't specify which section or aspect of the paper they are referring to. They are making a broad statement about the *general* contribution.", "verifiability_rationale": "The reviewer *states* that alternatives exist. While they don't provide specific examples or citations *within this review point*, the statement itself is a claim that can be supported or refuted by evidence.", "helpfulness_rationale": "The reviewer identifies a *potential* area for improvement (acknowledging existing alternatives) but doesn't provide concrete suggestions or point to specific weaknesses. The feedback is present but lacks actionable detail."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action of plotting the relative weight change after unlearning. This is a direct and actionable suggestion for the authors to visualize and understand the impact of the unlearning process on different layers.", "grounding_specificity_rationale": "The reviewer mentions 'relative weight change' and 'plot'. This directly refers to the model's weights and the visualization technique. The reviewer is very specific about the *what* and *how* of the visualization, indicating strong grounding specificity.", "verifiability_rationale": "The reviewer provides a clear method for verification: 'plot the relative weight change after unlearning to see which layers are affected the most'. This is a logical and verifiable suggestion, providing a concrete way to analyze the model's behavior.", "helpfulness_rationale": "The reviewer's suggestion directly addresses a potential need for the authors to understand layerwise impact on model weights after unlearning. This provides a concrete visualization technique to analyze and potentially improve their unlearning method. It offers a clear, actionable next step for the authors to gain insights into their model."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states that the novelty of the paper appears to be rather limited and provides a reason for this assessment by comparing it to the ENCODE work. This is a direct statement of an actionable point.", "grounding_specificity_rationale": "The reviewer mentions 'methodology aspect', 'ENCODE part' and 'decomposition part'. While they don't specify the exact section or table number, they clearly point to specific areas within the paper, making the grounding explicit. They also explain why they believe the novelty is limited in the methodology and how the decomposition is incremental, providing detail about the issues within these specific parts.", "verifiability_rationale": "The reviewer makes a claim about the paper's novelty being limited and compares it to the ENCODE work. However, they do not provide any specific examples, citations, or logical reasoning to support this claim. The statement is an opinion without evidence.", "helpfulness_rationale": "The reviewer identifies a potential limitation in the paper's novelty and points to specific areas (methodology, ENCODE, decomposition) for improvement. While this highlights areas for attention, the lack of verifiable evidence to support their claim makes the feedback less actionable and potentially confusing for the authors. It raises a flag about the novelty of the work without providing concrete evidence."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the question 'What is the domain of the inputs?' and provides the suggestion 'They are lying in the same sphere, not mentioned in the paper.' This is an explicit action (asking a question) and a concrete suggestion (identifying a potential issue). The implications are clear and directly address the inputs.", "grounding_specificity_rationale": "The comment explicitly asks 'What is the domain of the inputs?'. However, it does not specify which inputs or where in the paper this 'same sphere' is relevant. The grounding is weak because the authors cannot confidently determine which part the comment addresses beyond a general question about the data.", "verifiability_rationale": "The comment contains a claim: 'They are lying in the same sphere, not mentioned in the paper.' However, this claim is not supported by any logical reasoning, common knowledge, or external references. The suggestion lacks justification and examples, making it 1.", "helpfulness_rationale": "The comment identifies a potential issue (redundant inputs) but does not provide a concrete solution or actionable steps for the authors to take. While the problem is pointed out, the lack of a clear path forward makes it 3 but lacking in actionability and verifiability."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the request to compare the performance of the proposed CLN algorithm with 'this work'. This is a clear and direct instruction, making it an explicit action. Furthermore, the request is concrete in its goal \u2013 to compare performance \u2013 which is a specific direction for the authors to take. While the exact performance metric isn't specified, the request itself is actionable.", "grounding_specificity_rationale": "The reviewer refers to 'A' and 'CLN (region proposal generation algorithm)'. While they don't provide a specific section or figure number, the term 'region proposal generation algorithm' strongly suggests where the proposed method is described. This requires the authors to infer the location, making the grounding weakly grounded. The specificity of the request is underspecified as the reviewer doesn't mention a particular performance metric or comparison method. Therefore, the grounding is underspecific.", "verifiability_rationale": "The reviewer is not making a claim. They are asking a question about the performance comparison. There is no assertion of superiority, inferiority, or any other opinion. The request is a request for information, not a statement that needs verification.", "helpfulness_rationale": "The reviewer is asking for a performance comparison, which is a relevant and useful piece of information for evaluating the proposed CLN algorithm. This directly addresses the functionality and effectiveness of the algorithm. The request is clear and directly points to a potential weakness (the performance of the CLN algorithm) that the authors might be facing or curious about. Therefore, it provides a clear direction for the authors to seek information and understand the algorithm's performance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a specific weakness: 'presentation is at times too equationdriven and notation, especially in chapter 3, quite convoluted and hard to follow.' This indicates a clear issue that needs addressing. Furthermore, the reviewer suggests a concrete action: 'An illustrative figure of the key concepts in section 3 would have been helpful.' This direct suggestion of an improvement demonstrates a clear and actionable step the authors could take. The combination of identifying a problem and suggesting a specific action makes this review point 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'chapter 3' when suggesting an improvement: 'An illustrative figure of the key concepts in section 3 would have been helpful.' This precise identification of the section where the issue lies demonstrates strong grounding. The reviewer doesn't just say 'section 3 is unclear'; they specify 'an illustrative figure of the key concepts.' While not pinpointing every detail, this points to a concrete area for improvement within the section, making it highly specific.", "verifiability_rationale": "The review point does not contain a claim that requires verification. The reviewer identifies a problem ('presentation is at times too equationdriven...') and offers a suggestion ('An illustrative figure...'). This is a suggestion for improvement, not a critique that needs to be supported by evidence or references. Therefore, it does not fall into the 'X' category (X) as it doesn't present a statement that needs to be justified. However, it also doesn't present a claim that is verifiable. The focus is on suggesting a solution rather than making a judgment that needs support.", "helpfulness_rationale": "The reviewer clearly identifies a likely area of weakness for the authors: the presentation being 'equationdriven and notation hard to follow.' They directly address this weakness by suggesting a concrete improvement: 'An illustrative figure of the key concepts in section 3 would have been helpful.' This suggestion is directly aimed at resolving the identified issue. By pointing out a specific problem and offering a practical solution, the reviewer provides valuable guidance for the authors, making this review point 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential conflict between the definition of 'minimal conditional dependence' and Equation (7). They specifically suggest that if the set Z' is considered to be the empty set, then according to the definition, x and y should be independent given W. However, Equation (7) indicates that x and y are not independent given W. This is an explicit statement of a potential issue that requires clarification.", "grounding_specificity_rationale": "The reviewer refers to 'Lemma 2,' 'Eq (7),' and 'minimal conditional dependence,' explicitly pointing to specific parts of the paper. This strong reference makes the grounding very specific.", "verifiability_rationale": "The reviewer states a claim: 'Second rule in Lemma 2, i.e., Eq (7) and the definition of minimal conditional dependence seem to be conflicting.' While the reviewer identifies a potential conflict, they do not provide external references or logical reasoning to support or refute this claim within the review point itself. The verifiability depends on the reader's ability to understand the referenced concepts and equation.", "helpfulness_rationale": "The reviewer identifies a potential point of confusion regarding the relationship between 'minimal conditional dependence' and 'Eq (7)'. This could be helpful for the author to understand a potential flaw in their understanding or the lemma. However, without further clarification or context from the author, the helpfulness is conditional on the accuracy of the reviewer's assessment."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly mentions 'subscripts' and suggests 'enhancement for better readability and aesthetic appeal'. While the suggestion is general, it clearly points to an actionable change related to the identified element. The reviewer could reasonably infer the need for clearer labeling or formatting of the subscripts to improve readability.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'figure3' and specifically mentions 'subscripts'. The reviewer also states the issue as 'could be enhanced', which clearly identifies the specific part of the paper being addressed and the nature of the problem.", "verifiability_rationale": "The reviewer states 'I noticed that the visual presentation, specifically the subscripts, could be enhanced for better readability and aesthetic appeal.' This statement identifies a problem (subscripts are not readable/aesthetic) and suggests a solution (enhancement). While the suggestion is not a definitive statement requiring external references, it implies a flaw in the current presentation and a need for action.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion directly related to the figure in question. They identify a specific element ('subscripts') and propose a concrete improvement ('enhancement for better readability and aesthetic appeal'). This directly points to a change the authors can make to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points to a specific sentence in the paper that explains the difference between Batch Normalization and Online Normalization regarding gradient estimation. The sentence explicitly states the problem with Batch Normalization (using minibatch for gradient bias) and contrasts it with Online Normalization (no dependency on batch size). While the paper identifies a difference and attributes it to a specific mechanism, it doesn't explicitly state an action or suggestion based on this observation. The reviewer's confusion highlights a lack of clear action or guidance stemming from this statement.", "grounding_specificity_rationale": "The reviewer directly references a sentence in the paper that discusses the gradient bias issue. This provides strong grounding as the paper explicitly mentions the relevant section (the explanation of the difference). However, the reviewer is asking *why* Online Normalization is unbiased and Batch Normalization is biased. The paper mentions the *difference* but doesn't explicitly state which is which in a single, clear statement with a strong action. It implies the difference but doesn't explicitly state the unbiased/biased nature in a single, clear statement with a strong action.", "verifiability_rationale": "The reviewer expresses confusion about the paper's claim regarding the bias difference between Batch Normalization and Online Normalization. This constitutes a claim that the paper makes. However, the paper *mentions* the difference but doesn't provide a detailed explanation or evidence to *support* the claim that Online Normalization is unbiased and Batch Normalization is biased. The reasoning is presented as a statement rather than a wellsupported argument, making it somewhat underjustified.", "helpfulness_rationale": "The reviewer explicitly states they will 'stay with my original score.' This indicates that the reviewer did not find the review point helpful in understanding the paper or improving their work. The confusion expressed by the reviewer suggests the point did not provide clear or actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the issue: 'equations are crammed together, captions are too close to the figures.' However, it does not provide specific guidance on how to address these issues. It identifies the *what* but not the *how* to implement the action.", "grounding_specificity_rationale": "The comment explicitly mentions 'equations,' 'captions,' and 'figures,' clearly identifying the specific parts of the paper being addressed. This is a clear indication of full grounding. It also specifies the *problem* with these parts, making it specific to the referenced elements.", "verifiability_rationale": "The comment contains a claim: 'This by itself is grounds for rejection.' This claim is verifiable based on the stated 9page paper limit. The reasoning is clear and directly supports the claim.", "helpfulness_rationale": "The comment clearly identifies a significant issue (poor layout) and points to specific areas within the paper that need adjustment. While it doesn't provide specific solutions, it highlights a clear weakness that requires attention, making it helpful for the authors to know this draft is at risk of rejection due to these formatting issues."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly states that 'Technical details and formulations are limited' and infers that this is a problem by stating 'It seems that the main novelty reflected in the scheme or procedure novelty.' While it identifies an issue, it doesn't specify how to address it or what concrete actions the authors should take.", "grounding_specificity_rationale": "The comment generally refers to 'Technical details and formulations' and 'scheme or procedure' without specifying which exact parts are lacking detail or where the novelty is most prominent. This makes it difficult for the authors to pinpoint the specific area needing improvement.", "verifiability_rationale": "The comment contains claims such as 'Technical details and formulations are limited' and 'It seems that the main novelty reflected in the scheme or procedure novelty.' However, it does not provide any logical reasoning, common knowledge, or external references to support these claims. The justification is implied but not explicitly stated or verified.", "helpfulness_rationale": "The comment identifies a potential area for improvement ('Technical details and formulations are limited') but fails to explain why this is a problem or how it affects the work. It also doesn't suggest concrete actions or improvements for the authors to implement. The lack of specific guidance makes it difficult for the authors to act on this feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the ambiguity of 'local interactions' by asking a question about its definition. This indicates an implicit action: the reviewer wants the authors to clarify what they mean by 'local interactions'. While the action is not directly stated as a request to define it, the question itself is a clear indication of a need for clarification. The reviewer points to two possible interpretations ('time window' vs. 'modality'), suggesting the ambiguity is not fully resolved by the current phrasing.", "grounding_specificity_rationale": "The reviewer's comment is grounded in the term 'local interactions' by directly referencing it. However, the grounding is weak because the reviewer does not specify *which* aspect of 'local interactions' is unclear. They offer two possibilities ('time window' or 'modality') but do not commit to one or narrow down the ambiguity. The comment lacks a clear specification of the exact part of the paper or concept being addressed beyond the term itself.", "verifiability_rationale": "The review point itself does not contain a claim. It is a question posed to the authors to seek clarification. Therefore, the concept of verifiability does not apply to this review point as there is no statement that requires evidence or justification.", "helpfulness_rationale": "The review point is helpful in that it identifies a potential ambiguity in the term 'local interactions'. By asking for clarification, the reviewer is encouraging the authors to be more precise in their terminology. This can prevent confusion and ensure that the concept is understood consistently. While it doesn't provide a direct solution, it prompts a necessary step for improving the clarity of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a discrepancy between the claimed results and the actual outcomes of the constrained method, and suggests adding the method as a concrete action to address the lower validity and diversity.", "grounding_specificity_rationale": "The review point explicitly mentions 'the Molecule generation experiment (Table.3)' and refers to 'validity and diversity' as the metrics affected.", "verifiability_rationale": "The review point presents a statement about the constrained method yielding lower validity and diversity, but it does not contain a claim that requires external verification or justification within the provided text.", "helpfulness_rationale": "The review point directly identifies a contradiction between the paper's claims and experimental results, suggesting a concrete action (adding the constrained method) for the authors to consider."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks for clarification on how the archetype positions are updated after initialisation. While the reviewer identifies a specific area of the paper (Algorithm 2 and the update mechanism), the *specific* method of updating the positions is not explicitly stated in the provided text. The reviewer implies an action (asking for clarification) but doesn't provide concrete steps or details on how the update is performed. Therefore, the action is implicit and vague.", "grounding_specificity_rationale": "The reviewer refers to 'Algorithm 2' and the variables 'z_1, ..., z_k' which are initialised with 'FurthestSum'. However, the *specific* steps or logic for updating these archetype positions after initialisation are not explicitly detailed in the provided text. While the algorithm and initialization method are mentioned, the precise mechanism of the update is missing, making the grounding weak as the reviewer cannot confidently determine the referenced part.", "verifiability_rationale": "The reviewer points out a lack of clarity in the update mechanism of Algorithm 2. The reviewer states, 'it is not quite clear to me how the archetype positions are updated after initialisation.' This statement itself can be considered a claim that requires justification. The paper describes the initialisation but lacks a clear explanation or reference for the update process. Therefore, the claim is somewhat justified by the reviewer's observation of a lack of clarity.", "helpfulness_rationale": "The reviewer's question directly addresses a potential area for improvement in the algorithm's description. By asking how the archetype positions are updated, the reviewer is seeking a crucial detail that would enhance their understanding and potentially the implementation of the algorithm. While the question itself is not a critique of the outcome, it points to a missing piece of information that would be helpful for the reader. Therefore, the comment is 3 as it highlights a missing detail that would be beneficial to understand."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly lists several actions the authors should take, such as providing recording parameters, preprocessing steps, and the resting state condition. These are direct and concrete actions that the authors can readily address. The reviewer also suggests including the number of regions in the parcellation, which is a specific action. The reviewer's point is clear and directly points to what needs to be done.", "grounding_specificity_rationale": "The reviewer provides specific details about what information is missing, including 'recording parameters for the MRI', 'preprocessing steps', 'was the restingstate recorded under eyesopen or eyesclosed condition?', and 'the number of regions in the parcellation'. These are all specific and identifiable parts of the paper. The reviewer also implies that this information should be in the 'main text', which is a clear indication of grounding. The information is not just general or implied, but specific and actionable.", "verifiability_rationale": "The reviewer states that 'important information about the empirical study is missing'. This is a claim that needs to be addressed. While the claim itself is somewhat subjective (what constitutes 'important'), the reviewer's suggestion to provide specific details like 'recording parameters for the MRI', 'preprocessing steps', and 'the number of regions in the parcellation' provides a basis for verification. The claim is 3 because the *type* of information is specified. However, it lacks external references, which would make it 5.", "helpfulness_rationale": "The reviewer provides a list of concrete suggestions for the authors, including specific details about the empirical study. The reviewer explicitly states that this information is 'missing' and should be included in the 'main text'. These are all actionable and directly address potential gaps in the authors' understanding or presentation. The reviewer's suggestions are clear and directly point to areas where the authors can improve their work. The reviewer's point is not just a general comment but a specific call for action."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the problem (datasetspecificity of AU relationships) and suggests a clear, actionable improvement (performing crossdataset experiments). This direct identification of a weakness and a specific solution makes the comment 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'crossdataset experiments' as a way to address the limitations of AUbased methods. This directly identifies the specific part of the paper being addressed, making the comment fully grounded. The reviewer also explains *why* this is important, making it specific as well.", "verifiability_rationale": "The reviewer makes a claim that the paper is lacking and provides a specific reason (the datasetspecificity of AU relationships). This claim is supported by logical reasoning and the identified problem. While the claim is verifiable, it could be strengthened by explicitly referencing Figure 1 if possible, but the core point about verifiability is present.", "helpfulness_rationale": "The reviewer provides a specific and actionable suggestion (crossdataset experiments) to address a clear limitation (datasetspecificity of AU relationships). This directly helps the authors improve their understanding and application of AUbased methods. The suggestion is concrete and directly addresses a practical concern for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'I would have liked more description', indicating an intention to add more detail. However, it lacks specific guidance on *how* to achieve this, making it somewhat vague on the concrete action to be taken.", "grounding_specificity_rationale": "The comment explicitly mentions 'the Starcraft environment', which grounds the feedback to a specific part of the paper. However, it does not specify *what* aspect of the Starcraft environment requires more description, making it not very specific.", "verifiability_rationale": "The comment is a statement of preference, not a claim requiring verification. There is no logical reasoning, common knowledge, or external references provided to support the statement.", "helpfulness_rationale": "The comment clearly expresses a desire for more information about the Starcraft environment. This is a valid feedback point that can help the authors improve their draft by providing more context or details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly criticizes the statement about overparametrization and provides a counterargument by stating 'overparameterization seems to be very helpful for supervised learning of deep neural networks in practice...'. This directly identifies an action: 'correct the statement'. Furthermore, the reviewer provides a reason for this correction ('overparametrization seems to be very helpful...') and offers supporting evidence ('Also, I have seen a number of theoretical work showing the benefits...'). This makes the criticism concrete and actionable.", "grounding_specificity_rationale": "The review point criticizes a general statement about overparameterization: 'overparametrization invariably overfits the data and results in worse performance'. While the reviewer mentions the paper being criticized by line numbers (4748), the criticism itself is about the general principle, not a specific part of the paper. The reviewer does not explicitly identify a unique element or section of the paper being addressed. The grounding is weak because the reviewer is making a general point about overparameterization and providing a general counterargument.", "verifiability_rationale": "The review point contains a claim: 'overparameterization invariably overfits the data and results in worse performance'. This claim is verifiable because the reviewer provides a counterargument ('overparameterization seems to be very helpful for supervised learning of deep neural networks in practice...') and offers supporting evidence ('Also, I have seen a number of theoretical work showing the benefits...'). This provides logical reasoning, examples (implied through 'several theoretical work'), and external references (implied through 'theoretical work').", "helpfulness_rationale": "The review point is 5 because it directly criticizes a potentially harmful statement about overparameterization and offers a clear alternative viewpoint ('overparameterization seems to be very helpful...') with supporting evidence ('I have seen a number of theoretical work showing the benefits...'). This provides the authors with a clear direction to consider and potentially address the limitations of overparameterization."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests improvements such as comparing the processing efficiency of training and testing with existing work and discussing the parsing model. These are explicit suggestions for improvement. However, the reviewer does not specify *how* they would perform the efficiency comparison or what specific aspects of the parsing model they would discuss, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions specific details about the training process, such as the 'pixel level' training, the use of 'landmarks' for sparsity, the independent training on 'all font images and characters,' and the 'four types of factors' in the parsing model. These are specific elements of the method being described. The reviewer also explicitly mentions comparing efficiency with existing work, which is a clear action.", "verifiability_rationale": "The reviewer states that the shape model is trained in a 'timeconsuming' manner and suggests discussing the parsing model. The claim about the training process being 'timeconsuming' is verifiable as it describes an observed characteristic of the method. The suggestion to discuss the parsing model is also a clear action, although the reviewer does not provide any justification for why this discussion is necessary or beneficial.", "helpfulness_rationale": "The reviewer provides concrete suggestions for improvement, such as comparing the processing efficiency of training and testing with existing work and discussing the parsing model. These suggestions are directly related to potential weaknesses in the work and offer clear directions for improvement. The reviewer's comments are actionable and provide valuable insights to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests using 'other domain adaptation methods' to improve performance. This is an explicit action pointing to a specific area for change. The reviewer directly identifies the need to explore alternative methods, which is a clear and actionable suggestion.", "grounding_specificity_rationale": "The reviewer mentions 'the domain adaptation method here is a very old and simple method'. This statement explicitly identifies the specific method being criticized by name and provides characteristics (old and simple). This demonstrates a clear grounding of the comment in a specific part of the paper and its properties.", "verifiability_rationale": "The reviewer makes claims such as 'the adversarial attack or correction method and the domain adaptation method used by the authors are proposed by prior work' and 'the adopted domain adaptation method here is a very old and simple method'. These claims require verification through citations and comparison to existing literature. While the claims are not fully supported with specific examples or references within the review point itself, they are verifiable by examining the paper's content and external knowledge of the field.", "helpfulness_rationale": "The reviewer's suggestion to use 'other domain adaptation methods' is a clear and actionable piece of feedback. This directly addresses a potential weakness (lack of innovation and simplicity of the chosen method) and provides a concrete direction for improvement. The suggestion is welldefined and directly actionable for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of discussion regarding the prompt dataset creation and its source. This is an explicit action that the authors should take. Furthermore, the reviewer provides concrete information about what is missing (discussion of prompt dataset creation and its source). Therefore, the review point is both explicit and concrete.", "grounding_specificity_rationale": "The review point directly mentions 'prompt dataset creation' and 'its source'. This allows the authors to accurately pinpoint the specific aspect of the paper being addressed. Therefore, the grounding is full. While the reviewer doesn't specify *how much* discussion is needed, they clearly indicate that a discussion is missing, making the specificity somewhat underspecified but still present.", "verifiability_rationale": "The review point does not contain a claim in the sense of an assertion or opinion. Instead, it points out a deficiency: the lack of discussion on prompt dataset creation. While this could be considered a 'claim' in the sense that it identifies a missing element, there is no supporting evidence or justification provided. Therefore, it is not 5. If we were to extract a claim, it would be something like 'The paper should discuss prompt dataset creation,' but the review point itself doesn't provide any evidence for this claim.", "helpfulness_rationale": "The review point directly identifies a clear area for improvement in the authors' draft \u2013 the lack of information on prompt dataset creation. This is a valuable piece of feedback that directly addresses a potential weakness. The reviewer is asking the authors to include this information, which is a clear and actionable request. Therefore, the review point is 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states 'Very difficult to follow the motivation of this paper.' This indicates an implicit actionability, as the reviewer identifies a problem (difficult to follow) but doesn't explicitly state what needs to be changed. While the reviewer doesn't provide a concrete action, they clearly express a need for clarification, which implies an action is required. However, the lack of a specific, direct instruction makes it only 2.", "grounding_specificity_rationale": "The review point states 'Very difficult to follow the motivation of this paper. And it looks like an incremental engineering paper.' This comment is 1 at all. The reviewer does not identify a specific part of the paper that is difficult to follow. They make a general statement about the nature of the paper without pinpointing a specific section, table, figure, or unique aspect. The phrase 'it looks like an incremental engineering paper' is a general assessment and does not specify what is unclear.", "verifiability_rationale": "The review point contains a claim: 'it looks like an incremental engineering paper.' However, this claim is not verifiable. The reviewer makes a general assessment about the paper's nature but does not provide any specific evidence, references, or logical reasoning to support this claim. There is no justification for why the paper is considered an 'incremental engineering paper'.", "helpfulness_rationale": "The review point is a critique of the paper's nature ('it looks like an incremental engineering paper') without offering any specific suggestions for improvement. While the reviewer identifies a potential weakness ('difficult to follow the motivation'), they do not provide concrete steps the authors should take to address this. The comment is a general statement about the paper's characteristics rather than specific, actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of 'ablation' on the weighting method of the crossentropy loss. While the reviewer doesn't provide specific details on *how* to ablate it, the suggestion is clear and directly actionable. The reviewer also connects this suggestion to a specific issue they observed ('the game has repetitive background sounds'), which implies a concrete understanding of the problem and how the proposed action might address it.", "grounding_specificity_rationale": "The reviewer grounds the suggestion to the specific issue of 'repetitive background sounds' observed in the Atlantis method. This demonstrates a clear understanding of the paper's content and identifies a specific area for improvement. The reviewer also suggests a specific *action* ('ablation') related to this grounding, making the grounding concrete.", "verifiability_rationale": "The reviewer makes a claim ('The authors note...') and provides a specific example ('This is a scenario I'd expect the weighting might have helped remedy') to support their suggestion. This claim is verifiable based on the reviewer's understanding of the Atlantis method and their expectation of how the weighting might affect it. The reasoning is logical and directly related to the identified issue.", "helpfulness_rationale": "The reviewer provides a clear suggestion ('suggestion to ablate weighting') and connects it to a specific problem ('repetitive background sounds') observed in the paper. This suggests a clear and actionable improvement. The reviewer's tone is positive, implying the suggestion is valuable and could help the authors improve their work. The suggestion is directly related to the identified issue and offers a concrete solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a weakness but does not explicitly state how the authors should address it. While it suggests new datasets and benchmarks, it lacks concrete steps on implementation.", "grounding_specificity_rationale": "The review refers to general areas of the paper (column operations, benchmark papers) but does not specify a particular section, table, or figure where the lack of novelty is evident.", "verifiability_rationale": "The review makes a claim about the lack of novelty but does not provide specific evidence or references within the review point itself to support this claim.", "helpfulness_rationale": "The review identifies a valid concern and offers some relevant ideas, but it lacks explicit guidance on how to implement these suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment identifies a problem ('experiments are only done on one game environment') but does not specify how to address it or make the necessary changes. It lacks concrete steps or actionable items for the authors to follow.", "grounding_specificity_rationale": "The comment is too general and does not specify which game environment or aspect of the experimental setup is limited. It lacks a clear reference to a specific part of the paper.", "verifiability_rationale": "The comment points out a valid limitation ('experiments are only done on one game environment') but does not provide any specific evidence, reasoning, or references to support how this limitation should be addressed or how the suggested improvements can be implemented.", "helpfulness_rationale": "The comment identifies a valid weakness ('experiments are only done on one game environment') but does not offer specific, actionable, or wellsupported suggestions for improvement. It lacks the 'howto' element necessary for truly constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment implicitly states that the authors need to explain the importance of the assumptions and provide examples. However, it does not explicitly state the action the authors should take or how to achieve it.", "grounding_specificity_rationale": "The comment explicitly mentions the assumptions of bounded variance and bounded gradients, providing full grounding. However, it does not specify what is wrong with these assumptions or provide concrete examples to illustrate the importance of relaxing them.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a suggestion for the authors to provide more information.", "helpfulness_rationale": "The comment is a suggestion for the authors to improve their draft by providing more context and justification. While it is a valid point, it does not directly critique the work or offer concrete feedback on specific weaknesses."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem of slow testing and low accuracy, and provides specific details such as the dataset (ImageNet), models (AlexNet and ResNet18), and metrics (time and accuracy). This makes the action very concrete and directly actionable for the authors.", "grounding_specificity_rationale": "The reviewer mentions specific elements of the paper, including the dataset (ImageNet), models (AlexNet and ResNet18), and metrics (time and accuracy). This allows the authors to accurately pinpoint the section, table, figure, or unique aspect being addressed, making the grounding fully specific.", "verifiability_rationale": "The reviewer makes a claim about the performance of the implementation and provides specific numerical data (time and accuracy) to support this claim. This makes the claim thoroughly supported and verifiable.", "helpfulness_rationale": "The reviewer identifies a specific performance issue with a particular implementation and suggests a potential solution. This provides clear, actionable, and constructive feedback that empowers the authors to improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer's request is not explicitly stating what needs to be changed, but rather asking for more explanation. While the implicit request is to add detail to the experimental setting, the action of adding detail is not directly requested. The questions about Figure 3 are implied, but not explicitly stated as a request for clarification. Therefore, the action is implicit and not directly actionable.", "grounding_specificity_rationale": "The reviewer mentions 'Fig 3' and 'experimental setting', which grounds the comment to specific parts of the paper. However, the level of specificity is limited. The reviewer doesn't pinpoint a *unique* section, table, or figure, nor does the request for 'correspondence' imply a deep understanding of the content. The grounding is weak because the authors would need to infer the relevance of Figure 3 and the need for more detail on the experimental setting.", "verifiability_rationale": "The reviewer poses questions about the correspondence of learning curves and MPHATE, the purpose of examining the curves, the interpretation of 'worse performing model', and the presence of accuracy numbers. These questions are based on logical reasoning about what information is needed to understand the results. However, the reviewer does not explicitly state that these are claims that require justification or are based on external references. The questions themselves are verifiable, but the underlying intent isn't explicitly framed as a claim needing verification.", "helpfulness_rationale": "The reviewer's comment is not directly instructing the authors on how to improve their draft. Instead, they are asking for more explanation and clarification regarding existing content (Figure 3 and experimental setting). While this can be helpful, it doesn't directly prompt the authors to make a specific change. The reviewer is essentially pointing out potential areas where the paper could be clearer, but doesn't actively guide the authors on what to add or modify. Therefore, the feedback is not directly actionable in terms of specific edits."}
{"actionability_label": "3. 3", "grounding_specificity_label": "5. 5", "verifiability_label": "4. 4", "helpfulness_label": "4. 4", "actionability_rationale": "The review point introduces a question about a potential modification to consistency training and suggests exploring labeled data for this purpose. While it implies a benefit (it might be beneficial), it doesn't explicitly state an action or propose a concrete change to the current method. The suggestion is openended, lacking specific details on how labeled data would be used or how this approach would differ from unlabeled methods.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'labeled data for consistency training' and 'graph anomaly detection' and names two specific papers related to graph contrastive learning. This clearly identifies the specific aspect of the paper being addressed and provides specific examples.", "verifiability_rationale": "The reviewer suggests that 'labeled data has exact labels, which might provide effective information for consistency training the model in dealing with the taks of graph anomaly detection.' This statement presents a claim about the potential benefits of using labeled data. While it doesn't provide specific examples of how this would work, it offers a general rationale based on the nature of labeled data and the task of graph anomaly detection. The reviewer also mentions the specific application of graph anomaly detection, which further grounds the suggestion.", "helpfulness_rationale": "The review point suggests exploring a potential modification to consistency training and connects it to a specific application (graph anomaly detection) and relevant research. While it doesn't propose a specific change to the author's current method, it highlights a potentially valuable direction and encourages the author to consider a different training approach. The suggestion is openended but points towards a potentially beneficial area of research."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states actions to be taken, such as 'reorganized' and 'further improved', and provides specific suggestions like 'experimental content...does not highlight the superiority of the method well' and 'experimental suggestions...should include'. These actions and suggestions are clear and point towards concrete steps the authors should undertake.", "grounding_specificity_rationale": "The review point refers to 'the experimental part' generally, without specifying a particular section, table, figure, or unique aspect. While it mentions 'experimental content,' it doesn't pinpoint the exact content or its location within the experimental section. Therefore, the grounding is weak as the authors cannot confidently determine the specific part being addressed.", "verifiability_rationale": "The review point contains a claim: 'The experimental part needs to be reorganized and further improved.' However, it does not provide any justification or evidence for why this is necessary or how the suggested improvements will achieve this. The suggestions are general and lack specific reasoning or references.", "helpfulness_rationale": "The review point identifies a weakness ('the experimental content...does not highlight the superiority of the method well') and offers a general suggestion ('experimental suggestions...should include'). While it doesn't provide specific details for improvement, it clearly points to an area that needs attention and offers a general direction for action. Therefore, it is 3 as it guides the authors towards improvement, even if the specifics are missing."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point is 5. The reviewer explicitly states a concern about the classification error of the proposed network compared to softmax and provides a clear action: 'report the classification accuracy of the proposed classifier on ImageNet data? Some theoretical justifications, if possible, would be great for the issue.' This action is concrete and directly addresses the concern.", "grounding_specificity_rationale": "The review point demonstrates good grounding specificity. The reviewer specifies 'ImageNet data' as the context for evaluating the classification accuracy, making it clear which part of the paper is being addressed. Additionally, the request for 'theoretical justifications' further grounds the suggestion within a specific area of concern.", "verifiability_rationale": "The review point is 5. The reviewer identifies a claim: 'its classification error is universally as good as the standard softmax network.' This claim is supported by the suggestion to 'report the classification accuracy of the proposed classifier on ImageNet data' (logical reasoning) and the potential for 'theoretical justifications' (external references or common knowledge about classification performance). The evidence provided is sufficient to understand how to improve the work.", "helpfulness_rationale": "The review point is 5. The reviewer directly addresses a potential weakness (potential tradeoff between OOD detection and classification accuracy) and offers concrete and actionable suggestions: 'report the classification accuracy of the proposed classifier on ImageNet data' and 'some theoretical justifications, if possible, would be great for the issue.' These suggestions are directly aimed at improving the authors' understanding and potentially refining their model."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a potential issue with a specific type of recognition list in a specific scenario (old vs. new judgments). They suggest considering the implications for the model's applicability. This is an explicit action the authors should take.", "grounding_specificity_rationale": "The reviewer mentions 'recognition lists' and 'old vs. new judgments,' clearly identifying the specific part of the paper or scenario they are referring to. They specify the potential issue within this context.", "verifiability_rationale": "The reviewer makes a claim about the applicability of a specific recognition model to a specific recognition scenario. While they don't provide direct evidence, the nature of the claim makes it potentially verifiable through further analysis or experimentation. The claim could be supported by logical reasoning about how exhaustive lists might be implemented in recognition tasks.", "helpfulness_rationale": "The reviewer clearly articulates a potential issue with a specific method in a specific context. They suggest considering the implications for the model's applicability, which is a constructive suggestion for improvement. The specificity of the scenario makes the feedback more targeted."}
{"actionability_label": "2", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises a concern about the fairness of the experimental comparison, suggesting the proposed method's pretraining might give it an advantage. While the reviewer points out the pretraining aspect, the action to be taken (investigating the pretraining of compared methods) is not explicitly stated in the review point itself. The reviewer identifies a potential issue but doesn't provide a direct action or solution.", "grounding_specificity_rationale": "The reviewer's comment is somewhat vague. While they mention 'experimental comparison' and 'pretrained model,' they don't specify *which* part of the paper or experiment they are referring to. The grounding is at a higher level, discussing the experimental setup rather than a specific section, table, or figure. The specificity is also limited as the reviewer doesn't detail *what* is wrong with the compared methods' pretraining.", "verifiability_rationale": "The reviewer's claim about the unfair comparison is presented as a hypothesis or suspicion. They state that the proposed method's pretraining might be an advantage but do not provide any evidence, citations, or logical reasoning to support this claim. The verifiability verification methods (logical reasoning, common knowledge, external references) are not applied or demonstrated in the review point.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the fairness of the experimental comparison. This could be helpful for the authors to understand potential biases in the comparison and potentially replicate or extend the experiments. However, the reviewer does not offer a concrete solution or suggestion to address the identified issue. The helpfulness is limited by the lack of a proposed remedy."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what the authors should do. While the reviewer points out a detail about the metadata used in the experiments and suggests an improvement, they do not provide specific instructions on how to change the metadata embeddings or identify the specific part of the paper that needs adjustment. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer mentions \"zeroshot learning on CUB dataset\" and \"metadata embeddings\" (or \"attribute\"). While they point to a specific experiment, the exact type of metadata is not explicitly identified. The reviewer does not clearly identify the specific section, table, figure, or unique aspect of the paper being addressed. The mention of 'attribute' is general and does not pinpoint a specific part of the paper.", "verifiability_rationale": "The reviewer makes a claim that \"better metadata embeddings options are available\" and suggests an experiment. However, they do not provide specific examples of these better embeddings or explicitly justify why the current \"attribute\" embeddings are suboptimal in this context. While they refer to external literature, this is not a direct verification of the current metadata within the review itself. The reasoning is present but lacks concrete examples or references to support the claim within the review.", "helpfulness_rationale": "The reviewer's point is relevant and suggests a direction for future research. While it is a valid suggestion, it does not directly help the authors identify a specific weakness in their current draft or provide immediate actionable steps to improve it. The suggestion is more of a recommendation for further investigation rather than a direct improvement strategy for the current work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a concrete action: 'include a plot with sparsity on the xaxis and performance on the yaxis'. This action is directly related to the criticism about the limited applicability of SGC and provides a clear path for improvement.", "grounding_specificity_rationale": "The review point mentions specific methods, 'SGC' and 'LoRA', and suggests a specific visualization technique, 'plot with sparsity on the xaxis and performance on the yaxis'. This demonstrates a strong grounding in the paper's content and a clear reference to the relevant aspect.", "verifiability_rationale": "The review point makes a claim about PEFT methods targeting computeconstrained scenarios, which is a generally accepted concept in the field. This claim, while not requiring external references, is logically sound and relevant to the discussion. Furthermore, the suggestion to include a plot is also a claim that *could* be verified by providing examples or data.", "helpfulness_rationale": "The review point is 5 as it directly addresses a specific weakness identified by the authors (limited applicability of SGC) and provides a concrete and actionable suggestion for improvement. The suggestion is clear and directly relevant to the problem."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point directly asks a question about the experimental setup (training times) and relates it to performance (similar performance of different methods) and asks for code. This immediately suggests it's actionable \u2013 the reviewer is asking for clarification or further investigation.", "grounding_specificity_rationale": "The reviewer is asking about the training time difference between the two datasets. However, they do not explicitly state which part of the paper they are referring to when asking this question. They are asking a general question about the experimental setup. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer is asking for clarification on the training time difference and code. While they are *asking* for something, they don't explicitly state *why* they find the existing information unconvincing or lacking justification. The justification comes from the *implication* of similar performance and the request for code.", "helpfulness_rationale": "The reviewer is asking for clarification on the training time difference and code. While these are helpful, the request for clarification is somewhat vague. The helpfulness is present, but it could be more specific."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for clarification on 'alternate formulations for Confidence Diversity (CD)' and 'why is entropy not a good measure of 'amount of spreading of teacher predictions over the probability simplex among different (training) samples''. These are direct requests for information and explanations, making it 3 for the authors to understand the concept better. However, it doesn't identify a specific problem that needs fixing.", "grounding_specificity_rationale": "The reviewer explicitly names 'alternate formulations for Confidence Diversity (CD)' and 'why is entropy not a good measure of 'amount of spreading of teacher predictions over the probability simplex among different (training) samples''. These are very specific concepts, and the reviewer also mentions the location of the question (line 113 and 115), which helps ground the request. This makes the grounding very specific.", "verifiability_rationale": "The reviewer asks for an 'explanation of alternate formulations for Confidence Diversity (CD)' and a 'justification for why entropy is not a good measure'. These are claims that can be supported by referencing existing literature on uncertainty measures and the properties of entropy. While the paper might explain CD, the specific reasoning behind why entropy is not suitable could benefit from further elaboration or citation of relevant literature, making it 4.", "helpfulness_rationale": "The review point directly addresses a potential point of confusion for the authors regarding the definition and measurement of Confidence Diversity (CD). The request for clarification on 'why entropy is not a good measure' is particularly valuable, as it seeks to understand a specific methodological choice. The reviewer is asking for targeted information that is likely to improve the authors' understanding of the concept. While it doesn't ask for a solution, it's a valuable piece of information for the authors to process, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a difference in the amount of time the human and model spent following the paper. While the reviewer explicitly states the time difference (1 hour vs. 15 hours), they don't explicitly state *what* is wrong with the human baseline *based* on this difference. The reviewer implies that the weaker followup time might be a reason for the weaker human baseline performance, but this is an inference rather than a direct action. Therefore, the actionability is somewhat implicit.", "grounding_specificity_rationale": "The reviewer refers to the 'human baseline' and the 'abstract' of the paper. While these are general sections, the reviewer doesn't provide a specific line number, paragraph, or figure number within the paper to pinpoint the issue. The reviewer refers to these sections by name, which can be considered a form of grounding, but it's not as precise as pointing to a specific element like a table or a unique aspect. Therefore, the grounding is somewhat specific.", "verifiability_rationale": "The reviewer makes a claim in the review point: 'In the abstract, the authors mention \"already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources\" which is a bit misleading given the 1 hour vs.' This is a claim that needs verification. The reviewer infers that the 1 hour of followup time might be a reason why the human baseline isn't already at a comparable level to the model's. While the reviewer doesn't provide explicit evidence or citations to support this claim, the reasoning is logical \u2013 less time spent following should lead to a weaker baseline. Therefore, the claim is 3 as it's supported by logical reasoning, even if specific evidence isn't provided.", "helpfulness_rationale": "The reviewer identifies a potential misinterpretation in the abstract regarding the human baseline's performance. This could be helpful for the authors to understand the correct interpretation of the results. However, the reviewer doesn't explicitly state *how* the authors should rephrase the abstract or *what* the correct CER/BLEU should be. They point out a potential issue but don't offer concrete actionable steps for the authors to take. Therefore, the review point is 3 as it highlights a relevant issue, but it doesn't provide direct guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a potential issue with the assumption for termination states in the data, suggesting it might be 'strong'. However, they do not explicitly state an action or provide concrete steps to address this. While they imply a problem, the lack of a direct recommendation makes it difficult to assess actionability fully.", "grounding_specificity_rationale": "The reviewer refers to 'termination states' as a specific aspect of the data. This provides some level of grounding. However, they do not explicitly connect this to a specific section, table, figure, or unique element within the submitted paper. They make a general statement about the cost of labeling, which is vague and lacks specificity regarding the data itself.", "verifiability_rationale": "The reviewer makes a statement about the 'cost of manual labeling' in the 'general case'. This constitutes a claim. However, they do not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a general observation without any backing, making it 1.", "helpfulness_rationale": "The reviewer points out a potential inefficiency in the data labeling process, specifically mentioning the cost of labeling 'termination states'. This is a valuable observation as it highlights a practical challenge in data creation. While they don't explicitly propose a solution, the implication is that researchers would benefit from exploring more efficient labeling methods. The reviewer's statement is directly relevant to improving the data creation process and reducing costs, making it 5 in this context."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out that the paper fails to explicitly state how the number of bins is determined when choosing the number of bins for the ECE_sweep calculation. While the reviewer doesn't directly ask a question, they identify a missing detail that would allow the reader to understand the implementation. The action is implicit: the reviewer is inferring that the binning process is not clearly described. The lack of concreteness makes it 3 in the sense that the reader now knows there's a missing detail, but the action itself isn't directly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'nature of the contribution' and the 'binning process' in relation to the ECE_sweep calculation. They are pointing to a specific aspect of the paper that is unclear. The comment is grounded in identifying the missing information about how the number of bins is chosen. The specificity comes from the fact that the reviewer clearly identifies the missing detail as the binning process.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It's a statement of observation about the lack of clarity in the paper's description of the binning process. Therefore, it doesn't fit the 'Verifiability' category as it doesn't present a claim that needs supporting evidence.", "helpfulness_rationale": "The reviewer's comment is 5 because it clarifies a key point for understanding the contribution. By pointing out the ambiguity in the binning process, the reviewer provides a clear direction for the authors to seek more information or clarification. This directly addresses a potential point of confusion and aids in understanding the paper's contribution."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that 'none of them is used as a baseline' regarding RL methods. This directly identifies a missing element and provides a clear action for the authors to consider in their experiments. The statement is concrete, specifying the type of method (RL) and its intended use (as a baseline).", "grounding_specificity_rationale": "The review point mentions 'RL methods' generally. While it identifies a category of methods that are missing as baselines, it does not specify a particular section, table, figure, or unique aspect of the paper where this omission is most relevant. The grounding is at the level of the method category rather than a specific part of the authors' work.", "verifiability_rationale": "The review point contains a claim: 'none of them is used as a baseline.' This claim could potentially be verified by examining the paper's experimental setup or related work section. While the review point itself doesn't provide evidence, the claim is stated clearly and is potentially verifiable.", "helpfulness_rationale": "The review point is helpful because it identifies a gap in the related work (the absence of RL methods as baselines) and suggests a concrete area for the authors to explore in their experiments. This provides a clear direction for improvement and helps the authors contextualize their work within the broader field of NMT."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the ambiguity surrounding the term \"Efficient Proxy\". While the reviewer doesn't explicitly state what they mean by \"Efficient Proxy\", they clearly indicate that the authors are unclear about whether it refers to a specific proxy or a general family of proxies. This is an explicit statement of a problem. However, the reviewer doesn't provide a concrete action or suggestion to resolve this ambiguity. The reviewer identifies the *area* of confusion (the definition of \"Efficient Proxy\") but doesn't offer a specific direction for the authors to take. Therefore, while the reviewer identifies a problem, they don't provide a clear action for the authors to follow.", "grounding_specificity_rationale": "The reviewer explicitly mentions the term \"Efficient Proxy\" in the review. This demonstrates that the reviewer can identify the specific part of the paper being addressed, even if the exact nature of that part (a specific proxy vs. a family) is unclear. The reviewer also explains the ambiguity, stating that the authors are unclear if it's a particular efficient proxy or efficient proxies in general. This explanation provides clear grounding of the issue within the paper. Therefore, the reviewer not only identifies the *area* of confusion but also clarifies the nature of the ambiguity.", "verifiability_rationale": "The reviewer states that the authors are \"unclear if the authors mean a particular efficient proxy or efficient proxies in general, \"is\" suggests that it is a particular proxy, but then there is not proxy called \"Efficient Proxy\", which suggests that it is rather referring to a family of efficient proxies;\" This statement directly expresses a belief about the authors' understanding. However, the reviewer does not provide any external references or logical reasoning to support this claim. The reviewer is simply stating their observation about the authors' potential confusion. There is X being verified in this review point.", "helpfulness_rationale": "The reviewer's comment is a statement of observation about the potential ambiguity of the term \"Efficient Proxy\". While this observation is valid and could be helpful for the authors to understand the potential confusion, the reviewer does not provide any specific actions or suggestions to address this issue. The comment is a pointer towards a potential problem, but it doesn't actively help the authors improve their draft. Therefore, the comment is not directly actionable or verifiable, making it 3 in identifying a problem but not in providing a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential redundancy. They suggest that the 'stacking' of methods, which already includes a 'Grouplearning setting,' might implicitly handle the grouping that DBSCAN is later used for. While the reviewer doesn't explicitly state that the 'stacking' *is* the grouping, the implication is that it's already being addressed. The action is implied but not explicitly stated as 'use DBSCAN for clustering' without the context of the 'stacking' already handling grouping. The reviewer suggests the 'stacking' might be doing the grouping already, making the explicit use of DBSCAN potentially redundant. This implies a lack of clarity in the description of how the grouping is achieved.", "grounding_specificity_rationale": "The reviewer mentions 'methods of Mirzasoleiman et al., 2020' and 'Grouplearning setting' as well as 'DBSCAN'. These are specific terms and methods. This allows the reader to identify the referenced parts of the paper. The grounding is explicit as the reviewer names specific components of the method.", "verifiability_rationale": "The reviewer makes a statement about the method being 'stacked' and then using DBSCAN. This is a claim about the methodology. However, the reviewer does not provide any evidence or reasoning to support this claim. The reviewer is stating an observation or a potential inefficiency without providing a logical justification or external references. The claim is presented without sufficient support or explanation.", "helpfulness_rationale": "The reviewer points out a potential inefficiency in the method description. They suggest that the 'stacking' of methods might already handle the grouping that DBSCAN is later used for. This implies a lack of clarity in the description of how the grouping is achieved. The reviewer is making an observation about the potential redundancy of the method description. While it doesn't directly criticize the results, it points out a potential area for improvement in the clarity and conciseness of the method description. It's helpful in that it encourages the authors to consider whether the explicit use of DBSCAN is necessary after potentially already grouping the methods through the 'stacking'."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly suggests an action: 'see if the authors can clarify whether the MFTMA scores are resilient to the choice of random projection matrix.' This direct suggestion makes the review actionable.", "grounding_specificity_rationale": "The reviewer's suggestion is general and lacks specific details. They do not specify which aspect of the random projection matrix to vary or how to vary it. They also do not define what 'resilience' means in this context. The lack of specificity makes the grounding weak.", "verifiability_rationale": "The reviewer makes a claim: 'I think one could construct pathological projection matrices that skews the MFTMA capacity and width scores. These are probably unlikely with random projections, but it would still be helpful to see resilience of the metric to the choice of random projection.' While the claim is about resilience, the reviewer does not provide any specific evidence or reasoning to support this claim within the review point itself. Therefore, the verifiability is 3 as the claim lacks strong justification within the provided text.", "helpfulness_rationale": "The reviewer's comment is clearly aimed at improving the paper (or at least understanding the method better). They are offering a concrete suggestion: 'I think one could construct pathological projection matrices that skews the MFTMA capacity and width scores. These are probably unlikely with random projections, but it would still be helpful to see resilience of the metric to the choice of random projection.' This suggests a desire to address a potential weakness in the paper's methodology. Therefore, the review is helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification and explicit details, which can be seen as an implicit action to improve the paper. However, the action is not very concrete, and the reviewer does not explicitly state how to implement the suggested changes.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 1' and asks about specific terms within it ('support data' and 'predicted training count data'). This clearly grounds the comment to a specific part of the paper and its content. The comment also implies a desire for more explicit model details, which can be inferred from the request to add it to the appendix. While the action of adding to the appendix isn't explicitly stated, the grounding is clear.", "verifiability_rationale": "The review point does not make a claim that can be verified. It is a request for clarification and information rather than a statement that needs evidence or justification.", "helpfulness_rationale": "The review point is likely to be 3 as it prompts the authors to clarify their data and provide more explicit details about their model. This can help them identify potential issues in their description and ensure the reproducibility of their work. However, it doesn't provide a definitive critique or solution, so it's not 5."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The statement explicitly mentions 'the evaluation of FGT' and 'the ablation study' and how the former is used in the latter ('which should be used to evaluate the performance of the proposed method and the comparative methods'). While it doesn't specify the exact nature of the evaluation or the ablation study, it clearly identifies the action (evaluation) and its target (ablation study).", "grounding_specificity_rationale": "The statement refers to 'the evaluation of FGT' and 'the ablation study' and 'the performance of the proposed method and the comparative methods'. While not explicitly pointing to a specific section or table, it clearly identifies the part of the paper being addressed (the ablation study and the comparison). The comment also specifies what is being evaluated (FGT performance) and against what (proposed method and baselines).", "verifiability_rationale": "The statement makes a claim: 'the evaluation of FGT is only leveraged to evaluate the method performance in the ablation study'. This is a statement about the methodology. While it doesn't provide explicit reasoning or citations within the review point itself, it presents a logical argument: the ablation study is designed to assess performance, and if FGT evaluation is the primary tool, it's because it's relevant to that performance assessment. The 'only' is the main point of contention here.", "helpfulness_rationale": "The reviewer raises a potential concern about the completeness of the evaluation of the proposed method. If the ablation study *only* leverages FGT evaluation, it might suggest that other aspects of the method's performance are not being adequately assessed. This could be a helpful point for the authors to address, as it highlights a potential limitation in the experimental design or reporting."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment 'The model seems overly simple' does not explicitly state what action the authors should take. While it suggests the authors might want to consider more complex models, it doesn't pinpoint a specific part of the model or the analysis that needs improvement. It's a statement of opinion rather than a directive.", "grounding_specificity_rationale": "The comment 'The model seems overly simple' does not specify which part of the paper the model refers to. It uses the general term 'the model', which could refer to the entire model, a specific component, or the modeling approach in general. Therefore, it does not achieve full grounding specificity.", "verifiability_rationale": "The comment 'The model seems overly simple' is an opinion, not a claim that requires verification. It expresses a subjective assessment of the model's complexity without providing any specific examples or references.", "helpfulness_rationale": "The comment 'The model seems overly simple' identifies a potential weakness in the model but does not offer any concrete suggestions for improvement. It points out a feature (simplicity) but doesn't provide a bug (improvement)."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a declarative statement identifying a limitation, not a directive asking for changes. There is no explicit or implicit action or suggestion for the authors to take.", "grounding_specificity_rationale": "The authors can easily identify the specific part of the paper being addressed: 'narrow task (climate change QA) in a specific language (Arabic)'. This is a literal mention of sections, tables, figures, etc., and unique elements of the paper.", "verifiability_rationale": "The statement about the 'broader impact may be limited' is an opinion or judgment about the paper, not a claim that can be verified using logical reasoning, common knowledge, or external references within the review point itself.", "helpfulness_rationale": "The review point identifies a valid limitation of the work but does not offer any suggestions or constructive feedback on how to address this limitation. It is merely a statement of fact."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the concern about the paper's novelty and provides specific examples like 'simplified settings' and 'most of the findings have been reported in previous works (Sec 5)'. While the reviewer doesn't directly name an action to be taken, the statement 'It's unclear how this paper contributes novelly...' implies a desire for clarification on the novelty. The reviewer also points to specific areas (previous works, Sec 5) which could be seen as hints towards where the novelty might be lacking, although the exact element isn't specified.", "grounding_specificity_rationale": "The reviewer mentions 'previous works' and 'Sec 5' as context for evaluating the paper's contribution. While they identify a potential area of overlap with existing research, they don't explicitly pinpoint a specific section, table, or figure within the paper that is being criticized. The reviewer is general in their reference to previous work and a section, indicating a lack of precise grounding.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a critique of the paper's contribution rather than a statement that needs supporting evidence.", "helpfulness_rationale": "The reviewer raises a valid concern about the paper's novelty and contribution. However, the review point itself doesn't offer concrete suggestions or improvements to the draft. It's more of a critique of the research's novelty rather than a direct improvement suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two explicit suggestions: (1) to mention the computational cost in the main paper and (2) to include runtime examples. These are direct actions the authors can take to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly states the goal is to 'briefly mention' the computational cost in the 'main paper' and suggests including 'runtimes'. These are specific actions and sections within the paper.", "verifiability_rationale": "The reviewer's suggestions are based on the practical importance of computational cost and the usefulness of runtime information for application. While they don't provide external references, the reasoning is logical and directly relevant to the stated goals.", "helpfulness_rationale": "The reviewer provides two clear and actionable suggestions aimed at motivating the method and assisting readers in applying it. The suggestions directly address practical concerns and offer concrete steps for improvement. The reviewer explicitly states the 'why' behind the suggestions, connecting them to motivation and application."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly recommends the authors 'elucidate this procedure in greater detail' and asks a specific question about a key aspect ('whether the spatial arrangement of the EEG sensors played any role in this process'). This directly points to an actionable improvement the authors should make. The reviewer provides a clear direction for the authors to follow, making the action quite concrete. The reviewer is not just pointing out a problem but suggesting a specific way to address it.", "grounding_specificity_rationale": "The reviewer mentions 'Figure 3' which is a specific part of the paper. While they don't explicitly state the section number or title, referring to a specific figure implies they can identify the relevant part. The reviewer also specifies the type of plot ('EEG topography') and asks a question about a specific detail within that plot ('the role of spatial arrangement of the EEG sensors'). This level of detail in identifying the relevant part and the specific issue makes the grounding quite specific.", "verifiability_rationale": "The reviewer doesn't make a definitive claim about what is *wrong* with the EEG token quantization process. They are recommending improvement rather than critiquing the method itself. However, the implication is that the current process is unclear, leading to ambiguity. This could be considered a weak claim. The reviewer's suggestion is not verifiable because it's a recommendation for improvement, not a statement that can be proven true or false with evidence. The reviewer is suggesting the authors *elaborate* on the process, which is a suggestion for clarification, not a claim requiring external references or logical reasoning.", "helpfulness_rationale": "The reviewer provides a clear and actionable recommendation for the authors to improve their understanding of the EEG token quantization process. They specifically ask the authors to 'elucidate this procedure in greater detail' and to consider the 'role of spatial arrangement of the EEG sensors'. This directly addresses a potential area of confusion and provides a concrete direction for the authors to take. The reviewer's comment is not critical but rather constructive and aimed at improving the authors' understanding of a specific technical aspect. The suggestion is specific and directly targets a potential ambiguity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action of 'no need to distinguish' and provides a reason ('they are calculated in the same way'). While the action itself is not very specific on how to simplify, the reviewer clearly identifies a potential improvement. The reviewer also mentions the notations 'SM' and 'DM', which are specific to the paper's context, providing grounding for the suggestion.", "grounding_specificity_rationale": "The reviewer uses the notations 'SM' and 'DM', which are specific to the paper's context, providing grounding. The reviewer also explicitly states the reason for the suggestion ('they are calculated in the same way'), clearly identifying the issue and the potential simplification, making it specific.", "verifiability_rationale": "The reviewer makes a claim ('there may be no need to distinguish') and provides a justification ('as they are calculated in the same way'). This justification is logical and based on the information provided in the review point, making the claim verifiable.", "helpfulness_rationale": "The reviewer clearly identifies a potential improvement (simplifying the distinction between the metrics) and provides a reason for it. This suggests a relevant and actionable feedback for the authors, making it helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a fact ('the authors leverage the complexity...') and offers an opinion ('This feels like...'). While the reviewer points to a specific technical detail, they do not explicitly state what needs to be changed or how the authors should address this complexity. The action is implied but not explicitly stated and lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the Witness oracle,' 'polynomial time,' and 'tabular case.' These are specific technical terms and concepts within the paper, demonstrating a clear understanding of the section being discussed. This can be achieved through:  Literal mentions of sections, tables, figures, etc.  Mentions of unique elements of the paper.  General comments that clearly imply the relevant parts without explicitly naming them. In this case, the reviewer provides literal mentions of key terms.", "verifiability_rationale": "The reviewer states a fact ('the authors leverage the complexity...') which can be verified. However, the reviewer also offers an opinion ('This feels like...'). The claim is partially verifiable as the claim is wellsupported but lacks key elements (e.g., examples, references). The reviewer provides the fact about 'polynomial time' but doesn't elaborate with examples or references to external works to further support their feeling that it's not a 'direct way'.", "helpfulness_rationale": "The reviewer expresses a preference for a 'more direct way' but does not provide specific reasons why the current approach (using the Witness oracle and checking for 'polynomial time') is problematic or how the authors should change it. The comment is critical of the approach but lacks concrete suggestions or explanations of the limitations of the current method. The authors are left without actionable feedback on how to improve their draft based on this review."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out a specific section (lines 2230) and identifies a clear weakness: the lack of discussion on moment matching in distributional RL, despite using quantile regression. The reviewer suggests a concrete action: 'Discuss moment matching...even though the present paper still uses quantile regression instead of moment matching.' This suggests a clear next step for the authors, indicating a direct and actionable piece of feedback.", "grounding_specificity_rationale": "The reviewer provides a very specific section reference (lines 2230) and a precise suggestion (discuss moment matching, even though they use quantile regression). This demonstrates strong grounding specificity, as the reviewer clearly identifies the relevant part of the paper and the specific issue within that part.", "verifiability_rationale": "The reviewer does not explicitly claim that moment matching is better or worse than quantile regression. However, the suggestion to discuss it, even if the paper uses a different method, provides a basis for verification. The reviewer is proposing a concrete action the authors could take, which implies a potential improvement or clarification. While the claim is not explicitly stated as a judgment, the suggestion itself acts as a form of justification \u2013 the reviewer is proposing a relevant piece of information. Therefore, it is 3.", "helpfulness_rationale": "The reviewer's comment is clearly intended to be helpful. They are providing context and suggesting a relevant piece of information (moment matching) that could improve the authors' understanding of distributional RL, even if their paper uses a different method. The suggestion is concrete and actionable, directly pointing to a potential improvement for the authors. The reviewer is not criticizing the authors' choice of quantile regression but rather providing a broader perspective on the field. This makes the comment highly relevant and helpful for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a consequence of the subset choice ('raises questions about generalizability') but does not explicitly propose a solution or action to address this consequence. The action is implied but not clearly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Massive Text Embedding Benchmark (MTEB)' and refers to a 'subset' of it. This clearly identifies the area of the paper being discussed. While not pinpointing a specific section, the reference is clear and unambiguous.", "verifiability_rationale": "The reviewer expresses a concern ('raises questions about generalizability') and suggests further investigation ('it would be helpful to understand the criteria...'). This indicates a claim that the subset choice is problematic. However, the reviewer does not provide specific evidence or references to support this claim about the limitations of a subset.", "helpfulness_rationale": "The reviewer's comment prompts the authors to consider the limitations of their evaluation strategy and explore a broader range of benchmarks. This is a valuable piece of feedback that encourages improvement. However, the comment itself does not offer a concrete solution or specific steps to address the identified issue."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a lack of clarity in the second paragraph of the introduction regarding the subject of the 'modeling curves'. While it points out the ambiguity, it doesn't explicitly state that the curves are intended to model tumor growth or any other specific aspect. The reviewer suggests improving clarity, which is a general suggestion without specifying how to achieve it. Therefore, the action is implied but not explicitly stated, and the action itself (improving clarity) is vague.", "grounding_specificity_rationale": "The comment explicitly refers to the 'second paragraph of the introduction' when identifying the issue with 'modeling curves'. This allows the reader to locate the relevant section of the paper. However, the comment does not specify *what* is being modeled within that paragraph. The grounding is present (mentioning a specific section), but the specificity is lacking as the exact content being modeled is not identified.", "verifiability_rationale": "The comment contains a claim: that the second paragraph of the introduction needs to be clearer about what is being modeled. However, the comment does not provide any justification or examples to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the paragraph is unclear in this specific regard. The claim is stated without any supporting evidence.", "helpfulness_rationale": "The comment identifies a potential area for improvement in the introduction by pointing out the lack of clarity in the 'modeling curves' section. However, the comment does not offer any specific suggestions or guidance on how to improve this clarity. It simply states the problem without providing any actionable steps or examples of how the issue can be addressed. The feedback is identified but not elaborated upon with concrete suggestions."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific experimental detail (the comparison between shift=0 and shift~ N ( 0 , \u03c3 2 ) in shiftedMNIST) and suggests a specific experiment (testing the model and baselines on test samples from the observational distribution). This directly identifies an area where the author's draft could be improved by clarifying the experimental setup and providing results for a specific distribution. The reviewer's suggestions are direct and point to specific actions the author should take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'shiftedMNIST' and focuses on the comparison between 'shift=0' and 'shift~ N ( 0 , \u03c3 2 )'. They also specify the type of performance to show ('test samples from the observational (in) distribution'). This demonstrates a clear understanding of the specific section and table (or unique aspect) being addressed, making the grounding highly specific.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity in the current explanation of the shiftedMNIST experiment and suggests a specific experiment to be performed. This claim is supported by the reviewer's direct statement and the logical reasoning that testing on the observational distribution would provide valuable insights. While not a direct criticism of a claim within the paper itself, the reviewer's suggestion is a clear indication of a point that needs further clarification and verification within the context of the author's draft.", "helpfulness_rationale": "The reviewer's comment is 5 because it directly points out a potential source of confusion in the experimental setup description and provides a concrete suggestion for improvement. By highlighting the ambiguity surrounding the shift parameter and recommending a specific experiment, the reviewer empowers the author to clarify their methodology and potentially identify a weakness in their approach. The suggestion to test on the observational distribution is a practical and actionable step that can significantly enhance the understanding and evaluation of the model."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states 'Description of experimental details would significantly benefit from increased clarity', which directly tells the authors what the issue is and what they should do. This is an explicit and concrete action.", "grounding_specificity_rationale": "The comment refers to 'experimental details' generally, which does not pinpoint a specific section, table, figure, or unique aspect of the paper. While it implies the need for clarity in the methods section, it lacks specificity about the exact part requiring improvement. The suggestion for 'increased clarity' is also vague.", "verifiability_rationale": "The comment does not make a claim that requires verification. It suggests an improvement ('increase clarity') rather than stating a definitive point about the paper that needs justification.", "helpfulness_rationale": "The comment clearly identifies a weakness ('lacking detail') and provides a concrete suggestion for improvement ('increase clarity'). It directly tells the authors what to do and how to address the issue, making it 5 for revision."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'expected' and then provides a concrete suggestion: 'One of the main contributions of this paper is the CBR, so different optimization strategies and the corresponding results should discussion.' This indicates a clear action to be taken: to discuss the CBR and its optimization strategies. Furthermore, the reviewer provides a specific example of how this discussion should be conducted: 'For example, what will happen by minimizing both of the inter and intra terms in Eq 3 or only minimizing the first term?' This explicit and concrete action makes it 5.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'the main contributions of this paper is the CBR' and then asks about 'different optimization strategies and the corresponding results'. This direct mention of the CBR clearly identifies the specific part of the paper being addressed. The reviewer also specifies what needs to be explained about this part: the impact of different optimization strategies. This explicit identification and clear specification make it 5.", "verifiability_rationale": "The reviewer states 'expected' and then provides a rationale for this expectation: 'One of the main contributions of this paper is the CBR, so different optimization strategies and the corresponding results should discussion.' This statement is a claim that the paper lacks sufficient explanation and discussion in these areas. The reviewer provides a logical reasoning for this claim, linking it to the identified contribution (CBR) and the importance of discussing optimization strategies. While the reviewer doesn't provide external references, the reasoning is based on the content of the paper and the importance of these aspects. This makes the claim 3.", "helpfulness_rationale": "The reviewer directly points out a potential weakness in the paper: the lack of explanation and discussion, particularly regarding the CBR and optimization strategies. They then provide a clear and actionable suggestion: to discuss these aspects and provide corresponding results. The reviewer even gives a concrete example of how to do this: 'For example, what will happen by minimizing both of the inter and intra terms in Eq 3 or only minimizing the first term?' This constructive and specific feedback directly addresses a potential area for improvement and guides the authors on how to enhance their work. The reviewer's direct identification of the problem and their proposed solution make this review point 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out that 'treewidth' is central to all the proofs, which is a clear indication of its importance. While the reviewer doesn't explicitly state an action, the suggestion to 'include a formal or intuitive definition' is a direct and actionable step the author can take to improve their draft. The reviewer identifies a specific area where the author might need more context and guidance.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'treewidth' as the central element and suggests a specific way to address it ('include a formal or intuitive definition'). This directly identifies the missing part and provides a clear action, making it 5.", "verifiability_rationale": "The reviewer states a fact ('treewidth is central to all the proofs') and provides a suggestion ('include a formal or intuitive definition'). This claim is verifiable by examining the paper's proofs and by the author's ability to add a definition section. The suggestion is also verifiable by including either a formal definition or a good intuitive explanation.", "helpfulness_rationale": "This review point is 5 because it directly addresses a potential weakness for the reader \u2013 the lack of understanding of 'treewidth' and its importance to the proofs. By suggesting the inclusion of a definition, the reviewer provides a concrete and actionable improvement that would enhance the clarity and accessibility of the paper. The reviewer's point is directly relevant to the paper's core contributions and would significantly benefit the reader's understanding."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the *what* (convergence to permutations as local minima) and *what improvement is desired* (quality of these local minima). They even suggest a specific method for analysis (approximation ratio under certain assumptions). This provides clear guidance on how the authors should improve their draft.", "grounding_specificity_rationale": "The reviewer refers to 'Algorithm 1' and the 'local minima' of that algorithm. This is a specific part of the paper. They also identify the specific concept they want analyzed ('quality of these local minima'). This allows the authors to precisely identify the area needing improvement.", "verifiability_rationale": "The reviewer makes a suggestion for the authors to analyze the 'quality of these local minima' using the 'approximation ratio under certain assumptions'. While the paper doesn't *currently* do this, the *suggestion itself* is based on wellestablished concepts in optimization and theoretical computer science. The *assumptions* are a point of potential limitation, but the *core idea* of analyzing quality is verifiable. The reviewer is *suggesting* a way to improve the paper, not *stating* a fact about the current work.", "helpfulness_rationale": "The reviewer provides a concrete suggestion for the authors to improve their analysis. They are not just pointing out a *where* but also *how* the authors should improve their work by analyzing the quality of the local minima using the approximation ratio. This directly helps the authors improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the paper is not selfcontained and requires the supplementary material for understanding. While the reviewer requests supplementary material and code, the *action* of providing the supplementary material and code is not explicitly stated as a concrete action to be taken by the authors. The reviewer implies that this would help, but doesn't specify *how* the supplementary material or code will address the lack of selfcontainment. Therefore, while the reviewer identifies a problem, the specific action to be taken is not clearly defined.", "grounding_specificity_rationale": "The reviewer states that the paper is not selfcontained and that the supplementary material is necessary to understand 'large parts of the main paper'. This indicates that the reviewer cannot confidently pinpoint the exact section or table that is causing the difficulty. The use of the vague term 'large parts' suggests a lack of specific grounding. Furthermore, the reviewer does not specify what these 'large parts' are or how the supplementary material clarifies them. The request for code is also 1 in a specific aspect of the paper.", "verifiability_rationale": "The reviewer states two things: 1) 'The paper is not self contained Understandable given the NIPS format, but the supplementary is necessary to understand large parts of the main paper and allow reproducibility.' and 2) 'I also hereby request the authors to release the source code of their experiments to allow reproduction of their results.' Neither of these statements are claims that require justification or verification. They are statements of observation and a request for additional resources. Verifiability applies to claims, not requests or observations.", "helpfulness_rationale": "The reviewer clearly identifies a significant issue: the lack of selfcontainment and the need for supplementary material and code to achieve reproducibility. They directly state what is missing and what they believe is necessary to address it. This is a direct and helpful critique aimed at improving the reader's ability to understand and reproduce the work. The reviewer is not just pointing out a problem but also providing a clear direction for how the problem might be addressed."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks 'How important is the added complexity?' and 'Will one IN do?'. These are direct questions that the authors can use to evaluate the design choice. The reviewer also mentions 'a seemingly important novel feature' and 'the dynamics predictor', which are specific aspects of the model. The questions are about the impact of a specific design choice on a particular component of the model.", "grounding_specificity_rationale": "The reviewer refers to 'a seemingly important novel feature' and specifically asks about 'the dynamics predictor'. While not a direct section reference, the connection to the dynamics predictor is implied. The reviewer also mentions 'multiple speeds' in the dynamics predictor, which is a specific detail of the design. The questions directly relate to this specific design choice.", "verifiability_rationale": "The reviewer does not explicitly state a claim about the importance of the multiple INs. However, the reviewer's questions imply a belief that the added complexity might be unnecessary. While the reviewer suggests an investigation through ablation studies, this is a suggestion for future work rather than a claim that is immediately verifiable within the review point itself. The reviewer does not provide specific evidence or logical reasoning to support their belief *before* suggesting the ablation study.", "helpfulness_rationale": "The review point directly addresses a potential weakness of the model, which is the added complexity of the multiple INs at different speeds in the dynamics predictor. The reviewer's questions, 'How important is the added complexity?' and 'Will one IN do?', are directly relevant to the authors' concerns about this novel feature. The suggestion to investigate this through ablation studies is a concrete action the authors can take."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: 'the opponent simply doesn't aim at maximizing it' and provides a reason: 'because the opponent maximizes classical SE and AE'. This is an explicit action or suggestion that authors can directly identify modifications they should apply to their draft, though the specific modifications are not detailed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the experiments,' 'opponent,' 'multiagent payoff,' 'opponents aim,' 'classical SE,' and 'AE' when explaining the issue. This allows the authors to accurately pinpoint the section and concepts being discussed, making it fully grounded.", "verifiability_rationale": "The reviewer makes a claim: 'In particular, in the experiments, it doesn't come as a complete surprise that the opponent can be outperformed w.r.t. the multiagent payoff proposed by the authors, because the opponent simply doesn't aim at maximizing it (e.g. in the experiments he maximizes classical SE and AE).' This claim is verifiable based on the established definitions of Solution Equilibria and Alternating Equilibria in game theory, which are wellaccepted practices. While a formal proof might be needed for absolute certainty, the claim is supported by logical reasoning and common knowledge within the field.", "helpfulness_rationale": "The reviewer points out a potential flaw in the experimental design by highlighting the discrepancy between the authors' payoff and the opponent's objective (SE/AE). This is a valuable piece of feedback for the authors to consider when interpreting their results and potentially redesigning their experiments. The reviewer provides a clear explanation of why this discrepancy might exist, making the feedback constructive."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly asks for justification of the choice of the REINFORCE algorithm over alternatives like PPO. This is a direct request for information and a clear indication of a potential area for improvement. The reviewer also states their presumption that this choice is related to the paper's focus on attention models, which, while not explicitly stated, implies a connection. This explicitness makes it actionable in the sense that the authors should be able to directly identify the modification they should apply: seek justification for the algorithm choice.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'REINFORCE algorithm' and 'PPO' as the two options being considered. This provides a clear and specific reference point. While the reviewer also mentions the potential connection to 'attention model paper', this is an implied connection rather than a direct mention of a specific section or table. Therefore, the grounding is strong but not perfect.", "verifiability_rationale": "The reviewer is not presenting a claim that needs verification. They are asking a question: 'I presume it has to do with the attention model paper this one iterates on, but clarification would be good.' This is a request for information, not a statement that requires evidence or justification. There is X being made that needs to be verified.", "helpfulness_rationale": "The reviewer's point is a valid question that could potentially lead to further clarification and potentially a better methodological choice. However, it does not directly identify a flaw in the current approach, suggest a concrete improvement, or offer a novel insight. The feedback is primarily a request for more information rather than a constructive critique or suggestion. Therefore, it is not 5 in improving the paper's content or methodology."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states they are 'confused' about the statement in Theorem 5.1. While they could identify the theorem as relevant, the action they could take is to understand the comparison between MMD DRO and the variance regularized problem. However, the action itself is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Theorem 5.1' and compares it to a 'variance regularized problem'. This demonstrates a clear identification of the specific part of the paper and the comparison being made, indicating strong grounding and specificity.", "verifiability_rationale": "The reviewer states their confusion about the statement in Theorem 5.1 without providing any supporting evidence or justification. There is no logical reasoning, common knowledge, or external references provided to support their claim about the theorem's implications. The comment is presented as a statement without any backing.", "helpfulness_rationale": "The reviewer's confusion about the statement in Theorem 5.1, and their interpretation of it as potentially indicating a disadvantage for MMD DRO, is intended to provide insight and highlight a point of interest. While the comment is not explicitly asking for clarification or a question, it is intended to be a helpful comment by revealing a potential weakness or area for improvement in the authors' understanding. However, the lack of clarity makes the helpfulness somewhat limited."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states they want more information on how morphologic segmentation is conducted across domains and raises a question about its invariance. This directly points to a need for clarification and action. The reviewer believes this clarification is important for the task of domain adaptation, indicating a clear action the authors should take to understand this aspect better. The request for more detail and clarification is a direct action the authors can take to improve their understanding of the method.", "grounding_specificity_rationale": "The reviewer mentions 'morphologic segmentation' and 'domain adaptation' without explicitly stating which section or table discusses this. While the context strongly suggests they are referring to a specific part of the paper related to their expertise, the connection is not immediately obvious. The reviewer's question about the differences across domains highlights a lack of specific grounding in the paper's treatment of this topic. The grounding is implicit, requiring the reader to infer the relevance of the discussed methods to the specific task.", "verifiability_rationale": "The reviewer states that the paper 'assumed morphologic segmentation will be invariant' and questions this assumption. This is a clear claim made in the paper that lacks explicit justification or evidence within the paper. The reviewer's questioning implies a lack of sufficient support or logical reasoning to back this assumption. The claim is presented without a clear explanation of why this assumption is reasonable or supported by the presented evidence.", "helpfulness_rationale": "The reviewer's point directly addresses a core methodological aspect of the paper \u2013 the domainspecificity of morphologic segmentation. Their request for clarification and the question about the invariance assumption highlight a potential gap in the paper's explanation. This point is likely to be 5 for the authors by guiding them to consider the implications of this assumption and potentially improving the clarity and rigor of their method description. The reviewer's suggestion is constructive and directly addresses a potential area of confusion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the desired experiment ('there should be experimental results of excluding such mixup technique') and clearly identifies the missing element ('there should be experimental results of excluding such mixup technique in the proposed method'). This directly points to a needed action. While the request is clear, the reviewer doesn't *explain* *why* they think this experiment is necessary (beyond the general point about isolating contributions), making it slightly less vague than 'actionable.'", "grounding_specificity_rationale": "The reviewer *mentions* 'Sec. 4.2' and 'mixup technique in LUMP,' which grounds the comment to a specific section and related work. However, they *don't* explicitly state which part of LUMP's mixup technique they are referring to. This lack of precision makes it only somewhat grounded. The reviewer also *implies* the desired experiment, making it somewhat specific.", "verifiability_rationale": "The reviewer states a claim ('the lack of experiments makes it unclear what the pure contribution is') but provides *no* evidence or reasoning to support this claim based *only* on the information given in the review point. There's no logical reasoning, common knowledge, or external references provided to connect the missing experiments to the unclear contribution. Therefore, it's 1 based solely on the statement.", "helpfulness_rationale": "The reviewer clearly states a desire for *experimental results*. This is a direct and actionable request. The reviewer's statement is clear and directly addresses a potential weakness in the paper's experimental validation. While the request is clear, the reviewer doesn't *explain* *why* they think this experiment is crucial for understanding the contribution, making it slightly less actionable than '5.'"}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3.5", "grounding_specificity_label": "4.5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that information is missing. While it doesn't directly tell the authors what to add, it points to a specific area that needs attention. The reviewer is implicitly suggesting that the authors should include a discussion of the Set Transformer and related works using summary tokens. This level of detail suggests a clear area for improvement, making it more than just a vague comment.", "grounding_specificity_rationale": "The comment explicitly mentions 'Set Transformer' and 'other related works that also uses summary tokens'. This is a strong indication of the specific area where information is lacking. The reviewer is not just saying 'missing related work', but specifically pointing to these areas. This high level of specificity makes it easier for the authors to understand what needs to be addressed.", "verifiability_rationale": "The comment contains a claim that information is missing, specifically regarding the Set Transformer and related works using summary tokens. This claim is supported by the reviewer explicitly stating these areas as examples of missing information. The use of specific examples enhances the verifiability of the claim, making it clear and wellsupported.", "helpfulness_rationale": "The comment is helpful by directly pointing out a gap in the related work section. By mentioning the specific areas (Set Transformer and related works using summary tokens), the reviewer provides the authors with a clear direction for further research and discussion. This is a valuable piece of feedback that encourages the authors to broaden their context and potentially position their work more accurately within the field."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question about a specific technical detail in the paper (Fourier features and NTK convergence in the highfrequency range). This constitutes an explicit action, as the reviewer is seeking clarification or confirmation. While it doesn't directly propose a solution, it points to a potential area needing further explanation.", "grounding_specificity_rationale": "The reviewer directly asks a question about a specific aspect of the paper, namely 'How Fourier features accelerate NTK convergence in the highfrequency range?'. This clearly indicates that the reviewer can identify the specific section or concept being discussed, making the grounding explicit. The question is also very specific about the technical details being considered.", "verifiability_rationale": "The review point does not contain a claim. It is a question posed about a specific technical aspect of the paper. Therefore, it does not fall under the categories of verifiable or 1 claims.", "helpfulness_rationale": "The reviewer's comment seeks clarification on a specific technical point. While it doesn't identify a flaw or suggest a solution, it highlights a potential area where the reader's understanding could be improved. This type of feedback can be helpful for the authors by addressing a potential gap in the reader's comprehension."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer states that they cannot find details on a specific training mechanism. While they identify the topic of the missing information, they do not explicitly state how to apply this knowledge or what specific action they should take next. The request is about identifying a missing element, not about performing an action with it.", "grounding_specificity_rationale": "The reviewer refers to 'the network,' 'the residual,' 'the input,' and 'the output' without specifying a particular section, table, figure, or unique element of the paper. They imply it's related to the general training process, making the grounding somewhat weak. While the topic is clear, the exact location is not.", "verifiability_rationale": "The reviewer makes a claim that they 'can't find details on how they make the network fit the residual instead of directly learning the input  output mapping.' This is a claim that can be verified by searching the paper for information related to the training process, network architecture, and the concept of residuals. While the reviewer doesn't provide specific evidence *why* they can't find it, the claim itself is verifiable by looking for relevant sections or descriptions.", "helpfulness_rationale": "The reviewer's request is clear and directly points to a specific area of the paper where more information is needed. They want to understand how the network is trained to fit residuals, which is a crucial detail for understanding the method. This request provides a clear direction for the authors to improve their draft by adding this explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing information: 'What\u2019s the experiment setup in Section 3.3? (data augmentation methods, learning rate, etc)'. This directly points to an actionable step the authors should take to understand the context of their method. The missing information is also concrete, specifying the exact elements of the experiment setup that are needed. Therefore, the reviewer is providing clear guidance on what is missing.", "grounding_specificity_rationale": "The reviewer refers to 'Section 3.3' of the paper, which is a specific part of the document. They then further specify the missing information as 'experiment setup (data augmentation methods, learning rate, etc)'. This demonstrates a clear understanding of where the information is lacking and what specific details are missing within that section. The combination of a specific section reference and a specific detail makes this highly grounded.", "verifiability_rationale": "While the reviewer is pointing out a valid gap in the information provided, the request itself does not contain a claim that can be verified. The reviewer is stating a fact: the experiment setup is missing. There is no suggestion or opinion being made that requires evidence to support it. Therefore, the claim extraction step would classify this as 'X' (X). The request is more of a question or observation than a verifiable statement.", "helpfulness_rationale": "The reviewer clearly identifies a missing piece of information that is directly relevant to understanding the experimental setup of the method described in Section 3.3. This missing information is crucial for the authors to contextualize their work and evaluate its effectiveness. The reviewer's comment directly points to a specific area where the authors need more details. Therefore, the feedback is directly actionable and helpful for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises a question about a potential issue in the calibration steps and suggests a citation. While the reviewer doesn't explicitly state an action to be taken, the suggestion to cite the RVC paper implies a potential next step for the authors. The reviewer also points to a *potential* issue (speed disparity) that could be a result of the calibration steps, but doesn't provide a concrete action to address it. The reviewer's question is not an explicit instruction on what to do, but rather a suggestion for further investigation.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify a specific part of the paper being addressed. The comment is about the algorithm in general and the observed speed disparities. The reviewer does not mention any specific section, table, figure, or unique element of the paper. The comment is about a general observation related to the algorithm.", "verifiability_rationale": "The reviewer's comment is a question and a suggestion for citation. The suggestion to cite the RVC paper provides a reference point, which can be considered a form of justification or verification. However, the question itself is not explicitly justified or supported by any reasoning, common knowledge, or external references within the review point itself.", "helpfulness_rationale": "The reviewer's comment raises a question about a potential issue and suggests a citation. While the suggestion to cite the RVC paper is relevant and provides a potential resource, the question itself is not explicitly addressed or resolved within the review point. The reviewer does not provide a direct explanation or evidence for why an error in the initial calibration steps might explain the speed disparities. The comment is more of a suggestion for further investigation rather than a direct feedback on a specific weakness."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a fact about the difference between ASAP and other methods but does not explicitly recommend any changes or detailed steps for improvement. While the difference is stated, the lack of actionable steps makes it 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'ASAP (and similar methods)' and 'biological networks' and clearly states the difference between the artificial networks trained using ASAP and other techniques. This indicates a high level of grounding specificity.", "verifiability_rationale": "The statement presents a claim about the difference in network resemblance. While the underlying concepts are generally understood within the field, the statement itself is a claim that could be supported by further evidence or references. Therefore, it is 3.", "helpfulness_rationale": "The reviewer points out a potential limitation of ASAP. While it doesn't demand changes, it highlights a difference in the representation learned by ASAP compared to other methods. This could be valuable for authors considering using ASAP, as it helps them understand its potential limitations. However, it doesn't directly instruct the authors on what to do, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question, making it 3. However, the vagueness of the request makes it less actionable.", "grounding_specificity_rationale": "The reviewer asks a general question about statistical significance, which is a broad topic. They don't explicitly point to a specific part of their paper.", "verifiability_rationale": "The reviewer makes a claim (observation about the closeness of numbers). The question about statistical significance isn't a verifiable statement but a request for information.", "helpfulness_rationale": "The question is relevant and could be helpful, but it's a request, not a critique or actionable suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem: 'Which of the common inference tasks in a discrete HMM (filtering, smoothing, marginal observation likelihood) can be computed exactly/approximately with an NPSPECHMM?'. This directly addresses a specific issue within the paper. Furthermore, the reviewer provides a clear direction by asking for clarification on the impact of nonparametric emission distributions on inference. The request is for a direct answer to a specific question, which constitutes an explicit action. While the reviewer doesn't propose a solution, they are directly identifying a gap in the paper's explanation, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'learning HMMs with nonparametric emission distributions' and then directly asks about the 'impact on inference' and specifically which 'inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly/approximately with an NPSPECHMM?'. This clearly identifies the specific part of the paper being addressed. The reviewer provides a unique section (the list of inference tasks) as the grounding point. This falls under the definition of 'fully grounded' as the paper can be easily identified through the provided section and the unique aspect of the inference tasks being asked about. The request is also very specific, asking about the possibility of computing specific inference tasks with a specific type of HMM. This falls under 'specificity' as the question is very focused and clear.", "verifiability_rationale": "The reviewer is essentially posing a question seeking information, which can be considered a claim about what the authors should know. However, the paper does not currently provide the answer to this question. While the potential answer could be considered verifiable (the possibility of computing these tasks with NPSPECHMMs is a claim that could be supported by external references or logical reasoning), the paper itself does not currently provide this information. Therefore, it is not 5 as the information is not present. If we consider the question itself as the claim, the paper does not currently provide sufficient justification or evidence to support the answer to this question. Therefore, it is 2.", "helpfulness_rationale": "The reviewer is asking a very specific question about a relevant aspect of their work. They are trying to improve their understanding and potentially their work by knowing which inference tasks are possible with their specific type of HMM. While the paper does not currently provide this information, the request itself is a valuable piece of feedback that could help the authors improve their understanding and potentially their work. The question is clear and directly addresses a gap in the paper's explanation. Therefore, it is 3 as it points to a specific area where the authors need more information."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the authors 'only mention that the scope prompting method shows poor performance on GPT3.5turbo, but they do not provide any analysis of the underlying reasons behind this outcome.' This directly points out a missing analysis, making the comment actionable for the authors to investigate the reasons for the poor performance. The reviewer suggests the authors should analyze the reasons, which is a clear direction.", "grounding_specificity_rationale": "The reviewer mentions 'the scope prompting method' and 'GPT3.5turbo'. While the model name is specific, the method is described generally. The reviewer doesn't explicitly refer to a specific section, table, or unique aspect of the paper related to this method. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim about the authors' analysis: 'the authors only mention that the scope prompting method shows poor performance on GPT3.5turbo, but they do not provide any analysis of the underlying reasons behind this outcome.' This is a statement of fact about the authors' actions. While the reviewer doesn't provide specific examples of *why* the analysis is missing, the claim is clear and implies a lack of justification. The support is somewhat lacking as it doesn't point to a specific instance or provide a reference.", "helpfulness_rationale": "The reviewer clearly identifies a specific weakness in the authors' analysis: the lack of investigation into the reasons behind the poor performance of the scope prompting method on GPT3.5turbo. This is a direct and constructive criticism that provides a clear direction for the authors to improve their work. The reviewer suggests a specific action the authors should take (perform an analysis)."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a direct question about the discrepancy between the number of datasets mentioned and the number used in the experiments. This constitutes an explicit action or statement that requires further clarification. While the reviewer doesn't *immediately* tell the authors what to do, they are prompting the authors to explain their methodology. The action is somewhat vague as the reviewer doesn't specify *why* only 10 datasets were chosen or what the implications are.", "grounding_specificity_rationale": "The reviewer points out a specific discrepancy between the total number of datasets mentioned (120) and the number used in the experiments (10). This demonstrates a clear identification of a specific part of the paper (the experimental setup and dataset usage) where there appears to be a mismatch. The grounding is implicit because the reviewer is inferring that the 10 datasets are the ones actually used for the batch vs. greedy comparison, rather than explicitly stating the names or indices of these datasets.", "verifiability_rationale": "The reviewer makes a statement about the paper's methodology, questioning the scope of the experiments. This constitutes a claim that needs to be supported. The reviewer is asking *why* only 10 out of 120 datasets were considered. While the reviewer doesn't provide external references or logical reasoning *within this review point*, they are prompting the authors to explain their experimental design and its limitations. The claim is somewhat underspecified as the reviewer doesn't detail the criteria for selecting the 10 datasets or the reasons for excluding the other 110.", "helpfulness_rationale": "The reviewer's comment is informative and points to a potential area of confusion or a limitation in the paper's reporting. They are asking for clarification on a specific aspect of the experimental setup. This is a valuable piece of feedback as it encourages the authors to provide more detail about their methodology. The request is specific and directly related to the reported results."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to remove the lowrank factorization motivation from the introduction and to discuss the implications of the results for lowrank matrix factorization. This is a clear and direct action that authors can readily understand and implement.", "grounding_specificity_rationale": "The reviewer refers to the 'introduction' and the 'lowrank factorization' section. While they mention the specific areas of the paper, they do not explicitly identify the specific sentences, paragraphs, or unique elements within those sections that they believe need improvement. The reference is somewhat general.", "verifiability_rationale": "The reviewer makes a claim about the 'unnecessary nature' of the lowrank factorization motivation and expresses a desire to 'explicitly discuss' its implications. However, they do not provide any logical reasoning, examples, or external references to support this claim. It is presented as a preference or suggestion rather than a verifiable statement.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: to remove the lowrank factorization motivation and discuss the implications for lowrank matrix factorization. This is a valuable suggestion that directly addresses a potential area for improvement and could help the authors better position their work. The reviewer's intent is to enhance the paper's clarity and relevance."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "Weakly Grounded", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete improvement. It's a question about the labels, not a direct instruction on how to generate code. Therefore, it's not actionable as it doesn't tell the authors what to do or how to do it.", "grounding_specificity_rationale": "The reviewer is asking about the source of the labels (dataset itself, evaluation script, etc.). While the question is about the *source*, the reviewer is asking a specific question about the *specificity* of the labels. The labels themselves are not being identified, but the origin of their definition is being questioned. Therefore, it's weakly grounded because the reviewer can infer the labels exist but cannot precisely identify the referenced part (the label definition source).", "verifiability_rationale": "The review point itself does not contain a claim. It's a request for information about the labels. Therefore, it doesn't have verifiability as there's no statement to verify.", "helpfulness_rationale": "The review point is important because it directly addresses a potential ambiguity for the authors regarding the labels used for evaluation. By clarifying the source of these labels, the reviewer is helping the authors understand what constitutes a 'correct' generation for these specific datasets. This allows them to focus their debugging efforts and compare their code against a clear target. This directly helps the authors understand and improve their code."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point mentions adapting an existing architecture and producing heatmaps. While it points to a *change* (adaptation, joint heatmaps), it doesn't explicitly state *what to do next* or *how to implement* the adaptation. The connection to \"identity/tag heatmaps\" is implied but not a concrete action. The vagueness stems from \"adapt the existing architecture\" and \"producing identity/tag heatmaps with the joint heatmaps.\" It's unclear *how* the adaptation was done and *how* the heatmaps were produced. Therefore, it's 2 as it identifies a change but lacks explicit and concrete actions.", "grounding_specificity_rationale": "The review refers to \"31\", indicating a specific prior work. The statement \"The paper is rather incremental with respect to 31\" identifies a weakness in relation to this specific prior work. The weakness is stated clearly \u2013 the current work is seen as a minor adaptation. The authors can easily infer that the weakness is in the lack of significant advancement over 31. Therefore, it's fully grounded as the specific prior work is mentioned. The weakness is also clearly specified as being \"incremental.\"", "verifiability_rationale": "The review point contains the claim \"The paper is rather incremental with respect to 31\". This is a statement of opinion or judgment about the paper's contribution in relation to a specific prior work. The review does not provide any specific evidence, examples, or references to support this claim. It's a general statement about the nature of the contribution. Therefore, it's 1 as it lacks supporting evidence.", "helpfulness_rationale": "The review point identifies a potential lack of novelty or significant advancement over a prior work. While it highlights a potential weakness, it doesn't offer concrete, actionable suggestions for improvement beyond \"adapt the existing architecture.\" The *method* of adaptation is missing. The feedback is somewhat negative and focuses on a potential limitation rather than offering clear guidance on how to improve the paper. Therefore, it's 2 as it doesn't provide specific steps for the authors to take. The authors don't get concrete steps to improve."}
{"actionability_label": "3. 3", "grounding_specificity_label": "2. 2", "verifiability_label": "3. 3", "helpfulness_label": "1. 1", "actionability_rationale": "The review point is 1 because the authors fail to explicitly explain how the \u03bb parameters are calculated. The reviewer is left to infer the process, which is a common issue in reviews lacking explicitness. The request 'How is \u03bb computed from step here?' highlights the missing explicit action. While the authors mention the sensitivity of performance and sample efficiency to \u03bb, they do not provide a clear, stepbystep explanation of the calculation process, leaving the reviewer without a concrete action to take.", "grounding_specificity_rationale": "The review point is 1 and Not Specific regarding the \u03bb calculation. The authors do not explicitly identify the specific part of the paper where the \u03bb calculation is discussed. The reviewer's confusion about the 'step here' where the calculation is mentioned suggests that the authors could not confidently determine which part of the paper they are referring to. While the general area of hyperparameters is mentioned, the exact location or method isn't clear.", "verifiability_rationale": "The review point is not Verifiable regarding the explanation of ELLA's sample efficiency. The authors explain why ELLA does not increase sample efficiency in a COMBO environment, but the reviewer states they don't quite understand what it means. This suggests that the explanation lacks sufficient justification or supporting evidence. The reviewer also mentions specific papers (1, 2, 3) which hints at the expectation for external references to clarify the concept. The lack of clarity makes it difficult to verify the claim or understand the reasoning behind it.", "helpfulness_rationale": "The review point is 1 regarding the \u03bb calculation and ELLA's sample efficiency. The lack of clarity in both areas makes the feedback 1 and potentially confusing for the authors. The reviewer's confusion about the \u03bb calculation and ELLA's sample efficiency makes the feedback unclear and potentially contradictory. Furthermore, the absence of relevant citations (as pointed out in the review) makes the feedback less robust and potentially misleading, significantly impacting its helpfulness."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer asks a question about the alternating direction method, which implies a lack of clarity or detail in its mention. While the reviewer's question prompts the author to seek more information, it doesn't directly instruct them on what to do or how to implement the method. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer mentions 'alternating direction method' and 'minmin problem' generally, without pinpointing a specific section, table, figure, or unique aspect of the paper. While the terms are relevant, they don't provide a precise location or a detailed explanation of the issue within that context. The grounding is present but not fully specific.", "verifiability_rationale": "The reviewer states a fact ('It is briefly mentioned...') and then poses a question. The question itself doesn't present a claim that requires verification using logical reasoning, common knowledge, or external references. It's a request for clarification rather than a statement that needs to be proven.", "helpfulness_rationale": "The review point is a question about a specific implementation detail. While it encourages the author to provide more information, it doesn't directly critique the writing, suggest improvements, or identify a problem that needs to be solved. It's a request for clarification, not a helpful feedback point in itself."}
{"actionability_label": "2", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies potential weaknesses in the lower bound double qlearning algorithm and observes performance trends in different environments. However, the suggestions are very general and do not specify *how* to address these issues. The reviewer doesn't provide concrete steps for the authors to take, such as specific parameter adjustments or algorithm modifications. The suggestions are more like observations than actionable improvements.", "grounding_specificity_rationale": "The reviewer mentions 'double qlearning' and specific environments (MsPacman, WizardOfWor, Zaxxon RoadRunner, BattleZone). This indicates a reasonable level of grounding as the reviewer is referring to specific algorithms and experimental settings. The mention of 'double qlearning' points to a specific implementation, and the environments are clearly identified. However, the reviewer could be more explicit about the *part* of the algorithm being discussed. For example, they could specify if they are referring to the target network or the update rule.", "verifiability_rationale": "The reviewer points out a 'slight performance decrease' and 'convergence into same solutions' without providing specific evidence or references. While the observations are noted, there's no logical reasoning or external references to support these claims. The reviewer doesn't explain *why* these convergence issues might be happening or how they relate to the algorithm's design. The suggestions are based on observations rather than a thorough analysis.", "helpfulness_rationale": "The reviewer raises concerns about the effectiveness and stability of the double qlearning algorithm. While these concerns are generally valid and could be helpful for the authors, the lack of specific suggestions and the reliance on observations rather than concrete evidence make the review less impactful. The reviewer doesn't provide clear directions on how to improve the algorithm or address the observed issues. The suggestions are more like questions or areas for further investigation rather than direct solutions."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation of using linear models for interpreting DNN predictions. While this points to a potential area for improvement, it doesn't explicitly suggest a concrete action or modification to the draft. The statement is more of an observation than a direct instruction for the author.", "grounding_specificity_rationale": "The reviewer makes a general statement about the limited novelty of using linear models for interpreting DNN predictions. They do not specify which part of the paper this relates to or provide any details about the specific linear models or DNNs being discussed. The comment is broad and lacks specificity.", "verifiability_rationale": "The reviewer's statement about the limited novelty of using linear models for interpreting DNN predictions is a claim. While this claim is generally accepted within the field (that linear interpretations are not a novel approach), there isn't strong external evidence or specific examples provided to definitively prove this point. The claim is somewhat broadly stated.", "helpfulness_rationale": "The reviewer's comment identifies a potential limitation in the approach used in the draft. While it doesn't offer a specific solution, it points out an area where the authors could improve their work. This kind of feedback can be helpful for guiding the authors towards better model interpretation techniques."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a problem: 'It is unclear for me why the performance of DNN+MMA becomes worse than vanilla DNN when lambda becomes small? See fig.34.' This directly points to a discrepancy the reviewer is observing. The reviewer then asks a specific question: 'I would expect it will approach vanilla methods from above but from below.' This indicates a clear and actionable issue the reviewer is trying to understand. The reviewer is directly asking for clarification on a specific experimental result.", "grounding_specificity_rationale": "The review point explicitly refers to 'fig.34' as the source of the information. This clearly grounds the comment to a specific part of the paper. Furthermore, the reviewer makes a specific claim about the *expected* behavior based on these figures: 'I would expect it will approach vanilla methods from above but from below.' This specificity indicates that the reviewer has a clear idea of what they are referring to and what they expect to see.", "verifiability_rationale": "The review point contains a claim: 'the performance of DNN+MMA becomes worse than vanilla DNN when lambda becomes small.' This is a statement that requires verification. The reviewer then provides evidence (fig.34) to support their observation. While the reviewer's expectation is based on a common understanding, the *observation* of the figures constitutes evidence. The claim is supported by logical reasoning (the figures) and potentially external references (the figures themselves).", "helpfulness_rationale": "The review point is highly specific and directly addresses a potential issue the authors might be facing. The reviewer clearly states what is *wrong* (performance degradation) and what they *expect* (improvement). This provides the authors with a clear direction to investigate the figures and potentially identify a problem in their experimental setup or implementation. The reviewer's expectation is reasonable, making this a potentially impactful observation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states 'The paper does not compare the results with some of the earlier research work from 2020.' This is an explicit statement of a missing comparison. However, the reviewer does not specify which earlier work from 2020 is being referred to, nor does he suggest any concrete actions for the authors to take regarding this missing comparison. Therefore, while the action is explicit, the lack of specificity makes it 3 but not fully actionable.", "grounding_specificity_rationale": "The reviewer states 'earlier research work from 2020' and specifically names 'Taghipour and Ng (2016)'. This clearly identifies the specific part of the paper being addressed, making the grounding fully grounded. The comment also specifies what is missing \u2013 the comparison to this specific work. Therefore, the grounding is explicit and identifies the relevant part of the paper and the issue.", "verifiability_rationale": "The reviewer makes a claim: 'The paper does not compare the results with some of the earlier research work from 2020.' The reviewer also states that the authors have explained their reasons for not doing so. This provides some level of support for the claim. However, the reviewer does not provide any examples or references to support the claim that the authors' reasons are sufficient or logical. Therefore, the claim is supported by the authors' explanation, making it 3.", "helpfulness_rationale": "The reviewer points out a missing comparison with earlier work, which is a valid point for improvement. However, the reviewer does not provide specific, actionable suggestions for the authors to make regarding this missing comparison. The reviewer's comment is more of a pointer to an area of improvement rather than a direct solution. Therefore, while the comment is helpful in identifying a weakness, it lacks the depth needed for full helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests using a paired test instead of an independent samples ttest. This is a clear and actionable improvement that directly addresses a potential flaw in the statistical analysis. The reviewer identifies the issue (comparing two samples generated from the same input) and proposes a specific methodological change. This action is concrete, as the reviewer clearly states the desired statistical test.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'significane testing' and suggests a change in the test used for significance testing. This demonstrates a clear identification of the specific issue (potential flaw in the statistical analysis) and a specific suggestion for improvement. The reviewer directly addresses the comparison between two samples generated from the same input, pinpointing the methodological concern. The suggestion is directly tied to the identified problem.", "verifiability_rationale": "The reviewer claims that the choice of test might be incorrect and suggests a paired test. While the reviewer doesn't provide a detailed explanation *within this review point* of why the independent test might be incorrect or why the paired test is better, their suggestion implies an understanding of the statistical principles involved. The reviewer is making a claim about the appropriateness of the test, and the suggestion to use a paired test is a logical consequence of the identified issue (samples from the same input).", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion to use a paired test instead of an independent samples ttest. This is a highly specific and actionable improvement that directly addresses a potential flaw in the statistical analysis. The reviewer identifies the issue and offers a concrete solution, making this a 5 comment for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the desired improvements (comprehensive and general experiments) and provides clear reasons (limited model size and restrictive baselines). The reviewer directly indicates what needs to be done, making it 5.", "grounding_specificity_rationale": "The review point discusses the need for more comprehensive experiments in the context of language modeling and image classification. While it mentions these areas, it doesn't specify a particular section, table, or figure within the paper. The grounding is at the level of the task type rather than a specific element, making it weakly grounded.", "verifiability_rationale": "The review point contains a claim that the experiments should be more comprehensive and general. This claim is supported by the reviewer's reasoning that the current model size is limited and the baselines are restrictive. While the authors can infer these limitations themselves, the reviewer's point is based on an assessment of the existing work, making it 3.", "helpfulness_rationale": "The review point is 5 because it clearly identifies areas for improvement (comprehensiveness, generalization, model size, baselines) and provides a rationale for these suggestions. The reviewer guides the authors in enhancing their work with specific, actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential misunderstanding or misapplication of Hoeffding's inequality in the paper's analysis. They explicitly state that the inequality holds true as long as the samples are drawn independently and that stochastic algorithms further guarantee this. This is an explicit statement that suggests a potential issue with the paper's claim about the conditions for Hoeffding's inequality. While the reviewer doesn't provide a specific section or table, the topic itself is related to the paper's methodology, making it 3.", "grounding_specificity_rationale": "The reviewer is discussing a general statistical principle (Hoeffding's inequality) in the context of a specific analysis in the paper. While the topic is relevant to the paper's methodology, the reviewer doesn't explicitly point to a specific section, table, or figure where this issue arises. The connection is implied but not clearly established, making it weakly grounded. However, the topic is directly related to the paper's content, so it can be considered somewhat specific.", "verifiability_rationale": "The reviewer makes a claim about the conditions under which Hoeffding's inequality holds, questioning the paper's assertion. They suggest that the inequality is always true under certain conditions and that stochastic algorithms further guarantee this. This is a claim that can be verified by examining the specific equation and the conditions under which Hoeffding's inequality is typically applied. While the reviewer doesn't provide a specific equation, the claim is verifiable based on the general principles of the inequality. Therefore, it is 3.", "helpfulness_rationale": "The reviewer's comment is directly relevant to the paper's methodology, specifically the application of Hoeffding's inequality. They point out a potential misunderstanding or a need for clarification regarding the conditions under which the inequality holds. This is a helpful comment because it identifies a potential weakness in the paper's analysis and suggests that the stochastic algorithms might offer a better understanding. The reviewer's point is clear and directly addresses a potential issue, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks if it is possible to add a metalearning approach to Table 1, specifically mentioning MAML/implicitMAML. This directly suggests a concrete action the authors could take, making it 5.", "grounding_specificity_rationale": "The review point directly refers to 'Table1', accurately identifying the specific part of the paper. While the 'why' isn't fully elaborated, the 'what' (adding a metalearning approach to this table) is clear, making it 3.", "verifiability_rationale": "The review point is a suggestion rather than a definitive claim. It proposes a possibility but doesn't provide evidence or references to support it, resulting in X.", "helpfulness_rationale": "The review point is very specific and suggests a concrete improvement by adding a metalearning approach to Table 1. While it's a suggestion and not a guarantee of success, it points towards a valuable direction for the authors, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an improvement (an ablation study) and provides a *potential* reason (prompt choice) for it. This suggests it's at least partially actionable. However, it could be more specific about *which* prompts to try and *why* the current prompt is insufficient.", "grounding_specificity_rationale": "The review point is very general. It doesn't specify *which* prompt is being referred to (fewshot, zeroshot, specific prompt details). It also doesn't pinpoint where in the paper this issue arises (e.g., introduction, method section). The reviewer can't confidently identify the specific part of the paper or the exact prompt being discussed.", "verifiability_rationale": "The reviewer point contains a claim: \"The paper lacks an ablation study explaining why they chose the prompt in this specific way\". This is a statement of opinion. However, the reviewer doesn't provide any justification for this claim. They don't explain *why* an ablation study is needed or *why* the prompt choice is questionable. They simply state the problem without supporting evidence.", "helpfulness_rationale": "The review point is relevant and encourages the authors to consider an improvement (an ablation study). However, the lack of specific details about the ablation study makes the suggestion somewhat vague and less immediately actionable. The reviewer doesn't tell the authors *exactly* what prompts to try or *how* to conduct the ablation study. They also don't explain *why* the current prompt is a problem."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment points out a potential misunderstanding or imprecision in the use of terminology. While it doesn't directly instruct the author on what to change, it highlights a specific area where clarification is needed. The reviewer is implicitly suggesting that the authors should be more careful about the distinction between causality and temporal relationships.", "grounding_specificity_rationale": "The comment explicitly mentions the specific concepts being discussed: 'causal mechanisms', 'causality', and 'temporal relationship'. It accurately identifies the section of the paper (page 1) where this discussion takes place. This demonstrates strong grounding as the author can easily pinpoint the relevant part of the paper.", "verifiability_rationale": "The comment itself does not contain a claim that can be verified. It is a suggestion for improvement rather than a statement that can be supported by evidence. While it implies a potential issue with the author's writing, it lacks the necessary elements of a verifiable claim, such as specific examples or references.", "helpfulness_rationale": "The comment is helpful in that it points out a potential area for improvement in the author's writing. It encourages the author to be more precise about the distinction between causality and temporal relationships. While it doesn't provide a solution, it highlights a valuable point that can lead to better clarity in the paper."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue: 'replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance' and provides a comparative statement: 'better than random is a strong demonstration of capability.' This is an explicit statement of a problem and a suggestion for improvement. While the exact location of the procedure step isn't specified, the type of procedure step and the outcome are clear, making it concrete.", "grounding_specificity_rationale": "The reviewer refers to 'procedure steps of XAIFOOLER,' which clearly identifies a part of the paper being discussed. This can be considered 'Full Grounding' as the concept is directly referenced. However, the reviewer doesn't specify a 'specific' procedure step, and they don't provide a 'specific example' of where the random mechanism might be implemented. This makes the grounding somewhat underspecific.", "verifiability_rationale": "The reviewer makes a claim: 'I'm unsure that 'better than random' is a strong demonstration of capability.' However, they do not provide any evidence or justification for this claim. The reasoning, common knowledge, or external references are missing, making the claim 1.", "helpfulness_rationale": "The reviewer points out a potential flaw in the methodology or implementation of the XAIFOOLER algorithm. They are suggesting that a simple random mechanism could potentially outperform a more complex procedure within XAIFOOLER, which raises concerns about the effectiveness or novelty of the proposed method. While the reviewer doesn't offer a direct solution, they highlight a weakness that needs addressing. This can be helpful for the authors to understand a limitation of their approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they would like a discussion of a specific paper and a specific concept within that paper. The action is to discuss the paper, and the implementation is to discuss the specific concept.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific paper \"On the Complexity of Learning with Kernels\" and the specific concept \"kernel learning using lowrank approximation\". This is strong grounding as the paper and concept are clearly identified. The specificity is high as the reviewer is not just saying \"related work\" but a very specific theoretical result.", "verifiability_rationale": "The reviewer makes a claim that the paper should discuss the specified related work. The verification comes from the fact that the paper does discuss kernel learning and lowrank approximations, making the suggestion relevant and plausible.", "helpfulness_rationale": "The reviewer directly points out a specific weakness in the paper: the lack of discussion of a relevant piece of work. The suggestion is actionable (add the discussion), wellgrounded (specific paper and concept), and verifiable (the paper covers the relevant area). This directly helps the authors improve their draft by guiding them to include this relevant theoretical context."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point primarily asks a question ('How well are the assumptions met?') rather than explicitly stating an action or instruction. While the reviewer is implicitly suggesting that the lack of clarity on PCA assumptions is a weakness, the point itself doesn't directly guide the author on how to address this weakness. The action is implied, not explicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'PCA to reduce interaction count' and refers to a specific paper (1) as relevant context. This demonstrates a clear grounding of the comment in the technical details of the paper and relevant external knowledge. The reviewer is directly addressing a potential issue related to a specific aspect of the paper.", "verifiability_rationale": "The reviewer poses a question about the assumptions of PCA, which requires the author to provide justification or evidence. While the reviewer doesn't explicitly state a claim, the request for clarification about assumptions implies a need for verification and justification. The potential for verification exists, but it's not currently presented with supporting evidence or references within the review point itself.", "helpfulness_rationale": "The reviewer explicitly states that the point is unclear to them ('How well are the assumptions met?') and requests clarification. This directly addresses a potential weakness for the author and provides a clear direction for improvement. The request for justification and connection to related work also has the potential to be very helpful. The information is presented in a way that directly addresses a potential lack of understanding."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the fewshot RC models considered are not stateoftheart and suggests a comparison with relation extraction/generation models. This is an explicit action that is concrete, as it clearly identifies the models and the suggested comparison. The reviewer proposes a specific analysis to be conducted.", "grounding_specificity_rationale": "The review point explicitly mentions 'fewshot RC models' and 'relation extraction/generation models in fewshot settings.' This clearly identifies the specific parts of the paper being referred to, indicating strong grounding. The reviewer names the model types and the experimental setup, making it easy to understand which aspects are being discussed.", "verifiability_rationale": "The review point contains a claim that 'the fewshot RC models considered in the paper are not stateoftheart models'. This claim is not 5 within the review point itself, as it relies on the reviewer's external knowledge of what constitutes stateoftheart models. However, the suggestion to 'how does the performance compare to relation extraction/generation models in fewshot settings' is a request for information rather than a claim requiring verification. The core of the claim is about the *absence* of SOTA models, which is a statement of opinion.", "helpfulness_rationale": "The review point identifies a potential limitation in the methodology (using nonSOTA models) and suggests a concrete improvement (comparative analysis with relation extraction models in a fewshot setting). This is a valuable and actionable suggestion that directly addresses a potential weakness and provides a clear direction for further investigation. It helps the authors understand the relative performance of their models compared to a relevant category of models."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action: 'the results in section 4 apply only to shallow fullyconnected ReLU networks.' It clearly indicates what needs to be addressed (section 4) and the limitations (shallow fullyconnected ReLU networks). This makes the action clear and actionable for the author.", "grounding_specificity_rationale": "The comment explicitly mentions 'section 4' and 'shallow fullyconnected ReLU networks,' precisely identifying the part of the paper being referred to. This is a clear and accurate grounding of the comment.", "verifiability_rationale": "The comment contains a claim: 'the results in section 4 apply only to shallow fullyconnected ReLU networks.' While it doesn't provide a justification for this limitation, it clearly states a factual constraint. This makes the claim 3 as it points to a verifiable limitation within the paper's content or structure.", "helpfulness_rationale": "The comment is 5 as it directly points out a potential issue the author might be facing \u2013 that the results in section 4 are limited to a specific type of network. This is a clear and actionable piece of feedback that guides the author to focus their edits on a specific section and network type."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the desired outcome (adding background and moving related work), making the action somewhat explicit. However, the reviewer doesn't provide details on *how* to achieve these actions, making it vague.", "grounding_specificity_rationale": "The reviewer mentions \"background knowledge\" and \"related literatures,\" but doesn't specify the exact section or element of the paper they are referring to. The comment is too general to be considered grounded.", "verifiability_rationale": "The reviewer states an opinion about the paper's organization but doesn't provide any evidence or justification for this claim. There's no explicit recommendation to *do* something that would be verifiable.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the paper's organization and suggests improvements, which is helpful. However, the suggestions are quite general and lack specific details on how to implement them, making them somewhat vague and potentially less impactful."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'compare with other panoptic segmentation models.' This is a clear instruction for the authors to take a specific step in their work. The suggestion to include 'PanopticFPN' and 'Mask2Former' provides concrete examples of models to compare with, making the action even more explicit. The authors know exactly what needs to be added to their paper.", "grounding_specificity_rationale": "The review point explicitly mentions 'PanopticFPN' and 'Mask2Former' as examples of other panoptic segmentation models. This is a strong example of grounding specificity, as the authors can directly identify the specific part of the paper being addressed (the 'other panoptic segmentation models') and the specific elements within it (the named models).", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion to include more comparisons. Therefore, it does not fit into the 'Claim Extraction' category. The 'Assess Verifiability' step would classify this as 'X'  X, as it does not present an opinion, judgment, or suggestion that needs to be supported.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the authors to improve their draft. By suggesting the inclusion of comparisons with other panoptic segmentation models, it directly points to a potential weakness or area for improvement in their current work. The specific mention of 'PanopticFPN' and 'Mask2Former' makes the suggestion concrete and provides a starting point for the authors to explore additional baselines. This level of detail and direction is highly beneficial for the authors in enhancing their research and experimental evaluation."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out a lack of results and asks about the observed outcomes of the MCB vs. MCT comparison. While this is a valid observation, the comment does not explicitly state what action the authors should take based on this missing information. The authors are not told to change anything or to add something specific. The comment is more of a request for clarification and further details rather than a direct instruction on how to improve the draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the discussion of using sequential MCB vs a single MCT layers for the decision head'. This clearly identifies a specific aspect of the paper being discussed. The comment also asks about the 'observed' results, indicating a desire to understand what happened in that specific comparison. Therefore, the reviewer's comment is fully grounded as it refers to a specific section and asks for information about a specific outcome.", "verifiability_rationale": "The reviewer states 'no results were shown' and asks about the 'observed' results. This is a statement of fact and a request for information. It does not contain a claim that can be verified through logical reasoning, common knowledge, or external references. The comment is a statement of a gap in the results, not a claim that needs verification.", "helpfulness_rationale": "The reviewer's comment is not directly helpful in improving the draft. They are pointing out a missing element (results) and asking for more information about a specific comparison. While this is a valid point for the authors to consider, it does not provide a concrete action or suggestion on how to improve the draft. The comment is more of a request for clarification and further details rather than a direct critique of a flaw or a suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies areas for improvement in language usage and suggests fixes. While the reviewer points out 'minor comments' on language, the act of identifying grammatical errors and suggesting improvements constitutes an action. The reviewer could be more specific about the desired changes, but the intention is clear. The reviewer also mentions 'sensitivity to other hyperparameters', which could be interpreted as an implicit action to ensure the model's performance is not affected by these parameters. However, the lack of concrete steps makes it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific instances where language usage could be improved, such as 'we typically considers'. This demonstrates a clear grounding of the comment in the specific parts of the paper being discussed. The reviewer also provides general suggestions for improvement related to these instances, indicating an understanding of what needs to be addressed.", "verifiability_rationale": "The reviewer makes claims about the language usage, such as 'language usage: minor'. They also provide specific examples of grammatical errors, like 'we typically considers'. The reviewer suggests improvements based on these examples, indicating that the claims are verifiable through logical reasoning and examples. The reviewer's suggestions are directly linked to the identified issues.", "helpfulness_rationale": "The reviewer provides a list of specific issues related to language usage and suggests concrete improvements. For example, they point out 'we typically considers' and suggest 'improve language clarity and precision'. This directly identifies problems and offers actionable steps, making the review 5 to the author. The reviewer also provides a general statement about the impact of these issues on the model's performance, further emphasizing the importance of addressing them."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a lack of clarity regarding the choice of 20 distribution sets and provides a clear action for the authors to take: 'What if you select only few number of distribution set?'. This directly addresses a potential ambiguity and guides the authors to investigate further.", "grounding_specificity_rationale": "The reviewer mentions the number '20' and suggests 'controlling the number of distribution sets'. This clearly identifies the specific aspect of the paper being referred to, making the grounding explicit. The suggestion to control the number is also a specific action.", "verifiability_rationale": "The reviewer is not making a claim that needs to be verified. They are asking for clarification on a specific parameter (the number of distribution sets). Therefore, it does not fall under the 'verifiability' aspect.", "helpfulness_rationale": "The reviewer's suggestion to control the number of distribution sets directly addresses a potential point of confusion for the authors. It provides a clear direction for further investigation and potential experimentation, making it a helpful suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a statement of opinion, not a direct instruction or suggestion. It doesn't provide clear actions for the authors to take based on the criticism. The reviewer expresses concern about the framework's limitations but doesn't specify what needs to be improved or how the authors should proceed.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or the framework that is affected by the criticism. It broadly criticizes the framework's scope without pinpointing the relevant sections or experiments.", "verifiability_rationale": "The review point contains a claim ('somewhat limited scope') but does not provide any evidence or reasoning to support this claim. It expresses a concern about the framework's potential generalization without backing it up with logical arguments or references.", "helpfulness_rationale": "The review point expresses reservations about the method's broader applicability but does not offer specific, actionable feedback or suggestions on how the authors' current draft could be improved based on this criticism. It's a concern about the framework itself, not about the current work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem of using obsolete models and suggests transformerbased models as a solution. This indicates an explicit action, but the lack of specific implementation details makes it less actionable.", "grounding_specificity_rationale": "The reviewer names specific models (ngram HMM, RNN) and suggests transformerbased models. This demonstrates a degree of grounding in the review itself by mentioning specific examples. However, the paper itself isn't explicitly criticized for not using these models, so it's not fully grounded in the paper's content.", "verifiability_rationale": "The reviewer makes a claim about the models being obsolete and suggests transformerbased models. While this claim could be verified by checking publication dates and current trends, the review point itself doesn't provide specific evidence to support this claim. Therefore, it's only 2.", "helpfulness_rationale": "The reviewer provides a clear and relevant suggestion to update the perplexity experiments using more current models. This is a helpful comment for the authors as it directly addresses a potential limitation and provides a concrete direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point is a statement of opinion ('The experiments are not sufficient') rather than a direct instruction or suggestion. It doesn't explicitly tell the authors what to do or how to improve their experiments. While it implicitly suggests that more experiments are needed, it doesn't pinpoint which experiments or how to conduct them. Therefore, it lacks explicit and concrete actionability.", "grounding_specificity_rationale": "The review point refers to 'the experiments' in general. It does not specify which part of the paper or experiments is being addressed. The reviewer does not identify a specific section, table, figure, or unique aspect of the paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses. While the reviewer mentions 'empirical experiments' and 'toy experiments,' these are not explicitly linked to a specific part of the paper being discussed in the review point itself.", "verifiability_rationale": "The review point contains a claim: 'The experiments are not sufficient.' The reviewer offers a suggestion: 'More empirical experiments or toy experiments (for the simplified selfattention model considered in the theoretical analysis) need to be done to show the validity of the model relaxations and the consistence of the theoretical analysis with empirical results, besides citing the result in Kaplan et al. 2020.' This provides a potential direction for improvement, acting as supporting evidence for the claim. However, the support is not fully detailed. While the suggestion is helpful, it doesn't provide specific examples of what kind of additional experiments would be beneficial, nor does it cite specific literature to back up this claim beyond Kaplan et al. 2020. Therefore, the claim is somewhat supported but lacks key elements like examples or references in its current form.", "helpfulness_rationale": "The review point identifies a weakness in the experiments ('the experiments are not sufficient') and offers a suggestion ('More empirical experiments or toy experiments... need to be done'). While the suggestion is helpful in general, it is broad and lacks specific details about what kind of additional experiments would address the identified weakness. The reviewer doesn't specify which aspects of the experiments are problematic or provide concrete steps for improvement. Therefore, while the point is relevant and offers a general direction, it lacks the specificity and actionable steps needed for the authors to fully benefit from it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the difficulty in estimating mu, which is a concrete piece of information. While they don't provide specific steps, the identification of the problem is actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'mu, but as it is the proportion of missing observations.' This directly identifies the specific parameter being discussed, indicating strong grounding. However, they do not specify *how* to estimate it, making the specificity low.", "verifiability_rationale": "The reviewer makes a claim that 'as it is the proportion of missing observations  it is not wholly clear how it can be estimated at all.' This is a claim about the lack of clarity. While they don't provide external references or logical reasoning to support this claim, the statement itself is verifiable as an observation about the situation.", "helpfulness_rationale": "The reviewer points out a significant issue (difficulty in estimating mu) but does not offer any suggestions or guidance on how to address it. While they identify a problem, they don't provide actionable steps for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer proposes a specific change to the experimental setup by varying the distance of initialization M^0 to the groundtruth M^*. They suggest using a parameter 'c' to control this distance, ranging from 0.01 to 0.1. This is an explicit action with concrete details on how to implement it. The reviewer clearly states the goal: to report performance as a function of this distance and expects that the mean error and variance will increase as the quality of initialization decreases. This provides a clear path for the experiment and directly addresses the sensitivity to initialization.", "grounding_specificity_rationale": "The reviewer explicitly defines the variable 'c' as the distance between the initialization matrix M^0 and the groundtruth matrix M^*. They also specify the range for 'c' as 0.01 to 0.1. This demonstrates strong grounding specificity as the authors can easily identify the section where the initialization is discussed and the unique element being varied (the distance 'c'). The language is precise and directly addresses a specific part of the paper.", "verifiability_rationale": "The reviewer provides a clear methodology for how the experiment could be conducted. They specify the metric (performance as a function of the distance 'c'), the range of 'c', and the expected outcome (increased mean error and variance with decreasing initialization quality). This is logically sound and provides a basis for empirical validation. The reasoning is clear, and the claim is wellsupported by the proposed methodology. The use of logical reasoning (expecting increased error and variance) and the provision of a clear experimental design contribute to verifiability.", "helpfulness_rationale": "The reviewer's suggestion to vary the distance of initialization is 5. It directly addresses the potential sensitivity of the model to initialization, a common issue in machine learning. By proposing a specific experiment to quantify this sensitivity, the reviewer provides a concrete and actionable step for the authors to take. This is a valuable contribution that could significantly improve the robustness and reliability of the results. The suggestion is clear, specific, and directly addresses a potential weakness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential simplification in the Frobenius norm definition, which could be considered an implicit action. However, it doesn't explicitly state how the absolute value can be removed or what the implications are for the definition. The action is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The comment explicitly mentions the Frobenius norm definition (line 77), making it fully grounded. It clearly identifies the issue with the definition (unnecessary absolute value for real numbers).", "verifiability_rationale": "The claim that the absolute value is unnecessary for realvalued tensors is generally verifiable. The reasoning is based on the fact that the Frobenius norm for real matrices is typically defined using the squared sum of elements, and taking the square root of the sum of squared elements inherently yields a nonnegative result, making the absolute value redundant. However, the comment doesn't provide specific examples or references to external works to support this claim.", "helpfulness_rationale": "The comment points out a minor detail in the Frobenius norm definition that could make it clearer or more efficient for realvalued tensors. It suggests a potential simplification. While the suggestion is valuable, the comment itself doesn't explicitly guide the author on the next step or how to implement the simplification. The helpfulness is moderate as it points out a potential improvement without providing immediate actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a limitation in the methodology (only expectation bounds) and suggests a potential solution (using ensemble methods). While it points out an actionable item (improving bounds), it doesn't explicitly state how to achieve this improvement. The suggestion to use ensemble methods is implicit, requiring the reviewer to connect it to their experience in the experiments. Therefore, while the action is implied, the explicitness and concreteness of the action are lacking.", "grounding_specificity_rationale": "The review point discusses a general limitation of the methodology (bounds) and suggests a potential improvement (ensemble methods). It doesn't explicitly refer to a specific part of the paper being addressed, nor does it detail what is wrong with the current bounds. The mention of 'expectation bounds' is general and doesn't pinpoint a specific issue within the paper's content. The suggestion of 'ensemble methods' is also general and doesn't specify which part of the paper would benefit from it. Therefore, the grounding of the issue and the proposed solution is weak.", "verifiability_rationale": "The review point identifies a limitation in the current methodology (only expectation bounds) and suggests a potential improvement (ensemble methods). While it provides a suggestion based on common knowledge (ensemble methods are used in experiments), it doesn't explicitly connect the use of ensemble methods to a specific gap in the current approach. The suggestion is somewhat general and doesn't provide a detailed explanation of *why* ensemble methods would lead to highprobability bounds in this specific context. Therefore, the claim is present, but the supporting evidence is somewhat lacking in detail and specificity.", "helpfulness_rationale": "The review point identifies a valid limitation in the current methodology (only expectation bounds) and offers a relevant suggestion (using ensemble methods, which are mentioned in the experiments). It highlights a potential area for improvement and provides a direction for future work. While it doesn't provide a direct solution or specific steps, it points towards a concrete and actionable improvement. The suggestion about robustness further adds value. Therefore, the review provides a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states their opinion about the results being 'less impressive' without specifying what needs to be improved or how to achieve it. While they imply a desire for more concrete feedback, the action is not explicitly stated. The reviewer suggests improvements but doesn't detail how to implement them.", "grounding_specificity_rationale": "The reviewer mentions 'more aspects' for evaluation, but they do not explicitly state which parts of the paper or results they are referring to. The grounding is weak because the specific area being addressed is not clearly identified.", "verifiability_rationale": "The reviewer's assessment of the results being 'less impressive' is a subjective opinion without any supporting evidence or justification. The claim is not verifiable based on the information provided.", "helpfulness_rationale": "The reviewer's comment is primarily an opinion about the results and a suggestion for improvement, rather than a constructive critique with actionable feedback. The helpfulness is limited as the comment does not provide clear guidance or identify specific weaknesses in the work itself."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'there is no diversity' and implies the model *should* enforce it. This is a clear, actionable piece of feedback. The reviewer *knows* what they want (explicit diversity enforcement) and *knows* what is currently present (lack of explicit diversity). The vagueness lies in *how* they want it enforced (e.g., specific mechanisms, regularization terms).", "grounding_specificity_rationale": "The reviewer mentions the title contains 'diversity' and the paper 'motivates' diversity extensively. While they don't point to a specific section or table, they clearly identify the *concept* being overemphasized without explicit implementation. This shows grounding at the *conceptual* level.", "verifiability_rationale": "The reviewer states 'My biggest concern with this paper is the fact that it motivates diversity extensively (even the word diversity is in the title)'. This is a statement of concern and a factual observation about the paper's content. It's a claim about the paper's *presentation* and *motivation*. The reviewer *doesn't* provide external references or logical reasoning *within this review point* to *prove* the model doesn't enforce diversity. The support comes from the reviewer's own analysis of the paper.", "helpfulness_rationale": "The reviewer clearly identifies a significant concern (lack of explicit diversity) and points to the paper's emphasis on it. This highlights a potential disconnect between the paper's stated goals and its implementation. While the *how* is vague, the *what* and *why* are clear. This is a valuable piece of feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a weakness ('some experiments are missing') but does not specify what needs to be added or how to improve the draft based on this information. It's a statement of what is lacking, not what to do about it.", "grounding_specificity_rationale": "The comment mentions 'experiments' in general and then provides examples of missing experiments. While it hints at the type of experiments missing, it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper where these experiments are supposed to be. The examples are general, not specific to a particular part of the paper.", "verifiability_rationale": "The comment states a fact ('some experiments are missing') and provides examples. It doesn't make a claim that requires verification or justification. It's a descriptive statement about the current state of the experiments.", "helpfulness_rationale": "The comment identifies a valid point for improvement (the lack of certain types of experiments). However, it doesn't offer concrete suggestions or explain why these experiments are important or missing. It's a diagnosis of a lack, but lacks a prescription for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weaklyly Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an improvement to the bounds but doesn't explicitly state what needs to be done. While it implies an 'independent improvement,' it lacks specific actionable steps.", "grounding_specificity_rationale": "The review point mentions 'graphs' and 'results' but doesn't specify which part of the paper or methodology is affected. The suggestion of using the 'independence number' is general and lacks a clear reference to a specific section or detail.", "verifiability_rationale": "The review points out a discrepancy between bounds and suggests an 'independent improvement.' While it implies a potential issue, it doesn't provide a clear justification or evidence for why the independence number might be a better bound. The reasoning is present but lacks depth and specific references.", "helpfulness_rationale": "The review points out a significant discrepancy between theoretical bounds and suggests an alternative approach (using the independence number). This implies a clear action: investigate the independence number and potentially adjust the bounds. While the justification isn't fully developed, the suggestion of a concrete improvement makes it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states they 'recommend using DinoV2 Frechet Distances' as an alternative to FIDs, which is a direct action. However, the reviewer does not provide specific steps on how to implement this change or what modifications are needed. The action is stated, but the concrete steps are missing.", "grounding_specificity_rationale": "The reviewer clearly identifies 'FIDs' as the problematic metric and suggests an alternative ('DinoV2 Frechet Distances'). They also implicitly refer to the 'Inception network' as the tool associated with the criticized metric. This strong identification of the specific part of the paper and the proposed solution indicates high grounding specificity.", "verifiability_rationale": "The reviewer states that there are 'clear flaws' associated with FIDs and the Inception network, but they do not elaborate on these flaws within the review point itself. They recommend DinoV2 but do not provide any logical reasoning, examples, or references to support the claim that DinoV2 is a superior alternative in this context. The claim is made without sufficient justification based on the information provided in this review point.", "helpfulness_rationale": "The reviewer clearly identifies a problem with a widely used metric (FIDs) and provides a direct recommendation for improvement by suggesting an alternative (DinoV2 Frechet Distances). This is a valuable piece of feedback that directly addresses a common issue. The reviewer's suggestion is actionable and directly points to a potential solution, making it 5 for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their concern about the novelty of the work and asks for a comparison to a specific paper. This is an explicit action to identify a potential weakness. The reviewer also mentions the methodology, which makes the action concrete as they identify the area of comparison and the nature of the difference.", "grounding_specificity_rationale": "The reviewer directly names the paper they are comparing to, which is a literal mention of a section or paper. They also clearly states the nature of the comparison (novelty, similar methodology, new task). This makes the grounding 5.", "verifiability_rationale": "The reviewer makes a claim about the novelty of their work relative to another paper. They also ask for a comparison, which is a request for external reference. This claim is verifiable as it points to a specific paper and a specific comparison.", "helpfulness_rationale": "The reviewer's question directly addresses a potential concern for the authors regarding the novelty of their work. By providing a specific paper for comparison, they are offering a concrete point of reference and potentially highlighting a gap in their contribution. This directly helps the authors understand the context of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a problem: 'In the reported ablation studies in Table 2, for CUB and SOP datasets, the complete loss function performed even worse than those with some terms missing. That does not appear to make sense.' They also indicate what they expect: 'Why?' This is a clear and direct action taken on the part of the reviewer. The reviewer is asking for clarification on a specific experimental result.", "grounding_specificity_rationale": "The reviewer directly references 'Table 2', 'CUB dataset', and 'SOP dataset' in their review point. This is a very explicit grounding of the comment to the specific document and the specific datasets and columns being discussed. They also specify the columns being compared ('complete loss function' vs. 'some terms missing'). This is highly specific.", "verifiability_rationale": "The reviewer makes a claim: 'In the reported ablation studies in Table 2, for CUB and SOP datasets, the complete loss function performed even worse than those with some terms missing. That does not appear to make sense.' This is a verifiable claim. However, the reviewer does not provide any explanation or reasoning *within the review point itself* to support why this might be the case. The expectation is that the original paper or the authors should be able to explain this discrepancy. The lack of internal explanation makes it 3 but not fully so.", "helpfulness_rationale": "The reviewer identifies a clear issue: a discrepancy in the experimental results presented in Table 2. They explicitly state what they find 'not to make sense' and ask for an explanation ('Why?'). This is a 5 and constructive suggestion for improving the clarity and understanding of the experimental findings."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a clear and explicit suggestion for improvement by proposing specific experiments to address potential limitations in the model. The suggestion is concrete, detailing the type of experiments (occluded image, keypoint detection failure simulation, longrange inference inspection) and their intended purpose. The reviewer directly states the action of running these experiments and their expected outcomes, making it actionable for the authors. The request is very direct and prescriptive about what the authors should do.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific aspects of the model they are targeting with their suggestions. They state that the experiments will 'simulate the irregularity that is often present in neural/behavioral data' and 'allow us to inspect the longrange \u201cinference\u201d capacity of the model'. This demonstrates strong grounding specificity as the reviewer not only identifies the *type* of experiment but also the *specific problem* they aim to address within the model. The reviewer also mentions 'keypoint detection failed for some mice in some frames' which is a very specific detail. The suggestion directly addresses specific limitations or areas for improvement in the model's performance.", "verifiability_rationale": "The reviewer presents a claim that the model's performance might be affected by irregularities in the data and that the longrange inference capacity needs to be assessed. The reviewer provides a logical reasoning for this claim by stating that 'irregularity that is often present in neural/behavioral data' could indeed affect the model's performance and that 'inspecting the longrange \u201cinference\u201d capacity of the model' would allow for a better understanding of these limitations. The reviewer also provides a practical example of how this could be tested by simulating keypoint detection failures. The claim is wellsupported by logical reasoning and a clear purpose for the suggested experiments.", "helpfulness_rationale": "The reviewer provides a clear and helpful suggestion for improvement. They explicitly state the *type* of experiments they believe would be beneficial and provide a *reason* for this suggestion based on common challenges in neural/behavioral data and model analysis. The reviewer's request is not just a suggestion; it's a welljustified and practical recommendation for the authors to improve their model. The suggestion is actionable, specific, and directly addresses potential limitations."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"I think figure 6C is a bit awkward\" and suggests an action \"I would suggest using a second yaxis or another visualization\". This indicates a clear and actionable improvement the authors should consider.", "grounding_specificity_rationale": "The reviewer directly identifies \"figure 6C\" as the problematic element and provides a specific suggestion \"use a second yaxis\". This demonstrates a clear and specific reference to the relevant part of the paper and the proposed improvement.", "verifiability_rationale": "The reviewer makes a claim about the visualization being \"awkward\" and suggests a \"change\". This claim can be supported by the visual representation of the data, and the suggestion to use a second yaxis is a common and logical solution to avoid misinterpreting negative rates. While not explicitly citing external work, the reasoning is based on standard data visualization practices.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for improving the visualization of figure 6C. The suggestion to use a second yaxis is a direct and actionable step that would likely enhance the clarity and accuracy of the representation. This is a valuable and constructive feedback for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "High", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states they do not understand the technical terms in the abstract and asks for clarification. This clearly indicates an explicit action that needs to be taken to understand the meaning of the statement. The request for clarification is also concrete, specifying that the terms are unclear.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific part of the abstract as being unclear. They make a general statement about the abstract being unclear due to technicalities. Therefore, the grounding is weak as the authors cannot confidently pinpoint the problematic section.", "verifiability_rationale": "The reviewer makes a claim that the abstract is unclear and contains technicalities. They also suggest making it highlevel, which can be seen as a form of justification. However, the support for this claim within this review point is limited to the statement itself and the request for clarification, without providing specific examples or references.", "helpfulness_rationale": "The reviewer's request for clarification directly addresses a perceived weakness in the abstract. Their suggestion to make it highlevel is a concrete improvement idea. While the review point itself doesn't provide external references, it clearly identifies an area for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential area for improvement (complexity of Algorithm 2) but does not specify how or what aspects need improvement. It is implicit, making it difficult for the author to take a concrete action.", "grounding_specificity_rationale": "The review point explicitly mentions 'Algorithm 2' but does not specify which part of the algorithm or what specific issue within it needs improvement. This makes the grounding weak.", "verifiability_rationale": "The review point does not contain a claim, making it 1.", "helpfulness_rationale": "The review point is a general suggestion and lacks specific details on how to improve the complexity of Algorithm 2. While it points to a valid area, the lack of actionability makes it less helpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests exploring other modalities, but it doesn't specify *which* modalities, *how* to explore them, or *why* this would be beneficial. It's a vague suggestion. (1)", "grounding_specificity_rationale": "The review point is a general suggestion about the type of results the authors should present, not about any specific part of the paper. It doesn't identify a specific section, table, figure, or unique aspect of the paper. (1)", "verifiability_rationale": "The review point is a suggestion, not a declarative statement requiring evidence. Therefore, it doesn't fit the verifiability scale. (X)", "helpfulness_rationale": "The suggestion is relevant to the field (exploring different modalities) and could potentially broaden the authors' understanding and impact. However, it's vague and doesn't provide immediate actionable steps. (3)"}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the shortcomings of the paper: 'The proposed method does not consider how to effectively use \"fewshot\"' and 'how to guarantee the trained model can be generalized well to new tasks with 0/few training steps.' These are direct and actionable criticisms.", "grounding_specificity_rationale": "The reviewer identifies the specific areas where the paper is lacking ('how to effectively use \"fewshot\"' and 'how to guarantee the trained model can be generalized well'). However, they do not explicitly state which part of the paper (e.g., the introduction, methodology, experiments) contains this deficiency. The reviewer refers to the 'entire paper' and 'this paper' generally.", "verifiability_rationale": "The reviewer makes a claim that the paper 'does not consider how to effectively use \"fewshot\"' and 'does not explain how to guarantee the trained model can be generalized well to new tasks with 0/few training steps.' However, the reviewer does not provide any evidence, reasoning, or references to support this claim. They simply state the absence of these elements without explaining why or providing examples from the paper.", "helpfulness_rationale": "The reviewer provides a clear and actionable criticism of the paper. They point out a specific area where the paper is lacking and suggest what the authors should do to address it. This is a valuable piece of feedback for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential area for improvement by suggesting using more sophisticated GP models. However, it lacks specific instructions on how to implement this improvement, making it 3 but not fully actionable.", "grounding_specificity_rationale": "The comment makes a general statement about the GP usage being 'naive' and mentions 'dynamical modeling' and 'Gaussian Process Dynamical Model' in general terms, without specifying which part of the paper or method it's referring to.", "verifiability_rationale": "The comment contains a claim that the GP usage is 'naive' and implicitly suggests it's lacking sophistication by mentioning 'Gaussian Process Dynamical Model'. However, it lacks explicit examples or detailed reasoning within the review point itself to support this claim.", "helpfulness_rationale": "The comment identifies a potential weakness in the GP usage. However, it doesn't provide specific, actionable steps or suggestions on how the author can improve their GP implementation, making it 3 but not fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their disagreement with a specific claim in the appendix (D.4) about the necessity of smaller architectures for language models (LMs) compared to GANs to avoid overfitting. This constitutes an explicit action that the authors should take. While the reviewer doesn't provide a direct solution, they identify a potential area for improvement, making it 3.", "grounding_specificity_rationale": "The reviewer directly references section D.4 of the appendix, indicating a clear understanding of where the issue lies. They also provide a specific example (Zaremba et al. 2014) to support their claim that the baseline models might not be properly regularized. Furthermore, they pose a specific question about the regularization technique (dropout on hidden states), which clearly identifies the area needing attention. This strong grounding and specificity make it '5'.", "verifiability_rationale": "The reviewer makes a claim that the statement in the appendix is questionable and provides evidence (the counterexample of Zaremba et al. 2014) to support their interpretation. They also ask a specific question about the regularization technique, which is a request for clarification and further verification. This claim is wellsupported, making it '5'.", "helpfulness_rationale": "The reviewer directly addresses a potential issue in the appendix (D.4) regarding the necessity of smaller architectures for language models (LMs) compared to GANs to avoid overfitting. They provide a counterexample and a specific question about the regularization technique, which is a valuable contribution. This comment is clear, specific, and directly addresses a potential implementation detail, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that 'some of the ablations mentioned in previous sections are hard to locate' and 'the writing can be improved in this part'. While the reviewer points out a potential issue, they do not explicitly state which ablations are difficult to find or provide specific actions to take. The suggestions are general and lack concrete details. Therefore, the review point lacks explicit and actionable suggestions.", "grounding_specificity_rationale": "The reviewer states that 'some of the ablations mentioned in previous sections are hard to locate'. This indicates a lack of explicit grounding, as the reviewer does not specify which sections or parts of the paper contain the ablations. The suggestion 'the writing can be improved' is vague and does not pinpoint a specific aspect that needs improvement. Therefore, the review point is 1 at all.", "verifiability_rationale": "The reviewer states that 'some of the ablations mentioned in previous sections are hard to locate' and 'the writing can be improved in this part'. These statements are criticisms or suggestions, not claims that require verification. There is no assertion that something is wrong that needs evidence to support it. Therefore, the review point does not contain a claim that needs verifiability.", "helpfulness_rationale": "The reviewer states that 'some of the ablations mentioned in previous sections are hard to locate' and 'the writing can be improved in this part'. These are negative assessments of the information in the previous sections. While identifying areas for improvement is generally helpful, the lack of specific grounding and the vagueness of the suggestions make the feedback less actionable and less useful. Therefore, the review point is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests the authors should 'think more clearly' about the differential privacy application. While this is a general suggestion and not explicitly stated as an action to be taken, it implies a specific area for improvement. The reviewer provides a specific area ('differential privacy application') and a specific issue ('halfbaked'), making the suggestion quite concrete. However, the action is implicit, and the reviewer doesn't specify *how* the authors should think more clearly.", "grounding_specificity_rationale": "The reviewer refers to '2)5)' in their review. This is unclear and does not point to a specific section, table, figure, or unique aspect of the paper. While the *general* area is the differential privacy application, the specific reference is ambiguous. Therefore, the grounding is weak. Furthermore, even if the general area is considered grounded, the specific issue within the DP application is not clearly defined, making the specificity underspecific.", "verifiability_rationale": "The reviewer makes a judgment that the differential privacy application is 'a bit too 'halfbaked''. This constitutes a claim that something is lacking in quality or development. However, the reviewer does not provide any specific examples, citations, or logical reasoning to support this claim. The statement is based on an opinion rather than verifiable evidence. Therefore, the claim is 1.", "helpfulness_rationale": "The review point suggests the authors should 'think more clearly' about the differential privacy application. While this is a helpful direction for improvement, the lack of specific guidance makes it less actionable. The reviewer does not provide concrete steps the authors should take to improve their thinking. The statement is subjective and lacks specific examples or logical reasoning. Therefore, the review point is 3 as it points to a potential area for improvement, but it lacks the necessary specificity and justification to be fully helpful."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement compares two existing approaches, multilingual chainofthought and villa chainofthought, but it doesn't explicitly tell the authors what to do or how to improve their work based on this comparison. It raises a question about the relative contribution of each approach.", "grounding_specificity_rationale": "The comment explicitly mentions 'multilingual chainofthought' and 'villa chainofthought', clearly identifying the specific parts being discussed. It also specifies the comparison being made between the two approaches.", "verifiability_rationale": "The statement presents a claim about the 'incremental contribution' of one approach compared to another. However, it does not provide any evidence, examples, or references to support this claim within the review point itself. It is a statement of opinion without justification.", "helpfulness_rationale": "The comment raises a valid point about the relative impact of different approaches to chainofthought reasoning. It highlights a potential area for further investigation or discussion. While it doesn't directly tell the authors how to improve their specific work, it does point to a relevant difference between two existing methods, making it 3 in identifying a potential area for improvement or further research."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment suggests a more specific type of manipulation ('bimanual manipulation') but does not explicitly state what action the authors should take based on this suggestion. The reviewer implies that the current use of 'robotic manipulation' is too broad, but does not provide a concrete next step for the authors.", "grounding_specificity_rationale": "The comment criticizes the use of the general term 'robotic manipulation' without identifying a specific part of the paper or methodology that is problematic. The reviewer suggests 'bimanual manipulation' as a more precise term, but does not specify why the current approach is inadequate or what needs to be changed. The grounding is weak because the authors cannot confidently determine the exact area of concern.", "verifiability_rationale": "The comment is a critique of the generality of 'robotic manipulation' without providing any external references or logical reasoning to support this claim. It does not present a claim that can be verified. Therefore, it is classified as 'X' (X).", "helpfulness_rationale": "The comment is a critique of the term 'robotic manipulation' and suggests a more specific alternative ('bimanual manipulation') without providing a clear or actionable recommendation for the authors. It is a negative comment that does not offer concrete steps for improvement. Therefore, it is not very helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests providing METEOR results. While this is a clear action, it lacks specific guidance on how the authors should implement this change. The reviewer doesn't specify adding a new section, moving existing data, or creating a new table. The action is to provide the results, but the method of providing them is not defined.", "grounding_specificity_rationale": "The reviewer suggests providing METEOR results, which is a general suggestion about reporting a metric. The reviewer does not specify *where* in the paper the METEOR results should be provided (e.g., as a new section, table, or figure). Additionally, the reviewer does not specify *what* is wrong with the current results or how the METEOR results should be interpreted or discussed. The comment identifies a part of the paper (the paper) that needs improvement (providing METEOR results) but lacks specifics on the implementation.", "verifiability_rationale": "The reviewer makes a suggestion: 'you should provide the METEOR results, which is also reported in recent works 15.' This constitutes a claim that METEOR results are relevant and beneficial. The reviewer provides a justification by referencing recent works, which serves as supporting evidence for the claim. The reference to recent works provides a logical reasoning for why METEOR results might be useful.", "helpfulness_rationale": "The reviewer suggests providing METEOR results. While this is a standard practice in some fields and the reviewer provides a reference to support its relevance, the suggestion itself doesn't directly improve the authors' draft. The reviewer doesn't specify *how* the METEOR results should be presented or how they should address any specific issues in the authors' work. The suggestion is more about improving the evaluation process than directly addressing the authors' manuscript."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem of 'comparability of Geffect values across various unlearning objectives and approaches' and highlights its potential impact on the 'generalizability of conclusions'. This is a clear and actionable point, as it directly identifies a limitation in the experimental design and its implications for interpreting the results. The reviewer also implicitly suggests that this isolation might not reflect the true interactions between unlearning objectives, making the comparison potentially misleading. This provides a concrete direction for the authors to consider when interpreting their results and potentially designing future experiments.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 4' and the specific issue of 'comparability of Geffect values across various unlearning objectives and approaches'. This direct reference to a specific section and a precise description of the problem demonstrates high grounding specificity. The reviewer accurately identifies the location of the concern and the nature of the comparison being questioned. This level of detail allows the authors to directly address the specific area of the paper being criticized.", "verifiability_rationale": "The reviewer raises a concern about the 'comparability of Geffect values across various unlearning objectives and approaches' but does not provide specific examples or references to external work to support this claim within this review point. While the concern is valid and points to a potential methodological limitation, the claim itself is not 5 based solely on the information provided in this review point. The reviewer does not offer any logical reasoning or external references to back up this assertion. Therefore, it is classified as '3' as it points to a potential issue that needs further investigation, but the claim itself lacks strong supporting evidence within this review.", "helpfulness_rationale": "The reviewer raises a valid point about the potential limitations of studying Geffects of each unlearning objective in isolation. This is a helpful comment as it highlights a potential methodological consideration that could affect the interpretation of the results and the generalizability of the conclusions. By pointing out this limitation, the reviewer encourages the authors to consider the interactions between unlearning objectives and whether the isolated effects accurately represent the overall system. This feedback is valuable for improving the authors' understanding and the robustness of their findings."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the UNIFORM method does not always offer a clear advantage, particularly in the 1shot setting. They identify the inconsistency in the results as a weakness. The action is directly stated, and the specifics of the 1shot setting and the UNIFORM method are mentioned, indicating a clear intention to apply the comment.", "grounding_specificity_rationale": "The reviewer specifically mentions 'UNIFORM' and '1shot setting' when pointing out the inconsistency. This direct identification of the method and the experimental condition demonstrates a strong grounding in the relevant part of the paper. The comment clearly specifies the area of concern.", "verifiability_rationale": "The reviewer makes a claim that 'the results in the tables show that UNIFORM does not always offer a clear advantage over the results, especially in the 1shot setting.' This is a direct statement of a finding. The reviewer also states that the results are 'clear,' which provides some level of justification for their claim. However, they do not provide external references or detailed explanations to support this observation.", "helpfulness_rationale": "The reviewer identifies a weakness in the results (UNIFORM's inconsistency in the 1shot setting) and asks for a potential explanation. While they acknowledge the clarity and design of the experiments, their focus is on a specific result. They do not offer a concrete solution or actionable steps for the authors beyond asking a question. The criticism is specific, but it lacks a direct proposal for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the reason why information value is a stronger predictor for dialogue, which is the complementarity discussed in the paper. This is an explicit action suggesting the authors should investigate this further.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Complementarity' (page 7) or 'discussion' (page 8) as the context for the claim about information value. This demonstrates strong grounding as the specific section or aspect is identified.", "verifiability_rationale": "The reviewer makes a claim about the relationship between information value and the strength of predictors for dialogue. While the review point itself doesn't provide direct evidence or citations, the implication is that further investigation and analysis are needed to verify this claim, making it 3 in principle.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors: they should explore the link between information value and the complementarity discussed in the paper. This is a helpful direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a desire for more discussion on the implications of AutoML findings for future architecture design. While the reviewer criticizes the *lack* of this discussion, the review point itself doesn't offer concrete *actions* or *suggestions* on how to address this deficiency. The reviewer points out a *need* but doesn't provide specific steps or guidance within the review point.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly tied to a specific section or table of the paper. While the reviewer mentions 'AutoML approaches' and 'design of new network architectures,' these are general areas rather than specific elements within the paper. The reviewer's statement is a general criticism of the paper's content, rather than a precise identification of a particular finding or section that needs improvement. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer's comment is a critique of the paper's content, specifically the lack of discussion on AutoML implications. This is not a claim that can be verified through logical reasoning, common knowledge, or external references. The reviewer is stating an opinion about the paper's shortcomings, not presenting a statement that requires justification. Therefore, the verifiability is low as there is X to be supported.", "helpfulness_rationale": "The reviewer clearly identifies a gap in the paper regarding the discussion of AutoML and its potential for future architecture design. This is a valuable piece of feedback that highlights a specific area for improvement. However, the reviewer does not provide specific *actions* or *suggestions* on how to address this deficiency. While the feedback is relevant, the lack of concrete guidance makes it less helpful than a review that offers specific improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for the main part to be more concise and the introduction to be more concise. However, they do not specify *which* parts of the main or introduction need to be concise. While the action of making something concise is implied, the lack of specific details makes it not fully actionable. The reviewer also suggests including empirical results but doesn't specify *which* empirical results are needed, further reducing actionability. The suggestions are present but lack concrete details on how to achieve them.", "grounding_specificity_rationale": "The reviewer refers to the 'main part' and the 'introduction part' of the paper. While they don't provide specific section numbers or table references, they clearly identify the *location* where improvements are needed. This indicates a degree of grounding. However, the reviewer does not specify *what* is wrong with the introduction or the specific aspects of the main part that need improvement. Therefore, while the grounding is present, it is not fully specific.", "verifiability_rationale": "The reviewer makes a claim that the introduction is wordy and that empirical results are needed. However, they do not provide any logical reasoning, examples, or external references to support these claims. The suggestion to include empirical results is presented as a general idea without specifying *which* results are missing or *why* they are necessary. Therefore, the claim is not wellsupported, making it 1.", "helpfulness_rationale": "The reviewer provides a comment that identifies areas for improvement, specifically suggesting conciseness in the introduction and the inclusion of empirical results. While these are valid points, the lack of specificity makes it difficult for the author to directly implement the suggestions. The reviewer does not provide any concrete examples of how to make the introduction more concise or what specific empirical results would be beneficial. This vagueness reduces the helpfulness of the comment as it doesn't provide actionable guidance."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification and an explanation regarding the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score. While the action of clarifying and explaining is implied, the reviewer does not explicitly state what the authors should do with this information. The request for an explanation of *why* these adjustments are effective is also not explicitly stated. Therefore, the action is implicit and the explanation is not explicitly provided.", "grounding_specificity_rationale": "The review point refers to 'Figure 3' and 'Frequency Stability score' without explicitly stating which part of the paper these elements correspond to. While the topic is relevant to the paper's content, the connection to a specific section, table, or unique aspect is not clearly established. The reviewer implies a reference to Figure 3, but does not specify which part of that figure or table is being discussed. The reference to 'Frequency Stability score' is also 1 in the paper itself.", "verifiability_rationale": "The review point contains a claim that the adjustments to the amplitudes are effective in enhancing model performance. However, the reasoning or evidence supporting this claim is not provided within the review point itself. The reviewer states the effectiveness of the adjustments but does not logically explain *why* they are effective or provide references to support this claim.", "helpfulness_rationale": "The review point asks for clarification and an explanation regarding the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score. This directly relates to understanding the empirical analysis and improving the model's performance. While the reviewer does not explicitly state what the authors should do, the request for clarification and explanation is a clear indication of a helpful suggestion for the authors. The reviewer also points out a formatting issue, which is a clear observation about a problem."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the lack of comparison with CoCoOp and suggests a necessary comparison. The action is directly identified: 'compare with CoCoOp'. This is a clear and actionable suggestion.", "grounding_specificity_rationale": "The review point explicitly mentions 'CoCoOp' by name. This provides full grounding as the specific work is identified. The specificity is also clear as the comment suggests a comparison, which is a concrete action to be taken.", "verifiability_rationale": "The review point contains a claim: 'It is necessary to compare with CoCoOp'. However, it does not provide any specific justification or evidence for this claim. While the reviewer believes it's necessary, it's not logically deduced or supported by external references within the review point itself.", "helpfulness_rationale": "The review point is clear, concise, and directly identifies a relevant gap in the comparison with a recent related work. The suggestion to compare with CoCoOp is actionable and would likely be helpful for the authors to contextualize their work. The reviewer provides a specific, concrete suggestion without unnecessary ambiguity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'Fig. 1 can also be drawn better', which is a direct instruction for the authors to improve the figure. While the specific details of the improvement are not given, the action is clear: enhance the drawing of Figure 1. The reviewer is not asking for clarification but rather a specific action to be taken.", "grounding_specificity_rationale": "The comment explicitly mentions 'Fig. 1', which is a specific part of the paper. The reviewer is not making a general comment about the entire paper but specifically about Figure 1. Furthermore, the comment clearly states what the reviewer desires: 'drawn better', which is a specific instruction regarding the aspect of the figure being drawn.", "verifiability_rationale": "The comment contains a claim: 'Fig. 1 can also be drawn better'. However, it does not provide any specific examples, references, or logical reasoning to support this claim. The suggestion is based on the current state of the figure and the reviewer's perception of its quality. There is no justification for why the figure needs improvement or what specific aspects should be changed.", "helpfulness_rationale": "The comment directly points to a potential weakness in the paper, which is the quality of Figure 1. The reviewer suggests a concrete improvement: 'drawn better'. This provides a clear direction for the authors to focus on enhancing the visual representation of the processing pipeline described in Figure 1. While the suggestion is general, it is directly related to improving the paper's presentation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitation of using 'two typical games' and suggests testing on 'more complex problems, especially those with larger depth...'. This is an explicit action. While the reviewer doesn't specify the exact 'how' to implement this suggestion, the 'action' is clear.", "grounding_specificity_rationale": "The reviewer mentions 'ReBeL's performance' and 'value and policy function', which are specific aspects of the model. However, they don't pinpoint a specific section, table, or figure. The grounding is to the overall experimental setup and its limitations.", "verifiability_rationale": "The reviewer makes a judgment about the 'limited scope' of the experiments and its potential impact on 'generalizability'. This is a claim requiring justification. However, the reviewer doesn't provide specific examples, citations, or logical reasoning to support this claim. The statement is presented as a suggestion for improvement rather than a claim requiring immediate verification.", "helpfulness_rationale": "The reviewer's point is directly relevant to the authors, highlighting a potential limitation in the experimental validation. Suggesting testing on 'more complex problems' is a constructive suggestion aimed at improving the robustness and generalizability of the findings. This feedback is directly actionable for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the action to be taken: 'remove abbreviations'. While the reviewer doesn't specify *why* they want this change, the action itself is clear and direct. The reviewer also provides an example ('MoCo'), suggesting they are aware of a specific instance where this might be an issue, even if it's not the primary focus of the general instruction.", "grounding_specificity_rationale": "The reviewer identifies the specific part of the paper where the change is intended: 'section headers'. They also provide an example of an abbreviation ('MoCo') that they believe should be removed. While the reviewer doesn't explicitly state the *reason* for removing abbreviations (e.g., 'to improve clarity'), they clearly pinpoint the location of the problem and provide a concrete example of an affected element.", "verifiability_rationale": "The reviewer makes a claim: 'abbreviations like \"MoCo\" should not appear in the section header, since a reader might not know what it means.' This is a judgment or opinion. The reviewer then provides a rationale: 'This is a good practice to improve readability and reduce confusion for the reader.' While the general idea of avoiding ambiguous terminology is generally accepted good practice, the reviewer doesn't provide specific external references or examples to support this claim within the *review point* itself. The reasoning is logical and common sense.", "helpfulness_rationale": "The reviewer provides a suggestion: 'remove abbreviations from section headers'. This is a clear and actionable piece of feedback. The reviewer implies the benefit of this change is to improve readability and reduce confusion for the reader. The suggestion is directly related to the identified issue and provides a practical solution. While the suggestion is general, it is still a helpful direction for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The statement 'The technical contribution is unclear' is an explicit action, as the reviewer is pointing out a deficiency. However, the statement 'Most of the analysis are quite standard' is vague, lacking specific details on what analysis is being referred to and why it is considered standard. This vagueness makes it difficult for the author to take concrete action based on this comment.", "grounding_specificity_rationale": "The reviewer does not specify which part of the paper or analysis is unclear or standard. They make a general statement about the technical contribution and the nature of the analysis. Therefore, the grounding is weak as the authors cannot confidently determine the exact area needing improvement.", "verifiability_rationale": "The review point contains a claim: 'The technical contribution is unclear. Most of the analysis are quite standard.' However, it does not provide any evidence or justification for this claim. There are no logical reasoning, common knowledge, or external references provided to support these statements. Therefore, the claim is 1.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper ('unclear technical contribution') and suggests that the analysis might be standard. However, it does not offer any specific suggestions for improvement or provide any evidence to support its claims. The feedback is general and lacks actionable insights, making it not particularly helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point states \"the paper's primary contribution seems to be an incremental advancement in efficiency over the TACTiS approach.\" While this statement identifies a potential weakness in the paper's contribution, it does not explicitly recommend a specific action or provide concrete details on how to achieve this incremental advancement. The reviewer points out the *what* (efficiency) but not the *how* or *specifics* of how to make it efficient. Therefore, it is not fully actionable, as it lacks explicit and concrete suggestions.", "grounding_specificity_rationale": "The review point mentions \"the paper's primary contribution\" and \"the TACTiS approach.\" While it names the *general* subject, it does not pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. The reviewer refers to the paper's contribution in a general sense, lacking the specificity of mentioning a particular element or section. Therefore, it is 1 at all.", "verifiability_rationale": "The review point states \"the paper's primary contribution seems to be an incremental advancement in efficiency over the TACTiS approach. More substantial evidence or arguments are needed to establish this as a significant contribution to the field.\" This review point makes a claim about the nature of the paper's contribution and the need for more evidence. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The reviewer states a *claim* without *verifying* it. Therefore, it is 1.", "helpfulness_rationale": "The review point highlights a potential lack of substantial evidence for the claimed incremental advancement in efficiency over the TACTiS approach. This directly addresses a potential weakness in the paper's contribution. While it identifies a problem, it does not offer a specific solution or actionable steps to address it. It points out a gap in the evidence, which is valuable feedback for the authors. Therefore, it is 3 in identifying a potential issue, but it does not provide a concrete solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states their opinion about the paper's contributions and suggests a minor improvement. While the reviewer explicitly states their opinion ('trivial,' 'limited,' 'incremental'), the specific action they suggest ('focusing on more significant improvements') is vague and doesn't pinpoint exactly what needs to be changed. The reviewer implies that the current improvement (adding topic entities) is not substantial enough, but doesn't provide concrete examples of what constitutes a 'more significant improvement'.", "grounding_specificity_rationale": "The reviewer refers to 'improvements on different datasets' and 'improvement on the topic entities.' While the reviewer clearly identifies the *area* of improvement, they do not explicitly name the specific datasets or the unique aspects of 'topic entities' being addressed. The reviewer implies improvement but doesn't specify *what* is being improved within these areas.", "verifiability_rationale": "The reviewer makes a claim: 'The improvements on different datasets are trivial and the novelty of this paper is limited. Lots of previous works focus on this topic. Just adding topic entities seems incremental.' This is a clear statement of opinion and assessment. However, the reviewer does not provide any specific examples, references, or logical reasoning to *support* their claim that the improvements are 'trivial' or 'incremental'. They offer *why* they think it's limited but not evidence *for* that assessment.", "helpfulness_rationale": "The reviewer offers a general critique of the paper's contributions and suggests focusing on 'more significant improvements'. While the reviewer identifies a potential area for improvement, the suggestion is very broad and lacks specific details. The reviewer doesn't provide concrete, actionable feedback on how the authors should go about making these 'more significant improvements'. The suggestion is at a high level and doesn't offer specific guidance on what aspects of the work need to be changed or improved."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'lacks discussion,' which implies an action for the authors: 'include a discussion.' However, it doesn't specify the *content* of the discussion or the *specific aspects* of the hierarchical strategy and QUBO problem that should be addressed. Therefore, while it points to an action, it lacks the concrete details needed to be fully actionable.", "grounding_specificity_rationale": "The review point explicitly mentions key terms related to the theoretical analysis of the proposed method, such as 'theoretical guarantee,' 'approximation ratio,' 'hierarchical strategy,' and 'global optimal of original QUBO.' This clearly identifies the specific part of the paper being addressed, making it wellgrounded. Furthermore, it specifies the *nature* of the missing discussion, focusing on the approximation ratio of the hierarchical strategy compared to the global optimal of the original QUBO.", "verifiability_rationale": "The review point does not contain a claim that needs to be verified. It is a statement of a gap or missing information rather than a proposition that requires justification or evidence. Therefore, it does not fit the criteria for verifiability.", "helpfulness_rationale": "The review point identifies a specific area where the paper lacks theoretical analysis. This is likely to be helpful for the authors as it highlights a potential area for deeper understanding and improvement of their proposed method. While it doesn't provide specific instructions on how to conduct this analysis, it points to a relevant gap in the current work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a lack of a quantitative measure, which implies an implicit action of 'add a quantitative measure.' However, it doesn't provide specific guidance on *how* to do this, making the action vague and less actionable.", "grounding_specificity_rationale": "The review point criticizes the lack of a quantitative measure *without specifying where* this measure would be or what it would assess. This implies a lack of grounding in a specific part of the paper or a defined evaluation process. The criticism is about the *lack* of specificity, not a clear identification of a section or element to address.", "verifiability_rationale": "The suggestion of a quantitative measure is generally verifiable. However, the *lack* of such a measure means there's no concrete evidence provided to support the claim of a quantitative evaluation. The suggestion itself could be considered verifiable if implemented, but the absence of it makes this aspect less directly relevant to the current point.", "helpfulness_rationale": "The review point directly identifies a limitation in the current evaluation process (reliance on visual inspection) and suggests an alternative (a quantitative measure). This directly addresses a practical issue for the authors and offers a concrete improvement, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer states \"Only marginal improvements over baselines...\" which is an explicit action, but it lacks detail on *what* is improved and *how*. The reviewer also suggests 'suggesting that the performance differences between some methods are not very significant,\" which is an implicit action that needs to be inferred. The lack of specific details makes the action somewhat vague.", "grounding_specificity_rationale": "The reviewer makes a general statement about the overall performance, not pinpointing a specific section or table. They mention \"the method\" generally. While they imply something is not significant, they don't specify *what* is marginal or *where* the improvements are.", "verifiability_rationale": "The reviewer *claims* \"Only marginal improvements over baselines...\" but doesn't provide any evidence or justification for this claim. They mention \"error bar range\" as a factor, which is a suggestion but not a concrete verification. The statement 'suggesting that the performance differences between some methods are not very significant\" is an interpretation, not a verifiable claim on its own.", "helpfulness_rationale": "The reviewer's comment is primarily critical, focusing on the lack of significant improvement. They don't offer specific suggestions for how the method could be improved or what aspects need attention. While they point out a problem, they don't actively guide the authors towards a solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'significant artifacts' in 'generated videos' and compares the 'action recognition performance' to the 'current stateoftheart' on the 'UCF dataset'. This indicates a clear and direct identification of issues and suggests concrete improvements like 'improving the generation process' and 'increasing the depth of the architectures'.", "grounding_specificity_rationale": "The reviewer refers to 'generated videos' and the 'UCF dataset', which are specific parts of the work being discussed. While not a direct mention of a section number, it's a clear reference to a defined entity. The reviewer also mentions 'action recognition performance being much below the current stateoftheart' and the use of 'deeper architectures and optic flow' in the stateoftheart, providing some detail about what might be causing the performance gap.", "verifiability_rationale": "The reviewer makes a claim: 'action recognition performance is much below the current stateoftheart'. However, this claim is not supported by any specific evidence or references within the review point itself. The reviewer presents it as a general observation based on their understanding of the stateoftheart.", "helpfulness_rationale": "The review point identifies specific weaknesses related to 'artifacts in generated videos' and 'low action recognition performance'. It also provides concrete suggestions for improvement, such as 'improving the generation process' and 'increasing the depth of the architectures'. These suggestions are directly related to enhancing the quality and functionality of the work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states what they find unclear: 'how to make the new proposed evaluation set more diverse and representative' and 'how to select those representative images'. While the action of identifying these unclear aspects is explicit, the reviewer does not explain *how* they plan to achieve this. The action is stated, but the method is not detailed, making it vague.", "grounding_specificity_rationale": "The reviewer's comment is not specific to a particular part of the proposed method or paper. They are broadly stating a general concern about the lack of clarity in the evaluation process. They could be more specific, for example, by saying 'I'm unclear about the criteria for diversity' or 'I don't understand how they select representative images'. As it stands, the referenced part is not clearly identified.", "verifiability_rationale": "The reviewer makes a claim: 'It is still unclear how to make the new proposed evaluation set more diverse and representative than the previous method and how to select those representative images.' However, the reviewer does not provide any evidence, reasoning, or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the statement of uncertainty.", "helpfulness_rationale": "The reviewer's comment is a question about the proposed method, specifically about its novelty and selection process. While it raises a valid point for the authors, it doesn't directly address the current draft or provide actionable feedback on how to improve it. The comment is about the *future* method, not the *current* work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'include a background section to introduce the basic RL framework'. It is also somewhat concrete as it names the specific elements to be included: 'elements of the MDP, trajectories, and policy'. However, it lacks detail on *how* to implement this action, such as suggesting specific textbooks or online resources.", "grounding_specificity_rationale": "The comment explicitly mentions the specific part of the paper being addressed: 'the RL context being considered' within the methods section. It is grounded because it directly points to the area where the authors are currently working. However, it doesn't specify *which* subsection or equation this refers to, making it weakly grounded.", "verifiability_rationale": "The comment contains a claim: 'Without this, it is difficult to follow the subsequent sections' which is supported by reasoning: 'it is difficult to follow the subsequent sections'. It is also 3 as it points to a logical consequence of the missing background. However, it doesn't provide specific examples of *where* the difficulty lies (e.g., understanding policy gradients or the Bellman equation).", "helpfulness_rationale": "The comment is 5 as it identifies a crucial missing element (background section) that would significantly improve the authors' understanding of the paper's context. It also provides a clear reason *why* this is important ('it is difficult to follow the subsequent sections'). While it could be more specific about the *exact* nature of the missing information, it clearly identifies the need for a basic RL introduction. The suggestion to provide context for the modifications in the methods section is also valuable."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly asks a question about the relevance of a specific concept to their work, which is an explicit action.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"DoshiVelez, F., & Kim, B. (2017).\" This is a literal mention of a specific work, indicating full grounding. The reviewer also asks about the \"notion described in the work,\" which specifies the aspect of that work being considered, making it specific.", "verifiability_rationale": "The reviewer is asking a question, which can be considered a claim that requires verification. While the answer isn't a direct statement, the question itself is verifiable based on the definitions of interpretability and the context of the cited work. The connection can be argued based on the definitions of interpretability.", "helpfulness_rationale": "This is a highly relevant and actionable question. The reviewer is directly asking about the connection to a specific, relevant paper. This provides a clear direction for the authors to improve their understanding or the paper's presentation of interpretability."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a limitation in the experimental setup, suggesting that the authors should consider expanding their experiments. However, it does not explicitly state what specific changes or improvements are needed. The suggestion to 'expand' is general and lacks concrete details on how to achieve this.", "grounding_specificity_rationale": "The review point explicitly mentions 'MNIST' and 'a single realworld dataset' as the scope of the experiments. This clearly identifies the specific parts of the paper being addressed, providing strong grounding. It also specifies the *type* of limitation (lack of diversity in datasets), adding further specificity.", "verifiability_rationale": "The review point states a fact about the limited scope of the experiments. While it implies that this limitation is a problem in the field, it does not provide any specific justification or references to support this claim. The statement itself is a claim that requires implicit understanding or acceptance within the field.", "helpfulness_rationale": "The review point identifies a weakness in the experimental design (limited datasets) and suggests that the authors should consider expanding their experiments. This provides a clear direction for improvement, making the review point 3 in guiding the authors towards a better experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their agreement with the efficiency argument regarding FLOPs and activation size but requests more details on the parameter count. The action is clearly stated, and the request for more information is a direct consequence. While the action itself might be considered vague (how exactly are the parameters increasing?), the reviewer's intent is clear and actionable for the authors to seek clarification.", "grounding_specificity_rationale": "The reviewer refers to 'S2D structure' which is a specific part of the paper. While they don't provide a section number or a unique element, the term itself is specific enough to identify the intended part of the architecture. The reviewer is asking for clarification on a specific aspect (parameter count) within this structure, indicating a degree of grounding.", "verifiability_rationale": "The reviewer provides a logical explanation for why the parameter count might increase (due to increased depth when kernel size remains constant) and connects this to the known relationship between activation size and FLOPs. The reasoning is clear and provides a basis for understanding the potential increase in parameters. The claim is supported by logical arguments and common knowledge about convolutional layers.", "helpfulness_rationale": "The reviewer raises a valid point about the potential inconsistency in the description of the S2D structure regarding the number of parameters. They provide context (FLOPs and activation size) and suggest a concrete next step (asking for clarification on parameter count). This is a helpful observation that directly addresses a potential ambiguity for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The reviewer implies a comparison and potential extension of 10 but doesn't explicitly state what the authors should do next (e.g., 'You should try applying this to your method'). The lack of a clear next step makes it 2.", "grounding_specificity_rationale": "The reviewer mentions '10' but doesn't specify which aspect of '10' is relevant or why '10' can't do something. The reference is somewhat general.", "verifiability_rationale": "The review point is a question, not a declarative statement containing a claim.", "helpfulness_rationale": "The review point raises a question and suggests a potential improvement for a related method. It doesn't directly point out a weakness in the reviewed paper."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point does not specify any actions or improvements for the authors. It identifies a limitation in the experimental setup but does not provide guidance on this limitation.", "grounding_specificity_rationale": "The review point does not specify which Atari game or baseline is being referred to. The terms 'the Atari game' and 'a single baseline' are too general and do not pinpoint a specific section, table, or unique aspect of the paper.", "verifiability_rationale": "The review point makes a claim about the limitations of the Atari game results but does not provide any justification or evidence for this claim. It states that the results are 'limited' and 'very hard to interpret' without explaining why or providing supporting arguments.", "helpfulness_rationale": "The review point identifies a weakness in the experimental setup but does not offer any suggestions or guidance on how to improve the results. It is a critique without constructive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "Somewhat Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitation of the proposed method, indicating a clear action the authors should take. The statement 'As such, the model will not be incentivized to use less factors, leading to increasing number of factors and increased computation with more tasks' directly suggests a concrete action the authors should consider to address this issue.", "grounding_specificity_rationale": "The reviewer refers to a general aspect of the method ('the proposed method') and its behavior with more tasks. While the issue is somewhat specific (lack of sparsity constraint), the reference to the method as a whole rather than a specific section or table makes the grounding somewhat weak. The reviewer mentions 'more tasks' which is a general concept rather than a specific section or table.", "verifiability_rationale": "The reviewer makes a claim about the expected behavior of the model due to the absence of a sparsity constraint. This claim can be logically verified based on the understanding of factorization models and sparsity constraints. While the reviewer doesn't provide specific examples or references within this point, the claim is based on a general understanding of the field. The logical reasoning is sound: a lack of sparsity constraint would discourage the model from using fewer factors, potentially leading to an increase in the number of factors and computation with more tasks.", "helpfulness_rationale": "The reviewer points out a potential limitation of the proposed method, specifically its lack of a sparsity constraint and its potential impact on computation with more tasks. This is a valuable piece of feedback for the authors as it highlights a potential area for improvement and a potential challenge they might face. The reviewer suggests that the authors should be aware of this limitation and consider its implications."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the presentation of the simulation study is not favoring the authors and specifically points out the lack of explanation for GPC's outperformance. They even offer a potential reason (bandit feedback and cost function form). This suggests the reviewer has identified a clear area for improvement and has a concrete suggestion.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the presentation of the simulation study' and focuses on the 'authors' and the 'GPC (benchmark) is performing better than BPC (their method)'. They also state that the reason for GPC's outperformance is due to 'bandit feedback' and not using information about the 'form of the cost function'. This demonstrates a clear and specific identification of the relevant part of the paper and the issue within it.", "verifiability_rationale": "The reviewer makes a claim that 'the authors do not really comment on why the GPC (benchmark) is performing better than BPC (their method)'. They also provide a suggestion as to why this might be the case, linking it to 'bandit feedback' and the 'form of the cost function'. This claim is supported by the reviewer's statement and their proposed explanation.", "helpfulness_rationale": "The reviewer's point directly addresses a potential area of confusion for the authors regarding the simulation study results. By highlighting the lack of explanation for GPC's outperformance and suggesting it might be due to bandit feedback and cost function form, the reviewer provides a concrete piece of information that could help the authors understand and potentially replicate the study. The reviewer's suggestion is specific and actionable."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the action of 'ReLU does not work very well in very deep or in convolutional networks.' This is a clear and direct statement that authors can use to understand a potential limitation of ReLU.", "grounding_specificity_rationale": "The review point mentions 'deep or convolutional networks,' which attempts to ground the statement. However, it doesn't specify *which* parts of the network or provide a unique element to identify the issue. The mention is implied through the context of ReLU's limitations.", "verifiability_rationale": "The review point contains a claim: 'ReLU does not work very well in very deep or in convolutional networks.' The reviewer attempts to support this claim by mentioning the AlexNet paper. However, they don't explicitly state that ReLUs were used *in* AlexNet's convolutional layers (they imply it through the general use of ReLUs in the paper and the use of convolution). The connection between ReLU's use in AlexNet and the current point about ReLUs not working well in convolutional networks is not explicitly and clearly established.", "helpfulness_rationale": "The review point provides a clear action (not using ReLU) and encourages further investigation by suggesting the authors look for a counterexample (the AlexNet paper). This shows a desire for the authors to explore the claim further and potentially find a solution."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a potential issue with the reported perplexity, stating it's over 30. While this is a specific issue, the reviewer doesn't explicitly state what action the authors should take based on this. They don't provide a specific, actionable step beyond 'check the perplexity calculation'.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 1' and 'perplexities' in the paper. However, they do not explicitly state that the perplexity values are *within the paper*. They are criticizing the *reported* perplexity. Therefore, the grounding is weak because the authors cannot confidently determine the referenced part of the paper. The reviewer also doesn't specify what needs to be addressed in this part (the high perplexity) beyond stating it's a problem.", "verifiability_rationale": "The reviewer claims that the high perplexity contradicts better BLEU scores in their experience. This is a claim that needs to be supported. However, the review point does not provide any external references, logical reasoning, or examples to support this claim. The reviewer presents the discrepancy without explaining *why* it occurs or providing evidence to back it up. Therefore, the claim is 1 based on the information provided in this review point.", "helpfulness_rationale": "The reviewer's statement is a direct criticism of the reported perplexity value. While they identify a potential issue, the lack of clarity about the calculation makes it difficult for the authors to act upon this feedback. The criticism is about the *reported* value, not a clear, actionable improvement suggestion. The reviewer doesn't offer any specific steps or explanations for why this high perplexity is a problem or how it should be addressed."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the need for 'experiments on distributed deployment' and 'a larger model'. This indicates a clear action the authors should take. While it doesn't specify *how* to conduct the distributed experiments, it clearly identifies the *what*. Therefore, it is explicitly stated and points to a concrete action, although the action itself might be considered somewhat vague depending on the interpretation of 'concrete'.", "grounding_specificity_rationale": "The review point mentions 'distributed deployment' and 'a larger model'. However, it does not explicitly identify *which* specific experiment within 'distributed deployment' or *which* specific 'larger model' is needed. The reviewer is commenting on the *need* for these types of evaluations and model sizes, but not the precise element within those categories. Therefore, the grounding is weak as the authors cannot confidently determine the exact referenced part. The specificity is also underspecific as it doesn't detail the *how* of the distributed deployment or the *specific* large model to use.", "verifiability_rationale": "The review point states 'The evaluation needs experiments on distributed deployment and a larger model'. This is a statement of a need or requirement, not a claim that needs verification. It doesn't present a subjective opinion, a suggestion for change, a judgment about the paper, or a deduction based on existing information. Therefore, it does not contain a claim that requires supporting evidence or justification.", "helpfulness_rationale": "The review point identifies areas where the evaluation could be improved, specifically suggesting more comprehensive experimentation and the use of larger models. This provides a direction for improvement and is helpful in guiding the authors. However, it doesn't offer specific *how* to achieve this, making it somewhat general. It doesn't provide a critique of the current evaluation or suggest specific improvements, so it's not 5 in pinpointing exact flaws. It also doesn't present a claim that needs verification, so it's not unhelpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing information (the importance of rooted patterns and the choice of roots) and suggests a concrete action (providing this information). This is 5.", "grounding_specificity_rationale": "The reviewer does not explicitly name a specific part of the paper being addressed. While the concept of rooted patterns is mentioned, the *specific* section or detail lacking grounding is not clearly identified. The reviewer implies a need for more detail within the definition of rooted patterns, but doesn't pinpoint the exact location. This suggests weak grounding as the authors need to infer the relevance of this section.", "verifiability_rationale": "The reviewer points out a lack of justification for a design choice (the rootedness), which could be considered 1 without further explanation. While the reviewer doesn't explicitly claim something, the implication is that the lack of explanation makes the rootedness assumption less convincing, which relates to verifiability. The reviewer doesn't provide examples or references to support the importance of rooted patterns.", "helpfulness_rationale": "The reviewer's suggestion to either explain the rootedness or simplify to nonrooted patterns directly addresses a potential weakness in the authors' exposition and empowers them to improve their work. This is a 5 suggestion as it directly tackles a potential lack of clarity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the weakness ('that the consistency between training and inference can be easily satisfied') and suggests an improvement ('I would suggest giving more explanations on this'). The explicit identification of the weakness and the suggestion for improvement indicate an actionable point for the authors. While the specifics of the explanation are not detailed, the reviewer clearly points to an area needing attention.", "grounding_specificity_rationale": "The review point explicitly mentions the lines (Line 9597 and Line 308310) where the consistency issue is discussed. This grounds the comment in specific parts of the paper. However, the comment does not specify *what* is wrong with the consistency in those sections. It only suggests providing more explanations without detailing what those explanations should cover. Therefore, while the section is identified, the specific issue within that section is not.", "verifiability_rationale": "The review point contains a claim ('I would suggest giving more explanations on this') that the authors would like to be justified or supported by the paper. However, the paper does not provide any specific justification or examples for why more explanations are needed. The reviewer simply states their suggestion without providing any logical reasoning, common knowledge, or external references to support it.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper (the consistency between training and inference) and suggests an improvement (giving more explanations). While the suggestion itself is vague and lacks specific details, it points to a relevant area for the authors to address. By highlighting this specific point and suggesting more detail, the reviewer provides a direction for improvement, even if the direction is not fully specified. The reviewer's intent to improve the clarity of a potentially confusing concept is a valuable contribution."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states that the hyperparameters k and \u03b7 require finetuning. This is a direct action the authors should take. Furthermore, the comment explains *why* this finetuning is necessary, mentioning the dependency on environment availability or OPE methods. This provides a clear understanding of the practical steps involved.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper where the hyperparameters k and \u03b7 are used. It refers to them in general, without pointing to a particular section, table, figure, or unique aspect of the paper. Therefore, the grounding is weak.", "verifiability_rationale": "The comment contains a claim that the hyperparameters k and \u03b7 require finetuning, which depends on the availability of the environment or a good OPE method. This claim is 3 as the 'what' (hyperparameters require finetuning) is clear. The 'why' (environment availability or OPE methods) provides some justification. However, it lacks detailed examples or references to support the claim fully.", "helpfulness_rationale": "The comment identifies a practical limitation regarding the finetuning of the hyperparameters k and \u03b7. While it informs the authors about the dependency on the environment or OPE methods, it does not provide actionable steps or suggestions on how to overcome this limitation or improve their draft. It serves more as a headsup than a constructive suggestion for improvement."}
{"actionability_label": "3: 4", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a discrepancy in the regularization method used for the GLM model and suggests that the authors might be applying a different technique than what is described in previous work. This points to a potential area for clarification and improvement in the authors' methodology. While the reviewer doesn't explicitly state what action the authors should take, the suggestion to reproduce previous models implies a concrete step they could undertake. Therefore, the reviewer's point is 4, as it guides the authors towards a specific improvement.", "grounding_specificity_rationale": "The reviewer mentions 'the form of regularization' and specifically names 'L1 regularization' and 'lowrank approximation' in the context of the Pillow et al. model. This indicates a degree of grounding as the reviewer is referring to specific regularization techniques. However, the initial statement about 'regularization' is quite general, and the reviewer doesn't pinpoint a specific section or table within the paper where this issue is discussed. Therefore, the grounding is somewhat specific.", "verifiability_rationale": "The reviewer makes a claim about the regularization techniques used in the Pillow et al. model and suggests that reproducing these features would be beneficial. This claim is based on the reviewer's recollection of previous work. The suggestion to reproduce features is a logical next step for the authors. While the reviewer doesn't provide explicit verification of their recollection, the suggestion itself implies an understanding of the potential impact. Therefore, the reviewer's point is 3, as it builds upon a potentially valid observation.", "helpfulness_rationale": "The reviewer identifies a potential inconsistency in the authors' application of regularization and suggests a concrete action (reproducing previous model features) to address it. This is a valuable observation that directly points to a potential improvement in the authors' methodology. The reviewer's suggestion is clear and actionable, making it 5 for the authors to consider. Therefore, the reviewer's point is 5, as it provides a specific direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point suggests discussing 'failure cases,' which could be interpreted as an implicit action. However, the action of 'how to discuss failure cases' is not specified, making it vague. Explicit vs. Implicit: Implicit. Concrete vs. Vague: Vague. While the suggestion points to an area for improvement, the lack of a concrete action makes it 2.", "grounding_specificity_rationale": "The review point suggests discussing 'failure cases' but does not specify which part of the paper or section this refers to. The comment lacks a clear reference point, making it difficult to identify the exact location or nature of the suggested discussion. Explicit vs. Implicit: Implicit. Concrete vs. Implicit: Implicit. The lack of a specific reference makes it 1.", "verifiability_rationale": "The review point itself is not a claim or assertion. It is a suggestion for future work. Since there is X being made, there is nothing to verify. Claim Extraction: X. Verifiability Verification: N/A. The review point is a suggestion, not a claim.", "helpfulness_rationale": "The review point suggests discussing 'failure cases,' which is a relevant direction for improvement. However, it is a general suggestion and lacks specific details on how to implement this. It does not directly address existing weaknesses or provide concrete steps for improvement. The suggestion is relevant but lacks the specificity and actionable steps needed for significant impact. It is a suggestion for future work, not a direct improvement of the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a missing element (the base layer GNN encoding) and suggests an action (ablation study). However, they don't explicitly state that the authors *should* perform this ablation study to improve their draft. The suggestion is presented as a potential solution rather than a direct instruction.", "grounding_specificity_rationale": "The reviewer mentions a specific technical term ('base layer GNN encoding') but doesn't pinpoint its location within the paper. The lack of specificity makes it difficult for the authors to understand the exact issue.", "verifiability_rationale": "The reviewer clearly states a problem ('It's unclear...') and provides a proposed solution ('An ablation study... would be helpful'). While not citing specific evidence *yet*, the suggestion itself offers a logical pathway to understanding the issue.", "helpfulness_rationale": "The reviewer suggests a concrete action (ablation study) that could be beneficial. This indicates a helpful suggestion, but it's not a direct order or demand for the authors to perform it. The helpfulness is moderate because the suggestion is valuable but not immediately actionable."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem of the paper lacking adequate discussion on the computational complexity of counting homomorphisms and provides specific suggestions for improvement, such as 'state the bounds' and 'elaborate on empirical runtimes'. This is a clear and actionable critique.", "grounding_specificity_rationale": "The reviewer focuses specifically on the computational complexity of counting homomorphisms and mentions a specific paper section (line 145) when discussing their example. This demonstrates strong grounding as the reviewer can accurately pinpoint the area being addressed and specify the issue within it.", "verifiability_rationale": "The reviewer presents a claim about the lack of discussion on computational complexity and provides suggestions for improvement. While the suggestions are concrete, they could benefit from further elaboration on why these suggestions are important and how they address the identified issue. However, the claim itself is verifiable by pointing to the absence of such discussion in the paper.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improving the paper. By pointing out the lack of discussion on computational complexity and offering concrete ways to address it, the reviewer directly helps the authors improve their work. The suggestions are directly relevant to the technical content."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The suggestions are explicitly stated ('fix the form', 'correct the grammatical error', 'address the question'). However, the level of detail and specificity for each action is lacking. For instance, 'fix the form' doesn't specify which part needs fixing or how to achieve it. Similarly, 'correct the grammatical error' is too vague. The suggestions are broad and lack concrete steps for the authors to follow. The 'question' is also too general and doesn't provide a specific direction for the authors to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions the lines in the paper where the potential issues are located (line 108 and line 115). This demonstrates strong grounding as the authors can easily identify the specific section being referred to. However, the specificity of the feedback is limited. The reviewer points out a potential typo and a grammatical error but doesn't specify *what* the errors are or how they impact the paper's clarity or correctness. The question about the baseline method is also general and doesn't provide specific details about the method or its convergence.", "verifiability_rationale": "The reviewer makes claims about potential issues at specific line numbers (108 and 115) and raises a question about the convergence of the baseline method. However, the claims are not supported by any logical reasoning, common knowledge, or external references. The reviewer states 'there is a potential typo' and 'the grammatical error is significant' without providing evidence or justification. The question about the baseline method is also presented as a statement without any supporting information or context. The claims are presented as opinions rather than verifiable statements.", "helpfulness_rationale": "The review points out specific potential flaws in the paper (potential typo, grammatical error) and asks a relevant question about a method. However, the suggestions provided are too general and lack specific guidance on how to address these issues. The reviewer doesn't offer concrete steps for the authors to take, such as providing the exact typo, suggesting a specific way to correct the grammar, or explaining the convergence issue in detail. The lack of specific and actionable feedback makes the review less helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a missing element (inference time study) and suggests a reason (direct nature of the method) and a potential solution (comparing to other methods). While the suggestion is not a fully explicit action, it provides a clear direction for improvement, making it actionable.", "grounding_specificity_rationale": "The reviewer mentions 'inference time' and 'pose estimation method' generally but does not specify a particular section, table, figure, or unique aspect of the paper where this issue is present. The criticism is broad and lacks pinpointing of a specific location or detail.", "verifiability_rationale": "The reviewer identifies a claim ('this is a pose estimation method that is direct and does not require detection or keypoint grouping') and suggests a way to verify it ('it is worth to compare its inference speed to previous topdown and bottomup pose estimation method'). While the claim is present and the suggestion points towards verification, the reviewer does not provide specific examples, datasets, or metrics for the comparison, making the verification somewhat underspecified.", "helpfulness_rationale": "The reviewer identifies a valid concern (missing inference time study) and provides a relevant suggestion (comparing to other methods). This suggestion is directly related to improving the pose estimation method and provides a clear direction for the authors to take, making the review point helpful in guiding improvement."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out two specific mathematical errors in the proof of Theorem A.3. They state that the input x has two indices despite being a vector, and that the summation \u2211 k ( W k ( 2 ) ) 2 should equal 1/d, not d. This provides the authors with a clear and actionable indication of where the error lies in the proof. The reviewer also specifies the section (Theorem A.3 proof) and the equations involved, making the action explicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Theorem A.3 proof' and points to the specific equations involving the summation. This indicates a high level of grounding specificity as the authors can directly locate the referenced part of the paper. However, the reviewer does not specify *which* element within the proof is incorrect (e.g., a particular step or line number). Therefore, while the section and equations are mentioned, the exact location of the error within those equations is not specified.", "verifiability_rationale": "The reviewer makes a claim that there is an error in the proof, specifically stating that \u2211 k ( W k ( 2 ) ) 2 should equal 1/d, not d. The reviewer provides a logical argument for why the summation should be 1/d, based on the properties of orthonormal bases. While the reviewer doesn't provide a full derivation within the review point itself, the reasoning is clear and verifiable. The claim is supported by logical reasoning and common knowledge (properties of orthonormal bases).", "helpfulness_rationale": "The reviewer provides a clear and specific indication of an error in the mathematical proof. By pointing out the potential misunderstanding of the input x's dimensionality and the incorrect calculation of the summation, the reviewer guides the authors on how to potentially fix the proof. The reviewer also references a specific section of the appendix (Theorem A.3 proof), making the feedback actionable and directly addressable. The reviewer's suggestion is not just a general comment but a specific, actionable piece of feedback."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the use of terms like 'somewhat' and 'good generative ability' in the description. While these terms describe the quality of the results, they don't explicitly state an action the authors should take. The reviewer's question about the percentage of correct entities/relationships is a specific action the authors could ask, but the initial phrasing focuses on the potential issue rather than the action itself. Therefore, the action is implicit and vague.", "grounding_specificity_rationale": "The reviewer's comment doesn't explicitly identify a specific part of the paper being addressed. They are concerned about the evaluation process and its reliability, but don't pinpoint where the entities/relationships should come from. The comment is about the *potential* issue, not the specific location of the problem. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a clear claim: 'I am concerned that even with beam search, only 77% of the result lists contain the ground truth logical forms. If the relationships and entities were replaced, how do we ensure that the pluggedin entities/relationships were the right one?' This claim is supported by the statement about the 77% accuracy and the question about the correctness of replaced entities. The reasoning is based on the provided percentage and the lack of ground truth. The external references are the percentage itself. Therefore, the claim is verifiable.", "helpfulness_rationale": "The reviewer raises a valid concern about the reliability of the evaluation process, specifically regarding the accuracy of entity/relationship plugging when ground truth is unavailable. While the comment identifies a problem, it doesn't offer a clear solution or actionable steps for the authors to improve their draft based on this feedback. The helpfulness is limited to raising a concern rather than providing actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the claim about evolutional dropout addressing internal covariate shift is 'very limited' and provides a detailed explanation of the limitations, stating that evolutional dropout can only increase the variance of lowvariance units, while batch normalization standardizes and centers activations. This provides a clear action for the authors to consider the specific impact on lowvariance units and compare it to batch normalization's behavior. The reviewer also suggests discussing these points explicitly, which is a concrete action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'evolutional dropout' and discusses its limitations regarding 'lowvariance units'. They also contrast this with the effect of 'batch normalization' in 'standardizing and centering activations'. This demonstrates a clear grounding of the comment in the specific aspect of the paper being discussed, making it fully grounded. The specificity is high as the reviewer details the specific issue and provides a comparison to another relevant concept.", "verifiability_rationale": "The reviewer makes a claim that the original statement is 'very limited' and provides a logical reasoning and specific examples to support this claim. They explain the specific limitations of evolutional dropout and contrast it with the wellknown effects of batch normalization. This provides clear evidence and justification for their assessment, making the claim 5. The use of logical reasoning and specific examples enhances the verifiability.", "helpfulness_rationale": "The reviewer's comment is 5. They not only identify a potential misunderstanding or area for clarification but also provide a clear explanation of the limitations of evolutional dropout and its difference from batch normalization. They suggest discussing these points explicitly, which is a concrete and actionable suggestion for the authors. The comment is specific, logical, and provides clear guidance, making it 5 for improving the authors' understanding and addressing a potential issue."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states: \"The performance of FedPCL heavily relies on the selection of different pretrained models, limiting its applications to more wide areas.\" This is a statement of fact, but it does not explicitly state an action the authors should take. While it identifies a limitation, it doesn't provide a concrete step or suggestion for improvement. The connection to 'more wide areas' is also vague.", "grounding_specificity_rationale": "The review point mentions 'FedPCL' and 'pretrained models' generally. While it mentions FedPCL, it doesn't specify *which* aspect or component of FedPCL is being criticized. Similarly, 'pretrained models' is a broad category. The connection to 'more wide areas' is also vague.", "verifiability_rationale": "The review point states: \"The performance of FedPCL heavily relies on the selection of different pretrained models, limiting its applications to more wide areas.\" This is a statement of opinion or judgment about the limitations of FedPCL. It doesn't present a claim that can be verified with logical reasoning, common knowledge, or external references within the provided text. The sensitivity to pretrained models is presented as a fact without further justification.", "helpfulness_rationale": "The review point identifies a limitation of FedPCL related to pretrained models. However, it doesn't offer any suggestions or actions for the authors to address this limitation. It points out a problem but doesn't provide a path forward. The connection to the 'new try for federated learning' mentioned in the subsequent part of the review is not explicitly linked back to the initial point."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the missing element: 'the tentative attention maps'. This is a direct identification of what needs to be added. The suggestion to 'see them in the qualitative figures' further clarifies the action to be taken. The action is both explicit and concrete.", "grounding_specificity_rationale": "The comment explicitly mentions 'tentative attention maps' and their location 'in the qualitative figures'. This provides a clear and precise identification of the missing element and its context. The grounding is strong as the specific type and location are mentioned.", "verifiability_rationale": "The comment implies a suggestion for improvement ('it would have been interesting to see...') but doesn't provide a logical reasoning or external reference to support why showing tentative attention maps is necessary or beneficial. While the suggestion is implied, the lack of explicit justification makes it less verifiable. It's not a definitive statement, but it sets the stage for a need for more information.", "helpfulness_rationale": "The comment directly points out a specific area for improvement in the authors' analysis ('it would have been interesting to see... tentative attention maps'). This is a clear direction for the authors to focus their attention. The suggestion is actionable, indicating a practical way to enhance their work. While it doesn't delve into the *why* or *how* of showing tentative maps, it provides a concrete target for improvement, making it 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment suggests adding more description, which is an implicit action. It lacks specifics on *how* to add the description, making it less actionable.", "grounding_specificity_rationale": "The comment refers to the 'contribution of this paper' broadly, without specifying a section, table, figure, or unique element. This lack of specificity means it's 1.", "verifiability_rationale": "The comment is a suggestion, not a claim requiring justification or evidence. There's no logical reasoning, common knowledge, or external references provided.", "helpfulness_rationale": "The comment identifies a valid need (more detail) but lacks the specifics (how to add it) to be truly helpful. It's a suggestion, which is better than nothing, but 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the suggestions (separate section for attention, separate section for tricks, current description is scattered). This is an *explicit* action the authors should take. The suggestions are very specific about *where* to put the information. They are not vague or ambiguous. The reviewer directly names the sections where the information should go.", "grounding_specificity_rationale": "The reviewer *mentions* sections (2.3 and 2.4) where the layerwise attention is described. While not a direct name, it points to specific sections. However, it's not a *literal* mention or a clear identification of a unique element within those sections. The reviewer *mentions* the *type* of attention (for deep VAEs) and *tricks* (normalization, feature scaling). This provides some context, but it's not a precise reference to a specific part of the model or algorithm.", "verifiability_rationale": "The reviewer is making a *critical* point about the organization and clarity of the paper. They are stating a problem they perceive exists. There isn't a direct *reference* to external literature to *prove* that the current organization is hindering understanding. The criticism is based on the *absence* of the suggested structure.", "helpfulness_rationale": "The reviewer's suggestions are constructive and directly address potential areas of confusion. They provide a clear direction for improvement. The suggestions are likely to help authors better understand the structure and content of their paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states two possibilities: either they don't understand Figure 5 or the labels are wrong. This is a direct and clear indication of an issue.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 5' and then further specifies the potential issues as 'either I don't understand Figure 5 or the labels are wrong'. This demonstrates a clear identification of the specific part of the paper and the nature of the problem.", "verifiability_rationale": "The reviewer makes a claim about the authors' potential misunderstanding or error in the labels of Figure 5. However, they do not provide any evidence, reasoning, or references to support this claim. There is no logical justification for why this issue might exist.", "helpfulness_rationale": "The reviewer points out a potential area of weakness in the authors' work (either a lack of understanding of Figure 5 or incorrect labels). This directly suggests an improvement area and encourages the authors to address it. While the comment is specific about the figure, it lacks the depth of explanation or solution that would make it 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The suggestion is explicit about the *what* (supervised baselines), but lacks specifics on the *how* or *which* ones, making it *partially* actionable.", "grounding_specificity_rationale": "The comment doesn't pinpoint a specific section, table, figure, or unique element in the paper where the supervised baselines are relevant. It also doesn't specify *what* aspects of the baselines are important. Therefore, it's 'Weakly Grounded and UnderSpecific'.", "verifiability_rationale": "The suggestion to 'add missing supervised baselines' is a claim that lacks sufficient justification or references. It doesn't explain *why* these baselines are needed or *how* they should be implemented. Therefore, it's '1'.", "helpfulness_rationale": "The suggestion is relevant and generally helpful, providing a benchmark for comparison. While not the most specific, it's still a valuable direction for improvement. Therefore, it's '3'."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states a fact ('Performance differences between methods are minimal') and offers a potential explanation ('less than 1 percentage point'). While it points to a *difference*, it doesn't explicitly *recommend* an action or provide a concrete next step for the authors. It's more of an observation.", "grounding_specificity_rationale": "The reviewer comments on 'Performance differences between methods' and 'benchmarks selected.' They are not pinpointing a specific table, figure, or section within the paper. While they *mention* benchmarks, they don't explicitly state which one.", "verifiability_rationale": "The reviewer makes a claim about the performance differences and offers a potential reason ('less than 1 percentage point'). However, they don't explicitly *justify* why a small difference is significant or how this relates to the benchmarks being outdated. The link is implied but not explicitly proven or explained.", "helpfulness_rationale": "The review point presents a finding (minimal differences) and offers a potential explanation (benchmarks). It doesn't directly suggest a *specific* action the authors should take based on this finding. It's more of an observation."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer provides three explicit points for improvement: questioning the method's novelty on deterministic systems, suggesting evaluation on stochastic environments, and pointing out the missing BEAR baseline. While the suggestions are clear, they are not directly actionable as they require further analysis and experimentation from the authors.", "grounding_specificity_rationale": "The reviewer's comments are 1 in specific sections or tables of the paper. They are generally commenting on the method's behavior and the missing baseline without pointing to a specific location in the paper.", "verifiability_rationale": "The reviewer makes several declarative statements, indicating claims. However, these claims are not supported by any reasoning, references, or external evidence.", "helpfulness_rationale": "The reviewer's comments are relevant to the authors' work, raising concerns about the method's novelty and the experimental setup. However, the suggestions are presented as questions and observations rather than direct, actionable recommendations with concrete solutions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the action of 'providing theocratical justification' in relation to 'cotraining and weight averaging'. This directly indicates an intended action. The terms 'cotraining' and 'weight averaging' are also specific techniques, making the action quite clear.", "grounding_specificity_rationale": "The review point directly refers to 'cotraining and weight averaging' as the area needing improvement. This explicit mention allows the reader to precisely identify the section or techniques being discussed, thus achieving 'full grounding'. The point also specifies the *nature* of the improvement needed: 'theocratical justification' and its importance for 'performance', making the specificity high.", "verifiability_rationale": "The review point contains a claim in the form of a suggestion: 'It would be better if the author could provide some theocratical justification in terms of why cotraining and weight averaging can improve results, since they are important for the performance.' This is a statement of what the author should do or what the justification should include, but it doesn't present a factual claim that requires verification in the traditional sense of proving something is wrong or missing in the paper's content itself.", "helpfulness_rationale": "The review point identifies a potential area for improvement in the paper \u2013 the justification for using cotraining and weight averaging. It encourages the authors to provide a clearer explanation of why these methods are expected to improve performance. While it doesn't directly tell the authors how to fix their model or what data to use, it points to a specific aspect of the paper that needs clarification or improvement in its presentation. The helpfulness lies in guiding the authors towards a more welljustified explanation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides a clear and specific suggestion for improving the clarity and actionable nature of a comment. They identify a potential ambiguity in the comment's meaning and propose a concrete way to resolve it by specifying the exact changes needed. This directly addresses the reviewer's point about the comment lacking meaningful information and being vague.", "grounding_specificity_rationale": "The reviewer directly points out a specific issue with the grounding of a comment. They identify a potential problem in section 4 and clearly state that the comment does not identify a specific part of the paper being addressed. They also specify that the comment does not detail what needs to be addressed in that part. This clearly demonstrates a lack of grounding specificity.", "verifiability_rationale": "The reviewer raises a point about the definition of a graph notation. While it could be argued that the authors *should* be using multisets if they are dealing with repeated labels, the reviewer is pointing out a potential *inconsistency* or *ambiguity* in the *definition* itself. It's a suggestion for improvement in the *methodology* used to represent the graph, not a critique of a specific finding or claim made by the authors. The evidence is present, but the conclusion depends on the actual implementation.", "helpfulness_rationale": "The reviewer's suggestion is directly aimed at improving the clarity and accuracy of the graph representation, which is beneficial for the authors. They propose a concrete way to address a potential limitation in the *definition* of the graph notation, making the suggestion actionable and directly helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential limitation of the authors' derivation by referencing the distinction between classical learning theorybased bounds and BayesianPAC based bounds. However, it does not explicitly state what action the authors should take to address this limitation. It points out a potential issue but lacks a direct, actionable suggestion.", "grounding_specificity_rationale": "The comment refers to 'classical learning theorybased bounds' and 'BayesianPAC based bounds' generally, without specifying a particular section, table, figure, or unique aspect of the authors' paper where this distinction is crucial. While it names the types of bounds, it doesn't pinpoint the exact location of the issue within the authors' work.", "verifiability_rationale": "The comment contains a claim: 'the to the best of my knowledge, does not yield realistic bounds, unless Bayesian considerations are taken into account.' This claim is based on the reviewer's understanding and experience. However, the comment does not provide specific examples, references, or detailed explanations to support this claim within this review point itself.", "helpfulness_rationale": "The comment identifies a potential theoretical limitation of the authors' work by highlighting the difference between classical and Bayesian learning theory bounds. While it points out a potential area for improvement or consideration, it does not offer a specific, actionable suggestion for the authors to make their bounds more realistic. It's a statement of a concern rather than a direct prescription for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states what they need: 'how the implicit distribution characterize the uncertainty of each label value' and 'how the model mitigrate the uncertainty of the label distribution'. This is an explicit request for details and a clear indication of what needs to be done. While the reviewer doesn't state *how* to do it, they identify the specific actions required, making it 3.", "grounding_specificity_rationale": "The reviewer refers to a specific methodological aspect: 'how the implicit distribution characterize the uncertainty of each label value and how the model mitigate the uncertainty of the label distribution'. This suggests they can identify the relevant part of the paper if it were explained. However, the review point itself doesn't explicitly point to a specific section, table, or figure, making the grounding somewhat implicit.", "verifiability_rationale": "The review point is a question, not a declarative statement making a claim. There is X being made, so it doesn't fall under the verifiability categories. The underlying *implied* claim is that the paper lacks this information, but the review point itself doesn't explicitly state a claim.", "helpfulness_rationale": "The reviewer is pointing out a specific area where the authors seem to be lacking information. This can be helpful for the authors as it highlights a potential weakness in the paper and encourages them to seek clarification. However, the review point itself doesn't provide the information, so its immediate helpfulness is limited to identifying a need for more detail."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation of the proposed method but does not explicitly state what action the authors should take to address this limitation. The suggestion is more of a concern than a direct instruction. The reviewer identifies a potential problem but doesn't provide concrete steps the authors should follow to mitigate it.", "grounding_specificity_rationale": "The reviewer identifies a limitation of the proposed method regarding its ability to detect hallucinations in openended responses. While the reviewer mentions the variability of outputs, they do not specify a particular section, table, figure, or unique aspect of the paper where this issue is most prominent. The grounding is not as precise as it could be. The reviewer points out a general limitation without pinpointing the exact area of concern within the paper.", "verifiability_rationale": "The reviewer states a claim about the proposed method's potential struggle to detect hallucinations in openended responses. While the reviewer provides a rationale for this belief, they do not provide specific examples, references to external works, or logical reasoning to fully support their claim. The justification is present but lacks the depth and evidence required for full verifiability. The reviewer presents a potential weakness without sufficient backing.", "helpfulness_rationale": "The reviewer criticizes the proposed method for its potential struggle to detect hallucinations in openended responses. While this is a valid concern, the reviewer does not offer specific, actionable improvements or suggestions to address this limitation. The feedback is more of a critique than a constructive suggestion for improvement. The reviewer points out a potential weakness without providing a clear path forward for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "Partially Verifiable", "helpfulness_label": "None", "actionability_rationale": "The reviewer suggests an experiment to verify a conclusion about label noise and model size. While this implies a actionable step, it doesn't explicitly state what needs to be done with the draft. The suggestion is broad and doesn't pinpoint a specific missing element or action to take on the paper itself.", "grounding_specificity_rationale": "The reviewer suggests verifying a conclusion about label noise and model size, but doesn't explicitly mention the specific paper or section where this verification should occur. The connection to 'deep learning models' is implied but not clearly stated as a direct reference to a specific part of the draft.", "verifiability_rationale": "The reviewer claims there's a conclusion about label noise and model size that needs verification and suggests an experiment to do so. The claim is supported by the suggestion of an experiment, but the claim itself isn't explicitly stated as a conclusion within the review point. The evidence for verifiability comes from the *action* of suggesting an experiment.", "helpfulness_rationale": "The reviewer suggests an experiment to verify a conclusion about label noise and model size. This is a relevant and constructive suggestion that could help the authors improve their draft by addressing a perceived lack of clarity. While it doesn't directly critique the paper's content, it offers a concrete way to investigate a potential weakness."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests an improvement by stating 'The writing could be improved' and proposes a concrete action by saying 'It would be helpful to draw a table to compare different CoT prompting methods across different dimensions.' This demonstrates an explicit action with a clear goal. However, the reviewer does not specify *how* the table should be structured or what dimensions to include, making it somewhat vague on the implementation details. Therefore, while the action is explicit, the concreteness of the action is limited.", "grounding_specificity_rationale": "The review point asks specific questions about the methodology, such as 'How and why shall we make an assumption that \u201cquestions of all the wrong demonstrations fall into the same frequenterror cluster\u201d?'. It also asks about the selection criteria, 'Is the selection criteria in section 4.2 reasonable? Namely, why do we not choose questions with more than 60 tokens and rationales with more than 5 reasoning steps?'. These questions directly address specific parts of the paper (methodology and experimental setup) and explain *why* certain choices were made. The grounding is strong because the questions are specific to the paper's content. The specificity is also high as the reviewer is asking for justifications and reasons behind the choices.", "verifiability_rationale": "The review point contains claims that can be verified. For example, the reviewer states 'The paper is wellorganized' and 'The writing is good and most of the content is very clear to me' as observations. The reviewer also poses questions that imply a need for clarification or justification, such as 'How and why shall we make an assumption that \u201cquestions of all the wrong demonstrations fall into the same frequenterror cluster\u201d?'. These claims and questions are supported by logical reasoning and common knowledge within the context of academic writing and research methodology. The external references are not explicitly mentioned in this point, but the questions are based on common practices in the field. The verifiability is good as the claims are generally accepted and the questions are logical.", "helpfulness_rationale": "The review point is 5. It directly addresses a stated weakness ('The writing could be improved') and provides a concrete suggestion ('draw a table to compare different CoT prompting methods across different dimensions'). This is an explicit action with a clear goal. Furthermore, the reviewer asks specific and focused questions about the methodology, which can help the authors understand and potentially refine their approach. The questions are welldefined and directly address aspects of the paper being reviewed. The helpfulness is high because the suggestions are actionable and the questions are clear and relevant."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The review point implicitly suggests that the likelihood function needs to be Gaussian for the Kalman filter to work. While it doesn't explicitly state 'p(y | Hf_bar(tn)) has to be chosen Gaussian', the implication is clear. The reviewer is pointing out a missing detail that needs to be addressed for the Kalman filter to be correctly applied. The action is 'ensure the likelihood is Gaussian', which is concrete but requires further clarification on *how* to achieve this.", "grounding_specificity_rationale": "The review point explicitly mentions 'p(y | Hf_bar(tn))' as the location where the Gaussian requirement needs to be stated. This clearly identifies the specific part of the model description where the issue lies. The grounding is 'p(y | Hf_bar(tn))' and the specificity is 'the Gaussian requirement for Kalman filter implementation'.", "verifiability_rationale": "The review point makes a claim about a requirement for Kalman filtering and smoothing, stating that the likelihood function must be Gaussian. This claim is verifiable based on the fundamental principles of Kalman filter theory. While not explicitly citing external references, the logic is wellestablished within the field.", "helpfulness_rationale": "The review point is 5 because it points out a crucial detail that is often implicitly assumed but needs to be explicitly stated for the correct application of Kalman filters. By highlighting this requirement, the reviewer is directly informing the author of a potential oversight and suggesting a necessary step for accurate implementation. This is a clear and actionable piece of feedback."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "3 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "2 (2)", "actionability_rationale": "The review point points out a *potential* issue (large training loss with suboptimal weight decay) and suggests a *consequence* (suboptimal cosine similarities). It also mentions the *lack of reporting* of cosine similarities for *large* weight decay. While it identifies areas of concern, it doesn't explicitly *recommend* an action like investigating training loss or exploring alternative weight decay strategies. It also doesn't provide a concrete *fix*.", "grounding_specificity_rationale": "The reviewer mentions \"weight decay is applied to all layers\" and \"cosine similarities for such large weight decay strengths are not reported.\" While the *general* concept of weight decay is mentioned, the specific *layers* affected are not explicitly named (e.g., \"all convolutional layers,\" \"recurrent layers\"). The *range* of weight decay strengths is also vague ('such large weight decay strengths\"). However, the reviewer *specifically* mentions \"cosine similarities for such large weight decay strengths are not reported,\" providing a concrete piece of information. The vagueness of \"large\" weight decay strengths and the lack of a precise definition of the affected layers limit the grounding specificity.", "verifiability_rationale": "The reviewer makes a statement about the *expected* outcome of applying suboptimal weight decay (large training loss and suboptimal cosine similarities) and points out the *lack of reporting* of cosine similarities for large weight decay. This constitutes a claim that requires justification. However, the reviewer *does not provide any evidence* or *reasoning* to support this claim. They also don't explain *why* cosine similarities are important or how suboptimal values would manifest.", "helpfulness_rationale": "The review points out a potential issue related to training loss and cosine similarity but doesn't offer a concrete solution or a detailed explanation of how to diagnose the problem. While it identifies a problem, it lacks actionable steps for the author to take. It also doesn't explain the implications of suboptimal cosine similarities or suggest alternative weight decay strategies."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is a clear and direct identification of a missing piece of information, making it an explicit action. The reviewer also provides a clear description of the implications of this omission.", "grounding_specificity_rationale": "The reviewer identifies the specific sections (title, abstract, introduction, and discussion) where the information is missing. While they don't pinpoint the exact element within those sections that lacks clarity, they clearly indicate the *location* of the problem. This makes the grounding somewhat concrete, as the sections are identifiable. However, the lack of specific details within those sections makes the specificity somewhat underspecific.", "verifiability_rationale": "The reviewer's point is not a claim about the paper itself, but rather a critique of the *absence* of information. They are suggesting that readers might misinterpret the results due to the lack of clarity. This is more of an implicit suggestion rather than a direct claim that can be verified by referencing external sources or logical reasoning within the paper. Therefore, it leans towards '1' as a direct claim, but the concern itself could be considered somewhat 'X' as it implies a belief about the reader's understanding. Given the borderline nature of this point, I've opted for '1' as it highlights the lack of direct claim verification.", "helpfulness_rationale": "The reviewer clearly identifies a significant and actionable issue. They point out a lack of clarity regarding the experimental setup, which could lead to misinterpretations. This is a strong and specific piece of feedback that is likely to be helpful for the authors. The reviewer's concern about the implications for publication further emphasizes the importance of this feedback."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "3 (2)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer's suggestions are relevant and point towards improvements, making them 3, even if not fully explicit or concrete. The suggestions are broad and don't specify *how* to create the toy dataset or what visualization to use. However, the suggestions are clear about what needs to be done, which makes them 3.", "grounding_specificity_rationale": "The reviewer is making general suggestions about the need for more experiments and a new metric. They are not explicitly pointing to a specific section, table, or figure in the paper. The reviewer is *implying* these improvements rather than directly stating their location.", "verifiability_rationale": "The reviewer's suggestions are vague and lack specific details or references. There's no clear 'how to do this' or 'examples' provided. The suggestions are presented as claims that need to be verified, but the verification is not provided. The reviewer is making general statements about the need for experiments and a new metric without providing concrete examples or logical reasoning to support these claims.", "helpfulness_rationale": "The suggestions made by the reviewer are relevant and point towards improvements that could benefit the authors. They highlight areas where the paper could be strengthened, such as with additional experiments and a new metric. While the suggestions are broad and lack specific details, they are still generally helpful in guiding the authors towards better practices. The reviewer is not providing negative feedback but rather constructive suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about computational complexity and requests a comparison. While the question is clear and asks for a direct action (comparison), it lacks the specificity needed to be fully actionable. The authors are asked to compare the proposed method with 'other methods' but are not given any context or guidance on which methods to consider. This vagueness makes it less immediately actionable, although it points to a relevant issue.", "grounding_specificity_rationale": "The review point refers to 'other methods' without specifying which ones. The authors cannot confidently determine which part of the paper or concept the reviewer is addressing. While the point clearly specifies what needs to be compared (computational complexity), it doesn't pinpoint the exact area within the paper where this comparison should be made. Therefore, while the grounding is somewhat implicit in the request for a comparison, it's not as precise as it could be.", "verifiability_rationale": "The review point contains a claim: 'Is it true that the proposed method requires much more computation than other methods?'. However, the claim is not supported by any evidence or reasoning within the review point itself. The reviewer is making this assertion, but doesn't provide any justification or comparison to back it up. Therefore, while there is a claim, it is not verifiable within the provided text.", "helpfulness_rationale": "The review point raises a relevant question about the computational cost of the proposed method and requests a comparison with other methods. This points to a potential area for improvement and provides a direction for further investigation. However, the lack of specificity in identifying 'other methods' and the absence of a concrete request for the type of comparison makes it less immediately helpful for the authors. They are left with a broad request without clear guidance on how to proceed."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point suggests areas for further analysis and exploration but does not explicitly state how the authors should modify their draft based on the findings.", "grounding_specificity_rationale": "The review point discusses general aspects like cost, incentives, and performance without explicitly identifying a specific section, table, figure, or unique element of the paper being addressed.", "verifiability_rationale": "The review point presents suggestions and questions rather than explicit claims that require verification or supporting evidence.", "helpfulness_rationale": "The review point offers insights into the system's behavior and potential roles but does not directly instruct the authors on how to improve their current draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'no significance testing is done' and provides a concrete suggestion of 'check the distribution and accounting for multiple comparisons' to address this. This indicates a clear and actionable point.", "grounding_specificity_rationale": "The reviewer identifies specific claims being questioned (ChatGPT vs. GPT4 performance and FeedME2 vs. PPO performance) and points to specific lines (line 486) as examples. They also specify the dBLEU scores and humeval scores, making the identified issue very specific.", "verifiability_rationale": "The reviewer makes a claim 'it's hard to say whether it is significant without proper testing' and supports it by stating 'no significance testing is done' and highlighting the 'minimal difference' between the models. This claim is supported by logical reasoning and observations.", "helpfulness_rationale": "The reviewer directly points out the lack of statistical significance testing, which is a clear weakness in the presented results. They also offer a constructive suggestion ('check the distribution and accounting for multiple comparisons') to address this, making the feedback both identifying a problem and providing a solution."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The comment identifies a problem ('partially difficult to follow') and suggests a solution ('should be revised' and 'extend the approach description'). This is explicit. However, the suggestion to 'extend the approach description' is vague and doesn't provide specific actionable steps, making it partially actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions '\u00a7 3', indicating they understand which part of the paper is being discussed. This is strong grounding. While the *content* of the difficulty is vague, the *location* is clear. Therefore, it's fully grounded.", "verifiability_rationale": "The comment states a claim ('The approach description (\u00a7 3) is partially difficult to follow') but doesn't provide external evidence or reasoning within this review point to *prove* it's difficult to follow. The suggestion to use extra space *implies* it's a problem, but doesn't offer direct evidence within this review. Therefore, it's 1.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper ('approach description (\u00a7 3) is partially difficult to follow') and suggests a concrete improvement ('should be revised' and 'extend the approach description'). This directly addresses a potential issue for the authors. Therefore, it's 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a lack of interpretive insights in the discussion and explicitly points out the absence of comparisons with stateoftheart methods not based on gyrostructures. However, it does not provide concrete actions or specific suggestions on how to address these issues. The action is implied but not directly stated.", "grounding_specificity_rationale": "The comment refers to the 'related discussion' generally and mentions 'manifoldbased learning' broadly. It does not explicitly identify a specific section, table, figure, or unique aspect of the paper where the lack of interpretive insights or comparisons is evident. Therefore, the grounding is weak.", "verifiability_rationale": "The comment contains a claim (the lack of interpretive insights and comparisons) but does not provide any evidence or reasoning to support why this omission is problematic. It does not explicitly reference external works or logical reasoning to justify the importance of these comparisons. Therefore, the verifiability is low.", "helpfulness_rationale": "The comment identifies potential weaknesses in the discussion and experimental evaluation. It suggests that the lack of interpretive insights and comparisons with nongyro methods could impact the assessment of the proposed approach. However, it does not provide specific, actionable recommendations for the authors on how to address these issues. The feedback is present but lacks concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The request for 'more evidence or analysis' and 'other key properties' is broad and lacks a clear, actionable step. The request is somewhat vague.", "grounding_specificity_rationale": "The reference to 'training effectiveness property of the dataset' and 'other key properties' is general and doesn't specify a particular section or detail. The reviewer doesn't pinpoint a specific part of the dataset or provide details about the properties they are interested in.", "verifiability_rationale": "The review point does not contain a claim or assertion that needs to be supported. It's a request for information, not a statement that something is true or false.", "helpfulness_rationale": "The review point requests more information without providing any specific suggestions or guidance on how to use that information. It's a question rather than a constructive critique or suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states they would like to see more details about the two baselines presented in Figure 5. This is a clear and direct request for information, making it 5. The reviewer also specifies *more details about the two baselines*, which is concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 5' and the 'two baselines presented in Figure 5' as the specific part of the paper they are referring to. This provides a clear and explicit grounding. Furthermore, the reviewer specifies that they want 'more details about the two baselines', adding to the specificity of the grounding.", "verifiability_rationale": "The reviewer's point is a request for more information rather than a claim, judgment, or suggestion. While the desire to understand Figure 5 is generally reasonable, the review itself does not provide any logical reasoning, common knowledge, or external references to support the desire for more details. Therefore, based on the provided definition of verifiability, this point is 1.", "helpfulness_rationale": "The reviewer's point is about providing more information to the authors. While this information is valuable, it is not framed as a critique of the work itself or a suggestion for a major improvement. It is more of an information request than a constructive critique or actionable suggestion."}
{"actionability_label": "None", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states they think section 3.2 can be eliminated, which is a direct action. However, they do not specify how to implement this action, such as providing a link to the code or a more detailed explanation of the GumbelSoftmax/Concrete distribution. The action is stated, but the implementation details are missing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 3.2' by name, which demonstrates strong grounding. They also provide a reason for eliminating the section, stating, 'I think that at this point readers can be presumed to know about the GumbelSoftmax/Concrete distribution.' This provides a specific reason for the suggestion.", "verifiability_rationale": "The reviewer makes a judgment about the content of section 3.2, stating, 'I think that at this point readers can be presumed to know about the GumbelSoftmax/Concrete distribution.' This constitutes a claim. However, the reviewer does not provide any evidence or justification for this claim. They do not cite external sources or provide a logical argument to support their assertion that readers are likely familiar with the GumbelSoftmax/Concrete distribution at that point in the paper.", "helpfulness_rationale": "The reviewer suggests eliminating section 3.2, which is a clear suggestion for a structural change. However, the review lacks specific details on why this section is redundant or unnecessary. The reviewer does not explain the perceived value or information density of section 3.2, making it difficult for the author to understand the benefit of its removal."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the improvements could be due to regularization effects and suggests an ablation study as a solution. This is an explicit action and a concrete suggestion for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'regularization effects,' 'finetuning is performed for 10 epochs,' and 'without earlystopping' as potential reasons for the observed improvements. These are specific details about the experimental setup and methodology. The reviewer also implies that the high variance in GLUE finetuning without validation suggests a lack of clarity in the identified issue.", "verifiability_rationale": "The reviewer provides a justification for their concern by stating that 'the finetuning on GLUE without validation earlystopping usually has very high variances.' This provides a logical reasoning and a reference point (GLUE finetuning without validation) to support their claim. The reviewer also suggests 'proper ablation studies are needed' as a solution, which is a specific and actionable suggestion.", "helpfulness_rationale": "The reviewer directly addresses a potential flaw in the methodology (distillation vs. regularization) and provides a clear and actionable suggestion for improvement (ablation studies). This is 5 for the authors as it directly points to a potential issue and offers a concrete next step."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "Both suggestions are explicit, stating the action to be taken. The addition of performance on word similarity and sentence translation tasks is a concrete action with clear implications for evaluating the framework. Similarly, the suggestion to add experiments on morphologically rich and lowresource languages is a concrete action with clear implications for the robustness of the framework.", "grounding_specificity_rationale": "Both suggestions have weak grounding. While the terms 'word similarity and sentence translation tasks' and 'morphologically rich languages' and 'lowresource languages' are descriptive, the reviewer cannot confidently pinpoint the exact sections, tables, or figures in the paper that these tasks or languages correspond to. The reviewer would need to search for these terms or understand their relevance to the existing content to identify the specific parts being addressed.", "verifiability_rationale": "Both suggestions contain claims that are 3. For the word similarity and sentence translation tasks, the claim is that these evaluations would 'lend more credibility' and are 'standard benchmarks'. For the morphologically rich and lowresource languages, the claim is that these additions would be 'good to have' for evaluating robustness. While the claims lack specific references, the reasoning based on common knowledge of NLP tasks and language diversity supports the suggestions.", "helpfulness_rationale": "Both suggestions are 5. The addition of performance on standard NLP tasks like word similarity and sentence translation directly addresses a potential weakness in the framework's evaluation. Similarly, including experiments on diverse languages like Finnish, Hebrew, and lowresource languages would significantly enhance the robustness and generalizability of the framework's evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks two questions: 'how node importance can be used' and 'why the paper doesn't include the 1shot paper setting'. While the questions are clear, the reviewer doesn't provide specific details or examples within the review point itself to demonstrate how node importance is implemented or how the 1shot setting is handled. The questions are somewhat general.", "grounding_specificity_rationale": "The reviewer asks about the use of node importance in the 1shot setting and the absence of a 1shot experiment. While they mention the 1shot setting, they don't explicitly point to a specific section or element of the paper that discusses it. The connection to related works like RALE is implied but not explicitly stated as grounding the 1shot aspect to the RALE paper. The questions are about the *mechanism* and the *reasoning*.", "verifiability_rationale": "The reviewer makes claims about the paper's lack of explanation regarding the use of node importance in the 1shot setting and the absence of a 1shot experiment. These claims are valid based on the provided excerpt. The paper could benefit from clearer explanations and justifications for these aspects.", "helpfulness_rationale": "The reviewer has identified two key areas where they expect more information: how node importance is used in the 1shot setting and why the paper doesn't include a 1shot experiment. The paper doesn't explicitly address these points in the provided excerpt, making the reviewer's questions valid and pointing to areas for improvement in the paper's presentation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states \"There should be more discussions\" regarding two specific areas: \"why LLMs struggle at finegrained hard constraints\" and \"how to address these problems.\" This directly points to actions the authors should take. The reviewer is not just pointing out a problem but suggesting a concrete next step. The request is clear and identifies the scope of the discussion. Therefore, the reviewer is asking the authors to perform a specific action: engage in a discussion about a defined topic.", "grounding_specificity_rationale": "The review point explicitly mentions \"finegrained hard constraints.\" This is a specific technical term within the context of LLM limitations. The reviewer is directly referencing a specific aspect of the problem. The grounding is strong because the term is literal and specific. The reviewer is also implicitly asking for a discussion about the *cause* and *solution* related to this specific type of constraint. While not providing concrete examples within the review point itself, it clearly pinpoints the area of interest. Therefore, the grounding is fully grounded.", "verifiability_rationale": "The review point itself is not a claim that can be verified. It's a suggestion for further discussion. There's no logical reasoning, common knowledge, or external references provided within the review point itself. It's a prescription for the authors to explore a specific area, rather than a statement that can be proven true or false based on existing information. Therefore, the verifiability is 1.", "helpfulness_rationale": "The review point identifies a relevant problem area (LLM limitations with constraints) and suggests a direction for improvement (more discussion on the cause and solution). While it doesn't provide specific implementation details or evidence, it clearly points to a valuable area for the authors to investigate and potentially address. This sets a clear goal for the authors' future work. Therefore, the review point is helpful in guiding the authors towards further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that 'little insights are given about why do we need to do selfsupervised learning on this kind of data.' This directly identifies an actionable gap in the paper. While it doesn't specify *how* to address this, it clearly points to an area for improvement. The reviewer suggests investigating the necessity of this approach, which is a concrete action the authors can take.", "grounding_specificity_rationale": "The review point explicitly refers to 'selfsupervised learning on this kind of data' which is a specific part of the paper. The reviewer can accurately pinpoint the section being addressed, indicating strong grounding. However, the point focuses on the *lack* of insights *why* this is needed, which is a general area of concern rather than a specific issue within that section. Therefore, while grounded, it's not specific about the nature of the problem.", "verifiability_rationale": "The review point contains a claim: 'little insights are given about why do we need to do selfsupervised learning on this kind of data.' This is a statement of a deficiency. However, the point does not provide any evidence, examples, or references to support this claim. It simply states the problem without offering any justification or context. Therefore, the claim is not wellsupported.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper: the lack of justification for using selfsupervised learning on the specific data. This is a valuable point for the authors to consider. While the point doesn't offer a solution, it highlights a crucial area for further investigation and potentially adjustment of the approach. By pointing out this missing justification, the reviewer guides the authors to understand the *why* behind a key decision, which is important for improving the work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "One part of the review point is implicit, as the reviewer doesn't explicitly state how to improve the link between IP and equations. The reader would need to infer that they should try to understand the connection better. The other part is explicit, stating that subfigures in Figs 3 and 4 should have labels, not just be mentioned in the captions. This part is actionable as it clearly states what needs to be done.", "grounding_specificity_rationale": "The reviewer doesn't explicitly state which equations or terms are being referred to when mentioning the link with IP, making it weakly grounded. However, the reviewer explicitly mentions 'subfigures in Figs 3 and 4' and states they should have labels within the figures, making this part specifically grounded.", "verifiability_rationale": "Neither part of the review point makes a claim that needs verification. The first part is a suggestion for improvement, and the second part is a request for a specific formatting change. There are no claims that require logical reasoning, common knowledge, or external references to be considered verifiable.", "helpfulness_rationale": "The review point provides actionable feedback on how to improve the clarity of subfigures, which is directly helpful to the author. However, the suggestion about the link between IP and equations is less specific and requires the author to infer the intended improvement, making it less helpful overall."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need to average results over multiple runs, which is a direct and clear action to improve the statistical significance of the findings. This action is welldefined and directly addresses the issue of variability in results.", "grounding_specificity_rationale": "The reviewer's comment is 1 in a specific part of the paper. They are suggesting a general improvement to the experimental process rather than addressing a specific issue within a figure, table, or section.", "verifiability_rationale": "The reviewer's comment does not contain a claim. It is a suggestion for improvement rather than a statement that requires verification. Therefore, it is classified as 'X' for X.", "helpfulness_rationale": "The reviewer's suggestion to average results over multiple runs is a valid point that can improve the reliability of the findings. However, it is a relatively minor suggestion that does not directly address any specific weaknesses in the current draft. Therefore, it is 3 in identifying a potential flaw in the experimental design, but it does not provide a concrete fix for the current work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'there is no analysis on a seemingly important (see SimCLRv2 and other recent papers that show that) part of that approach, ie the projection head.' This clearly identifies an action the authors should take (analyze the projection head) and is concrete in its suggestion.", "grounding_specificity_rationale": "The reviewer explicitly names 'the projection head' as the missing part of the SimCLR method. This is a clear and specific reference, making it fully grounded. Furthermore, the reviewer explains *why* this is important by referencing 'recent work suggesting that' and mentioning 'SimCLRv2 and other recent papers'. This provides context and justification for the importance of the projection head, making it highly specific.", "verifiability_rationale": "The reviewer makes a claim: 'there is no analysis on a seemingly important (see SimCLRv2 and other recent papers that show that) part of that approach, ie the projection head.' This claim is supported by the reviewer stating that 'recent work suggests that'. However, the reviewer does not provide specific citations or detailed explanations to back up this claim within the review point itself. The justification is based on the reviewer's awareness of recent work, not explicitly stated within the review point's content.", "helpfulness_rationale": "The reviewer identifies a specific area (the projection head) in the SimCLR method that lacks analysis. By pointing this out, the reviewer provides a clear direction for the authors to improve their work. This is a constructive suggestion rather than just a criticism."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies the issue of hidden observations and conclusions but does not explicitly state how the authors should address this. It implies a need for highlighting but lacks concrete steps. The action is implicit rather than explicit.", "grounding_specificity_rationale": "The comment refers to the 'experimental section' generally, without specifying a particular subsection, table, figure, or unique element. This makes the grounding weak as the authors cannot confidently determine the exact area being addressed.", "verifiability_rationale": "The comment states that the observations and conclusions are important and suggests highlighting them. However, it does not provide any evidence, logical reasoning, or external references to support this claim. The claim is presented without sufficient justification.", "helpfulness_rationale": "The comment points out a valid concern (hidden observations) and suggests a potential improvement (highlighting). However, it lacks specific guidance on how the authors should implement this suggestion. The comment identifies a need for action but does not provide concrete steps, making it less helpful than a comment with more specific guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states \"it would be better to provide some ablation experiments of these tricks\". This is a direct and clear indication of an action the authors should take. The phrase \"these tricks\" further clarifies the action being suggested, making it concrete.", "grounding_specificity_rationale": "The comment explicitly refers to \"Section 3.4\" and mentions \"ablation experiments of these tricks\". This demonstrates a high level of grounding as the authors can accurately pinpoint the section and the nature of the suggested experiments. The use of \"these tricks\" further aids in identifying the specific aspect being addressed.", "verifiability_rationale": "The comment contains a claim in the form of a suggestion: \"it would be better to provide some ablation experiments of these tricks\". This is a statement that requires justification. However, the comment does not provide any logical reasoning, common knowledge, or external references to support this suggestion. It simply states what the reviewer believes would be beneficial.", "helpfulness_rationale": "The comment provides a clear suggestion for improvement: conducting ablation studies on the 'tricks' mentioned in Section 3.4. This directly points towards a concrete action the authors can take. While the comment doesn't guarantee the outcome of these experiments or provide specific examples of the 'tricks', it offers a specific direction for further investigation. The reviewer is not questioning the validity of the suggestion itself, but rather pointing out the lack of empirical validation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their intention to ask a question about the performance of their KDE method on datasets with a nonbinary decision space and suggests an experiment to compare it with another method. This constitutes an explicit action with a clear goal.", "grounding_specificity_rationale": "The reviewer mentions 'decision space' and 'binary?', which are specific terms related to the classification problem. However, they do not explicitly identify the specific part of the paper or dataset they are referring to, nor do they provide details about the nature of the nonbinary decision space. The reference to '44' helps ground the context but doesn't fully specify the scope of the request.", "verifiability_rationale": "The reviewer is asking a question about a potential limitation of their method and suggesting an experiment to investigate it. This is a request for information rather than a definitive claim that can be immediately verified or falsified. There is no explicit claim about what should be the case or what the outcome should be.", "helpfulness_rationale": "The reviewer is raising a valid point about a potential limitation of their approach and suggesting an experiment to address it. This is a relevant and potentially helpful feedback for the authors. However, the lack of specificity in the request makes it less immediately actionable and impactful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point lacks explicit and concrete actions for the authors. While it identifies areas for improvement, it doesn't specify *how* to change the SR model's capacity or *why* it affects the FID. Similarly, it mentions unexpected artifacts due to pipelining but doesn't guide the authors on how to address them. The missing details about the SR model's capacity are also not actionable. The reviewer points out issues but doesn't provide clear steps for the authors to take.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or model being discussed. The reviewer refers to 'the SR model's capacity' and 'the FID' generally, without specifying which SR model or where the FID is reported. Similarly, 'the proposed method is pipelining' is a general statement without pointing to a specific section describing the pipelining. The lack of specificity makes it difficult for the authors to pinpoint the exact issue being addressed.", "verifiability_rationale": "The review point presents observations as facts without providing any supporting evidence or justification. The reviewer states that 'the impact of the SR model affects the FID' and 'there are some unexpected artifacts' without explaining *why* these things happen. There is no logical reasoning or references provided to back up these claims. The statements are presented as discoveries rather than questions or suggestions for improvement.", "helpfulness_rationale": "The review point is not particularly helpful to the authors. While it identifies areas where the work could be improved, it does not offer concrete solutions or guidance on how to address the issues raised. The reviewer simply states the problems (impact of capacity, unexpected artifacts, missing details) without suggesting any actions or improvements. The feedback is descriptive rather than prescriptive."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the purpose of Proposition B.1, which can be considered an explicit action. They also point out a clear missing element (the 'proof'), which implies an actionable next step. While the reviewer doesn't provide a detailed explanation of *why* the proof is missing, the identification of the missing proof itself is a concrete action. The reviewer also implies that the proof is missing, which is a concrete action that needs to be applied.", "grounding_specificity_rationale": "The reviewer explicitly names 'Appendix A' and 'Proposition B.1' in their review point. This is a clear indication of full grounding. They also specify the *issue* with Proposition B.1, which is the unclear purpose and the missing proof. This specificity is quite high as the paper section and the exact problem are identified.", "verifiability_rationale": "The reviewer makes a claim that 'this is a wellknown concept' and 'the authors\u2019 socalled 'proof' is missing. The claim about the missing proof requires verification by checking Appendix B. The claim about the proof being 'wellknown' is less directly verifiable, as it's a general statement. However, the core of the point, the missing proof, is verifiable. The reviewer also provides a suggestion ('missing proof') which directly addresses the identified issue.", "helpfulness_rationale": "The reviewer provides a clear weakness in the paper: the unclear purpose of Proposition B.1 and the missing proof. They also offer a concrete suggestion: to include the proof. This directly helps the authors improve their draft by addressing a specific issue and providing a clear direction for improvement. The reviewer's feedback is directly actionable and addresses a specific problem."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the *lack* of *necessary* experiments. While the *type* of experiments (comparison, ablation, hyperparameter) is implicitly suggested, the *action* of conducting these experiments is not explicitly stated or recommended. The reviewer identifies a missing element but doesn't fully specify what needs to be done.", "grounding_specificity_rationale": "The reviewer makes a general statement about the *lack* of *additional* experiments. They do not specify a particular section, table, or unique aspect of the paper where these experiments are missing. The comment is broad and doesn't pinpoint the location of the deficiency.", "verifiability_rationale": "The reviewer states that the paper lacks *additional necessary experiments*. This is a claim that there is a deficiency. However, the reviewer does not provide any evidence, justification, or reasoning to support this claim. They do not explain *why* these experiments are necessary or *where* they should be conducted.", "helpfulness_rationale": "The reviewer identifies a clear area for improvement: the lack of necessary experiments. This directly impacts the reproducibility and completeness of the work. While the reviewer doesn't specify *which* experiments are needed, the identification of this gap is valuable information for the authors. It sets a direction for them to focus their efforts on conducting additional studies."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a vulnerability related to the approximations and suggests a way to address it by expanding the discussion of the feasible set. This constitutes an explicit action. The grounding of this action is the specific mention of 'the assumption of attacks being in the feasible set only in lines 107110', which clearly identifies the area needing improvement. The action is also concrete as the reviewer proposes a specific improvement: 'expand to reassure the readers that it is not a real concern'.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the assumption of attacks being in the feasible set only in lines 107110' as the specific part of the paper being addressed. This is a literal mention, indicating strong grounding. The comment also clearly specifies what needs to be addressed: 'expand to reassure the readers that it is not a real concern'. This specificity is quite detailed and directly relates to the identified approximation.", "verifiability_rationale": "The reviewer makes a claim by suggesting 'expand to reassure the readers that it is not a real concern'. This claim is supported by the general understanding that approximations are necessary and that the specific assumption might be a limitation. While not a direct citation, the reasoning is logical: if the feasible set is too restrictive, it could limit the applicability of the results derived from the approximations. This provides sufficient verifiability based on common knowledge and logical reasoning.", "helpfulness_rationale": "The reviewer directly addresses a potential weakness in the paper (the approximations and the feasible set assumption) by suggesting a concrete improvement: expanding the discussion to alleviate concerns. This suggestion is actionable and directly targets a potential area of confusion for the readers. By addressing this, the reviewer is providing valuable guidance for the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses an opinion about the paper's contribution and the model's approach but does not provide explicit or concrete suggestions on how to improve them. While it implicitly suggests the authors should consider these aspects, it lacks the necessary detail to be actionable.", "grounding_specificity_rationale": "The reviewer refers to the 'entire paper' and makes general statements about the 'contribution' and 'proposed model' without specifying a particular section, table, or figure. The reference to the paper is broad and lacks precision.", "verifiability_rationale": "The review point makes a statement about the 'somewhat limited' contribution and the 'incremental' approach of the model. This is a declarative statement expressing an opinion rather than a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support these statements.", "helpfulness_rationale": "The review point is a general comment about the paper's overall contribution and the model's approach. While it provides some context, it lacks specific, actionable feedback or suggestions on how the authors should improve their work. It doesn't pinpoint a specific issue or offer concrete guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a *possible* improvement ('probably is needed') but doesn't explicitly state what action should be taken. While it points to a *specific area* ('some pretty \"old\" benchmarks'), the exact nature of the problem and the required action are not clearly defined.", "grounding_specificity_rationale": "The review point mentions 'some pretty \"old\" benchmarks,\" which provides some grounding by identifying a specific part of the paper (benchmarks) and even a specific characteristic of them (\"pretty old\"). However, it doesn't explicitly identify a unique section, table, figure, or element within the paper. The suggestion is also vague about what specific problems exist in these benchmarks.", "verifiability_rationale": "The review point contains a claim: \"more careful analysis probably is needed, especially for some pretty \"old\" benchmarks that the data might have been indirectly seen by the model via the \"data curation\" process.\" This claim is supported by logical reasoning ('the model demonstrate impressive performance on many benchmarks (setting new SoTA scores)') and the mention of \"data curation,\" which implies potential indirect data exposure. However, the suggestion itself ('more careful analysis') is vague and doesn't provide specific examples or guidance on what analysis to perform.", "helpfulness_rationale": "The review point raises a valid concern about the model's performance on older benchmarks and suggests a more thorough analysis. This directly addresses a potential limitation of the proposed model and offers a suggestion for improvement, making it a helpful feedback point for the authors."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "2 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer identifies a problem (inconsistent datasets) and suggests comparing metrics, which is a form of action. However, the reviewer does not explicitly state which metrics should be compared or provide detailed guidance on how to implement this action. The action is implied but not fully specified.", "grounding_specificity_rationale": "The reviewer identifies the problem (inconsistent datasets) but does not explicitly point to a specific part of the paper where this issue should be addressed. While the problem is clearly stated, the lack of a specific paper reference makes the grounding weak. The reviewer mentions 'Figure 4 and Figure 5' which are specific parts of the paper, but the issue is the *lack of consistency* across methods, not a specific figure within a method's description.", "verifiability_rationale": "The reviewer makes a claim about the inconsistency in datasets and metrics. They support this claim by pointing to Figure 4 and Figure 5. However, the reviewer does not provide any logical reasoning, examples, or external references to back up this claim. The verifiability is limited to the observation of the inconsistency itself, without further explanation or evidence.", "helpfulness_rationale": "The reviewer states a concern about the inconsistent evaluation and suggests the authors should be aware of it. This is a helpful comment as it points out a potential issue in the experimental design. However, the reviewer does not ask for specific solutions or provide detailed guidance on how to address this issue. The helpfulness is limited to identifying a problem without offering concrete solutions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4: 3", "actionability_rationale": "The review points out a lack of specific instructions on what to do. It criticizes the comparison but doesn't explicitly state how the comparison is unfair or what needs to be done to address it. While it identifies the issue, the action is implicit, making it 2.", "grounding_specificity_rationale": "The authors can identify the general area (experimental results, proposed method). They mention the comparison and the need for prior information, which points to specific aspects of the experimental setup. However, the specificity is limited to explaining why the comparison is potentially unfair and suggesting a way to address it, making it weakly grounded and somewhat specific.", "verifiability_rationale": "The comment contains a claim (the unfair comparison) and provides a reason for it (the need for two models). While the justification is present, it could be more detailed, making it 3.", "helpfulness_rationale": "The comment is relevant and provides guidance on improving the experimental setup. It highlights a potential issue and suggests a modification, which can guide the authors in refining their work. While it's not a direct solution, it's helpful in identifying areas for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly suggests adding a new type of experiment (collaborative games) to the existing experiments. This is a clear and direct action that the authors can readily implement. The suggestion is not just about identifying a missing feature but proposing a specific change to the experimental setup.", "grounding_specificity_rationale": "The review point mentions 'collaborative games' but does not specify where in the paper or experiments this suggestion should be applied. It lacks the precision needed to pinpoint the exact location, making it difficult for the authors to understand the intended impact. While it specifies the *type* of game, it doesn't indicate the *section* or *experiment* where this suggestion is relevant.", "verifiability_rationale": "The review point presents a suggestion for future experiments (improving the paper by adding collaborative games) and a related statement about exploring both collaborative and competitive settings. While it contains a claim (improving the paper), it doesn't provide any logical reasoning, common knowledge, or external references to support why the current experiments are inadequate or insufficient. It's a suggestion, not a critique or verification of the existing work.", "helpfulness_rationale": "The review point suggests adding a new type of experiment (collaborative games) to the existing experiments. While this points towards a potential improvement, it doesn't directly address any specific weaknesses or shortcomings in the current draft. It's more of a forwardlooking suggestion for future research rather than a critique or improvement of the existing work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the problem: 'experimental settings for Figure 1 to Figure 9 are totally missing'. This directly identifies the missing information and provides a clear action for the authors to take: identify and add the experimental settings. The action is also concrete as it specifies 'experimental settings' which tells the authors exactly what information is needed.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1 to Figure 9', which directly and accurately identifies the specific parts of the paper being referred to. This is a literal mention of the sections, making the grounding fully grounded. The specificity is also high as the comment clearly identifies the exact figures being discussed.", "verifiability_rationale": "The comment contains a claim: 'they are totally missing, which makes them hard to be convincing'. This is a judgment or opinion about the impact of the missing information. The verifiability is somewhat implicit. While the reviewer doesn't provide specific examples of *why* the missing information makes the figures unconvincing, the logical connection is clear: Without knowing the experimental setup, it's difficult to interpret what the figures *mean*. The reviewer implies the importance of experimental settings for the interpretation of figures.", "helpfulness_rationale": "The comment is 5 because it clearly identifies a significant issue: the lack of experimental details hindering the interpretation of figures. The reviewer directly points out the *consequence* of this missing information: the figures are not convincing. Furthermore, the reviewer explicitly states *what is missing* in the experimental settings: 'experimental settings'. This information is directly actionable for the authors. They know *what information they are missing* and *why* it's important. While the reviewer doesn't provide specific examples of *what* is missing within the experimental settings, the *category* of missing information is clear, making it a valuable piece of feedback."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer raises a point about potential overlap with existing parameter isolation methods that leverage sparsity. While the paper introduces a new method, the specific mechanism by which it avoids hindering new task knowledge acquisition isn't explicitly stated as an actionable step. The reviewer's question implies a lack of clarity on how the proposed method differentiates itself from existing approaches in this regard. The action is implied (addressing the sparsity issue), but the concrete steps and evidence are missing.", "grounding_specificity_rationale": "The reviewer's question is about a specific aspect of the method: how it avoids impeding the learning of new task knowledge *specifically* by leveraging sparsity. While the paper's focus is on sparsitybased parameter isolation, the *specific mechanism* of its novelty isn't explicitly stated. The paper mentions avoiding hindering new task knowledge, but the details of how it achieves this, especially concerning sparsity, are not clearly grounded in the text.", "verifiability_rationale": "The reviewer's point is a claim: 'some parameter isolation methods are specifically tailored to leverage this sparsity.' The paper attempts to address this by proposing a new method. However, the *specific way* the proposed method avoids this overlap isn't fully detailed or verifiably supported. The claim is present, but the supporting evidence (the proposed method's specific mechanism) is not fully elaborated to make it 5.", "helpfulness_rationale": "The reviewer's question directly addresses a lack of clarity in the paper regarding how the proposed method avoids hindering the learning of new task knowledge, especially in light of existing sparsitybased methods. This question is a helpful point because it highlights a need for the authors to provide a clearer explanation of the novelty and distinctiveness of their approach. The information is relevant and directly addresses a potential ambiguity in the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the regularization term is 'adhoc' and provides a clear rationale for why this is the case, suggesting specific alternatives. The reviewer identifies the components of the regularization (mean and standard deviation) and proposes why they might not be the best choice. This is an explicit statement of a problem and a clear suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The reviewer directly refers to the 'regularization term' and its components, 'mean' and 'standard derivation', which are specific parts of the paper. This explicit identification demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer does not present a claim that can be definitively verified. Instead, they are suggesting alternatives to the current regularization method. While the grounding is clear, the suggestion itself is not a verifiable claim, making it underspecific in terms of verifiability. The grounding is present, but the specific suggestion lacks external references or logical reasoning to justify why the median is a better choice.", "helpfulness_rationale": "The reviewer provides a clear and actionable critique of the regularization term, explaining why it is adhoc and suggesting specific alternatives. This directly addresses a potential weakness in the paper and offers concrete guidance for improvement, making it 5."}
{"actionability_label": "3.5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for comparisons with existing fairness algorithms and clearly indicates the purpose is to enhance the paper and position the framework. This indicates an explicit action. However, the reviewer does not specify *which* algorithms to compare or *how* the comparison should be conducted, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'existing fairness algorithms' generally, without specifying a particular section, table, figure, or unique element in the paper. This indicates weak grounding as the reviewer does not point to a specific location within the paper. Furthermore, the comment lacks specificity regarding *which* algorithms to compare and the experimental setup for the comparison.", "verifiability_rationale": "The reviewer makes a claim about the benefits of benchmark comparisons. However, they do not provide any supporting evidence, reasoning, or references to back up this claim. The reviewer simply states their desire for such comparisons without explaining why they believe it would be beneficial or providing any justification for its expected impact.", "helpfulness_rationale": "The reviewer's comment identifies a potential improvement to the paper by suggesting benchmark comparisons. While this is a relevant suggestion and addresses a potential gap, the lack of specificity and justification makes it somewhat vague and underspecified. The reviewer does not explain *why* these comparisons are necessary or beneficial, or how they would be implemented. This lack of detail reduces the potential helpfulness of the comment."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action: 'The authors should discuss the iteration cost (computational budge) of the proposed method. It will be great if the authors discuss the iteration cost of all related methods.' This action is concrete, as it directly points to a specific aspect of the method and suggests a direct action. While it doesn't provide specific details on *how* to discuss the cost, it clearly identifies the area for improvement. Therefore, it is actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'the iteration cost (computational budge) of the proposed method' and 'the iteration cost of all related methods'. This directly identifies the specific part of the paper being addressed, making the grounding fully grounded. Furthermore, the comment specifies what needs to be addressed: 'discuss' the iteration cost. The comment also clearly identifies the scope: 'proposed method' and 'related methods'. Therefore, the grounding is fully specific.", "verifiability_rationale": "The comment contains a claim: 'The authors should discuss the iteration cost (computational budge) of the proposed method. It will be great if the authors discuss the iteration cost of all related methods.' This claim is supported by logical reasoning, as it suggests a relevant analysis for the method. While it doesn't provide external references, the suggestion itself is a logical point for improvement. Therefore, the claim is 3 as it is logically supported but lacks external references.", "helpfulness_rationale": "The review point directly points out a missing element in the authors' work \u2013 the discussion of iteration cost. It provides a clear suggestion for improvement by stating that this discussion should be included for the proposed method and all related methods. This is a constructive suggestion that guides the authors on what to add to their paper. While it doesn't critique the authors' work, it offers a concrete direction for improvement, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit suggestions for the authors to report average results over multiple runs, discuss decision boundaries in Sec. 3.1, and identify information in specific subfigures of Fig. 9 in Sec. 3.3. These are all direct instructions on what actions the authors should take to improve their work. The actions are clear and specific.", "grounding_specificity_rationale": "The review point explicitly mentions 'Sec. 3.1' and 'Fig. 9 middle and right' in Sec. 3.3, directly pointing to specific sections and figures within the paper. This allows the authors to directly locate the relevant information and understand the context of the suggestions.", "verifiability_rationale": "The review point makes claims that can be verified logically. For example, the suggestion to report averages is based on standard experimental practices. The observation about results being close together is a logical deduction from the presented data. The suggestion to discuss decision boundaries in Sec. 3.1 is based on the nature of toy datasets and the goal of understanding model behavior. The request for information in Fig. 9 is a logical next step for the authors to take.", "helpfulness_rationale": "The review point is very helpful as it directly addresses potential weaknesses or areas for improvement in the authors' work. The suggestions are clear, actionable, and logically derived from the context of the paper. The authors are guided on what to add, what to discuss, and what to explore in their results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the limitation: 'The new proposed model can be used only with a small number of dimensions because of the curse of dimensionality imposed by the core tensor C.' This is an explicit statement of a constraint. Furthermore, the reason for this limitation is clearly stated as 'because of the curse of dimensionality imposed by the core tensor C', providing a concrete explanation of why this limitation occurs. The authors know exactly what the limitation is and how to apply this information.", "grounding_specificity_rationale": "The review point explicitly mentions 'the core tensor C' as the specific part of the model being addressed. This is a literal mention of a specific element within the model. While the reviewer does not explicitly state the *function* of the core tensor C, the mention itself grounds the comment to a specific part of the paper. The comment is not vague in identifying the referenced part.", "verifiability_rationale": "The review point contains a claim: 'The new proposed model can be used only with a small number of dimensions'. This claim is supported by the reasoning: 'because of the curse of dimensionality imposed by the core tensor C'. While a citation might be ideal to back up the 'curse of dimensionality', the reasoning provided is a generally accepted concept in machine learning and data analysis. The claim is supported by a logical explanation.", "helpfulness_rationale": "The review point is helpful because it identifies a clear limitation of the proposed model: its restriction to a small number of dimensions due to the curse of dimensionality. This information is valuable for the authors to understand the practical constraints of their model and potentially explore alternative approaches or modifications. The reviewer provides a specific reason for this limitation, making it actionable for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a potential issue ('may lead to negative transfer') and provides a specific example ('TransformerM performs poorly...'). It also suggests a possible explanation ('contradictory to the description...'). This suggests an explicit action: the authors should investigate if pretraining on the homolumo gap is negatively impacting their model's performance on other tasks. The action is also concrete as it points to investigating the performance on specific tasks.", "grounding_specificity_rationale": "The review point explicitly mentions the 'generalpurpose neural network model' and focuses on the potential issue arising from 'supervised pretraining based on the prediction of homolumo gap'. It also specifies the 'downstream experiments' and mentions 'TransformerM' and the 'QM9 dataset' as examples. This strong mention of specific elements indicates good grounding.", "verifiability_rationale": "The review point makes a claim ('Supervised pretraining...may lead to negative transfer') but does not provide any evidence or citations to support this claim. It presents it as a potential issue based on an example. Therefore, it is not 5. It also does not consist solely of factual statements that require no verification.", "helpfulness_rationale": "The review point identifies a potential problem ('may lead to negative transfer') and suggests a direction for investigation (' TransformerM performs poorly...'). It also offers a possible explanation ('contradictory to the description...'). While it doesn't provide a complete solution, it points to a likely area where the authors might be facing issues and suggests a potential cause. Therefore, it is 3 in guiding the authors to investigate their model's performance on other tasks."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer correctly points out that the authors state on lines 8082 that the center correlation was not insightful for discriminating model defenses. However, the same authors then use this metric in Figure 4 A&B. This implies an implicit action or suggestion: the authors are drawing attention to the fact that the center correlation *is* insightful in this specific context, despite their initial statement. The action is implicit because the authors don't explicitly state *why* the metric was chosen for Figure 4 after stating it's not insightful elsewhere. The suggestion is that the reader should pay attention to the use of the center correlation in Figure 4. The lack of explicit connection makes the action somewhat vague on how to apply it.", "grounding_specificity_rationale": "The reviewer's question highlights a lack of grounding specificity. The authors state on lines 8082 that the center correlation was 'not insightful for discriminating model defenses.' This statement is 1 because the authors do not explicitly identify the specific part of their work they are referring to. They could have said, for example, 'Not insightful for discriminating model defenses in our experiments' or 'Not insightful for discriminating model defenses as shown in section 3.2.' The statement is general and doesn't pinpoint the exact context. Furthermore, the reviewer's question about the usefulness of the metric in Figure 4 A&B is not clearly specified within the statement. The statement only addresses the lack of insight *elsewhere*, not *here* in Figure 4. The lack of specificity makes it difficult to understand what exactly is being claimed and how it relates to the figure.", "verifiability_rationale": "The reviewer's question about the authors' statement on lines 8082 and its use in Figure 4 raises concerns about verifiability. The authors make a claim: 'the center correlation was not insightful for discriminating model defenses.' This is a claim because it expresses an opinion or judgment about the metric's usefulness. However, the paper does not provide sufficient justification for this claim. There is no logical reasoning, common knowledge, or external references to support why the center correlation would be considered unhelpful for this purpose. The lack of justification makes the claim somewhat underjustified. The reviewer's subsequent question about the usefulness of the metric in Figure 4 further highlights the lack of verifiability, as the paper doesn't explicitly connect the initial statement to the visual representation in the figure.", "helpfulness_rationale": "The reviewer's question about the authors' statement on lines 8082 and its use in Figure 4 makes the review point 3. It forces the authors to clarify their reasoning and provide justification for their use of the center correlation. This interaction has the potential to improve the clarity and consistency of the paper. However, the review point itself doesn't directly provide actionable feedback to the authors on what to do. It points out a potential lack of clarity, which is helpful but not a direct prescription for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states an opinion ('not particularly strong') but lacks explicit instructions on how to improve the contribution. It references characteristics of the contribution ('weak,' 'unpractical') but doesn't specify how to make it better. While it identifies a problem, it doesn't tell the authors what to do about it.", "grounding_specificity_rationale": "The reviewer mentions the 'theoretical contribution' generally. While they identify a specific area ('theoretical contribution'), the issue ('weakness') is not detailed enough to be fully specific. The reviewer doesn't pinpoint a specific section, table, figure, or unique element of the paper related to this weakness.", "verifiability_rationale": "The review point contains a claim ('the theoretical contribution is not particularly strong') and provides reasoning and implicit references to support it. The reviewer explains why they believe the contribution is weak and unpractical, referencing 'weak, unpractical bound' and 'the proof...does not provide particular mathematical novelty.' This constitutes a claim being made and is supported by reasoning and implicit references to the nature of the contribution.", "helpfulness_rationale": "The review point is critical and constructive, pointing out specific shortcomings of the theoretical contribution. While it doesn't offer direct, actionable steps, it identifies a significant weakness and encourages the authors to reflect on the practical implications and mathematical rigor of their contribution. This type of feedback is generally helpful for guiding further development."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states weaknesses and suggests improvements, directly addressing the 'picking' step and the CIFAR experiments. The suggestions are clear and point towards specific actions the authors should take, such as adding an ablation for the picking step and using more baselines. While the suggestions are present, they are somewhat highlevel and could be more concrete in terms of specific implementation details. The reviewer also points out a potential methodological flaw, which, while not an action, highlights a lack of clarity.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'picking' step and states that it is not ablated. They also mention the CIFAR experiments and the limited baselines used. The reviewer points out that the comparison on CIFAR is not convincing and specifically mentions that only one approach (DEN) is compared. The reviewer also states that it is unclear if DEN is correctly used/evaluated. In each case, the reviewer identifies the specific aspect of the paper being addressed and states what is missing or unclear. Therefore, the grounding is explicit and specific.", "verifiability_rationale": "The review point does not contain any claims that require verification or justification. It is a critique of the paper's content and experimental setup. Therefore, it does not meet the criteria for verifiability, which involves supporting a claim with logical reasoning, common knowledge, or external references. The reviewer is stating observations and suggestions, not making assertions that need to be proven.", "helpfulness_rationale": "The review point provides several concrete suggestions for the authors to improve their draft. The reviewer suggests adding an ablation for the 'picking' step, comparing against more baselines in the continual learning literature, and ensuring the correct implementation of the baseline (DEN). These suggestions are actionable and directly address the identified weaknesses. The reviewer also points out a potential methodological flaw ('unclear if DEN is correctly used/evaluated'), which is valuable feedback for the authors to consider. The suggestions are clear and specific, making them 5 for the authors to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests removing the 45degree line and adding a thin gray diagonal line to the plot. This is a clear, direct action with no ambiguity about what needs to be changed. The suggestion is concrete, specifying the *type* of line and its *general* location (above/below diagonal).", "grounding_specificity_rationale": "The reviewer refers to the visual element of the plot and the specific annotation ('above/below diagonal'). While they don't explicitly name a section or table, the context strongly implies a specific part of the plot. The reviewer also clearly specifies what should be added ('a thin gray diagonal').", "verifiability_rationale": "The reviewer is making a claim that the current annotation ('above/below diagonal') is less effective than adding a thin gray diagonal line for interpretability. This claim is supported by the reviewer's observation that the diagonal line is less intuitive than the anglebased approach. While there's no external reference, the reasoning is based on a practical, visual assessment, making it 3.", "helpfulness_rationale": "The reviewer is directly addressing a potential point of confusion for the author (the 45degree line) and offering a clear alternative. This is a direct and actionable suggestion that is likely to be helpful for improving the plot's clarity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the lines (240 and 428) where the word 'sufficient' is used and provides a concrete interpretation of what the authors likely meant by 'optimistic hoped for rewards'. This makes the action clear and specific.", "grounding_specificity_rationale": "The comment explicitly mentions the specific lines (240 and 428) being discussed, achieving literal mention and thus full grounding. It also specifies the likely intended meaning of 'sufficient' in the context of optimistic rewards, adding to the specificity.", "verifiability_rationale": "The comment contains a claim about the likely intended use of 'sufficient' but does not provide any supporting evidence or justification for this claim. It's a statement without logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The comment identifies a potential point of confusion in the authors' writing regarding the use of 'sufficient' and offers a plausible alternative interpretation. While it doesn't provide a direct solution, it encourages the authors to clarify their intended meaning, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is presented as a question, which is a direct and explicit way of pointing out a potential issue. The request for clarification about groundtruth building and the prediction mechanism is clear and actionable. Therefore, it is 5.", "grounding_specificity_rationale": "The reviewer is asking *how* the groundtruths are built. This requires understanding the data processing and labeling steps. While not explicitly stated in the review point, we can infer that the reviewer is looking for a connection between the model's output and the ground truth data. The reviewer *cannot* confidently determine how the groundtruths are built from the information given in the review point. They need to refer to the paper's data section. However, the reviewer is asking *specific* questions about the groundtruth building process and the network's prediction mechanism. These are quite specific.", "verifiability_rationale": "The reviewer is asking *how* the groundtruths are built and *how* the network can predict all keypoints. These are questions that ideally would be answered by referring to the paper's methodology and implementation details (specifically the data section and the network architecture description). The reviewer is not making a claim that something is *incorrect* but rather asking for clarification on how something works. Therefore, it's not strictly 'verifiable' in the sense of identifying a flaw, but it's a request for information that should be available in the paper.", "helpfulness_rationale": "The reviewer is pointing out a potential ambiguity or lack of clarity in the paper's description. If the paper is unclear about how groundtruths are built and how the network handles multiple keypoints per part, this can hinder understanding and reproducibility. Therefore, it has the potential to be helpful if the authors clarify these points."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the desired changes (larger font size) and points to specific elements (legends, axis labels, figure captions). While the reviewer doesn't suggest *how* to make these changes (e.g., through a command, a specific tool), the action is clear and the location is specific.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"legends and axis labels\" and \"figure captions,\" which are specific parts of the paper. The reviewer also specifies the *what* (font size) and the *where* (specific elements). They also point out the *confusion* between proposition numbers and equation numbers, adding detail.", "verifiability_rationale": "The reviewer is making a statement about the formatting of text elements in a figure. This is a factual observation about the presentation of the figure. While there isn't a citation or external reference, the claim is likely true based on common knowledge of figure formatting. The reviewer is also pointing out a *conflict* between the formatting of proposition numbers and equation numbers, which is a valid observation.", "helpfulness_rationale": "The reviewer points out a specific formatting issue that is likely to affect the readability of the paper. While the *how* of fixing it isn't specified, the reviewer provides a clear *what*. Authors would likely find this helpful in improving the presentation of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their suggestion to compare against Journey TRAK and provides a specific reason (the difference in effect size shown in 1, Figure 2). The action 'suggest a comparison' is direct and the reviewer identifies the specific parts of their work (counterfactual experiments) and the method (Journey TRAK) to compare against. The reviewer also specifies the *reason* for this comparison, linking it to a published finding, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'counterfactual experiments' and 'Journey TRAK' when stating their suggestion. They also provide a specific reason for the comparison by referencing 'Journey TRAK used at a particular step of the the sampling trajectory' and 'a much larger effect of removing highscoring images according to Journey TRAK, in comparison with CLIP cosine similarity' from 1, Figure 2. This demonstrates a clear understanding of the specific parts of the paper being addressed and the specific suggestion being made.", "verifiability_rationale": "The reviewer makes a claim by suggesting a specific comparison in their counterfactual experiments. This claim is supported by referencing a specific paper (Journey TRAK) and a specific figure (1, Figure 2) within that paper. The reviewer provides a clear justification for why this comparison is relevant, linking it to the observed difference in effect size between Journey TRAK and CLIP cosine similarity. The evidence provided is logical and directly supports the reviewer's suggestion.", "helpfulness_rationale": "The reviewer's suggestion is directly relevant to improving the reader's understanding of their counterfactual experiments. By suggesting a comparison against Journey TRAK, they are addressing a potential weakness in the reader's analysis (the difference in effect size) and providing a concrete improvement. The reviewer also provides a specific reason for the suggestion, linking it to a published finding, making the feedback actionable and valuable for the reader's work."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue with the placement of adaptive convolutions based on experimental results and suggests further analysis. While they don't explicitly state what action to take, they highlight a missing discussion in the original paper. The reviewer implies that the placement is important but doesn't provide concrete guidance on how to determine the optimal placement. The lack of explicit instructions makes this point 1.", "grounding_specificity_rationale": "The reviewer mentions 'adaptive convolutions' generally and refers to specific models (ACNNv3 and ACNNv2) in their analysis. While they identify a specific aspect (placement of adaptive convolutions), they don't explicitly pinpoint the exact section, table, or figure where this placement is discussed in the original paper. The mention of specific models is helpful, but the general reference to 'adaptive convolutions' makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer makes a claim based on their interpretation of the experimental results (Table 3) and the lack of discussion about the placement of adaptive convolutions in the original paper. They state that 'it seems that replacing normal convolutions with adaptive convolutions in not always a good' and that 'there is no analysis or comments on this aspect of the technique.' However, they do not provide any external references or logical reasoning to support this claim within the review point itself. The claim is based on their interpretation and observation, lacking sufficient evidence or justification.", "helpfulness_rationale": "The reviewer's point is valuable because it highlights a potential flaw in the experimental design or analysis of the adaptive convolution technique. They draw attention to the discrepancy between the experimental results and the lack of analysis in the original paper. While they don't explicitly state what action to take, their point encourages the authors to consider the placement of adaptive convolutions more carefully. The point is clear and directly relates to the experimental results, making it 3 in identifying a potential area for improvement in the original work."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a difference between the proposed method and another method (10) regarding the information content of their outputs. While the reviewer explicitly states this difference ('This means that the output of ACI has less information compared to the output of 10 that has a richer search space, i.e., DAGs.'), they do not provide an explicit action or suggestion on how to address this difference or what the implications are for the proposed method. The reviewer is stating a fact about the methods, but not providing a direct instruction on how to improve the proposed method based on this observation.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed method' and '10' by name. While they mention the outputs of these methods (ancestral graphs and DAGs), they do not explicitly point to a specific section, table, or figure in their own paper where these concepts are discussed or relevant. The grounding is implied rather than explicitly stated.", "verifiability_rationale": "The reviewer makes a claim about the information content of the outputs of two different methods. They state: 'This means that the output of ACI has less information compared to the output of 10 that has a richer search space, i.e., DAGs.' This claim can be verified by understanding the relationship between ancestral graphs and DAGs. Ancestral graphs are a coarsened representation of DAGs, and therefore, they contain less information about the causal structure. The reviewer provides a logical reasoning to support their claim.", "helpfulness_rationale": "The reviewer raises a valid point about the information loss when using ancestral graphs instead of DAGs. This is a constructive criticism that highlights a potential limitation of the proposed method. While the reviewer doesn't offer a direct solution or specific improvement, the point itself is valuable for discussion and further investigation. The reviewer identifies a weakness in the method's output."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer clearly states that the method simply discards TF bins with magnitude less than epsilon. This is a direct and actionable criticism of the method's implementation. The reviewer provides a specific action: 'I wouldn't call it a VAD, you are simply discarding TF bins with zero magnitude that will result in a division by zero.' This action is directly tied to the described method.", "grounding_specificity_rationale": "The reviewer provides a very specific description of the method being criticized: 'Your VAD description is puzzling. What is stated in the paper simply discards any TF bins that have a magnitude of less than epsilon.' This specific detail about the TF bins and the magnitude threshold demonstrates a clear grounding of the issue.", "verifiability_rationale": "The reviewer's explanation is logically sound and based on common knowledge within the field of audio signal processing. They connect the described method to the typical understanding of VAD (operating on time, detecting speech presence) and the more common implementation of thresholding. While they don't provide external references, the reasoning is clear and verifiable.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential misunderstanding or misinterpretation of the paper's VAD implementation. By clarifying the actual operation, they are providing valuable feedback that can help the authors better understand and potentially improve their own work. This is a significant contribution to the authors' understanding and the paper's clarity."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point asks a question about the motivation for timevarying parameters, which implicitly suggests a discussion. However, it does not explicitly state what the author should do with this information or how to implement it. The request is a suggestion, not a direct action.", "grounding_specificity_rationale": "The review point asks about the motivation for timevarying Q and S, which are parameters discussed in Section 4.2. While the topic is related to a specific section, the review point does not explicitly identify the section, table, or figure where these parameters are discussed or how they are used. The grounding is implied but not explicitly stated.", "verifiability_rationale": "The review point is a question asking for information about the motivation for timevarying parameters and their implications. It does not make a claim or assertion that requires verification. It is a request for clarification rather than a statement of fact or opinion.", "helpfulness_rationale": "The review point asks a question that, if answered, could provide valuable information for the author regarding the motivation for timevarying parameters and their impact on model volatility and predictive intervals. While it doesn't provide a direct solution, it encourages the author to consider a relevant aspect of their work and think critically about their model. The question itself can be considered a form of actionable feedback, prompting further analysis."}
{"actionability_label": "1", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not contain a proposal for action. The reviewer is asking a question about the technical details of different regression methods, not suggesting how to improve the draft based on this information. Therefore, it lacks explicit action or suggestion on how to apply the information.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or method being discussed. It is a general question about the difference between two regression techniques used in object detection. Therefore, it lacks grounding in a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The review point does not contain a claim. It is a question asking for clarification and explanation rather than making a statement that requires verification. Therefore, it does not have a claim that needs to be supported or verified.", "helpfulness_rationale": "The review point is a question about the technical details of different regression methods used in object detection. While it highlights a potential area for clarification in the paper, it does not provide actionable feedback or suggestions on how to improve the draft based on this information. The reviewer is asking 'why' and 'how' rather than 'what to do'. Therefore, it is not directly helpful in improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out that the paper is 'not particularly easy to follow' and that the 'presentation lacks a clear intuition for how the pieces fit together'. While this identifies a problem, it doesn't explicitly state what needs to be done to improve the flow or clarity. The reviewer doesn't provide specific actions or modifications the authors should apply. Therefore, while the issue is relevant, the specific action isn't clearly defined.", "grounding_specificity_rationale": "The reviewer refers to the 'paper', 'intuition', and 'pieces fit together'. While broad, they do identify a specific part of the paper and a specific aspect of it \u2013 the overall presentation and the connections between the different components. The authors can infer that the reviewer is pointing to the explanation of the method and how the different parts relate. Although not as precise as pointing to a specific table or figure, it's more specific than saying 'the paper needs improvement'.", "verifiability_rationale": "The reviewer makes a claim that the paper is 'not particularly easy to follow' and that the 'presentation lacks a clear intuition'. However, they do not provide any evidence, examples, or logical reasoning to support this claim. There are no references to external works or common knowledge used to back up this assertion. The reviewer simply states the problem without explaining why it's a problem or how it should be addressed. Therefore, the claim is not supported by any verifiable information.", "helpfulness_rationale": "The reviewer's comment identifies a problem with the paper's presentation but does not offer any specific suggestions or guidance on how to improve it. While they point out that the paper is 'not particularly easy to follow' and lacks 'a clear intuition', they don't provide concrete steps the authors should take to address this. The authors still need to figure out what to do based on this feedback. Therefore, the review point is not actionable or informative enough to be 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a potential benefit ('may improve the performance of the teacher network') and suggests a method to address it ('Is the comparison fair? Please provide KID/FID metrics of your teacher network'). While the action is clear, the underlying issue of unfair comparison isn't fully elaborated, making it 3.", "grounding_specificity_rationale": "The comment explicitly mentions 'simultaneous training' and 'teacher network', allowing for precise identification of the networks being discussed. However, it doesn't specify *why* the comparison might be unfair or what aspects of the training are causing the potential benefit. The request for KID/FID metrics focuses on the teacher network, adding a specific element to the grounding, but the initial grounding of the networks themselves is clear. Therefore, it can be considered weakly grounded with some specificity.", "verifiability_rationale": "The comment contains a claim ('simultaneous training may improve the performance of the teacher network') and offers a suggestion to verify it ('Please provide KID/FID metrics of your teacher network'). The verifiability is conditional on the request being helpful and the metrics being provided. The claim itself is somewhat vague ('may improve'), and the verifiability is dependent on external factors. Therefore, it can be considered 3.", "helpfulness_rationale": "The comment raises a valid concern about the fairness of a comparison and offers a concrete suggestion (providing KID/FID metrics) to address it. While the request itself might not be inherently helpful without the metrics, the intention to provide information and potentially improve the comparison process is a valid and helpful feedback point. The uncertainty about the fairness adds value to the helpfulness score."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their point about the scaling factor and provides a clear suggestion for improvement. This is a direct and actionable comment, providing a concrete example of a potential issue and proposing a specific change. The reviewer identifies the action of questioning the scaling and the action of suggesting a scaling variable.", "grounding_specificity_rationale": "The reviewer directly references 'line 157' and provides the mathematical formula for the refined region vector. This is a very specific and grounded comment, clearly identifying the section and the formula being discussed. The reviewer accurately pinpoints the relevant part of the paper.", "verifiability_rationale": "The reviewer provides a clear explanation of why they are questioning the scaling factor (limited to a factor of 2) and offers a specific alternative (a scaling variable). This is a welljustified and verifiable comment. The reviewer logically explains the implication of the current scaling and provides a concrete suggestion for improvement, supported by the understanding of attention weights.", "helpfulness_rationale": "The reviewer raises a valid point about the potential limitation of the scaling factor and suggests a reasonable improvement. This is a helpful comment as it identifies a potential area for enhancement and provides a clear direction for the authors to consider. While the suggestion is relatively simple, it directly addresses a potential weakness."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'Failures on the ALFRED benchmark often occurred due to goal misspecification' which is an explicit action or suggestion that authors should aim to improve. However, it does not provide specific details on how to achieve this improvement, such as whether the natural language description of the goal needs to be revised or if the formal goal predicate is incorrect. The action is stated, but the implementation is left vague.", "grounding_specificity_rationale": "The review point mentions 'ALFRED benchmark' which can be considered a ground, as it is a specific element of the paper. However, it does not specify which part of the ALFRED benchmark or the goal is misspecified. It identifies the *cause* (goal misspecification) but not the *specific* instance of misspecification within the ALFRED framework. The grounding is present but not fully specific.", "verifiability_rationale": "The review point makes a claim: 'Failures on the ALFRED benchmark often occurred due to goal misspecification.' This is a claim that needs to be verified. However, the review point does not provide any specific evidence, examples, or logical reasoning to support this claim. It simply states an observation. There are no external references or detailed explanations provided to justify the claim.", "helpfulness_rationale": "The review point identifies a problem ('Failures on the ALFRED benchmark often occurred due to goal misspecification') that is actionable for the authors. It suggests that addressing this misspecification could improve performance on the ALFRED benchmark. However, the point is somewhat vague and lacks specific details on how to identify and correct the misspecification. It doesn't provide concrete steps or examples for the authors to follow, making it less immediately helpful for largescale improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer offers suggestions and raises a concern. While the suggestion to analyze disparity distributions could be considered an explicit action, the raising of the concern itself is more of a question or observation rather than a direct instruction on how to improve the method. The lack of a clear, stepbystep action makes it less actionable.", "grounding_specificity_rationale": "The reviewer mentions 'iterative optimization schemes similar to IGEV' and 'SamplingGaussian'. While these terms are mentioned, the reviewer does not explicitly state which part of the paper these concepts are relevant to, nor does the reviewer provide a clear explanation of their connection to the reviewed method. The mention is present, but the explanation is missing, indicating weak grounding.", "verifiability_rationale": "The reviewer states that the improvement over SOTA methods is 'small' and raises a concern about the difficulty of improvement for iterative frameworks similar to IGEV. These statements can be considered claims. However, the reviewer does not provide any specific evidence or reasoning to support these claims within the review point itself. The claims are presented without sufficient justification or references, making them 1 based on the information provided in the review point.", "helpfulness_rationale": "The reviewer suggests analyzing disparity distributions and raises a concern about the potential limitations of SamplingGaussian for similar iterative frameworks. These are suggestions and a concern, which generally fall under the scope of helpful feedback. While the suggestions are relevant, the lack of specific evidence or detailed reasoning to support the concern makes the overall feedback somewhat limited in its helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests investigating specific models (GPT4o vs. InternVL2) and presenting differences in false positive rates (FPR). These are concrete actions with clear implications for the authors. The reviewer proposes specific model instances and a specific metric (FPR) for analysis, which are direct actions the authors can take. However, the reviewer does not explicitly state how to *calculate* or *interpret* the FPR differences, making the action somewhat implicit.", "grounding_specificity_rationale": "The review point explicitly mentions 'specific models (e.g., GPT4o vs. InternVL2)' and 'false positive rates (FPR)'. The use of 'e.g.' suggests the reviewer is providing examples, indicating a lack of precise grounding. While the *concept* of investigating specific models and FPR is mentioned, the reviewer doesn't pinpoint the exact section, table, or figure where these models are discussed or the specific FPR values to be presented. The grounding is weak because the authors need to infer the specific parts of the paper related to these models and FPR.", "verifiability_rationale": "The review point suggests investigating specific models and presenting FPR differences. While it doesn't explicitly claim to be *verifiable* in a strict academic sense (e.g., by citing a specific paper), it provides a clear direction for the authors to follow. The reviewer is suggesting a *type* of analysis to perform. The 'how' of this analysis isn't detailed, but the 'what' is clear. The suggestion is not a call for a new experiment but rather a request for a specific type of data presentation. Therefore, it leans towards being 3 as it points towards a specific area of investigation, but lacks the depth of a full literature review or a novel methodological contribution.", "helpfulness_rationale": "The review point offers concrete suggestions for the authors to explore specific models and analyze false positive rates. These suggestions directly address the idea of adding nuance to the conclusions and improving comparisons. By focusing on specific models, the reviewer is suggesting a more detailed and potentially impactful analysis than the current generic findings. The suggestions are actionable and provide a clear direction for the authors to improve their work. While more specific guidance could be provided, the suggestions are still valuable and likely to be helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the action of clarifying the nature of Fourier modes (\"Perhaps clarify if these are reals or complex\"). This makes the action clear and direct. The suggestion is also concrete, specifying the ambiguity as being whether they are real or complex numbers.", "grounding_specificity_rationale": "The comment explicitly refers to \"Fourier modes\" as the part of the paper being addressed. While it doesn't name a specific section or table, it clearly identifies a unique concept within the text. The comment also specifies what needs clarification (whether they are real or complex).", "verifiability_rationale": "The comment itself does not contain a claim that requires verification. It is a suggestion for clarification. Therefore, it does not fit the criteria for verifiability. While the need for clarification can be seen as an implicit request, the review point itself doesn't present a verifiable statement.", "helpfulness_rationale": "The comment directly addresses a potential point of confusion for the authors (the nature of Fourier modes). It provides a clear direction for clarification, which is a valuable piece of feedback. While it doesn't offer a definitive answer, it prompts the authors to consider a specific detail that could impact their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the contribution of different components to the performance gain. While the question itself is direct, it could be made more actionable by specifying the exact components and metrics being compared. The reviewer is implicitly suggesting that the paper should clarify this aspect, but the suggestion lacks concrete details.", "grounding_specificity_rationale": "The reviewer is asking for clarification on a key aspect of the paper (the contribution of task formulation vs. pretrained models). While they don't explicitly state which section or table this refers to, the context suggests it relates to the results. The reviewer is also asking for a *justification* of the results, which is a specific aspect. Therefore, the grounding is weak as the exact location isn't pinpointed, but the specificity is high as the reviewer is asking for a justification of a key finding.", "verifiability_rationale": "The reviewer is not making a claim that needs verification. They are asking for clarification on a point that is already presented in the paper. There is X being made, logical reasoning, or external references required to understand the point. The request is a demand for more information, not an assertion that needs validation.", "helpfulness_rationale": "The reviewer is asking a question about a crucial aspect of the paper. While the question itself isn't a direct solution, it points to a significant area where the authors might need more clarity. By highlighting this, the reviewer is directing the authors' attention to a potential weakness in the paper's presentation and encouraging them to seek further explanation. This is 3 in identifying a need for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the axes of Figure 1 are unclear. This is a direct and actionable suggestion for the authors to understand the data presented in the figure. The action is not vague as it directly points to a specific element of the paper.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1', which is a specific part of the paper. The authors can directly identify the figure being referred to. The specificity is high as the comment clearly identifies what needs clarification.", "verifiability_rationale": "The comment identifies a problem ('It is hard to understand') but does not provide any justification or explanation for why the axes are unclear. There is no external reference or logical reasoning provided to support the claim. While it implies a need for clarification, it doesn't guide the authors on how to achieve that. Therefore, it is 1 as it lacks sufficient evidence or justification.", "helpfulness_rationale": "The comment identifies a genuine issue \u2013 the lack of clarity around Figure 1's axes. This is a valid concern for the authors as it hinders their understanding of the data. While the comment doesn't explicitly tell them how to fix it, it points to a crucial area of improvement. Therefore, it is 3 in highlighting a necessary step for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly suggests an action: 'run experiments on ImageNet'. This is a direct instruction for the authors to modify their experimental setup. The suggestion is clear and actionable, indicating a direct path to improvement.", "grounding_specificity_rationale": "The review point does not specify which part of the paper or method is being improved by using ImageNet. The suggestion is general and does not point to a specific section, table, figure, or unique aspect of the paper. The mention of 'more convincing of the proposed method' is a judgment about the overall results, not a specific critique of a written element.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for future work, proposing a potential experiment (ImageNet) as a way to strengthen the results. There is no logical reasoning, common knowledge, or external references being presented as evidence for *why* this suggestion is valid or beneficial.", "helpfulness_rationale": "The review point offers a suggestion for improvement by proposing additional experiments on ImageNet. This could be helpful for the authors as it provides a concrete direction for future research and potentially strengthens the evaluation of their proposed method. While it doesn't directly identify a flaw in their current work, it offers a valuable suggestion for enhancing it."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing element '2 Direct runtime comparisons with existing methods' and provides a reason for its absence ('The proposed approach is based on implicit differentiation which usually requires additional computational costs'). This clearly indicates an actionable item for the authors: to conduct these runtime comparisons.", "grounding_specificity_rationale": "The review point refers to 'direct runtime comparisons' but does not explicitly identify which specific comparisons are needed. While the reason for their absence is given ('The proposed approach is based on implicit differentiation which usually requires additional computational costs'), the specific comparisons are not detailed. This makes the grounding somewhat weak as the authors need to infer which comparisons are necessary.", "verifiability_rationale": "The review point makes two claims: '2 Direct runtime comparisons with existing methods are missing' and 'The proposed approach is based on implicit differentiation which usually requires additional computational costs.' Both claims are supported by direct statements within the review point itself.", "helpfulness_rationale": "The review point is 5 as it identifies a significant omission in the authors' evaluation: the lack of direct runtime comparisons. This is a crucial piece of information for assessing the practical applicability of the proposed method and encourages the authors to perform this analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer states \"I cannot see any technical contribution.\" While this is an explicit statement about what the authors should do, it lacks specific details on *what* the technical contribution is missing. The action is implied (improve the draft), but the specifics are missing, making it somewhat vague. Therefore, it's not fully actionable but leans towards being explicit.", "grounding_specificity_rationale": "The reviewer mentions \"metalearning\" and \"federated learning\" and states \"I cannot see any technical contribution.\" This clearly identifies the specific part of the paper being addressed (the framework combining these two learning paradigms) and specifies the issue (lack of technical contribution). Therefore, the grounding is explicit and the specificity is clear.", "verifiability_rationale": "The reviewer makes a claim: \"I cannot see any technical contribution.\" However, they do not provide any evidence, reasoning, or references to support this claim. The statement is presented as an opinion without any logical backing or external references. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer points out a potential weakness in the proposed framework (lack of technical contribution) but does not offer any suggestions or guidance on how to address this weakness. The review is critical but lacks constructive feedback. Therefore, it is not particularly helpful for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "2", "actionability_rationale": "The reviewer criticizes the lack of actionable insights, focusing on the absence of concrete steps or solutions to improve model robustness based on the observed connection between multimodal complementarity and robustness. While the reviewer identifies a valid area for improvement, the criticism itself doesn't provide explicit or implicit instructions on how to address this gap. The reviewer's statement about the lack of solutions makes the criticism somewhat vague and doesn't specify the 'how' of leveraging the connection.", "grounding_specificity_rationale": "The reviewer's criticism is not explicitly directed at a specific section or part of the paper. While the focus is on the 'connection between the complementary and the model robustness,' the reviewer doesn't pinpoint a particular section, table, or figure where this connection is discussed. The reviewer's statement is more general, referring to the overall findings or methodology related to this connection. Therefore, while the intent is related to a specific aspect, the criticism itself lacks precise grounding within the paper's structure.", "verifiability_rationale": "The reviewer makes a claim about the intuitiveness of the conclusion (higher complementarity > more delicate robustness under corruption). This claim is not supported by specific evidence, references, or logical reasoning within the review point itself. The reviewer expresses an opinion about the intuitiveness without providing any backing. Therefore, the claim is not fully supported by verifiable information.", "helpfulness_rationale": "The reviewer's concern about the lack of actionable insights is a valid and important point for improving the paper. However, the criticism itself is not constructive in terms of providing specific, actionable feedback. The reviewer points out a gap but doesn't offer any suggestions or directions on how to address it. The helpfulness of this point is limited because it identifies a problem without proposing a solution."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the comparison between focusing on 'best' clusters and analyzing differences in representation. It identifies the action of focusing on 'best' clusters and the absence of the action of analyzing differences. The comparison between these two actions is also explicitly stated.", "grounding_specificity_rationale": "The review point refers to 'clusters' and 'representation' generally. While it implies a specific focus on these aspects, it doesn't explicitly point to a specific section, table, figure, or unique element within the paper. However, it clearly specifies the *what* being compared ('clusters' and 'representation differences'). The reason for the comment ('seems an odd choice given the motivation of the paper') also specifies the *why*.", "verifiability_rationale": "The review point contains a claim: 'Focusing on which clusters are 'best' rather than what the differences in representation are between them, seems an odd choice given the motivation of the paper.' This claim is based on a subjective assessment of the 'oddness' of the approach. While the *what* (clusters and representation) is 3, the *why* (it seems odd) is dependent on external context and the paper's specific motivation, making it less verifiable.", "helpfulness_rationale": "The review point raises a valid concern about a methodological choice made in the paper. It points out a potential area for improvement or clarification. The feedback is specific to the *methodological choice* and *why it seems odd*, connecting it to the paper's motivation. This provides a clear direction for the authors to consider."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the incorrect caption ('Node Dynamics') and the correct caption ('Edge Dynamics'). This is a direct identification of the issue and a clear suggestion for improvement. The action is also concrete, specifying which figure and what change should be made.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 7' and specifies the type of dynamics that is incorrect ('Node Dynamics') and what it should be corrected to ('Edge Dynamics'). This demonstrates strong grounding as the specific part of the paper is identified, and the issue within that part is clearly defined.", "verifiability_rationale": "The reviewer points out that the caption is incorrect and suggests a specific correction. While the paper itself might not explicitly state that 'Node Dynamics' is wrong, the implication is clear: the caption says 'Node Dynamics' when it should be 'Edge Dynamics'. The reviewer's suggestion is a logical inference based on the identified issue.", "helpfulness_rationale": "The reviewer has identified a specific, actionable issue with a figure's caption and has proposed a concrete fix. This directly improves the clarity and accuracy of the paper's presentation of edge dynamics. While it doesn't address broader issues, it provides a clear and actionable improvement for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action the authors should take: 'discuss case studies and error studies'. This action is clear and specific, instructing the authors on what to include in their work. The reviewer also provides a specific example related to the paper's content, further clarifying the action.", "grounding_specificity_rationale": "The review point explicitly mentions 'case studies and error studies' and provides a specific example related to the paper's content, the Elementlevel Graph Pretraining section. This demonstrates strong grounding as the reviewer not only identifies the type of studies but also connects them to a relevant aspect of the paper. The reviewer also explains what these studies are intended to achieve, further enhancing the grounding.", "verifiability_rationale": "The review point contains a claim: 'It could be convincing to discuss case studies and error studies'. The reviewer provides reasoning for this claim by stating that these studies can 'highlight the effectiveness of each proposed component'. Furthermore, the reviewer offers a specific example, 'this paper mentions that the Elementlevel Graph Pretraining abandons the strategy of capturing the complex structure but focuses directly on the core elements. However, without case study, it is less convincing to figure it out. An example of case study can be found in \u201cGraph pretraining for AMR parsing and generation\u201d', which directly links the suggested studies to a specific aspect of the paper and provides a concrete example.", "helpfulness_rationale": "The review point is 5 as it directly suggests a concrete and beneficial improvement for the authors. The reviewer provides a clear rationale for why discussing case studies and error studies would be valuable, explaining that they can 'highlight the effectiveness of each proposed component' and 'identify failure modes'. The reviewer also provides a specific example related to the paper's content, further clarifying the benefit of the suggested approach. This makes the advice actionable and wellsupported."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the suggestion to consider explicitness (E) and size (S) as extra evaluations. However, the reviewer does not provide any concrete steps or details on how to implement this extra evaluation. The action is stated, but the means to achieve it are not specified.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'explicitness (E) and size (S)' as the factors they are considering. This clearly indicates that the authors can identify the specific part of the paper and the issue being addressed, thus achieving full grounding. The comment specifies what needs to be addressed in this part (the entanglement of DCI and ES with E and S).", "verifiability_rationale": "The reviewer's claim about the entanglement of DCI and ES, and the need for explicitness (E) and size (S) as extra evaluations, lacks sufficient justification. There is no logical reasoning, common knowledge, or external references provided to support this claim. The reviewer simply states the motivation without backing it up.", "helpfulness_rationale": "The reviewer's suggestion to consider explicitness (E) and size (S) as extra evaluations is presented without any supporting evidence or justification for its value. The comment does not explain why this is a beneficial addition or how it would be verified. Therefore, it does not provide any actionable feedback to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing information: 'the standard deviation after multiple experiments is not provided'. It also suggests a concrete action to improve the analysis: 'clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method'. This makes the review point both explicit and actionable.", "grounding_specificity_rationale": "The review point explicitly identifies the missing element in the experimental section: 'standard deviation after multiple experiments is not provided'. This is a clear and precise grounding of the issue. It also specifies what the missing information is intended to clarify: 'which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method'. This makes the grounding both explicit and specific.", "verifiability_rationale": "The review point contains a claim: 'The improvement brought by SoRA compared with the baseline is quite limited, which may be due to random fluctuations.' This claim is verifiable because it points to a specific area where further analysis (providing standard deviation) is needed. The suggestion to clarify effects within standard deviation fluctuations is a logical and verifiable step to address the identified issue.", "helpfulness_rationale": "The review point is 5 because it directly addresses a specific weakness in the experimental analysis (lack of standard deviation) and provides a clear and actionable suggestion for improvement ('clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method'). This directly empowers the authors to enhance their work."}
{"actionability_label": "4", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a list of specific issues with the paper's organization and formatting. For example, they mention the small font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the wrong format of the top two lines on page 6. These are all concrete actions the authors should take to improve their draft. The reviewer implies that the authors should fix these issues, making the feedback actionable.", "grounding_specificity_rationale": "The reviewer explicitly refers to specific parts of the paper when mentioning the issues. They use the names 'Figure 1' and 'Figure 2' and 'Table 2'. This clearly indicates that the reviewer can identify the specific sections being addressed, demonstrating strong grounding. Furthermore, they describe the issues within these specific sections, such as the small font size and incorrect placement, making the grounding very clear.", "verifiability_rationale": "The reviewer states that the paper is 'not well organized' and lists specific formatting issues. This constitutes a claim about the paper. While the reviewer doesn't provide explicit logical reasoning for *why* these are problems, the lack of organization and incorrect formatting are generally understood as valid criticisms in academic writing. The reviewer provides specific examples of problems within the mentioned sections (e.g., 'font size of some annotations of Figure1 and Figure 2 is relatively small', 'Table 2 is inserted wrongly inside of a paragraph'). This demonstrates that the claim is supported by specific observations, making it 3.", "helpfulness_rationale": "The reviewer identifies several concrete issues with the paper's organization and formatting. They specifically mention problems with figures (font size, explicitness), tables (placement), and formatting (top lines). These are all actionable suggestions that the authors can directly implement to improve their work. The reviewer's feedback is focused on observable flaws, making it highly valuable for the authors to address."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a concern: 'it would be important to think about whether they are practical and safe for querying in the real world.' This indicates an explicit action or suggestion, even if it's not immediately clear how to implement it. The reviewer points out a weakness in the paper.", "grounding_specificity_rationale": "The review point refers to 'the types of interventions included in the paper' without specifying a particular section, table, figure, or unique element. While it identifies a category of interventions, it doesn't pinpoint the exact part of the paper being addressed. Therefore, the grounding can be considered weak.", "verifiability_rationale": "The review point contains a claim: 'it would be important to think about whether they are practical and safe for querying in the real world.' However, it does not provide any evidence, reasoning, or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the concern about practicality and safety.", "helpfulness_rationale": "The review point raises a relevant concern about the practicality and safety of the interventions. However, it does not offer any specific suggestions or guidance on how to address this concern. The feedback is a statement of a problem without any proposed solutions or actions to take."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point presents two distinct requests for clarification. The first asks for clarification on the meaning of 'upper faces' of the convex hull and the explanation of 'dual subdivision and projection \u03c0'. The second asks for clarification on the variable 'p' in the context of decision boundaries of neural networks. While the authors have not taken any specific action to address these points, the reviewer has explicitly identified actions they would like to be taken. The lack of immediate action does not negate the potential actionability of the requests.", "grounding_specificity_rationale": "The review point explicitly refers to 'the upper faces of the convex hull' and 'dual subdivision and projection \u03c0', which are specific mathematical concepts. The reviewer also refers to 'decision boundaries of neural networks' and the variable 'p', which are specific elements within that context. The reviewer is pointing to specific parts of the paper and concepts within them, indicating strong grounding. While the definitions might be missing, the references are precise.", "verifiability_rationale": "The review point makes claims about the lack of clarity regarding 'upper faces' of the convex hull and the explanation of 'dual subdivision and projection \u03c0', and that the variable 'p' is not explicitly defined and is problematic. While the claims are present, the reviewer does not provide specific examples or references to support these claims. The lack of specific evidence makes the verifiability somewhat low.", "helpfulness_rationale": "The review point is helpful in that it directly points out potential areas of confusion and missing information for the authors. The reviewer is asking for clarification on specific terms and definitions, which is a valuable feedback for improving the paper. The requests are specific and directly address potential issues."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer states their opinion ('not convinced') about treating images and augmentations separately and suggests an alternative ('they can be interchangeable'). While the reviewer expresses a lack of conviction, the suggestion itself is clear and actionable. They are proposing a change to how images are handled. The reviewer explicitly states their intention to suggest a change, making it 3.", "grounding_specificity_rationale": "The reviewer refers to 'images and their augmentations' and suggests they can be 'interchangeable.' This is a specific part of the paper being addressed. They are not making a very general comment about the entire draft. The reviewer is also very specific about the nature of the alternative, which is interchangeability. This indicates a clear identification of the specific aspect being discussed.", "verifiability_rationale": "The reviewer presents a point about the treatment of images and augmentations, stating that they 'need to be treated separately' and suggesting they 'can be interchangeable.' While this presents a point that could be considered a claim (in the sense that it's a proposition for change), the reviewer does not provide any specific examples, citations, or logical reasoning to *support* this claim. The suggestion is presented as a possibility rather than a proven fact. Therefore, it is difficult to verify the claim based on the information provided.", "helpfulness_rationale": "The reviewer's point directly addresses a potential complexity in handling images and augmentations, suggesting a simplification. While the reviewer expresses a lack of conviction ('not convinced'), the suggestion itself is clear and actionable. The reviewer is directly pointing out a potential area for improvement. Even though the reviewer's conviction is low, the suggestion itself is valuable and directly addresses a specific aspect of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'It is unclear which component contributes to the performance gain' and 'Since the proposed approach follows detectionparsing paradigm, it is better to evaluate on baseline detection or parsing techniques sperately to better support the claim.' These are clear statements of action or question, making it explicit and concrete.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed method' and then breaks it down into 'generative shape model' and 'word parsing model'. While they don't point to a specific section or table, they clearly identify the components of the method being discussed, making the grounding somewhat explicit but not perfectly precise.", "verifiability_rationale": "The review point states a finding ('It is unclear...') and suggests a method to address it ('evaluate on baseline...'). This is a statement of observation that can be verified by evaluating on baselines, making it 3 as the suggestion provides a path to clarification.", "helpfulness_rationale": "The review point directly addresses a potential weakness in the paper (unclear contribution of components) and provides a concrete suggestion (evaluate on baselines). This directly targets the authors and offers a clear direction for improvement, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that 'Another issue of the paper is that the disentangling is done manually.' This is an explicit statement about a limitation. Furthermore, the reviewer *specifically identifies* the manual disentanglement as being the 'semantic segmentation network' and *why it's an issue* by asking 'Why is that? Why not something else? It would be interesting if the paper did not have this type of manual disentangling, and everything was learned.' This provides a concrete action the authors could consider.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'manual disentanglement' and then narrows it down to 'the semantic segmentation network' and its position in the pipeline as the 'first module'. This provides a very specific reference point within the paper, indicating strong grounding. The reviewer also asks a question directly about this specific element, highlighting its importance and the need for clarification or improvement.", "verifiability_rationale": "The reviewer does not make a claim that requires verification. Instead, they present a question about a design choice: 'Why is that? Why not something else? It would be interesting if the paper did not have this type of manual disentangling, and everything was learned.' This is a suggestion for improvement rather than a declarative statement that needs to be supported.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the methodology (manual disentanglement) and suggests an alternative approach (endtoend learning). This is a constructive suggestion that directly addresses a potential limitation, making it highly likely to be helpful for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of a clear connection between the theoretical analysis and the proposed method. While this is an explicit statement, the reviewer does not provide specific details on *how* the theory and method are not connected or *what* aspect of the method is lacking. The vagueness of the statement makes it less actionable than a highly specific suggestion.", "grounding_specificity_rationale": "The reviewer mentions 'theoretical analysis' and 'proposed method' but does not specify *which* part of the paper or method the connection is unclear or *which* specific detail of the selfattention mechanism is causing the confusion. The criticism is about the *lack of connection* being unclear, not a specific detail within either. This is weak grounding.", "verifiability_rationale": "The reviewer makes claims about the *lack of connection* and the *lack of explanation* for the method's benefits. These are claims that need to be verified. However, the reviewer does not provide specific examples or references to support these claims. The verifiability is low because the reviewer is making general statements about the lack of connection and explanation, rather than pointing to specific gaps in the paper or method.", "helpfulness_rationale": "The reviewer provides a clear criticism: a lack of connection between theory and method, and an unclear explanation of the method's benefits. This directly points to areas where the authors can improve their paper. While the criticism is somewhat general, it is still a concrete suggestion for the authors to strengthen the link between theory and practice. The reviewer is not asking for a retraction or a completely new idea, but rather a clarification and justification of the existing approach."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The comment directly asks a question about the method's behavior under a specific condition (without the Lipschitz Hessian assumption). This makes it explicitly pointing out a missing piece of information. However, it doesn't provide concrete steps or details on how the behavior differs or what implications arise.", "grounding_specificity_rationale": "The comment explicitly refers to 'the Lipschitz Hessian assumption' by name, making it fully grounded. It also asks about the method's behavior *without* this assumption, which is a specific aspect of the method's performance or theoretical properties.", "verifiability_rationale": "The comment itself does not contain a claim that requires verification. It's a question prompting for clarification or understanding. There is no logical reasoning, common knowledge, or external references provided to support any implicit assumptions or expectations.", "helpfulness_rationale": "The comment identifies a potential area for clarification regarding the method's behavior under a specific condition. However, it doesn't provide direct instructions or guidance on how the author should modify their draft based on this missing information. It's a request for more information rather than a direct suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states 'Some of the pieces are simply using existing methods' and 'the presentation of these methods are also vague (can only be understood after checking the original paper)'. While the reviewer identifies a problem, they don't explicitly state what needs to be done about it. The action of 'understanding' is implied but not directly stated as an action. The vagueness makes it difficult to act upon directly within the review point.", "grounding_specificity_rationale": "The reviewer mentions 'equation (12)' when critiquing the presentation of existing methods. This indicates that the reviewer can identify the specific part of the paper being addressed, making the grounding explicit. However, the reviewer also states that the presentation is 'vague (can only be understood after checking the original paper)'. This lack of specific details about the vagueness makes the action or suggestion underspecific.", "verifiability_rationale": "The reviewer states 'Some of the pieces are simply using existing methods' which can be considered a claim. However, the reviewer does not provide any specific examples, references, or logical reasoning to support this claim within the review point itself. The justification relies on the reader checking the original paper, which is external to the review point.", "helpfulness_rationale": "The reviewer's comment identifies a problem (vague presentation of existing methods) but does not offer concrete suggestions or actionable steps for the authors to improve their draft. The reviewer's point requires the authors to seek external information (the original paper) to understand the issue, which is not helpful in itself."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks 'what are the main rationals for' (a) and (b), which directly requests explanations of *why* certain architectural choices were made. This provides clear guidance for the authors to understand the model's design decisions. While the action isn't explicitly stated, the request for rationale makes it actionable.", "grounding_specificity_rationale": "The reviewer asks about the rationales for specific architectural choices within the context of the provided figure and dataset. While the *model* isn't explicitly named, the request is tied to the *specific components* (timbre encoder, SADTW) and the *dataset* (amateur vs. professional recordings). The grounding is present as the reviewer is asking about the *reasoning* behind these choices within the model's architecture. However, without knowing the exact model, the specificity of the rationale is limited to the model's internal workings.", "verifiability_rationale": "The reviewer asks for the *rationale* behind specific architectural choices. This implies a claim that these choices are made for a *reason*. The request for justification makes this claim verifiable, as the authors would then need to provide evidence for these reasons. The reasoning, while not explicitly stated, is implied by the question itself.", "helpfulness_rationale": "The reviewer asks specific questions about the *rationale* behind architectural choices in a model. Understanding the *why* behind design decisions is crucial for improving a model. This review point provides valuable insights into the model's design, making it 5 for the authors to understand and potentially improve their own work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point does not explicitly state an action or suggest how to improve the paper. While the reviewer implies the need to complete Table 4, they don't specify the exact steps or criteria for completion.", "grounding_specificity_rationale": "The reviewer mentions 'Table 4' which is a specific part of the paper. However, they do not specify *what* is missing or *how* the results should be included. The grounding is present, but the specificity of the suggestion is lacking.", "verifiability_rationale": "The review point does not contain a claim or assertion. It simply states a problem ('Table 4 is incomplete') and suggests a solution ('It should include the results for all four datasets'). There is no logical reasoning, common knowledge, or external references provided to support this suggestion.", "helpfulness_rationale": "The review point identifies a clear weakness ('Table 4 is incomplete') and provides a specific suggestion for improvement ('It should include the results for all four datasets'). This directly informs the author about what is missing and how to address it, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem (jumbledness) but doesn't offer a concrete action or solution.", "grounding_specificity_rationale": "The comment refers to 'writing / presentation' generally, without pinpointing a specific section, table, figure, or element.", "verifiability_rationale": "The comment is a statement of opinion ('I found...') and doesn't require verification.", "helpfulness_rationale": "The feedback is general and lacks specific actionable steps. It's a broad suggestion."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer poses a question about the importance of the annealing scheme, which implicitly suggests it might be relevant. However, the action to take is vague. The reviewer doesn't explicitly state what the authors should do with the information. They are asking a question, which is an implicit action, but it's not clear what the authors should do with this information. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the last paragraph in Section 4' and the 'annealing scheme' within it. This clearly identifies the specific part of the paper being addressed, achieving 'Full Grounding'. The comment refers to a specific section and a specific method within that section.", "verifiability_rationale": "The reviewer makes a claim about the potential drawbacks of the annealing scheme, stating that it could induce a bias that outweighs the benefits of IWAE. However, this claim is not supported by any evidence or reasoning within the review point. There are no references to external works, no logical arguments, and no examples provided to back up this assertion. The reasoning is missing, making the claim 1.", "helpfulness_rationale": "The reviewer raises a concern about the annealing scheme without providing any supporting evidence or reasoning. They are speculating about potential issues but do not offer any concrete suggestions or analysis to address these concerns. The comment is a claim without any justification, making it unhelpful for the authors to understand the potential issues or how to mitigate them."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out a factual error in the authors' description of the IOI circuit, stating that the Induction, Duplicate Token, and Previous Token heads 'primarily attend' to the S2 token, while according to Wang et al., 2023, they are 'active' but not 'primarily attend'. The reviewer provides a clear alternative description and a specific section reference (Section 3 of Wang et al., 2023) to support their claim. This allows the authors to directly understand the error in their terminology and replace it with the correct concept.", "grounding_specificity_rationale": "The reviewer provides a specific section reference (Section 3 of Wang et al., 2023) to support their claim about the attention mechanism behavior. This demonstrates strong grounding specificity as the reviewer accurately identifies the relevant section in the cited work.", "verifiability_rationale": "The reviewer makes a claim that the authors' description of the IOI circuit is incorrect and provides a specific reference to Wang et al., 2023 to support this claim. The reference is verifiable, indicating that the reviewer has evidence to support their statement.", "helpfulness_rationale": "The reviewer's comment is 5 as they clearly identify a factual error in the authors' description and provide a correct alternative. The specific section reference and the clear distinction between 'primary attention' and 'activity' in attention mechanisms equip the authors with concrete information to improve their understanding and potentially their draft."}
{"actionability_label": "None", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point states that the method does not seem to be scalable. While this is a valid concern, the point does not explicitly state what action needs to be taken to address this issue. The reviewer is expressing a limitation rather than providing a concrete, actionable suggestion. Therefore, it is not explicitly stating an action, and the action is also vague as it does not specify how to make the method scalable. Based on the definitions, it is 2 as it points to a limitation but lacks specific details on how to address it.", "grounding_specificity_rationale": "The review point is a general statement about the method's scalability and does not mention any specific part of the paper or method being addressed. It is 1 at all as it does not identify a particular section, table, figure, or unique aspect of the paper. Therefore, it is 1 and specificity is not applicable as there is no reference to a specific part of the paper.", "verifiability_rationale": "The review point contains a claim: 'The method does not seem to be scalable...'. This is a statement of opinion or judgment about the method's limitations. However, the point does not provide any evidence or reasoning to support this claim. It is presented as a statement of what the reviewer thinks is a problem without any backing or justification. Therefore, the claim is present, but it lacks supporting evidence or justification, making it 3.", "helpfulness_rationale": "The review point identifies a significant practical limitation regarding the scalability of the method. However, it does not offer any suggestions or actions to address this limitation. It is a critique of the method's limitations rather than a constructive suggestion for improvement. Since it does not provide any actionable feedback, it is not 5 to the authors. It is more likely to be perceived as a negative comment rather than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for an explanation of why a specific term follows a noncentral chisquared distribution. While the paper mentions the distribution, it doesn't explicitly state the reasoning behind it. The reviewer is implicitly asking for an action: to understand the underlying reasons for this statistical property.", "grounding_specificity_rationale": "The reviewer's comment refers to 'eta_ri term' without specifying which part of the paper this term belongs to. They are making a general statement about the lack of clarity regarding the distribution. Therefore, the grounding is weak as the authors cannot confidently identify the referenced part.", "verifiability_rationale": "The reviewer is making a claim about the paper's content: that the reason for the eta_ri term's distribution is not clear. This claim requires justification, as the paper only states the distribution type. However, the review point itself does not provide any evidence to support this claim. The reasoning is present in the reviewer's mind but not explicitly stated in the paper or the review point.", "helpfulness_rationale": "The reviewer is asking for an explanation of a technical detail. While this can be helpful for the authors, the review point itself does not directly instruct the authors on what to do. The authors would need to infer that they need an explanation for the noncentral chisquared distribution of the eta_ri term. The helpfulness is indirect and requires the reader to take an action (inferring the need for explanation)."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit and concrete suggestions for improvement. On L15, the reviewer points out the vagueness of the statement and suggests looking into specific areas of RNN research (natural language inference and the SNLI leaderboard). On L16L18, the reviewer criticizes the reinforcement learningagent analogy and suggests focusing on generalization capabilities and providing examples later in the paper. These suggestions are clear and directly address potential weaknesses in the work, making them actionable.", "grounding_specificity_rationale": "The reviewer's comment on L15 is somewhat vague in terms of grounding. While they mention 'certain RNNs' and 'natural language reasoning tasks,' they do not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The suggestion on L16L18 is also somewhat vague as it refers to 'reinforcement learning / agent' without pinpointing a specific part of the paper where this analogy is used or where it might be outofplace. While the suggestions are general areas for improvement, they lack the specificity to directly target a particular element within the submitted work.", "verifiability_rationale": "The review point contains claims, as the reviewer expresses opinions and judgments about the clarity of the work and the appropriateness of the reinforcement learning analogy. However, the verifiability of these claims within this review point itself is limited. The reviewer states that the statement on L15 is 'too vague' and that the reinforcement learning analogy is 'outofplace,' but they do not provide specific references, logical reasoning, or external examples to support these claims within this review point. The suggestions are presented as statements of opinion rather than verifiable arguments.", "helpfulness_rationale": "The review point is 5 as it provides clear and actionable feedback. The reviewer explicitly points out a potential weakness ('too vague') and offers specific suggestions for improvement, such as exploring 'certain areas of RNN research' and focusing on 'generalization capabilities' with 'examples later in the paper.' These suggestions are concrete and directly address potential areas for enhancement, making the review point valuable for guiding the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a lack of significant difference in performance and a lack of justification, but it doesn't explicitly state what needs to be done. The claims are present, but the actions are implied rather than clearly stated.", "grounding_specificity_rationale": "The reviewer mentions 'Fig.5' and 'StableDiffusion' when discussing the performance difference, indicating some grounding. However, they don't specify which part of Fig. 5 or what exactly the difference is. The reference to 'Algorithm 1' for the lack of justification is also missing, making the grounding weak. The connection to 'sensitivelayer selection' is implied but not explicitly stated in the grounding.", "verifiability_rationale": "The reviewer states that there is 'no mathematical or theoretical justification' for Algorithm 1, which is a claim lacking support. They don't provide any examples, references, or explanations to back up this assertion. The reasoning is missing, making the claim 1.", "helpfulness_rationale": "The review points out observations (lack of significant difference and lack of justification) without providing concrete suggestions or directions for improvement. While the observations are factual, they don't directly guide the authors on how to proceed."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: \"the authors should change the notation in line 122 from sets to tuples.\" This is a concrete action with a clear goal. The reviewer directly tells the authors what to do and how to do it.", "grounding_specificity_rationale": "The review point explicitly mentions \"line 122\" and the specific notation being used ('sets\" vs. \"tuples\"). This clearly identifies the specific part of the paper and the issue being addressed. The reviewer does not need to infer the location or the problem, making the grounding very precise.", "verifiability_rationale": "The review point is a suggestion for improvement, not a claim that requires verification. It proposes a concrete change to enhance clarity. While it doesn't provide external references, the suggestion itself is logically sound and directly addresses the identified issue. Therefore, it can be considered 3 as it offers a clear and logical suggestion.", "helpfulness_rationale": "The review point is highly specific and directly addresses a concrete issue in the paper. It provides a clear and actionable suggestion for improvement, which is directly beneficial to the authors. It does not criticize the authors personally or make vague generalizations. The suggestion is constructive and directly addresses the identified problem."}
{"actionability_label": "5", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of speed analysis and suggests an alternative (FLOPs comparison). This directly points the authors to what needs improvement.", "grounding_specificity_rationale": "The reviewer mentions 'inference speed' and 'prior work' in general terms. While they imply the area of comparison, they don't specify a unique section, table, or figure. The suggestion to compare FLOPs doesn't add much specificity.", "verifiability_rationale": "The reviewer makes a claim about the importance of speed analysis but doesn't provide any evidence or reasoning to support this claim. The suggestion about FLOPs is presented as a preference, not a necessity or a welljustified alternative.", "helpfulness_rationale": "The review points out a specific area for improvement (inference speed) and provides a suggestion (FLOPs comparison). However, the justification for prioritizing FLOPs over speed is not provided, making the feedback less compelling."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem with quantization: it is not scalable and costly, especially with large datasets (N) and high dimensionality (M). They also state that this hinders the method's ability to achieve fast convergence, a stated goal in the abstract and introduction. The reviewer suggests that this makes the method lose its point, implying a lack of effectiveness. The reviewer identifies the issue and its consequence, which is a clear indication of an actionable point.", "grounding_specificity_rationale": "The reviewer directly addresses the scalability issue of quantization, which is a specific aspect of the method. They don't just say 'the method is bad,' but 'this specific part of the method is a problem.' They also specify the factors contributing to the problem: the cost associated with large datasets (N) and high dimensionality (M). This demonstrates a clear grounding of the issue within the method's technical details. The reviewer focuses on a specific component of the method and explains why it lacks grounding in terms of scalability.", "verifiability_rationale": "The reviewer makes a claim: 'Optimal quantization is not scalable... which makes the method loses its point.' This claim is supported by the reasoning provided, which explains *why* quantization is not scalable (costly to N and M) and *how* this impacts the method's ability to achieve fast convergence. The reviewer provides logical reasoning and specific examples (cost and scalability) to support their claim. The claim is not just a statement of fact but an analysis of the implications for the method's goals.", "helpfulness_rationale": "The reviewer provides a clear and actionable criticism. They identify a specific weakness in the paper's motivation (the lack of scalability of quantization hindering fast convergence) and offer a potential alternative approach by focusing on methods that don't have this issue. The reviewer explains *why* the quantization is a problem and *what* the consequences are for the method's effectiveness. This criticism is directly relevant to the paper's stated goals and provides a valuable insight for the authors to consider alternative approaches. The reviewer doesn't just complain; they offer a constructive critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the need for comparison to contrastive decoding and mentions notational issues. This is an explicit action pointing to specific areas for improvement. However, the reviewer doesn't specify *how* the comparison should be done or *what* the notational issues are, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'existing methods, such as contrastive decoding' and 'notations issues.' While they touch upon a category of methods, they don't pinpoint a specific section or table of the paper. They also don't explicitly state they are referring to a specific section, making the grounding weak. However, the reviewer is generally critical of the methodology, which could be interpreted as specifying the *nature* of the weakness, making it somewhat specific.", "verifiability_rationale": "The reviewer makes a claim: 'as part of the core methodology, the paper should compare its effectiveness against existing methods, such as contrastive decoding... Issues mentioned above should be addressed.' This is a claim that requires verification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no justification for why this comparison is necessary or what the notational issues might be. Therefore, the claim is not supported by any evidence.", "helpfulness_rationale": "The reviewer's comment is a general critique of the methodology and suggests a specific improvement (comparison to contrastive decoding). While this points to a potential area for improvement, the reviewer does not provide concrete steps or examples to make this suggestion helpful for the authors. The lack of specific details makes the comment somewhat vague and less actionable. The reviewer also mentions 'issues mentioned above,' which are not explicitly defined, further reducing the helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitations of the algorithm requiring the entire training dataset and the expectation for it to operate effectively without it. They also explicitly state the need for a time complexity analysis and a clearer technical contribution. These are all concrete and actionable suggestions.", "grounding_specificity_rationale": "The reviewer refers to 'the algorithm' and asks about its operation without the full dataset, time complexity, and technical contribution. While not always pointing to a specific section number, these are generally identifiable concepts within a research paper, and the reviewer is asking about the algorithm in general, which is a specific part of the paper. The reviewer also specifies what they expect the algorithm to do and what they don't like about it.", "verifiability_rationale": "The reviewer makes claims about the algorithm's limitations and expectations (requiring the full dataset, operating effectively without it, analyzing time complexity, and clarifying technical contribution). However, the paper itself, as presented in this context, does not provide specific evidence or references to support these claims. The reviewer is pointing out *what they wish the paper had addressed*.", "helpfulness_rationale": "The reviewer's overall comment is about the comprehensiveness of the validation experiments and the analysis of time complexity, which are valid points for improvement. The reviewer also explicitly states the expectation for a deeper technical contribution, which is a concrete suggestion. The phrasing 'Overall: ... the time complexity of the computation and the efficiency of the algorithm are not clearly analyzed' is particularly direct and actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states a limitation of using neural networks to represent kernels: that they can only represent finitedimensional RKHSs in practice, contrasting this with the infinitedimensional nature of some kernels like RBFs. This is an explicit action with concrete details (finite vs. infinitedimensional RKHSs) and a clear suggestion for improvement (\"make the limitation more clear\"). The reviewer provides a specific example (RBF kernels) to illustrate this point.", "grounding_specificity_rationale": "The review point explicitly mentions \"Reproducing Kernel Hilbert Spaces (RKHS)\" and uses the example of \"RBF kernels\". This clearly grounds the comment in specific aspects of the paper being reviewed. The reviewer also provides a concrete explanation of the issue related to the dimensionality of the RKHS.", "verifiability_rationale": "The claim in the review point, that \"one would need an NN with infinite width to represent it\" for infinitedimensional RKHSes like those of RBF kernels, is wellsupported by established knowledge of RKHS theory. The reasoning is generally accepted and the example of RBF kernels provides a concrete illustration.", "helpfulness_rationale": "The review point is 5 as it provides a specific example (RBF kernels) to illustrate the limitation of using neural networks for kernel representation. It also directly suggests a concrete improvement (\"make the limitation more clear\"), which is actionable for the authors. The reviewer provides a clear and informative critique."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the proposed method is not wellpositioned in literature and then provides specific examples (denoising score matching and scoreinterpolation) and explains the connection. This clearly indicates an actionable suggestion for the authors to improve their literature review and contextualize their work. The reviewer also suggests a thorough literature review, which is a concrete action.", "grounding_specificity_rationale": "The reviewer mentions that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is used in existing works like denoising score matching and scoreinterpolation. This directly grounds the comment in existing literature, as the authors can identify the specific concepts and areas they need to explore. While the reviewer doesn't explicitly point to a specific section, the mention of concrete examples provides grounding. The comment also specifies what needs to be addressed: understanding the connection to existing objectives.", "verifiability_rationale": "The reviewer makes a claim that the key idea of the proposed method is 'quite wellknown' and provides specific examples and explanations to support this claim. The reviewer explicitly names 'denoising score matching' and 'scoreinterpolation' as instances where this property is used, providing clear justification for the claim.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors: to investigate the connection of their method to existing objectives like denoising score matching and scoreinterpolation. This directly points the authors to specific areas of literature to explore and provides a clear purpose for their investigation. The reviewer also suggests a 'thorough literature review', which is a valuable and concrete piece of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer asks a direct question about the benefits of linear attention during inference, which can be interpreted as a suggestion for improvement in understanding the generation process. The question is specific to the interaction between linear attention and autoregressive decoding during the generation phase. The reviewer is seeking clarification on a technical aspect, which can be actionable by providing information or pointing to relevant resources. The question is clear and identifies a potential area for improvement in the understanding of the model's behavior during generation.", "grounding_specificity_rationale": "The reviewer's question is general and does not specify which part of the linear attention mechanism or the autoregressive process they are referring to. They are asking about the benefits of linear attention during inference in general. While the question is relevant, it lacks the specificity needed to pinpoint a particular aspect of the model or process. The reviewer is asking for a broader understanding rather than a detailed explanation of a specific component.", "verifiability_rationale": "The reviewer's question is not a claim or assertion. They are asking for information or clarification rather than making a statement that needs to be verified. Therefore, it does not fit into the categories of 'Claim Extraction' or 'Verifiability Verification'.", "helpfulness_rationale": "The reviewer's question is relevant to understanding a technical aspect of the model's behavior during inference. However, it is a question and does not directly provide actionable advice or a solution. It seeks information rather than a direct suggestion. While it points to a potential area for improvement, it doesn't immediately offer a concrete path forward. Therefore, it is not 5 in providing immediate guidance or improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides a clear argument for why the justification of PCC's relaxation strength over KL divergence is not convincing. They state: 'The assumption that PCC is a more relaxed constraint compared with KL divergence because of its invariance to scale and shift is not convincing enough.' This is a direct and explicit statement of the reviewer's understanding. They then offer a counterargument: 'The constraint strength of a loss function is defined via its gradient distribution. For example, KL divergence and MSE loss have the same optimal solution while MSE loss is stricter than KL because of stricter punishment according to its gradient distribution. From this perspective, it is necessary to provide the gradient comparison between KL and PCC.' This demonstrates that the reviewer understands the concept of constraint strength through gradient distribution and identifies a potential weakness in the paper's justification. The reviewer explicitly states an action: 'It is necessary to provide the gradient comparison between KL and PCC.' This action is directly derived from the reviewer's analysis.", "grounding_specificity_rationale": "The reviewer states their position about the justification of PCC's relaxation strength over KL divergence. However, they do not explicitly identify *where* within the paper this assumption is made. They are criticizing the *justification* of that assumption, but not pointing to a specific section being unclear. The reviewer's statement is a claim about the paper's content, but the grounding specificity is about how clearly the paper identifies the issue. The reviewer is not stating 'I cannot confidently determine which part of the paper this assumption is being made in.' They are stating a general critique about the justification. Therefore, the grounding specificity is not fully grounded. While the reviewer's statement is about a specific aspect of the paper (the comparison of PCC and KL divergence), the *identification* of where this assumption is made is missing.", "verifiability_rationale": "The reviewer makes a claim: 'The assumption that PCC is a more relaxed constraint compared with KL divergence because of its invariance to scale and shift is not convincing enough.' This is a direct statement of opinion. The reviewer then attempts to support this claim by stating: 'The constraint strength of a loss function is defined via its gradient distribution. For example, KL divergence and MSE loss have the same optimal solution while MSE loss is stricter than KL because of stricter punishment according to its gradient distribution. From this perspective, it is necessary to provide the gradient comparison between KL and PCC.' This is an attempt to verify the claim by explaining the concept of constraint strength through gradient distribution and suggesting a specific comparison. However, the reviewer does not provide any concrete evidence or references to support their initial claim that PCC's invariance is not a strong enough justification. The reviewer's argument is presented as a statement of opinion without direct evidence within the provided text. Therefore, the verifiability is '1' as the claim is presented without supporting evidence.", "helpfulness_rationale": "The reviewer provides a clear and logical argument against the justification for using PCC over KL divergence. They state their position: 'The assumption that PCC is a more relaxed constraint compared with KL divergence because of its invariance to scale and shift is not convincing enough.' They then offer a specific alternative: 'The constraint strength of a loss function is defined via its gradient distribution. For example, KL divergence and MSE loss have the same optimal solution while MSE loss is stricter than KL because of stricter punishment according to its gradient distribution. From this perspective, it is necessary to provide the gradient comparison between KL and PCC.' This argument is presented as a statement of opinion, and the reviewer does not provide any evidence or references to support their claim. However, the reviewer's statement directly addresses a potential weakness in the paper's justification and suggests a concrete alternative. This provides valuable information to the authors by highlighting a potential area for improvement in the paper's reasoning. The reviewer's statement is actionable for the authors by suggesting a different approach to constraint strength."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question about the impact of noise addition on GPI's fit with behavioral data, indicating an action to investigate this further. However, the reviewer does not explicitly state the action to be taken after identifying this potential issue (e.g., trying different noise levels, exploring alternative modeling approaches). The action is implied but not clearly articulated.", "grounding_specificity_rationale": "The reviewer refers to 'Fig. 4', 'GPI', 'noise added', 'behavioral data', 'behavioral trajectories', and 'time to goal' as specific elements. This demonstrates a clear attempt to pinpoint the area of concern and the specific aspects of the data being questioned. The language used, such as 'is it possible that GPI with noise added could reproduce the data similarly well', directly targets specific components of the analysis.", "verifiability_rationale": "The reviewer suggests exploring alternative measures beyond just the data in Fig. 4 and mentions 'pattern separation tasks' as a potential area for GPI. While this provides a direction for further investigation, the reviewer does not explicitly state how these alternative measures or tasks are verifiable or supported. The suggestions are presented as possibilities without clear justification or references.", "helpfulness_rationale": "The reviewer provides concrete suggestions, such as 'it seems to be suitable for modelling pattern separation tasks' and 'it would be nice to have some discussion on this'. These suggestions directly address potential limitations and offer actionable improvements for the authors. The reviewer is actively trying to help the authors understand and improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the experiment ('small learning rate for attention parameters') and the comparison ('with the proposed approach'). This is a clear and direct statement of an action to be taken. The action is also concrete, as the specific experiment and comparison are welldefined.", "grounding_specificity_rationale": "The reviewer mentions 'small learning rate for attention parameters' and 'proposed approach'. While they don't explicitly name a section or table, the concepts are quite specific. A reader familiar with the paper would likely understand what these terms refer to. The reviewer also implies a desire to compare these two aspects, which is a clear indication of grounding the comment in specific parts of the paper. The comment specifies what needs to be addressed (the experiment and the comparison).", "verifiability_rationale": "The reviewer suggests an experiment ('If you have the resources, I would be very interested to see how the \u201csmall learning rate for attention parameters\u201d benchmark...'). This is a suggestion, which can be considered a claim requiring justification. While the suggestion itself is verifiable in the sense that it's a concrete proposal, it doesn't provide a definitive answer or evidence. It points towards a specific area of investigation and is therefore 3 as it guides the authors towards a specific experiment.", "helpfulness_rationale": "The reviewer's suggestion to compare the 'small learning rate for attention parameters' benchmark with the 'proposed approach' is directly relevant to understanding the strengths and weaknesses of the proposed approach. This is a concrete suggestion that is likely to provide valuable empirical insights for the authors. It addresses a clear need for further experimentation and comparison."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the paper 'carelessly resolves a debate' and questions the methodology behind this resolution. They also explicitly ask 'why can't it be that the distribution has changed?' indicating a lack of clarity in the reasoning. While the reviewer doesn't provide concrete solutions, they clearly identify a potential area for improvement in the paper's methodology. The reviewer's statement 'Things I didn't understand:' suggests a lack of clarity in the paper's explanation, making the action implicit but the action itself clear.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'the paper' and asks specific questions about 'how it was previously handled,' 'distribution shifts,' and 'experiments disentangling.' This demonstrates strong grounding as the reviewer directly refers to the paper's content and methodology. The reviewer is also very specific about what they are questioning, indicating a clear specification of the issue.", "verifiability_rationale": "The reviewer mentions 'experiments disentangling changes in distribution from removal of information' as a potential gap. While the reviewer doesn't explicitly claim that this is a factual error, the lack of such experiments is a factual omission that could be considered a claim that needs justification. The reviewer's statement 'Things I didn't understand:' suggests a lack of clarity in the paper's explanation, which could be interpreted as a lack of justification for a claim.", "helpfulness_rationale": "The reviewer's comment is 5 as they are seeking clarification and understanding of the paper's methodology. They are pointing to a potential area of confusion or a flaw in the paper's approach. The reviewer is asking specific questions, which are actionable points for the authors. However, the reviewer does not offer solutions or alternative approaches, focusing more on identifying the problem than proposing a resolution."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to reproduce the baseline methods using the same training setup as the proposed method. This is a clear and direct action to address the identified issue.", "grounding_specificity_rationale": "The reviewer identifies a specific aspect of the paper being reviewed (the training parameters) and explains why it is important for a fair comparison. They pinpoint the lack of consistency in the training setup as a key factor that needs to be addressed. The reviewer also suggests a concrete solution (reproducing with the same settings), indicating a clear understanding of the problem and a specific plan to solve it.", "verifiability_rationale": "The reviewer makes a claim about the unfairness of the comparison due to the different training settings. While the reviewer identifies the specific issue (different training parameters), the *justification* for why this makes the comparison unfair is implied rather than explicitly stated with examples or references. The reviewer's intent is to highlight a potential flaw in the experimental setup.", "helpfulness_rationale": "The reviewer's comment is highly constructive and directly addresses a potential weakness in the paper being reviewed. They propose a concrete, actionable step (reproducing baselines with the same training settings) to improve the fairness and rigor of the comparison. This is a valuable suggestion that directly contributes to the improvement of the reviewed work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The suggestion to explore the combination of SOTA and an adaptive metric is explicit in mentioning the combination, which is a clear direction for improvement. However, it lacks specifics on which SOTA method or adaptive metric is being referred to, and how they should be combined, making it 3 but vague.", "grounding_specificity_rationale": "The comment refers to 'SOTA method' and 'adaptive metric' without specifying which ones or providing any context within the paper. This means the authors cannot confidently determine which part the comment addresses, making the grounding weak. Furthermore, the comment does not specify what needs to be addressed in this part, resulting in a lack of specificity.", "verifiability_rationale": "The review point does not present a claim or assertion that requires verification. It is a suggestion for further exploration rather than a statement that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The suggestion to explore the combination of SOTA and an adaptive metric is relevant to the potential for improvement in the paper. While the suggestion is vague, it points towards a valuable area of investigation and could lead to further discussion and potentially new experiments. Therefore, it is 3 in guiding the authors towards a potentially fruitful direction."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states several problems with the plots, such as them being 'too small,' having 'hard to distinguish' colors, 'poorly labeled' axes, and 'visually too similar' labels. These are all concrete actions or suggestions that the authors can directly implement to improve the presentation of their experimental results. The reviewer also implies an action by stating that these plots are the 'main presentation of the experimental results' and should be 'much clearer', indicating a desire for improvement.", "grounding_specificity_rationale": "The reviewer explicitly identifies the 'plots' as the problematic area and even specifies the exact plots being referred to as 'sdropout(tr)' and 'edropout(tr)'. This demonstrates a strong grounding as the authors can easily identify the specific part of the paper being addressed. Furthermore, the reviewer provides specific criticisms within those plots, such as the size, color contrast, and label similarity, indicating a high level of specificity.", "verifiability_rationale": "The review point contains a claim that the 'plots are terrible'. This claim is supported by the reviewer providing reasons for their assessment, such as them being 'too small,' having 'hard to distinguish' colors, 'poorly labeled' axes, and having 'visually too similar' labels. While these reasons are subjective, they provide a basis for understanding why the plots are problematic and how they could be improved. The reviewer does not explicitly cite external references for poor plot design, but the reasons provided are generally accepted principles of data visualization.", "helpfulness_rationale": "The review point is 5 because it directly addresses a critical aspect of the presentation of the experimental results. The reviewer not only identifies the problem ('plots are terrible') but also provides specific suggestions for improvement, such as making the plots larger, using colors that contrast better, labeling the axes clearly, and using different labels for the similar plots. These suggestions are concrete and actionable, giving the authors a clear direction for revising their figures."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states that the performance gains are 'not very high' and 'less than 1%'. This is a direct action pointing out a potential issue with the proposed changes (caption and warmup). The reviewer is suggesting the authors review their caption and warmup strategies based on this observation.", "grounding_specificity_rationale": "The comment refers to 'caption' and 'warmup' without explicitly naming specific sections or tables. However, it's a common practice in NLP papers to describe these components. The reviewer implicitly refers to the caption of the model and the warmup schedule used. The comment specifies the impact of these components on performance (not very high, less than 1%).", "verifiability_rationale": "The comment contains a claim: 'the performance gains are not very high...less than 1%'. However, it does not provide any evidence or justification to support this claim. It simply states the observation. There is no logical reasoning, common knowledge, or external references provided to verify this statement. The reviewer is pointing out a discrepancy, not verifying a claim.", "helpfulness_rationale": "The comment is helpful in guiding the authors to reevaluate their caption and warmup strategies based on the observed lack of significant performance gains. It provides a clear direction for improvement by suggesting a review of these specific components. While it doesn't offer a solution, it highlights a potential area for investigation, which can be beneficial for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "Not Helpfulness", "actionability_rationale": "The review point itself does not explicitly state what action should be taken. The reviewer is suggesting improvements to the feedback system, which is an implicit action. While the reviewer implies that the feedback system should value specific details, the point itself lacks a clear instruction on how to apply this.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or system being discussed. It is a general question about the feedback system. While it implies referring to a feedback system, it doesn't pinpoint a specific instance or component within that system.", "verifiability_rationale": "The review point does not contain a claim that can be verified. It is a suggestion for improvement rather than a statement that requires justification. There is no logical reasoning, common knowledge, or external references provided within the review point itself.", "helpfulness_rationale": "The review point does not directly address the feedback being reviewed. It focuses on the feedback system and its value. While the reviewer believes this feedback is helpful, the point itself does not provide actionable advice or insights specific to the paper being critiqued."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that Table 1 does not show standard deviations. While it doesn't explicitly say *how* to fix this, it implies the authors should add them. This makes the action somewhat explicit but not fully concrete.", "grounding_specificity_rationale": "The review point explicitly refers to 'Table 1' and mentions 'standard deviations'. This clearly identifies the specific part of the paper being addressed and the specific issue. Therefore, it is 5.", "verifiability_rationale": "The claim that 'Table 1 does not show standard deviations' is verifiable by checking the table. However, the reviewer also states that 'this includes' other related points, which are not explicitly justified within this part of the review point. The suggestion to make experiments more extensive is a general statement.", "helpfulness_rationale": "The review point directly points out a missing element (standard deviations) in a specific table. It also provides a suggestion to improve the experiments, which is a helpful and actionable comment. The reviewer clearly implies the authors should add the standard deviations."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer raises a question about the interpretation of the experimental results but does not explicitly state a concrete action or suggestion for the authors to take. While the question is relevant, the lack of a direct action makes it less actionable. The reviewer asks 'is there still a performance boost?' but does not propose a specific experiment or analysis to investigate this.", "grounding_specificity_rationale": "The reviewer refers to 'LinearTop', 'NLTop', and 'Unary' in the context of the tables, which suggests an attempt to ground the comment in specific elements of the paper. However, the reviewer does not explicitly state which section or table within the paper they are referring to. While the terms are mentioned, the connection to a specific part of the paper is not clearly established.", "verifiability_rationale": "The reviewer claims there is a potential inconsistency in the interpretation of the results, specifically regarding the performance of different models and the comparison to 14. However, the reviewer does not provide any explicit evidence, reasoning, or references within the review point to support this claim. The claim is based on an external reference (14) rather than internal justification within the provided text.", "helpfulness_rationale": "The reviewer raises a valid point about the potential inconsistency in the interpretation of the experimental results. However, the reviewer does not offer any concrete suggestions or actions for the authors to take based on this observation. The comment is primarily a question and a statement of concern, lacking actionable guidance."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests improvements such as 'improve the structure' and 'improve the visualization of the Fig 7, and Fig.' While these suggestions are relevant, the specific actions are not detailed. The reviewer does not explicitly state how to improve the structure or how to visualize the figures better. The suggestions are general and lack concrete steps. Therefore, the reviewer points out areas for improvement, making the comment actionable in principle, but the lack of specific details makes it vague.", "grounding_specificity_rationale": "The reviewer suggests improvements for 'introduction>method>experiments' and 'put more focus on the IEM in Fig 3'. While the reviewer *mentions* specific sections and a specific figure, they do not explicitly identify the *exact* part within those sections or the figure that needs improvement. The suggestions are general, indicating a lack of precise identification of the problematic areas. Therefore, the reviewer points to areas needing improvement, but the lack of specific identification within those areas makes the grounding weak.", "verifiability_rationale": "The reviewer states 'The paper is a bit hard to follow' and offers suggestions like 'improving the structure' and 'improving the visualization of the Fig 7, and Fig.' There are no explicit claims being made. The reviewer is providing feedback and suggestions, not stating something that requires verification or justification. Therefore, there are no claims in the review point, fitting the 'X' category.", "helpfulness_rationale": "The reviewer identifies a clear issue ('The paper is a bit hard to follow') and offers relevant suggestions ('improve the structure', 'improve the visualization of the Fig 7, and Fig.', 'improve the visualization of the Fig 7, and Fig.'). The suggestions are directly related to the identified issue and provide a direction for improvement. While the specific actions are not detailed, the feedback itself is helpful in guiding the authors on what needs to be addressed. Therefore, the reviewer provides feedback that is relevant and actionable, even if the specific actions are not fully defined."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests expanding the experiments to other architectures and classification tasks. While this is a valid suggestion for improving the paper, it is not an explicit action or a concrete step that the authors can directly follow. The reviewer implies a broad scope rather than a specific, actionable change. Therefore, the actionability is implicit and lacks clear direction.", "grounding_specificity_rationale": "The reviewer suggests expanding the experiments to other architectures and classification tasks. However, the reviewer does not explicitly identify which part of the paper is lacking or specify the exact nature of the missing information. The suggestion is general and does not pinpoint a specific section, table, figure, or unique element of the paper. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The reviewer's comment contains a claim: 'It would be interesting to see the performance of attack on other architecture and classification tasks.' This claim is not supported by any evidence or reasoning within the review point. The reviewer is simply stating their suggestion without providing any justification or references. Therefore, the verifiability is low as there is no supporting evidence for the claim.", "helpfulness_rationale": "The reviewer's comment suggests expanding the experiments to other architectures and classification tasks. While this could be a valuable suggestion for the authors, it is not a direct critique or a clear set of actionable steps. The reviewer is making a suggestion for future work rather than providing immediate feedback. Therefore, the helpfulness is moderate as it points to a potential improvement but lacks specific guidance."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the desired information: 'I'd like to know the final used learning rates for the deep models (particularly CIFAR10 and CIFAR100)'. This is a clear and direct request for action. The reviewer also implies a concern about the limited search space of learning rates, suggesting they believe the optimal rate might be outside the tested interval. This further indicates an actionable request for clarification or information.", "grounding_specificity_rationale": "The reviewer mentions 'deep models' and specifically 'CIFAR10 and CIFAR100', but does not identify a *specific* model or implementation within those categories. While the general area is clear, the exact model or architecture is not specified. This provides some grounding but lacks the specificity of identifying a unique element. The reviewer is implicitly asking for information relevant to the experiments conducted, which is a form of grounding, but it's not as precise as identifying a section or table by name.", "verifiability_rationale": "The reviewer is not presenting a claim or making a judgment. They are directly asking for information about the final learning rates used in the experiments. There is no logical reasoning, common knowledge, or external references provided in this review point. It is a factual request.", "helpfulness_rationale": "The reviewer's comment is directly pointing out a missing piece of information (final learning rates) that is crucial for understanding and potentially reproducing the results. They are also expressing concern about the limited search space of learning rates, which could potentially affect the validity of the findings. This feedback is specific and actionable, highlighting a potential issue with the experimental setup or reporting. While it doesn't directly instruct how to improve the paper, it identifies a significant gap in the provided information."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer expresses a disagreement with the choice of a 'no locality bias' transformer model and asks for a justification. While they don't explicitly state a specific action they want the authors to take, the implicit suggestion is that the current choice might be suboptimal. The reviewer is pointing towards a potential area for improvement, but the action isn't directly stated.", "grounding_specificity_rationale": "The reviewer refers to 'transformer free of localitybias' and 'neighborhood agents' as examples of issues. However, they do not explicitly identify the specific section, table, or unique aspect of the paper they are referring to. The concepts are mentioned generally, without pointing to a particular location in the paper. The reviewer also doesn't provide a specific example of where this bias might be a problem. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer does not present a claim that requires justification. They are simply expressing an opinion about the suitability of a particular model choice and asking for a rationale. There are no statements that need to be logically reasoned, supported by common knowledge, or backed by external references to be considered verifiable.", "helpfulness_rationale": "The reviewer directly addresses a specific design choice in the paper ('transformer free of localitybias') and asks for a justification. This is a clear and actionable feedback that directly targets a potential improvement. The reviewer is actively engaging with the paper and seeking to understand a key decision, making this feedback highly valuable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement is explicit about the potential dependency and suggests clarifying the issue. The reviewer is indicating a concrete action (clarification) is needed. While the dependency itself might be vague, the reviewer explicitly states it, making it more actionable than '1 and underspecific' or '3'.", "grounding_specificity_rationale": "The reviewer makes a general statement about the algorithm's dependency on the order of data processing. They do not explicitly point to a specific part of the paper or data being affected. The statement is about the algorithm in general, not a specific section of the draft. Therefore, it lacks grounding specificity.", "verifiability_rationale": "The statement is a factual observation about how algorithms work. It doesn't present a claim that requires verification in the context of the paper itself. It's a statement about the algorithm's behavior, not a claim about the paper's content or quality. Therefore, it's not verifiable in the sense of providing new information about the paper.", "helpfulness_rationale": "The statement identifies a potential issue with the algorithm's documentation or implementation and suggests clarifying it. This points to a concrete action (clarification) that could improve the draft. While it might not be a major discovery, it's a valuable piece of feedback that suggests a specific improvement. Therefore, it's 3 as it points towards actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the impact on performance: \"it's unclear what impact they might have on the overall performance of the model.\" It also suggests a potential consequence: \"If these mitigation strategies significantly impair the model's utility, it might deter their adoption.\" This suggests a clear action the authors could take: investigate the performance impact and check for utility deters.", "grounding_specificity_rationale": "The review point refers to \"mitigation strategies\" generally. It mentions \"performance of the model\" generally. It discusses a \"tradeoff\" generally. It refers to \"utility of the model\" generally. There is no specific section, table, figure, or unique aspect of the paper being directly addressed.", "verifiability_rationale": "The review point contains the claim: \"it's unclear what impact they might have on the overall performance of the model.\" This claim is based on the general understanding of mitigation strategies and their potential tradeoffs with performance, which is a common knowledge or logical reasoning point. The statement \"Often, there's a tradeoff between reducing a particular behavior and maintaining high performance\" provides justification for the first claim. The second part, \"If these mitigation strategies significantly impair the model's utility, it might deter their adoption,\" is a logical consequence and doesn't require external references in this context.", "helpfulness_rationale": "The review point raises a valid concern about the potential negative impact of mitigation strategies on model utility. It connects this concern to a practical consequence (detering adoption). This provides the authors with a reason to investigate further and potentially adjust their mitigation strategies."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer identifies a missing justification for using 6fold crossvalidation. While they don't explicitly state what action is being taken *with* the crossvalidation, the implication is that the crossvalidation is being used to evaluate the model's performance on unseen data. The action is implicit, requiring the authors to infer the purpose. The concreteness of the action is unclear as the reviewer doesn't specify *how* the crossvalidation is being used to improve the draft.", "grounding_specificity_rationale": "The reviewer is primarily concerned with the *reason* for using 6fold crossvalidation. They are asking *why* it's necessary, which implies they are not explicitly stating what the crossvalidation is being used for *in this specific paper*. The grounding is in the *reasoning* behind the choice, which is not clearly articulated. The specificity is low as the reviewer is not pinpointing a specific part of the paper being addressed in relation to the crossvalidation.", "verifiability_rationale": "The reviewer expresses uncertainty about the *justification* for using 6fold crossvalidation. They are questioning the *reasoning* behind their claim that the reason is not understood. This lack of clear reasoning or supporting evidence makes the claim somewhat 1. The reviewer is essentially stating a lack of justification, which is a claim that requires verification.", "helpfulness_rationale": "The reviewer's uncertainty about the *justification* for using 6fold crossvalidation translates to a lack of clear *value* for the authors. The comment is framed as a question about the *reason* for the crossvalidation, rather than a statement of how it helps them improve their draft. Therefore, the feedback is not clearly actionable and impactful."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "1", "actionability_rationale": "The review point criticizes the experimental evaluation but does not provide explicit or implicit suggestions on how to improve the evaluation itself or the proposed methods. The comment focuses on the *results* of the experiments rather than guiding the authors on *what to do* to address the identified limitations. Therefore, the action is implied but not explicitly stated in the review point.", "grounding_specificity_rationale": "The reviewer mentions 'Table 2' as the specific part of the paper being criticized, which can be considered 'full grounding'. However, the criticism is general, stating that the proposed approaches only outperform in one setup and there's no consistent trend. While the part of the paper is identified, the specific issue or flaw within Table 2 and the comparison between different proposed methods are not clearly defined. The reviewer doesn't specify *which* part of Table 2 is problematic or *which* method is better. Therefore, it's weakly grounded but not fully specific.", "verifiability_rationale": "The reviewer makes a claim that 'the results presented are insufficient to prove the benefits of the proposed methods.' This claim can be considered verifiable because it points to a logical consequence of the experimental results \u2013 the lack of consistent and significant outperformance. While the claim doesn't provide specific examples or references, the reasoning is clear and based on the observed data. Therefore, the claim is verifiable, but it lacks specific justification.", "helpfulness_rationale": "The review point criticizes the experimental evaluation and the lack of sufficient results. While this is a valid concern for the authors who likely spent time on the proposed methods, the review point itself does not offer any actionable suggestions or insights on how the authors can improve their methods or experiments based on this criticism. The feedback is focused on the evaluation rather than providing guidance on how to address its shortcomings. Therefore, the review point is not helpful in terms of providing concrete improvements to the authors' work."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a potential area for improvement by pointing out the presence of heuristic components. However, it does not explicitly state what actions the authors should take to address this. The reviewer raises a question about the impact, but lacks a direct action for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions 'NonAmbiguous Query Generation procedure relies on a sophisticated filtering template.' This clearly identifies a specific part of the paper and how the authors can locate it. The reviewer can easily find the relevant section.", "verifiability_rationale": "The review point makes a claim that 'It would be helpful if the author could clarify the impact of these heuristic components.' However, it does not provide any supporting evidence, examples, or references to back up this claim. The reasoning is vague and lacks detail.", "helpfulness_rationale": "The review point identifies a valid concern about the heuristic components. However, it does not offer concrete actions or guidance on how the authors should analyze or improve these components. It is a call for clarification rather than a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a missing piece of information needed for the proposed method (ray marching) to function correctly. They identify the 'knowledge of CAD model correspondences' as essential for determining the 'ray origin'. While the reviewer doesn't explicitly state an *action* to take, they highlight a necessary input that is missing, making the criticism 3 in identifying a gap.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'knowledge of CAD model correspondences' as a specific piece of information needed to address the limitation of not having camera information. They connect this specific detail to the proposed method (ray marching), indicating a clear grounding of the criticism in a specific aspect of the paper.", "verifiability_rationale": "The reviewer questions the claim that the proposed method can be trained without camera information, specifically the 'knowledge of CAD model correspondences'. They argue that without this knowledge, determining the 'ray origin' becomes impossible. The reviewer provides a logical argument based on their understanding of the method, suggesting a partially verifiable claim as they provide reasoning but might be missing some explicit references or examples to fully support their claim within this specific point.", "helpfulness_rationale": "The reviewer raises a valid point about a potential limitation of the proposed method. They highlight a specific assumption that might not hold true in all scenarios. While they don't offer a direct solution, they point out a potential area for improvement, making the critique 3 in identifying a potential weakness."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the paper would benefit from a more detailed comparison with related work. This is an explicit action. Furthermore, the reviewer specifies the *content* of this comparison, mentioning 'time complexity and competitiveness'. This specificity makes the action concrete. Therefore, the review point provides clear guidance on what the authors should do.", "grounding_specificity_rationale": "The reviewer mentions 'related work' generally but does not specify which section, table, figure, or unique aspect of the paper is being addressed. While the reviewer mentions specific *topics* for comparison ('time complexity and competitiveness'), the *location* within the paper is not pinpointed. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The reviewer makes a statement about the paper 'benefiting' from a more detailed comparison. This is a suggestion, not a direct claim requiring verification in the traditional sense. However, the *implied* claim is that the *absence* of this comparison is a weakness. This is a bit ambiguous. Crucially, the reviewer does not provide any evidence or justification for their claim. There is no logical reasoning, common knowledge, or external references provided to support the assertion that a detailed comparison is indeed beneficial or necessary. Therefore, the verifiability is low as there is no supporting evidence or justification for the claim.", "helpfulness_rationale": "The reviewer's desire for a more detailed comparison with related work, especially regarding 'time complexity and competitiveness', is a valuable direction for improvement. Even though the reviewer does not provide a strong justification for this desire, the *content* of the feedback is constructive and points towards a specific area for enhancement. Therefore, the review point has some inherent value in terms of guiding improvement, even without explicit justification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the presented method does not clearly show how it improves performance and computation speed compared to just using ODA. While the reviewer identifies a potential weakness in the paper's presentation, the actionability of this point is somewhat vague. The reviewer doesn't explicitly state what aspect of the method's improvement is unclear, leaving the reader to infer the ambiguity. The reviewer identifies an implicit action (identifying a lack of clarity) but doesn't provide concrete details on what needs to be done to address this issue.", "grounding_specificity_rationale": "The reviewer's comment refers to 'ODA' and 'the presented method' in a general sense. While they are addressing the relationship between these two, they do not explicitly point to a specific section, table, figure, or unique element of the paper where this lack of clarity exists. The reviewer's comment is more about the general flow and explanation of the methods rather than pinpointing a precise location within the paper.", "verifiability_rationale": "The reviewer makes a claim that 'the presented method has learned the policy to imitate the problemsolving method, but it did not clearly suggest how the presented method improved the performance and computation speed of the solution rather than just using ODA.' This is a claim that requires verification. The reviewer's statement is based on their interpretation of the paper's content and identifies a gap in the explanation. However, the paper itself doesn't explicitly state that the presented method *only* imitates ODA in terms of problemsolving. The reviewer is inferring this limitation based on the paper's description of the presented method. Therefore, the claim is not directly supported by explicit evidence within the paper, making it 1 based on the provided text.", "helpfulness_rationale": "The reviewer's comment is a question about how the presented method improves upon ODA. While this points out a potential area for clarification in the paper, it doesn't offer a solution or suggestion for how to address this lack of clarity. The reviewer is identifying a problem but not proposing a concrete improvement. Therefore, the helpfulness of this comment is limited as it doesn't directly contribute to resolving the identified issue."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'clarify' as an action and points to specific lines in Figure 4 ('No adapt or Finetune are covered by other lines'), indicating a concrete action to be taken.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 4' and then points to specific lines within that figure ('No adapt or Finetune'), indicating a clear and accurate identification of the part of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim about the figure's clarity and provides a specific example ('the line of No adapt or Finetune are covered by other lines'), which can be verified by examining the figure itself.", "helpfulness_rationale": "The reviewer directly points out a problem ('Some figures are not selfexplanatory') and provides a specific suggestion ('For instance, in Figure 4, the line of No adapt or Finetune are covered by other lines, without additional explanation'), making the feedback actionable and directly useful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the importance of the sampling method for convergence. However, it does not specify which sampling method is important or how to apply this action to improve the draft. The action is stated but not concretely implemented.", "grounding_specificity_rationale": "The review point mentions the importance of sampling and convergence but does not explicitly identify a specific part of the paper or a specific element within the optimization process that needs improvement. The comparison to uniform sampling in the supplementary material is a general point about experimental evaluation, not a specific detail within the current work.", "verifiability_rationale": "The review point contains a claim that the sampling method is important for convergence. However, it does not provide specific evidence or reasoning to support this claim within the main text. The reasoning provided is a general statement about the lack of experimental evaluation, which is not as strong as providing specific examples or references.", "helpfulness_rationale": "The review point identifies a potential weakness in the experimental evaluation by highlighting the lack of careful evaluation of the sampling method's impact on convergence. While this points to an area for improvement, it does not provide specific guidance on how to address this issue or what experiments to conduct. The helpfulness is limited by the lack of concrete suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer raises several questions about the rationale for the comparisons, the justification for computational cost comparisons, and the lack of discussion on computational cost. While the paper states the comparisons and computational costs, it does not explicitly explain the *why* behind these choices. The reviewer's questions highlight a lack of clear reasoning and a potential lack of clarity in the paper's methodology and experimental setup. The paper mentions the comparisons with 9 and 16 but doesn't elaborate on the *rationale* for this specific selection or the *reasons* for not comparing with other methods. Similarly, the paper states the computational cost but doesn't explain *why* these comparisons are important or *why not* compare with other methods. The lack of discussion on computational cost further contributes to the lack of actionability. The reviewer's questions are not just 'what' but also crucial 'why'. The paper presents the comparisons and costs but doesn't delve into the *reasoning* behind them.", "grounding_specificity_rationale": "The reviewer's questions about the rationale for comparisons and computational cost are not explicitly linked to specific parts of the paper. The paper mentions the comparisons and computational costs but doesn't specify *where* in the paper these are relevant. For example, the paper might compare with 9 because it's a common baseline, but this isn't stated. Similarly, the paper might compare computational cost with 9 due to its accessibility, but this isn't explained. The lack of specificity makes it difficult to pinpoint the exact issues being addressed. The reviewer's questions are general and don't target specific sections, tables, or figures. The paper doesn't provide *specific* examples or references to support these claims. The lack of grounding makes it difficult for the authors to understand the *specific* issues being addressed.", "verifiability_rationale": "The reviewer claims that the paper lacks justification and verifiability. The paper states the computational cost but doesn't provide *reasons* or *evidence* to support this claim. The paper presents the comparisons and computational costs but doesn't explain *why* these are important or *why not* compare with other methods. The lack of justification and evidence makes it difficult to verify the claims made in the paper. The reviewer's questions highlight the absence of logical reasoning and external references to support the claims. The paper presents the information but doesn't provide the *why* or the *how*.", "helpfulness_rationale": "The reviewer's concerns about the lack of justification and grounding significantly impact the helpfulness of the review point. The paper states the comparisons and computational costs but doesn't explain *why* these are important or *why not* compare with other methods. The lack of justification makes it difficult for the authors to understand the *rationale* behind these choices. The paper mentions the computational cost but doesn't specify *where* in the paper this is relevant, making it difficult for the authors to understand the *implications* of this cost. The lack of discussion on computational cost further contributes to the lack of helpfulness. The reviewer's questions are not just 'what' but also crucial 'why' and 'how', which are missing from the paper."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests \"conducing experiments\" or \"conducting experiments,\" which is an explicit action. However, the reviewer does not provide concrete details on how to apply this action, such as which additional datasets to use, how to analyze the results, or what specific aspects of the method should be evaluated on these new datasets. The action is stated, but the implementation details are missing, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions \"more datasets\" but does not specify which particular datasets are lacking results or what characteristics of the datasets are relevant. The reviewer does not identify a specific section, table, figure, or unique aspect of the paper being addressed. The reference is general, and the authors cannot pinpoint the exact area of improvement.", "verifiability_rationale": "The reviewer states that there is a \"lack of experimental results on more datasets\". This is a claim that needs to be supported. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to back up this claim. The claim is made without sufficient justification or examples.", "helpfulness_rationale": "The reviewer suggests conducting experiments on 'more datasets'. While this is a relevant point for improving the evaluation of the proposed method, the suggestion lacks specific details and justification. The reviewer does not explain why more datasets are needed, what specific aspects of the method should be evaluated on these new datasets, or how the results should be analyzed. The feedback is present but lacks clarity and actionable steps, making it less helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' While they identify a lack of understanding, they don't explicitly state what is unclear or suggest a specific action to take. The reviewer's statement indicates a lack of clarity, but not a direct instruction on how to improve the draft based on this lack of clarity.", "grounding_specificity_rationale": "The reviewer states that 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' and 'All in all, the whole dataset transformation and the ensuing experimental setup felt very cumbersome, and not very clear.' The reviewer criticizes the process but does not identify a specific part of the paper or dataset that is unclear. They are broadly criticizing the process, not pinpointing a specific element within the paper.", "verifiability_rationale": "The reviewer states that 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' This statement can be considered a claim, as it expresses an opinion or a judgment about the clarity of the methodology. However, the reviewer does not provide any evidence or justification to support this claim. The criticism is about the lack of clarity of a process, not about the verifiability of a statement within the paper itself.", "helpfulness_rationale": "The reviewer states that 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' and 'All in all, the whole dataset transformation and the ensuing experimental setup felt very cumbersome, and not very clear.' This comment primarily criticizes the methodology without offering any suggestions or improvements. The reviewer does not provide any actionable feedback to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the PL condition and its relation to a specific paper. While it doesn't explicitly state an action or demand a change, it implicitly suggests that the PL condition used in the paper might be relevant to the work in the cited paper. This could be seen as a suggestion for improvement by prompting the authors to consider alternative PL conditions or a more thorough literature review. However, the action is not explicitly stated, making it less actionable.", "grounding_specificity_rationale": "The review point asks a question about the PL condition and its relation to a specific paper. It does not explicitly identify a specific part of the paper being addressed. The question is general and doesn't pinpoint a particular section, table, figure, or unique aspect of the paper. Therefore, the grounding is weak as the authors have to infer which part of their work the PL condition is relevant to.", "verifiability_rationale": "The review point asks a question about the PL condition and its relation to a specific paper. It does not contain a claim that requires verification. It's a question posed to the authors, not a statement that needs to be proven or justified. Therefore, verifiability is not applicable as there is X being made.", "helpfulness_rationale": "The review point asks a question about the PL condition and its relation to a specific paper. While this could be valuable information for the authors, it is a broad request and does not directly identify a weakness in their work or provide a specific suggestion for improvement. It encourages the authors to do more research but doesn't pinpoint an actionable step. Therefore, it is not 5 as it lacks specificity and directness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the 'complete lack of discussing the impact of adding additional parameters and additional computational effort'. This is a clear indication of an actionable point for the authors. While the action is not fully specified, the reviewer identifies a missing piece of information.", "grounding_specificity_rationale": "The reviewer mentions 'computational effort', 'multistage training', and 'multiple discriminators'. While they identify the *types* of information missing, they do not explicitly identify the specific section, table, figure, or unique element of the paper where this discussion is lacking. The grounding is present in the general areas of concern, but not in a precise location.", "verifiability_rationale": "The reviewer makes a claim: 'there is a complete lack of discussing the impact of adding additional parameters and additional computational effort'. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as an observation rather than a welljustified assertion.", "helpfulness_rationale": "The reviewer points out a specific and relevant weakness in the paper: the absence of a discussion regarding the computational cost implications of the proposed method. This is a clear and actionable feedback for the authors, highlighting a potential area for improvement in their analysis or presentation."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem: 'the analysis of the correlation between dataset size and the Frobenius norm and the singular values is underwhelming.' It also provides clear actions for improvement: 'the trend isn't clear across different model architectures' and 'no theoretical evidence is advanced'. These actions are concrete and directly address the identified issue.", "grounding_specificity_rationale": "The reviewer refers to 'the analysis of the correlation between dataset size and the Frobenius norm and the singular values' without specifying a particular section, table, or unique aspect of the paper. While the issue is specific to the analysis, the reference to the analysis itself is broad.", "verifiability_rationale": "The review point contains a claim: 'the analysis of the correlation between dataset size and the Frobenius norm and the singular values is underwhelming.' However, this claim is not supported by any evidence or justification within the review point itself. The reviewer states their opinion about the analysis's quality without providing specific examples or references to external works.", "helpfulness_rationale": "The review point identifies a clear weakness in the analysis: the lack of generalizability of the correlation across different model architectures and the absence of theoretical backing. It provides actionable suggestions: 'investigate different model architectures' and 'advanced theoretical evidence.' These suggestions are specific and directly address the identified limitations, making the review point valuable for guiding improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer raises a question about a potential flaw in the experimental setup (AutoAugment's training data) and its implications. While the question itself is not explicitly stated as an action, it implicitly suggests a need to consider the impact of the training data on the learned augmentation policy. This could be interpreted as an actionable suggestion for the authors to investigate the potential for information leakage and its consequences.", "grounding_specificity_rationale": "The reviewer mentions 'L114,' indicating they are referencing a specific part of the paper. They are also asking a question about the implications of a finding, which could be seen as indirectly referring to a specific section. However, the question is more about the *implications* of a potential flaw rather than a direct critique of the content at that specific location. Therefore, it can be considered weakly grounded as the reference is explicit, but the subsequent question is more about interpretation.", "verifiability_rationale": "The reviewer is making an inference about a potential flaw in the experimental setup (AutoAugment's training data) and its implications for SSL algorithms. While the general idea of information leakage is a known concept, the specific claim about AutoAugment's policy being obtained through supervised training on ImageNet and the resulting information leakage is a plausible hypothesis. The reviewer also raises a question about the impact on SSL algorithms that strive for generic representations, which could be supported by logical reasoning about the nature of pretraining and SSL. Therefore, the claim is 3 as it is based on logical reasoning and common knowledge in the field, although the specific details might require further investigation.", "helpfulness_rationale": "The reviewer raises a valid concern about a potential flaw in the experimental setup (AutoAugment's training data) and poses a relevant question about its implications for SSL algorithms. This could help the authors refine their understanding of the relationship between pretraining data, augmentation strategies, and SSL. The question about whether matching datasets is a setback for SSL and the connection to combining datasets are also relevant and thoughtprovoking. This review point offers valuable insights and raises important questions for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "6: X (X)", "helpfulness_label": "1", "actionability_rationale": "The review point suggests an *interesting* possibility but doesn't *imply* any action. It's a statement of fact about a potential future direction. While it points out a potential area, it lacks the explicit and concrete actions needed for actionability. Therefore, it's 2 as it doesn't clearly state what needs to be done or how to do it.", "grounding_specificity_rationale": "The review point is about *general* multimodal data, not specifically about a particular section, table, figure, or unique element within the paper. The reviewer is making a general observation about a potential future direction, not referencing a specific part of the current paper. Therefore, it doesn't ground the discussion in a specific part of the paper, making it **1**.", "verifiability_rationale": "The review point is a suggestion for future research. It's not presenting a claim that needs verification. It's an *interesting* observation, not a critique or a statement of what *is* lacking. Since it's not a claim, there's no evidence to assess its verifiability. Therefore, it's **X (X)**.", "helpfulness_rationale": "The review point is about exploring multimodal data as a future direction. While interesting, it doesn't directly address *any* specific weaknesses or improvements in the *current draft*. It offers a potential avenue for future work but doesn't provide immediate, actionable feedback for improving the existing paper. Therefore, it's **1**."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The first part of the review point, 'For the languageagnostic characters of entity representations, the paper has weak analysis on the alignment of entity representations,' is an **implicit** action. The reviewer doesn't explicitly state what they want to do, but rather points out a deficiency in the existing analysis. It is also **vague** because it doesn't specify what aspects of the alignment are weak or how the analysis is lacking. The second part, 'the authors could add more analysis about the multilingual alignment of entity representations,' is an **explicit** action, as the reviewer directly states they want more analysis. However, it is **vague** because it doesn't specify what kind of analysis, how much more, or what specific aspects of alignment they want examined. Overall, the review point lacks clear and concrete actions or suggestions.", "grounding_specificity_rationale": "The first part of the review point, 'For the languageagnostic characters of entity representations, the paper has weak analysis on the alignment of entity representations,' is **weakly grounded**. The reviewer mentions 'entity representations' and 'alignment' but doesn't explicitly identify a specific section, table, figure, or unique aspect of the paper where this weakness manifests. While the concepts are related to the paper, the connection isn't clearly established. The second part, 'the authors could add more analysis about the multilingual alignment of entity representations,' is also **weakly grounded**. Similar to the first part, the reviewer mentions 'multilingual alignment' and 'entity representations' but doesn't pinpoint a specific section or aspect where this analysis is lacking. Although the mention of 'language families' and 'lowresource languages' adds a bit of specificity, the overall suggestion remains broad and doesn't directly point to a concrete part of the paper.", "verifiability_rationale": "The review point makes a claim: 'the paper has weak analysis on the alignment of entity representations.' This is a statement of opinion or judgment. However, the **verifiability** of this claim is **low**. The reviewer states the weakness but doesn't provide any evidence, logical reasoning, or external references to support this claim. There are no specific examples or references to external works that would justify the assertion of 'weak analysis'. The reasoning provided is simply a statement of opinion without any backing.", "helpfulness_rationale": "The review point provides **specific areas for improvement**, such as 'multilingual alignment,' 'language families,' and 'lowresource languages.' This suggests a desire to enhance the paper. However, the **helpfulness** is **low** because the reviewer doesn't provide any concrete evidence or reasoning to support their claim about the 'weak analysis.' Without evidence, the authors have no basis to understand what specific changes are needed or how to approach them. The suggestion to 'add more analysis' is broad and lacks direction, making it less helpful than a more specific suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a need for more details but lacks specific instructions on how to achieve this or where to implement the suggestion. It points to a potential area for improvement but doesn't specify the exact changes required or the location for these changes.", "grounding_specificity_rationale": "The comment refers to 'attention' generally, without specifying which part of the paper it relates to, and mentions 'an extra appendix' without linking it directly to the attention concept. The reference to 'attention' is vague, and the suggestion of an appendix is a specific location but not a specific part of the paper being discussed.", "verifiability_rationale": "The comment is a suggestion for improvement, not a claim that requires verification or justification. There is no assertion of a problem that needs to be proven or supported with evidence.", "helpfulness_rationale": "The comment identifies a valid area for improvement (more details) and suggests a reasonable location for it (appendix). While it doesn't provide specific *howto* details, it points in a helpful direction by suggesting a place to add more information."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the issues: 'duplicates' and 'missing publication venues' and 'missing publication years'. This indicates that the authors should be aware of these problems. However, it doesn't provide specific instructions on how to address them, making it 3 but not fully actionable.", "grounding_specificity_rationale": "The comment refers to the 'references list' but doesn't specify the exact section, table, figure, or unique element within that list where the issues are present. While it identifies the general area (references), it lacks precise grounding. The specificity is also limited as it doesn't detail *which* duplicate entries or *which* papers are missing.", "verifiability_rationale": "The comment contains a claim: 'The references list contains duplicates and the publication venues and/or the publication years of many of the papers are missing.' However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The implications are implied (inaccurate citations can harm credibility), but there is no explicit justification for why these are problems or how they should be addressed.", "helpfulness_rationale": "The comment identifies a significant issue with the references section, which is crucial for academic integrity. However, it lacks specific suggestions or guidance on how to improve the references. The authors are informed about the problems but are left without concrete steps to take, making it 3 but not 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the theoretical analysis in Theorem 1 is unclear and weak. They also point out that the error bound in Theorem 1 is not welldefined and that the analysis needs to be compared with other comparable methods. These are concrete actions that the authors can take to improve their understanding of the theoretical analysis.", "grounding_specificity_rationale": "The reviewer specifically mentions 'The theoretical analysis in Theorem 1' and highlights the 'error bound' as the problematic element. They also suggest comparing with 'comparable methods'. This indicates a strong grounding of the comment in the specific part of the paper and the nature of the issue.", "verifiability_rationale": "The reviewer makes a claim that the theoretical analysis is unclear and that it needs to be compared with other comparable methods to understand the error bound. This claim is 3 as the reviewer provides a method (comparing with other methods) for the authors to assess the clarity and meaning of the analysis. However, the reviewer does not provide specific examples or references to support this claim within the review point itself.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the theoretical analysis and provides a specific suggestion for improvement: clarifying the error bound and comparing it with other methods. This is a 5 and constructive comment that directly addresses a potential area of confusion for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks 'why the explicit methods perform better than implicit methods on the locomotion tasks'. This is a direct question about a relationship between two concepts. The reviewer also points out that the pseudocode of the proposed method is missing, which is a specific detail. While the question itself is somewhat general, the identification of the missing pseudocode adds a concrete element.", "grounding_specificity_rationale": "The review point mentions 'locomotion tasks' and the performance difference between 'explicit methods' and 'implicit methods'. While it doesn't explicitly identify a specific section, table, figure, or unique aspect of a paper, the general concepts are referenced. The reviewer also points out the 'missing pseudocode of the proposed method', which could be interpreted as implicitly referring to a specific implementation detail. However, without further clarification, the grounding is not as precise as 'fully grounded'.", "verifiability_rationale": "The review point contains a claim: 'why the explicit methods perform better than implicit methods on the locomotion tasks'. However, this claim is not supported by any logical reasoning, common knowledge, or external references within the review point itself. The reviewer simply states the observation and the missing pseudocode without explaining the underlying reasons or providing evidence. The statement 'the pseudocode of the proposed method is missing' is also a factual observation but doesn't explain why it's relevant to the performance difference.", "helpfulness_rationale": "The review point raises a relevant question about the performance difference between explicit and implicit methods, which is a common concern for researchers in the field. The reviewer also highlights the absence of pseudocode, which is a specific implementation detail that could be helpful for understanding and reproducing the proposed method. The combination of a relevant observation and a specific detail makes the review point helpful."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly mentions 'lowresource language pairs' and 'multilingual model' as potential limitations, which are direct actions or suggestions for the authors. However, the suggestion to 'use the method like R3F' is vague and lacks specific details on how to implement it. The lack of specificity makes it difficult for the authors to take concrete action based on this suggestion.", "grounding_specificity_rationale": "The reviewer refers to 'lowresource language pairs' and 'multilingual model' as areas needing further finetuning and the use of the R3F method. While these are specific parts of the model or data, the reviewer does not explicitly state which specific section, table, figure, or unique aspect of the paper they are addressing. The criticism about the 'insignificant improvement' is also not tied to a specific part of the paper.", "verifiability_rationale": "The reviewer makes a claim: 'Missing References: Aghajanyan, Armen, et al. 'Better FineTuning by Reducing Representational Collapse.' International Conference on Learning Representations. 2020.' However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a fact without justification.", "helpfulness_rationale": "The review point identifies a potential limitation regarding lowresource language pairs and suggests considering the R3F method. While this offers a direction for improvement, the lack of specificity regarding the R3F method and the missing reference make it difficult for the authors to understand the practical implications or how to implement it. The criticism about the 'insignificant improvement' is a valid point but does not provide a concrete solution or actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer is implicitly suggesting that the authors should broaden their experimental validation to include other types of image noise. While they don't explicitly state 'improve the experiments,' the question implies a desire for more comprehensive results. This is a form of implicit actionability.", "grounding_specificity_rationale": "The reviewer explicitly points out the discrepancy between the claim of the model working for various image noise types and the actual experimental results being shown only for Gaussian noise. They directly identify the specific part of the paper (the experimental section) and clearly state what is missing (results for other noise types). This is a clear and explicit identification of the gap.", "verifiability_rationale": "The reviewer makes a claim about the model's applicability to various image noise types and then identifies a lack of supporting evidence in the paper \u2013 specifically, the absence of results for noise types other than Gaussian. This claim is not explicitly justified by any reasoning, common knowledge, or external references within the review point itself. Therefore, the verifiability is somewhat lacking.", "helpfulness_rationale": "The reviewer's comment directly points to a concrete area for improvement in the paper \u2013 the limited scope of the experimental validation. They suggest that the authors should include results for other types of image noise to support the claim of broader applicability. This is a clear and helpful suggestion that directly addresses a gap in the current work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding a visualization to address the performance decline, which is a concrete action. However, it does not specify the exact steps or tools to use for creating the visualization, making the action implicit rather than fully explicit. The action is also somewhat vague as it doesn't detail the specific aspects of the performance decline to visualize.", "grounding_specificity_rationale": "The review point discusses the general issue of performance decline in PU learning with increasing dimensionality. It does not explicitly refer to a specific section, table, figure, or unique aspect of the paper. While it identifies a problem, it doesn't pinpoint the exact location or nature of the problem within the paper, making the grounding weak. The specificity is also somewhat vague as it doesn't detail the type of visualization or the specific performance metrics to be analyzed.", "verifiability_rationale": "The review point is a suggestion for improvement rather than a claim that needs verification. It doesn't make any assertions about the current state of the paper or propose solutions based on evidence. Therefore, it doesn't fall under the 'Claim Extraction' category, and there's no evidence to assess its verifiability.", "helpfulness_rationale": "The review point identifies a relevant area for improvement by suggesting a visualization to address the performance decline. This directly relates to the stated motivation of the paper. However, it lacks specific guidance on *how* to create the visualization, making it a helpful suggestion but not fully actionable or detailed enough to be fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the suggestion to move the empirical result to supplementary materials. This action is directly identified, making it explicit. Furthermore, the reviewer clearly states *where* to move the result, which is the supplementary materials, making the action concrete.", "grounding_specificity_rationale": "The reviewer mentions the 'empirical version of the objective (3)' but does not explicitly identify the specific section, table, figure, or unique aspect of the paper being addressed. The reference is implicit, implying the relevant part is related to objective (3). Therefore, the grounding is weak. The comment also does not specify what is wrong or missing in this part, focusing solely on the location of the result. Thus, the specificity is also low.", "verifiability_rationale": "The reviewer's comment does not contain a claim in the sense of stating an opinion or judgment about the paper. They are simply suggesting a change in the presentation format. Therefore, there is X to be verified.", "helpfulness_rationale": "The reviewer provides a suggestion to move the empirical result to supplementary materials. While this is a straightforward suggestion, it directly addresses the presentation of a key result and helps the authors organize their paper more effectively. It is helpful, though not a profound critique or suggestion for major changes."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests looking at 'topography plots' and 'differences in figures' as a way to investigate the issue. While 'topography plots' is somewhat general, it's a specific type of visualization. The reviewer also provides a concrete *method* for investigation: 'Although the topography plots plots seem to indicate something reasonable going on.'", "grounding_specificity_rationale": "The reviewer refers to 'result description' and 'figures,' which are reasonably clear indicators of the section and figures being discussed. They also mention ' listener gets reset,' which points to a specific concept within the result description. The reviewer then suggests investigating 'topography plots' and examining 'differences in figures,' which are specific to the content of those sections.", "verifiability_rationale": "The reviewer makes a claim that 'the differences in figures seem too small' and suggests investigating 'topography plots' and 'differences in figures.' They also provide external references and logical reasoning to support their claim, such as 'related ideas of speakerlistener communication from a teachability perspective' and 'check that useful communication is actually happening.'", "helpfulness_rationale": "The reviewer identifies a potential issue with the interpretation of results ('differences in figures seem too small') and provides specific suggestions for investigation, including 'a related idea of speakerlistener communication from a teachability perspective' and examining 'topography plots' and 'differences in figures.' These suggestions are clear and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests providing a 'mathematical characterization' of the approximation error. While they don't explicitly state the formula or method, the suggestion implies a concrete action: 'Calculate the error using this formula' (concrete). However, the reviewer doesn't explicitly state the formula or method, making the action implicit rather than explicit. Therefore, it's 3 as the reviewer clearly indicates a desire for a mathematical approach, but the specific steps are not laid out.", "grounding_specificity_rationale": "The reviewer refers to 'the approximation error' and 'objective values.' While they understand the general concept of the error and the values involved, they don't explicitly point to a specific section, table, figure, or unique element of the paper where these values are located. The reviewer's comment is general and doesn't provide precise grounding. Therefore, it's 2.", "verifiability_rationale": "The reviewer makes a claim: 'It would be better to provide a mathematical characterization.' This is a clear statement and a suggestion for improvement. The reviewer's statement is logically sound and based on a common understanding of how to define errors. While the reviewer doesn't provide the mathematical details in this review point, the suggestion itself is verifiable based on general knowledge of mathematical definitions and error analysis. Therefore, it's 3 as the suggestion is logically sound and based on common practices, even if the reviewer doesn't provide the details.", "helpfulness_rationale": "The reviewer explicitly states their desire for a 'mathematical characterization' of the approximation error. This directly addresses a potential ambiguity and provides a concrete direction for improvement. The reviewer's suggestion is actionable and directly targets a potential weakness in the paper. Therefore, it's 5 as the reviewer clearly indicates a desire for a mathematical approach, which directly addresses a stated problem."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly points out a specific issue with a technical claim (Corollary 10) and provides a clear action for the authors: to understand the difference between minimizing the expected 01 loss and the convex surrogate in this context. The action is explicit and concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Corollar 10' and discusses the concepts of 'uncertainty sampling', 'expected 01 loss', and 'expected convex surrogate'. This clearly identifies the specific part of the paper being addressed, making the grounding fully specific.", "verifiability_rationale": "The reviewer makes a claim about the interpretation of Corollary 10. While the claim itself might not be directly supported by external references, the reviewer's point about the interpretation of the corollary regarding the difference between 01 loss and convex surrogate is a logical deduction that can be verified by examining the mathematical details of the corollary and its proof (if available). Therefore, it is 3.", "helpfulness_rationale": "The reviewer's point is highly specific and directly addresses a potential area of confusion for the authors regarding a technical detail. By clarifying the relationship between the 01 loss and the convex surrogate in the context of Corollary 10, the reviewer provides a valuable insight that can significantly improve the authors' understanding. This makes the feedback 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitations of the model, such as the slow dynamics due to the reassignment probability and the simplicity of the evolution model. These are direct observations of the model's behavior.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed model' and 'the reassignment probability' without specifying a particular section, table, or unique aspect of the paper being addressed. While the concept of the model is implied, the specific part of the paper being criticized is not clearly identified.", "verifiability_rationale": "The reviewer makes claims about the model's behavior (e.g., 'only produces 1 node changing cluster per time step on average' and 'allows for only very slow dynamics') without providing any supporting evidence or justification. There is no logical reasoning, common knowledge, or external references to back up these statements.", "helpfulness_rationale": "The reviewer identifies limitations of the proposed model. While these criticisms are valid, they do not offer specific suggestions or guidance on how to improve the model or the draft. The feedback is primarily about what is wrong rather than how to fix it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing details: \"missing details about division to train and test sets, numbers as well as how the division was made (simply random? Any other considerations?)\". This directly points to what needs to be addressed, making it explicit. Furthermore, the reviewer provides specific information (numbers, description of the method) that should be included, making it concrete.", "grounding_specificity_rationale": "The reviewer points out a deficiency in the paper but does not specify *which* part of the paper is lacking these details. They are broadly criticizing the lack of information regarding the train/test split. While they mention \"numbers\" and \"how the division was made,\" they don't point to a specific section or table in the paper where this information is missing. The criticism is about the absence of information in general, not about a specific element.", "verifiability_rationale": "The reviewer does not make a claim in the traditional sense of stating an opinion or judgment. They are pointing out a deficiency or a missing piece of information. However, the lack of specific information about the train/test split can be considered implicitly verifiable. The reviewer is essentially saying, \"If you did this, you should have included these details.\" While there are no explicit examples or references provided to verify the absence of this information, the reviewer's suggestion implies a verification of the gap. Therefore, it's underspecific as the reviewer doesn't pinpoint where the information is missing, but the absence of it is a verifiable fact.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, including crossvalidation, which directly addresses the lack of detail regarding the train/test split. They are not asking for a general review but are actively suggesting concrete steps the authors should take. This makes the feedback 5 and directly helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the 'lack of automation' in building text descriptions and the 'variability' of optimal textual formats, providing clear actions for improvement. While the specific type of format and the exact tasks aren't pinpointed, the suggestion to explore different formats is a concrete action the authors can take.", "grounding_specificity_rationale": "The reviewer mentions 'text descriptions for each task' and 'optimal textual format,' but the 'each task' aspect is general, leading to weak grounding. However, the reviewer does specify a direction for improvement ('exploring different textual formats') within the realm of text descriptions and optimal formats, indicating some level of specificity within the suggested area.", "verifiability_rationale": "The reviewer presents observations about the 'lack of automation' and 'variability' without providing any evidence, justification, or references to support these claims. The statement is presented as a statement of observation and a suggestion for future work, but lacks the supporting elements needed for verifiability.", "helpfulness_rationale": "The review point raises a practical concern about the current reliance on human labor and suggests a potential area for future research or development by exploring different textual formats. While it doesn't offer a definitive solution, it provides a clear observation and a direction for improvement, making it a 3 comment."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point mentions a 'performance improvement' and a specific number (0.02). It also suggests an alternative way to present the data (tables). While it points to a *potential* improvement, it doesn't explicitly state *what* needs to be done. The suggestions are highlevel.", "grounding_specificity_rationale": "The review mentions 'the bank dataset' and 'figure 3'. This shows an attempt to refer to a specific part of the paper. However, it doesn't explicitly state the *section*, *table*, or *unique aspect* being addressed. The grounding is implicit.", "verifiability_rationale": "The review states 'the performance improvement of proposed methods seems not so significant, the biggest improvement in the bank dataset was ~0.02.' This is a claim. However, the review *mentions* the 0.02 improvement but doesn't *explain* why it's not significant or *refer to external literature* to support this claim. The justification is weak.", "helpfulness_rationale": "The review provides some relevant information about the results and suggests a way to improve clarity. However, the suggestions are general and don't pinpoint the exact cause of the lack of significant improvement. The advice on using tables is highlevel and doesn't provide specific guidance on how to create them or what data to present. The feedback is relevant but lacks the specific and actionable advice needed to help the authors improve their draft significantly."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the limitations of the experimental validation, mentioning 'only shallow networks are considered (2 or 3 layers)' and 'the optimization strategy, including the grid search strategy for hyperparameters selection, is not described.' These are concrete actions the authors should take. While the positioning point is more of a minor issue, the explicit nature of the experimental validation criticism makes it partially actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'experimental validation' and then narrows it down to 'shallow networks' and 'optimization strategy.' This indicates a clear identification of the specific aspect being addressed, making it fully grounded. The comment also specifies what is lacking: 'the optimization strategy, including the grid search strategy for hyperparameters selection, is not described.' This adds to the grounding and specificity.", "verifiability_rationale": "The comment contains a claim: 'Experimental validation are not convincing.' This claim is partially verifiable. While the reviewer points out 'only shallow networks are considered (2 or 3 layers)' and 'the optimization strategy, including the grid search strategy for hyperparameters selection, is not described,' these points could be considered somewhat underspecific in the context of directly verifying the 'convincingness' of the validation. However, they do provide some basis for understanding why the validation might be limited. The lack of external references is also implied but not explicitly stated.", "helpfulness_rationale": "The comment raises concerns about the experimental validation, which is a relevant and actionable area for improvement. The reviewer provides specific points of criticism, such as the use of shallow networks and the lack of detail on the optimization strategy. While the positioning point is a minor issue, the feedback on the experimental validation is likely to be helpful for the authors in understanding the limitations of their work and how to improve it. The suggestion to compare with related work on layer redundancy is also a valuable direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out that the work does not prove any new theoretical results. While this is a clear statement of a weakness, the reviewer does not explicitly state how to address this lack of theoretical results or what specific changes are needed. The weakness is identified, but the action to improve is not detailed.", "grounding_specificity_rationale": "The reviewer refers to 'this work' and 'this setting' when mentioning the lack of new theoretical results. This suggests an attempt to ground the comment in the specific context of the paper. However, the reviewer does not specify *which* theoretical results are missing or how they relate to the specific loss function and setting. The grounding is present but not fully specific.", "verifiability_rationale": "The reviewer states that 'this work does not prove any new theoretical results.' This is a claim that needs to be supported. However, the reviewer does not provide any evidence or reasoning to back up this claim. The statement is presented as a potential reason for the lack of theoretical results, but without further justification or references, it remains 1.", "helpfulness_rationale": "The reviewer's comment identifies a clear weakness in the work \u2013 the absence of new theoretical results. This is a valuable piece of feedback for the authors, as it highlights a potential area for future research and improvement. While the comment doesn't provide specific steps on how to address this, it points to a meaningful gap in the theoretical contribution, making it helpful in guiding future work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a hypothesis about the 'trivial part' and 'impossible part' of the images. This directly points to a specific area within the paper that needs further investigation. The reviewer also asks for evidence to support this hypothesis, which is a clear action for the authors to take. The explicit nature of the action (identifying a specific area and asking for evidence) makes it 5.", "grounding_specificity_rationale": "The reviewer refers to 'trivial part' and 'impossible part' without explicitly naming them or specifying their location within the paper. This makes the grounding weak. However, within the *proposed* trivial and impossible parts, the reviewer offers specific examples like 'consistent training data' or 'ambiguous labels'. This demonstrates a level of specificity within the vague grounding. Therefore, it's somewhat grounded but not fully specific.", "verifiability_rationale": "The reviewer proposes a hypothesis and asks for evidence to support it. This constitutes a claim that needs to be verified. While the reviewer provides some reasoning for the hypothesis, it's based on intuition and general observations rather than direct, verifiable facts or external references. The claim is present, and there's some justification, but it lacks strong support. Therefore, it's 3.", "helpfulness_rationale": "The reviewer directly asks the authors for evidence to support their hypothesis. This is a clear and actionable request that directly addresses a potential weakness or area for improvement in the authors' work. The request is specific enough to guide the authors' investigation. Therefore, it is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment implicitly suggests an action: investigating the performance of the model on other 'bAbI' tasks. While it doesn't explicitly state 'look at Task 2 and Task 3', the mention of 'other tasks' implies this. However, the action is vague as it doesn't specify how to go about this investigation or what to expect.", "grounding_specificity_rationale": "The comment mentions 'single supporting fact dataset' and 'other tasks' of the 'bAbI' project. While it identifies a category of datasets, it doesn't specify a particular paper, section, or table within the 'bAbI' literature that was used. The grounding is weak because the authors cannot confidently determine which part of the 'bAbI' literature is being addressed.", "verifiability_rationale": "The comment doesn't make a claim that can be verified. It's a suggestion for further experimentation rather than a statement that requires justification. Therefore, there's no evidence to assess its verifiability.", "helpfulness_rationale": "The comment provides a suggestion for further investigation, which can be considered a form of actionable feedback. However, it lacks specific details on how to investigate 'other tasks' or what the expected outcome should be. Therefore, it's 3 but could be more concrete."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The statement 'The technical contribution is limited' is a direct and explicit identification of a problem. It clearly indicates that the paper lacks significant novelty or advancement in its technical aspects. The reviewer directly points out the weakness, making it actionable for the authors to understand what needs improvement.", "grounding_specificity_rationale": "The statement 'The technical contribution is limited' is 1 at a specific technical aspect. While it identifies a problem related to 'technical contribution', it doesn't pinpoint the exact area within that contribution that is limited. It refers to a broad category rather than a specific element of the work.", "verifiability_rationale": "The statement 'The technical contribution is limited' is a claim that requires verification. To fully verify this, the reviewers would need to compare the paper's technical approach with established standards and typical models in the relevant field. While the statement itself is a claim, fully supporting it would require external references and a detailed analysis of the paper's technical details. Therefore, it is partially verifiable.", "helpfulness_rationale": "The reviewer's comment is 5 as it points out a potential weakness in the paper's technical contribution. By highlighting this, the reviewer provides valuable feedback for the authors to understand the limitations of their work and identify areas for improvement. This type of feedback is crucial for constructive peer review."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The reviewer is pointing out a potential issue (time complexity) related to the algorithm. While they don't explicitly state what action they would take, they identify the problem and its potential impact, which constitutes an implicit action. The specificity of the action is that it's about the hypervolume calculation in LaMOO.", "grounding_specificity_rationale": "The reviewer mentions 'hypervolume calculation' and 'LaMOO algorithm' generally. They do not explicitly identify a specific part of the paper they are referring to, such as a particular section, table, or figure. The mention is broad and doesn't pinpoint a specific element within the paper.", "verifiability_rationale": "The reviewer makes a claim about the impracticality of LaMOO for manyobjective problems due to hypervolume calculation. This is a claim that requires justification. While the claim is plausible based on general knowledge of hypervolume calculation complexity, the reviewer does not provide specific references or examples within this review point to support the claim.", "helpfulness_rationale": "The reviewer raises a concern about the scalability of LaMOO. However, they do not offer any suggestions or solutions to address this concern. The review point is primarily a question or observation, not a suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "None", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The comment suggests a potential improvement for future work by using larger datasets. While this is a valuable suggestion, it does not directly instruct the authors on what changes to make to their current paper. The authors are aware of their paper, and the comment is about the experimental setup, not the content of the paper itself. Therefore, it does not provide explicit or direct actions that the authors should take to improve their draft.", "grounding_specificity_rationale": "The comment refers to 'the dataset used in the experiments' as a potential area for improvement. While this relates to the paper's experimental validation, it does not specify a particular section, table, figure, or unique aspect of the paper that needs improvement. The suggestion is about the experimental setup in general, not a specific flaw or area within the paper. Therefore, it does not identify a specific part of the paper being addressed.", "verifiability_rationale": "The comment does not contain a claim or assertion about the paper's quality or specific issues. It is a suggestion for future work, not a critique or evaluation of the current paper's content or methodology. There is no logical reasoning, common knowledge, or external references provided to support a claim. Therefore, it does not make a claim that requires verification.", "helpfulness_rationale": "The comment offers a suggestion for future research by proposing the use of larger datasets. While this is a valuable and potentially helpful suggestion, it does not directly address any perceived weaknesses or areas for improvement in the current paper. The authors are aware of their paper, and the comment is about the experimental setup, not the content of the paper itself. Therefore, it does not provide actionable feedback that empowers the authors to significantly improve their draft."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "2 (3)", "verifiability_label": "2 (Weakly Verifiable)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer suggests 'honest and direct feedback' and asks a question ('What does 'brittle convergence properties mean'?'). These actions are explicit, but the level of detail in the question is low, making the actionable part somewhat vague. Explicit actions are generally considered more actionable than implicit ones.", "grounding_specificity_rationale": "The reviewer mentions 'evolutionary methods,' 'state, reactiveness, and learning during an episode,' and 'brittle convergence properties' as areas for improvement. While they *mention* these areas, they don't explicitly state *which* specific part of these broad categories they are criticizing. The title is mentioned generally without a specific connection to a detail. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes claims about the limitations of evolutionary methods and the adoption of DeepRL. While they *suggest* these are limitations, they don't provide specific evidence or references to back up these claims within the review point itself. The request for clarification ('What does 'brittle convergence properties mean'?') indicates a lack of immediate understanding or justification for their point. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer provides specific suggestions ('honest and direct feedback') and asks a question. The act of providing feedback is generally considered helpful. While the depth and clarity could be improved, the *act* of offering feedback makes it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies the key steps and challenges in the methodology, but it doesn't explicitly state what the authors should do with this information. The questions posed are clear and direct, indicating an explicit action, but the answers are not provided, making it 3.", "grounding_specificity_rationale": "The review point explicitly refers to 'the paper' and asks specific questions about its components (focal stack, defocus map, image, edges). This makes it 5.", "verifiability_rationale": "The review point presents a claim that the authors need to understand how the focal stack is synthesized and the challenges at image edges. It doesn't provide explicit justification or references for this claim, making it 3.", "helpfulness_rationale": "The review point raises several important questions about the methodology and implementation details of the paper. These questions directly address potential gaps in the authors' understanding and could significantly improve their work. The questions are clear and specific, making it 5 for the authors to address these points."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests 'there should be some empirical justification'. This is a direct and explicit action the reviewer proposes. While the reviewer doesn't specify *how* this empirical justification should be done, the suggestion itself is clear and actionable for the authors. Therefore, the action is explicit, even if not fully concrete.", "grounding_specificity_rationale": "The reviewer refers to 'the first claimed contribution' of the paper. This indicates they are specifically addressing a previously stated claim. They also mention 'points' and 'apriori knowledge about dimensions of subspaces,' which likely refers to specific details or descriptions in the paper. This shows the reviewer is identifying a weakness in a specific part of the paper's claims. Therefore, the grounding is explicit and specific to the claim being discussed.", "verifiability_rationale": "The reviewer makes the claim that the paper lacks 'empirical justification' for its first contribution. This is a clear statement of a deficiency. They also suggest 'there should be some empirical justification,' providing a logical reasoning for why this is a desirable addition. This supports the claim with a clear justification.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential weakness in the paper's presentation of its contribution. They suggest adding 'empirical justification,' which is a concrete and actionable suggestion for the authors. This is a valuable and constructive comment that directly helps improve the paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the lack of novelty in the approach, the use of nonnovel algorithms (MLP, Regression Tree, Random Forest), the similarity of the sampling strategy to existing methods (epsilongreedy, BRPNAS), and the similar performance results. These are all direct statements that the authors can directly identify modifications they should apply to their draft. The reviewer provides specific examples of the algorithms used and refers to a table in the appendix, making the suggestions concrete enough for the authors to investigate.", "grounding_specificity_rationale": "The reviewer does not explicitly name a specific section, table, or figure in the paper where the lack of novelty is discussed. They refer to 'the approach' and mention the algorithms and sampling strategy generally. However, they do specify what aspects of the approach are being criticized (the algorithms and the sampling strategy) and even refer to a table in the appendix (Table 2 in Appendix C) where the performance is compared. This makes the grounding somewhat weak but the specificity of the critique is high.", "verifiability_rationale": "The reviewer makes a claim that the proposed method lacks novelty and uses similar techniques to existing work. This is a clear claim that requires verification. The reviewer provides specific examples of the algorithms used (MLP, Regression Tree, Random Forest) and the sampling strategy (similar to epsilongreedy and exactly the same as BRPNAS). These provide sufficient justification for the claim. The reviewer also points out the similar performance results, which further supports the claim and makes it verifiable.", "helpfulness_rationale": "The reviewer provides several concrete points for the authors to consider. They point out specific algorithm choices (MLP, Regression Tree, Random Forest), a sampling strategy (similar to epsilongreedy and BRPNAS), and a performance comparison. These points directly help the authors understand the limitations of their approach and potential areas for improvement. The reviewer's criticism is wellsupported by specific examples and references to existing work, making it 5 for the authors to understand and address the identified issues."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a concern about the similarity of the proposed S1DBED algorithm to RMED and the lack of discussion about this similarity in the paper. This directly points to a potential issue and identifies the area where more discussion is needed. The reviewer clearly identifies the potential problem and the area where more discussion is needed. The reviewer explicitly states the concern and the area of improvement.", "grounding_specificity_rationale": "The reviewer names the proposed S1DBED algorithm and the existing RMED algorithm by name. They also specify the concern is about the similarity and the lack of discussion. This is very specific. The reviewer isn't just saying 'the algorithms are similar'; they're pointing to a *specific* area of the paper where this similarity needs to be addressed. This is **fully grounded** and **specific**. The reviewer names the specific algorithms and the area of concern, making it highly specific.", "verifiability_rationale": "The reviewer makes a judgment about the *novelty* of the algorithm based on the similarity to RMED. This is a claim that needs to be supported. While the reviewer doesn't provide *new* evidence, they are highlighting a potential issue that the authors should consider. This claim is **partially verifiable** because it points to a potential problem that the authors could investigate further (e.g., by looking at the differences between the algorithms and the impact of the similarity). The reviewer makes a claim about the similarity and its impact on novelty, which can be verified by examining the algorithm details and existing literature. The reviewer's statement about similarity and limited novelty is a claim that can be supported by examining the algorithm details and existing literature, making it partially verifiable.", "helpfulness_rationale": "The reviewer clearly states a concern about the similarity of the proposed S1DBED algorithm to RMED and the lack of discussion about this similarity in the paper. This directly helps the authors improve their paper by highlighting a potential lack of novelty and prompting them to include a more thorough comparison with RMED. This is a 5 comment because it directly addresses a potential weakness and guides the authors to a specific area for improvement. The reviewer's comment directly addresses a potential weakness and guides the authors to a specific area for improvement, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point implicitly states that the authors should discuss previous work more comprehensively but does not explicitly tell them what to do. The authors need to infer the action from the comment, making it implicit.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper or a unique element being addressed. It only mentions the lack of a comprehensive discussion of previous work. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment refers to. The specificity is also low as the comment does not specify what aspects of previous work are missing or why a comprehensive discussion is needed.", "verifiability_rationale": "The comment states a fact (the authors did not give a comprehensive discussion) but does not provide any justification or examples to support this claim. It lacks external references or logical reasoning to back up the assertion. Therefore, it is not verifiable as it stands.", "helpfulness_rationale": "The review point identifies a valid weakness in the authors' draft (the lack of a comprehensive discussion of previous work) and suggests an improvement (adding more discussion). This points to a need for the authors to enhance their work. However, it does not provide specific guidance on *how* to improve this aspect, making it 3 but not fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "Partially Verifiable", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks multiple questions about the OT sample selection process and its relation to training. These questions are directly related to the paper's methodology and ask for specific details like 'onetime' or 'iterative' and 'runtime'. The reviewer is directly identifying modifications they should apply to their draft by clarifying these aspects.", "grounding_specificity_rationale": "The reviewer asks about the iterative nature of the OT sample selection process and the relationship between training steps and OT solving. These are specific aspects of the method. However, the reviewer also asks about the *purpose* of solving the OT problem, which is not explicitly stated in the paper. While the *process* is reasonably welldefined, the *purpose* could be clearer.", "verifiability_rationale": "The reviewer asks questions that are directly related to the paper's methodology. They are asking about the relationship between training and OT, which is a logical point. They are also asking about the *runtime*, which is a practical detail that *could* be found in the paper (if it were included). However, the paper doesn't explicitly state the runtime. The *purpose* of solving the OT problem is to select a representative subset of samples, which is a reasonable inference, but not explicitly stated.", "helpfulness_rationale": "The reviewer is directly addressing a potential point of confusion for someone trying to understand the method. They are asking for clarification on a key aspect of the training process. This is clearly beneficial for the authors who are trying to understand and potentially reproduce or improve the method."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing experiments for continuous tasks and the absence of empirical comparison for entropy methods. They also ask for specific actions, such as 'how to include experiments' and 'how to compare the empirical performance'. This indicates a clear and actionable feedback.", "grounding_specificity_rationale": "The reviewer implies the missing experiments are related to the discussion of continuous task settings in the paper. While they don't explicitly name a section, the context suggests the grounding is in the general idea of continuous tasks. The specificity is in pointing out the lack of experiments and comparison for entropy methods, but it's not as precise as identifying a specific table or figure. Therefore, it's somewhat grounded but not fully specific.", "verifiability_rationale": "The reviewer makes a clear claim about the missing empirical validation of entropy methods derived in the appendix. They also provide reasoning for why these methods are not included in the experiments, stating 'why are these not included in the experiments? How does the empirical performance of these methods compare to ConBO?'. This claim is supported by logical reasoning and the expectation of empirical validation for novel methods. Therefore, it is highly verifiable.", "helpfulness_rationale": "The reviewer's points are directly actionable and address specific shortcomings identified by the authors. They are asking for concrete improvements and comparisons, which are essential for the authors to address the weaknesses. The questions are clear and specific, making the feedback 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests a *specific* improvement: comparing GCG's transferability across LLMs. This is a clear indication of an explicit action. The reviewer also suggests *how* this comparison could be included, which further strengthens the actionability of the suggestion.", "grounding_specificity_rationale": "The reviewer refers to 'GCG' and 'other LLMs' which implies the relevance of their work. However, they don't explicitly point to a specific section, table, or figure in the original paper where this connection is most relevant. They could have mentioned a specific section or table, which would have improved grounding.", "verifiability_rationale": "The reviewer states 'It would be good if such a comparison *could be included*.' This clearly indicates a suggestion or claim. The reviewer also provides a *reason* for this suggestion: 'A minor point: The jailbreaking percentage is low for certain LLMs.' This provides a justification for the suggestion, making it verifiable.", "helpfulness_rationale": "The reviewer directly states the suggestion and its potential benefit: 'It would be good if such a comparison *could be included*.' This clearly indicates a desire for the authors to improve their work. The suggestion is actionable, and the reviewer provides a reason for why this comparison would be beneficial, making it helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they 'hope the author can give me a more detailed explanation'. This indicates a clear need for an explanation, making the review actionable. However, the action itself (providing the explanation) is not yet explicitly stated or implemented in the paper. The reviewer is aware of the concepts but needs guidance on their application.", "grounding_specificity_rationale": "The reviewer mentions 'similarity' and 'exit times in nature' as the core of their confusion. These are specific terms. However, the reviewer's lack of understanding suggests that the paper does not clearly ground the application of these terms within the context of unsupervised feature selection from a diffusion perspective. The terms are mentioned, but their specific meaning and relationship are not welldefined or explained in a way that makes the reviewer's confusion understandable.", "verifiability_rationale": "The reviewer makes a claim: 'I think this is a very novel thing for feature selection, but i can't understand what is the difference between similarity and exit times in nature.' This constitutes a claim that needs to be verified. The reviewer is stating a difference they believe exists (between similarity and exit times) and is expressing a lack of understanding of this difference. While the claim is about a difference, the reviewer doesn't provide any external references or logical reasoning to support this claim within the review point itself. The verifiability depends on whether the paper provides a clear explanation and justification for the relationship between these two concepts.", "helpfulness_rationale": "The reviewer explicitly states they 'hope the author can give me a more detailed explanation'. This is a direct and specific desire for feedback that directly addresses a core concept in the paper. The reviewer is clearly indicating that the current explanation is not sufficient for them to understand the difference between similarity and exit times. This constitutes 5 feedback as it directly addresses a perceived weakness in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking about the limitations of the framework, which implies a desire for improvement or clarification. While not directly stating a missing element, the question is related to actionable steps. Therefore, it's 3.", "grounding_specificity_rationale": "The reviewer's comment is general and doesn't specify a particular part of the paper or the framework's implementation. It's a broad inquiry about the framework's capabilities.", "verifiability_rationale": "The core of the review point is a question, not a statement that requires verification. Questions don't have the same verifiable evidence as claims.", "helpfulness_rationale": "The question about the framework's limitations is relevant for the authors. It helps them understand the scope and potential applicability of the framework, which is 3 for their decisionmaking process."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer's question directly addresses a potential point of confusion for the authors regarding the calculation of precision, recall, and F1score. They are asking for clarification on how these metrics were specifically calculated for the 4class classification of breast density. This is a direct request for information that could help the authors understand and potentially improve their model's performance. The reviewer is asking for a specific action (clarification) related to their work.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'precision/recall/F1score for 4class classification of breast density' and 'AUC results for comparisons'. This clearly grounds the feedback in the specific details of the authors' work. The reviewer is directly referencing the metrics and the context. This is strong grounding as the reviewer is directly referencing the specific aspects of the authors' work.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are suggesting an alternative evaluation metric (AUC) for model performance, specifically for breast cancer detection. This is more of a suggestion or critique rather than a statement that needs to be supported by evidence. While the suggestion is valuable, it's not a claim that needs verification in the sense of stating something that requires logical reasoning, common knowledge, or external references to be supported.", "helpfulness_rationale": "The reviewer's question is very specific and directly addresses a potential point of confusion for the authors regarding the evaluation of their 4class breast density classification model. They are asking for clarification on the calculation of precision, recall, and F1score. This is a clear and actionable request that directly impacts the authors' understanding and interpretation of their results. The reviewer is directly asking for information relevant to their work, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests an alternative to the dataset created by the authors (Kialo dataset) but does not explicitly state that the authors *must* use the Kialo dataset or provide a concrete action to take if they choose to follow this suggestion. The reviewer is presenting a potential solution without mandating its adoption.", "grounding_specificity_rationale": "The review point explicitly identifies the problem: \"the creation of the dataset is optional.\" It then provides specific reasons why the Kialo dataset might be preferable: \"the Kialo dataset is wellstudied in the community,\" \"it provides exactly what the authors need (pairs of short claims and their counters),\" and \"it is even cleaner (no automatic processes exist to construct it).\" This clearly grounds the suggestion in the authors' needs and the characteristics of an ideal dataset.", "verifiability_rationale": "The claim that \"the Kialo dataset is wellstudied in the community\" is generally verifiable based on common knowledge within the NLP community. The claim that \"it provides exactly what the authors need\" (short claims and their counters) is also generally verifiable based on common practices for dataset creation. The claim that it is \"cleaner\" is also verifiable by the absence of automatic construction processes compared to the dataset the authors created.", "helpfulness_rationale": "The review point offers a concrete alternative (the Kialo dataset) and highlights its potential benefits. It directly addresses the perceived limitation of the authors' current dataset by suggesting a wellestablished, readily available resource. This is a clear and actionable suggestion that directly helps the authors improve their draft by providing a readily available resource."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the limitations of the crosslayer attention modification in terms of providing significant machine learning insight and quantifies the improvement of selfcross attention. It also points out that the main improvements come from using a naive transformer. These are all direct statements that authors can use to understand areas for improvement.", "grounding_specificity_rationale": "The reviewer makes a general statement about the nonnovelty of the transformer in NLP and vision, which could be considered weak grounding as the authors might not be explicitly discussing a specific section. However, the reviewer then focuses on the crosslayer attention modification and the limited improvement of selfcross attention, which are more specific. The statement about the main improvements coming from using a naive transformer is fully grounded as it directly points to the core contribution.", "verifiability_rationale": "The claim about the limited improvement of selfcross attention (1%) is wellsupported by the data in Tables 4 and 5, making it 5. However, the claims about the nonnovelty of the transformer and the lack of ML insight from the modification are general statements without specific examples or references, making them 1.", "helpfulness_rationale": "The review point is 5 as it directly points out a significant weakness in the proposed modification (lack of ML insight and limited improvement) and provides quantitative evidence to support this claim. It also highlights the core contribution (using a naive transformer), guiding the authors to focus on the most impactful aspect."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the perceived limitation of the number of tasks and directly suggests an improvement by mentioning a specific number (at least 10). This indicates a clear and direct action the authors should take.", "grounding_specificity_rationale": "The comment explicitly mentions 'the number of tasks' and suggests a specific number ('several tasks (at least 10)'). This clearly identifies the specific part of the paper being addressed. Additionally, the comment implicitly suggests a change in the type of results reported ('epochs' vs. 'sequential results'), which is a specific aspect of the experimental setup.", "verifiability_rationale": "The comment presents an opinion ('I consider the number of tasks quite limited') without providing specific examples, references, or logical reasoning to support this claim. While the suggestion for 'sequential results' is 3, the initial statement about the number of tasks lacks sufficient evidence.", "helpfulness_rationale": "The comment is 5 as it directly points out a potential weakness ('limited number of tasks') and provides a clear and actionable suggestion ('to be convinced, see several tasks'). The suggestion for 'sequential results' is also a concrete, actionable item for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests adding sentence inference tasks like MNLI and RTE to the experiments. While the reviewer doesn't explicitly state 'You should add MNLI and RTE to your experiments,' the suggestion implies an action: identifying a gap in the current experimental scope and proposing a concrete solution. The reviewer points to a weakness (limited scope) and suggests a specific improvement (including sentence inference tasks).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'sentence similarity tasks,' 'open domain QA tasks,' 'MNLI,' and 'RTE.' These are specific types of tasks within the broader category of sentence pair tasks. The reviewer provides clear examples, indicating a strong grounding in the specific areas being addressed.", "verifiability_rationale": "The reviewer provides specific examples of sentence pair tasks (MNLI, RTE) that are wellestablished in the NLP field. While they don't cite external references, the mention of these specific tasks provides a basis for understanding their relevance and potential impact. The reasoning is implicit, but the examples offer a degree of verifiability.", "helpfulness_rationale": "The reviewer identifies a clear limitation in the experimental scope (only sentence similarity and opendomain QA) and provides specific, relevant suggestions (sentence inference tasks like MNLI and RTE). This directly addresses a potential weakness for the authors and offers concrete directions for improvement. The suggestions are actionable, even if not perfectly explicit. The reviewer's point is directly relevant to enhancing the evaluation of the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the prompt should be in the appendix or supplement. It also implies that the prompt might be in a supplement if the appendix doesn't contain it. This is an explicit action that the authors should take.", "grounding_specificity_rationale": "The comment refers to 'the prompt' which is a specific part of the paper. However, it does not specify the exact section, table, figure, or unique element where the prompt is located. Therefore, while it identifies a specific part, it lacks the precision needed for full grounding. The comment also doesn't specify *why* the prompt should be in the appendix or supplement, making it somewhat specific but not fully specific.", "verifiability_rationale": "The comment does not contain a claim. It is a suggestion or request for information. Therefore, it does not have verifiability.", "helpfulness_rationale": "The comment points out a potential issue (prompt not in appendix/supplement) but does not provide specific guidance on what to do next or what the consequences are. It lacks the actionable steps and details that would make it 5. While it identifies a problem, it doesn't offer a clear solution, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4: 5", "actionability_rationale": "The reviewer explicitly states the motivation for analyzing the last convolutional layer and asks a question prompting for clarification on why numerosity might not appear in earlier layers. While the request for explanation implies a desire for more information, making it 3 rather than 1.", "grounding_specificity_rationale": "The reviewer explicitly refers to the motivation for analyzing the last convolutional layer, clearly identifying the specific part of the paper (the section discussing layer analysis) and the specific element within that section (the discussion of numerosity). However, the specificity of the reason why numerosity might not appear earlier is lacking.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity in the motivation for analyzing only the last convolutional layer. The support for this claim comes from the lack of explicit reasoning or evidence in the paper, making it only 3.", "helpfulness_rationale": "The reviewer points out a potential weakness in the methodology by questioning the rationale for focusing on the last layer. This directly addresses a gap in the paper's explanation and could be valuable information for the authors to consider, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks 'How to set the parameter S remains a problem.' This is a question, not a direct instruction on how to modify the paper. It identifies a weakness but doesn't provide an action to address it.", "grounding_specificity_rationale": "The review point refers to 'parameter S' generally, without specifying which part of the paper or where this parameter is located. This makes the grounding weak as the authors cannot pinpoint the referenced part.", "verifiability_rationale": "The review point is a question, not a claim that needs verification. It identifies a problem but doesn't state something is incorrect or needs improvement.", "helpfulness_rationale": "The review point identifies a problem with parameter S but does not provide any guidance on how to set it. It's a diagnostic question rather than a prescriptive solution."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that 'human evaluation' would be 'more convincing' as the 'automatic evaluation metrics can be misleading'. This is an explicit action, but it lacks specific details on how human evaluation would address the limitations of automatic metrics. Therefore, the action is explicit but vague.", "grounding_specificity_rationale": "The reviewer suggests 'human evaluation' without specifying which aspects of caption generation need human evaluation. This comment does not identify a specific part of the paper being addressed, making it 1.", "verifiability_rationale": "The reviewer's suggestion of 'human evaluation' could be interpreted as a claim that 'automatic evaluation metrics can be misleading'. However, the reviewer does not provide any supporting evidence or justification for this claim. Therefore, the claim is not wellsupported.", "helpfulness_rationale": "The reviewer's suggestion of 'human evaluation' is a relatively highlevel proposal. While it could be considered a 3 suggestion as it proposes a concrete change, it does not directly address specific weaknesses in caption generation or provide concrete steps for improvement in that area."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the *choice* of employing different types of constraints as a hyperparameter that needs tuning. This directly identifies a concrete action the authors should take: consider different constraint types and evaluate their impact on generalization. The reviewer provides a clear and actionable suggestion.", "grounding_specificity_rationale": "The review point explicitly mentions 'convex or concave constraint' and 'increasing/decreasing constraint'. This directly and accurately identifies the specific aspects of the shape constraints being discussed, providing clear grounding for the suggestion. The reviewer does not need to infer these parts from the paper.", "verifiability_rationale": "The review point makes a practical observation about the common practice of considering different types of shape constraints in machine learning. While it might not be based on a formal citation, it's a wellestablished concept within the field. The reviewer provides a clear justification based on common knowledge and the potential impact on generalization, making the claim 3.", "helpfulness_rationale": "The review point directly addresses a practical choice the authors will need to make when implementing shape constraints: considering convex/concave vs. increasing/decreasing. By highlighting the potential impact on generalization, the reviewer provides a clear reason and rationale for why this choice should be considered. This directly empowers the authors to make a more informed decision, making the review point 5."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "High", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states the issues with the convergence proof, such as the i.i.d. assumption in Assumption 4.1 and its implications for the covariance of Z. They also point out that modifications in Appendix C allow for straightforward adjustments. These are concrete and specific actions the authors can take to address the perceived weakness.", "grounding_specificity_rationale": "The reviewer directly references 'Assumption 4.1' and 'Modification 1 in Appendix C'. This explicit mention of specific sections in the paper clearly grounds the comment. The reviewer also explains the implications of the i.i.d. assumption for the covariance of Z, further specifying the issue.", "verifiability_rationale": "The reviewer makes a claim about the convergence proof's lack of novelty and rigor. This claim is supported by the logical reasoning that the i.i.d. assumption leads to a clear covariance matrix and allows for straightforward modifications. The reference to Appendix C provides external evidence. While the reviewers' suggestions for improvement are not direct verifications, they point towards verifiable steps the authors can take.", "helpfulness_rationale": "The reviewer's comment is 5 as it directly points to a potential weakness in the theoretical analysis and suggests concrete steps the authors can take to address it. The specific mention of Assumption 4.1 and Appendix C provides clear directions for further investigation and potential modifications. The reviewer's suggestions, while not definitive solutions, are actionable and constructive."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the multinode seed cascades are 'artificially created by merging singlenode seed cascades'. This provides a clear action for the authors to take: they should be aware that the experimental setup deviates from a fully realistic scenario. The reviewer also implies that this artificiality might affect the generalizability of the results. The reviewer's statement is direct and identifies a specific methodological choice.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the experimental setup' as the area of concern. This clearly identifies the specific part of the paper being addressed. The reviewer does not need to infer which part is being discussed, as the term 'experimental setup' is a common and wellunderstood term in the context of research papers. The reviewer also specifies that the multinode cascades are 'artificially created', which clearly indicates what is being discussed within the experimental setup.", "verifiability_rationale": "The reviewer makes a claim that the experimental setup is 'semireal' and that multinode seed cascades are 'artificially created'. This claim is supported by the statement that they are 'merged singlenode seed cascades'. The reviewer provides a logical reasoning for why the setup is not fully realistic. The evidence is present in the description provided by the reviewer, making the claim verifiable.", "helpfulness_rationale": "The reviewer points out a specific limitation in the experimental methodology, namely the semireal nature of the multinode seed cascades. This is a valuable piece of feedback for the authors as it directly impacts the interpretation of the experimental results. The reviewer clearly identifies a methodological choice that could affect the generalizability and reliability of the findings. This information is actionable and directly addresses a potential weakness in the experimental design."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point mentions \"bias benchmarks only assess gender, race, and religion\" which is an explicit action or suggestion. However, it doesn't specify how to address this limitation or what steps should be taken. The statement \"Other important biases and datasets are not measured\" is also explicit but lacks concrete steps on how to measure them. The statement \"missing are assessments on stateoftheart generative models like GPT\" is explicit but doesn't detail how to incorporate these models. While the reviewer identifies a problem, they don't provide specific actions or concrete steps to address it.", "grounding_specificity_rationale": "The review points to \"bias benchmarks,\" \"datasets,\" and \"models.\" While it identifies specific areas lacking information, it doesn't explicitly state which *part* of these areas is missing information about. For example, within \"datasets,\" it doesn't specify which type of dataset is missing. Similarly, within \"models,\" it doesn't specify which generative model is missing. The reviewer implies a general deficiency rather than pinpointing a specific missing element.", "verifiability_rationale": "The review contains claims such as \"bias benchmarks only assess gender, race, and religion\" and \"Other important biases and datasets are not measured.\" These are statements that require justification or evidence. However, the review does not provide any logical reasoning, common knowledge, or external references to support these claims. The statement about missing generative models also lacks supporting evidence. The claims are presented without any verification.", "helpfulness_rationale": "The review point identifies a limitation in the evaluation of bias. While this is a valid observation, it does not offer any suggestions or actions to address this limitation. It points out a problem but doesn't propose solutions or provide guidance on how to improve the evaluation process. The feedback is diagnostic rather than prescriptive."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "1 (1)", "verifiability_label": "3 (3)", "helpfulness_label": "4 (4)", "actionability_rationale": "The review point encourages clarification but does not explicitly state a specific action or modification the author should make based on the identified performance loss and knowledge sharing. While it points to a potential area for improvement, it doesn't directly tell the author what to do.", "grounding_specificity_rationale": "The review point is a general statement about the multienv model's performance and knowledge sharing, without specifying which part of the paper or result it refers to. It lacks a clear reference to a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The review point is a question about the interpretation of results, not a claim that requires verification. While it could be expanded to include references or examples, as it stands, it doesn't present a statement that needs to be justified or supported by evidence.", "helpfulness_rationale": "The review point identifies a potential source of confusion for the author regarding the multienv model's performance and knowledge sharing. By encouraging clarification, it prompts the author to engage with the results and potentially resolve the apparent contradiction, making it a helpful suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need to find a proper \u03b1, which is a clear action for the authors to take. The suggestion is direct and targets a specific hyperparameter.", "grounding_specificity_rationale": "The reviewer explicitly mentions the hyperparameter \u03b1, indicating they are focusing on a specific part of the method. However, they don't specify *how* to find the proper \u03b1, making it less grounded in terms of specific steps.", "verifiability_rationale": "The reviewer makes a general statement about hyperparameter sensitivity. While likely true, they don't provide specific examples or references, making the claim somewhat supported but not 5.", "helpfulness_rationale": "The reviewer's point is directly relevant to the authors' workflow. They are given a specific action to take (search for \u03b1) that is likely to improve their results."}
{"actionability_label": "Low", "grounding_specificity_label": "Weak Grounding", "verifiability_label": "1", "helpfulness_label": "Low", "actionability_rationale": "The review point does not explicitly state the metrics being referred to, making it difficult to understand the context and the nature of the metrics. Therefore, it's impossible to determine the explicitness and concreteness of the feedback regarding these metrics. The reviewer's comment is vague and doesn't provide specific actions or suggestions related to the metrics.", "grounding_specificity_rationale": "The reviewer's comment is general and does not specify which metrics are lacking explanation or grounding. It refers to 'the metrics used in the paper' without identifying them or providing context. Therefore, the grounding is weak as the authors cannot pinpoint the specific area needing clarification.", "verifiability_rationale": "The reviewer's comment suggests a need for a citation, which can be considered a claim requiring justification. However, the specific citation is missing, and the reasoning for needing a citation is implied rather than explicitly stated and justified. The lack of a specific reference makes it difficult to verify the claim fully.", "helpfulness_rationale": "The reviewer's comment highlights a significant lack of detail and specificity regarding the metrics used in the paper. While the general direction of suggesting a citation is helpful, the absence of a concrete citation and the lack of explanation about the metrics themselves make the review point unhelpful for the authors in terms of providing actionable feedback. The authors would need to refer to the original paper to find the metrics, which is not ideal."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that Figure 3 is 'challenging to understand' and that the 'workflow and captions are unclear, and the representation of communication modes on the left side is confusing.' This indicates that the reviewer did not find the information presented to be explicitly stated or easily interpretable. While the reviewer points to specific elements of the figure, they do not provide explicit instructions on how to address these issues. The reviewer implies that the authors need to infer the meaning of the unclear elements, making the action implicit.", "grounding_specificity_rationale": "The reviewer explicitly names the 'figure' as the part of the paper being addressed, indicating strong grounding. Furthermore, they specify *what* is unclear within that figure: 'workflow,' 'captions,' and 'representation of communication modes.' This level of detail demonstrates a clear understanding of the specific section and its contents that needs clarification.", "verifiability_rationale": "The comment does not contain a claim or assertion that needs verification. The reviewer is stating a problem with the figure's clarity, not making a judgment about its correctness or suggesting a specific solution that can be evaluated. Therefore, there is no evidence of verifiability in this comment.", "helpfulness_rationale": "The reviewer's comment identifies a weakness in the paper (Figure 3 being unclear) but does not provide any specific suggestions or guidance on how to improve it. While it points to an area needing attention, it lacks the actionable elements necessary for the authors to make changes. Therefore, it is not 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out the lack of clarity regarding 'learned MASK embedding' in the SSL pretraining stage. This constitutes an explicit action or suggestion that is directly identifiable. While the action is somewhat vague in terms of *how* to understand it, the reviewer clearly identifies a missing piece of information. Therefore, it is 3.", "grounding_specificity_rationale": "The reviewer directly addresses a specific technical term ('learned MASK embedding') within the context of the SSL pretraining stage. This demonstrates strong grounding specificity. The reviewer is not making an educated guess; they are directly pointing to a specific part of the paper and highlighting a missing definition. The use of the exact phrase 'learned MASK embedding' further emphasizes the specific identification. Therefore, it is 5.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. Instead, they are pointing out a lack of information. While the absence of a definition is a verifiable fact, the reviewer is not presenting a claim that needs to be supported by evidence. The phrasing focuses on identifying a missing definition rather than making a statement that can be verified. Therefore, it is not verifiable in the sense of requiring justification or evidence. This is a borderline case, as the reviewer is highlighting a gap, but not a claim needing verification.", "helpfulness_rationale": "The reviewer's point directly addresses a potential obstacle for the reader \u2013 a lack of clarity on a specific technical detail. This is 5 as it directly points to a potential area where the reader (and potentially the authors) might be struggling. By highlighting this, the reviewer is providing a clear direction for improvement or clarification. Therefore, it is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the concern about the derivative work. It identifies the *type* of derivative work (extension to hypernetworks) and the *area* of comparison (results for standard networks). However, it does not directly suggest *how* the extension was done or what the implications are for the authors.", "grounding_specificity_rationale": "The comment mentions 'hypernetworks' and 'results already presented in the literature for standard networks,' providing some grounding. However, the reviewer infers the nature of the derivative work, making the grounding not absolute. The specificity is about the areas being compared, but the degree of derivative work is implied rather than explicitly stated.", "verifiability_rationale": "The comment contains a claim ('the reported results seem to be partially derivative') and provides a logical reasoning ('extension to hypernetworks of results already presented in the literature for standard networks') to support it. While the reasoning is logical, the claim itself is based on an inference rather than a direct observation or citation, making it 3.", "helpfulness_rationale": "The comment raises a valid concern about the novelty and contribution of the work. It points out a potential issue that could hinder the authors' perception of the value of their research. This directly impacts the authors' ability to understand and build upon the existing literature, making it 5 and helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues with the paper's framing and experimental setup. They point out that the paper starts with an objective but doesn't motivate the applications, and that the datasets used are static instead of streaming. These are clear and direct statements about what needs to be improved. The reviewer also suggests concrete actions, such as 'motivating the applications' and 'using streaming datasets'. These actions are specific and actionable for the authors.", "grounding_specificity_rationale": "The reviewer identifies specific issues with the paper's grounding. They point out that the paper doesn't explicitly state which part of the paper addresses the lack of motivation or the use of static datasets. While the reviewer's general criticism implies the motivation is in the introduction, it's not explicitly labeled or referenced. However, the reviewer does clearly specify the *what* \u2013 the lack of motivation and the use of static datasets.", "verifiability_rationale": "The reviewer states a fact: 'The paper starts with the objective of designing fast label aggregation algorithms for a streaming setting. But it doesn\u00e2\u0080\u0099t spend any time motivating the applications in which such algorithms are needed.' This is a factual statement without any claim or opinion. There is no evidence presented to support or refute this statement. Therefore, it is classified as 'X (X)'.", "helpfulness_rationale": "The reviewer provides clear and actionable feedback. They point out a significant weakness in the paper's motivation and suggest a concrete improvement: 'motivating the applications'. They also identify a specific experimental limitation: 'the use of static datasets instead of streaming data' and suggest a solution: 'using streaming datasets'. These suggestions are directly aimed at helping the authors improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the 'scope of the study is underspecified' and then provides a specific example of what the reviewer believes is missing ('the work focuses on injecting CoT based approach to smallscale Language Models'). This clearly indicates an explicit action the authors should take, which is to either clarify the scope or include relevant CoT baselines for LLMs.", "grounding_specificity_rationale": "The reviewer attempts to ground the comment by mentioning 'the work focuses on injecting CoT based approach to smallscale Language Models'. They further specify what is missing by suggesting 'additional relevant CoT baselines for incontext learning of Large Language Models (for text003 and ChatGPT) are missing in Table 2 and 3'. This shows a clear understanding of the specific aspect of the paper being discussed and the specific issue.", "verifiability_rationale": "The reviewer states a potential issue ('the scope of the study is underspecified') but does not provide explicit justification or evidence for why this is the case within the review point itself. While they suggest potential solutions ('additional relevant CoT baselines for incontext learning of Large Language Models...'), this is presented as a suggestion rather than a direct claim that needs verification. The reviewer is essentially pointing out a potential gap or area for improvement without explicitly stating a claim that requires further substantiation.", "helpfulness_rationale": "The review point raises a valid concern about the underspecification of the study's scope and suggests relevant baselines as a potential solution. This provides a clear direction for the authors to improve their draft. While the initial statement about the scope being underspecified might not be verifiable on its own, the suggestion of including relevant baselines is a concrete and actionable piece of feedback that can help the authors improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the action of 'improving the figure' and identifies the issue as 'hard to read anything'. While the specific type of improvement isn't detailed, the action itself is clear. This makes it 3 as the authors know they need to address the figure's readability.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 3' and states that it is 'very hard to read anything on the figure'. The use of the section reference makes it fully grounded. The comment also clearly specifies the issue within the referenced section, making it specific.", "verifiability_rationale": "The comment contains a claim that 'Figure 3 is very hard to read anything on the figure'. However, it does not provide any justification or evidence for this claim. There are no logical reasons, common knowledge, or external references provided to support the assertion that the figure is hard to read. Therefore, it is 1.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper (a difficulttoread figure) and suggests an action to address it (improve the figure). This directly points the authors in a direction for improvement. While it lacks specific details on how to improve the figure, it is a helpful starting point. The reviewer is directing the authors to focus on Figure 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer is asking for an explanation of how the general statement about the difficulty of symmetric tensor decomposition connects to the specific finding about the 'nice' landscape of symmetric order4 tensors. This is a direct and explicit request for clarification and a logical action for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions the paper 1 and specifies the type of tensor (symmetric, orthogonal, order4) and the property of the objective function ( 'nice' landscape). This provides strong grounding and high specificity.", "verifiability_rationale": "The reviewer is making a claim about the connection between the general statement and the specific finding. This claim requires logical reasoning and verification, making it 3. The verifiability depends on the authors' understanding and the reviewer's ability to find relevant connections in the literature.", "helpfulness_rationale": "The reviewer is asking for a connection between a general observation and a specific finding. This is a 5 comment as it encourages the authors to explore the relationship between these two points, potentially leading to new insights or improvements in their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3: Weakly Helpful", "actionability_rationale": "The comment implies the GAT is trained with the whole model but doesn't explicitly state it. It suggests reviewing by a native speaker and rewriting sentences for clarity, but doesn't specify which sentences or how to rewrite them. The level of detail is low, making it implicit and vague.", "grounding_specificity_rationale": "The comment refers to 'the GAT' and 'the whole model,' but it doesn't explicitly point to a specific section, table, figure, or a unique aspect of the model being discussed. The connection is implied but not explicit in the paper.", "verifiability_rationale": "The comment contains suggestions for improvement, such as 'Needs to be reviewed by a English native speaker' and 'some sentences need to be rewriting for improving the clarity.' However, it doesn't provide any specific evidence or reasoning to justify these suggestions. The claims are presented without sufficient support.", "helpfulness_rationale": "The comment raises a valid question ('The GAT is trained with the whole model?') which could be helpful for clarification. However, the suggestion to 'rewrite some sentences for improving the clarity' is vague and lacks specific guidance. The overall feedback is limited in its actionable value."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states two concrete actions: 'Replace `n^2/(2*s^2)` with an arbitrary parameter `lambda`' and 'Taking SGD learning rate ~ 0.1'. These are direct instructions on how to modify the paper, making the action explicit. The changes are also concrete, specifying exactly what replacement and learning rate value should be used. Therefore, the review point is 5.", "grounding_specificity_rationale": "The review point explicitly references 'lines 119121' for the first suggestion and 'line 164' for the second. These are literal mentions of specific sections and lines, making the grounding fully explicit and precise. The suggestion to take the learning rate as 'approximately 0.1' is also specific, indicating a clear target value. Therefore, the review point is 5.", "verifiability_rationale": "The review point makes a claim about the SGD learning rate: 'Taking SGD learning rate ~ 0.1 is unlike the Adam default value, it is unclear what the justification *is*.' This is a statement that something is missing or requires explanation. While the review does not provide the justification, the fact that it is *unlike the Adam default value* and *unclear what the justification is* is a verifiable claim. The reasoning is that the reviewer is identifying a gap in the explanation. The common knowledge aspect is that different optimizers often have different default learning rates, and the lack of justification is a verifiable observation. The external references aspect is not directly applicable here as the lack of justification is an internal point. Therefore, the review point is 3.", "helpfulness_rationale": "The review point provides clear and actionable feedback by directly instructing the authors on what changes to make: 'Replace `n^2/(2*s^2)` with an arbitrary parameter `lambda' and 'Taking SGD learning rate ~ 0.1'. These instructions are directly applicable and empower the authors to improve their draft. The feedback is not vague or general, and it points to specific areas for modification. Therefore, the review point is 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the importance of conducting error analysis and provides clear instructions on what the authors should do (conduct error analysis) and how to do it (under different scenarios). This makes the action clear and actionable for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'model performance' but does not explicitly point to a specific section, table, figure, or unique aspect of the paper where this performance is discussed. While the intent is clear, the reviewer would need to infer which part of the paper relates to the model performance.", "verifiability_rationale": "The reviewer makes a claim that 'Error analysis plays a crucial role in evaluating model performance and identifying potential issues.' While this is a generally accepted truth in model evaluation, the reviewer does not provide specific examples or references to back up this claim within the context of the paper being reviewed.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors, specifically recommending the inclusion of error analysis in their evaluation. This is a valuable piece of feedback that directly addresses a common area for improvement in research papers."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests analyzing the domain gap and adding discussions about the gap between datasets. While this is a relevant suggestion, it lacks specific actions or concrete steps on how to achieve this. The reviewer does not explicitly state what needs to be done or how to analyze the domain gap. The suggestion to finetune on synthetic data is also a potential solution but lacks specifics. Therefore, the review point is implicit and lacks concrete actions, making it 2.", "grounding_specificity_rationale": "The review point discusses the domain gap and suggests adding discussions about the gap between datasets. It does not specify which part of the paper or dataset this refers to. The reviewer mentions 'the paper' generally, without pointing to a specific section, table, figure, or unique aspect. Therefore, the review point does not identify a specific part of the paper being addressed, making it 1.", "verifiability_rationale": "The review point contains a claim: 'It would be nice to add some discussions about the gap between datasets.' This is a statement that the current draft lacks this discussion. The reviewer provides some justification for this claim by stating 'Some datasets are closer to each other thus the adaption may not be a big issue.' This justification, while not a direct citation, offers a reason for the suggestion. The reviewer also suggests 'If the method is able to finetune a pretrained model on synthetic data, then the value of the approach would be much higher.' This provides a potential solution, further supporting the claim. Therefore, the review point contains a claim that is supported by some justification and potential solutions, making it 3.", "helpfulness_rationale": "The review point suggests analyzing the domain gap and adding discussions about the gap between datasets. While this is a relevant suggestion and points towards a potential area for improvement, it does not provide specific actionable steps for the authors. The reviewer suggests a general direction for improvement but lacks specific details on how to analyze the domain gap or what aspects of the gap to focus on. The suggestion to finetune on synthetic data is a potential solution but lacks specifics. Therefore, the review point is helpful in guiding the authors towards further improvements, but it lacks concrete action, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem of performance degradation with increasing identities and suggests a potential solution by presetting a small capacity. This indicates an explicit action and a concrete suggestion on how to address the issue.", "grounding_specificity_rationale": "The reviewer refers to 'Table 3 (a)' and 'maximum number of identities,' which are specific parts of the paper. This demonstrates that the reviewer can identify the relevant section and the specific element being discussed.", "verifiability_rationale": "The reviewer makes a claim about the performance trend based on Table 3 (a). However, they do not explicitly provide evidence or justification within the review point itself to support this claim. The verifiability relies on the reader having access to Table 3 (a) and being able to observe the trend.", "helpfulness_rationale": "The reviewer identifies a clear issue related to scalability and provides a suggestion. While the suggestion is somewhat general ('think about how to scale up'), it does offer a direction for improvement. The reviewer's identification of the problem and potential solution makes the feedback 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the authors' claim about LLP being a preliminary work with NLPspecific application is incorrect. While the reviewer identifies a flaw in the authors' claim, they don't explicitly state what is *not* NLPspecific or how the authors should revise their work to be NLPspecific. The reviewer's statement is a direct criticism of the authors' claim, but lacks specific actionable steps for the authors.", "grounding_specificity_rationale": "The reviewer criticizes the authors' claim about LLP being a preliminary work with NLPspecific application by stating 'I don't see anything NLPspecific in their approach.' While the reviewer mentions LLP and NLP, they don't pinpoint a specific part of the paper that lacks NLPspecificity. The criticism is general and doesn't identify a concrete element of the work being critiqued. The reviewer's statement is about the absence of something, not the presence of a specific detail.", "verifiability_rationale": "The reviewer's statement 'I don't see anything NLPspecific in their approach' is a claim that lacks supporting evidence. There is no logical reasoning, common knowledge, or external references provided to back up this assertion. The reviewer simply states their opinion about the authors' work without providing any basis for it. This claim is not verifiable because there is no justification for it.", "helpfulness_rationale": "The reviewer's comment is a critique of the authors' claim about LLP being a preliminary work with NLPspecific application. While the reviewer identifies a potential flaw in the authors' understanding, the comment itself doesn't offer any specific suggestions or corrections. It's a statement of what the reviewer believes is incorrect, but without any guidance on how to address it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests adding a significance test to the human evaluation results and comparing the proposed method with recent LLMs. These are direct, actionable suggestions that guide the authors on what improvements to implement. The reviewer is implying that the current evaluation lacks rigor and that the proposed method needs to be benchmarked against current stateoftheart models.", "grounding_specificity_rationale": "The review point mentions 'the experiment section' and 'the human evaluation results' and 'some most recent LLM'. While the general area is clear, the specific sections, tables, figures, or unique elements within the experiment section and the exact nature of the human evaluation results and the specific recent LLMs are not precisely identified. The reviewer can infer the general areas but needs to refer back to the paper for specifics.", "verifiability_rationale": "The review point makes claims by suggesting that adding a significance test to the human evaluation results is beneficial and that comparing the proposed method with recent LLMs is beneficial. However, the reasoning behind these claims is not explicitly provided or supported by external references. The reviewer is making general assumptions about the importance of statistical significance and model comparisons, but lacks the necessary evidence to fully convince the authors.", "helpfulness_rationale": "The review point provides suggestions for improvement, specifically suggesting the addition of a significance test to the human evaluation results and the comparison of the proposed method with recent LLMs. However, the suggestions are somewhat vague and lack specific details. The reviewer does not specify *how* to carry out the significance test or which specific human evaluation results are being referred to. Similarly, the comparison with LLMs is suggested without providing concrete examples or data points, making it less actionable for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the authors' claim about 'no research focusing on the joint error for UDA' and then names a specific paper ('Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment') that contradicts this claim. The reviewer also states the intention to discuss the relationship between the two works and justify the proposed method, which is a concrete action.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific paper ('Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment') and the specific concept ('joint error for UDA') that the authors' claim refers to. They also clearly state the intention to discuss the relationship and justify the proposed method, further specifying the area of concern.", "verifiability_rationale": "The reviewer makes a clear claim that the authors' claim is incorrect and requires addressing. The reviewer then provides a specific reference and a clear explanation of how this work relates to the authors' claim. The suggestions to 'discuss on that work', 'directly illustrate the relationship', and 'why the proposed method is better' are logical next steps to verify the reviewer's point.", "helpfulness_rationale": "The reviewer provides a clear and actionable critique. They identify a specific gap in the authors' discussion (lack of mention of prior work on joint error) and offers concrete suggestions for improvement (discuss the work, illustrate the relationship, justify the proposed method). This directly helps the authors address a potential weakness in their understanding or framing of the problem."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state any actions or suggest any changes to the paper. It is a critique of the comparison, not a proposal for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'comparison with the SOTA methods' and 'newly collected 209M dataset' and 'smaller datasets' as examples. While the grounding is somewhat present, the reviewer does not specify *which* part of the paper or comparison these elements refer to. The grounding is implied but not explicitly pointed out within the text of the review point itself.", "verifiability_rationale": "The claim that the comparison is 'unfair' is presented as a potential issue. While the reviewer *identifies* a problem (dataset size difference), they do not provide any specific examples, references, or logical reasoning to *justify* why this constitutes a significant flaw in the comparison. The claim is stated, but not wellsupported within the review point.", "helpfulness_rationale": "The review point raises a concern about the fairness of a comparison. While this is a valuable piece of feedback, the reviewer does not offer any concrete suggestions or actions to address the identified issue. The point is critical but lacks actionable recommendations."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the absence of a justification for designing a new curriculum learning method and the lack of discussion regarding the limitations of existing methods. It directly identifies the gap in the paper and suggests addressing it by providing a rationale and discussing limitations. The action is clearly stated, making it 5.", "grounding_specificity_rationale": "The review point explicitly refers to 'Section 1' and the 'need for designing a new curriculum learning method for text graphs'. This direct and specific reference clearly identifies the part of the paper being addressed, making the grounding fully specific. The reviewer also states what is missing, further emphasizing the specificity.", "verifiability_rationale": "The review point makes a claim that 'Several curriculum learning methods have been discussed in Section 1. However, the need for designing a new curriculum learning method for text graphs is not justified. The research gap, e.g., why existing methods can\u2019t be applied, is not discussed.' This claim is supported by stating the absence of a justification and a discussion of limitations, making it 5. No external references or logical reasoning beyond stating the facts are needed to understand the claim.", "helpfulness_rationale": "The review point is 5 as it directly points out a significant gap in the related work section. By highlighting the lack of justification for a new method and the absence of discussion on the limitations of existing methods, the reviewer provides clear direction for the authors. This information is valuable for the authors to understand the research gap and motivate them to explore new approaches. The feedback is constructive and directly addresses a potential weakness."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the suggestion to use pretrained language models as a base encoder and compare the transfer parts. This is an explicit action. However, the reviewer does not provide concrete details on *how* to implement this, such as which specific models to use or how to train the transfer parts. Therefore, it's partially actionable.", "grounding_specificity_rationale": "The reviewer mentions \"pretrained language models\" in the \"NLP field.\" They do not explicitly refer to a specific section, table, figure, or unique aspect of the authors' paper. Furthermore, they do not specify which pretrained models (e.g., BERT, XLNet) or how they should be used as a base. This lack of specificity in both grounding and detailing the models makes it 2.", "verifiability_rationale": "The reviewer makes a claim about the effectiveness of pretrained language models in overcoming domain shift. This claim is supported by general knowledge about the capabilities of these models in the NLP field. While not a formal proof, the suggestion is based on established principles.", "helpfulness_rationale": "The reviewer's suggestion to use pretrained language models as a base encoder is relevant to the field of NLP and addresses a potential limitation of ngram features (lack of semantic understanding). The suggestion provides a clear direction for improvement by focusing on the transfer learning aspect. However, it lacks specific implementation details, making it 3 but not the most detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the issue and suggests an investigation, indicating a degree of actionability. However, the vagueness of the identified performance gain makes the action somewhat unclear on the exact steps to take.", "grounding_specificity_rationale": "The review point makes general statements about the method (complicated modules, more parameters) without explicitly identifying the specific parts or issues. The specificity of the problems is also not clearly defined, making it difficult to pinpoint the exact areas needing improvement.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity in the ablation study. However, the support for this claim is limited to a suggestion for further investigation, lacking specific evidence or references.", "helpfulness_rationale": "The reviewer identifies a potential issue and suggests a direction for improvement. However, the lack of specific details makes the feedback less immediately actionable and more of a general suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests an action: 'this requires more explanation'. However, the specifics of what needs more explanation and why are not provided. The action is implied but not explicitly stated or detailed.", "grounding_specificity_rationale": "The reviewer refers to 'two quantities' but does not specify which quantities they are referring to. The section or context of the review point is needed to identify the specific parts of the paper being addressed. The grounding is weak as the referenced part is not explicitly identified.", "verifiability_rationale": "The reviewer makes a claim: 'this requires more explanation'. However, they do not provide any evidence or justification for why this explanation is needed or how it would be beneficial. The claim is stated without supporting reasoning or references.", "helpfulness_rationale": "The reviewer identifies a weakness in the paper ('this requires more explanation') and suggests an improvement ('more explanation'). However, the suggestion is vague and lacks specific details. The reviewer is pointing out a potential area for improvement, but the lack of concrete suggestions makes the feedback less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point asks the authors to discuss the sensitivity of fixed tuning parameters. While not explicitly stated as an action, the reviewer implies the authors should analyze how changes to these parameters affect the model's performance. This requires the authors to identify fixed tuning parameters and then perform an analysis, making it 3.", "grounding_specificity_rationale": "The reviewer refers to 'fixed tuning parameters.' While not explicitly stating the section or table, this is a fairly specific concept within the context of model tuning. The authors can reasonably infer the reviewer is interested in a specific aspect of their model's configuration. Therefore, it can be considered weakly grounded as the authors can make an educated guess about the referenced part.", "verifiability_rationale": "", "helpfulness_rationale": "This review point is 5. It prompts the authors to investigate a crucial aspect of their model: the sensitivity of fixed tuning parameters. Understanding how these parameters affect performance is essential for model optimization and robustness. It provides a clear direction for the authors to conduct further analysis and potentially improve their model. The request for both strengths and weaknesses makes it particularly valuable."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X (X)", "helpfulness_label": "Not 5", "actionability_rationale": "The review point asks a question about the framework's compatibility with different policy gradient approaches and requests experimental details. It doesn't explicitly state what needs to be done or suggest an alternative, making it not fully actionable. It's a request for information rather than a proposed change.", "grounding_specificity_rationale": "The review point directly asks about the number of random seeds used in experiments, explicitly mentioning 'DDPO and IPPG'. This clearly grounds the review in the specific experimental setup and asks a very specific question about it.", "verifiability_rationale": "The review point is a question seeking information, not a statement of opinion or assertion. Therefore, it doesn't contain a claim that needs verification.", "helpfulness_rationale": "The review point is a request for experimental details, which is valuable for understanding the framework but doesn't directly improve the reviewed draft. It's more of a request for information about the reviewed paper's experiments than a suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests a specific action: evaluating the paper on more datasets and tasks. This is a clear and direct suggestion for improvement, making it 5. The reviewer implies they understand the current limitations and are proposing a concrete solution.", "grounding_specificity_rationale": "The reviewer explicitly states 'one dataset' and 'one task' in the paper evaluation. This directly identifies the specific part of the paper being addressed, making it fully grounded. The reviewer provides precise information about the scope of the evaluation.", "verifiability_rationale": "The reviewer's suggestion is logically sound and directly addresses a limitation of the paper's conclusions. The reasoning behind the suggestion is clear and beneficial, making it 5. The reviewer doesn't need external references to justify their point.", "helpfulness_rationale": "The reviewer's suggestion is directly aimed at improving the paper's conclusions by expanding the evaluation. This is a highly beneficial and actionable suggestion for the authors, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question ('what are the \"relevant\" auxiliary model weights?') rather than stating an explicit action to be taken. While the intent is to improve clarity, the request itself doesn't directly instruct the authors on what to do. They still need to figure out what \"relevant\" means in this context.", "grounding_specificity_rationale": "The reviewer refers to \"definition 2.1\" which is specific. However, the comment itself doesn't explicitly identify the specific part of that definition that is unclear or problematic. The focus is on the *definition* itself rather than a specific element within it.", "verifiability_rationale": "The reviewer doesn't explicitly state a claim or assertion about the paper's quality or correctness. They are suggesting that the definition is unclear, which could be interpreted as a claim, but it lacks specific examples or references to external sources to support this claim. It's more of a constructive suggestion for the authors to clarify rather than a direct criticism of a flaw.", "helpfulness_rationale": "The reviewer's comment points to a potential area for improvement (clarity in definition 2.1). This can be helpful for the authors as it guides them towards selfcorrection. However, the vagueness of the comment ('relevant' weights) makes it less impactful than a more specific suggestion. It's not a direct fix, so its helpfulness is limited."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'Dependence on MIA (Membership Inference Attack) Testing via Ulira: While the paper uses MIA testing as a metric for unlearning effectiveness, the effectiveness of MIA testing itself is not sufficiently robust for privacy guarantees. Additionally the use of ULiRA 1 is recommended.' The reviewer clearly identifies the area of the paper being discussed and provides a specific suggestion to improve it by using ULiRA. The action is both explicit (the reviewer points to a specific aspect) and concrete (the reviewer specifies the issue and the solution).", "grounding_specificity_rationale": "The review point identifies the specific aspect of the paper being discussed by mentioning 'MIA testing' and 'Ulira'. The reviewer can accurately pinpoint the section or table where these concepts are discussed. Furthermore, the reviewer explicitly states the issue with MIA testing ('not sufficiently robust for privacy guarantees') and recommends a specific improvement ('the use of ULiRA 1'). This demonstrates a high level of grounding and specificity.", "verifiability_rationale": "The review point contains claims that need verification. The claim 'the effectiveness of MIA testing itself is not sufficiently robust for privacy guarantees' is stated without providing specific evidence or citations to support this assertion. While the reviewer recommends 'the use of ULiRA 1', this is a suggestion, not a claim requiring the same level of verifiable evidence. The lack of supporting evidence for the negative assessment of MIA testing makes the claim 1.", "helpfulness_rationale": "The review point is actionable, as it clearly states what the authors should do (improve MIA testing and consider ULiRA). It is also grounded, as the reviewer refers to 'MIA testing' and 'Ulira', which are specific concepts within the paper. However, the claim about the limitations of MIA testing lacks supporting evidence, making the advice less certain. While the reviewer suggests a solution, the lack of verifiable support for the problem makes the overall feedback less helpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation in the evaluation process but doesn't explicitly state a desired action or solution. While they imply a need for more concrete feedback, the current statement is more of a critique than a directive action. The reviewer suggests a quantitive comparison on the final outputs, which could be seen as an implicit action, but it's not a fully explicit or concrete action to be taken by the authors.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 3' and 'Figure 4' in their review point. These are specific elements of the paper, indicating a clear identification of the part being addressed. This aligns with the definition of 'Full Grounding' as the reviewer accurately pinpoints the sections being discussed.", "verifiability_rationale": "The reviewer makes a claim about the evaluation results being 'not convincing enough' and suggests a 'quantitive comparison on the final outputs.' While the reviewer identifies a problem with the current evaluation, the claim about the evaluation being 'not convincing enough' lacks specific justification or evidence. The suggestion for a 'quantitive comparison on the final outputs' is a potential action, but the current statement is a critique without concrete supporting evidence. Therefore, it's partially verifiable as the reviewer makes a claim, but lacks sufficient justification.", "helpfulness_rationale": "The reviewer's comment about the evaluation being 'not convincing enough' suggests a lack of clear and actionable feedback. While the reviewer identifies a problem with the current evaluation, they don't provide specific suggestions or evidence to support their claim. The reviewer's comment is more of a critique of the evaluation's current state rather than a direct suggestion for improvement. Therefore, it's not currently 5 as it lacks specific and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides explicit suggestions for improvement, such as 'add details to the experimental procedures,' 'add error bars and pvalues to statistical inferences,' and 'include supplementary information.' While the suggestions are clear, they are somewhat vague in terms of *how* to add these details. For example, 'add details' doesn't specify *which* details are needed. Similarly, 'include supplementary information' is broad. The reviewer also points out the lack of specificity in the procedures, which makes it difficult to know exactly what needs to be added. Therefore, while the suggestions are explicit, the lack of concrete details makes them somewhat vague in terms of actionable steps.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'explanations,' 'procedures,' and 'figures' where the issues lie. For example, they state, 'Most importantly, the explanations are very qualitative.' They also point out the confusion in Figure 2 regarding the 'sample count.' This directly identifies the specific parts of the paper being addressed, making the grounding quite explicit. The reviewer doesn't just say 'there's a problem,' but rather pinpoints the location of the problem.", "verifiability_rationale": "The reviewer makes claims about the paper being 'qualitative,' 'lacking detail in experimental procedures,' 'confusing figures,' and 'lacking statistical rigor.' These are clear claims that the reviewer believes are supported by the content of the paper. For example, they state, 'whenever simulation or experimentbased evidence is given, the procedures are described very minimally or not at all.' While the reviewer's claims are valid, they lack specific examples or references to support these claims. The reasoning is present, but the evidence is general and not explicitly linked to specific sections or figures. Therefore, the claims are 3, as there is a basis for the criticism, but it lacks the depth of external references or specific examples.", "helpfulness_rationale": "The reviewer provides clear and actionable feedback, directly addressing specific areas of the paper. They explicitly state what is missing and what should be added. For example, they say, 'Most importantly, the explanations are very qualitative and whenever simulation or experimentbased evidence is given, the procedures are described very minimally or not at all, and some figures are confusing.' This clearly identifies the weaknesses. They also suggest concrete improvements, such as 'adding details to the experimental procedures,' 'adding error bars and pvalues to statistical inferences,' and 'including supplementary information.' These suggestions are directly linked to the identified weaknesses and are likely to be helpful for the authors. The feedback is not just a general criticism but points to specific areas for improvement."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests adding references to existing studies. While this is a valid suggestion, the review point itself doesn't explicitly state how to add these references or where to find them. The action of adding references is implied but not explicitly stated as a step for the author.", "grounding_specificity_rationale": "The reviewer mentions specific factors (order sensitivity, complexity, diversity, style sensitivity) that have been discussed in existing studies. This demonstrates that the reviewer has identified parts of the paper (prompting strategies) and connected them to existing literature. However, the reviewer does not explicitly state which specific studies are relevant or how these factors directly impact the paper's specific implementation of chainofthought prompting.", "verifiability_rationale": "The reviewer states that 'most of the above factors have been discussed in existing studies.' This is a claim that something exists. However, the reviewer does not provide any specific examples or references to support this claim within the review point itself.", "helpfulness_rationale": "The reviewer's suggestion to add references is relevant to the paper's content, as it relates to the factors affecting chainofthought prompting. However, the suggestion is quite general. It doesn't specify which references to add, where to add them, or how these references would improve the draft. The impact on the authors' ability to improve their work is limited."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests explicitly showing the settings for the various knobs of the algorithm to mimic prior work. While the reviewer identifies a potential improvement (showing settings), the exact *method* or *implementation* of how to show these settings is not specified. The reviewer states the *goal* (mimicking prior work), but the *how* remains vague. Therefore, while the reviewer points out a valuable suggestion, the lack of concrete details makes the action somewhat ambiguous.", "grounding_specificity_rationale": "The reviewer mentions 'various knobs of this algorithm' and 'prior work: Dagger, searn, etc...'. This indicates a clear identification of the specific part of the paper being discussed (the algorithm's parameters and its relation to existing algorithms). Furthermore, the reviewer names specific algorithms (Dagger and SEAR/SEAR). This demonstrates a high level of specificity in identifying the relevant aspects of the paper and providing concrete examples of prior work. The reviewer is not just talking about 'prior work' in general, but about specific algorithms and their parameters.", "verifiability_rationale": "The reviewer states a suggestion: 'This paper could be improved by explicitly showing the settings for the various knobs of this algorithm to mimic prior work...'. This constitutes a claim, as the reviewer is making a statement that could lead to improvement. However, the reviewer does not provide any justification or reasoning for why this suggestion is valuable or how it would be implemented. There is no logical reasoning, common knowledge, or external references provided to support the claim. The reviewer simply states the suggestion without backing it up.", "helpfulness_rationale": "The reviewer suggests explicitly showing the settings for the various knobs of the algorithm to mimic prior work. While this is a potentially useful suggestion, the reviewer does not provide any details on how this would be done or why it would be beneficial for the authors. The suggestion is presented as a general idea without any specific implementation details or justification. The reviewer states the *what* (showing settings) but lacks the *how* and *why*, making the suggestion somewhat vague and lacking a clear contribution to the community."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the problem: 'we are not sure how general these situations are.' This indicates an awareness of a potential issue. However, the reviewer does not provide a concrete action or suggestion to address this lack of clarity. The action is implied rather than explicitly stated and acted upon.", "grounding_specificity_rationale": "The reviewer mentions 'section 3.2' and 'Theorem 1', which demonstrates a clear grounding in the paper's structure and content. However, the reviewer is pointing out a lack of grounding in the *generalizability* aspect of the biases and prediction shifts. While the grounding is specific to the examples, the lack of grounding in the generalizability is a broader, less specific issue.", "verifiability_rationale": "The reviewer is suggesting that the paper should investigate the generalizability of the biases and prediction shifts. This is a suggestion or a recommendation, not a claim that something is or is not generalizable. There is no logical reasoning, common knowledge, or external references provided to support this suggestion within the review point itself.", "helpfulness_rationale": "The reviewer is pointing out a limitation in the paper's analysis by highlighting the lack of clarity regarding the generalizability of the discussed concepts. This is a constructive comment aimed at improving the paper by suggesting further investigation. While it doesn't offer a direct solution, it identifies a valuable area for future work."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment suggests the need for more datasets but lacks specific details on how to implement this suggestion, making it only implicitly actionable.", "grounding_specificity_rationale": "The comment refers to 'datasets' and 'crosstask transferability' generally without pinpointing a specific section or element of the paper, making the grounding weak. While it mentions specific areas, it doesn't detail what is missing or how to address it, making the specificity also weak.", "verifiability_rationale": "The comment is a suggestion for improvement rather than a claim that something is wrong or needs fixing. Therefore, it doesn't have a claim to verify.", "helpfulness_rationale": "The comment is relevant to the authors as it points to a potential area for improvement (more data for crosstask transferability). However, the vagueness of the suggestion makes it less actionable and potentially less helpful than a more specific comment."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests 'some unique tasks created from this nice dataset showcasing the diversity of images/plots' and gives an example 'Question Answering from images'. While this suggests a potential improvement, it lacks specific details on how to implement these unique tasks or how they differ from existing tasks. The reviewer doesn't explicitly state an action or provide concrete steps on how to achieve this. The suggestion is present, but the 'how' is missing.", "grounding_specificity_rationale": "The reviewer mentions 'Figure captioning' and 'matching figures/subfigures to appropriate captions' but doesn't specify which figures or sections of the paper are being referred to. The criticism is about the general nature of these tasks being 'somewhat standard' rather than pinpointing a specific part of the paper. The reviewer doesn't provide a clear explanation of what is wrong with these tasks in a specific section or table.", "verifiability_rationale": "The reviewer states 'It would have been nice to see some unique tasks created from this nice dataset showcasing the diversity of images/plots. e.g. some variety of interleaved imagetext tasks such as Question Answering from images could have been considered.' This statement presents a suggestion and implies a difference from current practices. However, it doesn't provide a claim that something is wrong with the current tasks or that these new tasks are needed. There is no explicit claim being made, and no logical reasoning or external references are provided to support this suggestion.", "helpfulness_rationale": "The reviewer's suggestion to introduce 'some unique tasks created from this nice dataset showcasing the diversity of images/plots' is relevant to the field and could be a valuable addition. It points out a potential area for improvement in dataset creation. However, the suggestion is quite general and doesn't offer specific details on how to implement these unique tasks or what makes them different from existing ones. It lacks a strong justification for why these specific unique tasks are necessary or beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the method in Sec. 3.1 follows Luciddreamer but doesn't explicitly state it's *novel*. They imply it's not different, which is an implicit statement but lacks detail on *how* it's similar. The vagueness makes it difficult to pinpoint an actionable improvement.", "grounding_specificity_rationale": "The reviewer mentions 'Sec. 3.1' and 'Luciddreamer' but doesn't specify *which* part of Sec. 3.1 they're referring to or provide a detailed comparison with Luciddreamer. This makes it difficult to pinpoint the exact issue and understand the grounding.", "verifiability_rationale": "The reviewer claims the method follows Luciddreamer without providing any evidence, examples, or logical reasoning to support this claim. There's no external reference or justification given to back up their assertion.", "helpfulness_rationale": "The reviewer's comment raises a valid question about the novelty of the method. While this can be helpful for the authors to understand the context of their work, it doesn't directly provide actionable feedback on how to improve the draft. It's more of a diagnostic statement than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitations of MMD DRO, such as the lack of a tractable exact reformulation, the looseness of the upper bound, and the restrictive assumption about the loss function belonging to the RKHS. These are all concrete actions or suggestions that the authors could potentially implement or address. While the reviewer doesn't explicitly state *how* to address these issues, the identification of these problems is actionable.", "grounding_specificity_rationale": "The reviewer refers to 'MMD DRO,' 'Theorem 3.1,' 'RKHS,' and 'loss function.' While they don't explicitly state which specific part of their own paper or the referenced work they are referring to, the mention of 'Theorem 3.1' strongly implies they are referring to a specific result or section in the paper they are reviewing. This provides some level of grounding, but it's not as precise as referring to a specific table or figure. Therefore, it's 'Weakly Grounded'.", "verifiability_rationale": "The reviewer provides specific reasons *why* they find MMD DRO problematic. They explain *how* the lack of an exact reformulation, the looseness of the bound, and the RKHS assumption lead to a 'severe drawback.' This provides a clear logical reasoning for their criticism. The reviewer's argument is based on established concepts in optimization and functional analysis, making it verifiable.", "helpfulness_rationale": "The reviewer clearly articulates their concerns and suggests potential improvements. They point out specific limitations of MMD DRO and propose directions for future work. While they don't explicitly state *what* changes should be made, the underlying criticism and the implied suggestions for improvement make this review quite helpful for the authors. The reviewer is not just pointing out a problem but also offering a direction to potentially solve it."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer directly asks questions about the framework's relevance and limitations in specific scenarios (nonconvex losses/nonnorm constraints, binary classification with oracle mean). These questions prompt the authors to consider the framework's applicability and potential shortcomings in these contexts. While the reviewer doesn't explicitly state an action, the questions implicitly guide the authors towards investigating these aspects. The reviewer also asks about the implications of the nonvanishing duality gap and difficulty of maximization, which are actions the authors could take to explore further.", "grounding_specificity_rationale": "The reviewer's questions are general and do not explicitly point to a specific part of the paper they are referring to. They ask about the framework's relevance to 'nonconvex losses and/or nonnorm type defenses' and 'binary classification' without specifying which section or table this relates to. While the questions are about specific concepts, the lack of a direct reference to a specific part of the paper makes the grounding weak.", "verifiability_rationale": "The reviewer presents specific scenarios and asks questions about the framework's limitations and potential extensions. For example, they ask if the nonvanishing duality gap and difficulty of maximization over nonnorm constraints make the algorithm irrelevant or if it still gives intuitions on the risk upperbound. They also ask if covariance or other statistics can be used when the true mean is known through an oracle. These are claims that the authors need to verify or consider, but the paper does not explicitly provide immediate references or derivations to support these specific claims within the provided text. The reviewer is making assertions that require further investigation.", "helpfulness_rationale": "The reviewer provides a list of questions and suggestions for the authors. These are actionable and directly address potential limitations of the framework in specific contexts. The reviewer asks about the framework's relevance to nonconvex losses/nonnorm constraints, the implications of the nonvanishing duality gap, and suggests exploring covariance when the true mean is known. These are concrete points that the authors can consider and potentially improve their work based on. The reviewer's suggestions for improvement are also helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests an action: 'sparsify the trained models' and a comparison: 'compare accuracy to the proposed model'. While the action is clear, the method of sparsification is not specified, making it somewhat vague on how to implement it. The comparison is explicit. Therefore, it is 3 but lacks concrete implementation details for the action.", "grounding_specificity_rationale": "The reviewer refers to 'the baselines on the left hand side' of Figure 3, which implies they have seen the figure and are specifically pointing to a subset of the baselines. This is strong grounding as the section, table, figure, or unique aspect is accurately pinpointed. The reviewer also specifies the comparison to the 'proposed model', adding to the specificity of the referenced part.", "verifiability_rationale": "The reviewer does not explicitly state a claim. They are suggesting an experiment and asking a question. While the suggestion to sparsify is a valid point for investigation, there is X being made or supported by evidence within the review point itself. Therefore, it is best classified as having X.", "helpfulness_rationale": "The reviewer's suggestion to sparsify the trained models and compare accuracy to the proposed model is a relevant and actionable point for improving the draft. It directly addresses the performance of the baseline models. However, the suggestion lacks specific details on how to perform the sparsification, which limits its immediate helpfulness. It provides a direction for further investigation but doesn't offer a concrete solution or a detailed analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the lack of detail regarding the techniques, which is a direct identification of an action the authors should take. The examples provided (sparsification, landmark generation, feature types, radius) are concrete actions. However, the reviewer doesn't specify *how* these actions should be performed, making it only partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'techniques' generally, which doesn't strongly ground the specific part of the paper being addressed. However, they do specify *what aspects* of the techniques are lacking detail (landmarks, features, radius). This provides some level of specificity about the areas needing clarification.", "verifiability_rationale": "The reviewer makes a claim that the paper 'lacks detail about the techniques and make it hard to reproduce the result.' However, they do not provide any specific evidence or reasoning to support this claim. The reviewer lists missing information but doesn't explain *why* this lack of detail is problematic or *cite* any specific examples of how this information is crucial for reproducibility. Therefore, the claim is not wellverified.", "helpfulness_rationale": "The reviewer identifies a significant issue ('lacks detail about the techniques and make it hard to reproduce the result') that is crucial for the authors to understand and implement. However, the lack of specificity regarding the *nature* of this missing detail makes the feedback less helpful. The authors don't know *exactly* what information is missing or *how* it impacts reproducibility. This makes the point somewhat vague in its guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the desired action: 'it should be reorganized'. This clearly indicates a direction for improvement. While the specifics of the reorganization are not provided, the action itself is clear and actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'Appendix H', which is a specific part of the paper. This demonstrates strong grounding as the reviewer can easily identify the referenced section. However, the comment does not specify *what* is wrong with Appendix H, making it only '4'.", "verifiability_rationale": "The comment contains a claim: 'Appendix H is difficult to follow'. This claim is supported by the statement itself, indicating a belief or judgment about the paper's content. The suggestion to 'reorganized' implies a logical connection between the identified problem and the proposed solution.", "helpfulness_rationale": "The comment identifies a specific area for improvement ('Appendix H') and offers a clear suggestion ('reorganized'). While the suggestion is somewhat general, it points to a valuable direction for the authors. The reviewer's intent is to help the authors improve their draft by addressing a concrete issue."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the need for more details to reproduce the work and provides specific examples of missing information, such as the number of units in the RNN implementation. While it doesn't directly tell the authors what to add, it clearly points out the areas where information is lacking, making it actionable.", "grounding_specificity_rationale": "The comment explicitly mentions specific parts of the paper where details are lacking, such as the RNN implementation, and provides examples of what is missing. The reviewer accurately identifies the specific aspects of the implementation that require clarification, making the comment 5.", "verifiability_rationale": "The comment contains a claim (i.e., 'I don't get the feeling the paper is written to be reproduced') and provides supporting evidence (pseudocode and supplementary material) to back up this claim. The reviewer logically explains why the provided information might not be sufficient for reproduction, making the claim verifiable.", "helpfulness_rationale": "The comment clearly states a need for more information to reproduce the work and provides a rationale for this feeling. The reviewer explains that the lack of specific implementation details hinders reproducibility, making the comment 5 for the authors to understand what information is missing and how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action (adding error bars) and provides a concrete detail on how to implement it (improving the visual representation of the data). This fits the definition of 'Explicit' and 'Concrete'.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 1' and suggests a modification directly related to this figure. This clearly identifies the specific part of the paper being addressed and the issue.", "verifiability_rationale": "The review point does not make a definitive statement about what Figure 1 'should' look like. It's a suggestion for improvement, not a claim requiring verification. The suggestion is open to interpretation.", "helpfulness_rationale": "The review point directly addresses a potential weakness (lack of error bars/visibility of results) and suggests a concrete improvement (adding error bars). While the suggestion to 'potentially get rid of fluctuations' is less specific, the core focus is on improving the clarity and rigor of the results presentation. It provides a clear direction for the author to take."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests adding an introduction to energy models in the related work section, which is a direct action the authors can take. However, the suggestion lacks specific details on where this introduction should be placed within the related work section or what specific aspects of energy models should be covered. The request to clarify Figure 1 is an implicit action, as the reviewer identifies a missing element (labels) that needs to be addressed, but the authors still don't know how to carry out this action.", "grounding_specificity_rationale": "The suggestion to add an introduction to energy models in the related work section is 1, as the authors cannot confidently determine which part the comment addresses. The reviewer mentions 'energy models' but doesn't specify which section, table, figure, or unique aspect of the paper this should relate to. However, the request to clarify Figure 1 is partially grounded, as the authors can identify the specific part of the paper (Figure 1) where the information is missing.", "verifiability_rationale": "The review point does not contain a claim that requires verification. The suggestions are recommendations for improvement rather than statements that need to be supported by evidence or reasoning.", "helpfulness_rationale": "The review point offers two suggestions. The suggestion to add an introduction to energy models in the related work section is generally helpful for providing context. The request to clarify Figure 1 is 5 as it directly addresses a potential issue with the clarity of the experimental setup or results. The combination of these suggestions makes the review point 3."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem of premature evictions based on utility scores and suggests considering chunk age as an action to address this issue. The action is clear and directly actionable for the authors.", "grounding_specificity_rationale": "The review point discusses the FIITED framework and the concept of utilitybased eviction. While it doesn't explicitly name a section or table, it clearly identifies the issue as 'premature evictions' within the context of the 'utilitybased approach.' This makes it fully grounded in the described framework but underspecific as it doesn't target a particular element like a table or figure.", "verifiability_rationale": "The review point makes a claim about the potential for bias in utilitybased eviction. It provides a logical explanation and an example of how this bias might manifest ('recent chunks might gain a temporary high utility'). This logical reasoning and example support the claim, making it verifiable.", "helpfulness_rationale": "The review point is clear, identifies a specific problem within the FIITED framework, and provides a concrete suggestion for improvement ('consider chunk age'). This actionable feedback is directly relevant to the authors' work and is likely to be helpful in refining their chunk management strategy."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the first paragraph of the Introduction is about DNNs but lacks any mention of drift. They clearly identify the action needed: 'This entire paragraph provides little valuable information to readers.' The reviewer provides a direct and specific suggestion for improvement, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly identifies the section of the paper being addressed as 'the first paragraph of the Introduction' and the specific topic within that section as 'DNNs'. They also specify the *absence* of driftrelated information. This demonstrates strong grounding as the reviewer can confidently identify the referenced part and clearly identifies the issue with it.", "verifiability_rationale": "The reviewer makes a claim that the DNN introduction is 'not central' and 'provides little valuable information' to readers. They support this claim by arguing that a general DNN introduction is not directly relevant to 'detecting drift types and drift magnitude'. The reviewer provides a clear justification for their claim based on the paper's stated focus, making the claim verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable critique. They identify a specific section of the paper and its lack of relevance to the paper's core focus. They suggest a concrete improvement: 'This entire paragraph provides little valuable information to readers.' This critique is directly relevant to improving the paper's clarity and focus, making it 5."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer suggests improvements to the framework, such as 'quantitative experiments and comparison between selection of algorithms' and 'detailed explanations on the presented ones.' However, the review lacks specific details on *how* these improvements should be implemented. The reviewer doesn't specify which parts of the framework need new experiments or comparisons, nor does they provide a clear methodology for the 'detailed explanations.' Therefore, while the intent is to improve the framework, the lack of concrete action makes it difficult to act upon. The reviewer suggests *what* should be improved but not *how* to improve it.", "grounding_specificity_rationale": "The reviewer mentions 'how the different part of this framework performs and contribute to the final result' and refers to the 'result section.' However, they do not specify *which* part of the framework they are referring to or *how* the performance is being evaluated. The reviewer also mentions 'individual parts compared to other solutions' without specifying which parts or solutions are being compared. The reference to the 'result section' is too general and doesn't pinpoint the specific information needed for grounding. The reviewer is vague about the *specifics* of the framework's performance and the *nature* of the comparisons.", "verifiability_rationale": "The reviewer states, 'it lacks either quantitative experiments and comparison between algorithms, or a more detailed explanations on the presented ones.' They also express uncertainty about 'what the exact performance of the whole framework and individual parts compared to other solutions.' This indicates a lack of supporting evidence or justification for the claims being made. The reviewer doesn't provide any references, examples, or logical reasoning to back up their assessment of the framework's performance. The claims are presented without sufficient grounding or verifiability.", "helpfulness_rationale": "The reviewer expresses a lack of clarity regarding the framework's performance and contribution to the final result. They state that the comment lacks supporting evidence or justification, making it difficult to understand the framework's effectiveness. The reviewer is uncertain about the performance of the framework and the lack of quantitative experiments, comparisons, and detailed explanations makes it hard to gain actionable feedback. The reviewer's statement that the comment is '1' reflects their inability to extract meaningful information from the review point."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not provide explicit or implicit actions that the authors can directly implement. The reviewer is questioning the potential of the work rather than suggesting concrete changes to the authors' current draft. There is no guidance on what the authors should do or how they should apply the feedback.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or unique element that it is addressing. It is a general question about the potential of the work, not a critique of a particular section, table, figure, or unique aspect of the authors' paper. The reviewer is asking about the broader implications rather than specific issues within the current draft.", "verifiability_rationale": "The review point does not contain a claim that is verifiably supported. It is a question about the potential of the work, not a statement that can be proven or disproven based on the current draft. There are no references to external works or logical reasoning provided within the review point itself.", "helpfulness_rationale": "The review point raises important questions about the potential of the work, which could be helpful for the authors to consider. However, it does not provide specific, actionable feedback on how to improve their current draft. It lacks concrete suggestions or guidance on what changes to make or how to address the identified issues. While it prompts reflection, it doesn't directly help the authors improve their immediate work."}
{"actionability_label": "0", "grounding_specificity_label": "1", "verifiability_label": "0", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, not a directive. It doesn't tell the authors what to do or how to do it. It's a request for information about presenting the theorems simply.", "grounding_specificity_rationale": "The review point is about presenting the theorems simply, but it doesn't specify *which* theorem or definition this refers to. It's a general suggestion about presentation.", "verifiability_rationale": "The review point is a suggestion, not a claim that needs verification.", "helpfulness_rationale": "The review point suggests a valuable direction for the authors (presenting theorems simply), but it doesn't directly address a specific weakness or provide immediate actionable steps. It's a forwardlooking suggestion."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential experiment (using larger resolution) but does not explicitly state how to conduct it or what action needs to be taken. While it implies an action (running the experiment), the lack of specific steps makes it less actionable. The reviewer suggests an improvement to the experiments section but doesn't provide the details to make it actionable.", "grounding_specificity_rationale": "The review point is general and does not specify which part of the paper or experiment it is addressing. It suggests an improvement to the experiments section as a whole but doesn't point to a specific issue or component within the current experiments. The reviewer doesn't identify a specific section, table, figure, or unique aspect of the paper being addressed.", "verifiability_rationale": "The review point suggests an experiment (using larger resolution) and asks a question about its impact. However, it does not provide any justification or reasoning for why this experiment is relevant or how the impact will be verified. The reviewer doesn't cite any external references or provide a logical argument for the suggestion. The claim is made without sufficient support.", "helpfulness_rationale": "The review point identifies a potential experiment (using larger resolution) and asks a relevant question about its impact on performance. This provides some value to the authors in terms of exploring potential improvements and understanding the limitations of the current experiments. However, it lacks the specifics to make the experiment actionable or verifiable. The suggestion is interesting and prompts further investigation, making it 3 in exploring avenues for improvement, even if it doesn't provide concrete steps."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the exact mathematical operation to perform on the feature map, making it 5.", "grounding_specificity_rationale": "The review point directly references a specific section and a concept within that section, fully grounding the comment. It also specifies the mathematical operation, making it specific.", "verifiability_rationale": "The review point is a question seeking clarification, not a declarative statement making a claim. Therefore, it has X and is not verifiable.", "helpfulness_rationale": "The review point is helpful in that it seeks clarification on a specific implementation detail. However, it doesn't identify a weakness or suggest an alternative approach, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the location of the issue ('Figure 2 right.') and provides concrete suggestions for improvement ('maybe make use of styles (e.g. dashed lines) or add color'). This indicates an explicit and concrete action to be taken.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 2 right', which is a specific part of the paper. This constitutes full grounding. The review also specifies the nature of the problem ('difficult to distinguish between the different curves') and provides concrete suggestions ('make use of styles... or add color'), making it fully specific.", "verifiability_rationale": "The review point contains a claim ('I found it difficult to distinguish between the different curves') and provides direct suggestions for improvement ('maybe make use of styles... or add color'). While the suggestions are not claims requiring external verification, the actionability and grounding specificity are what makes this potentially helpful. The claim is supported by the reasoning that better visualization would improve clarity.", "helpfulness_rationale": "The review point identifies a clear weakness ('difficult to distinguish between the different curves') and offers concrete, actionable suggestions ('maybe make use of styles... or add color'). While the suggestions could be more specific, they are directly tied to the identified problem and are intended to improve the figure. This makes it a '3' point."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review points out a clear mismatch between the stated goals (language learning) and the actual evaluation (question answering). While it doesn't explicitly say 'fix the intro,' it provides a concrete, actionable point for the authors to address the discrepancy between the language learning claim and the evaluation method.", "grounding_specificity_rationale": "The reviewer identifies the 'introduction' as the problematic area but doesn't specify a particular section, table, figure, or unique element within that area. This makes the grounding weak.", "verifiability_rationale": "The review states a discrepancy between the introduction's claims and the evaluation method. While this is a verifiable claim, the review point itself doesn't provide explicit evidence or justification for this discrepancy. The verifiability relies on the authors' ability to investigate further.", "helpfulness_rationale": "The review highlights a significant issue: the mismatch between the language learning claim and the questionanswering evaluation. This is a clear and actionable feedback that guides the authors to reevaluate their framing and evaluation process. While it doesn't offer a complete solution, it is highly relevant and actionable."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer raises a concern about the novelty and validity of a specific problem (ODE weight evolution inaccuracy) in the context of the paper's contribution. While the reviewer identifies a potential issue, they do not provide a clear action for the authors to take. They are questioning the problem itself rather than suggesting a solution. The reviewer's statement, 'The reviewer is not convinced about this problem,' indicates a lack of conviction rather than a direct instruction.", "grounding_specificity_rationale": "The reviewer mentions 'ODEs,' 'neural ODEs,' and 'weight evolution' but does not pinpoint a specific part of the paper or methodology where this problem is occurring. The reviewer's statement is general and does not provide a clear reference point for the authors. The lack of a specific section or table number makes the grounding weak.", "verifiability_rationale": "The reviewer states a claim, 'appears a previous paper first reported this issue. The reviewer is not convinced about this problem,' which could be considered verifiable as they are pointing out a potential discrepancy or lack of clarity. However, the reviewer does not provide any evidence or reasoning to support their conviction. The statement is presented as a question of belief rather than a wellsupported claim. The lack of external references or logical reasoning makes the verifiability low.", "helpfulness_rationale": "The reviewer raises a valid concern about the core methodology, specifically the modeling of weight evolution using ODEs. By questioning the accuracy of this approach, the reviewer highlights a potential weakness in the paper's foundation. This raises a helpful point for the authors to consider and potentially address. However, the reviewer's lack of conviction in their assessment reduces the overall helpfulness of the comment. The comment identifies a problem but doesn't offer a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "6: X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a potential improvement by mentioning the sampled policy. While it implies an action (improving clarity), it lacks specific details on how to implement this action. The suggestion is general and doesn't provide concrete steps for the authors to take. Therefore, it is 3 but lacks the necessary detail to be fully actionable.", "grounding_specificity_rationale": "The review point refers to 'these algorithms,' which are reasonably clear in the context of the discussion, but it doesn't explicitly identify a specific section, table, or figure. This requires the authors to infer the target. The suggestion to 'mention the sampled policy' is also vague and doesn't specify how or why. Therefore, the grounding is weak, and the specificity is underdefined.", "verifiability_rationale": "The review point itself does not contain a claim or assertion that needs verification. It's a suggestion for improvement. While the *implied* claim is that the current description might be lacking detail about the sampled policy, the review point doesn't explicitly state this as a claim that requires justification. Therefore, it has X.", "helpfulness_rationale": "The review point suggests a potential improvement by mentioning the sampled policy. This directly addresses a potential weakness in the current description of the algorithms. While the suggestion is relevant and aims to enhance the clarity and completeness of the draft, the lack of specific details about *how* to mention the sampled policy limits the immediate helpfulness. The authors would need to infer the implementation, making the improvement somewhat conditional."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point clearly states the weakness: 'Also, proving lower bounds for round complexity is the major chuck of work involved in proving results for batched ranking problems.' It then directly explains the reason for this weakness: 'However, this paper exploits an easy reduction from the problem of collaborative ranking, and hence, the lower bound results follow as an easy corrayory of these collaborative ranking results.' The term 'easy corrayory' (intended to mean 'easy corollary') explicitly indicates a straightforward deduction. The reviewer identifies a specific aspect of the paper's contribution (lower bound proofs for round complexity) and explains how it is lacking due to a simple methodological approach. This information is directly extractable and actionable for the authors.", "grounding_specificity_rationale": "The review point starts by referring to 'proving lower bounds for round complexity' as a 'major chuck of work involved in proving results for batched ranking problems.' While this is a specific area of contribution, the reviewer does not explicitly identify a specific part of the paper or method that is being criticized in relation to this. They are more broadly criticizing the overall approach of proving lower bounds. The reviewer does not mention a specific section, table, figure, or unique element of the paper that they are referring to. The criticism is about the *difficulty* of a general area rather than a specific flaw in a particular part of the paper. Therefore, it is 1 in a specific part of the paper.", "verifiability_rationale": "The review point contains a claim: 'this paper exploits an easy reduction from the problem of collaborative ranking, and hence, the lower bound results follow as an easy corrayory of these collaborative ranking results.' This is a statement of opinion and a deduction. The reviewer provides logical reasoning ('easy reduction', 'easy corrayory') to support this claim. While the reviewer does not provide external references, the logic is based on the understanding of reductions and corollaries within the field. The claim is supported by reasoning and common knowledge within the field of ranking problems. The reviewer's assessment of the method's simplicity and its direct connection to existing results makes the claim verifiable.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper's approach to proving lower bounds for round complexity. The reviewer points out that the paper relies on an 'easy reduction' and that the 'lower bound results follow as an easy corrayory of these collaborative ranking results.' While this critique highlights a potential limitation in the paper's methodology, it does not offer specific suggestions or guidance on how the authors should improve their work. The reviewer explains *why* their work might be limited but does not provide concrete steps or alternative approaches. The feedback is about the *difficulty* of a general aspect and the *potential* impact on the results, but it lacks direct actionable advice for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review states that the prompting technique is 'basic' and suggests 'carefully curated prompts' could be better. While the reviewer identifies a potential improvement, the specific action to take is not explicitly stated. The reviewer implies the current technique is lacking, but doesn't detail how to make it better. Therefore, the action is implicit and vague.", "grounding_specificity_rationale": "The review mentions 'prompting technique' generally and 'systematic reviews' specifically. It doesn't pinpoint *which* aspect of the prompting technique or the systematic review process is flawed. The reviewer is making a general comment about the limitations of the technique in the context of systematic reviews, but not specifically addressing a deficiency in a particular part of the prompt or the review process. Therefore, the grounding is weak as the specific area being criticized is not clearly defined.", "verifiability_rationale": "The review states that the prompting technique is 'basic' and suggests 'carefully curated prompts' could be better. This is a statement of opinion about the current technique's potential and a suggestion for improvement. There is no explicit claim being made that requires verification. The reviewer is not presenting a statement that can be logically reasoned, referenced, or supported by external evidence. Therefore, there is X to be verified.", "helpfulness_rationale": "The review offers a suggestion that 'carefully curated prompts' could be better than the current 'basic' technique. However, this suggestion is very general and lacks specific, actionable steps for the authors to take *now* to improve their draft. The reviewer doesn't provide concrete examples of how to implement 'careful curation' or what specific improvements could be made. The suggestion is broad and lacks the necessary detail to be truly helpful. Therefore, the review offers a suggestion but lacks the specific, actionable steps needed for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment implicitly suggests an improvement by mentioning 'Additional experiments on larger data sets' but doesn't explicitly state what needs to be done. The phrase 'but I understand that compute might be an issue' indicates a lack of concrete guidance on how to address this. While the intent is clear, the action is not directly stated, making it implicit.", "grounding_specificity_rationale": "The comment refers to 'larger data sets' generally, without specifying which part of the paper or experiment this relates to. The reviewer is not pointing to a specific section, table, or figure. The mention of 'probabilities' is vague and doesn't pinpoint a specific aspect of the method or results.", "verifiability_rationale": "The comment doesn't contain a claim that requires verification. It's a suggestion for improvement rather than a critique or assertion about the paper's content. There's no logical reasoning, common knowledge, or external references provided.", "helpfulness_rationale": "The review point offers a specific concern about 'maintaining the probabilities' with large batch sizes, which is a relevant issue for the authors. While it doesn't provide a solution, it identifies a potential area of concern and acknowledges the previous feedback. The reviewer also expresses a desire for more experiments, which is a valid suggestion, albeit vague. The overall intent is to provide feedback that, while not fully actionable, is relevant to the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the performance gap between the submitted model and GLaMM and UNINEXT. While it doesn't provide specific instructions on how to improve, it points to a clear area for improvement by highlighting the lower performance on REC and RES. The mention of specific metrics (cIoU and IoU>0.5) provides some guidance on where the issues might lie.", "grounding_specificity_rationale": "The review point explicitly refers to 'Table 4' and names specific models, GLaMM and UNINEXT, by name and citation. It also specifies the performance metrics (REC and RES) and provides concrete performance numbers from these models as examples. This clearly identifies the specific part of the paper and the relevant information being discussed.", "verifiability_rationale": "The review point contains a claim: 'Table 4: The performance on REC and RES are clearly behind more recent models.' This claim is supported by providing specific examples of more recent models, GLaMM and UNINEXT, and citing their performance on the same metrics in RefCOCO and RefCOCOg datasets. The reasoning is logical, and the references are external works.", "helpfulness_rationale": "The review point identifies a clear weakness in the submitted work by pointing out the performance gap on REC and RES compared to more recent models. This is a valuable piece of feedback as it highlights an area where the authors could improve their model's performance. However, it does not offer specific, actionable steps on how to address this weakness."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer identifies a potential issue ('shows evidence that some information is learned before the model is able to use the concepts'). This identifies an explicit action: 'improve the model's ability to use concepts after learning them'. However, the reviewer does not specify *how* this improvement should be made or *what* specific changes are needed. The action is implied but not explicitly stated with concrete details.", "grounding_specificity_rationale": "The reviewer refers to 'some information' and 'the model' generally, without pinpointing a specific part of the paper or concept. There is no explicit mention of a section, table, figure, or unique element. The reference is vague and does not clearly identify the issue. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim ('shows evidence...'), but does not provide any specific evidence, references, or logical reasoning to support this claim. The statement is presented as a possibility ('I think') rather than a verifiable observation. Therefore, the claim is not supported by verifiable evidence.", "helpfulness_rationale": "The reviewer points out a potential issue in the model's development. While this highlights a weakness, it does not offer concrete, actionable feedback or suggestions that would directly improve the authors' draft. The comment is about the model's capabilities, not directly about improving the authors' work. Therefore, the feedback is not directly helpful for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the similarity to ConsiStory's approach ('mirrors the approach used in ConsiStory') and highlights the difference in the mask source ('utilizing CLIPseg and OTSU segmentation rather than crossattention'). This provides a clear action for the authors to take: acknowledge the similarity and emphasize their contribution in the mask source.", "grounding_specificity_rationale": "While the reviewer doesn't explicitly state which part of the paper they are referring to, the context implies they are discussing the 'video storyboarding' method. The reviewer then specifies what is being compared ('framewise SDSA') and what the difference is ('the mask source'), and mentions specific techniques used in the difference ('CLIPseg and OTSU segmentation') and the technique the original method uses ('crossattention'). This provides a degree of specificity about the aspect being discussed.", "verifiability_rationale": "The reviewer makes a claim ('The innovation of the proposed video storyboarding approach is limited') and provides a reason ('The primary method relies on framewise SDSA, which largely mirrors the approach used in ConsiStory'). This claim can be verified by comparing the proposed method to ConsiStory. While the reviewer doesn't provide external references, the comparison to an existing method provides a basis for evaluation.", "helpfulness_rationale": "The reviewer's point directly challenges the perceived novelty of the work by pointing out the similarity to ConsiStory. This is a valuable piece of feedback for the authors, as it helps them contextualize their contribution within existing research. While it might not be the most constructive critique (as it doesn't offer a direct solution), it is still helpful in guiding the authors to reevaluate their claims."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review points out a *potential* weakness and suggests a *specific* way to test it. This suggests it *could* be actionable if clarified. While the action is somewhat vague, the potential for action exists.", "grounding_specificity_rationale": "The review clearly refers to \"this method\" and \"fewshot classification,\" indicating a strong grounding in the specific area being discussed. It also suggests comparing against previous methods on a *specific* dataset, which further grounds the comment and specifies the area of investigation.", "verifiability_rationale": "The review makes a claim about the potential prominence of the weakness in certain scenarios and suggests a concrete experiment (comparing against previous methods on a specific dataset) to verify this claim. This provides a clear method for investigation, making the claim verifiable.", "helpfulness_rationale": "The review identifies a potential weakness and offers a concrete suggestion for investigation, which is valuable feedback for the authors. While the exact *how* of the experiment isn't specified, the *what* and *why* are clear, making the feedback actionable and specific, thus 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'I think the paper could greatly benefit from more explanation of the meaning of the bounds (perhaps in the appendix).' This clearly indicates that the authors should provide more details about the bounds. The action is directly stated, making it 5.", "grounding_specificity_rationale": "The review point refers to 'the bounds' generally, without specifying a particular section, table, figure, or unique aspect of the paper. While the reviewer implies it's related to the 'space limitations' mentioned in the introduction (assuming the context), they don't pinpoint the exact location or specific element within it. Therefore, the grounding is weak, although the specific aspect (explaining bounds) is clear.", "verifiability_rationale": "The review point contains a claim: 'I think the paper could greatly benefit from more explanation of the meaning of the bounds.' This is a statement of opinion. However, the reviewer does not provide any supporting evidence or justification for this claim. There is no logical reasoning, common knowledge, or external references provided to back up their assertion. Therefore, the claim is 1.", "helpfulness_rationale": "The review point identifies a potential area for improvement in the paper \u2013 providing more explanation of the bounds. While the specific bound is not mentioned, the reviewer clearly states that more explanation is needed. This provides some actionable feedback for the authors. The suggestion to put this explanation in the appendix is also a general recommendation for improvement. Therefore, the review point is helpful, even if it lacks precise details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the implementation framework (OpenAI's Triton) and the alternative (CUDA), providing a clear action for the authors to adopt the correct framework. It also implicitly suggests a change in presentation style by recommending conciseness. The reviewer identifies a specific technical detail and proposes a concrete change.", "grounding_specificity_rationale": "The comment implicitly refers to the implementation details of the kernels, which is a specific part of the paper. While not explicitly stating a section or table number, the context clearly points to the implementation aspect. The reviewer also implies they are referring to the implementation details by mentioning 'OpenAI's Triton' and 'CUDA'.", "verifiability_rationale": "The comment makes a claim about the implementation framework and provides a justification for conciseness based on 'wellknown engineering improvements'. While not a direct citation, this provides a logical reason for the suggestion. The reviewer identifies a factual error and offers a clear rationale for a specific presentation choice.", "helpfulness_rationale": "The review point directly identifies a factual error regarding the implementation framework and provides a clear suggestion for improvement by recommending conciseness. The justification for conciseness, based on 'wellknown engineering improvements', adds value to the feedback. This information is directly actionable and will help the authors improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer criticizes the zeroshot claim but does not propose an action or suggest how to improve it. They are pointing out a limitation or a potential issue with the zeroshot approach, but they do not offer a concrete solution or modification. The criticism itself is a statement of a problem, but it lacks a proposed action or remedy.", "grounding_specificity_rationale": "The reviewer provides specific examples of tasks (walkerrun, walkerwalk, 3prong, 4prong) and mentions the source and target tasks. They are pointing out limitations related to the difficulty of the source task and the sufficiency of the experimental setup. While they don't explicitly state which section or table these tasks belong to, they clearly identify the concepts being discussed. The grounding is present, but it could be more explicit about the location within the paper.", "verifiability_rationale": "The reviewer makes claims about the difficulty of the source and target tasks and the sufficiency of the experimental setup. While they don't provide direct evidence *within this review point* to support these claims, the reasoning is logical and based on common knowledge about task complexity. They argue that the difficulty gap between the tasks makes the zeroshot transferability questionable and that the experimental setup might provide sufficient information. The claims are supported by logical reasoning, but lack specific citations within this point.", "helpfulness_rationale": "The reviewer provides a clear and actionable critique of the zeroshot claim. They explain why the difficulty gap between the source and target tasks makes the transferability questionable and suggest that the experimental setup might already provide sufficient information. This critique directly challenges a key assumption and provides a reason for the authors to reconsider their approach. It offers a specific alternative or at least a more nuanced perspective."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "Weakly Verifiable", "helpfulness_label": "Not Very Helpful", "actionability_rationale": "The reviewer suggests trying larger backbones as a potential improvement. While this is a direction for future work, it doesn't explicitly state what specific changes need to be made to the current draft or how to evaluate the performance on larger backbones. The suggestion is more of a general direction than a concrete action to be taken on the existing work.", "grounding_specificity_rationale": "The reviewer mentions 'the paper' generally but then focuses on 'the small backbone ResNet50' when discussing the relative gains. While the context is specific, the initial part of the review doesn't pinpoint a particular section, table, figure, or unique aspect of the paper being addressed. The grounding is present but could be more explicit.", "verifiability_rationale": "The reviewer claims that the gains are 'not very strong' and speculates that the global pooling might be the reason. This is a claim that could potentially be supported by further analysis or experiments. However, the review point itself doesn't provide specific examples of where the current draft falls short or suggest concrete ways to address these issues. The claim is present, but the supporting evidence is missing within the review point itself.", "helpfulness_rationale": "The reviewer provides a potential direction for future research (trying larger backbones) but doesn't directly address the weaknesses or shortcomings of the current draft. While the suggestion is relevant, it doesn't offer specific, actionable feedback on how to improve the existing work. The review point is more about future work than directly helping with the current submission."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The statement explicitly states that the extension from linear models to wide fullyconnected neural networks is 'trivial' and that the work only considers 'easy wide fullyconnected neural networks'. This directly implies a lack of significant contribution in this area, making the action implicit but clear.", "grounding_specificity_rationale": "The comment mentions 'wide fullyconnected neural networks' and 'Section 3.2, 3.3', indicating a general reference to a specific area. However, it doesn't pinpoint a specific part of a section, table, figure, or unique element within those sections that needs addressing. The reviewer is making a general comment about the type of neural networks considered, rather than a specific critique of a particular element.", "verifiability_rationale": "The comment contains a claim: 'With the existing NTK theorem, the extension from linear models to wide fullyconnected neural networks is trivial' and 'The work bypasses the core problem of overparametrized neural networks and only considers the easy wide fullyconnected neural networks'. These claims are supported by logical reasoning ('with the existing NTK theorem') and by stating the consequences ('is trivial...only considers the easy...').", "helpfulness_rationale": "The review point is highly critical, stating that the analysis of neural networks contributes 'less' and explicitly points out the limitations regarding the triviality of the extension and the focus on 'easy' networks. This directly informs the authors on what aspects of their neural network analysis are lacking and how to improve them."}
{"actionability_label": "N/A", "grounding_specificity_label": "N/A", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly address the aspects of actionability, such as whether it suggests concrete steps for improvement or leaves the authors to infer them. There is no mention of specific actions or recommendations related to the paper's content or structure.", "grounding_specificity_rationale": "The review point does not discuss the specific part of the paper or task being addressed. It focuses on the *number* of datasets used for evaluation, not on the details of the experimental setup or the tasks themselves.", "verifiability_rationale": "The review point contains a claim (the concern about the number and size of datasets) and provides some justification (the authors' reply clarifies the situation). However, the verifiability of this claim is somewhat borderline as the justification is presented as a clarification rather than a strong argument or evidence.", "helpfulness_rationale": "The review point is 3 as it raises a valid concern about the rigor of the evaluation due to the number and potential size limitations of the datasets. It encourages the authors to consider a more comprehensive evaluation strategy. However, the mention of the authors' detailed reply and their commitment to a repository are not helpful at this stage as they are responses and future actions, not feedback on the current review point itself."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the absence of results for larger models, which is a clear indication of a weakness. However, it does not directly instruct the authors on what to do about this weakness.", "grounding_specificity_rationale": "The comment mentions 'imageNet classification with ResNet50/34/18' and then introduces 'larger models like ResNet101/152'. While it implicitly relates the two, it doesn't explicitly identify a specific part of the paper being addressed in relation to this gap in results. The grounding is weak because the authors can only infer the relevance of the missing results.", "verifiability_rationale": "The comment states a fact: 'there are no results with larger models like ResNet101/152.' This is a declarative statement and does not present a claim that requires verification or justification.", "helpfulness_rationale": "The comment identifies a missing and potentially important piece of information (results for larger models) for the imageNet classification task. This can be helpful for the authors as it highlights a gap in their current evaluation and suggests a direction for further experimentation or analysis."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential confusion regarding the terms 'relatively inexpensive' and 'expensive to evaluate'. While the reviewer doesn't explicitly state an action, they imply a need for clarification. This could involve explaining the context in which these terms are used, providing examples of what constitutes 'inexpensive' or 'expensive', or defining the criteria used to make such assessments. The lack of explicit action makes it less actionable compared to a direct suggestion on how to improve something.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017)' and highlights a potential point of confusion in the abstract and introduction regarding the terms 'relatively inexpensive' and 'expensive to evaluate'. This demonstrates a clear identification of a specific paper and a specific area within the paper where clarification is needed. Therefore, the grounding is strong. However, the reviewer doesn't specify *what* needs to be improved regarding the terminology, making it somewhat underspecific.", "verifiability_rationale": "The reviewer makes a claim: 'somewhat confusing to read \"relatively inexpensive\" in the abstract and then \"expensive to evaluate\" in the first line of the introduction!'. This claim is verifiable as the reviewer identifies a potential inconsistency in terminology. The reasoning is clear: the terms seem contradictory. However, the reviewer doesn't provide external references or examples to support this claim, making it somewhat underjustified.", "helpfulness_rationale": "The reviewer's point about the potential confusion in terminology is directly relevant to the reader's experience. It highlights a practical issue that a reader might encounter when trying to understand the paper. By pointing out this inconsistency, the reviewer provides a suggestion for improvement, which is to clarify the terms. Therefore, the review offers a clear direction for the authors to take, making it helpful."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states \"How does this method address sparse reward problems in a better way?\" which is a question, not an action. While they imply the proposed method *should* address the issue better, they don't provide specific instructions on how to do it. The minor comment about subtask rewards is also a statement of opinion, not an actionable suggestion. The Qmix point is a suggestion, but it's a *general* suggestion, not specific to the current paper being reviewed.", "grounding_specificity_rationale": "The reviewer refers to \"this method\" without explicitly naming the paper or the specific section describing the reward mechanism. The reference to 'sparse reward problems\" is general. The claim about 'subtaskspecific rewards\" is a possible interpretation but not directly linked to the reviewed paper. The Qmix suggestion is general.", "verifiability_rationale": "The reviewer states \"From the experiments, this does not support well.\" This is a claim. However, they *don't* provide any specific evidence or reasoning to *prove* that the method doesn't support well. They offer a potential alternative (Qmix) but don't explain *why* they think Qmix would or wouldn't work in this context. The minor comment is speculative.", "helpfulness_rationale": "The reviewer's point is about the *effectiveness* of a method in addressing sparse reward problems. While relevant to the general topic of reinforcement learning, it doesn't directly *guide* the authors on how to improve *their specific method*. The suggestion of subtask rewards is a general idea, not a specific improvement for their work. The Qmix suggestion is also too general. The lack of specific evidence makes it difficult for the authors to act on this feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point directly addresses the use of the AH36M dataset and its potential role in training. While it doesn't explicitly state whether it's used for training, it implies this through the context of a draft and the comparison with other methods. The reviewer asks for clarification, suggesting an implicit action: to investigate the training process and ensure fair comparisons. However, the action of identifying the missing information is not explicitly stated, making it somewhat implicit.", "grounding_specificity_rationale": "The review point explicitly mentions the 'AH36M dataset' and the potential issue of its usage in training. It directly refers to a specific part of the paper (the dataset) and what might be missing from it (its use in training). This demonstrates strong grounding specificity as the reviewer can precisely identify the referenced part and clearly identify the issue with it.", "verifiability_rationale": "The review point poses questions about the AH36M dataset's usage in training. These are factual questions that could be answered by referring to the authors' methodology or by conducting a quick search. The questions are based on established practices (training data) and a specific dataset, making them verifiable. While no external references are provided, the questions themselves are logically sound and directly related to the topic.", "helpfulness_rationale": "The review point raises important questions about the methodology and potential unfairness in comparisons. It encourages the authors to clarify a key aspect of their work (dataset usage) and ensures transparency. This information is valuable for the authors to improve their draft and address potential concerns about the validity of their comparisons. While it doesn't directly tell the authors what to do, it prompts them to be more explicit about their methodology, which is a crucial step in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer states 'there are some confusing mistake in the proof of the main results' without specifying which part of the proof or what the mistake is. They also say 'this paper lacks a detailed discussion and comparison with the previous work' and 'this paper seemed not to give any new insight on this field' without pointing to specific areas needing improvement. While the reviewer identifies problems, they lack the specificity needed for the authors to know exactly what to do or what information is missing.", "grounding_specificity_rationale": "The reviewer mentions 'the proof of the main results,' 'discussion,' and 'new insight' generally, but doesn't pinpoint the exact location within the paper (e.g., a specific theorem, lemma, or section). This lack of specificity makes it difficult for the authors to understand where the issues lie. Furthermore, the reviewer doesn't specify what is missing in the discussion or what new insight is lacking, making it unclear what needs to be added or improved.", "verifiability_rationale": "The reviewer makes several claims: 'there are some confusing mistakes,' 'the paper lacks a detailed discussion,' and 'the paper seemed not to give any new insight.' These are statements of opinion or judgment. However, the reviewer does not provide any specific examples, references, or logical reasoning to support these claims. The language used is speculative, and there is no evidence presented to back up the assertions.", "helpfulness_rationale": "The review point provides a general critique of the paper, mentioning issues with the proof, the lack of discussion, and the lack of new insights. However, it does not offer specific suggestions or actionable steps for the authors to take. The feedback is broad and lacks the necessary detail to be truly helpful. The reviewer points out problems but doesn't guide the authors on how to address them."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states the motivation is unclear and that the comparison is unfair due to a larger model and pretrained model. However, the reviewer does not explicitly state what specific aspects of the motivation are unclear or what concrete actions the authors should take to address these issues. The reviewer provides a general statement without offering specific, actionable steps. Therefore, the comment lacks explicit and actionable feedback.", "grounding_specificity_rationale": "The reviewer mentions 'adversarial network' and 'model' in the context of unclear motivation and unfair comparison. However, the reviewer does not explicitly identify the specific section, table, figure, or unique aspect of the paper being addressed. The reviewer refers to general concepts without pinpointing the exact location or detail in the paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer states that the motivation is unclear and that the comparison is unfair. However, the reviewer does not provide any evidence or reasoning to support these claims. The reviewer simply states the problems without explaining why they are problems or how they impact the paper. Therefore, the claims are not wellsupported by logical reasoning, common knowledge, or external references, making them 1.", "helpfulness_rationale": "The reviewer's comments are criticized as unclear and unfair. However, the reviewer does not provide specific suggestions or ask for clarification. The reviewer points out problems but does not offer concrete solutions or explain how these problems should be addressed. Therefore, the review point is not helpful for the authors in improving their draft as there are no actionable feedback provided."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desired outcome (comparison to the official COOC leaderboard) and contrasts it with the actual outcome (comparison to dev/test sets). This constitutes an implicit action: to highlight a deficiency in the current evaluation approach and suggest a more rigorous alternative. While not stated directly, the reviewer implies the action of comparing against the official leaderboard.", "grounding_specificity_rationale": "The reviewer mentions the 'official COOC leaderboard' and the 'blind test set' as specific elements of the evaluation framework. While the paper could have explicitly stated 'The results should be compared on the official COOC leaderboard using the blind test set,' the reviewer's phrasing implies a specific reference point. The 'grounding' is present, but it's not absolute certainty.", "verifiability_rationale": "The reviewer provides a link to the COOC leaderboard and mentions that 5,17 have won the challenge and been evaluated on the blind test set. This provides some level of verifiability by referencing a specific resource and demonstrating the significance of the blind test set. However, the paper could have provided more explicit references or explanations to support the claim.", "helpfulness_rationale": "The reviewer's comment directly targets improving the paper by highlighting a specific limitation in the evaluation methodology and suggesting a more comprehensive approach. The suggestion to compare against the official leaderboard is a concrete and actionable step that would likely enhance the paper's findings. This clearly benefits the authors by providing a more robust evaluation framework."}
{"actionability_label": "3. 3", "grounding_specificity_label": "5. 5", "verifiability_label": "1. 1", "helpfulness_label": "2. 2", "actionability_rationale": "The comment explicitly states an action or suggestion: \"the experimental results are unreliable, especially in Table 1, where the MSE is significantly smaller than the MAE, which raises concerns about their validity.\" While it doesn't explicitly state the next step, it clearly indicates a problem that needs addressing.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 1\" and specifies the metrics \"MSE\" and \"MAE\". This clearly identifies the specific part of the paper being addressed.", "verifiability_rationale": "The comment contains a claim: \"the experimental results are unreliable, especially in Table 1, where the MSE is significantly smaller than the MAE, which raises concerns about their validity.\" However, it does not provide any justification or evidence to support this claim. It simply states the observation without logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The comment identifies a weakness in the experimental results but does not provide any specific suggestions or actionable steps for the authors to take to address this issue. It points out the problem but doesn't offer a path forward."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment identifies the lack of novelty in the methodology but does not specify any concrete actions or improvements the authors should implement. It's a valid observation but lacks actionable steps.", "grounding_specificity_rationale": "The comment is general and does not specify which part of the paper or methodology is lacking novelty. It applies to the entire methodology.", "verifiability_rationale": "The comment is a statement of opinion about the lack of novelty, not a claim that requires verification or evidence. It's descriptive, not assertive with supporting facts.", "helpfulness_rationale": "The comment identifies a valid weakness in the methodology but does not provide specific, actionable suggestions for improvement. It's a constructive observation but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment states a fact about the loss function but does not provide any actionable steps or guidance on how to implement or apply it to the paper. It describes a training detail, not a general improvement to the draft.", "grounding_specificity_rationale": "The comment is a general statement about adversarial loss and data perturbation, without specifying which part of the paper or issue it addresses. It lacks grounding as it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The comment is a factual statement about the loss function and its goal. It does not contain a claim that requires verification or justification.", "helpfulness_rationale": "The comment is about a training detail and doesn't directly address any issues or areas for improvement in the submitted paper. It's more relevant to the training process than to the paper's content."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "X (X)", "actionability_rationale": "The reviewer explicitly states 'improve clarity' as a suggestion, making it at least 3. However, the suggestion lacks specific details on how to achieve this goal. The reviewer points to the lack of 'nuance' at L255 as the issue, implying the need for more specific guidance, but doesn't offer concrete steps for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'the nuance of this position at L255,' indicating they are addressing a specific part of the paper. However, they do not explicitly state the exact line number or section they are addressing. They are pointing to the *content* of that line. The reviewer's criticism is specific to the explanation at L248.", "verifiability_rationale": "The reviewer makes a judgment about the quality of the explanation at L248 ('the paper gets into some of the nuance of this position at L255, but it would be helpful to clarify what is meant by a good/bad/wrong explanation before using those concepts'). However, the reviewer does not provide any external references or logical reasoning to justify why the explanation is 'wrong.' They offer a definition of 'wrong' but do not explain why the explanation at L248 falls into that category.", "helpfulness_rationale": "The review point is a suggestion for improvement ('improve clarity') and does not contain a direct claim or assertion. It's an actionable suggestion, but without a specific basis for improvement, it doesn't fit the criteria for a claim."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The reviewer states that the proposed method is 'not consistently better' than other methods. While this suggests a direction for improvement, it lacks specific guidance on *how* the comparison should be expanded or *why* the proposed method is failing in the inferior cases. The reviewer does not explicitly state the actions the authors should take to address this issue. Therefore, the reviewer's point is implicit and lacks concrete action.", "grounding_specificity_rationale": "The reviewer mentions 'few methods' but does not specify which part of the comparison is lacking. They also state that the results 'violate the motivation' but do not identify the specific aspect of the motivation that is not met. The reviewer's criticism is general and does not pinpoint the exact location of the problem. While the reviewer *knows* there's an issue, they don't clearly identify *where* the problem lies within the paper or the comparison.", "verifiability_rationale": "The reviewer states that the results 'violate the motivation.' This is a claim that needs to be supported by evidence or logical reasoning. The reviewer does not provide any specific examples or justifications for why the results are inconsistent with the stated motivation. Therefore, the claim is not supported by logical reasoning, common knowledge, or external references, making it 1.", "helpfulness_rationale": "The reviewer explicitly states that the review point is '1' because the results are inconsistent and violate the motivation. This directly indicates a lack of value for the authors in the provided feedback. The authors are left without clear guidance on how to improve their method given the seemingly contradictory results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of sufficient experimental demonstration and highlights the missing comparison with Mid Vision Feedback (MVF). It suggests including the image classification result of MVF to support the claim about the superiority of the schema searched by ELF. This is an explicit and concrete action that the authors can readily implement to improve their draft.", "grounding_specificity_rationale": "The review point explicitly mentions 'Mid Vision Feedback (MVF)' and explains why its inclusion is necessary to validate the contribution points. The authors can clearly identify the specific part of the paper (experimental setup or results) where this comparison should be made. This demonstrates strong grounding specificity as the reviewer provides a clear reference point within the paper.", "verifiability_rationale": "The review point makes a claim about the *absence* of sufficient experimental demonstration and a *specific* missing comparison (MVF). However, it does not provide any logical reasoning, examples, or external references to support this claim. The verifiability of this statement depends on the authors' ability to prove their point, not the reviewer's assertion of its absence. Therefore, without evidence to support the claim itself, it is 1.", "helpfulness_rationale": "The review point directly identifies a significant weakness in the experimental validation of the paper. It provides a clear direction for improvement by suggesting a crucial comparison. This actionable feedback is highly relevant and directly addresses a key area for enhancement, making it 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states that the authors have not covered more on the types of activities captured in the datasets and their importance in smart homes. This directly points to a specific area where the authors should make improvements. The reviewer is suggesting that this information is relevant to the paper's goals, particularly regarding occupant comfort and energy efficiency. The comment is clear about the nature of the missing information and the need for its inclusion.", "grounding_specificity_rationale": "The comment refers to 'datasets' and 'smart homes' generally. While it identifies a relevant area for discussion, it doesn't explicitly pinpoint a specific section, table, figure, or unique aspect of the paper where this information should be added. The authors would need to infer the appropriate location based on the paper's structure and content. The comment is general about the types of activities and their importance, lacking specific details about which activities or how they relate to comfort and energy efficiency.", "verifiability_rationale": "The comment contains a claim that the authors have not covered more on the types of activities and their importance in smart homes. The reviewer provides a logical reasoning for this claim, suggesting that this information is crucial for occupant comfort and energy efficiency. However, the claim lacks specific examples or references to external works to support the assertion that this information is indeed missing and important. The reasoning is present but lacks concrete evidence.", "helpfulness_rationale": "The comment identifies a clear gap in the authors' discussion by pointing out the absence of a detailed explanation of the types of activities captured in the datasets and their significance for occupant comfort and energy efficiency. This is a relevant and actionable suggestion for the authors. By highlighting this gap, the reviewer guides the authors to expand their discussion and provide a more comprehensive analysis of their dataset in the context of smart home applications. This feedback is directly helpful in improving the paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states the problem (D used for two different things) and suggests a solution (use different notation). This is a clear and direct action. The reviewer is pointing out a specific issue and offering a concrete fix.", "grounding_specificity_rationale": "The reviewer refers to the symbol 'D'. While they don't explicitly say 'D is in Section X', the context implies it's related to the summary. The grounding is *weak* because the reviewer has to infer that 'D' relates to the summary. However, the comment is *specific* about the *meaning* of 'D' \u2013 it's suggesting it's being used for two different things. This specificity is high *within* the context of the summary.", "verifiability_rationale": "The review point is making a judgment: 'D is used to represent both dimensionality of points and dilation factor. Better to use different notation to avoid confusion.' This is a statement of opinion and a suggestion. While it doesn't *necessarily* *need* verification (it's a suggestion for clarity), it's a *recommendation*. The lack of external references is clear. The lack of logical reasoning is also clear \u2013 it's a suggestion, not a claim requiring proof.", "helpfulness_rationale": "The review point is relevant and suggests a concrete change to improve clarity. While it might not be *critical* confusion, it's still a valid point. The reviewer is pointing out a potential source of ambiguity and suggesting a specific solution. This is generally helpful for the author's understanding and potentially the paper's presentation. It's not a completely useless comment, but it's not a groundbreaking insight either."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their understanding of 'state' as 'agent position' and asks a direct question about the meaning of 'elements' in relation to this understanding. This is an explicit action, and the reviewer provides a concrete example to support their interpretation. The action is clear and directly addresses a potential point of confusion.", "grounding_specificity_rationale": "The reviewer directly refers to lines 186187 of the paper, indicating a specific part of the text they are concerned about. They also ask a question about the relationship between 'elements' and their understanding of 'state,' further specifying the area of confusion. This shows a clear identification of the specific aspect of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim that 'elements' are equivalent to their understanding of 'state' (agent position). While the paper describes 'elements' as the 'input to the environment,' it doesn't explicitly state that these are the same as the agent's 'position.' The reviewer is prompting for clarification, suggesting the connection isn't immediately obvious or explicitly stated in a verifiable way.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential point of confusion regarding the definition of 'state' and 'elements' in the context of the reinforcement learning framework. By asking for clarification, they are actively seeking to improve their understanding of the method. While the paper describes 'elements,' the reviewer's point highlights a potential lack of clarity or explicit connection to their interpretation of 'state'."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point is a question about comparing support, not a directive to the author. It doesn't explicitly state what needs to be done or how to achieve it. The reviewer asks 'how' to compare, implying a need for further clarification, but doesn't provide a concrete action. Therefore, it lacks explicitness and concreteness required for actionability.", "grounding_specificity_rationale": "The review point is about comparing support in general, not a specific part of the paper. It doesn't identify a unique section, table, figure, or aspect where this comparison is being made. The grounding is implicit and broad, lacking specificity to a particular element of the paper. Therefore, it doesn't identify a specific part, making it 1.", "verifiability_rationale": "The review point is a question, not a declarative statement that makes a claim. It doesn't assert anything about the paper or propose a solution that can be verified. Verifiability requires a claim that can be supported by evidence. Since there's X, there's nothing to verify. Therefore, it doesn't contain a claim that can be evaluated for verifiability.", "helpfulness_rationale": "The review point is a question about comparing support, which is a valid area for improvement. However, it doesn't provide specific, actionable feedback or suggestions to the author. It asks a question but doesn't directly guide the author on how to implement the comparison or why it's important. The helpfulness is limited to raising awareness of the concept of support, but it doesn't offer concrete steps or insights. Therefore, it's not 5 as it doesn't directly address the author's needs for improvement in a specific way."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific experimental observation (generator collapse with RGCN discriminator vs. the proposed module) and explicitly states a missing explanation (the mechanism behind the proposed module's stability). While the reviewer doesn't explicitly state an action or a concrete step, the request to 'see why the proposed module can prevent a generator from collapsing' implies a desire for a specific type of action (explanation of the mechanism).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Sec 5.3' and compares 'a generator equipped with a standard RGCN as discriminator' with 'the proposed module.' This clearly identifies the specific part of the paper and the elements being discussed, making the grounding explicit. However, the reviewer does not specify *what* is wrong with the RGCN discriminator or *how* the proposed module prevents collapse, making the specificity somewhat lacking.", "verifiability_rationale": "The reviewer presents a factual observation ('a generator equipped with a standard RGCN as discriminator tends to collapse...') and a request for an explanation ('I would like to see why the proposed module can prevent a generator from collapsing'). The observation itself could potentially be verified through analysis or experimentation, making it partially verifiable. However, the request for explanation is not a claim that can be verified, making the overall verifiability somewhat ambiguous.", "helpfulness_rationale": "The reviewer identifies a specific experimental observation and explicitly requests an explanation for a discrepancy. This directly points to a potential weakness in the submission (lack of explanation for the stability). The request is clear and directly addresses a relevant aspect of the proposed method. While it's a request, it's a specific and relevant request for improving the understanding of a key mechanism."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue (resemblance) but doesn't provide a clear action for the authors to take. It asks a question about novelty, which is a valid concern, but doesn't specify what needs to be changed or how to address it. The suggestion is vague. Is the extension 'trivial'? 'Significant'? The degree of novelty is unclear.", "grounding_specificity_rationale": "The review refers to the 'article's reasoning and writing logic' generally, without pinpointing a specific section, figure, or table. The reviewer asks a question about novelty, which is a valid concern, but doesn't pinpoint a specific problematic element within the reasoning or writing logic. The grounding is weak because it's hard to know exactly where the similarity is impacting the work.", "verifiability_rationale": "The review points out a similarity and asks a question about novelty. These are more like observations or questions than explicit claims that need verification. There is no clear claim, so it falls into the 'X' category (X).", "helpfulness_rationale": "The review raises a valid concern about the potential lack of novelty. However, it doesn't offer a concrete solution or actionable steps for the authors to address this concern. It's more of a question and observation. While it identifies a potential issue, it lacks the actionable elements needed for significant improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment identifies a potential area for improvement (unclear theoretical comparisons) but does not explicitly state what aspect of the comparison is unclear or how the authors should go about clarifying it. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The comment mentions 'adaptive learning of GPRGNN' which provides some grounding by naming a specific area. However, it does not specify which part of the GPRGNN method or the comparison process is unclear. The specificity of the referenced part is weak.", "verifiability_rationale": "The comment does not contain a claim that can be verified. It's a statement of uncertainty or lack of clarity, not a critique supported by evidence or reasoning.", "helpfulness_rationale": "The comment points out a potential issue (unclear theoretical comparisons) but does not offer any specific advice or guidance on how to address it. It lacks concrete suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their suggestion: 'Consider using a more nuanced evaluation method, such as a Likert scale or a detailed annotation scheme.' This clearly indicates an action the authors should take.", "grounding_specificity_rationale": "The reviewer's suggestion to use a Likert scale or a detailed annotation scheme is grounded in the limitations of yes/no responses. They explicitly state that yes responses 'may not indicate that the model comprehends the presence of the object in the image.' This shows an attempt to identify the specific issue and propose a solution. However, the suggestion itself is somewhat general, not pinpointing a specific part of the paper or a unique element.", "verifiability_rationale": "The reviewer makes a claim: 'Yes response does not necessarily indicate that the model comprehends the presence of the object in the image, as it may still produce incorrect objects when undertaking other tasks.' This claim is supported by logical reasoning \u2013 the binary nature of yes/no responses doesn't capture the nuances of object comprehension or potential errors in other tasks. While it lacks specific examples, the reasoning is clear and based on common understanding of evaluation metrics.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'Consider using a more nuanced evaluation method, such as a Likert scale or a detailed annotation scheme.' This directly addresses a potential limitation of the current evaluation method and offers a concrete alternative. While the suggestions are general, they are likely to be helpful for researchers working on object hallucination."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states actions to be taken, such as 'conducing experiments on more datasets' and 'training the baseline models with the 'correct' forecast horizon.' These actions are further detailed, making the comment 5.", "grounding_specificity_rationale": "The review point directly refers to 'the verylongterm forecasting task,' providing a clear and specific reference point within the paper. It also offers concrete suggestions for improvement related to this specific task.", "verifiability_rationale": "The review point contains a claim about the 'limited practical significance' of the verylongterm forecasting task. While the suggestions for improvement ('conducing experiments on more datasets' and 'training the baseline models with the 'correct' forecast horizon') are verifiable through experimentation, the initial claim lacks supporting evidence or external references, making it 3.", "helpfulness_rationale": "The review point is 4 as it provides clear and actionable suggestions for improving the evaluation of the verylongterm forecasting task. While it begins with a subjective observation about the task's significance, it offers concrete directions for further experimentation and analysis, empowering the authors to consider these improvements."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the missing components as 'experiments and explanation regarding the different queries used in spatiotemporal representation' and suggests exploring 'what if only have spatial one, or temporal and summary one?'. This indicates a clear and actionable request for the authors to include more detailed experimental analysis and explore different configurations of their queries. The reviewer provides a clear direction for improvement by specifying the type of experiments needed and the variations to consider.", "grounding_specificity_rationale": "The reviewer mentions 'experiments' and 'different queries' but doesn't specify a particular section, table, or unique element of the paper where these experiments are located. While the reviewer identifies the *type* of queries (spatial, temporal, summary), the overall *area* of the experiments is not precisely grounded. The grounding is present at a general level, but the specificity of the grounded element is limited.", "verifiability_rationale": "The reviewer makes a claim that 'experiments and explanation regarding the different queries used in spatiotemporal representation, i.e., spatial, temporal and summary' are missing. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a suggestion for improvement rather than a verified assertion. Therefore, the claim is not fully supported by evidence.", "helpfulness_rationale": "The reviewer identifies a clear gap in the experimental evaluation by pointing out the absence of experiments and explanation regarding different query types. They also suggest exploring variations of these queries, which is a valuable direction for the authors to consider. While the reviewer doesn't provide concrete evidence of the missing experiments, their suggestion is actionable and addresses a specific aspect of the model's design. The reviewer's point is helpful in guiding the authors to further investigate and potentially improve their model's spatiotemporal representation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the proposed FRM is a 'simple combination' of channel attention and spatial attention and lacks 'indepth innovative detail'. This is an explicit statement about the method's composition and a request for more specific information about its innovation. While the reviewer identifies a potential area for improvement, the lack of detail makes it difficult to pinpoint exactly what is meant by 'simple combination' or 'indepth innovative detail'.", "grounding_specificity_rationale": "The reviewer mentions 'channel attention' and 'spatial attention' as components of the FRM. While these are specific techniques, the reviewer does not explicitly identify the specific section, table, figure, or unique aspect of the paper where these concepts are discussed. The reviewer also does not specify which particular channel or spatial attention mechanisms are being referred to. The lack of specificity in identifying the exact part of the paper being addressed makes the grounding somewhat weak. However, the reviewer does point to specific technical terms, which provides a degree of grounding.", "verifiability_rationale": "The reviewer makes a claim that the proposed FRM is a 'simple combination' of channel attention and spatial attention. To verify this claim, one would need to examine the authors' method description to see if they explicitly state or imply this combination. However, the reviewer does not provide any evidence or justification to support this claim. The lack of detail in the reviewer's assessment makes it difficult to verify this statement. The reviewer also claims a lack of 'indepth innovative detail', which, while not a direct claim about verifiability, contributes to the lack of verifiable information about the method's novelty.", "helpfulness_rationale": "The review point identifies a potential issue with the authors' description of their proposed FRM, suggesting it might be a 'simple combination' of existing attention mechanisms and lacking 'indepth innovative detail'. This is a helpful comment as it points out a specific area for improvement in the authors' work. However, the lack of specificity in the reviewer's assessment makes it difficult for the authors to pinpoint exactly what is meant by 'simple combination' or 'indepth innovative detail'. This lack of clarity reduces the helpfulness of the comment, as the authors have a general direction for improvement but lack concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's comment is an *implicit* statement regarding a potential weakness (the lack of anticipated negative impact). While the reviewer suggests *specific examples* (increased automation, dual use risks) as potential areas for the authors to address, the *action* isn't fully clear. The authors could improve the paper by *discussing* the societal impact, even if they don't believe it's negative. The reviewer's suggestion is helpful but not a direct instruction for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions the authors' statement about 'no negative social impacts' made at 'line 379'. This is a clear reference to a specific part of the paper. The reviewer then *specifies* the potential impacts by mentioning 'increased automation' and 'risks from the dual use of their method'. This adds further specificity to the discussion.", "verifiability_rationale": "The reviewer's comment is a statement of opinion ('I do not believe this work has the potential for significant negative social impact') and a suggestion for improvement ('the authors could always mention...'). It's not a claim that requires verification. Therefore, it's **1**.", "helpfulness_rationale": "The reviewer's primary point is to encourage the authors to discuss societal impact. While this is helpful, it's a suggestion rather than a direct instruction for improvement. The reviewer acknowledges this uncertainty ('I'm not quite sure if/how I'm meant to review this aspect of their work'). This suggests the comment is somewhat incomplete or open to interpretation. Therefore, it's **3**."}
{"actionability_label": "4 (4)", "grounding_specificity_label": "4 (5)", "verifiability_label": "X (X)", "helpfulness_label": "4 (4)", "actionability_rationale": "The reviewer explicitly states 'reorganize Sections 3 and 4,' which is a direct and clear action. While the reviewer doesn't specify *how* to reorganize, the suggestion itself is a concrete action that the authors can take. The reviewer is pointing out a potential issue and offering a solution, which is more actionable than simply stating a problem.", "grounding_specificity_rationale": "The reviewer refers to 'Sections 3 and 4,' which are specific parts of the paper. They further specify the *exact* parts to be moved ('the first paragraph of sec 4' and 'the remainder of sec 4'). This demonstrates a high level of specificity in identifying the relevant sections and the specific elements within them that are being considered for reorganization. The authors can easily pinpoint the areas being discussed.", "verifiability_rationale": "The reviewer's comment is primarily a suggestion for improvement rather than a claim that requires verification. They are proposing a reorganization based on their perception of potential redundancy. While the suggestion itself is logical and potentially helpful, it doesn't present a verifiable fact or require external references to be considered valid. The reviewer is offering a constructive idea, not a statement that needs to be proven.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by proposing a reorganization of Sections 3 and 4. They identify a potential issue (redundancy) and offer a specific solution (moving the first paragraph of Section 4 to the beginning of Section 3 and the remainder before Section 3). This is a concrete and actionable suggestion that directly addresses a potential weakness in the current structure. The authors can readily understand and implement this change. While it might not be a groundbreaking insight, it is a valuable piece of feedback that directly points towards a potential improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of connection between the two aspects, which constitutes an action. However, the specifics of where this disconnect is most apparent are not clearly identified, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions the two concepts ('improved variance control of prediction y^ or the smoothness of loss landscape' and 'zeroshot learning effectiveness'), indicating some grounding. However, the specific part of the paper being addressed is not explicitly identified, making the grounding weak. The reviewer also mentions the lack of clarity as the reason for the unclear connection, which specifies what needs to be addressed, adding a degree of specificity. However, the overall grounding is still weak because the section or table isn't pointed out.", "verifiability_rationale": "The reviewer states that there is a 'lack of connection' between the two aspects. This constitutes a claim. The reviewer attributes this lack of connection to 'poor clarity'. While this provides some justification, it is not a strong or specific example of poor clarity, making the verifiability somewhat borderline.", "helpfulness_rationale": "The reviewer points out a potential misunderstanding or a gap in the paper's explanation regarding the connection between the two aspects. While this could be helpful for the authors to clarify their work, the lack of explicit grounding and the weak justification for the claim make the overall helpfulness somewhat limited."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "Partially Verifiable", "helpfulness_label": "2", "actionability_rationale": "The reviewer states a suggestion for deeper analysis but doesn't explicitly define how to perform it, making the action implicit.", "grounding_specificity_rationale": "The reviewer identifies a lack of explanation for why certain methods perform better, making the grounding weak. The specificity is also underspecified as the reviewer doesn't pinpoint the exact missing elements.", "verifiability_rationale": "The reviewer makes a claim about the missing rigorous analyses, but the verifiability is partially verifiable because the paper presents results but lacks the explanation the reviewer is asking for.", "helpfulness_rationale": "The reviewer's comment is a request for improvement, not a direct critique of the paper's current content. It provides some feedback but lacks the actionable improvement to directly guide the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review points out a *lack* of discussion. It's not *saying* something is missing, but *asking* where it is. This leans towards implicit. The question is general. It doesn't specify *where* else the problem was discussed or *what* was discussed. It's a broad request for information. This is very vague.", "grounding_specificity_rationale": "The reviewer is asking \"Where else...\" This is a general question. They *don't* specify a particular section, table, or figure. They don't even imply a specific location. The grounding is weak. The question is about the *kmax problem* itself, but it doesn't specify *what* was discussed or *where* it was discussed. The specificity is low.", "verifiability_rationale": "The request is a question and a request for information (a citation). It's not making a claim that needs verification. It's a request for external information. While it *could* be considered a request for justification of their own work in relation to prior work, the review itself doesn't make a claim about *their* work's novelty or contribution in this specific regard. It's a request for information about * someone else's work.", "helpfulness_rationale": "The request for a citation is a common and valid request in academic writing. It directly addresses the need to contextualize the work within existing literature. While it doesn't directly tell the authors *how* to improve their draft, it provides a crucial piece of information that will likely lead to improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states a lack of information and implicitly asks for it. While it points to a specific element (Equation 1), it doesn't provide the details of how the function was estimated. This makes it an implicit instruction but not a fully explicit one.", "grounding_specificity_rationale": "The review point mentions 'the function for the optimal sequence length' and 'Equation 1'. While it doesn't explicitly name a section, table, or figure, the reference to a specific element of the paper allows for inference. However, it doesn't specify what the implications are for the authors' work or why this information is crucial.", "verifiability_rationale": "The review point contains a claim: 'There is no information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable we expect this model to be.' However, it does not provide any justification or references to support this claim. It simply states the absence of information.", "helpfulness_rationale": "The review point identifies a missing piece of information relevant to the authors' work. However, it doesn't provide any suggestions or guidance on how to address this lack of information or what the implications are for their specific research or methodology. It raises a concern without offering a constructive solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the 'strong assumptions' required for the methods to work, such as 'extrinsics and intrinsics are known' and 'object segmentation'. This directly identifies a limitation and provides a clear action for the authors to take \u2013 they need these assumptions to be met for the methods to be applicable. The reviewer also implies that the lack of these assumptions limits the realworld applicability, which is a concrete action the authors can consider.", "grounding_specificity_rationale": "The reviewer refers to 'strong assumptions about the availability of camera parameters (extrinsics and intrinsics are known) and object segmentation.' This explicitly names the specific parts of the paper or concepts being discussed, providing full grounding. Furthermore, the reviewer specifies what is missing \u2013 the lack of these parameters and segmentation \u2013 and what the consequence is \u2013 limited applicability. This specificity clearly identifies the issue.", "verifiability_rationale": "The reviewer states a limitation ('The applicability... is rather limited...') and provides a logical explanation for why this limitation exists ('strong assumptions are made about the availability of camera parameters... and object segmentation'). This explanation, without requiring external references, verifies the claim. The reviewer implies that the methods 'require' these parameters and segmentation, making the claim verifiable.", "helpfulness_rationale": "The review point directly addresses a crucial limitation for the practical application of the methods. By highlighting the strong assumptions required (extrinsics, intrinsics, object segmentation), the reviewer provides the authors with a clear understanding of the scope and limitations of their work. This actionable feedback helps the authors consider alternative approaches or data requirements, making the review 5 for improving their draft in a realworld context."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the inaccuracy of the number and suggests a specific way to improve the description. While the action is implied (the authors need to correct the number and add detail), it is concrete enough that they know exactly what needs to be done. The suggestion to add 'on the subword level' is a specific action.", "grounding_specificity_rationale": "The review point directly mentions a specific line number (L006), which is strong evidence of good grounding. The authors can easily identify the section being referred to. Furthermore, the review point specifies the *type* of inaccuracy (the number being too small) and even suggests a specific way to fix it ('add 'on the subword level''). This level of detail indicates high specificity.", "verifiability_rationale": "The review point contains a claim that 'thousands' is not accurate. This claim is supported by the suggestion to change it to 'millions' and add 'on the subword level'. While it doesn't provide a direct citation, the logical connection between the identified inaccuracy and the suggested fix makes it 3. The authors can infer the need for verification and the suggested approach.", "helpfulness_rationale": "The review point is directly pointing out a factual error in the paper and suggesting a concrete improvement. This is 5 for the authors as it directly addresses a discrepancy and provides a clear direction for correction. The suggestion to add 'on the subword level' is a specific and actionable piece of feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions the absence of hyperparameters and suggests providing them. This is an explicit action. For the figure behavior, the reviewer infers that the y=0 at x=0 might be due to normalization, which is an implicit action that could be made concrete by suggesting a specific normalization method. For the further analysis suggestion, the reviewer explicitly states 'I would be interested in seeing some further analysis on this model, perhaps using the interpolations themselves', which is an explicit action.", "grounding_specificity_rationale": "The review point explicitly mentions 'regularization' as an example of a hyperparameter, which grounds the discussion to a specific part of the paper. It also generally refers to 'latent path figures' and then specifically asks about 'why is the y value at x= 0 always 0?', indicating a clear grounding to the figure. The suggestion to use 'the interpolations themselves' also grounds the discussion to a specific element of the model.", "verifiability_rationale": "The review point does not explicitly state a claim about the missing hyperparameters. It infers that the y=0 at x=0 might be due to normalization, which is a claim that could be supported by external references or logical reasoning. The suggestion to use 'the interpolations themselves' is a suggestion without a claim requiring immediate verification.", "helpfulness_rationale": "The suggestion to provide specific hyperparameters is generally helpful for reproducibility. The suggestion to investigate the y=0 at x=0 behavior is helpful but lacks specific guidance on how to do it. The suggestion to use 'the interpolations themselves' for further analysis is a very helpful suggestion that directly addresses a potential area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly mentions two issues: 'material is introduced without proper explanation' and 'material supporting the main contributions seems to be in the appendix and not the main sections'. These are explicit statements that authors can directly address. However, the review point does not provide specific guidance on *how* to improve the explanation or reorganize the content. The actions are identified but not detailed.", "grounding_specificity_rationale": "The review point explicitly refers to 'Figure 1' and mentions the 'deeprag algorithm' and 'discussion on the high concurrency'. These are specific parts of the paper being addressed. However, the reviewer does not specify *what* is wrong with Figure 1 or how the deeprag algorithm or high concurrency discussion should be improved. The grounding is present, but the specificity of the issues is not detailed.", "verifiability_rationale": "The review point makes factual observations about the paper's structure and content: 'material is introduced without proper explanation' and 'supporting the main contributions seems to be in the appendix'. These are claims that can be verified by examining the paper. However, the review point does not provide *justification* for why these issues are problematic or why the content is misplaced. The claims are stated but not logically supported or referenced to external knowledge.", "helpfulness_rationale": "The review point identifies two key weaknesses in the paper: the lack of explanation for introduced material and the placement of key components in the appendix. While these are valid points, the review point does not offer specific suggestions or guidance on how to address these issues. The feedback is identified but lacks actionable recommendations."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks two questions: 'What is the effect on the approximation in the full tensor error?' and 'Is there any error bound in terms of epsilon?'. These are direct requests for information, making the action somewhat explicit. However, the reviewer does not specify *how* they want this information, leaving the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'the paper it is mentioned that the obtained core tensors can be rounded...', providing a clear reference point within the paper. This indicates strong grounding. Furthermore, the reviewer asks specifically about the 'error bound in terms of epsilon', which is a precise and specific request related to the mentioned rounding method, indicating high specificity.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question about a specific aspect of the paper. Therefore, the 'X' category applies.", "helpfulness_rationale": "The reviewer is asking a question directly related to the paper's content and seeks clarification on a specific methodological aspect. While it doesn't directly identify a bug or error, it seeks to understand the implications of a method. This information can be helpful for the authors to better understand and potentially improve their work. Therefore, it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing information in Table 1 and clearly indicates the generative setting. The action is to look for the results in the generative setting, and the details are provided in the comment.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 1' and the two 'test settings' (discriminative and generative), clearly identifying the specific part of the paper being addressed. The information requested is also very specific: 'the result on the generative setting'.", "verifiability_rationale": "The reviewer is not making a claim but rather asking a question. There is no statement that requires verification.", "helpfulness_rationale": "The reviewer directly points out a missing piece of information in the results table and asks for it. This directly guides the authors to look for the generative setting results, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point is a statement of opinion about the feasibility of 'SEARCH' queries. It doesn't propose any concrete actions or modifications to the paper. Therefore, it's 1.", "grounding_specificity_rationale": "The comment uses generic terms like 'query of the type SEARCH' and 'realistic scenario' without linking them to any specific part of the paper or document. This lack of specificity means it's 1.", "verifiability_rationale": "The comment is more of a suggestion for improvement than a declarative statement that requires verification. There's no 'yes' or 'no' question, and no specific evidence is being referenced.", "helpfulness_rationale": "While the comment identifies a potential area for improvement, it lacks concrete suggestions or actionable steps. It's a direction for improvement, but not a direct solution, making it 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a potential weakness (unknown effectiveness for other languages) but doesn't provide any actionable steps or specific information to address it. It's a diagnosis, not a prescription.", "grounding_specificity_rationale": "The reviewer is expressing a concern about a general aspect of the approach's applicability, not specifically referencing a previously mentioned section or detail. It's about 'other language families' in general, without specifying which ones or providing context.", "verifiability_rationale": "The comment points out a potential issue ('unknown effectiveness') but doesn't provide any evidence or justification to support why it's unknown. It's a statement of a problem without further explanation or references.", "helpfulness_rationale": "The comment highlights a potential area for improvement but lacks specific details or actionable steps. It's a mild suggestion to investigate further, rather than a concrete improvement plan."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the authors 'do not analyze the security (i.e., protection of the privacy) of the proposed framework'. This directly points to a missing action. However, it does not specify *how* this analysis should be conducted, leaving the authors with a general direction but lacking specific guidance on the implementation. Therefore, while the action is identified, the details are missing, making it 3 but not fully actionable.", "grounding_specificity_rationale": "The comment explicitly refers to 'the security (i.e., protection of the privacy) of the proposed framework'. This directly identifies the specific part of the paper being addressed. While it mentions 'privacy' as a specific aspect of security, it doesn't pinpoint a unique element within that framework. Therefore, the grounding is explicit, but the specificity is slightly lacking.", "verifiability_rationale": "The comment makes a clear claim: 'the authors do not analyze the security (i.e., protection of the privacy) of the proposed framework'. This claim is supported by the common understanding that a thorough evaluation of security, including privacy, is a standard expectation in the field. There is no missing information or external references needed to understand this claim. Therefore, the claim is wellsupported and verifiable.", "helpfulness_rationale": "The comment clearly identifies a significant deficiency in the authors' work: the absence of a privacy analysis. This is a valuable piece of feedback as it directly points to an area where the authors can improve their work. While the comment doesn't provide specific suggestions for how to perform the analysis, it does highlight a concrete need for such an analysis. Therefore, the feedback is clear and relevant to the authors' draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their desire for a description near line 135, making the action explicit. However, the reviewer does not specify *how* this description should be provided, making it implicit. Therefore, while the action is explicit, the lack of detail makes it only partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'near line 135,' which provides a specific location in the paper, indicating weak grounding. However, the *content* of what should be described at line 135 is not specified, making the grounding incomplete and not specific.", "verifiability_rationale": "The reviewer makes a claim that 'it would help if the form of p was described somewhere near line 135.' This is a claim that needs to be verified. The reviewer *assumes* it is a Gaussian distribution without providing justification or evidence. Therefore, the claim is made without sufficient support, making it 1.", "helpfulness_rationale": "The reviewer points out a lack of clarity in the paper and suggests a specific improvement (describing the distribution at line 135). While this points to a valid issue, the suggestion lacks specificity and detail. The reviewer doesn't explain *why* this is a problem or *why* they think it's important to describe the distribution. Therefore, the helpfulness is limited as the suggestion is vague and lacks context."}
{"actionability_label": "2", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that 'related work could be improved' but does not specify any concrete actions or modifications that the authors should make. While the reviewer identifies a problem, they do not provide any guidance on how to address it. The lack of explicit and actionable suggestions makes this review point less helpful for the authors.", "grounding_specificity_rationale": "The review point mentions 'related work' generally but does not pinpoint a specific section, table, figure, or unique element within the paper. The reviewer implies that the related work is unclear, but they do not specify which part of the related work needs improvement or what aspects are lacking. This lack of specific identification makes the grounding of the review point weak.", "verifiability_rationale": "The review point makes a claim that 'related work could be improved' but does not provide any evidence or reasoning to support this claim. The reviewer states a problem but does not explain why the related work is unclear or suggest any specific examples or references to back up their assertion. Without supporting evidence, the claim remains 1.", "helpfulness_rationale": "The review point identifies a weakness in the related work section but fails to offer any constructive suggestions or directions for improvement. The reviewer acknowledges the lack of differences between related works but does not propose any specific actions to address this issue. The review point is essentially a negative statement without any positive or actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the importance of understanding PPP effects using PPP maps but does not provide any actionable steps or specific details on how to achieve this understanding. The reviewer asks a direct question about the type of understanding one reaches by looking at the PPP maps, indicating a lack of clarity on the expected outcome. This suggests the reviewer's point is not actionable as it is presented.", "grounding_specificity_rationale": "The review point does not explicitly identify the specific aspect of the paper being addressed. The reviewer is asking a general question about the understanding of PPP effects using maps. There is no mention of a specific section, table, figure, or unique element of the paper. Therefore, the grounding is weak as the reviewer cannot pinpoint the area being discussed.", "verifiability_rationale": "The review point raises a question about the understanding of PPP effects using maps. While the reviewer implies that the paper should explain this understanding, the paper itself does not explicitly state what type of understanding is expected. The reviewer's point is a suggestion for improvement rather than a claim that can be verified with evidence from the paper.", "helpfulness_rationale": "The review point identifies a potential improvement to the paper by suggesting a more detailed explanation of PPP maps and their implications for understanding PPP effects. While the paper itself doesn't explicitly address this, the reviewer's point is a constructive suggestion for enhancing the clarity and impact of the work. The reviewer's question directly points to a potential gap in the current explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the lack of comparison with other stateoftheart methods, which can be considered an implicit action suggesting the reviewer wants a comparison. While the reviewer doesn't identify a specific part of the paper being addressed, the suggestion itself is a clear action for the authors to take.", "grounding_specificity_rationale": "The comment refers to 'other stateoftheart methods' generally, which is vague and doesn't pinpoint a specific part of the paper. However, when the specific method 'SpanBERT' is mentioned, it clearly specifies what needs to be addressed. Therefore, the grounding is weak until the specific method is mentioned.", "verifiability_rationale": "The comment contains a claim (lack of comparison) and mentions specific methods (SpanBERT) which can serve as external references. However, it doesn't explain *why* this comparison is important or *how* the authors should go about it. The claim is stated, but the reasoning and justification are lacking.", "helpfulness_rationale": "The comment identifies a valid weakness (lack of comparison) and suggests a solution (comparing with SpanBERT). However, the suggestion lacks detail on *how* this comparison should be done, making it less immediately actionable for the authors. The claim is present, but the supporting evidence is incomplete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point directly addresses a potential inconsistency in the paper's discussion of regret. The reviewer explicitly points out the statement \"the regret cannot be sublinear\" and the subsequent proof of T^(1/2) regret. The reviewer is asking for clarification on what is meant by 'sublinear\" in this context. This is a clear indication of an actionable request. The reviewer proposes a clarification to resolve the ambiguity.", "grounding_specificity_rationale": "The review point directly refers to the lines mentioned by the reviewer (lines 32  37). The reviewer provides a clear reference point for where the issue lies in the paper. The comment is explicitly linked to a specific section of the text.", "verifiability_rationale": "The review point doesn't present a claim that requires verification. It's a question about the interpretation of a statement within the paper. There's no assertion of a fact that needs supporting evidence. The reviewer is seeking clarification, not a new piece of information.", "helpfulness_rationale": "The review point identifies a potential source of confusion for the authors regarding the definition of 'sublinear\" in the context of regret. While it doesn't directly propose a solution, it highlights a gap in the clarity of the paper. It points to a specific area where the authors might need to reread or clarify the paper to understand the distinction between the general claim and the specific result."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for the authors to 'explain the forwardprediction model' and even suggests a specific action, 'redrawing the figure.' This is a clear call for action, making the review actionable. The reviewer directly identifies the missing explanation as a problem, which is a concrete action the authors should take.", "grounding_specificity_rationale": "The reviewer specifically mentions 'Figure 2(b) does not really show the schematic representation of the forward prediction model' and highlights the difficulty in connecting the 'pieces of the text with the figure as well as the equations.' This indicates a clear understanding of the specific part of the paper and its lack of clarity in relation to the surrounding information, demonstrating strong grounding specificity.", "verifiability_rationale": "While the reviewer states that the model is 'not well explained' and 'Figure 2(b) does not really show the schematic representation,' these statements, in themselves, could be considered 1 without specific examples of missing information or logical gaps. However, the reviewer's suggestions to 'redraw the figure' and the general feedback about the difficulty in connecting the text, figure, and equations, *could* be argued as implicitly suggesting that the schematic is missing or unclear, which could be considered 3. However, without specific citations or logical reasoning provided by the reviewer, it's difficult to definitively classify it as 5. I will lean towards borderline verifiability as the reviewer doesn't provide specific examples of missing verifiable elements.", "helpfulness_rationale": "The reviewer provides concrete suggestions such as 'It was hard to connect the pieces of the text with the figure as well as the equations' and 'recommend to redraw the figure.' These are actionable and directly address the authors' understanding of the model and its presentation. This makes the review 5 as it provides clear guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the idea of training only on rewarded actions in RBI and suggests that the absence of supervision from rewardless actions could be a factor in FP+RBI's success. However, the reviewer does not provide specific details on how to implement this change or what types of rewardless actions would be most beneficial. The suggestion is present, but the lack of concrete action makes it 2.", "grounding_specificity_rationale": "The reviewer mentions 'RBI training' and 'rewarded actions' generally. While they imply it's related to their experiments, they do not specify a particular section, table, or unique element in the paper that they are referring to. The reference is vague, indicating weak grounding. Furthermore, while they mention the potential benefit of rewardless actions, they do not specify *which* actions or provide examples, making the grounding even less specific.", "verifiability_rationale": "The reviewer makes a claim that 'This could be one significant factor that makes FP + RBI better than RBI alone.' This claim is presented as a possibility without providing any evidence, reasoning, or references to support it. The reviewer does not offer any logical reasoning, common knowledge, or external references to back up their assertion. Therefore, the claim is not wellsupported, making it 1.", "helpfulness_rationale": "While the reviewer raises a valid point about a potential limitation of the standard RBI approach and suggests that incorporating supervision from rewardless actions could improve FP+RBI's performance, the review point lacks the necessary details to be truly helpful. The suggestion is not specific enough for the authors to implement it directly. The reviewer also requests a stronger baseline for the RBI, but doesn't provide a concrete example of what that baseline would look like within the review point itself. Therefore, the review point, while relevant, does not offer a clear, actionable, and wellsupported suggestion, making it 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states two points: (1) the multiscale statement is misleading regarding physical time scales, and (2) the benefit of the slow RNN is reduced gradient path mitigation. These are direct and clear criticisms of the paper's description. The reviewer provides a specific alternative explanation for the first point and a clear specification of the benefit for the second. There's no ambiguity about what needs to be addressed.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific part of the paper being discussed \u2013 the \"multiscale statement.\" They also specify the potential misunderstanding regarding \"physical time scales\" and the benefit of the slow RNN in terms of \"reduced gradient path.\" This demonstrates strong grounding as the reviewer can accurately pinpoint the referenced part and clearly detail what is being criticized or explained.", "verifiability_rationale": "The reviewer provides a clear explanation for their claim about the misleading statement, linking it to the logical processing of sequential data in graph structures. For the benefit of the slow RNN, they specify the mechanism as \"reduced gradient path.\" While they don't provide external references, the reasoning is based on fundamental understanding of RNNs and graph neural networks. The claims are supported by logical reasoning and a clear specification of the benefit.", "helpfulness_rationale": "The reviewer provides a clear critique of a specific aspect of the paper and offers a specific alternative explanation. They also highlight a beneficial aspect (reduced gradient path) of a component (the slow RNN). This feedback is not just negative; it points out a potential area for clarification and provides a concrete benefit to focus on. It is specific enough for the authors to act on."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the weakness of baseline methods and the lack of discussion on limitations. While it identifies a problem, it doesn't specify *how* to improve the baselines or *how* to address the limitations. The suggestions are general and lack concrete steps.", "grounding_specificity_rationale": "The review point refers to 'baseline methods' generally and doesn't specify a particular section, table, figure, or unique element of the paper. The grounding is weak because it's not tied to a specific part of the paper being discussed.", "verifiability_rationale": "The review point makes claims about the weakness of baseline methods and the lack of discussion on limitations. While these are valid observations, the evidence provided is somewhat general and lacks specific examples or references to external works to fully support these claims.", "helpfulness_rationale": "The review point identifies a valid issue (weak baselines) and suggests a potential direction for the conclusion. However, it doesn't offer specific, actionable steps for the authors to take to address this issue or the suggestion in the conclusion. The feedback is more of a question or suggestion rather than a concrete improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the difference between expected performance under observation noise and the stochastic noisy function. They also point out that the paper focuses on the latter. This is an explicit statement of a difference and a clear identification of the two concepts. However, the reviewer does not provide concrete, actionable steps for the authors on how to change their objective function or how to evaluate performance under observation noise. The reviewer is highlighting a potential area for improvement in the paper's presentation, not a direct instruction for the authors.", "grounding_specificity_rationale": "The reviewer points out a potential issue with the paper's framing of the objective function. They suggest that the authors might be confused about the distinction between expected performance under observation noise and the stochastic noisy function. However, the reviewer does not explicitly identify a specific section, table, figure, or unique aspect of the paper where this confusion arises. The reviewer is implying a lack of clarity in the paper's explanation, but not pinpointing a specific element.", "verifiability_rationale": "The reviewer makes a claim about the paper's focus and the potential benefit of considering expected performance under observation noise. This claim is supported by the definitions provided in the review point. The reviewer states a judgment about the paper's current focus and suggests a potential alternative. This claim is supported by the definitions provided in the review point.", "helpfulness_rationale": "The reviewer's point is helpful in that it highlights a potential area for improvement in the paper's presentation and could guide authors to consider alternative evaluation strategies. The reviewer suggests that the paper could benefit from emphasizing the distinction between expected performance under observation noise and the stochastic noisy function. This suggestion is a potential action for the authors. However, the reviewer does not provide specific, actionable steps on how the authors should go about implementing this change or evaluating performance under observation noise."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests two concrete actions: (1) trying to run VGAE with a Vamp prior and (2) suggesting an experiment to keep the generative model fixed while optimizing only the inference part. These actions are direct and point towards specific improvements the authors could make. While the reviewer doesn't explicitly state 'how to implement this', the suggestions are clear and actionable.", "grounding_specificity_rationale": "The reviewer's suggestion about Figure 3 is explicitly tied to 'Figure 3', providing a clear reference point. However, the suggestion about the Vamp prior is less specific, mentioning a general concept (Vamp prior) within a specific model (VGAE) without explicitly naming a section or unique element of the paper. This makes it weakly grounded. The reviewer is specific about the models (SIGVAE and VGAE) in the minor point, which is fully grounded.", "verifiability_rationale": "The reviewer provides clear claims and suggests ways to verify them. For the first suggestion, the claim is that running VGAE with a Vamp prior would help determine if benefits are from a better generative model or better inference. The reviewer suggests comparing representations, which provides a logical reasoning for verification. For the minor point, the claim is that fixing the generative model would allow for a better comparison of representations, and the reviewer suggests parameterizing the inference part as SIGVAE or VGAE, providing a clear method for verification. The claims are wellsupported by logical reasoning or clear experimental suggestions.", "helpfulness_rationale": "The reviewer's points are directly relevant to the potential ambiguity in the current analysis. The suggestion about the Vamp prior directly addresses the question of whether benefits are from the generative model or inference. The suggestion about Figure 3 directly addresses the difficulty of comparing representations when generative models differ. Both points offer clear and actionable directions for the authors to further investigate their results and understand the underlying mechanisms. The reviewer's questions are specific and aim to clarify key uncertainties."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a weakness in the perceived novelty and contribution but does not provide specific, actionable steps on how to improve the method or network design.", "grounding_specificity_rationale": "The comment refers to the 'method' and 'network design' in general, without specifying a particular section, table, figure, or unique element of the paper.", "verifiability_rationale": "The comment contains a claim about the 'somewhat incremental' novelty and offers an opinion based on inspiration from prior work, but lacks concrete evidence or references to support this assessment.", "helpfulness_rationale": "The comment identifies a potential area for improvement by acknowledging prior work, but lacks specific, actionable suggestions on how to modify the method or network design to address this perceived lack of novelty."}
{"actionability_label": "Partially Actionable (3)", "grounding_specificity_label": "3 (3)", "verifiability_label": "3 (3)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer states their suspicion about the graph structure and its relation to locality, which can be considered an implicit action. However, the reviewer does not explicitly state how to apply this suspicion or what specific changes are needed based on this suspicion. The connection between the observed longrange dependencies and the lack of explicit 2D locality in the graph is implied but not explicitly verified or supported.", "grounding_specificity_rationale": "The reviewer mentions 'longrange dependencies' and 'graph structure' but does not explicitly identify the specific part of the paper they are referring to. While they mention 'Table 3' where they observed longrange dependencies, they do not clearly link it to the discussion of locality. The reviewer can infer the relevance of Table 3 but cannot precisely identify the referenced part.", "verifiability_rationale": "The reviewer presents a claim about the lack of 2D locality encoding in the graph structure and its potential impact. This claim is 3 as the reviewer provides a logical reasoning based on the observed longrange dependencies in semantic segmentation. However, the reviewer does not provide specific examples or references within the paper to support their claim about the graph structure. The connection between the observed longrange dependencies and the lack of explicit 2D locality in the graph is implied but not explicitly verified or supported with external references.", "helpfulness_rationale": "The reviewer raises a valid point about the potential role of locality in the graph structure and its impact on predictions. This point could be helpful for the authors as it highlights a potential area for further exploration and consideration. However, the lack of explicit verification and the implicit nature of the claim make it less directly actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a weakness in the theoretical framework by pointing out the lack of definition for $e_l$ in Eq. (3) and the exponential dependence on the diameter $M$ in several theoretical results. It suggests concrete actions: define $e_l$ and investigate the impact of $M$ on the constant factor. This provides clear directions for the authors to improve their draft.", "grounding_specificity_rationale": "The review point explicitly mentions 'Eq. (3)' and discusses specific results (Corollaries 1, 2, and 3 and Theorem 4). It identifies the *specific* issue of exponential dependence on the diameter $M$ and its impact on the constant factor. It also connects this theoretical weakness to the observed performance in Figure 1, indicating a strong understanding of the relevant section and its content.", "verifiability_rationale": "The review point contains a claim: 'This may exhibit the weakness of the proposed approaches (or at least of the theoretical results)'. It provides evidence for this claim by pointing to the specific theorems and corollaries with the exponential dependence and by referencing Figure 1 to illustrate the impact on performance. While it doesn't provide a formal proof, it strongly indicates the existence and significance of the weakness.", "helpfulness_rationale": "The review point is 5 as it directly points out two significant weaknesses in the proposed approaches. It provides clear suggestions for improvement, such as defining $e_l$ and investigating the impact of the diameter $M$. The connection to the observed performance in Figure 1 further emphasizes the practical implications of these theoretical limitations, guiding the authors towards concrete steps for refinement."}
{"actionability_label": "3  3", "grounding_specificity_label": "3  5", "verifiability_label": "4  4", "helpfulness_label": "3  3", "actionability_rationale": "The review point identifies a weakness ('poor longrange modelling ability of DGNs') and attributes it to a specific cause ('oversquashing and vanishing/exploding gradients'). It also mentions an alternative explanation ('oversmoothing'). While the point identifies potential causes, it doesn't explicitly state what the authors *should* do to address these issues. The suggestions are presented as possibilities rather than concrete actions.", "grounding_specificity_rationale": "The review point mentions 'DGNs' (Deep Graph Networks) and 'longrange modelling ability' and specifically names 'oversquashing and vanishing/exploding gradients' as a potential cause. It also mentions 'oversmoothing' as an alternative. While the point does identify the specific model and the aspect of performance being discussed, the connection between the identified causes and the weakness in longrange modeling isn't explicitly elaborated upon. The reviewer is pointing out related phenomena in deep graph networks.", "verifiability_rationale": "The review point states that the poor performance of DGNs in longrange modeling *could* be due to oversmoothing, based on the observation of this phenomenon in other deep graph networks. The reviewer doesn't provide any specific evidence or logical reasoning to support this claim about DGNs. It's presented as a possibility based on prior observations.", "helpfulness_rationale": "The review point identifies a potential cause of a problem (poor longrange modeling) in DGNs and offers an alternative explanation (oversmoothing). While the point is relevant to understanding the limitations of DGNs, it doesn't provide concrete, actionable steps for the authors to improve their models. The suggestions are more like alternative hypotheses than concrete recommendations for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks direct questions about the model's behavior with less data and the commonality of gradient vanishing. While the questions are explicit in identifying areas of interest, they lack specific guidance on how to address these issues or what concrete steps the authors should take. The reviewer is seeking information rather than a direct action to improve the draft.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'line 159' and 'your experiments,' providing clear grounding of the questions within the paper and the authors' own work. However, the questions themselves are general and do not specify *how* this relates to the model collapsing or the observed gradients. The grounding is present, but the specificity of the questions is lacking.", "verifiability_rationale": "The reviewer does not present a claim or assertion that requires verification. They are asking questions about observed phenomena. Therefore, it falls under the 'X' category (X).", "helpfulness_rationale": "The reviewer's questions are relevant to understanding the model's behavior and the observed phenomena of gradient vanishing. While the questions are openended and do not provide specific guidance on how to improve the draft, they are pertinent to the authors' understanding of the model. Therefore, they are 3 in the context of gaining insights."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point identifies a weakness in the paper's problem formulation but does not provide any actionable steps or suggestions for improvement. It simply states that the formulation is unclear.", "grounding_specificity_rationale": "The review point refers to the 'statement and introduction examples' generally, without pinpointing a specific section, paragraph, or concept that is unclear.", "verifiability_rationale": "The review point is a statement identifying a problem in the paper's presentation ('the problem formulation is somewhat unclear') without making any claims that need to be supported by evidence or references.", "helpfulness_rationale": "The review point highlights a lack of clarity in the problem formulation but does not provide any suggestions, explanations, or guidance on how the authors should revise or improve this section."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'conducting trials with models like OPT, BLOOM, or other alternatives.' This directly tells the author what to do.", "grounding_specificity_rationale": "The review point refers to 'different LLM families' generally, without pinpointing a specific section, table, figure, or unique aspect of the paper. The grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point makes a claim 'This paper lacks experiments on different LLM families.' and provides a suggestion 'Conducting trials with models like OPT, BLOOM, or other alternatives could provide valuable insights...'. The suggestion is a logical consequence of the identified lack, making the claim verifiable.", "helpfulness_rationale": "The review point identifies a valid weakness ('lacks experiments on different LLM families') and provides a clear and actionable suggestion ('conduct experiments with OPT, BLOOM...'). This directly helps the author understand a gap in their experimental evaluation and how to address it."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The statement explicitly identifies a limitation of the method, stating 'This method seems to only work for generative models that can be finetuned as an in/outpainting model.' This directly points to a constraint that the author's method might not meet. The action is to identify this limitation, which is a clear and direct instruction.", "grounding_specificity_rationale": "The reviewer is making a general statement about the method's limitations regarding finetuning capabilities. They are not specifying a particular section, table, figure, or unique element of the paper where this limitation is relevant. While the limitation is specific to the type of model, the location within the author's work is not identified, making the grounding weak. The specificity is about the *type* of model, not a specific part of the author's paper.", "verifiability_rationale": "The statement is a claim about the limitations of the method. It is a judgment about what the method *cannot* do. This claim is verifiable because it's a generally understood characteristic of finetuning in/outpainting models. The reasoning is clear and based on common knowledge within the field. There are no external references needed to support this claim.", "helpfulness_rationale": "The reviewer is informing the author about a limitation of the method they are using. This is valuable information for the author to know what the method *cannot* handle. It helps the author understand the scope of the tool they have and potentially choose a different approach. While it doesn't directly suggest an improvement to the author's own work, it is helpful in the context of using the method they have."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential misunderstanding between the 'curve finding' method and FGE. While the reviewer identifies a discrepancy, the action taken is implicit. The reviewer suggests an alternative interpretation of the method, but they don't explicitly state what action the authors should take based on this understanding. The reviewer could have been more explicit about how the authors should reevaluate their understanding of the method or how they should proceed with the FGE.", "grounding_specificity_rationale": "The reviewer's comment is 1 in the paper. The reviewer is making a general statement about a potential misunderstanding of the method and FGE, without specifying which part of the paper they are referring to. There is no mention of a specific section, table, figure, or unique aspect of the paper. The comment is a general observation about the relationship between the two concepts.", "verifiability_rationale": "The reviewer makes a claim: 'take random weights, learn curves between weights, and find nice weights to be mixed into the final ensemble, but it was not like that.' This claim is not 5. The reviewer states a potential interpretation of the 'curve finding' method and contrasts it with the actual implementation. However, they do not provide any specific evidence or references to support this claim. The reviewer's statement is a hypothesis based on their understanding of the method's description, but it lacks concrete verification.", "helpfulness_rationale": "The reviewer's comment is 3 as they identify a potential misunderstanding between the 'curve finding' method and FGE. This highlights a point of confusion for the authors and suggests an alternative interpretation. However, the comment lacks specific details and concrete examples. The reviewer doesn't provide a specific suggestion for how the authors should proceed or what changes they should make. The feedback is more about identifying a potential issue than providing a clear path forward."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the disagreement with the choice of baselines and provides a clear suggestion for improvement. The reviewer mentions 'heuristicbased solvers are much better than the heuristicbased solvers' (which seems like a typo and should be 'heuristicbased solvers are much better than the learningbased solvers'), indicating a clear action: to include Concorde. The reviewer further elaborates by stating 'However, for the single objective TSP, the SOTA heuristicsolver (e.g., Concorde) usually has the best performance.' This clearly indicates the action of including Concorde and the reason for it. The reviewer also states 'Since the obtained Pareto front is not highly nonconvex (as in Figure 2), the results for linear scalarization + Concorde should be included for a better comparison.' This provides a concrete action: including linear scalarization + Concorde and the reason: the nonconvex Pareto front. The reviewer's point is very direct and leads to a clear action.", "grounding_specificity_rationale": "The reviewer refers to 'Pareto front' and 'linear scalarization' in their review point. While they don't explicitly state 'Section 4' or 'Figure 2', the mention of 'Pareto front' strongly implies they are referring to the experimental results presented in the paper. The reviewer also mentions 'linear scalarization + Concorde', which is a specific method. However, they don't pinpoint a specific subsection or table. The grounding is implicit through the mention of the experimental results and the specific method. The specificity lies in the mention of 'linear scalarization + Concorde' and the implication for the comparison. The reviewer's point is about the results and a specific method, making the grounding somewhat implicit but the specificity relatively clear.", "verifiability_rationale": "The reviewer makes a claim by stating 'the results for linear scalarization + Concorde should be included for a better comparison.' This is a clear statement that requires justification. The reviewer then provides reasons for this claim: 'the SOTA heuristicsolver (e.g., Concorde) usually has the best performance' and 'Since the obtained Pareto front is not highly nonconvex (as in Figure 2)'. These reasons are logical and based on general knowledge of heuristic solvers and the implications of a nonconvex Pareto front for linear scalarization. The claim is wellsupported by logical reasoning and common knowledge. The reviewer is not introducing new external references, but the reasoning is sound and based on established knowledge.", "helpfulness_rationale": "The reviewer's point is 5 as it identifies a relevant alternative baseline (Concorde) and highlights a potential misinterpretation of the results due to the nonconvex Pareto front. The reviewer provides a specific suggestion ('include linear scalarization + Concorde') and explains why it's relevant ('the SOTA heuristicsolver (e.g., Concorde) usually has the best performance' and 'the obtained Pareto front is not highly nonconvex'). This actionable feedback helps the authors understand a more comprehensive comparison for their singleobjective TSP and potentially reevaluate their results. The reviewer's point directly addresses a potential limitation in the current experimental setup and offers a concrete improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point starts with \"while it is interesting to see the grounding of the proposed method in neuroscience...\" This is a statement of observation, not a directive. While it implicitly suggests a comparison or discussion, it doesn't explicitly state what the authors should do with their method. The reviewer is highlighting a potential overlap with existing ideas, but doesn't provide concrete steps for the authors to address this. Therefore, the action is implied rather than explicitly stated, making it less actionable.", "grounding_specificity_rationale": "The reviewer attempts to ground the criticism by mentioning \"general ideas are already present in other methods\" and listing specific methods like \"generalized Voronoi graph, semantic maps, pose graphs, graphbased slam\". However, the connection between the proposed method and these specific methods is not explicitly stated. The reviewer implies a link, but doesn't clearly identify the specific part of the paper or method being addressed, nor does he clearly specify what is already present in the mentioned methods. The grounding is present but not fully explicit.", "verifiability_rationale": "The review point contains a claim: 'some of the general ideas are already present in other methods...\". This is a statement of opinion. The reviewer provides some support by listing methods, but the connection to the proposed method is not clearly explained or justified. The reasoning is present, but it's not presented in a way that logically verifies the claim in relation to the proposed method. The evidence is there, but the link is not explicitly and clearly demonstrated.", "helpfulness_rationale": "The review point suggests that the authors should \"discuss the proposed method with respect to such methods\". This is a suggestion for improvement, but it lacks specific guidance. The reviewer identifies a potential area for the authors to contextualize their work, which is helpful. However, the suggestion is quite general and doesn't provide concrete steps or advice on *how* the authors should approach this discussion. Therefore, while the feedback is relevant, it lacks the specificity needed to be truly helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a problem (experimental details in the appendix making interpretation hard) and suggests a solution (moving some details back). While the reviewer points out a weakness in the current structure, the specific action of 'moving some details back' is not explicitly stated. The reviewer also suggests moving background to the appendix, which is a suggestion but not a concrete action. The reviewer implies that the missing experimental details are crucial for understanding the tasks, requiring the authors to infer which details are missing and why they are important.", "grounding_specificity_rationale": "The reviewer refers to 'experimental setup, tasks, and other details' generally, without specifying a particular part of the paper or a specific detail. The comment does not identify a section, table, figure, or unique element of the paper. The reviewer's statement is vague and does not pinpoint the exact issue.", "verifiability_rationale": "The reviewer makes a claim: 'The experimental setup, tasks, and other details are also moved to the appendix which makes it hard to interpret this anyway.' This is a claim that could be supported by evidence. However, the reviewer does not provide specific examples or references to external works to support this claim within the review point itself. The reviewer also suggests a solution (moving details back) as evidence, but the suggestion itself isn't verifiable.", "helpfulness_rationale": "The reviewer points out a potential issue (appendix hindering interpretation) and offers suggestions for improvement (moving details back, moving background). While the reviewer identifies a weakness in the presentation and provides suggestions, the suggestions are not perfectly specific. The reviewer doesn't specify which details should be moved back or which background information should be moved. The suggestions are relatively general and could be improved by being more specific."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point states \"It would be helpful if you provided glosses in Figure 2.\" This comment identifies an action (providing glosses) but does not specify how to achieve this action. The action is implied but not explicitly stated, making it somewhat vague on how to implement it.", "grounding_specificity_rationale": "The review point explicitly mentions \"Figure 2,\" which is a specific part of the paper. This allows the authors to accurately pinpoint the section being addressed, making the grounding 5.", "verifiability_rationale": "The review point states \"It would be helpful if you provided glosses in Figure 2.\" This is a suggestion or recommendation, not a claim that something is wrong or needs improvement. There is no logical reasoning, common knowledge, or external references being made. It's a helpful suggestion, but not a claim requiring verification, thus having X.", "helpfulness_rationale": "The review point suggests adding glosses to Figure 2. This points to a potential improvement in the paper. While it doesn't specify *how* to add the glosses, it clearly identifies a meaningful change that could be helpful for the authors. Therefore, it is 3 as it identifies a meaningful improvement but lacks complete detail on implementation."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states \"Memb is apparently the previous stateoftheart, but there is no mention to any reference.\" This tells the authors what is missing (a reference for \"Memb\") but doesn't explicitly tell them how to fix it (e.g., suggest a specific paper). The lack of a concrete action makes it borderline.", "grounding_specificity_rationale": "The review point is very general. It mentions \"Memb\" and the lack of a reference but doesn't specify *where* in the paper \"Memb\" is used or what specific issue arises from its lack of referencing. The grounding is weak because the section or aspect isn't clearly identified.", "verifiability_rationale": "The review point makes a claim: \"Memb is apparently the previous stateoftheart, but there is no mention to any reference.\" It *claims* there's a gap in referencing. However, it doesn't *justify* why this is a problem or *suggest* how to address it. The evidence is the *lack of a reference*, but the reasoning is missing.", "helpfulness_rationale": "The review point identifies a potential issue (lack of reference for \"Memb\"). However, it doesn't *help* the authors in any concrete way. It tells them something is missing but doesn't guide them on how to fix it. This makes it less helpful than a comment that suggests a specific alternative or provides a citation."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment asks for a justification for not considering finer grouping, which can be seen as an implicit request for explanation or a concrete suggestion for an alternative approach. While it doesn't explicitly state 'how to implement this', it implies a desire for a more granular control over quantization, making it 3 in terms of exploring different options. However, it lacks specific details on *why* finer grouping is not considered, making it less explicit.", "grounding_specificity_rationale": "The comment is 1 at all in a specific part of the paper. It refers to the general concept of quantization and suggests an alternative granularity (finer grouping) without pointing to a specific section, table, figure, or unique element of a paper that it's critiquing. The comment is more of a suggestion for improvement in the methodology rather than a direct critique of a specific aspect of the work.", "verifiability_rationale": "The comment itself does not contain a claim that requires verification. It's a question prompting for justification or an explanation of a design choice. While the *implication* is that the reviewer believes finer grouping is a valid alternative, this is not explicitly stated as a claim. The comment lacks any logical reasoning, common knowledge, or external references to support its suggestion. It's essentially a request for more information.", "helpfulness_rationale": "The comment identifies a relevant point (the potential for finer grouping in quantization) but fails to provide any concrete suggestions or ask specific questions to guide the authors. It's a question about a design choice, not a critique of a specific aspect of the work. Therefore, it doesn't offer any actionable feedback to the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment suggests a *direction* for further investigation but doesn't provide a specific *action* or *change* to be made in the current draft. There's no explicit instruction on how to modify the draft based on this suggestion.", "grounding_specificity_rationale": "The comment refers to a general concept (''unseen classes'') without linking it to a specific part of the author's submitted work. It doesn't identify a specific section, table, figure, or unique element within the draft.", "verifiability_rationale": "The point is a suggestion for future research, not a claim about the current work's quality or needing improvement. There is no assertion that the current work has a problem that needs to be addressed.", "helpfulness_rationale": "The suggestion is for future research, not for addressing current draft issues. It doesn't offer any direct feedback on the current draft, doesn't identify specific problems, and doesn't suggest concrete improvements."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking *why* specific architectures were chosen for different parts of the model. While the *what* (GRU and LSTM) is stated, the *how* (the reasoning behind these choices) is not explicitly provided. The reviewer is prompting for justification, which is an implicit action rather than a direct instruction. Therefore, while the reviewer points to the *where* of the choice, the *why* is missing, making it 3 but not fully explicit.", "grounding_specificity_rationale": "The reviewer directly asks about the *Pyramid* and the *sequential part*, strongly implying they are referring to specific components or sections of the paper. While the *specificity* of the issues is not addressed, the *grounding* of the reference is clear and explicit. The reviewer is pointing to specific parts of their work, making it fully grounded. However, the lack of specific examples or details about the problems makes it underspecific.", "verifiability_rationale": "The reviewer is posing a question seeking *explanation* for their architectural choices, not making a claim that needs verification. They are asking 'why' rather than stating 'this is better because...'. This is a request for justification, not a verifiable statement. Therefore, it is not a claim that can be supported by evidence, making it 1 as a claim.", "helpfulness_rationale": "The reviewer is asking questions to help the authors understand their implementation choices. While they are not directly offering *suggestions* for improvement, they are seeking clarification and justification for their architectural decisions. This is very helpful for the authors to understand *why* they chose certain models. The questions are diagnostic and seek to improve understanding, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer's question about 'active vertices' is implicit. While the statement 'Initially the network only has a few active vertices, due to sparsity' is present, the term 'active vertices' is not explicitly defined within this sentence. The reviewer would need to infer its meaning from the context or external knowledge. The action is implicit (identifying the need for a definition), but the definition itself is missing, making it vague. Therefore, it is 2.", "grounding_specificity_rationale": "The reviewer's question about 'active vertices' is not directly grounded in the sentence 'Initially the network only has a few active vertices, due to sparsity.' The authors do not explicitly mention 'active vertices' or any unique element within that specific sentence. The reviewer is making an inference about what might be meant by the limited number of vertices. Therefore, the grounding is weak. The specificity is also lacking as the definition is not provided. This scores as '2'.", "verifiability_rationale": "The original statement 'Initially the network only has a few active vertices, due to sparsity' is a factual observation and does not contain a claim that requires verification. The reviewer is asking for a definition, which is a request for information that is not present in the original text. Therefore, there is X to verify, and the verifiability is not applicable in the sense of checking a claim. This could be interpreted as '1' as the reviewer's request is not directly related to the statement itself. However, a more nuanced interpretation is that the grounding is weak because the term is not explicitly linked to the statement, and the specific definition is missing. A score of 2 seems appropriate as it captures the lack of direct grounding to the statement and the missing specific definition.", "helpfulness_rationale": "The reviewer's request for a definition of 'active vertices' is directly addressing a lack of clarity in the original text. The statement 'Initially the network only has a few active vertices, due to sparsity' is understandable, but the term 'active vertices' is not defined, making it unclear for the reader. This lack of clarity hinders the reader's ability to fully grasp the context and potentially implement something based on that statement. Therefore, this review point is 5 as it seeks to clarify a key term."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out two distinct areas where the paper could be improved. They highlight the lack of acknowledgment of the theory's limitations when applied to the specific model used and suggest a more thorough discussion of the potential negative societal impacts of graph neural networks. While the reviewer doesn't provide explicit instructions on *how* the authors should address these issues, they clearly identify where the paper is lacking in detail or critical discussion. This provides implicit guidance for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'the fact that their theory does not seem to be applicable to the used model' and 'the vagueness of unspecified 'structural assumptions'' without explicitly naming the specific section, table, figure, or unique aspect of the paper where these issues are present. Similarly, they refer to 'the current use of graph neural networks in industry' without specifying which part of the paper this relates to. Therefore, while the reviewer identifies areas for improvement, they do not pinpoint the exact location within the paper.", "verifiability_rationale": "The reviewer makes claims about the paper's limitations regarding the theory's applicability and its discussion of the societal impact of graph neural networks. They provide logical reasoning to support these claims, explaining *why* the theory might not be applicable and *what* the potential negative impacts could be. While the paper might not explicitly state these limitations or lack of discussion, the reviewer provides sufficient information to infer these claims and offers logical justifications for them.", "helpfulness_rationale": "The reviewer identifies two distinct and actionable weaknesses in the paper: the lack of acknowledgment of the theory's limitations and the underestimation of the societal impact of graph neural networks. While they do not provide explicit instructions on *how* the authors should address these issues, they clearly point out areas where the paper is lacking in detail or critical discussion. This provides a clear direction for improvement, even if the specific actions are not explicitly stated."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment is explicit about the weaknesses regarding the lack of clear examples for loss principles and the need for better justification of the FSR metric. However, it doesn't explicitly state how the authors should go about improving these aspects. The authors are left to infer the necessary steps.", "grounding_specificity_rationale": "The comment explicitly mentions the areas needing improvement: 'how hard is it to find examples that illustrate the loss principles clearly' and 'Weaknesses of the proposed FSR metric specifically'. The authors can easily identify the referenced parts. However, the comment doesn't specify *how* to find clearer examples or *what specific evidence* would justify the FSR metric. The grounding is clear, but the specificity is lacking.", "verifiability_rationale": "The comment raises concerns about the clarity and verifiability of the FSR metric but doesn't provide any evidence or reasoning to support or refute these concerns. There is X made, so this aspect is not applicable to this review point.", "helpfulness_rationale": "The comment is valuable in identifying areas for improvement, specifically regarding the clarity of examples and the justification of the FSR metric. However, because it lacks specific guidance on how to achieve these improvements, its helpfulness is somewhat limited. The authors are aware of the issues but lack concrete steps to address them."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states they do not understand the integration of epsilongreedy exploration with the proposed strategy. This implies a lack of clarity on how this specific implementation detail is handled, making the action implicit.", "grounding_specificity_rationale": "The reviewer mentions 'epsilongreedy exploration' but does not specify how it is integrated with the proposed strategy. They only ask 'What does this mean exactly? You have epsilongreedy exploration on top of the proposed strategy?'. This indicates a lack of precise identification of the part being addressed.", "verifiability_rationale": "The reviewer is not presenting a claim that needs verification. They are asking for clarification on a specific implementation detail. The purpose is to understand the implementation, not to evaluate the claim itself.", "helpfulness_rationale": "The reviewer's question directly seeks clarification on a crucial implementation detail. This information is valuable for the authors to understand and potentially reproduce the work, making it helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states their understanding of the method as a combination of GCN and normalizing flow, and then criticizes it for lacking 'new stuffs'. This is an explicit statement of the method's structure and identifies a potential weakness. However, the reviewer does not provide concrete suggestions on how to improve the method or address the lack of novelty. The action is identified, but the implementation details are missing.", "grounding_specificity_rationale": "The reviewer attempts to explain their understanding of the method as a combination of GCN and normalizing flow. This indicates an effort to ground their criticism in their interpretation of the method. However, the explanation is highlevel and does not pinpoint the exact specific aspect of the method that lacks novelty. The grounding is present, but the specificity of the grounded part is limited.", "verifiability_rationale": "The reviewer makes a claim that 'Technically, there is no enough new stuffs here.' However, they do not provide any evidence, reasoning, or external references to support this claim. The claim is presented as a statement of opinion without justification. The reasoning and common knowledge are missing, and external references are not provided.", "helpfulness_rationale": "The reviewer expresses a strong opinion that the work lacks novelty and provides no evidence or reasoning to support this claim. The feedback is presented as a statement of opinion without any suggestions for improvement or further analysis. The lack of supporting evidence makes the review unhelpful for the authors in understanding the limitations of the work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point states that only the projection head (CNN layers) are affected but not the classification head (FCN layer). This provides a specific observation about the model's behavior. However, it does not explicitly state what the author should do with this information. The reviewer could have suggested further analysis or experimentation to confirm this observation. The action is implicit in the observation, but the explicit instruction on how to act is missing.", "grounding_specificity_rationale": "The review point explicitly mentions 'projection head (CNN layers)' and 'classification head (FCN layer)'. This clearly identifies the specific parts of the paper being addressed. The grounding is strong as the reviewer directly names these sections. The specificity is also high as the reviewer further specifies the layers within each head.", "verifiability_rationale": "The review point is a statement of observation: 'Only projection head (CNN layers) are affected but not classification head (FCN layer)'. This is a descriptive statement and does not contain a claim that requires verification. There is no suggestion to prove or disprove this statement. Therefore, it does not fit the criteria for verifiability.", "helpfulness_rationale": "The review point identifies a potential area for improvement by highlighting the differential impact of projection and classification heads. However, it does not provide specific, actionable advice to the author on how to address this observation. The reviewer could have suggested further analysis, experimentation, or modifications to the model based on this finding. The feedback is present but lacks concrete guidance, making it less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a direct question about the vital part of the framework, which can be interpreted as an explicit action or suggestion. However, the question is broad and doesn't specify exactly what is vital, making it less concrete.", "grounding_specificity_rationale": "The reviewer refers to the 'framework,' 'CLIP,' 'weakly supervised learning,' and even hints at the 'discussion section' without explicitly naming a specific part. While they point to general areas, they don't pinpoint a precise section or element, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer states a claim: 'I think the discussion is necessary... help this paper to be distinguished from the other related work.' This claim is verifiable to some extent, as the reviewer is stating their belief about the discussion's importance. However, they don't provide specific examples or references to back up their claim, making it 3.", "helpfulness_rationale": "The reviewer provides a question and a critique of a section ('discussion section needs more clarity'). This directly points to a potential area for improvement in the paper, making it 5. However, the question is broad and doesn't offer specific suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the weakness of the analogy between HOI analysis and Harmonic analysis, indicating an awareness of a potential disconnect. They also specify the nature of this weakness, mentioning the limited number of 'basis' in the paper's context and the lack of a close connection with Fourier analysis. This suggests a clear understanding of the issue and a desire for the authors to address it.", "grounding_specificity_rationale": "The reviewer mentions 'HOI analysis' and 'Harmonic analysis,' which are specific concepts. They then further specify the weakness by referring to the 'limited number of basis' in the paper's context and the 'disconnect with Fourier analysis.' This level of specificity indicates a clear understanding of the relevant parts of the paper and the nature of the problem.", "verifiability_rationale": "The reviewer makes a claim about the weakness of the analogy but does not provide any specific evidence or references to support this claim within the review point itself. They are stating an observation about the paper's content but are not providing a logical reasoning or external references to back it up.", "helpfulness_rationale": "The reviewer's comment is a critique of the paper's analogy. While they identify a potential weakness, they do not offer specific, actionable feedback or suggestions on how the authors should improve their draft based on this observation. The review is focused on questioning the connection rather than providing direct improvement guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the findings might restrict meaningful implications and provides a clear suggestion to consider the implications for bitparallel fixedpoint numbers. This is an explicit action with a clear direction.", "grounding_specificity_rationale": "The reviewer mentions 'most existing ML accelerators tend to use bitparallel fixedpoint numbers.' This is an explicit grounding of the comment to a specific hardware characteristic, although it doesn't pinpoint a specific paper or section.", "verifiability_rationale": "The reviewer states a potential implication ('this might restrict the implications of the proposed methodology') but doesn't provide any evidence, explanations, or references to support this claim within the review point itself. The reasoning is plausible but not verifiable based on the provided text.", "helpfulness_rationale": "The reviewer identifies a potential limitation in the scope of the findings and provides a clear suggestion to consider the implications for bitparallel fixedpoint numbers. This feedback is actionable and directly addresses a potential constraint for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the issue with Figure 8, identifying the limited focusing distances (1m and 5m) present in the training data. The action is to point out the discrepancy between the figure's content and the reviewer's question about generalization to unseen distances. This is a clear and explicit action that is also concrete as the paper content is directly referenced.", "grounding_specificity_rationale": "The reviewer refers to 'fig 8', which is a specific part of the paper. The issue is also clearly specified: the figure shows focusing distances present in the training data, and the question is about generalization to other distances. The grounding is explicit, and the specificity is clear.", "verifiability_rationale": "The reviewer raises a question about the generalization of the model's focusing distance capabilities. There is X being made, and no evidence or reasoning is provided within the review point itself. It's a question that could be explored, but as a standalone point, it lacks a verifiable claim.", "helpfulness_rationale": "The reviewer points out a potential issue with Figure 8 and raises a question about generalization. However, they do not offer any suggestions or constructive feedback. The review point primarily identifies a problem without providing solutions or insights, making it not particularly helpful."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification and a definition, not proposing a specific action or improvement. While the reviewer implies a desire for better clarity, they do not explicitly state what the authors should do to improve their definition of 'style' or 'content'. The request is for understanding, not for implementing a concrete change.", "grounding_specificity_rationale": "The reviewer refers to concepts like 'content,' 'style,' 'neural application,' and 'Gabbay & Hosehn (2018)' but does not explicitly point to a specific section, table, figure, or unique element within the authors' paper. While the reviewer mentions related concepts, the connection to the authors' specific work is not clearly established, making the grounding somewhat weak. The reviewer also mentions 'temporal dynamic structure' and 'movement dynamic,' which are not present in the authors' work, further weakening the grounding.", "verifiability_rationale": "The reviewer makes a claim by stating, 'The authors should also consider defining content and style more broadly...'. This is a suggestion and a request for clarification, not a statement that can be directly verified or falsified based on the authors' current submission. The reviewer does not provide any specific examples, references, or logical reasoning to support this claim about the authors' work.", "helpfulness_rationale": "The reviewer's point is helpful in that it prompts the authors to clarify their conceptual framework and consider a broader perspective. However, it does not directly identify a specific weakness in the authors' current draft that needs improvement. The reviewer is more focused on guiding future work and improving the theoretical understanding of the topic rather than providing direct feedback on the current submission."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues with the paper's claims and the proposed method, making the action clear and direct. They identify the specific areas of concern (variance difference, precision loss) and suggest that the paper's argument is not convincing and the proposed method doesn't address the problem. The reviewer also points out that the variance difference is even larger with the proposed approach, further emphasizing the lack of improvement.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific parts of the paper being discussed, such as 'vit quantification,' 'Line 45,' 'Fig1(b),' 'Fig5(b),' 'Block.3,' 'MHSA,' 'ViT model,' 'transformer quantization,' and even names specific papers like 'QBERT,' 'Q8BERT,' etc. This demonstrates strong grounding as the reviewer can confidently pinpoint the sections and concepts being addressed.", "verifiability_rationale": "The reviewer provides evidence and reasoning to support their claims. They point to specific figures (Fig1(b) and Fig5(b)) to illustrate the variance difference and cite relevant papers in NLP (QBERT, Q8BERT, BinaryBERT, FullyBinaryBert, etc.) to support the claim that precision loss in quantization is not unique to ViT models. The reviewer also provides logical reasoning by stating that the paper's argument is not convincing and the proposed method doesn't improve upon it.", "helpfulness_rationale": "The reviewer provides clear feedback on specific areas of the paper that need improvement. They highlight the lack of depth in the analysis of vit quantification and point out inconsistencies in the results. The reviewer's suggestions, while not proposing exact solutions, indicate a clear direction for the authors to strengthen their work. The feedback is directly related to the paper's claims and suggests actionable steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the similarity to STNs and the lack of comparison. It also mentions specific related works (neighborhood STNs, PointNet). Once the action is identified (e.g., 'the proposed Xtransformation seems quite similar to STN'), the authors can directly identify modifications they should apply by looking for comparisons in the related work section or by implementing the STN locally. The level of explicitness is high, and the level of concreteness is also high as the reviewer points to specific areas of prior work.", "grounding_specificity_rationale": "The authors cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part \u2013 the lack of technical novelty compared to STNs and the missing comparison to STNs. The reviewer mentions 'spatial transformer networks (STN)' and 'local application in a neighborhood' which pinpoints the area of concern. While the exact section isn't named, the grounding is relatively clear as the reviewer refers to specific concepts and related works.", "verifiability_rationale": "The comment contains a claim: 'the technical novelty seems limited in this work' and 'there are also existing works that propose to apply STN in a local pixel neighborhood' and 'Also, there are no empirical or conceptual comparisons to STN in this work, which is important.' The claim 'there are no empirical or conceptual comparisons to STN in this work' is not fully supported by evidence within this review point. While the reviewer mentions existing works, they don't provide specific examples or references within this review point to support the claim of a lack of comparison. The reasoning is present, but the evidence is missing within this review point.", "helpfulness_rationale": "The comment provides a clear criticism about the lack of novelty and the missing comparisons. The reviewer identifies a significant area for improvement for the authors. However, the comment doesn't explicitly suggest how the authors should go about making these comparisons. The reviewer identifies the *need* for comparison but not the *how* to achieve it. The feedback is relevant but could be more actionable by providing specific steps or guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "Both review points are implicitly suggesting improvements. L384 suggests adding a clarification about the notation, and L431 suggests a correction to a potential notational inconsistency. While the actions are clear, they are not explicitly stated, requiring the authors to infer the necessary changes. The suggestions are concrete in terms of what should be added or corrected, but they lack specific details on *how* to implement these changes.", "grounding_specificity_rationale": "L384 is fully grounded as the reviewer explicitly mentions the notation and the probabilistic constraint. L431 is weakly grounded as the reviewer refers back to the previous point where the notation was introduced, implying a strong connection to the context.", "verifiability_rationale": "Both review points are 3. L384 suggests a clarification, implying a lack of complete clarity in the original paper. L431 suggests a correction, which also points to a potential issue that needs justification or clarification.", "helpfulness_rationale": "Both review points are 4. L384 suggests a way to improve clarity, which is directly actionable for the authors. L431 suggests a correction to a potential notational inconsistency, which is also a clear and actionable improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question ('Where does the reward come from at each trial?') that implies the authors should identify the source of the reward in Eq. 12. While not explicitly stated as 'action', the reviewer encourages the authors to perform an action by clarifying the equation. The second part of the review point ('Is one of the r_i taken from Eq. 11?') also implicitly asks the authors to verify a specific element within the equation. The reviewer's suggestion to explain the network model with equations is a direct action the authors can take to improve their understanding.", "grounding_specificity_rationale": "The review point explicitly refers to 'Eq. 12' and asks about the 'reward' and 'r_i' within that equation. This clearly identifies the specific part of the paper being addressed. The reviewer also suggests explaining the network model using 'equations', which directly points to the relevant section in Sec. 4.2. The request is precise and directly targets specific elements within the mentioned equation.", "verifiability_rationale": "The review point does not contain a claim that something is wrong or needs to be improved. It is a question seeking clarification about the origin of the reward in Eq. 12 and whether a specific variable (r_i) is taken from Eq. 11. While the reviewer implies a potential misunderstanding or lack of clarity, it does not explicitly state a verifiable error or deficiency. Therefore, it is 2 as it does not present a claim that requires justification.", "helpfulness_rationale": "The review point identifies a potential area of confusion regarding the reward mechanism in Eq. 12 and suggests improving the clarity of the network model explanation in Sec. 4.2. While the suggestion is relevant and could be helpful, it is somewhat highlevel and does not pinpoint specific errors or provide concrete solutions. The reviewer's request for clarification is a valuable suggestion, but it doesn't directly instruct the authors to perform a specific action beyond seeking more information."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the incorrect figure number and suggests a general improvement for the paper. While the suggestion is good, it's not a specific action the authors need to take immediately. The explicit nature of the figure number error makes it partially actionable.", "grounding_specificity_rationale": "The comment explicitly mentions the incorrect figure number (Fig.7 vs. Fig.12), which allows the authors to directly identify the issue. However, the suggestion to add proof links is general and doesn't specify which theorems/corollaries are missing links for, making the grounding underspecific.", "verifiability_rationale": "The comment identifies a factual error (incorrect figure number) and provides a clear justification for its correction. The suggestion to add proof links is a beneficial suggestion, but it lacks a concrete reason why this is necessary before the authors create the links, making it partially verifiable.", "helpfulness_rationale": "The comment identifies a clear error (incorrect figure number) and provides a specific, actionable suggestion to fix it. The suggestion to add proof links is also helpful for improving the paper's structure and accessibility, even though it lacks immediate justification. Both points contribute positively to the authors' ability to improve their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point asks clarifying questions about the choices made in Section 3, specifically regarding the selection of classes and action verbs. While it prompts the authors to consider the implications of missing action verbs, it doesn't explicitly tell them what to do. The questions are openended and don't provide concrete solutions. Therefore, the action is implicit, making it 1.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Section 3' and 'Section 3.306ff' when discussing the issues with action verbs and action frames. This clearly identifies the specific part of the paper being addressed, making the grounding explicit. However, the reviewer does not specify *why* the action verbs are missing or *what* action frames are being referred to, making the grounding somewhat underspecific.", "verifiability_rationale": "The review point raises concerns about the selection and tagging of action verbs and the definition of action frames in Section 3. While it points out potential issues, it does not provide any specific examples, references, or logical reasoning to support its claims. The statements are presented as observations rather than verifiable statements with evidence. Therefore, the claim is not supported by any verifiable evidence.", "helpfulness_rationale": "The review point is likely to be 3 in that it prompts the authors to reflect on their choices regarding action verbs and action frames. It encourages them to consider the implications of missing action verbs and the clarity of their action frames. However, it doesn't provide concrete solutions or actionable steps, making it less directly helpful than a review that offers specific improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the issue (a spelling error) and provides a concrete solution (the correct spelling). They also implicitly suggest the author should correct it. This information is directly actionable for the author.", "grounding_specificity_rationale": "The reviewer accurately pinpoints the exact location of the error (Ln 32, Page 1), fully grounding the comment. They also clearly specify the incorrect spelling and the correct spelling, providing specific details about the issue in the referenced part of the paper. This allows the author to precisely identify what needs correction.", "verifiability_rationale": "The comment identifies a factual error in the text ('Empiically'). While it could be argued that the reviewer is making a claim about the paper's content being incorrect, the core of the comment is the identification of the error itself, not a claim about the paper's overall quality or a request for justification. Therefore, it doesn't fall under the 'claim extraction' category and is considered to have 'X'. As a factual observation, it doesn't require verification in the sense of logical reasoning or external references.", "helpfulness_rationale": "The comment identifies a minor issue (a spelling error) and provides a direct solution. While this is helpful for correcting the error, it doesn't offer broader advice or highlight a significant weakness in the paper. It's a very specific fix and doesn't provide much guidance beyond that. Therefore, it's 2 as it doesn't significantly improve the author's understanding of how to make their work better beyond fixing this specific typo."}
{"actionability_label": "4", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests that the framework described in Section 4.1, which is meant to be general, seems to be limited to rawlevel selection, while the proposed method in Section 4.2 focuses on mask selection and rawlevel features. This implies an implicit suggestion that the framework in Section 4.1 should also consider representation learning, which is a concrete action. The reviewer provides a clear rationale based on the apparent inconsistency between the scope of the framework and the actual implementation.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Section 4.1' and 'Section 4.2' and discusses concepts like 'mask selection', 'rawlevel features', and 'representation learning'. This clearly indicates that the reviewer can identify the specific parts of the paper being addressed. Furthermore, the reviewer directly points out a potential inconsistency, which is a specific detail. The reviewer also names 'representation learning' as a relevant concept, further emphasizing the specificity of their feedback.", "verifiability_rationale": "The reviewer claims that the framework in Section 4.1, which is meant to be general, seems to be limited to rawlevel selection. The reviewer also mentions that the proposed method in Section 4.2 considers 'mask selection and rawlevel features' and suggests that 'representation learning' could be a relevant consideration. This is a claim that can be verified by examining the descriptions in Section 4.1 and Section 4.2. While the reviewer doesn't provide explicit examples of where representation learning is missing, the suggestion itself is a clear indication of a gap that could be verified with further examination. The reviewer's reasoning for this claim is logical, pointing to the different focuses of the two sections.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement: 'I think the feature selection, presented in Section 4.2, could be further improved, with consideration of representation learning.' This is a direct and specific recommendation for the authors. The reviewer identifies a concrete area for improvement and suggests a specific direction (considering representation learning). This makes the comment 5 and directly beneficial for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a gap in information (missing details on reward design) but does not explicitly state how to address this gap or provide concrete steps. It points out a problem but lacks a direct action or instruction.", "grounding_specificity_rationale": "The comment mentions 'how to design the rewards is not fully understandable' but does not explicitly identify a specific section, table, figure, or unique aspect of the paper where this information is lacking. The reference to 'the rewards' is somewhat general.", "verifiability_rationale": "The comment does not make a claim that requires verification. It states a fact (something is missing) but lacks supporting evidence or justification.", "helpfulness_rationale": "The comment points out a weakness in the draft (missing details on reward design), which is generally helpful for the authors. However, it does not provide any specific guidance or suggestions on how to improve the draft based on this weakness."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a problem (generalization to different numbers of entities) but does not offer a specific solution or action to address it. The language is more about identifying an issue than providing a direct instruction on how to fix it.", "grounding_specificity_rationale": "The reviewer mentions 'Figure 3 of INs,' which provides some grounding by referencing a specific part of the paper. However, they do not explicitly state which specific aspect or element within Figure 3 is causing the issue. The grounding is present but not precise.", "verifiability_rationale": "The reviewer states a problem (generalization to different numbers of entities) without providing any evidence, justification, or references to support this claim. The statement is presented as a statement of concern rather than a wellsupported claim.", "helpfulness_rationale": "The reviewer's point is about clarifying a technical issue, which can be helpful for the author to understand the limitations of their model. However, it does not directly propose a solution or improvement to the draft itself, making it 3 but not fully transformative."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies the weakness ('incremental improvement, little novelty') and suggests a consequence ('if there's no code release after the revision process, then this weakness stands'). While not a direct 'fix,' the reviewer points towards a concrete action the authors could take. However, the weakness itself is not explicitly stated as a solution or action the authors should take.", "grounding_specificity_rationale": "The reviewer mentions 'KNN based MT approach,' which grounds the criticism to a specific technique. However, they do not specify *which* part of the KNN MT implementation is lacking. The reviewer describes the *nature* of the weakness ('incremental improvement, little novelty') but doesn't detail *what* aspects of the KNN MT are specifically weak.", "verifiability_rationale": "The reviewer makes a claim: 'It's an incremental improvement to KNN based MT approach, little novelty'. This is a statement of opinion. However, the reviewer does not provide concrete evidence *within the review point itself* to *verify* this claim. They offer their interpretation and a potential consequence ('backed by good experimental design') but don't point to specific examples or references to support the claim of 'incremental improvement' or 'little novelty'.", "helpfulness_rationale": "The reviewer explicitly states their opinion: 'This weakness is a little nitpicking esp when I personally execution (replicable) beats idea (novelty)'. They also suggest a potential remedy: 'if there's no code release is produced after the revision process, then this weakness stands'. This indicates a desire for the authors to improve their work and provides a concrete action they could take (code release). While the underlying claim about the weakness is 1 within the review point itself, the reviewer's suggestion for improvement is actionable and directly addresses the potential lack of novelty."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'discuss the runtime of Prithvi WxC'. It also connects this action to a specific characteristic of the model ('large parameter count') and its relevance to the selling point of MLbased emulators ('computational cheapness'). This makes the action clear and directly actionable.", "grounding_specificity_rationale": "The review point explicitly grounds the discussion in the specific model 'Prithvi WxC' and its unique characteristic, the 'large parameter count'. This allows the authors to precisely identify the aspect being addressed, making the grounding very specific.", "verifiability_rationale": "The review point provides a clear claim: 'the runtime of Prithvi WxC should be discussed'. It also offers a justification for this claim by linking the model's 'large parameter count' to its potential 'high runtime', which is relevant to the context of MLbased emulators and their computational efficiency. This justification provides a basis for verifiability.", "helpfulness_rationale": "This review point is 5. It directly addresses a key aspect of MLbased emulators (computational cost) and provides a specific reason (large parameter count) for why the runtime of Prithvi WxC is important. It also suggests a concrete action (discuss the runtime). This information is valuable for the authors to understand the tradeoffs and limitations of their model."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem (lack of novelty) but does not provide explicit or concrete steps for the authors to take. The authors still need to interpret what constitutes 'not enough' and how to address it.", "grounding_specificity_rationale": "The comment refers to the 'idea' in general, not a specific part of the paper like a section, table, or figure. This makes it difficult for the authors to pinpoint the exact area needing improvement.", "verifiability_rationale": "The comment is a statement of opinion ('the idea is not enough') rather than a claim requiring evidence or verification. There are no suggested metrics or methods to support this claim.", "helpfulness_rationale": "The comment raises a concern about the novelty of the idea but does not offer specific, actionable suggestions or point to particular areas for improvement. The authors are left to interpret the meaning and implications of the comment."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer identifies a potential issue ('oversell the method') and its consequence ('contribution less clear'). However, they do not specify *how* to address this. The comment is more about pointing out a problem than providing a clear, actionable step.", "grounding_specificity_rationale": "The comment refers to the 'framing of the paper' and the 'method' in a general sense. It does not specify a particular section, table, figure, or a unique aspect of the method.", "verifiability_rationale": "The comment expresses an opinion ('seems to oversell') and identifies a potential consequence ('contribution less clear'). It lacks specific examples, references to external work, or logical reasoning to support these claims within the paper itself.", "helpfulness_rationale": "The review point highlights a potential issue in the paper's presentation. While it doesn't offer a specific solution, it points out a problem that the authors should be aware of, which can be helpful in guiding their selfreflection and improvement efforts."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issues with the model description (generative process in detail, too many symbols, notation table) and provides concrete suggestions for improvement (presenting in separate steps, a notation table). This indicates a direct identification of areas needing change and clear actions to be taken.", "grounding_specificity_rationale": "The reviewer refers to the 'model description' generally. While they identify issues within this area, they do not specify a particular section, table, or unique element of the paper where these issues are located. The reference is broad, indicating a general understanding of where the problems lie but not a precise identification.", "verifiability_rationale": "The reviewer makes a claim that 'the model description could be improved' and provides specific suggestions and examples to support this claim (e.g., presenting the generative process in separate steps, a notation table). This demonstrates that the reviewer's statement is not just a general observation but is backed by concrete ideas and potential solutions.", "helpfulness_rationale": "The reviewer provides specific and actionable feedback on the model description, suggesting concrete improvements like presenting the generative process in separate steps and including a notation table. These suggestions are directly relevant to the task of understanding and improving a model description, making the review point practically useful for the authors."}
{"actionability_label": "Low", "grounding_specificity_label": "Full", "verifiability_label": "Low", "helpfulness_label": "Low", "actionability_rationale": "The reviewer points out a problem (unclear paraphrases) but doesn't propose a solution or explicitly state what the authors should do about it. The action is implicit  the authors should understand the impact is negative  but the howto is missing.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific issue: 'how different the paraphrases are from the original sentences.' They also clearly explain what makes them unclear ('this crucially impacts the subsequent steps because the model will greatly rely on the quality of these paraphrases'). This is a clear and specific identification of the part being addressed. The grounding is 'Full' because the reviewer explicitly names the concept. The specificity is also 'Full' because they clearly explain *what* makes the paraphrases unclear (impact on subsequent steps, reliance on quality).", "verifiability_rationale": "The reviewer raises a concern about the quality of the paraphrases but doesn't provide any evidence or justification for why they are good enough. They are questioning the *evidence* for the model's reliance on them. The evidence is based on the potential negative consequences (low quality training data, few added pairs). There is no logical reasoning, common knowledge, or external references provided to support the claim about the paraphrases' quality.", "helpfulness_rationale": "The reviewer's comment is primarily a critique of the training data generation process. While it highlights an important issue, it doesn't offer any concrete suggestions or solutions for the authors to improve their draft. The comment is focused on a problem without actively addressing it."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly suggests improving the paper by identifying areas for specific improvement related to rationales. This is a clear and actionable suggestion.", "grounding_specificity_rationale": "The reviewer identifies a problem with Figure 2 and the 'bold' text but does not specify the exact section, table, or unique aspect being addressed. This makes the suggestion somewhat vague.", "verifiability_rationale": "The reviewer makes a claim about the difficulty of identifying rationales but does not provide direct evidence or references within the review point to support this claim. The suggestions are about improving visualization, not verifying the claim about the NLP task.", "helpfulness_rationale": "The reviewer provides specific suggestions for improving the paper, both in terms of identifying areas for specific improvement related to rationales and suggesting an alternative visualization for Figure 2. This makes the review helpful for the authors.)"}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer suggests 'further verify the effectiveness and universality to nonLLMbased models'. This implies an action, but it's not explicitly stated what needs to be done or how to do it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the FlippedQA framework' and suggests verifying its effectiveness on 'nonLLMbased models like HiTeA and InternVideo'. This clearly identifies the specific part of the paper (the FlippedQA framework) and the issue (its applicability to nonLLM models).", "verifiability_rationale": "The reviewer states 'I believe the FlippedQA is a general framework for various generative VideoQA models' and then suggests 'further verify the effectiveness and universality to nonLLMbased models'. This is a claim that needs justification, but the reviewer doesn't provide any specific examples or references within this review point.", "helpfulness_rationale": "The reviewer directly suggests 'further verify the effectiveness and universality to nonLLMbased models'. This is a clear and actionable suggestion for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that 'the writing could be improved' and 'it took me quite a lot of effort to go back and forth to understand the main idea and the theoretical analysis of the paper'. While it identifies a problem, it doesn't specify what needs to be improved or how. The phrase 'a lot of effort' is vague and doesn't provide concrete steps for the author. Therefore, the action is implicit and vague.", "grounding_specificity_rationale": "The comment refers to 'the main idea' and 'the theoretical analysis' of the paper. While it doesn't explicitly name a specific section, table, or figure, it clearly identifies the areas of the paper being discussed. The reviewer is referring to specific parts of the paper, even if not by their exact names. Therefore, the grounding is present but not fully explicit.", "verifiability_rationale": "The comment makes a claim that 'the writing could be improved' and 'it took me quite a lot of effort to go back and forth to understand the main idea and the theoretical analysis of the paper'. This is a subjective statement about the clarity and understandability of the paper's content. While there is a logical reasoning behind this claim (the reviewer found it difficult to understand), the review point itself doesn't provide specific examples or references to external works to support this claim. The claim is made without sufficient evidence within the review point itself.", "helpfulness_rationale": "The review point states that 'the writing could be improved' and describes the reviewer's experience of struggling to understand the 'main idea and the theoretical analysis' due to 'a lot of effort'. While this highlights a problem, it doesn't offer any specific suggestions or actionable steps for the author to improve their writing. It's a statement of the reviewer's struggle rather than a constructive critique with solutions. Therefore, the review point is not particularly helpful in terms of providing actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states a weakness ('it doesn't present significant theoretical novelty') but doesn't provide specific actionable steps on how to address it. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer explicitly names the specific methods and provides citations, clearly pinpointing the relevant aspects of the proposed method.", "verifiability_rationale": "The reviewer makes a claim about the method's nature and novelty without providing any supporting evidence or logical reasoning. The verifiability relies on the authors' ability to independently assess the claims made by the reviewers.", "helpfulness_rationale": "The reviewer identifies a potential issue (lack of theoretical novelty) but doesn't provide specific suggestions or a clear path forward, making the feedback somewhat limited."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the validity of a specific operation, which can be interpreted as an implicit request for clarification. While the question itself doesn't directly identify an action the authors should take, it points to a potential area of confusion or misunderstanding, which can be addressed by an action. The reviewer is essentially prompting for information.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'text input' and the 'four text elements of an object,' making the specific part of the paper being addressed very clear. The comment is not making a claim but rather asking a question about a specific aspect.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question about a specific operation. While a helpful answer could involve referencing programming language concepts or documentation, the request itself doesn't contain a claim that needs supporting evidence.", "helpfulness_rationale": "The reviewer is asking a specific question about a technical detail. While it doesn't directly tell the authors what to do, it points to a potential issue or area of confusion that they might be experiencing. A helpful response would explain the behavior of text input concatenation in the context of the software or framework being used, which could resolve the reviewer's uncertainty and provide valuable information."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point is a statement of desire, not an explicit instruction. While it implies a lack of motivation, it doesn't specify what needs to be done to improve it. The action is implicit (improving motivation), but the how is not detailed.", "grounding_specificity_rationale": "The reviewer refers to the paper as a whole ('the paper') and the lack of motivation. They do not specify which part of the paper needs better motivation or what specific aspects of motivation are lacking. The grounding is at a high level, lacking specificity about the location or nature of the issue.", "verifiability_rationale": "The review point is a suggestion, not a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support the need for better motivation. It's a statement of desire, not a statement that can be proven or disproven.", "helpfulness_rationale": "The review point identifies a potential weakness (lack of motivation) but does not offer any concrete suggestions or guidance on how to address it. It's a pointer towards improvement rather than a direct solution. The helpfulness is minimal as it doesn't provide actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the suggestion to clarify the sentence in lines 1217 and provides a clear action: 'clarify the sentence'. This action is concrete, meaning the authors know exactly what needs to be done.", "grounding_specificity_rationale": "The reviewer directly refers to 'lines 1217' in the abstract, providing a precise and obvious identification of the specific part of the paper being addressed. The comment also specifies what needs to be addressed: 'the sentence in lines 1217'.", "verifiability_rationale": "The reviewer's comment does not contain a claim that requires verification. The suggestion is a general piece of advice ('clarify the sentence') that is not supported by specific examples or references. While the location is grounded, the *type* of improvement is general and not verifiable within the abstract itself.", "helpfulness_rationale": "The review point directly identifies a specific section of the paper ('lines 1217') and provides a clear, actionable suggestion ('clarify the sentence'). This makes the feedback directly actionable and targeted, making it 5 for the authors to focus on improving that specific part of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out a discrepancy in the experimental setup (Pix3D training and testing) and compares it to zeroshot methods. This doesn't directly tell the authors *what to do*. It highlights a potential flaw in their evaluation. While the action of identifying this flaw is clear, the reviewer doesn't specify how the authors should address this issue. The action is explicit (identifying the flaw), but the implementation is vague. Therefore, it is 2.", "grounding_specificity_rationale": "The reviewer mentions \"Pix3D training and testing\" and \"zeroshot singleimage 3D reconstruction models.\" While they name the models, the *specific* *section* or *table* in the paper where this limitation is most relevant isn't explicitly stated. The comparison to \"zeroshot\" is a generalization. The authors cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part (the potential unfairness in the evaluation). Therefore, it is 3.", "verifiability_rationale": "The reviewer states a fact: \"The domainspecific model is trained on Pix3D. And the experiments are conducted on Pix3D.\" This is a factual statement. The statement itself is a clear observation, not a claim requiring justification. Therefore, it is not verifiable in the sense of providing new insights or guidance. It is a straightforward observation about the experimental setup. Therefore, it is not verifiable.", "helpfulness_rationale": "The reviewer points out a potential flaw in the experimental design. While relevant, it doesn't directly instruct the authors on *how* to improve their draft. It highlights a potential issue with the evaluation methodology, which could impact the validity of the results. However, it doesn't offer a specific, actionable step for the authors to take *based on this observation*. Therefore, it is not 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the proposed approach does not outperform or is even worse than Decouple Kang et al.. This is a clear indication of an actionable point. However, the reviewer does not specify *how* the proposed approach underperforms or *why* it is worse. The lack of specific details makes it somewhat vague in terms of actionable steps.", "grounding_specificity_rationale": "The reviewer mentions 'Decouple Kang et al.' and 'head and tail categories'. While the terms are mentioned, the exact section or table where this information is discussed in the paper isn't explicitly stated. The connection to the tradeoff is implied but not clearly linked to specific parts of the paper, making it weakly grounded. The reviewer also mentions 'Table 5', which further supports the idea that the grounding is not fully explicit.", "verifiability_rationale": "The reviewer makes a claim: 'the proposed approach does not outperform or is even worse than Decouple Kang et al.'. This is a verifiable claim. The reviewer also states that 'Table 5 shows the tradeoff between head and tail categories'. This provides some justification for the claim, making it 3. However, the reviewer does not provide details about Table 5 or the specific hyperparameters of Decouple, which would strengthen the verifiability.", "helpfulness_rationale": "The reviewer points out a performance gap between the proposed method and a baseline (Decouple) and highlights a tradeoff in their results. This is a helpful point as it identifies a limitation of the current work. The reviewer also suggests that similar tradeoffs could be investigated for the baselines, which provides a direction for future improvement. While the point is not a complete solution, it does offer a clear area for enhancement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests \"additional experiments on realistic noisy datasets like WebVision would have provided more support for C2D.\" While it proposes an action (additional experiments), it lacks specific details on how these experiments should be conducted or what specific results would be considered \"more support.\" The suggestion is implied rather than explicitly stated.", "grounding_specificity_rationale": "The review point refers to \"C2D\" without explicitly naming a specific section, table, figure, or unique aspect of the paper being addressed. The suggestion is about a future experiment (\"additional experiments on realistic noisy datasets like WebVision\") and doesn't specify what part of the reviewed paper it aims to improve or clarify. The grounding is weak because it doesn't directly point to a specific part of the reviewed paper being discussed.", "verifiability_rationale": "The review point is a suggestion for additional experiments. It doesn't contain a direct claim that can be verified using logical reasoning, common knowledge, or external references. It's a suggestion for future work, not a critique or assertion about the reviewed paper.", "helpfulness_rationale": "The review point suggests an improvement to the paper by proposing additional experiments on realistic noisy datasets, which could indeed provide more support for C2D. This is a relevant and generally helpful suggestion. However, the lack of specificity in the suggestion (e.g., what aspects of C2D to experiment with, what metrics to use) makes it less actionable and potentially less impactful than a more detailed suggestion."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "Highly Grounding Specific", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'relying on 4 OCR QA datasets' and 'more scenarios like the LLaVA benchmark.' These are concrete actions or suggestions. They provide clear directions for the authors to consider and improve their evaluation methods. The reviewer also implies a concern about the limitations of the current approach, which is a direct action for the authors to address.", "grounding_specificity_rationale": "The reviewer mentions '4 OCR QA datasets' and 'LLaVA benchmark' in the review. While they don't explicitly state 'the section discussing evaluation methods,' the mention of specific datasets strongly implies they are referring to that section. This provides weak grounding. However, the reviewer clearly specifies the *types* of datasets and benchmarks they are suggesting, making the specificity high.", "verifiability_rationale": "The reviewer makes a claim: 'The evaluation is limited, mostly relying on 4 OCR QA datasets.' This is a statement of opinion or observation about the current evaluation. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion to 'more scenarios like the LLaVA benchmark' is presented as a potential improvement but lacks verification or justification within the review point itself.", "helpfulness_rationale": "The reviewer provides a helpful suggestion: exploring different evaluation methods, especially with LLaVA. This is a suggestion that could directly benefit the authors by potentially improving the robustness and comprehensiveness of their evaluation. The reviewer also acknowledges the authors' admission about the limitations, showing an understanding of the authors' situation and a desire to assist. The suggestion is specific and actionable."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Partially Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states the problems with the abstract visual reasoning tasks, which can be seen as an implicit suggestion for improvement. However, the specific action of 'improving' is not explicitly stated, making it less actionable than a suggestion to 'try simpler tasks'. The reviewer identifies the *nature* of the problems (intuitiveness, difficulty, multiple changing factors), which makes the implicit suggestion somewhat concrete.", "grounding_specificity_rationale": "The reviewer mentions 'abstract visual reasoning tasks' but doesn't explicitly identify a specific section, table, figure, or unique aspect of the paper they are referring to. They are referring to the general nature of the tasks. However, the reviewer does specify *what* is problematic about the tasks ( unintuitiveness, difficulty, multiple rows, changing factors), which makes the implicit grounding somewhat specific, as they are pointing to issues within the task description.", "verifiability_rationale": "The reviewer makes a clear statement about their *problems* with the abstract visual reasoning tasks. This constitutes a claim. However, the reviewer does not provide any evidence, justification, or reasoning to support their claims about the problems. They state the issues but don't explain *why* they are problems or what solutions might be. There are no citations or references to support their claims, making the claim 1.", "helpfulness_rationale": "The reviewer's statement about the tasks being 'problematic,' 'intuitively confusing,' and 'overly difficult' reflects a negative perception. While the reviewer identifies a problem, they do not offer any suggestions, solutions, or improvements. The lack of constructive feedback makes the review point less helpful in terms of guiding the authors towards better designs. The reviewer's question about the 'formulation' suggests a desire for improvement but doesn't provide concrete steps on how to achieve it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'Weak supervision could be better evaluated' and 'The generation of authors is also not realistic'. These are clear suggestions for improvement, allowing authors to directly identify modifications they should apply to their draft. The actions are direct and concrete.", "grounding_specificity_rationale": "The reviewer mentions 'weak supervision' and then provides specific examples of what they perceive as 'weakly realistic tweets' and a 'realistic' generation method ('author embeddings are initialized by averaging the corresponding artificial tweets'). This demonstrates a clear identification of the specific part of the paper being addressed and the issues within it.", "verifiability_rationale": "The review point contains claims such as 'Weak supervision could be better evaluated' and 'The generation of authors is also not realistic'. However, it does not provide explicit justification or references to support these claims. The reasoning is implied but not clearly articulated or backed by evidence.", "helpfulness_rationale": "The review point directly points out specific areas for improvement in the evaluation methodology and the author generation process. It provides clear suggestions for better practices, enabling authors to understand the shortcomings and how to address them. The suggestions are actionable and directly relevant to the identified issues."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment identifies a potential weakness ('lack of') but doesn't explicitly state what needs to be improved. The vagueness makes it difficult to pinpoint actionable steps. While the reviewer hints at specific areas ('intermediate processes' and 'comparisons'), they don't provide concrete details on how these should be visualized or compared.", "grounding_specificity_rationale": "The comment refers to 'intermediate processes' and 'comparisons' generally, without specifying which parts of the paper or what kind of comparisons are lacking. This makes it difficult for the authors to pinpoint the specific issue and understand what needs to be done. The language is too broad to be considered fully grounded.", "verifiability_rationale": "The comment states a problem ('lack of') but doesn't provide any evidence or justification for why visualization is missing or why comparisons are inadequate. It's a statement of a potential issue without a claim that requires verification. Therefore, it doesn't offer any verifiable information to the authors.", "helpfulness_rationale": "The review point identifies a potential area for improvement (visualization) but fails to offer any concrete suggestions or actionable steps for the authors. It's a negative statement about a missing element without proposing solutions or providing guidance on how to address the issue. Therefore, it doesn't empower the authors to improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer points out a result but doesn't explicitly state how it's significant or actionable for the authors. They offer a general intuition based on prior work, but don't provide concrete steps or insights on how this result impacts their work or the field. The action is implied but not clearly stated or followed up on.", "grounding_specificity_rationale": "The reviewer mentions prior work and their own understanding of its implications, suggesting they can identify the relevant part of the paper (the result about perturbed gradient descent and its connection to the current algorithm). They can accurately pinpoint the issue being addressed.", "verifiability_rationale": "The reviewer is concerned about the justification of the claim. While they acknowledge the result, they don't provide a clear logical reasoning, common knowledge, or external references to support why this result is significant or how it helps the authors. The claim is presented without sufficient backing.", "helpfulness_rationale": "The reviewer explicitly states they are concerned and find the comment unconvincing. They don't provide specific actionable feedback or explain why the result is important. The comment lacks a clear path for the authors to improve their draft based on the presented information."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of 'including the keypoint detection results' in the 'experiments section'. This is a clear and direct instruction, making it an explicit action. Furthermore, the reviewer directly states the intended location for these results, making the action concrete and actionable for the authors. The authors know exactly where and what to include.", "grounding_specificity_rationale": "The review point explicitly mentions 'experiments section' as the location for the keypoint detection results. This is a literal mention of a specific part of the paper, indicating full grounding. The reviewer also clearly states the action of 'including the results' in this section, making the grounding specific to the exact location where the information should be placed.", "verifiability_rationale": "The review point does not contain a claim in the sense of an opinion or judgment about the quality of the keypoint detection or its importance. It is a suggestion for improvement, not a statement of what is right or wrong. Therefore, it does not have supporting evidence or justification, falling under the 'X' category.", "helpfulness_rationale": "The review point identifies a valid area for improvement in the paper (organizing keypoint detection results) and provides a clear suggestion for action. It is directly actionable and helps the authors understand where to place this information, making it 5 for their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the suggestion to compare with a specific model and provides a reason for this comparison. This indicates a clear action to be taken.", "grounding_specificity_rationale": "The reviewer explicitly names the relevant paper (Jabri et al., ECCV16) and clearly states the reason for the comparison, indicating strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim about ternary potential being the main factor in performance improvement. While this is a claim, the reviewer does not provide any evidence or justification for this claim within the review point itself. The suggestion is more of a request for further analysis based on this implication.", "helpfulness_rationale": "The reviewer's suggestion to compare with a specific model based on their interpretation of ternary potential is relevant and points to a potential area for improvement. However, it is a request for further analysis rather than a direct solution, and the authors would need to interpret the reviewer's statement about ternary potential."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment implicitly asks for clarification on a standard practice in machine learning experiments (whether grid search is performed on the validation set). While it doesn't explicitly state 'Here's how you should do it,' the act of clarifying this point is an implicit action that needs to be taken to understand the experimental setup and potentially identify a flaw.", "grounding_specificity_rationale": "The comment explicitly refers to 'the grid search of learning rate' and 'validation set,' clearly identifying the specific part of the methodology being discussed.", "verifiability_rationale": "The review point is a question, not a statement that requires justification or evidence. Therefore, it has no inherent verifiability.", "helpfulness_rationale": "The question about whether the grid search is done on the validation set is a common point of confusion for researchers. Addressing this question can help the author understand a crucial detail of their experimental setup and potentially identify a flaw in their methodology."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "Highly Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer is asking for clarification on the authors' definition of 'discourse relations' and specifically questioning the high number of 'dobj' relations. While the reviewer doesn't explicitly state an *implicit* action, they are prompting the authors to *explain* their methodology for identifying and categorizing these relations. This is a direct request for action, even if the action is primarily explanatory rather than directive. The reviewer is asking the authors to take *action* by clarifying their understanding of discourse relations.", "grounding_specificity_rationale": "The reviewer directly refers to 'discourse relations' and 'dobj relations' in the context of the authors' treebank. They are also referencing the 'ud/en/pos/' directory, which is a specific location where such information might be stored. The reviewer is asking the authors to *ground* their claim by explaining their criteria for identifying discourse relations and addressing the discrepancy with UD. The reference to 'unique elements' suggests the authors might be using a nonstandard definition. This indicates a clear attempt to ground the discussion in the authors' specific work and the UD framework.", "verifiability_rationale": "The reviewer is asking the authors to *justify* their understanding of discourse relations. They are prompting for *verifiable* evidence or reasoning to support their categorization of relations, particularly the high number of 'dobj' relations. The reviewer is asking the authors to provide *verification* by explaining their methodology and potentially providing examples. This is a request for verifiable information about their approach.", "helpfulness_rationale": "The reviewer is asking the authors to *explain* their methodology for identifying and categorizing discourse relations. This is a direct request for *helpful* feedback, as it aims to clarify a potential ambiguity and improve the authors' understanding of their own resource. The reviewer is asking the authors to provide *helpful* information by explaining their approach and addressing the reviewer's concerns."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question about a specific aspect of the data (racial/economic diversity) and its implications for generalizability. While the action is not entirely explicit in providing a solution, the reviewer clearly identifies a missing element and implies a direction for investigation. The action is also somewhat vague as the exact method of analysis isn't specified.", "grounding_specificity_rationale": "The reviewer refers to 'racial/economic diversity' within the sample. While they don't explicitly point to a specific section, table, or figure, the context strongly implies they are referring to the data they are evaluating. The request is also quite specific, asking about the generalizability of results based on this specific characteristic of the data.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the current sample and its potential impact on generalizability. However, they do not provide any specific examples, citations, or logical reasoning to support this claim. The comment is essentially a question posed without any accompanying evidence or justification.", "helpfulness_rationale": "The reviewer is asking a question that directly addresses a potential weakness in the study's design and limitations. This is relevant information for improving the paper. While they are not providing a solution, they are highlighting a specific area for further consideration and analysis."}
{"actionability_label": "3", "grounding_specificity_label": "4: Mostly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a potential issue with output quality but does not provide explicit or concrete actions the authors should take to improve it. The suggestion is general and lacks specific guidance on how to achieve higher quality.", "grounding_specificity_rationale": "The review mentions recent GAN works and their highquality outputs but does not specify which part of the paper or experiment is lacking. The reference is general and does not point to a specific element of the authors' work.", "verifiability_rationale": "The review does not contain a claim that requires verification. It presents an opinion about the current output quality and suggests an improvement direction, but without specific details or references.", "helpfulness_rationale": "The review identifies a potential weakness in the output quality and suggests an improvement direction. However, it lacks specific, actionable suggestions on how to achieve this. The level of 'room for improvement' is vague, making the feedback less helpful for guiding concrete changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue with the 'soft labels' implementation and its impact on the performance metrics (CRM and Crossentropy). While they express concern about the hyperparameters used, they don't explicitly state what action the authors should take or how to diagnose the problem. The suggestion to 'similarly to' implies a potential solution but doesn't provide concrete steps. Therefore, while the concern is valid, the lack of explicit action or diagnosis makes it not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions 'soft labels,' 'CRM,' and 'Crossentropy,' which are specific terms related to the methodology. They also refer to 'iNaturalist19.' This suggests an attempt to ground the criticism in specific parts of the paper or experiments. However, the connection isn't explicitly stated, and the reviewer doesn't clearly identify the specific section or table being referred to. The concern is implied rather than directly grounded.", "verifiability_rationale": "The reviewer expresses a concern about the hyperparameters used, stating, 'I am concerned that the authors are using subpar hyperparameters, similarly to.' While they express doubt, they don't provide any specific evidence or justification for this concern. The statement is a question rather than a claim supported by reasoning or references. Therefore, the concern is expressed but not verifiably supported.", "helpfulness_rationale": "The reviewer clearly states a concern regarding the 'soft labels' implementation and its impact on the results. They suggest an alternative approach ('similarly to'). This indicates a desire for improvement and suggests a concrete action (checking hyperparameters). The concern is stated, and a potential solution is offered, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "Somewhat Verifiability", "helpfulness_label": "3", "actionability_rationale": "The review point suggests \"add translations to Figure 6\". While it implies an action (adding evaluation for unseen words), it doesn't explicitly state the action or provide concrete steps on how to implement it. The suggestion is present, but the explicit action and detailed methodology are missing.", "grounding_specificity_rationale": "The review point explicitly mentions \"unseen characters\" and \"unseen words\" and refers to \"Figure 6\" and \"translations\". It clearly identifies the specific part of the paper being addressed and provides details about the desired change and the method of implementation. The grounding is strong, and the specificity is also high.", "verifiability_rationale": "The review point presents a suggestion for improvement (adding evaluation for unseen words) and a concrete method for achieving it (translations). While it doesn't provide external references, the suggestion is logically sound and based on common practices in NLP. The claim is that this will help classify unseen words, which is a reasonable and verifiable goal.", "helpfulness_rationale": "The review point directly addresses a potential limitation of the simple experiment (the lack of evaluation for unseen characters) and provides a concrete suggestion for improvement (translations). While the action isn't explicitly stated, the suggestion is clear and actionable. It offers a practical direction for the authors to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the concern about the dataset size and its impact on validating the approach. They also specify the number of images and categories, making it concrete enough to potentially impact the analysis. The action is to investigate the dataset size and its effect on the textual analysis aspect.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'VioT dataset' and the specific numbers of images and categories. This is a clear reference to a specific part of the paper, making it fully grounded. The specificity is high as they are not just guessing but referring to the exact dataset details.", "verifiability_rationale": "The reviewer makes a claim about the dataset size being small for 'texting' validity. However, they do not provide any external references or logical reasoning to support this claim. The verifiability is low as the claim is based on the reviewer's perception without evidence.", "helpfulness_rationale": "The reviewer points out a potential limitation of the dataset size and its impact on validating the approach. While they don't offer a solution, they identify a concrete issue that the authors should consider. The helpfulness lies in highlighting a potential area of concern."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment suggests an interesting experiment (ablation study of number of layers vs performance) but does not explicitly state what action the author should take with their current draft. It proposes a future direction of research rather than a direct instruction or suggestion for improvement. Therefore, it lacks explicit and actionable steps for the author.", "grounding_specificity_rationale": "The comment is general and does not specify which part of the paper or work the ablation study is being applied to. It lacks precision in identifying a specific section, table, figure, or unique aspect of the paper. The author is left to interpret the scope of the suggested experiment, which reduces the clarity of the feedback.", "verifiability_rationale": "The comment is a suggestion for future research or experimentation. It does not make a claim about the current paper or provide evidence about its limitations. It's a recommendation, not a critique or assertion. Therefore, it doesn't contain a claim that can be verified.", "helpfulness_rationale": "The comment suggests an interesting experiment but does not directly address any specific weaknesses or issues in the author's current draft. It's a suggestion for future exploration, not a critique or improvement suggestion for the existing work. Therefore, it doesn't provide meaningful feedback for improving the current paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a need for 'intuitive explanations' and points out issues with figure captions, indicating a desire for actionable improvements. However, the request lacks specific details on *how* to achieve these improvements. The reviewer mentions 'more intuitive explanations' and 'additional explanations and legends,' but doesn't specify the exact nature of these explanations or the problems with the figure elements.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'mathematical derivations' and 'figure captions and legends (e.g., explain the colors in Fig. 2)' as areas needing improvement. This clearly identifies the specific parts of the paper being addressed. The reviewer also states that 'Fig. 1 and 2 did not contribute much to my understanding,' indicating a clear specification of the issues within these figures.", "verifiability_rationale": "The reviewer makes a claim that the paper is 'hard to follow' and that 'more intuitive explanations on the mathematical derivations are needed.' This claim is supported by the reviewer stating that 'Figure captions are lacking, and require additional explanations and legends (e.g., explain the colors in Fig. 2). Fig. 1 and 2 did not contribute much to my understanding, and I had to read the text few times instead.' The reasoning, common knowledge, and external references (the reviewer's own experience) all support the claim.", "helpfulness_rationale": "The reviewer provides a clear and actionable feedback. They identify specific areas where the paper is unclear (hard to follow, lack of intuitive explanations, missing figure captions, unclear legends) and suggest concrete improvements (more intuitive explanations, figure legends). The reviewer's statement that 'I had to read the text few times instead' highlights the impact of the lack of clarity on their understanding, demonstrating the helpfulness of the feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review points out a valid concern (sensitivity to hyperparameters) but lacks specific details about which hyperparameters are affected and how to address them. It suggests reconsidering the rating, which is a vague action without any concrete steps.", "grounding_specificity_rationale": "The review does not specify which part of the paper is being affected by the hyperparameter sensitivity issue. It's a general concern about the methodology.", "verifiability_rationale": "The review makes a claim about the sensitivity of empirical results to hyperparameter choices but doesn't provide any specific evidence, examples, or references to support this claim. The suggestion to reconsider the rating is a potential action but lacks justification.", "helpfulness_rationale": "The review raises a valid and relevant concern about a crucial aspect of the method. It encourages the authors to reconsider their hyperparameter choices, which is a helpful direction. However, it doesn't offer specific steps or guidance on how to address this issue."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point directly states a problem: 'This work utilizes existing attack methods on a surrogate model. It is similar to use the transferability of adversarial examples directly.' This statement identifies a lack of novelty and suggests the authors need to highlight their contribution. While the reviewer doesn't explicitly say 'the paper needs to be more novel', the implication is clear. The action is to point out the existing methods and transferability, which the authors should acknowledge as a basis for their work.", "grounding_specificity_rationale": "The review point mentions 'existing attack methods,' 'surrogate model,' and 'transferability of adversarial examples.' These are specific technical terms and concepts related to the paper's topic. The reviewer is referencing specific aspects of the method, making the grounding quite explicit.", "verifiability_rationale": "The review point makes a claim: 'The author needs to further claim the novelty and contribution of the proposed method.' This claim is based on the observation of using existing methods and the transferability of adversarial examples. While the reviewer doesn't provide a specific citation to support this claim, the reasoning is logical: if the method relies on wellestablished techniques, demonstrating novelty requires further justification. The claim is based on a logical inference rather than a direct statement of a gap.", "helpfulness_rationale": "The review point identifies a key weakness: the lack of demonstrated novelty given the reliance on existing methods and transferability. While it doesn't offer a solution, it clearly points out a crucial area for the authors to address. The reviewer is guiding the authors to acknowledge the limitations of their approach and the need for a stronger contribution. This provides a clear direction for improvement, even if it's not a specific solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly names two specific issues: the small text in Table 1 and the missing gradient symbol in Algorithm 1. This directly tells the authors what needs to be changed. The reviewer also implies the actions to be taken: improve the readability of Table 1 and add the missing gradient symbol in Algorithm 1. These actions are concrete and actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 1' and 'Algorithm 1', providing clear grounding. Furthermore, they specify the *issues* within these tables/algorithm, making the grounding very specific. The reviewer not only identifies the location but also the nature of the problems.", "verifiability_rationale": "The reviewer implies that the small text in Table 1 hinders understanding and that the missing gradient symbol makes the algorithm description incomplete. While not providing direct evidence, these are logical inferences. The reviewer's comments suggest a desire for better clarity and completeness in the paper.", "helpfulness_rationale": "The reviewer points out specific areas for improvement in the paper's presentation and content. This is directly actionable and likely to benefit the authors. The reviewer's comments are focused on concrete issues within the paper that the authors can address."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a limitation in the practical applicability of the proposed methods, specifically regarding their performance in highdimensional settings. They highlight that the algorithm requires solving several Linear Programs (LPs) in high dimensions, where a crucial parameter is not easily calculable. This limitation is mentioned as a concern, and the reviewer notes that the experiments are conducted on smallscale datasets, which further supports the claim that the methods might not be practically useful for high dimensions. While the reviewer doesn't explicitly state a solution, they identify a significant gap in the current work. The reviewer's statement about the algorithm requiring solving several LPs in high dimensions, each involving a parameter that is not easily calculable, is a clear indication of an actionable issue. The reviewer also mentions the experiments being performed on very small scale datasets, which further supports the claim that the methods might not be practically useful for high dimensions. The reviewer's statement about the algorithm requiring solving several LPs in high dimensions, where a parameter is not easily calculable, is a clear indication of an actionable issue. The reviewer also mentions the experiments being performed on very small scale datasets, which further supports the claim that the methods might not be practically useful for high dimensions.", "grounding_specificity_rationale": "The reviewer mentions \"high dimensions,\" \"parameter that is not easily calculable,\" and 'small scale datasets\" as issues. While these are relevant, the reviewer does not explicitly identify a specific section, table, or figure in the paper where these problems are discussed or manifest. The reviewer refers to these aspects generally, making the grounding somewhat weak. The reviewer mentions \"high dimensions,\" \"parameter that is not easily calculable,\" and 'small scale datasets\" as issues. While these are relevant, the reviewer does not explicitly identify a specific section, table, or figure in the paper where these problems are discussed or manifest. The reviewer refers to these aspects generally, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer states that the authors do not quite discuss computational aspects in detail (other than a short discussion in the appendix), but it is unclear whether their proposed methods can be made practically useful for high dimensions. As stated, their algorithm requires solving several LPs in high dimensions, each involving a parameter that is not easily calculable. This is reflected in the authors\u00e2\u0080\u0099 experiments which are all performed on very small scale datasets. The reviewer states that the authors do not quite discuss computational aspects in detail (other than a short discussion in the appendix), but it is unclear whether their proposed methods can be made practically useful for high dimensions. As stated, their algorithm requires solving several LPs in high dimensions, each involving a parameter that is not easily calculable. This is reflected in the authors\u00e2\u0080\u0099 experiments which are all performed on very small scale datasets. The reviewer states that the authors do not quite discuss computational aspects in detail (other than a short discussion in the appendix), but it is unclear whether their proposed methods can be made practically useful for high dimensions. As stated, their algorithm requires solving several LPs in high dimensions, each involving a parameter that is not easily calculable. This is reflected in the authors\u00e2\u0080\u0099 experiments which are all performed on very small scale datasets.", "helpfulness_rationale": "The reviewer raises a valid concern about the practical applicability of the proposed methods in highdimensional settings. They point out a theoreticaltechnical limitation (solving LPs in high dimensions with uncalculable parameters) and link it to the experimental setup (small datasets). This highlights a crucial gap in the current work and provides a valuable point for the authors to address. The reviewer raises a valid concern about the practical applicability of the proposed methods in highdimensional settings. They point out a theoreticaltechnical limitation (solving LPs in high dimensions with uncalculable parameters) and link it to the experimental setup (small datasets). This highlights a crucial gap in the current work and provides a valuable point for the authors to address. The reviewer raises a valid concern about the practical applicability of the proposed methods in highdimensional settings. They point out a theoreticaltechnical limitation (solving LPs in high dimensions with uncalculable parameters) and link it to the experimental setup (small datasets). This highlights a crucial gap in the current work and provides a valuable point for the authors to address."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "2: 3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states potential errors in the mathematical formulation and suggests corrections. While they don't directly tell the author *what* to do, the *action* for the author is clear: reexamine the derivation around Line 502. The potential errors are specific to the identified mathematical elements and their locations.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Line 502' and the specific mathematical expressions where potential errors might exist. This clearly identifies the specific part of the paper being addressed, making the grounding very strong. The errors are also specific to the identified mathematical elements.", "verifiability_rationale": "The reviewer makes a claim about potential errors in the mathematical formulation and provides specific suggestions for correction. However, they do not provide any external references, logical reasoning, or examples to *justify* why they believe these are errors. The claim is based solely on their interpretation of the formulas.", "helpfulness_rationale": "The reviewer identifies potential errors in a specific mathematical expression and provides concrete suggestions for correction. This is valuable information for the author and directly addresses a potential issue in their work. While it doesn't offer a complete overhaul strategy, it points in a specific direction for improvement."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point does not explicitly state an action or provide a clear path for the authors to take. While the reviewer is prompting the authors to consider a specific implementation detail (parameter sharing) and a related experiment, they are not directly instructing them on how to do so. The reviewer is asking a question, which implies a desire for clarification rather than a direct action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 7.1' and the 'ResNet' within that section. They are also asking about a specific implementation detail ('parameter sharing'). This provides a clear and specific reference point within the paper. The reviewer is even suggesting a *why* by connecting it to a baseline experiment and ODEs, further specifying the area of interest. Therefore, the grounding is strong.", "verifiability_rationale": "The review point is not making a claim that can be verified. It is a question prompting the authors to consider a specific implementation detail and a related experiment. There is no assertion of truth or falsity, and no references to external sources are provided. It is a suggestion for further investigation, not a statement of fact.", "helpfulness_rationale": "The review point is 5 because it directly addresses a potential ambiguity in the experimental setup (parameter sharing) and suggests a relevant followup experiment. This provides the authors with a concrete question to consider and a direction for further exploration. It highlights a potential weakness in the methodology and offers a constructive suggestion for improvement. This type of feedback is valuable for guiding the authors' work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly points out a specific implementation detail (trimming questions after the first 10) and clearly states why it seems like an odd choice for a bagofwords model. This is a direct and actionable point for the authors, allowing them to understand the potential impact of this design choice on their data.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'L254,' indicating a precise location in the paper. They also clearly explain the potential negative consequence of the trimming, which is the loss of information from questions beyond the first 10. This level of detail makes the comment highly specific to the relevant part of the paper.", "verifiability_rationale": "The reviewer makes a claim that 'trimming the questions after the first 10 seems like an odd design choice.' While this is a valid observation, the reviewer does not provide specific external references or logical reasoning to *justify* why it's an 'odd design choice' beyond the potential for information loss. The support is somewhat vague and lacks depth.", "helpfulness_rationale": "The reviewer's comment is 3 as it points out a potential issue with the data processing pipeline (trimmed questions). While they don't provide concrete evidence of negative consequences, they raise a valid concern about the potential loss of information. This constructive critique can guide the authors in considering alternative approaches or further investigation."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a problem (antiquated model/method) and its impact. It also mentions \"baseline algorithms/methods are also antiquated.\" This suggests a potential action, but it's vague. The reviewer doesn't explicitly state what needs to be done. While the problem is identified, the specific steps to address it are not provided. The reviewer identifies a weakness, but the action is not clearly defined or concrete.", "grounding_specificity_rationale": "The reviewer refers to \"this framework\" and \"baseline algorithms/methods.\" While they don't name a specific section, the context strongly implies a specific part of the paper. However, the reviewer does not pinpoint a unique element or section within the paper. They refer to a category of things rather than a specific instance.", "verifiability_rationale": "The reviewer makes a claim about the GNN model/method and the baseline algorithms/methods being \"antiquated.\" However, they do not provide any evidence or justification for this claim. They state the problem but don't explain why it's a problem or where the limitations lie. The claim is made without supporting evidence or reasoning.", "helpfulness_rationale": "The reviewer raises a valid concern about the methodology. However, the lack of specific guidance on how to improve it limits the feedback's practical value. While the problem is identified, the reviewer doesn't offer concrete suggestions on how to address it. The feedback is relevant but lacks actionable steps, making it less helpful overall."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The reviewer is asking for a specific explanation of how the proposed method produces the explanation for Figure 1, stating it seems to require additional postanalysis. This implies the explanation is implicit and vague, as the authors need to infer the mechanism from the reviewer's description rather than it being directly stated in the paper.", "grounding_specificity_rationale": "The reviewer is asking the authors to identify the specific part of the paper related to Figure 1 where the explanation is located. They are implying this information is missing or unclear, making the grounding weak. The reviewer also implies the explanation is specific to the NO2 group, but doesn't explicitly state it within the paper.", "verifiability_rationale": "The reviewer is making a claim about the method's ability to identify the NO2 group in Figure 1. While the paper describes the method identifying patterns, it doesn't explicitly verify or prove that this method specifically leads to the identification of the NO2 group. The connection is implied but not explicitly supported by evidence or reasoning within the paper.", "helpfulness_rationale": "The review point is unclear and requires the authors to infer the mechanism of explanation for Figure 1. This lack of clarity and the implication of needing additional postanalysis make the review point less directly helpful for improving their draft. The authors have to spend extra effort to understand the method's application in this specific case."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer identifies specific areas of the experiment that are problematic (using pseudo feature importance, reliance on Prop 3.2 and perturbation value, and the difference in methods being only the number of perturbations). However, the reviewer does not provide explicit instructions or concrete steps on how to address these issues. The suggestions are general and lack specific implementation details.", "grounding_specificity_rationale": "The reviewer refers to 'an experiment' and 'pseudo feature importance' in general terms. They do not specify which part of the paper or method they are referring to. There is no mention of a unique element or section that the reviewer is specifically addressing.", "verifiability_rationale": "The reviewer makes claims about the limitations of the experiment and the need for different methods and metrics. However, these claims are not supported by specific evidence or references within the review point itself. The reviewer suggests improvements but doesn't provide logical reasoning, common knowledge, or external references to back up their criticisms.", "helpfulness_rationale": "The reviewer points out potential weaknesses in the experiment. While these weaknesses are valid concerns, the reviewer does not provide actionable feedback on how the authors can improve their draft based on these weaknesses. The suggestions are general and lack specific implementation details, making the feedback less helpful for immediate action."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states a potential issue with nonconvexity and suggests it might not be an issue if the function Z has 'good properties'. This constitutes an explicit action, as the reviewer points out a potential problem and suggests a possible solution or mitigation. However, the term 'good properties' is vague and lacks specific details, making the action less concrete.", "grounding_specificity_rationale": "The comment refers to 'the function Z' in the context of nonconvexity and SGD convergence. While it doesn't explicitly name a section, table, or figure, the reference is clear and directly points to the function being discussed. This provides weak grounding as the authors can infer the specific part being addressed. However, the comment doesn't specify *what* these 'good properties' are, making it underspecific regarding the issue.", "verifiability_rationale": "The comment contains a claim: 'Nonconvexity may not be an issue for the SGD to converge, if the function Z has some good properties.' This is a statement that can be verified. However, the comment does not provide any justification, examples, or references to support this claim. The reasoning is presented as a possibility without evidence, making it 1.", "helpfulness_rationale": "The comment raises a valid point about the potential impact of nonconvexity on SGD convergence, which is a relevant issue for authors training models. However, the suggestion that this might not be an issue if the function has 'good properties' is vague and lacks specificity. It doesn't provide concrete guidance on what constitutes 'good properties' or how to identify them in the context of their loss function. Therefore, while the comment identifies a potential problem, it doesn't offer actionable improvements, making it less helpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the incorrect colors and table number in the SuppMat references and clearly indicates the desired corrections. The reviewer directly tells the authors what needs to be changed and where. The actions are direct and unambiguous.", "grounding_specificity_rationale": "The reviewer accurately identifies the specific lines and tables in the SuppMat that contain the errors. They not only pinpoint the sections but also clearly state what is wrong and what needs to be done. The grounding is strong because the reviewer can easily identify the referenced part, and the specificity is high because the issues are clearly defined and the fixes are explicit.", "verifiability_rationale": "The reviewer points out factual errors in the SuppMat. While the errors are verifiable, the justification for the specific changes (green color and inclusion in Table 4) is not explicitly provided. The reviewer simply states what should be done, but doesn't explain *why* these are the correct approaches. Therefore, it's 4 as the errors are factual, but the reasoning behind the specific changes is missing.", "helpfulness_rationale": "The review point is exceptionally helpful. It directly identifies specific errors in the SuppMat and provides clear, actionable steps for the authors to correct them. The reviewer is not just pointing out a problem; they are guiding the authors to the exact locations and the exact changes needed. This level of detail is highly beneficial for improving the clarity and correctness of the paper."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point is a statement of opinion, not a direct instruction on what to do. It suggests that more comprehensive and dataintensive analysis would be beneficial, but it doesn't specify how to achieve this or what aspects of the paper need improvement to make this happen. The suggestion is implied, not explicitly stated as 'You should add a more comprehensive analysis.'", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or element that needs improvement. It is a general suggestion about the type of analysis that could be beneficial. There is no mention of a specific section, table, figure, or unique aspect of the paper being addressed.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for improvement rather than a statement that something is wrong or needs to be changed. There is no logical reasoning, common knowledge, or external references provided to support the suggestion itself as a necessary or valid critique of the current work.", "helpfulness_rationale": "The review point offers a suggestion for improvement, which could be seen as potentially helpful in the long run. However, it lacks specificity and does not directly address the current state of the draft. It does not pinpoint a specific weakness or improvement area, making it less helpful than a review that directly critiques the paper. The suggestion is general and does not provide actionable feedback on the current work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states 'The experimental settings are not mentioned properly' which is a direct action. However, it does not specify what aspects of the experimental settings are missing or how the authors should revise them. This makes it somewhat vague on how to implement the action.", "grounding_specificity_rationale": "The comment identifies 'experimental settings' as the area needing improvement. While it doesn't specify a particular section, table, figure, or unique element, it clearly points to a general area within the paper. This can be considered weakly grounded as the authors can infer the section where experimental details are usually provided. The specificity is limited as it doesn't detail what is missing within those settings.", "verifiability_rationale": "The comment contains a claim: 'result reproducibility is critical using the provided information.' This claim is not verifiable based on the provided text as there are no logical reasoning, common knowledge, or external references provided to support it. The statement is presented as a judgment about the importance of information rather than a claim requiring justification.", "helpfulness_rationale": "The review point directly identifies a critical issue: the lack of proper mention of experimental settings, which hinders result reproducibility. This is a significant problem for the authors, and the suggestion to provide code is a concrete and helpful step they can take. The comment clearly points to a practical obstacle they face."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks 'Why is it discarded?' and 'What are the challenges of including it in the evaluation?' These are direct requests for explanation and justification of the exclusion of online learning and RL. The authors could, and should, have provided more detail on the reasoning behind these choices.", "grounding_specificity_rationale": "The reviewer directly asks about 'retraining cost' and 'other challenges', referencing the 'online learning formulation'. While the paper doesn't explicitly name a section 'online learning formulation', the context strongly implies they are referring to the aspects discussed in that potential section. The reviewer is also asking 'why' these are discarded, which implies a lack of clarity in the paper regarding these aspects.", "verifiability_rationale": "The reviewer is asking 'Why is it discarded?' and 'What are the challenges of including it in the evaluation?'. This is a question about the paper's methodology and analysis. While the paper claims to overlook practical considerations, it doesn't provide a detailed explanation of *why* online learning is excluded or how retraining costs are handled. This requires external knowledge or further investigation to understand the authors' reasoning.", "helpfulness_rationale": "The reviewer is asking 'Why is it discarded?' and 'What are the challenges of including it in the evaluation?'. This is a request for clarification and justification of the exclusion of online learning and RL. While it's important for the authors to address these points, the review point itself doesn't *directly* tell them how to improve their method. It highlights areas where the paper could be clearer."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests actions: 'they should be cited' and 'link existing work to this'. These are direct and clear instructions for the authors. While the reviewer doesn't explicitly state 'do X', the implication is strong. The reviewer is not inferring, but rather stating the desired outcome and how to achieve it.", "grounding_specificity_rationale": "The review point explicitly mentions 'RL for architecture search and/or as optimizers for learning' as a specific area to connect. This provides a clear reference point for the authors. The reviewer is not making a general comment but rather focusing on a specific technical aspect.", "verifiability_rationale": "The reviewer makes a claim about the relevance of linking existing work to continual learning but does not provide any external references or logical reasoning within the provided text snippet to support this claim. The reviewer is stating an opinion or judgment about the potential value of this connection. There is no verification provided within the review point itself.", "helpfulness_rationale": "The review point provides clear suggestions for improvement, such as 'citing missing works' and 'linking existing work'. These are actionable and directly aimed at enhancing the draft. The reviewer is not just pointing out a problem but also offering concrete solutions. The suggestions are relevant and directly address the identified issue."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment does not explicitly state what the reviewer intends to do with the feedback or how the feedback should be applied. It raises a question about the process of feedback rather than providing a direct instruction for improvement. Therefore, it lacks explicit and concrete actionable steps for the authors.", "grounding_specificity_rationale": "The comment does not specify which aspect of the paper the reviewer is referring to when they talk about 'autogenerated' feedback. It is a general question about the feedback process. Therefore, it does not identify a specific part of the paper being addressed.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a question about the feedback process, not a statement that needs to be supported by evidence. Therefore, it does not make any claims that are verifiable.", "helpfulness_rationale": "The comment raises a valid point about the diversity of feedback and the potential need for multiple rounds of review. However, it does not directly provide specific suggestions or guidance on how to achieve this diversity or implement the feedback process. Therefore, it is not directly helpful in improving the draft itself."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the intention to make the main text clearer about the additional experiments in the supplement and to summarize their results. These are direct actions the authors should take. The reviewer's language is clear and prescriptive, indicating a direct action to improve the paper.", "grounding_specificity_rationale": "The reviewer's comment is a general suggestion about the clarity of the main text regarding supplementary experiments. They do not explicitly point to a specific section, table, or figure. While the reviewer implies a lack of clarity, they cannot confidently identify the exact location of the missing information. The grounding is weak because the authors cannot pinpoint the specific part they need to improve.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement, not a claim requiring verification. They are proposing changes to how information is presented in the main text. There are no external references or logical reasoning provided to justify why the main text should be made clearer about supplementary experiments. The comment is a suggestion, not a statement of fact that needs verification.", "helpfulness_rationale": "The reviewer's comment is a positive suggestion aimed at helping the authors by making the paper more understandable. They are proposing a concrete action (improving clarity and summarizing results) that directly benefits the authors. While it's a suggestion, it is clearly aimed at improving the authors' experience and the quality of their work, making it helpful."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'Important references are missing' and names specific relevant works (Gated Fully Fusion for Semantic Segmentation, AAAI'20 and EfficientFCN: Holisticallyguided Decoding for Semantic Segmentation, ECCV'20). It also suggests a type of comparison ('I encourage the authors to have a comprehensive comparison with these work'). This provides clear and actionable feedback for the authors.", "grounding_specificity_rationale": "The review mentions the missing references but doesn't specify the exact section, table, or figure where these references should be added. While it identifies the *type* of comparison to be made, it doesn't pinpoint the exact part of the paper being addressed in terms of content. The grounding is present in the general area of missing references, but the specificity is limited.", "verifiability_rationale": "The review contains a claim: 'the GFF1 and EfficientFCN2 both aims to implement the fast semantic segmentation method in the encodedecoder architecture. I encourage the authors to have a comprehensive comparison with these work.' This claim is partially supported by the naming of the specific papers and the suggestion for comparison. However, it lacks external references to back up the claims about the methods implemented in GFF and EfficientFCN.", "helpfulness_rationale": "The review clearly identifies a weakness in the manuscript (missing important references) and provides a suggestion for improvement (a comprehensive comparison with specific works). While it doesn't provide specific details on *where* in the paper these references should be added, it offers a concrete direction for the authors to follow. The 'see above' instruction also adds a degree of helpfulness by directing the authors to relevant information."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review points out that the slight improvement doesn't support the claim. While it implies the authors should reevaluate their prompts, it doesn't explicitly state what changes to make or how to achieve improvement. The action is implicit.", "grounding_specificity_rationale": "The reviewer refers to \"our proposed prompts\" generally, without specifying which prompts, how they were designed, or what aspects of them are being questioned. The connection to Table 6 and 7 is implied but not explicitly stated.", "verifiability_rationale": "The reviewer makes a claim about the effectiveness of the prompts based on experimental results and then directly challenges this claim by pointing to the data in Tables 6 and 7. The reasoning is clear and directly links the claim to the evidence.", "helpfulness_rationale": "The reviewer clearly identifies a discrepancy between the claims made about the results and the actual data presented in the tables. This highlights a potential issue in the paper's presentation or interpretation of results, prompting the authors to be more careful in their claims."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a *comparison* with two specific papers. This is an implicit action, as the authors are encouraged to implement and evaluate their model against these baselines. However, the *how* of this comparison is not explicitly stated, making it less actionable.", "grounding_specificity_rationale": "The reviewer mentions the names of two specific papers, 'Multilingual unsupervised neural machine translation with denoising adapters' and 'MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer'. This indicates that the reviewer can identify the specific parts of the paper (the related works) being referenced. However, the *purpose* of mentioning these papers isn't entirely clear within the review point itself. The connection to the *current work* isn't explicitly stated, making the grounding somewhat weak. The *specificity* of the comparison is also low, as the reviewer doesn't specify *why* these papers are relevant or *what* aspects of their methods should be compared.", "verifiability_rationale": "The review point states: 'It is also recommended to compare the performance with \"Multilingual unsupervised neural machine translation with denoising adapters. \" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\"', which clearly presents a claim (a recommendation). However, the review point does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no justification for *why* this comparison is suggested.", "helpfulness_rationale": "The review point suggests a *comparison* with two papers. This is a helpful suggestion as it provides context and allows for performance assessment relative to existing work. However, the review point lacks specifics on *how* to perform this comparison (e.g., specific evaluation metrics, code structure). While the core idea is helpful, the lack of implementation details makes it less directly helpful for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states 'There could be many different designs of it' and then implicitly suggests exploring 'sampling intervals and sample size' as potential improvements. While the intention is clear, the specific action and its implementation are not detailed.", "grounding_specificity_rationale": "The comment refers to 'Cycle FC align features at different spatial locations to the same channel' as a process within the paper. However, it doesn't explicitly name a specific section, table, figure, or unique aspect of the paper it's addressing. The issue 'analysis is slightly insufficient' is a general statement about the analysis, not a specific element within it. The suggestion to explore 'sampling intervals and sample size' is a potential area of improvement, but not a direct identification of a problematic element within the analysis.", "verifiability_rationale": "The comment contains the claim 'analysis is slightly insufficient'. However, it doesn't provide any specific evidence or justification for this claim within the review point itself. The suggestion to explore 'sampling intervals and sample size' is a potential improvement, but the review point doesn't logically connect this exploration to the identified insufficiency of the analysis.", "helpfulness_rationale": "The review point identifies a potential area for improvement in the analysis section and suggests exploring 'sampling intervals and sample size' as a way to address it. While the suggestion points to a potential direction, it lacks concrete details on how to implement this exploration or what specific improvements to expect. The feedback is somewhat general and lacks actionable steps."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the concern about the numerical instability of Algorithm 1 due to the use of the Vandermonde matrix. This indicates a clear and direct action that the authors should take: investigate the numerical properties of the algorithm and potentially modify it or use alternative techniques. The reviewer identifies the specific algorithm and the matrix as the source of the problem, making the action quite explicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Algorithm 1' and 'Vandermonde matrix' as the specific part of the paper being addressed. This is a strong form of grounding, as the reviewer can accurately pinpoint the section and technical term being discussed. Furthermore, the reviewer specifies the *issue* (numerical instability) related to this specific component, adding to the specificity of the criticism.", "verifiability_rationale": "The reviewer claims that Algorithm 1 is numerically unstable due to the illconditioning of the Vandermonde matrix. This is a claim that can be supported by referencing known properties of Vandermonde matrices. While the reviewer doesn't provide specific external references within this review point, the general knowledge about the numerical instability of Vandermonde matrices serves as sufficient justification for their claim. The claim is wellsupported by established knowledge, making it 3.", "helpfulness_rationale": "The reviewer's request for experimental results is a valuable suggestion for the authors to address their concern about the numerical stability of Algorithm 1. However, the *review* itself, as presented, does not directly guide the authors on how to conduct these experiments or what specific experiments to run. The reviewer is pointing out a potential issue that the authors might address in future work or by conducting experiments, but the review itself doesn't actively improve the paper's content or methodology. Therefore, the helpfulness of this specific review point is limited."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "1", "actionability_rationale": "The review points out a problem (lack of standard deviations) and its consequence (uncertainty about the best method). While it doesn't directly suggest a solution, it highlights an issue that needs addressing. Therefore, it is 3 in identifying the missing information.", "grounding_specificity_rationale": "The review refers to 'Random Forest' and 'performances,' which are general terms. It doesn't explicitly name the specific table, figure, or section where this information is missing. Therefore, it is weakly grounded.", "verifiability_rationale": "The review makes a claim: 'No standard deviations are displayed. Thus, we are not sure...'. This claim is logically connected to the missing information. Therefore, it is verifiable.", "helpfulness_rationale": "The review points out a lack of information and its negative impact on confidence in the results. This directly translates to a lack of actionable feedback for the authors. Therefore, it is not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "6: X", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a direct question about the generalizability of the approach, which implies a potential limitation in the current specific setting. By asking how the approach can be extended, they are suggesting an actionable direction for future work. This fits the definition of actionability, where the reviewer points out a limitation and proposes a solution.", "grounding_specificity_rationale": "The reviewer refers to 'your setting' which is a general description of the problem and approach. They do not explicitly point to a specific section, table, figure, or unique aspect of the paper. While the question is relevant, the lack of a precise reference makes the grounding weak.", "verifiability_rationale": "The reviewer is posing a question about the generality of the approach, not making a claim that can be verified. They are asking what changes would be needed, which is a question without a clear assertion. Therefore, it does not fit the criteria for a verifiable claim.", "helpfulness_rationale": "The reviewer is highlighting a limitation of the current approach (its specific setting) and suggesting a potential direction for improvement (generalization). This points out a relevant weakness and offers a constructive suggestion, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification on a specific detail (the feature extractor) but is not explicitly stating an action the authors should take. While the information is potentially actionable, the request itself is implicit.", "grounding_specificity_rationale": "The reviewer refers to 'each region' which is a broad term and could refer to all regions or a specific type. This lack of specificity makes it weakly grounded. The comment does not explicitly state what is wrong with the dimensionality or suggest improvements, focusing solely on the feature extractor.", "verifiability_rationale": "The reviewer is not making a claim that needs verification. They are simply asking for information. There is no assertion of correctness or a request for justification.", "helpfulness_rationale": "The request for information about the feature extractor is specific. However, its helpfulness depends on the authors' familiarity with different feature extractors and their typical output dimensions. If the authors are already familiar, the information might be redundant. If they are not, it could be 5. Therefore, the helpfulness is subjective."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point suggests adding more details but doesn't specify how or where these details should be included. It's a desire for more information, not a directive.", "grounding_specificity_rationale": "The review point is very general and doesn't specify which part of the paper it's referring to. It lacks specificity in identifying a particular section, table, figure, or unique element.", "verifiability_rationale": "The review point is a suggestion for improvement, not a claim that something is wrong. It lacks a claim that needs verification.", "helpfulness_rationale": "The review point is a suggestion, not a critique identifying a specific weakness. It doesn't provide actionable feedback on how to improve the paper. It's a desire for more information, not a critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking for justification for a specific numerical threshold (p < 0.4). While they are prompting for an action (understanding the choice), the explanation is not explicitly stated, and the request is quite general, making it vague on how to apply the information. Therefore, it is 3 but lacks concrete details on how to implement the inferred action.", "grounding_specificity_rationale": "The reviewer is implicitly referencing the algorithm and the variable 'p' when asking about the threshold. They are not explicitly pointing to a specific section, table, or figure. However, the value itself (p < 0.4) is clearly defined and specific to the algorithm's parameters. Therefore, it is 1 but is specific.", "verifiability_rationale": "The review point does not contain a claim. It is a question seeking information. Therefore, it does not have verifiability in the defined sense.", "helpfulness_rationale": "The reviewer is asking for justification for a specific numerical threshold. This is valuable information for the authors as it helps them understand the rationale behind the algorithm. However, the request is quite general and doesn't provide specific guidance on how to change the value or why this specific value is optimal. Therefore, it is 2 as it seeks information rather than providing direct action."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the actions needed: 'explain why there are negative numbers in Figure 1' and 'analyze the implications of Figure 2 and Figure 3'. These actions are concrete, specifying exactly what should be done.", "grounding_specificity_rationale": "The reviewer explicitly and accurately identifies the specific parts of the paper being addressed: 'Figure 1', 'Figure 2', and 'Figure 3'. This is full grounding as the sections are directly mentioned. The reviewer also specifies the nature of the issues: 'why there are negative numbers' and 'the implications', adding to the specificity.", "verifiability_rationale": "The reviewer makes a claim by stating that the figures 'fail to provide explanations or analysis'. This claim is verifiable as it points to a clear omission in the paper. The reviewer also implicitly suggests that the figures need to be 'explained and analyzed', providing a basis for verification.", "helpfulness_rationale": "The review point is 5 as it directly points out missing information and asks specific questions about the figures. The reviewer provides clear actions (explain and analyze) and specifies the aspects of the figures to be addressed (negative numbers, implications). This is actionable and constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review states \"the motivation behind applying CMD in federated learning seems a bit unclear and could benefit from a more explicit demonstration or explanation.\" While this suggests the authors should investigate the 'why', the action of investigating is not explicitly stated. The reviewer identifies a potential area for improvement but doesn't provide a concrete task for the authors to perform.", "grounding_specificity_rationale": "The review refers to \"CMD in federated learning\" generally. It does not specify a particular section, table, figure, or a unique aspect of the CMD application. The issue of \"unclear motivation\" is a highlevel concern about the overall approach rather than a specific detail within a method description.", "verifiability_rationale": "The review does not make a claim that requires verification. It expresses a suspicion or uncertainty about the motivation behind using CMD in federated learning, but it does not propose a specific error, improvement, or missing information that needs to be substantiated.", "helpfulness_rationale": "The review points out a potential area for improvement (clarifying the motivation behind CMD). However, it doesn't provide concrete suggestions or a clear path for the authors to take. The action is implied, but not explicitly stated. This leaves the authors with a vague idea but no concrete steps to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'Lack of Analysis' and 'Lack of comparison' regarding the data augmentation methods and their approach compared to other paraphrasing techniques. These are clear statements of what *should* be done, making the comment actionable. However, the reviewer does not specify *what aspects* of the analysis are missing or *how* the comparison should be done, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'data augmentation methods' and specifically mentions 'EDA or LLMbased paraphrasing' as examples. This indicates that the reviewer is referring to specific parts of the paper being discussed. However, the reviewer does not specify *what specific aspects* of these methods or the comparison process are lacking. Therefore, while the comment is grounded in identifying specific methods, it is somewhat specific in identifying the *what* but less specific about the *how*.", "verifiability_rationale": "The reviewer makes a claim by stating 'There is insufficient analysis of the effectiveness of each data augmentation method' and 'Comparing their approach to other paraphrasing methods... would clarify the unique advantages of their method.' These are statements that can be verified. However, the reviewer does not provide logical reasoning, common knowledge, or external references to support these claims. The lack of justification makes the claim 3 but not 5.", "helpfulness_rationale": "The reviewer clearly identifies a gap in the analysis and suggests a specific improvement by recommending a comparison to other paraphrasing methods. This is a constructive criticism that directly points to an area for the authors to improve their work. The reviewer's point is directly aimed at enhancing the paper, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a specific area for improvement (lack of an ablation study for MMD) and suggests alternative ablation targets (typical knowledge distillation loss and distilling a Hydra architecture with MMD loss). While the reviewer points out the lack of clarity regarding the effect of each component, the suggested alternatives are concrete and actionable. The reviewer implies that the authors should perform ablation studies using these alternative losses to understand the contribution of the MMD component. This suggests a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'learning with MMD' and then narrows down the specific issue to 'the lack of an ablation study for the MMD component'. They further specify the potential ablation targets as 'typical knowledge distillation loss' and 'distilling a Hydra architecture with MMD loss'. This clearly identifies the section and the specific components being discussed, making the grounding very precise.", "verifiability_rationale": "The reviewer provides a clear claim: 'Without an ablation study, it is hard to see the net effect of each component.' They then provide reasoning by stating that 'ablation studies are crucial for understanding the contribution of individual components in a system.' They further suggest specific alternatives for the ablation study, which are logically derived and verifiable. The claim is supported by logical reasoning and specific suggestions, making it verifiable.", "helpfulness_rationale": "The reviewer clearly identifies a problem (lack of understanding of the MMD component's effect) and provides specific suggestions for improvement (ablation studies with alternative losses). The suggestions are actionable and directly address the identified issue. This makes the review point 5 for the authors to understand and improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the action of assigning all negative samples to a distractor class. This action is direct and clear, allowing the authors to directly implement the suggested change. The criteria for implicit vs. explicit actions are not met here, as the action is stated directly. The criteria for concrete vs. vague actions are also met, as the exact action to be taken is clearly defined.", "grounding_specificity_rationale": "The reviewer does not explicitly mention a specific part of the paper or experiment. The suggestion is more general, proposing a baseline evaluation method. While the *type* of baseline experiment is specific, the *general concept* of evaluating performance against a distractor is not tied to a specific section, table, or unique aspect of the paper. The reviewer is suggesting a general methodology rather than focusing on a particular element of their work.", "verifiability_rationale": "The review point poses a question about the performance of the suggested baseline experiment but does not provide any justification or explanation for why this experiment would perform a certain way. There are no references to external works or logical reasoning provided to support the expected outcome of this baseline. The reviewer is asking a question rather than making a claim that can be verified.", "helpfulness_rationale": "The review point identifies a potential area for improvement in model evaluation \u2013 considering distractor classes. This is a valuable point for authors who are thinking about simple baseline experiments. However, the review point does not provide any actionable feedback or suggestions on how to implement this baseline or what the expected outcome would be. It simply asks a question, which, while potentially insightful, does not directly guide the authors on how to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the observation that the advantage of RLCD over RLAIF shrinks with increasing model size and provides a clear suggestion to investigate whether RLCD (or RLCDRescore) can scale to larger models. The action is directly related to the observation and is a clear call to action for the authors.", "grounding_specificity_rationale": "The comment refers to 'RLCD' and 'RLAIF' by name and mentions 'model size' generally. While it doesn't explicitly state the section or table number where the data is presented, it strongly implies a specific location by referencing 'Tab. 2'. The methods are also named specifically, indicating a degree of grounding. However, the comment doesn't specify *what* is wrong with RLCD's performance at larger scales, making it somewhat underspecific within the grounding category.", "verifiability_rationale": "The comment presents a claim based on the observation in Tab. 2, stating that the advantage of RLCD shrinks. While it doesn't provide a definitive 'yes' or 'no' to whether RLCD can scale, the suggestion to investigate scaling provides a clear direction for further verification. The claim is supported by the observed data, making it 3.", "helpfulness_rationale": "The comment identifies a specific observation about the performance difference between RLCD and RLAIF in Tab. 2 and provides a clear and actionable suggestion to investigate the scaling of RLCD. This directly points to a relevant area for improvement and guides the authors on what to focus on."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue, but the suggestion lacks concrete details on how to address the scalability problem. While the suggestion is relevant, it doesn't provide a clear path forward for the authors to implement a solution.", "grounding_specificity_rationale": "The reviewer explicitly states the input data size as the focus. They clearly identify the problem with the method's reliance on the entire training and test datasets. This can be considered fully grounded as the specific aspect of the method is identified, and specific issues are raised.", "verifiability_rationale": "The reviewer makes a claim about the method's impracticality, supported by the lack of a clear learning mechanism for large datasets. They logically argue why the method would be difficult to apply to largescale datasets. While they don't provide specific examples of why it's impractical, the reasoning is sound and wellsupported by common knowledge about computational cost and resource requirements.", "helpfulness_rationale": "The reviewer highlights a significant limitation that would hinder the practical use of the method. While the suggestion to ask a question is a step towards improvement, the core issue of scalability is the primary concern. The comment identifies a meaningful weakness and offers a suggestion, making it 3 in guiding the authors towards a more practical approach."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "4", "verifiability_label": "Partially Verifiable", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'lacks specific measurements or comparisons' as the weakness. This is an explicit action the reviewer is pointing out is missing. While the reviewer could be more specific about *what* measurements are missing (e.g., GPU hours, memory usage, training time) and *how* the comparisons should be made, the *act* of pointing out the lack of quantitative analysis is clear and actionable.", "grounding_specificity_rationale": "The reviewer mentions 'quantitative analysis,' 'measurements,' 'comparisons,' 'GPU hours,' 'memory usage,' and 'training time.' These are all specific elements of the analysis requested. The reviewer doesn't explicitly name a section or table, but the mention of these concrete terms strongly implies they are referring to a specific part of the paper where these metrics are typically reported (or where the reviewer expects to find them). This can be considered fully grounded as the reviewer can infer the specific area of the paper being addressed based on the mentioned terms.", "verifiability_rationale": "The reviewer states the paper 'claims computational benefits from replacing the MAE model with a CNNbased data augmentation strategy' but 'lacks specific measurements or comparisons to substantiate these gains.' This claim is verifiable because it makes a statement about the outcome (computational benefits) and the reviewer identifies the lack of supporting evidence (specific measurements and comparisons). However, the claim itself is underspecific as it doesn't detail *what* measurements are being referred to or *how* the comparisons should be made.", "helpfulness_rationale": "The review point clearly identifies a gap in the paper's evidence. It states that while the paper claims computational benefits, it lacks specific measurements. This is a very specific suggestion for improvement and directly addresses a stated claim in the paper. The reviewer provides a clear and actionable suggestion for the authors to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the consequence of *not* considering the time for COLMAP and scenebyscene finetuning, making the action clear and direct. It identifies the missing element (time) and its impact on efficiency, which is a concrete action to take.", "grounding_specificity_rationale": "The review point refers to 'COLMAP' and 'scenebyscene finetuning,' which are specific terms within the context of the paper. While it doesn't explicitly state the section or figure number, the terms themselves strongly imply a specific part of the method. The comment specifies what is missing within that part.", "verifiability_rationale": "The review point contains a claim ('rendering the method less efficient for these scenes') that requires some level of justification. While it doesn't provide a detailed explanation or external references, it points to a potential issue in the method, making it 3 as it highlights a potential area for improvement.", "helpfulness_rationale": "The review point identifies a potential inefficiency and suggests considering the time involved. This directly points the authors towards a potential area for improvement, making the feedback actionable and helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly raises several potential areas for improvement related to the 'filter manifold network' (FMN). It suggests exploring alternative architectures, investigating the scaling of adaptive convolutions, and analyzing the impact of channel size. These are all actionable suggestions that the authors could consider. While the reviewer doesn't explicitly ask a question, the suggestions themselves are clear and point towards specific areas of potential improvement.", "grounding_specificity_rationale": "The reviewer points out a potential lack of discussion or analysis on the 'filter manifold network' (FMN). While they don't explicitly state which specific section or table is missing, the implication is that the authors should have discussed or analyzed this component in more detail. This lack of specific grounding makes it harder for the authors to understand what needs improvement. The reviewer suggests exploring alternative architectures, which implies a need to understand the current architecture. The scaling of adaptive convolutions and the impact of channel size are more about understanding the behavior of the component rather than specific parts of the paper.", "verifiability_rationale": "The reviewer doesn't explicitly make a claim that needs verification. They are pointing out potential areas for improvement or further investigation related to the FMN. While they imply that the authors should have discussed or analyzed this component, they don't state a specific problem or deficiency that requires justification. The suggestions are more about exploring possibilities rather than identifying concrete issues that need verification.", "helpfulness_rationale": "The review point raises several potential areas for improvement related to the 'filter manifold network' (FMN). It suggests exploring alternative architectures, investigating the scaling of adaptive convolutions, and analyzing the impact of channel size. These are all potential weaknesses or areas for further exploration that the authors could consider. The suggestions are clear and point towards specific areas of potential improvement, making them likely to be helpful."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a question about the contribution of different components of the proposed model and suggests a specific experiment to investigate this. The reviewer asks 'What brings the claimed performance boost  the fractional transform or the UNet operation in the fractional Fourier domain?' and suggests 'at least comparisons to UNets are therefore inevitable.' This is an explicit action that the authors can directly address by conducting the suggested experiment.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'UNet part after the fractional transform' in the CoNO model, grounding the suggestion directly in the architecture being proposed. The reviewer also specifies the comparison they suggest: 'at least comparisons to UNets are therefore inevitable.' This explicit grounding makes it clear which part of the model the reviewer is referring to and what aspect they are questioning.", "verifiability_rationale": "The reviewer provides a clear hypothesis ('the performance boost isn't due to either component') and a concrete suggestion for testing it ('comparison to UNets'). This is a logical and verifiable claim. The reviewer is not just stating an opinion; they are proposing a specific experiment that could provide evidence to support or refute their hypothesis.", "helpfulness_rationale": "This review point is 5 because it directly addresses a potential weakness in the authors' proposed model. By questioning the specific contribution of the UNet component and suggesting a comparison to standard UNets, the reviewer is providing a clear direction for further investigation. This helps the authors diagnose whether the performance boost is genuinely due to the fractional transform, the UNet in the Fourier domain, or the UNet component itself. The suggestion for a direct comparison is a concrete and actionable step that the authors can easily implement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the potential issue with computational cost and suggests a comparison with baselines. They also point to a specific step in Algorithm 1 (flipped previous layer output) which makes the issue concrete.", "grounding_specificity_rationale": "The reviewer mentions 'the proposed PSA method' and 'baselines' and refers to a specific step in Algorithm 1. This clearly identifies the relevant part of the method and the comparison intended.", "verifiability_rationale": "The reviewer presents a claim that 'the proposed PSA method requires more computation than baselines.' However, within this review point, there is no supporting evidence or justification for this claim. The reviewer suggests an experiment but does not provide any reasoning, references, or examples to back up the assertion that PSA is more computationally expensive than baselines.", "helpfulness_rationale": "The reviewer identifies a potential issue with the proposed method (computational cost) and suggests an experiment for comparison. However, they do not offer any concrete solutions or guidance on how the authors should address this issue. The comment primarily points out a weakness without providing actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point directly asks a question about the contribution of specific factors (noise and exponential moving average) to the model's performance. This is an explicit question about an action (identifying the contribution of these factors). However, it doesn't provide concrete steps or modifications the authors should apply based on this question alone. The question itself is the action, but it lacks the 'how to apply' component.", "grounding_specificity_rationale": "The reviewer explicitly mentions the two factors being considered: 'noise' and 'exponential moving average'. This clearly identifies the specific part of the paper (or the model's behavior) being addressed. The language is precise and directly targets these elements.", "verifiability_rationale": "The reviewer poses a question that could potentially be answered through further experimentation or analysis. While it doesn't provide a direct claim that needs verification, it sets up a scenario where the authors could investigate the individual contributions of the factors. The reviewer is asking for a deduction or inferred observation that goes beyond merely stating facts.", "helpfulness_rationale": "The review point raises a valid question about a potential area for improvement in the model. It points to a concrete area for future research and optimization. While it doesn't provide a direct solution, it identifies a potential avenue for enhancing the model's performance by understanding the individual contributions of different components. This information, if obtained, would be very useful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their desire for larger fonts and clearer figures, which are concrete actions. However, the request for 'more detailed comparisons' is vague, making it partially actionable.", "grounding_specificity_rationale": "The reviewer refers to specific elements within figures (fig 1, grey box) and variables (V_mem, Th_i, U_i^t), indicating strong grounding.", "verifiability_rationale": "The reviewer makes claims about the size of elements and variables. However, they don't provide evidence or justification for *why* these elements should be larger, making the claims 1.", "helpfulness_rationale": "The review offers helpful suggestions for improving figure clarity and the rigor of comparisons. However, the lack of specificity in some areas makes the recommendations less immediately helpful."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The review point does not explicitly state what the authors should do. The first part, 'The results are only reported after a bunch of training has occurred,' is a statement of observation, not an actionable suggestion. The second part, 'I presume that early in training the model parameters are essentially garbage,' is a speculative statement, not an actionable instruction. While the reviewer points out a potential issue, they don't provide concrete steps for the authors to take to address it. The action is implied but not directly stated, making it implicit.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or concept. The first part, 'The results are only reported after a bunch of training has occurred,' is a general statement about the reporting process. The second part, 'I presume that early in training the model parameters are essentially garbage,' is more specific, focusing on 'early in training' and 'model parameters.' However, it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper. The grounding is weak because the authors can only infer that the reviewer is referring to the training phase and model parameters.", "verifiability_rationale": "The review point does not contain a claim that can be supported using logical reasoning, common knowledge, or external references. The first part, 'The results are only reported after a bunch of training has occurred,' is a statement of observation. The second part, 'I presume that early in training the model parameters are essentially garbage,' is a hypothesis, not a verifiable claim. There is no explicit claim being made, and therefore there is no evidence to support or refute it.", "helpfulness_rationale": "The review point does not provide clear and actionable feedback that empowers the authors to significantly improve their draft. The first part, 'The results are only reported after a bunch of training has occurred,' highlights a limitation in the reporting process but doesn't offer a solution. The second part, 'I presume that early in training the model parameters are essentially garbage,' is a speculative question, not a helpful suggestion. The feedback is not directly related to the authors' work and does not provide concrete steps for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks a question about a potential action or consideration (whether the documents were treated as entire sentences) and identifies a missing detail (how multiple entity mentions were handled). This implies the reviewer is aware of a potential gap or area for clarification, suggesting a direct or apparent action the authors should take or consider. The question format encourages the authors to provide this information, indicating a clear next step.", "grounding_specificity_rationale": "The review point directly mentions \"DocRED\" and \"entire sentence\" and \"multiple entity mentions referring to the same entity.\" These specific terms and concepts clearly identify the area of the paper being discussed and the specific issue being raised. The reviewer is not just making a general comment but is pinpointing a specific aspect of the methodology or data.", "verifiability_rationale": "The reviewer states that \"This information is currently missing from the manuscript.\" This is a claim that needs to be addressed. While the reviewer doesn't provide a specific solution, they are indicating a gap in the current information. The claim is supported by the statement that the information is missing, making it 3 as the authors are pointing out a clear gap.", "helpfulness_rationale": "The review point identifies a potential oversight or gap in the manuscript by pointing out the missing information on how entity mentions are handled in DocRED. While it doesn't explicitly state what the authors should do about it, it highlights a specific area where clarification is needed. This points to a missing detail that could be important for reproducibility or understanding the methodology, making it 3 in identifying a gap."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states their opinion directly ('marginal'), which is explicit. However, the underlying feeling is vague, making it 3 but not fully concrete.", "grounding_specificity_rationale": "The reviewer offers a general assessment of the contribution being marginal and provides a reason ('all the methods used are well designed and demonstrated'), which is somewhat specific. However, they don't pinpoint a specific part of the paper as the source of the marginal contribution, making it weakly grounded.", "verifiability_rationale": "The reviewer makes a claim ('the contribution looks marginal...') and provides a justification ('all the methods used are well designed and demonstrated') as evidence. This justification, while present, lacks specific references or examples, making it 3.", "helpfulness_rationale": "The reviewer provides a direct statement of their opinion ('Adding another stream for lowresolution might not be a major contribution for a toptier venue like ICLR.') which is a clear and actionable feedback, albeit negative. This makes it 3 as it points to a specific area for improvement. However, it lacks concrete suggestions, making it not 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the performance gain is 'mostly from PBSD' and asks 'any other motivations?'. While the paper might contain some motivation, the reviewer is asking for more concrete details. The question itself is a concrete action.", "grounding_specificity_rationale": "The reviewer states 'the main contribution is somehow a little bit unclear' and then asks about the 'motivation for PBSD'. They are trying to pinpoint the specific part of the paper they are referring to. They also mention 'ablation study' and 'tail classes', which are specific elements. While the initial phrasing is a bit vague, the reviewer is clearly trying to connect their question to specific parts of the paper.", "verifiability_rationale": "The reviewer states that the performance gain is 'mostly from PBSD' and asks 'any other motivations?'. This is a claim about the ablation study results. The reviewer is asking for justification or reasoning to support the claim beyond tail class performance. The paper itself might not explicitly provide this justification in the way the reviewer is expecting.", "helpfulness_rationale": "The reviewer provides specific questions that, if answered, would improve the paper. They are seeking clarity and justification. While the paper *might* contain this information, the reviewer is explicitly pointing out its lack of clarity and prompting for more detail. The questions are directly aimed at improving understanding."}
{"actionability_label": "2 (2)", "grounding_specificity_label": "5 (5)", "verifiability_label": "5 (5)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer states a fact (''2 gives a tester for the spread parameter...') but doesn't explicitly say what the implication is or how it relates to an (\u03f5, \u03b4)identity tester. The connection is implied but not clearly stated. The reviewer also raises a specific concern about the (\u03c0, \u03d5) pairs, indicating a lack of clarity on the practical application of the mentioned tester.", "grounding_specificity_rationale": "The review point explicitly mentions \"review point 2\" and \"a tester for the spread parameter\", providing a clear reference to the location and a specific technical concept. The reviewer then asks a very specific question about the implications for (\u03f5, \u03b4)identity testers and the behavior of (\u03c0, \u03d5) pairs.", "verifiability_rationale": "The reviewer asks a question (\"For e.g., how is it dealing with...\") about the properties of a specific type of tester (a tester for the spread parameter) and its behavior with specific types of probability distributions (where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large). This question can be answered through logical reasoning about the definition and properties of identity testers and the concept of KullbackLeibler divergence.", "helpfulness_rationale": "The reviewer asks a very specific question about the implications of a certain type of tester for a specific problem. The question is about how the tester would behave in a particular scenario involving KL divergence. This is a question that could be helpful for the author to understand the limitations and applicability of the tester."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review states the Appendix is good but doesn't provide any specific actions or suggestions on how to improve the paper based on the unreviewed experiments in the Appendix.", "grounding_specificity_rationale": "The review refers to 'the Appendix' generally, without specifying which section or subsection is being discussed or the specific experiments mentioned (like the Brusselator).", "verifiability_rationale": "The review makes a claim about the reviewer's lack of time, which is a statement of fact based on the reviewer's personal situation, but it lacks external evidence or justification related to the paper being reviewed.", "helpfulness_rationale": "The review provides information about the Appendix's quality and the reviewer's time constraints but lacks actionable feedback on how to improve the paper based on this information."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a question about the relationship between the described 'active learning pipeline' and 'traditional active learning'. This directly points to an actionable step the authors should take to clarify their method. The reviewer is asking if their described method is the same as a wellestablished concept, which is a clear and direct action the authors can take to improve their description.", "grounding_specificity_rationale": "The reviewer refers to 'active learning pipeline' as a specific part of the method description. While it doesn't explicitly name a section, it clearly identifies a defined element within their method. This allows the authors to identify the specific part they are referring to, thus achieving 'Full Grounding'. The reviewer's focus on this specific component also allows them to understand what needs to be clarified, contributing to 'Specificity'.", "verifiability_rationale": "The reviewer makes a claim about the relationship between their 'active learning pipeline' and 'traditional active learning'. This claim can be verified by referencing the common characteristics of traditional active learning, such as selecting informative samples to label. The reviewer provides a clear definition of traditional active learning, which serves as evidence to verify their claim. This makes the claim verifiable with sufficient evidence.", "helpfulness_rationale": "The reviewer directly asks a question that could help the authors improve their description. They are asking if their 'active learning pipeline' is the same as a wellknown method. This is a very actionable and specific piece of feedback. By asking this question, the reviewer is prompting the authors to be more precise in their description of their method and to acknowledge existing work in the field."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point states a problem ('The detailed distribution of the proposed dataset is unclear;') but does not offer any specific action or suggestion on how to address this issue. The authors are left without concrete steps to take.", "grounding_specificity_rationale": "The review point mentions 'the detailed distribution of the proposed dataset' but does not explicitly identify the specific part of the paper or dataset being addressed. While it points to a problem related to the dataset, it doesn't specify which section, table, or unique element of the paper this refers to.", "verifiability_rationale": "The review point states a problem ('The detailed distribution of the proposed dataset is unclear;') but does not make any claims or assertions about the paper. It's a statement of a missing detail, not a claim requiring verification.", "helpfulness_rationale": "The review point identifies a valid issue (unclear dataset distribution) but does not provide any actionable feedback or suggestions on how the authors should address it. It points out a problem but doesn't offer a solution or guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The phrase \"annotated labels\" is explicit about a requirement for the method. The reviewer implies that the method needs annotated labels to learn semantic tokens, making this an explicit action. The reviewer also implies that the method *needs* annotated labels, making the action concrete.", "grounding_specificity_rationale": "The reviewer implies that the method *relies* on the concept of \"annotated labels\" to function. While not explicitly stating a section number, the context strongly suggests a dependency on labeled data. The reviewer also identifies the *specific type of annotation* needed, which is \"labels\". This implies a strong grounding in the need for annotations. The reviewer also specifies the *specific* issue: the need for annotated labels, making it specific.", "verifiability_rationale": "The reviewer makes a claim about the proposed method's limitation due to the need for annotations. The reviewer logically explains why annotations are needed for learning semantic tokens. The reviewer also implies that the alternative approach *lacks* this annotation requirement. The reviewer provides a logical explanation of why annotations are needed, making this claim verifiable.", "helpfulness_rationale": "The reviewer provides feedback on the limitations of the proposed method, specifically the need for annotated labels. This feedback is clear and identifies a concrete problem. The reviewer also suggests an alternative approach, making the feedback constructive. The feedback is specific to the need for annotations, making it actionable and directly helpful for the authors to consider alternative approaches."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the next step the authors should take: conduct experiments on more complex tasks. This is a clear and actionable suggestion.", "grounding_specificity_rationale": "The reviewer points out a trend in existing experiments (continuous control on simple tasks) and suggests an improvement (testing on more complex tasks). While the general area is mentioned, the specific paper or section isn't named, leading to weak grounding.", "verifiability_rationale": "The reviewer makes a statement of importance and suggests an improvement, but it's not a claim requiring external verification. It's more of a constructive suggestion.", "helpfulness_rationale": "The reviewer identifies a relevant and important area for improvement (scalability) and provides a clear next action for the authors (conducted experiments). This is a 5 and valuable comment."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests a change to the abstract and provides a specific reason ('as measured by the change in linear regions in output space after citation'). This indicates an explicit action: suggesting a modification to the abstract. The suggestion is also concrete, proposing a specific wording change. While the reviewer doesn't explicitly state how to implement this change, the suggestion itself is clear and actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'the abstract' and suggests a specific change related to 'greater expressivity' and 'linear regions in output space'. This clearly grounds the comment to a specific part of the paper and specifies the nature of the suggested improvement. The reviewer also provides a reference to support the suggestion, further enhancing grounding.", "verifiability_rationale": "The review point proposes a suggestion for improvement to the abstract, stating 'in the abstract, I think it should say ...'. This is a suggestion, not a claim that requires verification. The reviewer is proposing a change, not making a judgment about the current phrasing or providing external references to support this specific suggestion. Therefore, there is no verifiable claim in this review point.", "helpfulness_rationale": "The review point is clear about a specific area for improvement (the abstract) and offers a concrete suggestion ('in the abstract, I think it should say ...'). While the suggestion is focused on the abstract, it is a direct and actionable comment. The reviewer also offers a related suggestion (including learning curves), which adds to the helpfulness. However, the review point itself doesn't explicitly justify why this change is beneficial or how it will improve the paper's impact."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the paper's motivation is unclear and that the application of the proposed method is not apparent. While the reviewer suggests demonstrating the method's use on actual tasks, this is a suggestion for improvement rather than a direct action the authors should take based on the current review. The lack of a clear motivation and application is a vague issue, and the reviewer doesn't specify how the authors should address it.", "grounding_specificity_rationale": "The reviewer's statement about the lack of clarity regarding motivation and application is general. They do not specify which part of the paper or which aspect of the method is unclear. The reviewer uses phrases like 'unclear what this paper's motivation is' and 'how would this be useful,' indicating a lack of specific grounding in the paper's content.", "verifiability_rationale": "The reviewer makes a claim that the paper's motivation is unclear and the application is not apparent. However, they do not provide any evidence or reasoning to support this claim. The reviewer suggests demonstrating the method's use on actual tasks, which is a suggestion for improvement but not a verifiable statement based on the current review. The claim is presented without any supporting evidence.", "helpfulness_rationale": "The reviewer identifies a clear weakness in the paper: the lack of a clear motivation and application. They also suggest a potential solution (demonstrating the method's use on actual tasks). However, the reviewer does not provide a concrete, actionable step for the authors to take *now* based on this review. The suggestion is more of a direction for future work rather than a direct improvement suggested by the reviewer."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a weakness ('MULT was proposed in 2019 and thus sort of out of fashion') and suggests a potential improvement ('The paper regards MULT as the only deep learning based baseline that considers crosssensory interaction but MULT was proposed in 2019 and thus sort of out of fashion. *The reviewer suggests considering more recent deep learning baselines*'). While the suggestion is present, it lacks specific details on *which* more recent baselines to consider or *why* they are particularly relevant. The reviewer identifies an implicit action (implying the need for better baselines) but doesn't provide concrete steps on how to implement this action.", "grounding_specificity_rationale": "The comment mentions the years of the cited papers (2020 and 2022) and explicitly states that MULT is 'out of fashion.' This demonstrates a degree of grounding as the reviewer refers to specific publications and a point in time. However, the comment does not specify which part of the *reviewer's own paper* it is addressing. The grounding is present but not fully specific to a particular section or element of the paper.", "verifiability_rationale": "The comment contains a claim ('MULT was proposed in 2019 and thus sort of out of fashion') and provides supporting evidence in the form of the publication years of the cited papers (2020 and 2022) and the statement that MULT is 'out of fashion'. The reasoning is based on the temporal difference and the examples provided. The claim is wellsupported by explicit information.", "helpfulness_rationale": "The comment identifies a potential weakness in the paper's baseline selection by pointing out the age of the cited work and suggesting considering more recent baselines. It provides a clear explanation of the issue and offers a constructive suggestion for improvement. While it doesn't explicitly name specific recent papers, it guides the authors towards considering the temporal relevance of their baselines. The feedback is directly related to the choice of baselines and encourages the authors to think about the current state of the field."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer clearly identifies a significant issue: the lack of clarity in the experimental comparison against other models. They point out the omission of crucial information like the ranks of the core tensors and the number of model parameters. This directly tells the authors what is missing and how to address it for a fairer comparison. The reviewer's suggestion to compare tensor completion results with models having the same number of parameters is a direct and actionable step. While the reviewer doesn't explicitly state that the action is 'determine the ranks of the core tensors and the number of model parameters', the implication is clear. The reviewer is suggesting a specific action to be taken, which is to identify and compare models with similar complexity. This is a direct and actionable criticism.", "grounding_specificity_rationale": "The reviewer explicitly states the missing information: 'The value of the used ranks for all the models are omitted which make not possible a fair comparison.' and 'To show the superiority of TW over TT and TR, the authors must compare the tensor completion results for all the models but having the same number of model parameters.' This clearly indicates that the reviewer can precisely identify the specific part of the paper being addressed \u2013 the experimental comparison and the need for fair evaluation. The reviewer then specifies the *type* of information needed \u2013 the ranks and the number of parameters. This level of detail and specificity makes the criticism fully grounded. The reviewer is not just saying 'something is missing', but rather pinpointing exactly what is missing and why it is important.", "verifiability_rationale": "The reviewer provides a clear and wellreasoned suggestion. They state that the comparison is unfair because the models likely have different numbers of parameters. They then propose a solution: comparing results with models having the same number of parameters. This claim is directly supported by the need for a fair comparison in the context of model evaluation, especially when the focus is on the proposed method's effectiveness rather than just raw performance. The reviewer provides a logical reasoning for why the comparison needs to be fair and suggests a concrete way to achieve it. This makes the claim thoroughly supported and verifiable.", "helpfulness_rationale": "This review point is extremely helpful for the authors. It directly addresses a significant weakness in their experimental setup: the lack of a fair comparison against other models. The reviewer provides a clear and actionable suggestion: to compare the tensor completion results of the proposed method (TW) with other methods (TT and TR) while ensuring that all models have a similar number of parameters. This is a concrete step that the authors can readily implement to strengthen their experimental evaluation and draw more reliable conclusions about the superiority of their approach. The reviewer is not just pointing out a problem, but also offering a solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment suggests an action (including ATA in the comparison) but doesn't explicitly state how to *identify* that ATA is better than FP. The grounding of 'ATA' and 'FP' is present in Table 1, but the action itself is implied.", "grounding_specificity_rationale": "The comment explicitly mentions 'Table 2' and 'leave one out setting' when referring to the experimental setup, providing strong grounding. It also specifies the comparison being suggested ('ATA' vs. 'FP'). The comment clearly identifies what needs to be addressed in this part (the comparison).", "verifiability_rationale": "The claim that 'As ATA is a bit better than FP according to the results in Table 1' is verifiable because it directly references the results in Table 1. The reasoning is logical, stating that the existing results justify the suggestion. While a direct external reference isn't provided, the suggestion is grounded in the paper's own findings.", "helpfulness_rationale": "The comment is clear and directly points out a missing comparison, which is a valuable piece of feedback for the authors. While the suggestion is implied, it is easy to understand and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out that the normalization module seems different in two versions and suggests a standardization of icons. While these are valid observations, they are not explicitly stated as actions to be taken. The reviewer doesn't specify *which* modules are different or *why* the icons need standardization.", "grounding_specificity_rationale": "The reviewer specifically mentions 'Fig. 4' and the '0/50 latency range, 2.5/4.0 MAE: the chosen symbols overlap.' This clearly identifies a specific part of the paper and provides details about the issue with the icons in that specific context. The reviewer is confident in this identification.", "verifiability_rationale": "The reviewer states that 'Fig. 4 is a bit confusing in the 0/50 latency range, 2.5/4.0 MAE: the chosen symbols overlap.' This is a statement of a problem. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support why this overlap makes the figure confusing. The claim is presented as an observation without justification.", "helpfulness_rationale": "The reviewer provides two main points: the discrepancy in normalization modules and the need for standardization of icons. These are actionable suggestions that could help authors improve their work. The reviewer also points out minor problems with the text. While the textual issues are minor, the two main points are helpful in addressing potential problems or areas for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer correctly identifies a gap in the paper by pointing out that while the general idea of pruning subdivision splines is mentioned, the specific algorithm used to achieve this is not detailed. The reviewer's question about how the algorithm works and whether it introduces extra computational cost highlights this lack of specific information. While the reviewer understands the *need* for such an algorithm, the *how* is missing, making it an implicit action rather than an explicit one. Furthermore, the lack of detail makes the action vague.", "grounding_specificity_rationale": "The reviewer's question about the algorithm for removing subdivision splines indicates a lack of specific grounding in the paper. While the general concept of pruning is mentioned, the specific algorithm isn't explicitly named or described. The reviewer is asking about the *algorithm itself*, not just a general recommendation or observation about pruning. This lack of explicit identification makes the grounding weak. The specificity is also lacking because the reviewer isn't asking about a specific part of the paper, but rather about the algorithm's details and computational cost, which are not welldefined.", "verifiability_rationale": "The reviewer's questions about the algorithm's details and computational cost are valid but not 5. The paper doesn't explicitly state the algorithm's steps or provide a detailed analysis of its computational complexity. While the questions themselves are not claims, the lack of information to answer them verifiably is a valid point. The reasoning is that the paper doesn't provide the necessary evidence to support the claims about the algorithm's implementation and cost.", "helpfulness_rationale": "The reviewer's questions are valid and point to areas where the paper lacks detail. While the questions are helpful in identifying gaps, they don't directly provide solutions. The reviewer is asking *what* to do, but the paper doesn't explicitly state the algorithm or its computational cost. Therefore, the feedback is more of a *reminder* or *diagnosis* of a missing piece of information rather than a direct *healing* suggestion. The lack of explicit information makes it less helpful than a paper that provides a clear algorithm and cost analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states that 'W1 and W2 are not defined' in the model description. This is a direct identification of a missing element, making the action explicit. However, the reviewer does not specify *how* these variables should be defined or what they represent, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer points out the lack of definition for 'W1 and W2' in the context of their model description. While the reviewer doesn't explicitly state the section where these variables should be defined, they clearly relate the issue to the model description, indicating a weak grounding. The reviewer also specifies what is missing ('definitions of W1 and W2'), adding to the specificity of the criticism.", "verifiability_rationale": "The reviewer's comment does not contain a claim. They are simply stating a fact ('W1 and W2 are not defined') without providing any justification or reasoning. Therefore, it is not verifiable because there is X to be supported.", "helpfulness_rationale": "The reviewer's comment is a criticism of the lack of definition of variables in the model description. They do not offer any suggestions or propose an alternative. The comment is diagnostic but does not provide actionable improvement for the author. Therefore, it is not helpful."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "Borderline Helpful", "actionability_rationale": "The reviewer is questioning the fairness of the comparison, suggesting the baselines might be missing information. This is a subjective concern about the *justification* of the comparison, making it hard to directly map to the defined aspects. It feels 2 because the comparison itself is an *action*, but the lack of clarity in the *justification* makes it difficult to determine how to apply it. The reviewer is essentially asking for clarification on *why* the comparison was made, which is a valid point but doesn't directly translate to actionable advice.", "grounding_specificity_rationale": "The reviewer is not pointing to a specific part of the paper being questioned. They are making a general statement about the comparison's fairness. Therefore, the grounding specificity is not directly addressed by the review point. The comment is about the *comparison itself*, not a specific element within the paper.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are questioning the *justification* of the comparison. This is a subjective concern about the fairness of the comparison, and it doesn't fit the defined categories for verifiability, which focus on claims and supporting evidence. The comment is about the *process* of comparison, not a statement that needs to be proven.", "helpfulness_rationale": "The reviewer is questioning the value of the comparison as feedback. While the question itself is valuable, it doesn't actively provide actionable advice or insights into how the baselines could be improved. The comparison, as presented, doesn't offer concrete steps or justifications that would directly help the authors. Therefore, it's not actively helpful, making it a borderline case."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly asks a question about the state of negative chips and suggests an alternative training approach. This directly points to aspects of the RPN training process. However, the reviewer does not provide any details or explanations about how negative chips are generated or how the suggested training method would function. The action is stated, but the specifics are missing, making it only implicitly stated.", "grounding_specificity_rationale": "The reviewer refers to 'negative chips' and the 'RPN training process' generally. While they don't explicitly name specific sections, tables, or unique elements within the RPN, the concepts are broadly understood. The reviewer's question is specific to these concepts, indicating some level of grounding. However, without specifying which parts of the RPN are being referred to, the grounding remains weak.", "verifiability_rationale": "The reviewer makes a claim by asking a question about the state of negative chips and suggesting an alternative training method. However, they do not provide any evidence or reasoning to support this claim. The question is posed without any logical justification or references to external sources, making the claim 1.", "helpfulness_rationale": "The reviewer's review point is primarily a question and a suggestion for improvement. While the suggestion is potentially helpful, the review itself lacks specific details about the current state of negative chips or the specifics of the suggested training approach. The lack of clarity makes it difficult to assess the actual value or impact of the suggested improvement, rendering the review point not very helpful as it stands."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action to be taken: 'evaluate the proposed approach on new patients and old patients respectively.' This is a clear and direct instruction for the authors, indicating a concrete action to be performed. The reviewer is not just pointing out a problem, but also suggesting a solution.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'new patients' and 'old patients' in the review point. This directly identifies the specific parts of the paper or the data being addressed. The comment provides a clear and precise reference point, indicating a strong grounding of the comment.", "verifiability_rationale": "The reviewer suggests a method of evaluation: 'evaluate the proposed approach on new patients and old patients respectively.' While this is a suggestion for a process, it does not contain a claim that can be verified through logical reasoning, common knowledge, or external references. The reviewer is proposing a way to evaluate, not making a statement that can be proven true or false with evidence.", "helpfulness_rationale": "The reviewer clearly states a need for a specific evaluation strategy: 'evaluate the proposed approach on new patients and old patients respectively.' This is a direct and actionable request for the authors, providing a clear direction for how they should proceed with their analysis. The reviewer is not just pointing out a problem, but also suggesting a concrete solution that will directly benefit the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a discrepancy in the methodology, stating that the baselines do not use the 300WLP dataset in their training, while the proposed method is trained with it. This is an explicit statement of a potential issue. While the reviewer doesn't directly tell the authors what to do, they highlight a potential flaw in the experimental setup. The action is 'pointing out a discrepancy', which is explicit. However, the reviewer doesn't provide concrete steps on how the authors should address this discrepancy, making it only 3.", "grounding_specificity_rationale": "The reviewer mentions '300WLP dataset' and its use in training, which is a specific part of the paper. While they also mention 'baselines' generally, the core of the concern is the dataset. The reviewer explicitly names a specific element of the paper being addressed, which aligns with the 'grounding' criteria. The specificity comes from mentioning the dataset and the potential unfair advantage.", "verifiability_rationale": "The reviewer makes a claim about the inconsistency in the use of the 300WLP dataset. This claim could potentially be verified by examining the training procedures of the proposed method and the baselines. The reviewer identifies a potential issue and suggests a way to investigate it, making the claim verifiable. The claim is about the dataset used, which is a specific aspect of the methodology.", "helpfulness_rationale": "The reviewer raises a valid concern about the consistency of the experimental setup and its potential impact on the results. This feedback is valuable for the authors to consider and potentially address. The reviewer identifies a potential weakness and asks a question about its implications, which is helpful for guiding the authors' thinking. The feedback is relevant to the experimental methodology and aims to improve the authors' understanding of their method's performance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a potential issue with the novelty of certain techniques but does not specify which techniques, how they are implemented, or how they are used in the paper. The connection between the general statement and the specific algorithm is not explicit, requiring the author to infer the relevant parts of the paper.", "grounding_specificity_rationale": "The comment mentions 'computation offloading' and 'gradient augmentation' generally, without referencing a specific section, table, figure, or algorithm in the paper. It does not identify the specific part of the paper being addressed.", "verifiability_rationale": "The comment contains a claim ('Some technique behind the algorithm may not be that novel...') but does not provide any specific examples, references, or logical reasoning to support this claim. The justification for the claim is missing.", "helpfulness_rationale": "The comment points out a potential lack of novelty in specific techniques but does not provide concrete feedback on how to improve the algorithm or address this perceived lack of novelty. The feedback is general and lacks actionable steps for the author."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the model *assumes* the observations are obtained by averaging over the corresponding support v. Furthermore, the reviewer provides concrete examples of alternative aggregation methods (summation or populationweighted average) and mentions the nature of the data (count or rate per the number of residents). This indicates a clear and actionable point of critique regarding the model's assumption about observation aggregation.", "grounding_specificity_rationale": "The reviewer identifies a potential issue with the model's observation aggregation but does not explicitly pinpoint the specific part of the paper where this assumption is most relevant. While the reviewer mentions 'Equation (1)' and 'observations' generally, they do not provide a precise location within the paper (e.g., a specific section, table, or unique element) where this concern is most pertinent. However, the reviewer does specify the *nature* of the potential aggregation process (averaging, summation, populationweighted average) and the *type* of data (count, rate).", "verifiability_rationale": "The reviewer makes a claim that the model's assumption about observation aggregation might be too simplistic and that other methods are more appropriate. The reviewer suggests alternative aggregation methods and mentions the nature of the data. However, the reviewer does not provide external references or logical reasoning to *demonstrate* why averaging is inherently problematic or why summation or ratebased averaging are definitively superior. The justification is more about suggesting alternatives than providing concrete evidence to support the claim.", "helpfulness_rationale": "The reviewer's comment is 5. They clearly identify a potential limitation in the model's assumption about how observations are generated and offer concrete alternatives. This provides the authors with specific points to consider and think about when evaluating their model. While the reviewer doesn't provide a definitive solution, they offer a valuable discussion point and potential avenues for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'no indepth analysis' and asks 'why?'. This indicates a clear request for a specific action (providing analysis). However, the request lacks specific details on *what kind* of analysis or *how* to explain the inverse scaling dynamics. The action is implied but not fully defined.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific section, table, figure, or unique aspect of the paper. They are referring to the general observation about inverse scaling. Therefore, the comment does not identify a specific part of the paper being addressed.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are pointing out a weakness (lack of indepth analysis) and suggesting an improvement (providing analysis). This is a suggestion, not a claim that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the paper (lack of indepth analysis) and offers a constructive suggestion (providing analysis). This directly addresses a potential area for improvement and is therefore helpful, even if the suggestion is not perfectly specific."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'I assume these are the inputs for the attention layer, namely query, keys, and values.' This directly points to a missing connection between the figure and the description, and asks for clarification on a key architectural detail. The reviewer also states 'Are the same vectors used for keys and values here or different sections of them?' This is a direct question for clarification, indicating a lack of clarity.", "grounding_specificity_rationale": "The reviewer refers to 'multihead attention' generally, and while they *mention* the description, they don't explicitly point to a specific section or equation number. However, the reviewer *clearly identifies* the *location* of the issue as 'Figure 2'. The comment specifies what needs to be addressed in this part, which is the lack of mathematical definition and clarity regarding keys/values.", "verifiability_rationale": "The reviewer *identifies* a lack of mathematical definition and a lack of clarity in Figure 2. This is a statement of a problem, which can be considered a *suggestion for improvement*. The reviewer doesn't explicitly claim that the paper is wrong, but rather points out a missing element. The reviewer's suggestions for improvement (asking about the relationship between keys/values and clarifying the split arrow) are implicit in their request for clarification.", "helpfulness_rationale": "The reviewer provides specific questions and suggestions for improvement (asking about the relationship between keys/values and clarifying the split arrow). These are concrete suggestions, directly addressing the identified lack of detail. The reviewer's request for clarification is a valuable feedback point for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for a nonfixed policy and suggests exploring more complex tasks. This is a clear, actionable suggestion for the author. The reviewer also implies the potential for such tasks to emerge, which is a concrete action. While the action is not directly tied to a specific section, the suggestion is clear and actionable.", "grounding_specificity_rationale": "The reviewer refers to 'fixed policy' and 'reinforcement learning' generally, without pinpointing a specific section, table, figure, or unique aspect of the paper. The connection to a specific part of the author's work is weak. The reviewer mentions the potential for more complex tasks, which could be seen as a general suggestion without specific grounding within the paper's content.", "verifiability_rationale": "The reviewer makes a claim about the potential for more complex tasks to lead to nonfixed policies and suggests comparing against a reinforcement learning baseline. This claim is supported by the logical reasoning that more complex tasks could lead to nonfixed policies and that comparing against RL is a valid approach. The reviewer provides a clear reasoning for both the claim and the suggestion.", "helpfulness_rationale": "The reviewer offers a relevant technical suggestion about exploring more complex tasks and a concrete comparison strategy with a reinforcement learning baseline. This is helpful for the author as it provides a direction for improvement and a way to evaluate their policy. The suggestion is clear and actionable, and the comparison strategy is a valid and useful recommendation. While the impact might depend on the author's specific situation, the feedback is constructive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a desire to improve the analyses of the method and experimental outcomes. However, it lacks specific details on what aspects of the analysis need improvement or how to achieve this improvement. The request is general and openended.", "grounding_specificity_rationale": "The review point mentions the 'method itself' and 'the experimental outcomes' as areas needing improvement. However, it does not specify which particular parts or aspects of the method or outcomes are lacking. The reference to 'sense level' is also vague and doesn't pinpoint a specific sense. Therefore, the grounding of the point is weak.", "verifiability_rationale": "The review point contains a claim: 'Given that the authors' method underperforms the baseline in some instances, one might question to what extent the performance improvement brought by this pretraining method can be attributed to the authors' claim of \"moving codeswitched pretraining from the word level to the sense level, by leveraging word sensespecific information from Knowledge Bases\".' This claim is supported by the observation of underperformance and raises a question about the attribution of improvement. The reasoning is logical and based on the observed results.", "helpfulness_rationale": "The review point identifies a potential weakness in the experimental analysis (lack of comprehensive analysis of the method and outcomes) but does not offer specific, actionable suggestions for improvement. It raises a question but does not provide guidance on how to address the identified issue. Therefore, the feedback is not particularly helpful in terms of providing concrete steps for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The review points out a limitation of the paper's scope. While it identifies a problem, it doesn't explicitly * tell the authors *what to do. It's more of a statement of fact. The 'how' is missing. While it implies a need to narrow the focus, the specific actions or changes are not detailed.", "grounding_specificity_rationale": "The reviewer refers to 'the paper's focus' generally. They are *inferring* that the focus is on multitask model explanations. They aren't pointing to a specific section, table, figure, or unique element. The grounding is weak because the authors can't confidently determine which part is being overfocused. The specificity is also lacking as the review doesn't detail *what* is limiting the applicability.", "verifiability_rationale": "The review states a fact: 'This paper mainly focuses on explaining multitask models'. However, it doesn't provide any external references or logical reasoning to *prove* that the paper *mainly* focuses on explaining multitask models. This is an opinion, not a verifiable fact based on evidence. The claim is presented without sufficient support.", "helpfulness_rationale": "The review points out a limitation of the paper's scope. While it identifies a problem, it doesn't offer specific actionable steps on how to address it. The 'how' is missing. Even if the authors *decide* to narrow the focus, the review doesn't provide guidance on *how* to do that. The lack of specific suggestions and supporting evidence makes the feedback less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the literature review 'ignores several papers' and then names two specific papers (1 and 2) as relevant, satisfying Assumption 2 and having a better rate than QSGD in the stochastic regime. This provides a clear direction for the authors to improve their literature review by including these missing references and potentially comparing their method against VRMARINA and DASHAMVR. The reviewer also suggests that these papers are relevant, which is a direct action the authors can take.", "grounding_specificity_rationale": "The reviewer not only states that the literature review 'ignores several papers' but also specifies which papers (1 and 2) are relevant and highlights their characteristics (satisfy Assumption 2, better rate than QSGD in the stochastic regime). This level of detail allows the authors to precisely identify the missing information and understand the specific properties of the relevant papers. The reviewer's statement is not just a general comment but a specific identification of the relevant parts of the paper (the literature review section) and their features.", "verifiability_rationale": "The reviewer makes a claim that the suggested papers are relevant and have a better rate than QSGD in the stochastic regime. However, within this review point itself, there is no explicit or implicit evidence provided to *prove* these claims. The reviewer is making an inference based on their knowledge of the field. While the implication is clear, the direct evidence is missing within the review point.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the literature review (omission of relevant papers) and suggests specific papers and a potential performance comparison with QSGD. This provides the authors with a clear direction for improvement. While the claim about the performance of the suggested papers is not directly verified in this review point, the suggestion itself is a valuable piece of feedback that can help the authors enhance their work. The reviewer is directly pointing out a missing element and offering a concrete suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment states that the paper is 'hard to follow' but does not specify what aspects are difficult to follow or provide concrete steps for improvement. It lacks explicit action, focusing on a general issue without detailing how to address it.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper or section that is difficult to follow. It is a general statement about the presentation's clarity without pinpointing the source of the problem.", "verifiability_rationale": "The comment is a statement of opinion about the presentation's clarity, not a claim that requires verification. It does not present a suggestion, judgment, or reference to external work.", "helpfulness_rationale": "The comment identifies a weakness (difficult to follow) but does not offer any specific suggestions or guidance on how to improve it. It is a negative comment without actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point does not contain explicit or implicit actions or suggestions. It asks questions but does not provide concrete steps or modifications the authors should make to their draft. The questions are about seeking further information or performance evaluation, not about directly improving the draft.", "grounding_specificity_rationale": "The review point does not explicitly identify any specific part of the paper being discussed. The questions are general and do not target a particular section, table, figure, or unique aspect of the paper. The reviewer is asking about performance on Clothing1M and WebVision in general, without specifying where in the paper these datasets are discussed or the specific issue being addressed.", "verifiability_rationale": "The review point does not contain a claim. It is a question asking for information or clarification, not a statement that requires verification. Therefore, it does not fit into the verifiability categories.", "helpfulness_rationale": "The review point does not provide actionable feedback or solutions to the authors' concerns. It asks questions but does not offer concrete insights or suggestions for improvement. The questions are about seeking further information or performance evaluation, not about directly addressing potential issues in the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer's request for more detail about the compared models and their computational costs is a valid point that would help the authors understand the tradeoffs between different approaches. However, the request is not explicitly stated as an action to be taken, making it somewhat implicit. The reviewer is suggesting a specific area for improvement in the original paper's explanation of the models.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify a specific part of the paper being addressed. While they mention 'the compared models' and 'KVAE parameters', they don't pinpoint a specific section, table, figure, or unique element of the paper. The grounding is present but weak. The reviewer is making a general request for more information rather than explicitly identifying a specific issue within a particular section.", "verifiability_rationale": "This review point does not contain a claim. It is a question or suggestion for information. Verifiability applies to statements that make assertions or judgments that need support. Therefore, this point does not fall under the defined scope of verifiability.", "helpfulness_rationale": "The reviewer's request for more detail about the compared models and their computational costs is a relevant and helpful suggestion for the authors. It directly addresses a potential area of confusion and provides a concrete direction for the authors to seek additional information. While the request is broad, it is a clear and actionable suggestion for improving the clarity and completeness of the paper's explanation of the methods."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks information on the hyperparameters used by each defense and how those hyperparameters are derived. While the information is missing, the reviewer does not provide specific guidance on how to obtain this information, making it 3 but lacking detail.", "grounding_specificity_rationale": "The review point is a general statement about the missing information regarding hyperparameters and their derivation. It does not explicitly identify the specific section, table, figure, or unique element of the paper where this information should be found, making the grounding weak. Furthermore, the point does not specify what needs to be addressed in this part, making the specificity underspecific.", "verifiability_rationale": "The review point is not a claim that requires verification. It is a critique of the paper's completeness regarding the description of hyperparameters and their derivation.", "helpfulness_rationale": "The review point clearly identifies a significant deficiency in the paper \u2013 the lack of information on hyperparameters and their derivation. This is a helpful point as it directs the authors to a specific area where they should look for crucial details to enable a maximally charitable evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points to a 'main takeaway point' and a specific action ('query a cluster proportionally to the square root of its size'), but it doesn't explicitly state how to implement this action or provide the details of the 'main takeaway point'. The action is implied, but the specifics are missing.", "grounding_specificity_rationale": "The review refers to 'theoretical results' and 'the main takeaway point'. While it touches on a specific finding, it doesn't pinpoint a specific section, table, figure, or unique element of the paper. The 'main takeaway point' is vague.", "verifiability_rationale": "The review makes a claim about the 'immediate practical implications' of the theoretical results and suggests a specific action, but it doesn't provide any justification for why this is a relevant or novel finding, nor does it cite any external sources to support this claim. The suggestion is presented as an observation.", "helpfulness_rationale": "The review points out a limitation of the work (lack of practical implications) and suggests a potential improvement (providing practitioner takeaways). However, it doesn't offer concrete steps on how to make the results more practical or how to identify 'takeaway points for practitioners'. The suggestion about the square root law is interesting but lacks context and connection to practical applications within the review itself."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks 'why separators are introduced' and 'what additional info they convene beyond T/I/O'. This is an explicit request for an explanation of a design choice. However, the action itself (asking the question) is somewhat vague as the 'convenience' is not clearly defined.", "grounding_specificity_rationale": "The reviewer directly refers to 'section 4' when asking about the separators. This clearly identifies the specific part of the paper being addressed, making the grounding explicit. However, the reviewer does not specify *what* additional information the separators provide beyond T/O, making the specificity underspecific.", "verifiability_rationale": "The reviewer states a claim: 'In section 4, I don't see the reason why separators are introduced. what additional info they convene beyond T/I/O?' This claim requires verification. The original text (section 4) should, by definition, explain the purpose and benefits of separators. The reviewer's statement indicates a lack of this explanation, making the claim 1 based on the provided text. The request for clarification implies a need for justification of the claimed missing information.", "helpfulness_rationale": "The reviewer's question directly aims to improve the clarity and understanding of the paper, specifically regarding the use of separators. By asking for the reason and additional information, the reviewer is seeking actionable feedback to enhance the draft. This aligns with the goal of helping authors improve their work."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The comment suggests exploring different pooling strategies, which is an actionable step. It explicitly mentions 'mean pooling' and proposes alternatives like 'max pooling' or 'learned pooling'. This indicates a clear intention to address the issue of mean pooling. However, it doesn't provide specific instructions on how to implement these different pooling methods or which parts of the code to modify.", "grounding_specificity_rationale": "The comment mentions 'tokens' and 'pooling strategies' generally. While it implies a potential issue with mean pooling, it doesn't explicitly point to a specific line of code or a clear problem with the current implementation. The suggestion is more exploratory than pinpointing a concrete error.", "verifiability_rationale": "The comment poses questions like 'why is it that mean pooling works?' and 'What about other pooling strategies?'. This can be considered a claim that needs justification or explanation. However, it doesn't provide immediate references or concrete examples to support these claims.", "helpfulness_rationale": "The comment is relevant to the authors as it points towards potential improvements in their model's token processing. Suggesting the exploration of different pooling strategies is a pertinent request for optimization. However, it lacks specific guidance on how to proceed with this exploration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a missing element ('real search cost') and suggests a concrete way to measure it ('in terms of GPU days'). This constitutes an explicit and actionable suggestion.", "grounding_specificity_rationale": "The comment explicitly mentions 'Table 3' and suggests calculating 'real search cost (e.g. in terms of GPU days)' within that table. This allows the authors to accurately identify the relevant section and understand the suggested metric. The 'e.g.' provides a specific example.", "verifiability_rationale": "The comment contains a claim ('It would be better to compare the real search cost (e.g. in terms of GPU days)') and suggests a method for achieving this ('in terms of GPU days'). This claim is verifiable by implementing the suggested measurement method.", "helpfulness_rationale": "The comment directly identifies a potential improvement ('including real search cost') and provides a clear and actionable suggestion ('in terms of GPU days'). This is 5 for the authors as it provides a concrete next step."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a gap in the paper: 'Missing training details? Specifically, I am wondering if the VQGAN is pretrained? Or only trained on the 88,635 images from the Computer Vision Figures dataset?' This directly points to a missing action or instruction for the authors. The reviewer is implicitly suggesting that the authors should clarify these training details.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'VQGAN training details' and further narrows it down to 'pretrained' or 'trained on the 88,635 images from the Computer Vision Figures dataset.' This clearly identifies the specific part of the paper being addressed, demonstrating strong grounding specificity.", "verifiability_rationale": "The comment asks a direct question about the training of the VQGAN, which is a factual question. While the paper doesn't explicitly state this, the reviewer is seeking clarification. The verifiability is good because the information is likely available through a simple search of the paper's content or by asking the author directly. There's X being made, just a request for information.", "helpfulness_rationale": "The comment identifies a potential ambiguity or gap in the author's description of their methodology (missing training details for the VQGAN). By asking specific questions about whether it's pretrained or trained on a specific dataset, the reviewer is directly informing the author where they might need to clarify their work. This provides a clear direction for improvement and is therefore 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point does not explicitly state what needs to be improved or how to achieve it. It describes the observed performance on the MSVD dataset but does not provide actionable steps for the authors to address this observation.", "grounding_specificity_rationale": "The review point identifies the issue as being related to the performance on the MSVD dataset (or Table 3). This can be considered 'Weakly Grounded' as it identifies the *data* involved, but it doesn't pinpoint the exact specific part of the method or model being affected. It is not 'Fully Grounded' because it doesn't explicitly name a section, table, or figure within the paper.", "verifiability_rationale": "The review point contains a claim: 'the performance in MSVD (Table 3) shows minor improvements.' This claim is based on the observation of the results presented in Table 3. While it doesn't provide new information or external references, it points to an existing discrepancy or area for further investigation based on the presented data. Therefore, it can be considered 'Partially Verifiable' as it is supported by the data presented in the table, but it doesn't offer a deeper explanation or justification for the observed improvement.", "helpfulness_rationale": "The review point highlights a discrepancy or an area for improvement based on the MSVD results. It encourages the authors to 'revisit their methods' and 'consider the performance on this specific dataset'. While it points to a relevant issue, it doesn't provide specific actions or detailed explanations of *why* the performance is improved or *how* the methods need to be changed. Therefore, it is '3' as it identifies a relevant problem but lacks concrete guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states an alternative method (vanilla Adam) and its parameters (40 random initial points), making the action clear and concrete. Authors can directly understand and potentially implement this suggestion.", "grounding_specificity_rationale": "The reviewer explicitly mentions '40 different networks from the training phase' and 'vanilla Adam on the final network with 40 random initial points', directly identifying the specific part of the paper being questioned. This demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer presents an alternative method and a reason for questioning the proposed approach's strengths. However, they do not provide any specific evidence, reasoning, or references to support their claim that the experimental strengths are not convincing. The claim is presented without sufficient justification.", "helpfulness_rationale": "The reviewer offers a concrete alternative and a reason for reconsidering the proposed method. While the suggestion is constructive, its impact on the authors is uncertain as the reviewer does not provide a strong, evidencebased argument for why the proposed method is flawed. The helpfulness is conditional on the authors finding the reasoning compelling."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point states a limitation but does not explicitly tell the authors what to do or how to fix it. The reviewer points out that the relationship between the identified patches and the disease is not yet established, but this is a statement of a problem, not a direct instruction.", "grounding_specificity_rationale": "The reviewer refers to \"top selected patches,\" which implies a specific part of the paper, but doesn't explicitly name it or provide a unique identifier. This makes the grounding somewhat implicit.", "verifiability_rationale": "The reviewer makes a claim about the study's limitations but does not provide any evidence or reasoning to support this claim. There is no suggestion of where to find this information or why it's a problem.", "helpfulness_rationale": "The review identifies a valid concern about the scope and conclusions of the study. While it provides valuable information, it doesn't directly guide the authors on how to improve their current draft. It suggests a direction for future research but lacks concrete actionable steps for the current work."}
{"actionability_label": "4", "grounding_specificity_label": "3: 5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the error: 'the first quotation mark needs to be the forward mark rather than the backward mark' and provides the correct alternative: '(i.e., \u2018 i n \u2212 b e t w e e n \u2032 )'. This directly identifies the action the authors should take: replace the existing quotation mark with the forward quote. The 'i.e.' further clarifies the desired outcome. The reviewer also points to the specific location: 'for 'inbetween' uncertainty'.", "grounding_specificity_rationale": "The reviewer explicitly names the location of the error: 'for 'inbetween' uncertainty'. This is strong grounding as the authors can directly identify the problematic part. Furthermore, the reviewer clearly specifies the issue: 'the first quotation mark needs to be the forward mark rather than the backward mark (i.e., \u2018 i n \u2212 b e t w e e n \u2032 )'. This specifies *what* needs to be changed within the identified location.", "verifiability_rationale": "The reviewer makes a claim: 'In the phrase 'for 'inbetween' uncertainty', the first quotation mark on 'inbetween' needs to be the forward mark rather than the backward mark (i.e., \u2018 i n \u2212 b e e n \u2032 ). p.' This claim is supported by the reviewer stating the correct representation: '(i.e., \u2018 i n \u2212 b e t w e e n \u2032 )'. The reviewer also provides the location of the error, which acts as a form of justification by pointing to a specific instance where the error occurs.", "helpfulness_rationale": "This review point directly identifies a factual error that needs correction. By stating the correct representation of the quotation marks, the reviewer provides a clear and actionable step for the authors to take. This specific feedback is crucial for improving the clarity and correctness of the paper."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment does not explicitly state an action or suggestion for improvement. It simply points out a fact: that FedSP is not the best performer on some datasets.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper (e.g., a section, table, or figure). It refers to 'FedSP' generally and 'some datasets' without specifying which ones.", "verifiability_rationale": "The comment is not a claim that requires verification. It is a statement of observation about the results presented in Table 1 and Table 2.", "helpfulness_rationale": "The comment identifies a weakness in the presented results (FedSP not being the best on some datasets). However, it does not provide any actionable suggestions or guidance on how to address this issue. It is a factual observation without further insight or recommendations."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's request is to clarify what Omega is. While the paper should ideally define Omega earlier, the reviewer's suggestion to be more explicit about it and to specify the link function and theorem reference is an implicit suggestion for improvement. The reviewer is indicating a lack of clarity in the current description of Omega and its relation to OMD. The request to be more explicit and to ask for the link function and theorem reference adds a concrete element to the suggestion.", "grounding_specificity_rationale": "The reviewer is asking for the definition of Omega. While the paper should define it, the reviewer doesn't explicitly state the section or table where Omega is typically defined. However, the reviewer clearly states what they want to know (the definition of Omega) and also asks for specific details like the link function and theorem reference, which makes the request somewhat specific.", "verifiability_rationale": "The reviewer is making a judgment that the paper's description of Omega is lacking. They are asking for a clearer definition and specific details like the link function and theorem reference. This is a claim that needs to be supported. The reviewer doesn't provide any external references or logical reasoning to support this claim about the paper's shortcomings. The claim is based on the reviewer's perception of the paper's clarity and completeness.", "helpfulness_rationale": "The reviewer's comment directly points to a potential area of confusion for the authors \u2013 the definition and role of Omega in the context of OMD. The reviewer's suggestions to be more explicit about Omega, specify the link function, and provide the theorem reference are actionable steps that, if implemented, could significantly improve the clarity and understanding of the paper. The reviewer's comment is not just a critique but also offers concrete suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that 'the models are learned directly from pixels without a Markovian state.' This is a clear and actionable statement. The authors can directly identify the missing component (the Markovian state) and understand what they should try to add to improve their model. The statement is not vague or ambiguous.", "grounding_specificity_rationale": "The review point explicitly mentions 'Markovian state.' This directly identifies the specific aspect of the paper being addressed. The authors can easily pinpoint the missing element being discussed. This is a strong example of full grounding.", "verifiability_rationale": "The review point makes a claim: 'the models are learned directly from pixels without a Markovian state.' While it doesn't provide a detailed explanation *why* this is a problem, it identifies a specific detail about the model's architecture. This detail could potentially be verified by examining the model's design or comparing it to models that *do* use Markovian states. Therefore, it is 3.", "helpfulness_rationale": "The review point is 5 because it directly points out a specific, actionable improvement the authors can make. By stating the absence of a 'Markovian state,' it guides the authors to consider adding this element, which is a concrete and potentially beneficial change. It's not just a negative comment about the model being unclear; it offers a specific direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their surprise at the 'common' practice of using Hamming distance over entire parts of the sequence and suggests looking for references. While the reviewer doesn't provide a specific example of how this 'common' practice is implemented, the act of suggesting references indicates an implicit understanding of the action needed to investigate this claim. Therefore, the actionability is somewhat present but could be more explicit by directly naming the potential issue or providing a more concrete action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Example 2' and specifically refers to the 'Hamming distance over entire parts of the sequence' as a point of surprise. This precise identification of the section and the specific usage demonstrates strong grounding specificity. The reviewer is not making an educated guess but rather pointing to a specific location and detail within the paper.", "verifiability_rationale": "The reviewer provides evidence by stating they have not encountered this specific usage of Hamming distance and are only aware of nodewise Hamming loss. This statement directly supports the claim and provides a basis for verification. The reviewer is not making a claim without evidence, but rather pointing out a discrepancy or lack of clarity within the paper itself.", "helpfulness_rationale": "The reviewer's comment is constructive and points out a potential inconsistency or lack of clarity regarding the use of Hamming distance. While they don't offer a direct solution, their feedback highlights an area for improvement in the paper. The reviewer's surprise and suggestion for clarification indicate that the issue is relevant and potentially impactful, making the feedback helpful to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need to change the name of the 'Evaluation' element to 'Metrics'. They also specify that the content within this element should be moved to a separate section and that the feedback should be presented either by briefly mentioning the datasets or including them in the captions of the tables. These are all direct and concrete actions that the authors can readily implement.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific element being discussed, which is the 'Evaluation' element. They then explicitly state the desired change \u2013 renaming it to 'Metrics' and relocating its content. Furthermore, they suggest specific ways to present the feedback, such as briefly mentioning the datasets or including them in the captions of the tables. This demonstrates a strong grounding in the specific part of the paper and a clear specification of the desired changes.", "verifiability_rationale": "The reviewer suggests renaming the 'Evaluation' element to 'Metrics' and recommends presenting feedback either by briefly mentioning the datasets or including them in the captions of the tables. While the reviewer doesn't provide explicit external references to justify why 'Metrics' is the superior term, the suggestion itself implies that this terminology is a desirable or standard practice. The action of renaming and relocating content is a clear claim that can be supported by the reviewer's reasoning. The suggestion to use dataset information in captions is also a clear action that can be verified. Therefore, the claim is 3 as it is based on a suggestion and an implication of standard practice, even without direct citations.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: renaming the 'Evaluation' element to 'Metrics' and suggesting specific ways to present the feedback. This directly addresses a potential area for improvement in how the evaluation process is documented. While it doesn't offer new insights into the *content* of the evaluation, it empowers the authors to make a change and present their work more effectively. Therefore, the review point is 4 as it provides a clear direction for improvement in the presentation and structure of the evaluation."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete change. It is a suggestion for future work rather than a critique or improvement of the current paper. While it implies a potential area for improvement, it lacks the explicitness and concreteness required for high actionability.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or the DRRI dataset. It is a general suggestion about exploring a new dataset. There is no mention of a specific section, table, figure, or unique aspect of the paper that the reviewer is referring to, making the grounding weak. The suggestion is about a general future direction rather than a specific issue within the current work.", "verifiability_rationale": "The review point does not contain a claim. It is a suggestion for future research rather than a critique or an assertion about a deficiency in the current work. Therefore, it does not fit into the verifiability categories as it lacks a claim to be verified.", "helpfulness_rationale": "The review point suggests exploring a new dataset as a potential future direction. While this could be beneficial, the review point itself does not directly improve the current paper. It is a suggestion, not a critique or actionable feedback on the existing content. Therefore, it is not 5 in the context of improving the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests using more objective terms than 'remarkable' and questions its appropriateness. While the reviewer doesn't explicitly state what the replacement should be, they are implicitly pointing to a need for more precise language. The action they suggest is to replace 'remarkable' with a more objective term. The reviewer is aware of the visual representation of the improvement and is suggesting a more appropriate label for it.", "grounding_specificity_rationale": "The reviewer mentions 'the axes' in their comment. While they identify a potential area for improvement, they do not explicitly state which figure, table, or specific element they are referring to. The reviewer's comment is about the visual representation of the improvement, but lacks a precise reference to the specific part of the paper being discussed.", "verifiability_rationale": "The reviewer states, 'Looking at the axes, which are rather squished, the improvement is definitely there but it would be difficult to characterize it as remarkable.' This statement expresses an opinion about the visual representation of the improvement and its labeling. However, the reviewer does not provide any external references or logical reasoning to support this claim. The statement is based on their own visual assessment and the difficulty of justifying the use of 'remarkable' based on their observation. There is no explicit claim being made, and the reviewer's assessment is based on their interpretation of the visual data.", "helpfulness_rationale": "The reviewer's comment points out a potential issue with the presentation of the results, specifically the use of the term 'remarkable'. While they don't offer a specific alternative, they suggest a more objective term. This is a valid point as it could improve the clarity and accuracy of the presentation. The reviewer is identifying a potential weakness in how the results are described."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of short video sequences and suggests exploring longer ones. While the suggestion is about a *potential* improvement rather than a specific action on the 16frame part, the criticism is clear. Therefore, it's **3**.", "grounding_specificity_rationale": "The reviewer directly refers to 'short video sequences (e.g., 16 frames)\" and then specifically mentions the problems with these sequences. This is both wellgrounded and specific. Therefore, it's **5**.", "verifiability_rationale": "The reviewer makes a claim about the problems with the synthesized results. They also provide a suggestion, which is more exploratory. The claim is supported by their observation. Therefore, it's **3**.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the evaluation and offers a relevant suggestion. This is a constructive and helpful critique for the authors. Therefore, it's **5**."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review points out a limitation or a missed opportunity. While it identifies a *problem* (inefficiency on GPU), it *doesn't* explicitly tell the authors *what* to do about it or *where* in their work this might be relevant. It's a statement of fact, not a directive.", "grounding_specificity_rationale": "The review mentions \"work on pruning\" and \"GPU.\" While it *mentions* pruning, it doesn't specify *which* pruning method or *which* part of their work it's referring to. The mention of \"GPU\" is also general.", "verifiability_rationale": "The review states a fact about the current state of pruning on GPUs. It does not present a claim that requires further justification or evidence.", "helpfulness_rationale": "The review points out a relevant limitation (inefficiency on GPU) within the broader context of pruning work. While it doesn't offer a solution, it identifies a potential area for improvement or a point of discussion. It helps the authors understand a constraint they might face or consider."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer's comment is explicit about the limitations of the evaluation method, stating it's 'not fully convincing' and based on 'synthetic data'. This directly points to an actionable suggestion for improving the evaluation by considering realworld data. While the comment is clear, it doesn't delve into the specifics of how to implement these changes, making it somewhat general.", "grounding_specificity_rationale": "The reviewer's comment focuses on the 'synthetic data' aspect of the evaluation, which could be interpreted as a lack of clear grounding in realworld scenarios. While the comment identifies a specific aspect (data type), it doesn't explicitly pinpoint a specific part of the evaluation methodology that needs improvement. Therefore, while there's a focus on a specific element, the overall grounding of the comment is not fully explicit.", "verifiability_rationale": "The reviewer's comment expresses a lack of confidence in the evaluation's conclusions, stating it's 'not fully convincing' and that the comparison with 5 is 'not completely fair'. This suggests a lack of strong evidence or justification for the evaluation's claims. The reviewer points out a difference in problem complexity, which weakens the direct comparability, indicating a lack of verifiable support for the evaluation's conclusions.", "helpfulness_rationale": "The reviewer's comment directly criticizes the evaluation method, stating it's 'not fully convincing' and that the comparison with 5 is 'not completely fair'. This clearly indicates a lack of meaningful and actionable feedback for the authors regarding the evaluation. The reviewer's statement is a strong critique of the value of the evaluation itself."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a question and suggests an experiment to investigate the relationship between the number of bits in logits and robustness against a stronger adversary (PGD attack with a larger epsilon). This constitutes an explicit and concrete action, as the reviewer proposes a specific experiment to address a potential weakness or area for improvement.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'numbers of bits in logits' and 'epsilon in the PGD attack' by name. This demonstrates strong grounding specificity, as the reviewer accurately identifies the specific aspects of the paper being discussed.", "verifiability_rationale": "The reviewer does not make a claim. Instead, they suggest an experiment and ask a question. Therefore, the 'X' category applies. While the suggestion is logically sound and potentially verifiable if the experiment were conducted, the prompt focuses on the review point itself, not the potential outcome.", "helpfulness_rationale": "The reviewer provides a clear question and a suggestion for an experiment. This directly addresses a potential gap in the understanding of the impact of logit precision and robustness against stronger adversaries. This is valuable information for the authors, as it guides them towards further investigation and potentially strengthens their work. The suggestion is specific and actionable, making it 5."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "1 (1 and Not Specific)", "verifiability_label": "X (X)", "helpfulness_label": "2 (2)", "actionability_rationale": "The review point asks a question about the outcome of applying a method but does not provide any specific instructions or guidance on how to address it. It is vague and lacks concrete steps for the authors to take.", "grounding_specificity_rationale": "The review point refers to general categories like 'men,' 'women,' and 'insurance' without specifying which section, table, or figure of the paper it relates to. It lacks explicit grounding in a particular part of the document.", "verifiability_rationale": "The review point is a question, not a claim or statement requiring verification. Therefore, it doesn't fall under the verifiability scale.", "helpfulness_rationale": "The review point raises a valid concern about potential unfairness. However, it lacks specific, actionable feedback and doesn't guide the authors on how to address the issue. It's a highlevel concern without concrete suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states \"The meta solvers seem to be centralized controllers\" and provides a clear next step: \"The authors should clarify the difference between the meta solvers and the centralized RL where agents share the weights.\". This is a direct and actionable suggestion for the authors to improve their paper's clarity.", "grounding_specificity_rationale": "The reviewer's comment is general and does not specify a particular section, table, figure, or unique aspect of the paper that needs clarification. They are referring to the concept of \"meta solvers\" and \"centralized RL\" in general. While they imply a connection to how meta solvers are described, they do not pinpoint the exact location or aspect requiring clarification.", "verifiability_rationale": "The reviewer's comment is a claim that the description of \"meta solvers\" in the paper might be interpreted as \"centralized controllers\". While the reviewer doesn't explicitly state what is wrong with the current description, the suggestion to \"clarify the difference\" implies a potential lack of clarity in the paper's explanation of these concepts. The reviewer provides an external reference (Foester et al., 2016) as an example of a centralized RL approach, suggesting a potential point of confusion.", "helpfulness_rationale": "The reviewer's comment points out a potential source of confusion for readers of the paper. By clarifying the relationship between meta solvers and centralized RL, the authors can improve the clarity and accessibility of their work. While it might not be the most immediately critical issue, it addresses a potential point of ambiguity for readers trying to understand the paper's contribution."}
{"actionability_label": "1", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review points out a *problem* (unequal access to information) but doesn't offer a *specific action* to address it. It criticizes the *splitting method* but doesn't suggest an alternative or how to implement a change. The reviewer focuses on the *cause* of the problem (papers being on arXiv earlier) but doesn't provide concrete steps for the authors to take. While the reviewer mentions 'splitting according to publication years on the ACL anthology,' they don't specify how this is a problem or what should be done instead. The criticism is about the methodology, not a direct suggestion for improvement within that methodology.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the BERT paper' as a specific example of a paper that is on arXiv before the ACL anthology publication. They then state what is wrong with this situation: 'many papers are posted on arxiv much earlier than ACL anthology' and 'for example, the BERT paper is available on arxiv from Oct.' This clearly identifies a specific part of the paper and explains the issue with it. The reviewer is not just stating a general observation but pinpointing a specific instance and its implications.", "verifiability_rationale": "The reviewer makes a claim about the BERT paper being available on arXiv before being included in the 2018 ACL anthology split. This is a claim that can be supported by common knowledge in the field. While the reviewer doesn't provide a direct citation, the general understanding that many papers are released on arXiv before formal publication in academic venues is a generally accepted piece of information. This provides a basis for verifying the claim, even if it's not a direct citation. The reviewer's statement is logically sound and based on observable trends.", "helpfulness_rationale": "The review points out a potential issue with the data splitting methodology. While this observation could be helpful for the authors if they are using a similar approach, the review itself does not offer a specific solution or detailed explanation of *why* this is a problem or how it affects their results. The reviewer criticizes the splitting method but doesn't provide actionable advice on how to improve it. The comment is more of a critique of the methodology rather than a direct suggestion for improvement within that methodology."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "Not Directly Evaluated", "actionability_rationale": "The reviewer identifies a potential ambiguity in the definition of M_T and suggests providing examples as a solution. While the reviewer *identifies* a potential issue (the ambiguity of M_T's definition) and *proposes* a solution (providing examples), they do not explicitly state that they will take action to clarify M_T. The reviewer's comment is more about identifying a potential area for improvement than directly addressing it.", "grounding_specificity_rationale": "The reviewer explicitly states: \"Page 3, it seems to me that M_T is defined over the probabilities of atomic events. The notation as it is used not making it difficult to make sense of this concept. Please consider providing examples to explain M_T.\" This clearly identifies the specific section of the paper (Page 3) and the specific issue with the definition of M_T (potential ambiguity regarding atomic events). The reviewer can confidently pinpoint the location and the nature of the problem. Therefore, the grounding is strong.", "verifiability_rationale": "The reviewer makes a claim: \"Please consider providing examples to explain M_T.\" This claim is about suggesting a way to improve understanding. The reviewer does not provide explicit reasoning or evidence within their comment to *justify* why providing examples would be beneficial or how they would ensure the examples are correct or helpful. The claim is presented as a suggestion without detailed backing within the review point itself. Therefore, it is 1 based on the information within this single review point.", "helpfulness_rationale": "The reviewer makes a claim: \"Please consider providing examples to explain M_T.\" This claim is about the potential benefit of the suggestion. While the suggestion itself might be helpful, the reviewer doesn't explicitly state why it would be *beneficial* or how it would *empower* the authors to improve their draft. The claim is about the potential impact of the suggestion, not a direct statement of what the reviewer expects from the comment itself. Therefore, it is not directly verifiable within the comment itself. It's a claim about the potential value of the suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their lack of understanding regarding the motivation and the difference between QRS and RS. However, the feedback is quite general and doesn't offer specific actionable steps for the authors to take.", "grounding_specificity_rationale": "The reviewer refers to key concepts and algorithm names, showing they are trying to locate the issue. However, the questions are broad and don't pinpoint a specific problem within the paper's content.", "verifiability_rationale": "The reviewer makes claims about their own understanding and ability to differentiate algorithms. Crucially, they don't provide any evidence or reasoning to support these claims, making the feedback 1.", "helpfulness_rationale": "The reviewer highlights important areas for improvement (motivation and algorithm difference). However, the feedback is primarily a question format, lacking concrete solutions or guidance on how to address the identified issues."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment does not explicitly state how to improve the observed performance enhancements. It suggests 'further refinement' but lacks specific details on what actions to take.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper being addressed. It refers to 'the observed performance enhancements' without specifying which section, table, figure, or unique aspect is being discussed.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a statement of observation ('modest') and a suggestion ('further refinement').", "helpfulness_rationale": "The comment is general and does not provide specific guidance on how to improve the observed performance enhancements. It suggests 'further refinement' but does not specify what needs to be refined or how."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states two actions: 'please provide references' and 'What is \"MLP\"?'. These are direct instructions for the authors to improve their draft.", "grounding_specificity_rationale": "For the references, the reviewer does not explicitly identify a specific part of the paper being addressed, making it '1'. For the acronym, the reviewer does not identify a specific part of the paper being addressed, making it '1'.", "verifiability_rationale": "The reviewer does not make any claims that require verification. They are simply requesting information or clarification.", "helpfulness_rationale": "The reviewer provides two suggestions for improvement: 'please provide references' and 'What is \"MLP\"?'. These are actionable and directly address potential weaknesses in the paper."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue: 'a) The experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method' and suggests a reason: 'since the performance is similar to IRM'. While the reviewer identifies a problem, they do not provide a specific action or suggestion on how to improve the experimental setup or analysis. The reviewer points out a weakness but doesn't detail how to address it.", "grounding_specificity_rationale": "The reviewer mentions 'the experimental results on the last two datasets' and 'the performance is similar to IRM'. This demonstrates a degree of grounding as the reviewer refers to specific parts of the paper (the experimental results) and even specific elements within that part (the performance metric and the comparison to IRM). However, the reviewer does not specify *why* the performance is similar to IRM, leaving the issue underspecified.", "verifiability_rationale": "The reviewer makes a claim: 'the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method' and 'the performance is similar to IRM is a problem'. This is a clear claim that requires justification. However, the reviewer does not provide any external references, logical reasoning, or examples to support this claim. The connection to the 'problems mentioned above' is vague as no prior 'problems' have been discussed in this context.", "helpfulness_rationale": "The reviewer provides specific information about the issue with the experimental results and points to a potential cause (similarity to IRM). This provides some actionable insight and context for the authors to investigate. The reviewer's question about the cause ('which I wonder if it is caused by the problems mentioned above') indicates a desire for clarification, which is helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer's question is an implicit suggestion that the explanation of why both entities are needed in Figure 2 is unclear or lacking. The reviewer is prompting the authors to understand the rationale behind distinguishing between the long and short entities. While the question is not directly instructing the authors on what to do, it is asking them to infer the reasoning, making it somewhat implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'why should both entities be detected' and 'what is the difference to \"just\" knowing the long one?'. While the paper *does* explain the difference (long entity is the full name, short entity is a shortened version), the *grounding* of this explanation is weak. The reviewer is asking the authors to understand the *purpose* of this distinction, which is not explicitly stated in the paper. The authors need to infer the reason for both types from the reviewer's question, indicating weak grounding.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question about the rationale behind a specific aspect of the paper. Therefore, verifiability is not applicable and should be marked as \"X\".", "helpfulness_rationale": "The reviewer is asking a question, not providing a critique or suggestion. While the question points to a potential area for improvement in the explanation, it doesn't directly tell the authors what to do. The helpfulness is limited as it's a request for clarification rather than a direct critique or actionable suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'I would like to see some experiments where the bounds are validated.' This is an explicit action, stating that the authors should conduct experiments. However, the action is somewhat vague because the 'bounds' are not specified, making it difficult to know exactly what needs to be validated.", "grounding_specificity_rationale": "The reviewer refers to 'some experiments' in general, without specifying which part of the paper or what exactly needs to be validated. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses. The specificity is also low as the request is general and lacks details about the experiments or the bounds to be validated.", "verifiability_rationale": "The review point states 'I would like to see some experiments where the bounds are validated.' This is a claim that suggests a desired improvement. However, the claim is not wellsupported by logical reasoning, common knowledge, or external references. The request is a suggestion for future work rather than a critique of the current state of the paper. There is no clear justification provided for why this is a necessary or beneficial step.", "helpfulness_rationale": "The review point clearly states a desire for more empirical validation. While this is a valuable suggestion for improving the paper, the lack of specificity regarding the 'bounds' makes it somewhat vague and less actionable for the authors. Without knowing what needs to be validated, the authors may not know how to proceed or what kind of experiments to conduct."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential inconsistency in the application of Theorem 1 to a specific case (a node with 0 neighbors), which could be interpreted as an implicit action to clarify the theorem's scope. However, the reviewer does not explicitly state what action they would like the authors to take or how to implement it. The lack of a concrete action makes it difficult to assess the full impact on the authors' ability to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Theorem 1' and 'neighbors' in their comment, indicating they can identify the specific part of the paper being addressed. However, they do not specify *what is wrong* with the theorem's application to a node with 0 neighbors. The identification of the paper section is specific, but the issue being highlighted is not.", "verifiability_rationale": "The reviewer makes a claim that 'the upper bound here is 0' and questions its validity. However, they do not provide any evidence, reasoning, or external references to support this claim or explain why it might be incorrect. The claim is presented without sufficient justification.", "helpfulness_rationale": "The reviewer raises a concern about a potential flaw in Theorem 1's application to isolated nodes. While this highlights an area that needs clarification for the authors, the review point itself does not offer a direct solution or actionable advice on how to fix the issue. It primarily serves as a diagnostic comment."}
{"actionability_label": "2", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a potential lack of technical novelty and draws parallels to two specific papers. However, it doesn't explicitly state what needs to be improved or how the current paper differentiates itself. The suggestion is implied rather than explicit and actionable.", "grounding_specificity_rationale": "The reviewer mentions 'coattention mechanism' and 'architecture' as being similar to the two papers. While they identify a specific part of the paper, they don't clearly specify what is wrong with these components or how the current paper improves upon them. The issue is implied but not explicitly stated.", "verifiability_rationale": "The reviewer claims there is a similarity to the two papers. This constitutes a claim. However, the evidence supporting this claim is weak. The reviewer doesn't provide specific comparisons, citations, or logical reasoning to back up the assertion of similarity. The claim is presented without sufficient justification.", "helpfulness_rationale": "The review point criticizes the potential lack of technical novelty and suggests a lack of detail. While this highlights a potential weakness, it doesn't offer concrete, actionable suggestions for the authors to improve their work. The feedback is primarily critical rather than constructive, lacking specific steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the reason for the less drastic training time reduction: 'most gradients are still computed for early downsampling layers'. This provides a clear, albeit implicit, action: the Discussion should address this observation. However, the reviewer doesn't suggest a specific *how* to address it, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Pg.5' and then to 'most gradients are still computed for early downsampling layers'. This demonstrates strong grounding as the specific section and detail are clearly identified.", "verifiability_rationale": "The reviewer states 'This seems not to have been revisited in the Discussion (which is fine, just delete \u201cDiscussion\u201d).' This is a claim about the state of the Discussion. However, the reviewer doesn't provide any evidence or reasoning to support this claim. It's presented as an observation rather than a verifiable statement.", "helpfulness_rationale": "The reviewer points out a specific area in the Discussion that needs attention. By highlighting the lack of revisiting the observation about gradients, the reviewer helps the authors focus their efforts on improving the completeness of the Discussion. While it doesn't directly suggest a solution, it provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer poses a question, which can be interpreted as an implicit request for clarification. While the reviewer doesn't explicitly state an action to be taken, the act of asking for information about the problem's scope and justification implies a desire for clarification. However, the action itself isn't explicitly stated, making it less actionable than a direct suggestion. The lack of specific information makes it difficult to pinpoint exactly what the reviewer needs.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'downstream tasks' and 'binding affinity prediction'. This demonstrates that the reviewer can identify the specific part of the paper or concept being discussed. However, the reviewer doesn't specify *which* downstream tasks are relevant or *why* the problem is specific to binding affinity prediction. The grounding is present, but the specificity of the grounding is limited.", "verifiability_rationale": "The review point is a question, not a statement containing a claim. Therefore, it doesn't have verifiability in the sense of supporting evidence. The question itself is a request for information, not a claim that needs verification.", "helpfulness_rationale": "The reviewer's question directly addresses a potential ambiguity or lack of context regarding the problem. By asking about the problem's applicability to other tasks and its specificity to binding affinity prediction, the reviewer is seeking clarification and justification. This is a valid and helpful request for the authors to understand the scope and limitations of the problem. While it doesn't propose a solution, it contributes to a deeper understanding of the issue."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's comment is a critique of the paper's analysis of GPTgenerated rumors, stating that the paper points out the challenges but doesn't offer further analysis or solutions. While the reviewer identifies a potential area for improvement, they do not explicitly state what action the authors should take based on this observation. The comment is more about highlighting a gap in the discussion rather than providing a direct instruction for the authors to follow.", "grounding_specificity_rationale": "The reviewer mentions the paper's analysis of GPTgenerated rumors, indicating some level of grounding. However, the reviewer does not specify the exact section, table, figure, or unique aspect of the paper where the analysis is lacking. They raise a general question about the difficulty of detecting GPTgenerated rumors compared to natural ones, without providing specific examples or pointing to a particular part of the paper. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a statement about the paper's analysis: 'The paper points out the challenges of detecting rumors generated by GPT, but further analysis or solutions can be proposed.' This statement is a claim. However, the reviewer does not provide any evidence or logical reasoning to support this claim. They are stating an observation about the paper's content without attempting to verify it. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer's comment points out a potential flaw in the paper's analysis and suggests further investigation into the difficulty of detecting GPTgenerated rumors compared to natural ones. This is a relevant observation that could guide the authors in refining their work. While the reviewer does not provide specific solutions or detailed explanations, their comment highlights a valuable area for improvement and encourages further exploration. Therefore, the comment is 3 in identifying a potential area for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'The technical contribution is limited' and provides a specific example ('the contents of Section 4 are not about a formal and principled solution, but most about heuristics'). This makes the action somewhat explicit as the authors can infer that the technical contribution needs improvement, particularly in Section 4. However, the action is not fully concrete as the authors are not given explicit steps on how to achieve this.", "grounding_specificity_rationale": "The comment explicitly mentions 'Section 4' as a specific part of the paper. This clearly identifies the area being addressed. Furthermore, the comment specifies the *type* of contribution that is lacking ('not about a formal and principled solution, but most about heuristics'). This provides a clear indication of what needs to be improved in Section 4.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is more of a constructive suggestion for improvement rather than a declarative statement that needs to be supported by evidence. Therefore, it does not fit into the verifiability categories.", "helpfulness_rationale": "The comment identifies a valid concern ('limited technical contribution') and provides a specific example ('Section 4 is not formal and principled, but more heuristics'). This suggests a direction for improvement and guides the authors towards focusing on more principled solutions. While it doesn't provide exact implementation details, it offers valuable insight and direction, making it helpful."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a problem with the visual presentation of information in Figure 6. While it doesn't explicitly state the action to be taken, it points to a clear issue that needs addressing. The authors should ideally increase the font size for better readability.", "grounding_specificity_rationale": "The authors can identify the specific part of the paper being addressed, which is Figure 6. However, the comment describes a general issue ('the font size is a little bit small') rather than a specific element within the figure that needs improvement. This makes the grounding somewhat specific but not fully precise.", "verifiability_rationale": "The review point is a factual observation about the font size in Figure 6. It does not contain a claim that requires verification or justification. Therefore, it does not fit into the 'Verifiability' scale.", "helpfulness_rationale": "The review point identifies a clear weakness in the draft (small font size in Figure 6). However, it lacks specific guidance on how to address this weakness. The authors are left with a general suggestion without concrete steps, making it less helpful compared to a more detailed comment."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their opinion about the quasiuniform distribution and suggests exploring alternatives. While the reviewer doesn't provide a specific reason for their concern, the suggestion to 'consider various probability mass functions' is a clear indication of a concrete action they believe should be taken. The reviewer identifies a potential improvement by suggesting experimenting with different PMFs.", "grounding_specificity_rationale": "The reviewer mentions 'probability mass function', 'MixBoost', and 'quasiuniform distribution'. While these are technical terms, the reviewer doesn't explicitly identify the specific section or table in the paper where the PMF is discussed. The reviewer's comment is more about the general approach rather than pinpointing a specific element within the paper.", "verifiability_rationale": "The reviewer makes a judgment about the suitability of the quasiuniform distribution, which constitutes a claim. However, the reviewer does not provide any justification or reasoning for their opinion within the review point itself. The statement 'I think that considering various probability mass function would've added further depth' expresses an opinion but lacks supporting evidence or logical reasoning.", "helpfulness_rationale": "The reviewer clearly states their opinion about the quasiuniform distribution and suggests exploring alternatives. This directly addresses a potential weakness in the experimental setup. The reviewer's suggestion to 'consider various probability mass functions' is a valuable direction for future work and provides a concrete, actionable improvement for the authors."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "1 (1)", "verifiability_label": "1 (1)", "helpfulness_label": "1 (Not Helpful)", "actionability_rationale": "The review point does not propose any specific actions or improvements. It raises a question about the fairness of comparing models based on abstention rates. While it identifies a potential issue with the comparison methodology, it doesn't offer concrete steps the authors could take to address it or how it impacts their work. The comment is more of a critique of the comparison method rather than a direct suggestion for improvement.", "grounding_specificity_rationale": "The review point does not ground its comment in a specific aspect of the paper or the models. It's a general question about the fairness of comparing models based on abstention rates without pinpointing where this discrepancy might be impacting the evaluation. The comment is about the models' behavior in general, not a specific part of the paper or a specific model's behavior.", "verifiability_rationale": "The review point does not make a claim that requires verification. It's a question about the fairness of a comparison, not a statement that needs to be supported by evidence or reasoning. It doesn't present a judgment that needs justification.", "helpfulness_rationale": "The review point is not helpful to the authors. It raises a valid concern about the fairness of comparing models based on abstention rates but does not provide any actionable insights or solutions. It doesn't suggest specific ways the authors could adjust their evaluation or improve their models based on this observation. It's a critique of the comparison method, not a helpful suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need to discuss connections with a specific paper (a Samulowitz & Memisevic, 2008) and highlights the relevance of supervised learning in QBF solving. This is a clear and direct action for the authors to take. The action is also concrete as the reviewer specifies the paper and the concept to focus on.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific paper a and the specific concept 'supervised learning in QBF solving' as the area for discussion. This clearly identifies the specific part of the paper being addressed, making the grounding fully grounded. The specificity is also high as the reviewer names a specific paper and a specific concept within that paper.", "verifiability_rationale": "The reviewer's comment can be interpreted as a suggestion or request for the authors to explore a relevant piece of external work. While it doesn't explicitly state a flaw or error, it points to a potential area of further research or connection. This can be considered 3 as the reviewer provides a basis for the authors to find information and potentially make connections. The reviewer is not making a claim about what is *incorrect*, but rather suggesting a relevant resource.", "helpfulness_rationale": "The reviewer's comment is helpful because it guides the authors to relevant literature and suggests a potential area for further exploration or connection. It provides a concrete direction for the authors to take their work further. While it's not a direct criticism, it's a valuable suggestion that can enhance the authors' understanding and potentially improve their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "6", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a design choice: 'a mono tonic relationship is imposed between the degree of a singletask predictor participation and the weight of the corresponding task loss'. They also suggest an alternative: 'Whether the mono tonic relationship can be replaced by other relationships?'. This clearly indicates an actionable suggestion. The reviewer proposes a change to the existing method and provides a reason for it: 'As a result, the ensemble engenders a subspace that explicitly encodes tradeoffs and results in a continuous parameterization of the Pareto Front. Whether the mono tonic relationship can be replaced by other relationships?'. This suggests a concrete action: exploring alternative relationships. The reviewer's suggestion is direct and provides a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer's comment is a general question about a design choice in the method. They do not explicitly point to a specific part of the paper (e.g., a section, table, or figure) and explain what they find problematic. The comment is about the *concept* of imposing a monotonic relationship, not a specific element within the paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer does not present a claim that requires verification or justification. They are posing a question about an existing method (the one described in 1). There is no assertion of what is wrong with the current approach, nor is there a suggestion of what alternative approach should be taken. The comment is a request for further exploration of the method's properties. Therefore, there is X to be verified.", "helpfulness_rationale": "The reviewer's suggestion to explore alternative relationships for the monotonic constraint is a valuable piece of feedback for the authors. It provides a concrete direction for improving their method and potentially uncovering new tradeoffs. The question is directly relevant to the functionality and performance of the ensemble. While it doesn't offer a specific solution, it raises a pertinent concern and encourages further investigation. The suggestion is actionable and directly related to the described method."}
{"actionability_label": "Explicit and Concrete", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states they are asking about a comparison of computation cost / running time. This is a direct and clear action. Once the comparison is understood, the action is also concrete, as the type of comparison is specified.", "grounding_specificity_rationale": "The reviewer is not explicitly pointing to a specific section, table, or figure in the paper when making this suggestion. While they mention 'computation cost / running time', this is a general concept and not tied to a specific element within the paper being reviewed. Therefore, it is not fully grounded. However, the suggestion itself is specific, focusing on a comparison, making it somewhat specific in its intent.", "verifiability_rationale": "The reviewer is making a suggestion ('How about the comparison...') rather than stating a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support this suggestion. Therefore, it does not have verifiable support.", "helpfulness_rationale": "The reviewer is suggesting a comparison of computation cost / running time. While this is a relevant and potentially useful piece of information for the authors, it does not directly guide them on how to improve their draft. It is an external comparison, not an internal suggestion for improvement within the paper itself. Therefore, it is not 5 in the context of directly improving the current work."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of clarity on the paper's goal in the introduction and provides reasons for this lack of clarity. They suggest specific areas for improvement, such as focusing on problems with nondecomposable loss functions. While the reviewer doesn't provide concrete steps on how to implement these suggestions, the *identification* of these areas is an actionable step for the authors.", "grounding_specificity_rationale": "The reviewer's suggestion to focus on problems with nondecomposable loss functions is quite specific. They are not just saying 'the paper is unclear,' but rather pointing to a *specific area* where the paper needs improvement. This provides a clear target for the authors to focus their revision efforts. The mention of samplingbased Bayesian methods as an example where the results are irrelevant is also a specific point of confusion.", "verifiability_rationale": "The reviewer provides specific suggestions for improvement, such as focusing on nondecomposable loss functions and suggesting alternative algorithms like Hogwild. While the reviewer expresses *doubt* about the current framing and examples, the *suggestions* themselves are based on established concepts in distributed computing and are therefore verifiable. The reviewer could have provided more specific references or examples to further strengthen the verifiability.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as focusing on nondecomposable loss functions and suggesting alternative algorithms like Hogwild. While the reviewer expresses *doubt* about the current framing and examples, the *suggestions* themselves are concrete and point towards specific areas for the authors to revise. The suggestions are actionable and relevant to the potential weaknesses the reviewer is highlighting."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question about the privacypreserving aspect of the approach, which is a direct request for clarification. However, the reviewer does not provide any specific actions or suggestions that the authors should take based on this question. The question itself is clear, but the lack of a concrete solution makes it not fully actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'traffic signal control' aspect as a potential issue, which clearly identifies a specific part of the paper. The reviewer also asks a question about a specific traffic signal scenario, further pinpointing the area of concern. While the reviewer doesn't provide a detailed explanation of the privacy issues within that scenario, they do identify the *specific* section and a *specific* example. This indicates strong grounding.", "verifiability_rationale": "The reviewer raises a concern about the privacy preservation of a specific traffic signal application. While the reviewer presents a claim about the potential privacy issues, they do not provide any evidence, reasoning, or references to support this claim within the review point itself. The reviewer is asking a question but not providing a basis for the authors to verify the claim. Therefore, the claim is not verifiable based on the information provided in the review point.", "helpfulness_rationale": "The reviewer raises a valid concern about the applicability of federated learning to the specific traffic signal scenario. This is a relevant point that could highlight a limitation or area for improvement in the application of the technique. However, the reviewer does not provide any specific suggestions or actions for the authors to take to address this concern. The review point identifies a potential issue but doesn't offer a solution, making it not fully helpful in terms of actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the unfairness of the comparison and suggests a specific alternative. The action is clear: to compare CPEF with another pretrained model. The details are also provided: PMEF lacks a pretraining module, and ExpertBert is suggested. The action is concrete: compare with ExpertBert.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 3,' 'CPEF,' 'PMEF,' and the concept of 'pretraining module.' This is literal mention of specific parts of the paper. The reviewer also explains *why* the comparison is unfair, linking it to the lack of pretraining in PMEF, which is a specific detail within the paper.", "verifiability_rationale": "The reviewer makes a claim about the unfairness of the comparison. The claim is supported by the logical reasoning that PMEF's lack of pretraining makes the comparison unfair. While the reviewer doesn't explicitly cite a specific external reference within the review point itself, the reasoning is based on the established role of pretraining in model performance. The suggestion to compare with ExpertBert implies an awareness of existing pretrained models.", "helpfulness_rationale": "The reviewer's point is 5 because it clarifies a potential misunderstanding for the authors regarding the contribution of pretraining. By highlighting the unfair comparison, the reviewer provides valuable context and helps the authors interpret their results more accurately. While it doesn't directly tell them how to fix the comparison, it clarifies the rationale behind it, which is a significant piece of information for understanding the model's performance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a problem ('The hyperlink... do not seem to work') but does not explicitly state how the author should fix it. The action is implied but not directly stated, making it less actionable.", "grounding_specificity_rationale": "The comment mentions 'footnote 3 and 4,' which provides some grounding by identifying the location of the issue within the paper. However, it does not specify *which* part of footnote 3 or 4 is malfunctioning, leaving the author to infer the specific element.", "verifiability_rationale": "The comment states a problem ('The hyperlink... do not seem to work') but does not make a claim that requires verification. It's a statement of a problem, not a claim that needs supporting evidence.", "helpfulness_rationale": "The comment points out a functional issue (broken hyperlink) that would likely frustrate the author. However, it does not provide any suggestions or guidance on how to resolve this issue, making it less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need to revise the modeling section and provides specific examples of what needs improvement, such as 'better formalization' and 'external parameters'. This indicates a clear and actionable call for change.", "grounding_specificity_rationale": "The reviewer mentions the 'modeling section' and then specifies the issues within it, such as the lack of clarity, the need for 'better formalization', and the figure being a 'misleading representation'. This demonstrates a strong grounding in the specific part of the paper and a clear identification of the issues.", "verifiability_rationale": "The reviewer provides observations about the modeling section, such as its lack of clarity and the need for 'better formalization'. However, they do not provide direct, conclusive evidence to support these claims. The suggestions are inferential and require the authors to make their own deductions.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as 'revising the modeling section', 'better formalization', and 'external parameters'. They also point out a specific area for improvement ('modeling section') and suggest concrete actions within that area. This makes the comment directly actionable and valuable for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the section description is unclear and suggests starting the section with the clearer explanation found in the final paragraph. This is an explicit suggestion because the reviewer identifies the problem (unclear description) and proposes a solution (starting with the clearer explanation). The suggestion is also concrete as it points to a specific location in the paper where the clearer explanation should be. Therefore, the actionability is high.", "grounding_specificity_rationale": "The reviewer states 'this description of the neural network' without specifying the exact section or table. While they identify the topic of the unclear section, they do not pinpoint the exact part of the paper being addressed. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer states that 'this description of the neural network is hard to understand' without providing any external references or logical reasoning to support this claim. The statement is a subjective opinion without any verifiable evidence. Therefore, the verifiability is 1.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by stating 'consider starting the section with it' where 'it' refers to the clearer explanation in the final paragraph. This provides a direction for the authors to improve their writing. While it doesn't fully resolve the issue, it offers a concrete step. Therefore, the helpfulness is 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests an alternative training method (attentionbased) as a potential improvement over the current CTC loss. This is a direct suggestion for the authors to try, making it an explicit action. The reviewer also implies that the current CTC loss is limiting, providing a clear direction for exploration. Once the authors understand the suggestion, the concrete steps to implement it are implied, although not explicitly detailed in this review point. Therefore, it is a concrete action once the direction is understood.", "grounding_specificity_rationale": "The reviewer explicitly states 'It seems like the model is limited to CTC loss...'. This directly points to the CTC loss as the specific issue. The reviewer uses clear and direct language to identify the limitation. While the reviewer doesn't provide specific examples of what is missing under CTC loss, the reference to 'CTC loss' itself indicates a precise identification of the area being addressed. Therefore, the grounding is explicit.", "verifiability_rationale": "The reviewer suggests an alternative training method (attentionbased) as a potential improvement. While the suggestion itself is based on general knowledge of training objectives, the reviewer doesn't provide specific examples, references, or logical reasoning to *justify* why attentionbased loss is a good alternative or how it would specifically improve the model. The implication is that the authors should explore this, but the evidence for its effectiveness is not fully presented in this review point. Therefore, it is 3.", "helpfulness_rationale": "The reviewer suggests an alternative training method (attentionbased) as a potential improvement over the current CTC loss. This is a relevant and actionable suggestion for the authors. The reviewer clearly identifies a potential limitation (CTC loss being limiting) and proposes a concrete next step (exploring attentionbased training). While the reviewer doesn't provide specific details on how to implement this change, the suggestion is directly related to improving the model and is likely to be helpful for the authors. Therefore, it is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the observation about tables being divided into three types and asks a question, making it explicit. However, the action of investigating and potentially changing the division is not explicitly stated or concrete.", "grounding_specificity_rationale": "The authors can accurately pinpoint the section being addressed (Section 3) and identify the specific issue (the three types of tables). The comment specifies what needs to be addressed in this part (understanding the table structure).", "verifiability_rationale": "The comment contains a claim (the observation about tables being divided into three types) and provides some justification (asking for clarification). However, it lacks explicit examples or references to external works.", "helpfulness_rationale": "The comment identifies a point of potential confusion and encourages the authors to seek clarification. It's a constructive comment that helps the authors improve their understanding of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the attack methods are 'naive' and suggests using 'more classical attack methods in NLP'. While this points to a potential weakness in the experimental setup, it lacks specific details on what constitutes a 'naive' method or why the suggested alternatives are superior. The reviewer offers a general criticism rather than a concrete, actionable suggestion for improvement. Therefore, the feedback is somewhat general and lacks specific guidance on how to address the identified issue.", "grounding_specificity_rationale": "The reviewer mentions 'other classical attack methods in NLP' but does not specify which methods are missing or why the current methods are inadequate. The criticism is general and lacks specific examples or details about the shortcomings of the current approach. The reviewer does not identify a specific part of the paper being addressed, making the grounding very weak.", "verifiability_rationale": "The reviewer makes a claim that the attack methods are 'naive' and suggests 'checking the following papers'. This constitutes a claim that requires justification. However, the reviewer does not provide specific evidence or reasoning within their review point to support why the current methods are 1 or why the suggested methods are verifiable. The suggestions are general and lack concrete examples or references within the review itself.", "helpfulness_rationale": "The reviewer criticizes the 'toy setting with classification tasks' and suggests using 'more classical attack methods in NLP'. While the reviewer's suggestions are generally helpful for improving the experimental setup, the criticism itself is somewhat vague and does not directly provide specific, actionable feedback on the paper being reviewed. The reviewer is offering a broader perspective on potential improvements rather than directly addressing the weaknesses of the specific methodology used in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality. This is an explicit statement of a potential issue. However, the reviewer does not specify how to address this, making it only implicitly actionable. The action of identifying a problem is clear, but the action of providing a solution or specific steps is missing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'image generation capabilities of diffusion models' and states that 'mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality.' This clearly identifies the specific part of the paper being addressed and specifies the nature of the effect (affect...which can lead to lower image quality). Therefore, the grounding is full and the specificity is also full.", "verifiability_rationale": "The reviewer states that 'mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality.' This is a claim that something happens. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. The statement is presented as a possibility, not a certainty or something backed by information. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer points out that 'mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality.' While this identifies a potential issue, the reviewer does not offer any specific advice on how to mitigate this effect or what changes might be necessary. The feedback is primarily about a problem rather than offering concrete solutions. Therefore, the feedback is not particularly helpful in terms of guiding improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a concern (fairness of comparisons) but doesn't explicitly state what needs to be done or how to address it. It raises a question about the use of prior knowledge, which the author would need to investigate or address.", "grounding_specificity_rationale": "The review point mentions 'prior knowledge' and 'fairness of comparisons' generally without specifying which part of the paper or comparison is being questioned. It lacks a clear reference to a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The review point raises a concern ('concerns') about the fairness of comparisons but doesn't provide any evidence, reasoning, or external references to support this claim. It's a statement of concern without justification.", "helpfulness_rationale": "The review point raises a concern about fairness but doesn't offer any specific advice, analysis, or suggestions on how to address this concern. It identifies a problem but doesn't provide a solution."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer expresses surprise and a potential misunderstanding about the dominance of 'function words' over 'content words' in a Japanese sentence. While they implicitly suggest that this observation might be incorrect, the review point lacks a direct, actionable suggestion for the authors to improve their draft. The reviewer does not explicitly state what needs to be done or how to address this potential issue. The action is implied but not explicitly stated, making it difficult for the authors to take concrete steps.", "grounding_specificity_rationale": "The reviewer mentions 'Figure 1' in their review point, which grounds the comment to a specific part of the paper. However, the specifics of the issue (the dominance of 'function words' and 'content words') are not tied to a particular element within Figure 1. The comment refers to general linguistic terms rather than a specific issue within a table, graph, or unique aspect of the figure. Therefore, while the comment is grounded in a specific section, it is not fully grounded within a specific detail of that section.", "verifiability_rationale": "The reviewer's statement about the dominance of 'function words' over 'content words' in a Japanese sentence could be interpreted as a claim that requires verification. However, the review point does not provide any evidence, examples, or references to support this claim. The reviewer is essentially asking for clarification, which is a valid request, but without any supporting information, the claim is not verifiable based solely on the content of this review point.", "helpfulness_rationale": "The reviewer's review point primarily consists of expressing surprise and a potential misunderstanding. While this can be helpful for the authors to understand their own lack of clarity, it does not directly provide actionable feedback on how to improve the draft. The review point lacks specific suggestions or requests for changes, making it not particularly helpful in terms of guiding the authors towards a better version of their work."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly suggests a change to the baseline calculation by stating 'I think the minimal kmeans objective over multiple seeds is more reasonable' and proposes 'Minor suggestion: the average of k means objectives with multiple seeds are used as a baseline, I think the minimal k means objective over multiple seeds is more reasonable'. The action is to change the calculation from average to minimum. This is a clear and direct action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'kmeans objective across multiple seeds' as the specific aspect of the baseline calculation being improved. They are also referencing specific papers (1 Jin, Chi, et al. \"Local maxima in the likelihood of gaussian mixture models: Structural results and algorithmic consequences.\" Advances in neural information processing systems 29 (2016): 41164124. 2 Fr\u00e4nti, Pasi, and Sami Sieranoja. \"Kmeans properties on six clustering benchmark datasets.\" Applied Intelligence 48.12 (2018): 47434759.)' to support their claim about the average vs. minimum. This demonstrates a clear understanding of the specific component of the method being critiqued.", "verifiability_rationale": "The reviewer makes a claim that the average kmeans objective is less reasonable than the minimum. They provide reasoning based on the behavior of kmeans algorithms, suggesting that the average is sensitive to outliers and random fluctuations, while the minimum represents the best possible result. While they don't explicitly cite external references within the review point itself for this reasoning, the provided references 1 and 2 are directly relevant to the properties of kmeans and its baselines. The claim is supported by logical reasoning and common knowledge about kmeans.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion. They are directly addressing a potential weakness in the current baseline calculation (sensitivity to initialization) and proposing a specific improvement (using the minimum objective). The suggestion is constructive and directly aims to enhance the robustness of the method. The reviewer acknowledges that it's a minor suggestion, which is a good way to frame a potentially small change."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a perspective on the task without explicitly proposing a concrete action or improvement based on that perspective. While they imply a need for further clarification, the action is not directly stated.", "grounding_specificity_rationale": "The reviewer makes a general statement about the task without pinpointing a specific section, table, figure, or unique aspect of the paper. The grounding is weak because they don't identify where their 'closer to Argument Mining' view originates.", "verifiability_rationale": "The reviewer's statement is an opinion, judgment, or suggestion, which constitutes a claim. However, this claim is not supported by any logical reasoning, common knowledge, or external references. The verifiability is low because the claim is presented without justification.", "helpfulness_rationale": "The reviewer offers a subjective opinion about the task and suggests further clarification. While this raises a valid point that could lead to better framing, it doesn't directly propose a specific, actionable improvement or identify a concrete flaw in the current approach. The feedback is helpful in guiding the authors to consider a different perspective but doesn't immediately solve a problem."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "3 (4)", "verifiability_label": "3 (4)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer raises valid points about the relationship between temperature and uncertainty calibration and the role of the regularization term H. While the paper mentions the regularization term H and its connection to temperature calibration, it doesn't explicitly detail the simultaneous optimization process or the specific purpose of H in preventing overconfidence. The reviewer's questions are directly related to the method description and are aimed at improving understanding. The paper mentions the concepts, but the lack of clarity makes the information less actionable for the authors.", "grounding_specificity_rationale": "The reviewer's questions are about the clarity and consistency of the method description. While the paper mentions the regularization term H and its role in temperature calibration, it doesn't explicitly state which part of the paper it addresses (grounding) or provide specific details on how to implement the calibration (specificity). The questions highlight a lack of clarity in the paper's description, making it difficult for the authors to pinpoint the relevant aspects.", "verifiability_rationale": "The reviewer's questions are about the clarity and consistency of the method description. While the paper mentions the regularization term H and its role in temperature calibration, it doesn't explicitly state which part of the paper it addresses (grounding) or provide specific details on how to implement the calibration (specificity). The questions highlight a lack of clarity in the paper's description, making it difficult for the authors to understand the reasoning behind the method. The paper mentions the concepts, but the lack of clarity makes the information less verifiable.", "helpfulness_rationale": "The reviewer raises valid points about the relationship between temperature and uncertainty calibration and the role of the regularization term H. While the paper mentions the regularization term H and its connection to temperature calibration, it doesn't explicitly detail the simultaneous optimization process or the specific purpose of H in preventing overconfidence. The reviewer's questions are directly related to the method description and are aimed at improving understanding. The paper mentions the concepts, but the lack of clarity makes the information less helpful for the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing reference and provides a specific suggestion ('Lista'). This directly points out a missing element and offers a concrete direction for improvement, making it actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the idea of unrolling, first proposed in, 'Lista'' and names a specific paper. This clearly identifies the specific part of the related work being discussed and provides a concrete example, making it highly grounded and specific.", "verifiability_rationale": "The reviewer makes a claim about the importance of discussing related work and implicitly suggests a comparison with 'Lista'. While the reviewer doesn't provide explicit examples or references within the review point itself, the act of suggesting a comparison and highlighting the importance of discussing related work provides some level of verifiability.", "helpfulness_rationale": "The reviewer directly points out a crucial missing element ('Important reference missing') and provides a specific suggestion ('Lista') by name. This is a valuable contribution that directly addresses a potential gap in the authors' understanding of related work and provides a concrete point for them to explore further. While it could be expanded, it is a helpful starting point."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for an explanation of the objective and constraints in the linear program. This is a direct and clear request for information, making it 5 for the authors to understand the theorem's implications. The request is also concrete, asking for specific details about the objective and constraints in equation (3).", "grounding_specificity_rationale": "The reviewer directly refers to 'Theorem 3' and specifically asks about the objective and constraints in 'equation (3)'. This explicit referencing demonstrates a clear understanding of the paper's structure and the specific location of the relevant information. The reviewer can confidently identify the referenced part of the paper and the specific issue being addressed.", "verifiability_rationale": "While the reviewer's statement that 'this is a main theorem but it would help the reader a lot if the authors can explain what are the objective and the constraints in (3)' suggests they have some prior knowledge of linear programs, the lack of explanation in the paper makes it difficult to verify this claim. The reviewer is stating a common understanding of LPs, but the paper doesn't provide sufficient justification or background for the specific LP in question. Therefore, the claim is 3 as it relies on common knowledge but lacks sufficient explanation within the paper.", "helpfulness_rationale": "The reviewer explicitly states that 'it would help the reader a lot' if the objective and constraints were explained. This indicates a strong perceived benefit for the authors and a clear understanding of the impact of the suggested improvement. The request is specific and directly addresses a potential area of confusion for readers."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the 'FLOT cost matrix in Algorithm 1 is not defined.' This directly points to a missing piece of information and is therefore explicit. While the comment doesn't provide the definition itself, it clearly identifies where the definition should be, making it somewhat concrete in identifying the location of the missing information.", "grounding_specificity_rationale": "The comment explicitly refers to 'Algorithm 1' and mentions 'FLOT cost matrix' as the missing element. This directly identifies the specific part of the paper and the specific issue, making it 5.", "verifiability_rationale": "The comment contains a claim that 'FLOT cost matrix in Algorithm 1 is not defined.' This is a statement that requires justification or explanation. The comment itself does not provide any reasoning or references to support this claim, making it 1.", "helpfulness_rationale": "The comment identifies a specific location (Algorithm 1) where a definition is missing. This points to a clear weakness or area for improvement in the paper. While it doesn't specify *what* the cost matrix should be defined as, it directs the reviewer's attention to a specific part of the paper that needs clarification. Therefore, it is helpful in identifying a problem, even if it's not fully resolved."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for a proof regarding the convergence of a specific term in a mathematical paper. The request is clear and directly targets a potential issue or area for improvement. While the reviewer doesn't state 'prove this,' the willingness to increase the score upon addressing the question indicates a desire for a concrete action to be taken on their part. The request is not implicit but rather a direct call for a specific type of action.", "grounding_specificity_rationale": "The reviewer refers to 'Theorem 2, Eq. (30)' and specifically asks about the 'second term' within that equation. This provides a clear and explicit reference to a specific part of the paper. The request for a 'proof' further specifies the desired outcome. The reviewer's statement 'I'm willing to increase my score if the authors can address my questions properly' suggests they understand the importance of addressing this specific point. The reference is precise and the request is very specific.", "verifiability_rationale": "The reviewer makes a claim: 'Can the authors prove this?' This is a direct assertion about the potential lack of convergence of a specific term. While the request is valuable, it doesn't directly verify a claim *within* the reviewed paper. It asks for external information or justification (a proof) rather than identifying a flaw or error within the current analysis. The request is about the *ability* to prove something, not a statement *within* the paper that needs proof.", "helpfulness_rationale": "The reviewer's question is highly specific and directly addresses a potential issue or area for improvement in the paper. They are asking for a proof, which is a concrete and actionable request. The reviewer's willingness to increase their score upon addressing the question highlights the perceived value of this feedback for the authors. This type of feedback is very helpful as it directly points to a concrete area for action and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential issue with Algorithm 2 (it's unclear) but doesn't explicitly state how the authors should update it. It's unclear if the 'avg' variable is intended to be used and what its purpose is. While it points to a potential action, it doesn't directly instruct the authors on the *specific steps* to take.", "grounding_specificity_rationale": "The comment explicitly refers to 'Algorithm 2' and asks about specific variables within it ('j' and 'i'). This demonstrates a clear identification of the specific part of the paper being addressed and specific elements within it.", "verifiability_rationale": "The comment describes the authors' intention to update Algorithm 2 and address the unclear 'avg' computation. It does not contain a claim that requires verification or justification. It's a statement of fact about the authors' action, not a claim about the paper itself.", "helpfulness_rationale": "The comment points out a potential area of improvement (Algorithm 2 being unclear) and asks specific questions about it. While it doesn't provide a complete solution, it identifies a weakness and guides the authors to investigate specific aspects of the algorithm. It offers a direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to clarify the definition of the sparsity of the residual term and requests evidence to support the sparsity assumption. This directly points to actions the authors should take: seek clarification and provide supporting evidence. While the reviewer doesn't specify *how* to clarify, the request itself is a concrete action. However, the reviewer doesn't specify *which* part of the paper relates to this, making it slightly less actionable than '5'.", "grounding_specificity_rationale": "The reviewer mentions 'residual term' and 'sparsity assumption' when describing the unclear definition. This indicates that the authors can identify the specific part of the paper being addressed, albeit not with perfect precision. The reviewer doesn't explicitly point to a specific section, table, or figure, but the concepts are generally welldefined within the paper. Therefore, it can be considered 'Weakly Grounded'. However, the reviewer does specify the *nature* of the issue (sparsity of the residual term), making it 'Specific'.", "verifiability_rationale": "The reviewer makes a claim that the definition of sparsity is unclear and requests evidence to support the sparsity assumption across various noisy cases. This claim is supported by the logical reasoning of needing clarification and the request for specific examples (evidence). The comparison to existing methods also provides a basis for external references. While the reviewer doesn't provide the evidence themselves, the *request* for evidence and comparison constitutes verifiable claims. The lack of specific section or table reference makes it not '5' in terms of the location of the issue, but the nature of the issue and the type of evidence requested are clear.", "helpfulness_rationale": "The reviewer provides specific areas for improvement by pointing out the lack of clarity regarding the sparsity definition and the need for evidence. They also request a comparison to existing methods, which is a valuable piece of feedback. The reviewer's request is not just a general comment but specific actionable requests for information and analysis. The reviewer is clearly trying to help the authors improve their work, making this a helpful comment."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that 'connectivity' is misleading. This is a direct action the reviewer is taking \u2013 pointing out a specific issue with the terminology. The reviewer also specifies what they believe 'connectivity' should refer to ('structural connections between the brain and body'), making the action concrete.", "grounding_specificity_rationale": "The reviewer does not explicitly name a specific section, table, or figure. They are making a general comment about the terminology used. However, they clearly specify what they believe 'connectivity' should refer to ('structural connections between the brain and body'), which adds specificity to the criticism.", "verifiability_rationale": "The reviewer makes a claim ('connectivity is misleading') but does not provide any evidence or justification for this claim. There is no logical reasoning, common knowledge, or external references provided to support the assertion that 'connectivity' is misleading or what it should be replaced with.", "helpfulness_rationale": "The reviewer points out a potential ambiguity in the terminology used. While it might not be a critical flaw in the core arguments of the paper, it does suggest a need for clarification and improved communication. The reviewer's suggestion to use 'structural connections between the brain and body' is a concrete improvement, even though it doesn't provide a definitive replacement term."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out 'missing details' in various sections, which can be considered an implicit action. However, the specific nature of these missing details is not explicitly stated, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'related work,' 'experiments,' and 'writing,' indicating a clear identification of the specific part of the paper being addressed. This is a strong form of grounding. The reviewer also provides a general description of the missing details within these sections, adding to the specificity.", "verifiability_rationale": "The review states 'The paper is not polished and not ready to publish...'. This is a claim about the paper's quality. However, the reviewer does not provide any specific examples or references to support this claim. The suggestion is general and lacks concrete reasoning.", "helpfulness_rationale": "The review is critical, stating the paper is 'not polished and not ready to publish' and lacks details. While this identifies areas for improvement, it lacks specific suggestions on how to address these issues. The guidance is broad and lacks actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential simplification in step 3 and criticizes the lack of study on the essentialness of using orthogonal matrices. While the reviewer identifies a potential issue (the possibility of a simplification) and suggests a missing element (the lack of study), the action is not explicitly stated. The authors are not directly told to remove the orthogonal matrix or to conduct a specific study. The reviewer's intent is to prompt further investigation and justification.", "grounding_specificity_rationale": "The reviewer refers to 'steps 2 and 3' of the proposed method and mentions the 'weight matrix of this local window MLP' and the 'essentialness of using orthogonal matrix'. While the reviewer doesn't provide a specific section or equation number, they clearly identify elements within the method that are relevant. The reviewer is not just making a general comment but is referencing specific components of the proposed approach. The lack of precise grounding might make it slightly harder for the authors to pinpoint exactly what needs improvement, but the elements being referred to are identifiable.", "verifiability_rationale": "The reviewer states, 'I believe this should be studied' and criticizes the lack of study on the essentialness of orthogonal matrices. This statement can be considered a claim that something is missing (the study) and should be investigated. However, the reviewer does not provide specific examples of why this study is necessary or how it should be conducted. The claim is present, but the supporting evidence (reasons and specifics) are lacking, making it somewhat underjustified.", "helpfulness_rationale": "The reviewer's comment is clear and identifies a potential issue with the proposed method. They point out a possible simplification in step 3 and suggest that the paper should have studied the essentialness of using orthogonal matrices. This provides context and highlights a potential area for improvement. While it doesn't directly tell the authors *how* to fix it, it offers a constructive critique and points towards a missing element, which can be helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue (accuracy drop) and asks a question (is it due to overfitting?). While they don't explicitly state the action to take, they identify a weakness and suggest a possible cause, making it 3.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 5' as the part of the paper they are referring to. This is a clear and precise identification of the section being discussed, making it fully grounded. The reviewer is asking about a trend observed in this specific figure.", "verifiability_rationale": "The reviewer suggests 'overfitting' as a potential reason for the accuracy drop. This is a claim that could be supported by further analysis or references to common knowledge about overfitting in machine learning models. While not definitively proven, it's a plausible hypothesis that can be investigated, making it 3.", "helpfulness_rationale": "The reviewer is asking a question and suggesting an area for further investigation. While they are not directly pointing out a flaw in the methodology or results, they are prompting the authors to consider a known issue (overfitting) in the context of their findings. This encourages further analysis and understanding, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the models and datasets are 'toylike' and provides specific examples of more complex alternatives (CIFAR100, ResNet 34/50, ViT tiny/small). This is an explicit statement of the issue and a clear suggestion for improvement. The reviewer also explicitly states a question, which can be interpreted as an actionable request for clarification.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific models and datasets (CIFAR100, ResNet 34/50, ViT tiny/small) as alternatives to the current ones. This demonstrates a strong grounding as the reviewer can accurately pinpoint the section, table, figure, or unique aspect being addressed (the models and datasets used). The reviewer also specifies the *purpose* of these suggestions (to make the experiments more realistic).", "verifiability_rationale": "The reviewer makes a claim that the models and datasets are 'toylike' without providing any supporting evidence or justification. They do not cite any literature to support their claim or explain why the suggested alternatives are necessary or beneficial. The reasoning is purely based on the reviewer's opinion that these are more realistic benchmarks, but without concrete arguments or references, the claim is not wellverified.", "helpfulness_rationale": "The reviewer's comment is 3 in identifying a weakness in the experimental setup. However, the lack of justification and specific suggestions for improvement makes it less helpful than it could be. The reviewer's desire for more realistic experiments is a valid point, but without the supporting evidence or reasoning, the reviewer is left wondering why these suggestions are necessary or how they would improve the results."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that some natural ablation studies are missing and suggests a specific experiment (scratchGAN) to address this issue. The action of conducting this experiment is clear and concrete.", "grounding_specificity_rationale": "The review point does not specify which ablation studies are missing or why MLE pretraining is questioned. It lacks specificity regarding the part of the paper being addressed.", "verifiability_rationale": "The review point contains a claim (ablation studies are missing) but does not provide any justification or evidence for this claim or explain why scratchGAN is a relevant suggestion.", "helpfulness_rationale": "The review point identifies a potential weakness in the evaluation methodology and offers a concrete suggestion (testing with scratchGAN) to address it, which could be beneficial for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the method used for handling comparisons between episodes of different lengths: padding shorter sequences by replicating their last state. While this directly addresses the issue of comparing episodes of varying lengths, it lacks an explicit statement of the action taken and how it is implemented. The action is implicit.", "grounding_specificity_rationale": "The review point explicitly states the method used for handling comparisons between episodes of different lengths: padding shorter sequences by replicating their last state. While this directly addresses the issue of comparing episodes of varying lengths, it lacks an explicit statement of the action taken and how it is implemented. The action is implicit.", "verifiability_rationale": "The review point explicitly states the method used for handling comparisons between episodes of different lengths: padding shorter sequences by replicating their last state. While this directly addresses the issue of comparing episodes of varying lengths, it lacks an explicit statement of the action taken and how it is implemented. The action is implicit.", "helpfulness_rationale": "The review point directly addresses a specific methodological choice made by the authors regarding how they handle comparisons between episodes of different lengths. It clearly states that shorter sequences are padded by replicating their last state and that there is no normalization factor of 1/T. This provides the authors with concrete information about their methodology. However, the review does not explain *why* this specific choice was made or what the implications are for the interpretability of the distance metric. While the information is present, the lack of justification makes it less helpful in fully understanding the authors' approach."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'In the experiment, the author didn\u2019t consider Vision Transformer' and 'Will the pruning strategy will be different in self attention layers?'. These are direct statements that can be acted upon. The reviewer also implies a potential issue with the pruning strategy based on the missing consideration of ViTs. While the exact nature of the missing consideration isn't specified, the reviewer clearly identifies a potential gap in the analysis. The uncertainty about ViTs' effectiveness on larger datasets adds a layer of vagueness, but the core suggestions are clear.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Vision Transformer' and the specific question about selfattention layers. This clearly identifies the section, topic, and even the *unique aspect* being addressed. The reviewer doesn't just imply a missing element; they name it and its specific area of inquiry. The question about selfattention layers further pinpoints the exact aspect within the missing consideration.", "verifiability_rationale": "The reviewer presents a claim: 'In the experiment, the author didn\u2019t consider Vision Transformer...'. This is a statement of fact (or potential fact) that requires verification. However, the reviewer doesn't provide any evidence or logical reasoning to support this claim. They are raising a potential issue based on the absence of a known SOTA model. The uncertainty about ViTs' effectiveness on larger datasets further weakens the verifiability. There are no external references provided to back up the claim.", "helpfulness_rationale": "The reviewer points out a potential gap in the experimental setup by suggesting the author didn\u2019t consider Vision Transformers. This is a relevant point for the authors to consider when evaluating their model's performance. The reviewer also raises a pertinent question about the pruning strategy in selfattention layers, which is a specific technical detail that could impact the model's behavior. While the review doesn't offer a solution, it highlights a potential area for further investigation and provides a direction for the authors to look. The suggestions are directly related to the paper's content and could help the authors improve their understanding and potentially their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'no comparison against baselines' and explains why this is important: 'This is a widelyunderstood binary analysis application and many papers have developed architectureagnostic similarity comparison (or often reported as codesearch, which is a similar task). Many papers have developed architectureagnostic similarity comparison (or often reported as codesearch, which is a similar task).'", "grounding_specificity_rationale": "The reviewer explicitly states the area of comparison: 'binary analysis and similarity comparison' and even provides a more specific term: 'architectureagnostic similarity comparison' or 'codesearch'. This clearly identifies the part of the paper being addressed.", "verifiability_rationale": "The reviewer provides a clear explanation of why the lack of baselines is a problem: 'It makes it harder to assess the novelty and significance of the work'. While they don't provide specific examples or citations, the claim is logically supported by the reviewer's understanding of the field.", "helpfulness_rationale": "The reviewer clearly states the impact of the missing baselines: 'It makes it harder to assess the novelty and significance of the work'. This provides valuable feedback for the authors to understand the context and contribution of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the change in evaluation methodology for SI 6.5, indicating an explicit action. However, it does not provide concrete details on how this change should be implemented or what the implications are. The action is stated, but the implementation is left ambiguous.", "grounding_specificity_rationale": "The comment explicitly mentions 'SI 6.5' and 'human starts', providing a clear reference point within the paper and a specific term. This allows the authors to identify the relevant section and understand the concept being addressed. The grounding is explicit and accurate.", "verifiability_rationale": "The comment makes a claim that the evaluation in SI 6.5 is 'slightly different' from the previous work. This claim is verifiable by comparing the current SI 6.5 with Mnih et al. 7. The reasoning is present, stating the difference in the evaluation approach. The claim is supported by a logical reasoning.", "helpfulness_rationale": "The comment identifies a change in the evaluation methodology for SI 6.5, which is a specific area for the authors. However, it lacks a clear explanation of *why* this change is being made or *what the implications are* for their work. While it points to a relevant section, it doesn't provide sufficient context or justification to be 5. The feedback is specific but lacks deeper insight."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem and provides concrete details about what makes the figures difficult to parse, including the text size, unclear explanations, and poor captions. This clearly indicates an actionable issue.", "grounding_specificity_rationale": "The reviewer mentions 'Fig. 1 to Fig. 3,' which provides some grounding by identifying the specific figures. However, the reviewer does not specify which *part* within these figures is problematic (e.g., a specific subfigure or a specific type of data). Additionally, while the reviewer mentions 'texts in the figures are too small' and 'inputs and outputs for each task are not clearly explained,' these are general statements and do not pinpoint the exact issue.", "verifiability_rationale": "The reviewer states 'Fig.1 to Fig.3 are very difficult to parse,' which can be considered a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no evidence presented to justify why the figures are difficult to parse.", "helpfulness_rationale": "The reviewer clearly identifies a problem with the figures (difficult to parse) and provides specific details about the issues (text size, unclear explanations, poor captions). This directly informs the authors about areas for improvement. While the reviewer does not suggest specific fixes, the identification of the problem and the details provided are valuable feedback that can help the authors improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the authors claim the proposed method is more efficient. This is an explicit statement of the advantage. However, the reviewer also notes that the paper does not report any metrics to support this claim. While the action (claiming efficiency) is stated, the lack of a concrete *how* makes it less actionable for the authors.", "grounding_specificity_rationale": "The reviewer's point is not directly about grounding or specificity in the traditional sense of pointing to a specific section or detail within the paper. The reviewer is pointing out a lack of *evidence* for a claim made about the method. While the *type* of efficiency being discussed (training) is specific, the *where* the claim is made (in the comparison section) is not explicitly pointed out. Therefore, it can be argued that the claim is not *fully* grounded to a specific part of the paper.", "verifiability_rationale": "The reviewer correctly identifies a claim of greater efficiency. However, the reviewer also points out that the paper lacks any supporting metrics or reasoning to back up this claim. The reviewer's statement that the paper does not report any metric that shows it is more efficient to train with this proposed method directly indicates a lack of verifiable evidence. The claim is present, but there is no justification or supporting information.", "helpfulness_rationale": "The reviewer's point is valuable for the authors as it highlights a missing piece of information (efficiency metrics) that could help them understand and potentially improve their draft. However, the lack of supporting evidence (as pointed out in the verifiability evaluation) makes the advice less helpful. The authors cannot confidently act on the claim of greater efficiency without concrete evidence."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the contribution but does not offer specific, actionable feedback on how to improve it. The reviewer suggests 'differentiable augmentation' but does not explain what limitations the current contribution has or how the suggested augmentation addresses them. The criticism is general and lacks concrete steps for the authors to take.", "grounding_specificity_rationale": "The reviewer mentions 'overfitting problem of training GAN with limited data' and 'differentiable augmentation' but does not explicitly point to a specific part of the paper where these issues are discussed or the proposed solution is described. The connection between the criticism and the paper's content is implied but not clearly established.", "verifiability_rationale": "The reviewer's statement is a critique of the contribution's size. There is X being made, let alone any justification or evidence provided. The statement is an opinion without supporting arguments or references.", "helpfulness_rationale": "The review point provides a general criticism of the paper's contribution but lacks specific, actionable feedback. The reviewer suggests 'differentiable augmentation' as a potential improvement but does not explain how this suggestion can be implemented or what specific issues it addresses. The feedback is vague and does not provide clear guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "None", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks for more details about the statespace, continuity, actions, and the space of theta. While this information is needed, the review point itself doesn't explicitly state what action the authors should take with this information. They are simply requesting it. Therefore, it is 2.", "grounding_specificity_rationale": "The reviewer asks for details about the statespace and theta, indicating they are referring to a specific aspect of the paper. However, they do not explicitly state *which* aspect of the paper they are referring to. They jump directly to asking about specific details without first identifying the relevant section or table. Therefore, the grounding is weak.", "verifiability_rationale": "The review point is a request for more information, not a claim or suggestion that needs verification. There is X being made, and no logical reasoning, common knowledge, or external references are being presented. It is a request, not a critique or a suggestion for improvement based on evidence.", "helpfulness_rationale": "The reviewer's request for more details is inherently helpful as it guides the authors towards a better understanding of the proposed method. However, it is presented as a request rather than a direct suggestion for improvement based on that information. Therefore, it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "Ungrounded and underspecific", "verifiability_label": "1", "helpfulness_label": "Not helpful", "actionability_rationale": "The review point states a limitation of the method (poor performance on general reasoning) compared to math reasoning. This doesn't directly tell the authors *what to do*. It describes a problem but doesn't offer a solution or actionable step.", "grounding_specificity_rationale": "The reviewer points out a *general* weakness without pinpointing the specific area within \"general reasoning\" where the method falls short. The description is vague. \"General reasoning\" is broad and could encompass many subtypes. The authors gain some insights, but the feedback does not fully address their needs for improving the draft.", "verifiability_rationale": "The statement about the method's performance is presented as a fact within the review point, lacking any supporting evidence or reasoning within that point itself. The claim is not supported by logical reasoning, common knowledge, or external references within the review point.", "helpfulness_rationale": "The review point identifies a limitation of the method. While relevant feedback, it doesn't offer a solution or suggestion for improvement. The authors do not know what they should do after reading the comment."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'the proof relies on a special case where a contradiction arises as matrix norms approach infinity.' They also explicitly mention the consequence: 'This is acknowledged by the authors in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable.' The reviewer clearly identifies a flaw in the proof technique and its limitations under specific conditions. This is a direct and clear identification of a problem.", "grounding_specificity_rationale": "The reviewer provides specific references to support their claim: 'After reviewing Appendix A, I noticed that the proof relies on a special case where a contradiction arises as matrix norms approach infinity. This is acknowledged by the authors in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable.' The reviewer names the specific section (Section 3) and theorem (Theorem 1) where the relevant information can be found. This demonstrates a clear understanding of the paper's structure and the location of the pertinent details. The reviewer doesn't just say 'Section X is unclear'; they point to the specific section and theorem that confirm the issue.", "verifiability_rationale": "The reviewer makes a claim: 'After reviewing Appendix A, I noticed that the proof relies on a special case where a contradiction arises as matrix norms approach infinity. This is acknowledged by the authors in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable.' This claim is supported by the information provided in Section 3 and Theorem 1, which the reviewer references. While the reviewer doesn't provide a new proof or example, they point to existing information that confirms the issue. The claim is supported by logical reasoning and references to external works (the paper itself).", "helpfulness_rationale": "The reviewer's comment is 5 because it identifies a specific limitation of the proof technique. By pointing out the special case involving infinite matrix norms and the inapplicability of Theorem 1 due to normalization, the reviewer provides the authors with concrete information about a potential weakness. This allows the authors to consider alternative approaches, acknowledge the scope of their results, or refine their proof under these specific conditions. The reviewer's feedback is directly actionable and provides valuable guidance for the authors' revision process."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests a specific action: 'the continuous diffusion model should be compared as a baseline in Table 3'. This action is clearly stated and directly addresses a potential improvement to the evaluation.", "grounding_specificity_rationale": "The reviewer explicitly identifies the 'continuous diffusion model' as the relevant part of the paper to compare and provides specific details about the 'GDSS framework using classifier guidance' as the method for this comparison. This clearly grounds the suggestion in the paper's context and specifies the implementation.", "verifiability_rationale": "The reviewer presents a claim that 'Although GDSS does not explicitly present a conditional framework, recent work 2 proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline.' This claim is supported by the reference 2 and the logical connection to the initial observation about the performance of continuous diffusion models.", "helpfulness_rationale": "The reviewer's suggestion is directly relevant to the context of the paper, as it builds upon the observed performance difference in Table 2 and proposes a concrete next step for comparison in Table 3. The suggestion is clear and actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests using LiDARbased segmentation as an alternative to object detection for the downstream task. While they identify a potential benefit (accurate locations and poses for IoUbased metrics), the suggestion lacks specific implementation details. The reviewer doesn't explicitly state how the pretraining should be changed or what modifications would be needed to adapt the current model for segmentation. The suggestion is present, but the lack of concrete steps makes it less actionable for the authors.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'LiDARbased segmentation' as a potential improvement and names specific benchmarks like 'KITTI and Waymo' by reference. This indicates a clear identification of the specific part of the paper being addressed and a specific suggestion for improvement.", "verifiability_rationale": "The reviewer makes a claim about the limitations of colorizationbased pretraining for object detection, specifically mentioning its focus on semantics rather than accurate locations and poses. They connect this to the use of IoUbased metrics in benchmarks like KITTI and Waymo, providing a logical reasoning for their claim. The claim is supported by the understanding of how these benchmarks work and the nature of colorization pretraining.", "helpfulness_rationale": "The reviewer provides a clear criticism of the pretraining approach and suggests a potentially better alternative. While the criticism is valid and points towards a specific direction for improvement, it could be more specific about *how* to implement this change. The feedback is generally helpful in identifying a weakness and suggesting a solution, but it lacks concrete steps for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the potential contradiction between the objective of Eq (12) and the IPO principle. This constitutes an explicit action. However, the action is vague, lacking specific details about which part of Eq (12) or IPO is causing the issue, or how the objective is in contradiction. Therefore, while the action is stated, the lack of detail makes it somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'Eq (12)' and 'IPO' when identifying the problematic area. While they don't provide the exact location within the paper, referencing the equation and the principle implies they are identifying specific parts. However, the reviewer does not specify *what* is wrong with the objective of Eq (12) in relation to IPO. The grounding is present, but the specificity of the identified issue is limited. Therefore, it can be considered weakly grounded as the referenced parts are identified, but the specific problem is not clearly defined.", "verifiability_rationale": "The reviewer makes a claim: 'the objective of Eq (12) seems to be in contradiction with IPO.' This constitutes a claim. However, the reviewer does not provide any evidence, examples, or references to support this claim. The verifiability relies solely on logical reasoning, which is insufficient to make the claim verifiable. Therefore, the claim is 1 as there is no supporting evidence provided.", "helpfulness_rationale": "The reviewer points out a potential contradiction between Eq (12) and IPO. While this raises a concern for the authors, the review stops short of providing a specific suggestion or solution. The reviewer identifies a problem but doesn't offer actionable guidance. Therefore, the feedback is not 5 as it lacks concrete suggestions. It is also not unhelpful as the reviewer did identify a concern. The feedback is 3 in identifying a potential issue, but it lacks the depth to be fully helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a desired change: \"replace \"t\" with the size of T\". This indicates a clear action that the authors should take to improve their draft.", "grounding_specificity_rationale": "The review point mentions \"histogram intersection kernel\" but does not specify a particular section, table, figure, or unique aspect within the paper where the change should be applied. The reviewer is suggesting a change to the variable 't' within the context of this kernel, but the exact location of 't' or the specific part of the kernel is not clearly identified.", "verifiability_rationale": "The review point suggests replacing \"t\" with the size of T for the purpose of clarity. While it doesn't provide a specific justification or citation for this suggestion, the intent is to improve the readability and understandability of the code or mathematical formulation. The suggestion is based on a general principle of clarity, which is a reasonable and often accepted practice.", "helpfulness_rationale": "The review point is 5 as it provides a clear and actionable suggestion for improving the clarity of the histogram intersection kernel. The reviewer explicitly states the desired change and the method of implementation (using len(T)). This is a direct and useful piece of feedback for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their 'doubt' about the assumption regarding DINO embeddings. While the reviewer doesn't provide a direct action, the question implies a desire for clarification or further investigation, indicating a degree of actionability. The explicit statement of doubt makes it more actionable than a vague comment.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'DINO representations' and distinguishes between 'geometrically distinctive concepts' and 'concepts where class label correlates more with semantics.' This clearly identifies the specific aspect of the paper being referred to, making it fully grounded. The reviewer also elaborates on the nature of these concepts and the concern about adaptation capacity, adding detail to the identified part of the paper.", "verifiability_rationale": "The reviewer poses a question as a point for clarification, which can be seen as a request for justification or evidence. While the reviewer doesn't provide direct evidence or logical reasoning within this single point, the question implies a need for more information to address the concern. The lack of immediate support makes it less verifiable.", "helpfulness_rationale": "The reviewer raises a valid point about the potential limitations of DINO embeddings for adapting to new concepts, particularly those where semantics outweigh geometry. This highlights a relevant area for further discussion and potential improvements. However, the review primarily poses a question rather than offering concrete suggestions or solutions. While it points to a problem, it doesn't provide immediate actionable advice, making it less helpful overall."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests comparing the proposed method against specific stateoftheart loss functions like CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This is an explicit action, as the reviewer directly states what needs to be done. However, the point lacks concrete details on how to perform this comparison, such as which specific aspects of the method should be evaluated against these loss functions. The action is implied rather than fully stated.", "grounding_specificity_rationale": "The review point mentions 'biometric verification learning' and 'stateoftheart loss functions widely used in face/iris verification' but does not explicitly identify a specific section, table, figure, or unique aspect of the paper where this comparison should be made. The reviewer is commenting on a general aspect of the field and suggesting a comparison. While relevant, the review does not pinpoint a specific element within the submitted paper, making the grounding weak.", "verifiability_rationale": "The review point contains a claim: 'The comparison against the stateoftheart loss functions widely used in face/iris verification should be added'. This is a statement of what the authors should do. However, the review does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion is presented as a recommendation without any justification or context.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper: the lack of comparison against stateoftheart loss functions in biometric verification. This is a relevant suggestion that could help improve the paper's positioning and contribution. However, the review point lacks specific guidance on how to perform this comparison or why it is necessary. The suggestion is vague and does not provide actionable steps for the authors, making it difficult to assess its helpfulness."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point offers multiple explicit suggestions for improvement, such as correcting a grammatical error, a terminology issue, a writing issue, a numerical formatting problem, and referencing inconsistencies. While the *method* of correction isn't always specified, the *action* is clear.", "grounding_specificity_rationale": "The reviewer explicitly points to a specific line for the grammatical correction, another specific line for the terminology issue, a specific word repetition for the writing improvement, a specific table, row, and column for the numerical formatting, and specific lines for the referencing inconsistencies. The reviewer also suggests *specific* types of changes (e.g., grammatical correction, terminology change, writing improvement, numerical formatting, referencing).", "verifiability_rationale": "The review point clearly states what the authors *should* be doing. For example, 'the DOI number is the same as the one at lines 10011002' implies a potential error that needs investigation. Similarly, the suggestions for corrections are implied. The reasons provided are generally verifiable through common practices or logical reasoning.", "helpfulness_rationale": "The review point provides a comprehensive list of specific and actionable suggestions that directly address potential issues the authors might be facing. The suggestions are clear, relevant, and cover various aspects of writing and referencing, making them highly valuable for improving the draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"M and N are used without definition.\" This is an explicit action pointing out a lack of clarity. The reviewer also suggests \"Spell out F.L.T.R, etc.\" which is a concrete action to improve understanding. The reviewer refers to \"Figure 4\" and \"Figure 1,\" indicating they ground the problem in specific parts of the paper. The reviewer's suggestions are directly related to improving the clarity of the figures, making them verifiable claims.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"Figure 4\" and \"Figure 1,\" indicating they ground the problem in specific parts of the paper. The reviewer suggests \"Spell out F.L.T.R in figure 4  Figure 1 text is too small to see,\" which clearly specifies what needs to be addressed in these parts. The reviewer also suggests \"It is recommended to have notation and figure crossreferencing (e.g. M and N are not shown in the figure),\" which is a concrete suggestion for improvement.", "verifiability_rationale": "The reviewer makes clear claims about the confusing notation and the need for improvement. The reviewer's suggestions are directly related to improving the clarity of the figures, making them verifiable claims. The reviewer's suggestions are based on common sense and understanding of how figures are typically used. The reviewer's suggestions are specific to improving the clarity of figures 1 and 4. The reviewer's suggestions are wellsupported by the identified issues with the notation.", "helpfulness_rationale": "The reviewer offers specific, actionable suggestions directly related to improving the clarity of the paper. The reviewer's suggestions are likely to be directly implementable by the authors. The reviewer is not just pointing out a problem but also offering a solution path."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out a potential issue in Algorithm 1 where the same symbol 'p' is used for two different purposes: the phase mixing probability and a dummy variable in the inner loop. This is a clear indication of a potential ambiguity and a concrete action the authors should take: renaming one of the 'p' variables to improve clarity.", "grounding_specificity_rationale": "The reviewer refers to 'Algorithm 1' in their review point, which provides a basis for grounding. However, they do not specify a particular part within Algorithm 1 that needs clarification. The grounding is implied to be the entire algorithm. Therefore, it can be considered '2'.", "verifiability_rationale": "The reviewer states that using 'p' for two different purposes in Algorithm 1 'might be confusing'. This is a statement of judgment about the potential impact on clarity. While it doesn't provide a concrete claim or suggestion, it's a verifiable observation about the potential for confusion. Therefore, it can be considered 'Partially Verifiable'.", "helpfulness_rationale": "The reviewer clearly identifies a potential problem in Algorithm 1 and provides a concrete suggestion for improvement: renaming one of the 'p' variables to reduce confusion. This actionable feedback is directly helpful for the authors to understand and implement the algorithm correctly. Therefore, it can be considered '5'."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests adding a mathematical formulation in the appendix and depicting the WiC task in the figure. While these are suggestions for improvement, they are not explicit actions the authors can directly take from the review point. The reviewer points out a lack of detail in the highlevel description, but doesn't specify *how* to make it more detailed. The sentiment analysis figure is criticized for being abstract and misaligned, but the reviewer doesn't offer concrete, actionable changes to fix this. The suggestions are vague and require further elaboration from the authors.", "grounding_specificity_rationale": "The reviewer does not explicitly identify a specific part of the paper or section being addressed. They mention the 'highlevel description' and the 'figure' in general terms. There is no mention of a unique element or section that the reviewer is referring to. The reviewer's comments are about the *content* of these general elements, not a specific location within the paper.", "verifiability_rationale": "The reviewer states that the highlevel description lacks detail and the sentiment analysis figure is abstract and misaligned with the WiC task. This constitutes a claim that needs to be verified. However, the reviewer does not provide specific examples or references to support these claims. The criticism is general and lacks concrete evidence. The reviewer's suggestions for improvement are also vague and not directly verifiable without further elaboration.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as adding a mathematical formulation and depicting the WiC task in a figure. While these suggestions are relevant to the paper's contribution, they are not immediately actionable for the authors based on the review point alone. The reviewer identifies areas for improvement, but the suggestions are somewhat vague and require further development. The feedback is present but lacks the immediate clarity and specificity needed for maximum impact."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The comment suggests including benchmarking tasks, which is an explicit action. However, it lacks specific details on how to include them or why they are necessary. The action is to 'include', but the method and context are missing.", "grounding_specificity_rationale": "The comment does not specify which part of the paper it is referring to. It is a general suggestion about including benchmarking tasks without pinpointing a specific section, table, figure, or unique aspect of the paper. The reviewer cannot confidently determine which part of the paper they are addressing.", "verifiability_rationale": "The comment states that 'it would have been helpful to include additional benchmarking tasks'. This is a subjective opinion or judgment about a potential improvement. There is X being made that something is missing or that something should be done, but rather a suggestion based on a desired outcome. The claim is that *benchmarking tasks are needed*, but this is not explicitly stated as a claim being made about the paper itself.", "helpfulness_rationale": "The comment suggests adding benchmarking tasks, which is relevant to improving the paper. However, it lacks specific details on *how* to add them, *where* they should be added, or *why* they are necessary. The suggestion is general and lacks actionable steps, making it less helpful than a more detailed comment."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for a comparison of YOSO with Linformer on iterationwise convergence and provides a specific request for the 'steps vs ppl' metric in Figure 4. This is a clear and direct action the authors should take to improve their draft by addressing this gap in the experimental evaluation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Linformer' as the baseline and 'steps vs ppl' as the metric in Figure 4. They also point to 'iterationwise convergence' as the specific aspect of comparison. This demonstrates a clear and precise identification of the relevant part of the paper and the specific issue.", "verifiability_rationale": "The reviewer identifies a missing experimental result ('steps vs ppl' of Linformer with YOSO in Figure 4) and asks for an explanation of the performance difference on downstream tasks (SST2). This can be seen as a claim that needs justification, as the authors should be able to provide a reason for the observed discrepancy.", "helpfulness_rationale": "The reviewer's questions directly address gaps in the paper's experimental evaluation. They are asking for specific data ('steps vs ppl') and an explanation of a performance difference, which are both actionable and constructive suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the discrepancy between the abstract and the text regarding the proposal distribution. It points out that the abstract implies a global upper bound, while the text clarifies it's 'everywhere'. This is a direct identification of a specific issue that needs clarification.", "grounding_specificity_rationale": "The comment explicitly mentions 'proposal distribution' and refers to it being an 'upper bound'. This directly identifies the relevant part of the paper, making it fully grounded. It also specifies the 'everywhere' aspect, adding to the specificity.", "verifiability_rationale": "The comment contains a claim: 'In the abstract the authors require the proposal distribution to upper bound the target everywhere which is not true as the authors themselves clarify in the text.' This claim is partially supported by the location of the clarification mentioned in the text, making it verifiable but not fully supported by explicit examples or external references.", "helpfulness_rationale": "The comment is 5 as it directly points out a potential misunderstanding or inconsistency regarding a key technical detail (the proposal distribution). By highlighting this discrepancy, the reviewer guides the authors to a specific location in the paper and suggests they seek clarification. This directly addresses a need for the authors to understand a specific aspect of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential confusion arising from referencing '15' as 'PointNet'. While the reviewer doesn't explicitly state what action the authors should take, they highlight a specific issue with the current referencing. This allows the authors to identify that the citation '15' does not directly correspond to the 'PointNet' paper they are likely referring to. This provides a clear direction for them to doublecheck and potentially correct the citation. Therefore, while not fully actionable, the reviewer identifies a concrete problem that the authors can address.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly pointing to a specific part of the paper (e.g., 'Section 3.2', 'Table 1'). Instead, they are pointing to a potential issue with the referencing of '15'. However, the reviewer *is* specifying what is potentially confusing: the connection between '15' and 'PointNet'. They are indicating that the citation '15' does not clearly refer to the intended 'PointNet' paper. This specificity lies in the *citation* itself rather than a direct reference to a paper section or table. Therefore, while not fully grounded, the specificity is present.", "verifiability_rationale": "The reviewer's comment does not contain a claim or assertion that requires verification. They are describing a potential issue with the referencing. There is no logical reasoning, common knowledge, or external references provided to support or explain the confusion. The language used is descriptive ('is confusing', 'is misleading'). Therefore, this comment does not fall under the 'Verifiability' category and is classified as 'X'.", "helpfulness_rationale": "The reviewer's comment highlights a potential source of frustration for the authors due to the unclear referencing. While they don't explicitly state what the authors should do, they identify a specific problem that could hinder their ability to understand and build upon the work. The feedback is specific to the referencing of '15' and its connection to 'PointNet'. This points to a concrete issue that the authors can investigate. Therefore, while not fully helpful, the comment provides a specific point of concern that could be addressed, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer raises questions about the optimality of the policy gradient method in Eq. 6 for solving the optimal problem in Eq. 5. While the reviewer suggests considering the limitations of policy gradient methods, the action is not explicitly stated as a direct instruction or action to be taken. The reviewer's questions are more about clarification and understanding rather than directly instructing how to improve the method. Therefore, the action is implicit.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Eq. 6', 'Eq. 5', and 'Line 132' in their review point. This demonstrates a clear understanding of the specific section and equation being discussed in the paper. The reviewer is directly addressing a part of the paper, making the grounding explicit and accurate.", "verifiability_rationale": "The reviewer raises a valid point about the connection between the local optimization in Eq. 6 and the global goal in Eq. 5. This is a logical concern that could be supported by further explanation or references. While the reviewer doesn't provide a definitive answer, the question is clear and directly addresses a potential issue with the method. The suggestion to clarify notation is also a logical next step. Therefore, the claim is 3.", "helpfulness_rationale": "The reviewer's questions directly address a potential weakness in the paper, specifically the optimality of the policy gradient method. The reviewer also suggests clarifying notation, which is a direct and actionable suggestion for improvement. This review point provides clear and actionable feedback for the authors, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about a methodological choice (using a general Gaussian distribution instead of an isotropic one) but does not explicitly demand an action or suggestion from the authors. While the authors might infer that understanding this choice is important for the algorithm's behavior, the review point itself doesn't prompt them to take a specific action to improve their draft.", "grounding_specificity_rationale": "The review point does not attempt to identify a specific part of the paper or algorithm where this distribution choice is made. It is a general question about the method.", "verifiability_rationale": "The review point introduces a claim (the difference between general and isotropic Gaussian distributions) but does not provide sufficient justification or references to support this claim within the review itself. The authors would need to infer the implications of this choice from their existing knowledge of Gaussian distributions or by looking up the relevant concepts.", "helpfulness_rationale": "The review point is 3 as it prompts the authors to consider a relevant methodological choice (distribution type) and asks for clarification on its implications. This could help them understand the algorithm's behavior and potentially identify areas for improvement. However, the request is not a direct suggestion for an improvement, making it less '5'."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the action of 'freezing the partitioning' and implies the need for a concrete action by suggesting 'discuss the limitations'. This makes the action clear and directly actionable, fitting the definition of explicit action. While the comment doesn't provide specific details on *how* to freeze or *what specific limitations* to discuss, the action and the desired outcome are welldefined, making it concrete as well. The reviewer is directly pointing out a potential improvement needed.", "grounding_specificity_rationale": "The comment explicitly refers to 'Line 192', providing a precise location in the paper where the partitioning is discussed. This allows the authors to accurately identify the section being addressed, fulfilling the criteria for 'Full Grounding'. The comment also clearly identifies the issue as the 'limitations of this', specifying the area of discussion within that section.", "verifiability_rationale": "The comment itself does not contain a claim in the sense of presenting a definitive statement of truth. Instead, it points out a potential issue ('a risky choice') and suggests an action ('discuss the limitations'). While the suggestion to discuss limitations can be seen as an implicit claim that the current approach needs improvement, the comment lacks any logical reasoning, common knowledge, or external references to support this point. Therefore, it is best classified as '1' as it doesn't provide any evidence or justification for why freezing partitioning is inherently risky.", "helpfulness_rationale": "The comment identifies a potential weakness ('a risky choice') and explicitly suggests an improvement ('discuss the limitations'). This directly addresses a likely area for the authors to improve their draft. While it doesn't provide specific *howto* guidance, it clearly points in a direction that could lead to positive change. Therefore, it is a '3' comment as it identifies a meaningful issue and suggests a concrete direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point is a question, which doesn't directly instruct the authors on what to do. While it implicitly suggests the reviewer wants to understand the section's purpose, the action is not explicitly stated. The lack of a clear action makes it less actionable than a statement that says, for example, 'Section 5.2 needs a clearer explanation of its methodology.'", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 5.2' as the area of focus. This directly identifies the specific part of the paper being addressed, making it fully grounded. The reviewer is asking about the intent *of* this specific section, not a general area.", "verifiability_rationale": "The review point is a question, which does not contain a claim or assertion that needs verification. It's a request for information rather than a statement that can be logically reasoned, supported by external references, or deduced from the paper. Therefore, it lacks verifiability as defined in the prompt.", "helpfulness_rationale": "The review point is a question, which does not directly provide actionable feedback or suggestions on how to improve the draft. While it highlights a potential area for clarification, it doesn't tell the authors *what* to change or *how* to address the lack of intent. A helpful comment would be something like, 'Section 5.2 could benefit from a more explicit explanation of its objectives and methodology.'"}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer provides specific areas needing clarification (e.g., interaction between knowledge types, overall approach, benefits). This is explicit. However, the *nature* of the clarification needed is vague. The reviewer *doesn't* specify *what* is unclear or *how* the approach works. The action is implied but not explicitly stated with concrete details.", "grounding_specificity_rationale": "The reviewer mentions \"many aspects of the approach\" and \"how it makes knowledge about objects interact with knowledge about verbs.\" These are highlevel aspects of the approach. The reviewer also refers to \"the paper\" generally and doesn't pinpoint a specific section or table. The concern about \"why it is a good idea\" is a general question about the motivation, not tied to a specific part of the paper.", "verifiability_rationale": "The reviewer doesn't make a direct claim about the *quality* of the paper (e.g., \"The paper is flawed\"). Instead, they express a concern about the *clarity* and *motivation* of the approach. There's no suggestion of *what* is wrong or *how* the approach is lacking, beyond the general areas mentioned. The review point focuses on identifying areas for improvement rather than making a claim that needs verification.", "helpfulness_rationale": "The reviewer clearly identifies areas for improvement (clarification). The concern about the \"why it is a good idea\" highlights a lack of clear motivation. While the feedback points to a valid issue, the lack of specific details makes it less immediately actionable for the authors. The reviewer expresses a need for more information rather than a direct critique or solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point asks the authors to define the threat model more explicitly. While this implies an action (improving clarity), it does not provide concrete steps or a specific direction for this definition. The authors are not told *what* needs to be clarified or *how* they should approach the definition. Therefore, while the point suggests an improvement, the lack of specific action makes it only partially actionable.", "grounding_specificity_rationale": "The review point asks for a more explicit definition of the threat model. While this could relate to the methodology or experiments sections, it does not specifically point to a unique element within a particular section of the paper. The reviewer is asking for a more general clarification rather than a specific change to a defined part of the work. Therefore, the information is not explicitly tied to a specific part of the paper, making it 1.", "verifiability_rationale": "The review point states that the threat model needs further clarification. This is a claim that something is needed. However, the point does not provide any justification or examples for why the threat model needs clarification or how this clarification should be approached. The suggestion is present, but the supporting evidence is missing, making it 1.", "helpfulness_rationale": "The review point identifies a relevant area for improvement \u2013 the clarity of the threat model. This suggests a meaningful suggestion. However, the point lacks specific details about what aspects of the threat model need clarification or how the authors should go about clarifying it. While the point is relevant, the lack of actionable steps makes it 3 but not entirely helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a missing justification for a methodological choice (using link prediction accuracy for early stopping) but doesn't specify the exact action the authors should take to address this weakness. They identify the implicit action of 'choosing link prediction accuracy' but lack concrete guidance on *why* this was done.", "grounding_specificity_rationale": "The reviewer explicitly states the section (590) where the decision to use link prediction accuracy for early stopping is made. They also state that the authors can deduce that this is the decision being made. However, they do not specify *why* this decision was made.", "verifiability_rationale": "The reviewer makes a claim (link prediction accuracy should be the sole metric for early stopping) and requests justification. This claim is 3 because the paper doesn't explicitly refute this choice. However, it's not 5 because the paper doesn't provide examples or cite literature to support this design choice.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential weakness in the paper's methodology (the choice of evaluation metric for early stopping). They are asking for a justification for this choice, which is a valuable piece of feedback for the authors. While it might not immediately provide a solution, it highlights a potential area for improvement and prompts the authors to think critically about their methodology."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "None of the claims in the review point provide explicit and concrete actions for the authors. The reviewer states that the ChatGPT baseline is 'rudimentary' and that 'fewshot approach isn\u2019t tested,' but these are general observations about the baseline and experimental setup, respectively. The reviewer also suggests that 'including the discourse relation information in the prompts (probably in a ChainofThought style approach) might yield good results,' which is a suggestion but lacks specific implementation details. The reviewer's final statement that 'it is extraneous to their line of evaluation as presented' is an opinion, not an actionable suggestion.", "grounding_specificity_rationale": "The review point mentions the 'ChatGPT baseline,' 'fewshot approach,' and 'discourse relation information' but does not specify which particular aspect of the paper or experiment these relate to. For example, it refers to the 'rudimentary' nature of the baseline without pointing to a specific section or table where this baseline is discussed. Similarly, it mentions 'fewshot approach' without specifying which approach was used or where it is documented. The suggestion to include 'discourse relation information' is also general and does not point to a specific part of the paper where this information is relevant. While the reviewer identifies the *type* of information being discussed, they do not ground these claims in specific, identifiable parts of the paper.", "verifiability_rationale": "The review point contains claims that can be partially verified. The statement 'fewshot approach isn\u2019t tested' is a factual observation about the experimental setup, which the authors could verify by examining the paper's methodology section. However, the other claims, such as 'The ChatGPT baseline is very rudimentary' and 'including the discourse relation information in the prompts (probably in a ChainofThought style approach) might yield good results,' are more subjective or speculative. While the suggestion about discourse relations is based on common practices, it is not definitively proven or disproven by the paper. Therefore, some aspects of the claim are verifiable, while others are not.", "helpfulness_rationale": "The review point provides some relevant information about the limitations of the ChatGPT baseline and the lack of testing of fewshot approaches. However, it does not offer concrete, actionable suggestions for the authors to improve their draft. While the suggestion to include 'discourse relation information' is a potential area for improvement, it is vague and lacks specific implementation details. The reviewer's final statement that 'it is extraneous to their line of evaluation as presented' is an opinion, not a constructive suggestion. Therefore, the review point offers limited guidance for the authors to make improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3: Partially Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the paper doesn't explain how the pruning was done (\"no details on how actual pruning was done\") and that the ground truth of sensitivity is not explained (\"no details on how actual ground truth was achieved\"). While the reviewer identifies an area lacking detail, the action of identifying this lack of detail itself is not explicitly stated. The reviewer infers the need for more information. The vagueness of the criticism further supports it being implicit. Therefore, the action is implicit, making it 2 as the action itself is not directly stated.", "grounding_specificity_rationale": "The reviewer mentions \"lines 238239\" and specific phrases like \"we first estimate a layer's sensitivity by pruning...\". This indicates that the reviewer can identify the section of the paper being discussed. However, the reviewer cannot pinpoint the exact details within that section that are missing. The lack of detail is implied but not explicitly stated as a missing element. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part. The specificity is partially specific as the reviewer points out the lack of detail regarding the pruning process and the ground truth, which are specific aspects of the method.", "verifiability_rationale": "The reviewer makes a claim that the paper \"just says\" how sensitivity is estimated without providing details on the pruning process or the ground truth. This is a subjective opinion requiring justification. The paper makes a statement (\"we first estimate a layer's sensitivity by pruning...\") but does not provide sufficient evidence or justification for this claim. There is no logical reasoning or external references provided to support the *absence* of this detail. Therefore, the claim is partially justified as the paper makes a statement but lacks supporting evidence.", "helpfulness_rationale": "The reviewer's comment is a constructive criticism aimed at improving the clarity and completeness of the paper. By pointing out the lack of detail regarding the pruning process and the ground truth of sensitivity, the reviewer is providing a specific area for improvement. While the criticism might not be the most comprehensive feedback possible, it is definitely helpful for the authors to understand what information is missing and how to address it. The reviewer's comment directly addresses a specific issue and suggests a concrete improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states that some parts could be written more clearly. While the reviewer identifies specific lines (97, 105106), they don't directly state how to improve the clarity. The action is implied but not explicitly defined.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific lines (97, 105106) where clarification is needed. They also ask for a definition of a 'proper rotation matrix' and to clarify a mathematical statement, providing a clear indication of what needs to be addressed and why.", "verifiability_rationale": "The reviewer points out potential areas of confusion in the paper. While they identify a potential issue (the matrix not being positive semidefinite), they don't explicitly state what is wrong or provide a clear justification for why it is a problem. The need for external references or further clarification is implied but not explicitly stated.", "helpfulness_rationale": "The reviewer directly addresses potential areas of confusion for the authors by asking for clarification on key concepts and mathematical statements. This provides actionable feedback and is likely to be helpful in improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the suggestion to change the term 'g activation function' to 'binary operator' and provides a reason for this suggestion by drawing an analogy to the 'activationpooling operator' in Cohen and Shashua, 2016. This clearly indicates an intended action.", "grounding_specificity_rationale": "The reviewer accurately identifies the specific term 'g activation function' and draws a parallel to the concept of 'activationpooling operator' in the cited work. This demonstrates a strong grounding as the specific part of the paper and the relevant concept are mentioned.", "verifiability_rationale": "The reviewer makes a claim suggesting that 'binary operator' would be a better term for 'g activation function' by analogy to the 'activationpooling operator'. While the reviewer doesn't provide a direct citation within the review point, the intent is to suggest a connection to an existing concept. The claim is somewhat inferable but could be more explicit with a citation.", "helpfulness_rationale": "The reviewer's point is highly relevant to improving the clarity and precision of the notation in the paper. Suggesting an alternative term that aligns with existing concepts can help readers understand the intended operation. This is a valuable suggestion for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the action of 'shrinking the captions' and provides a concrete suggestion of 'leaving more space for methods or related work'. This is a direct and specific action that the authors can readily implement.", "grounding_specificity_rationale": "The reviewer explicitly identifies the parts of the paper being addressed by mentioning 'Fig. 1 and Fig. 2'. This is a strong form of grounding as the authors can directly locate the relevant figures. Furthermore, the reviewer explains *why* the captions are an issue ('large overlaps') and *what to do' (shrink them), making the grounding very specific to the identified figures.", "verifiability_rationale": "The reviewer identifies a potential issue ('large overlaps' in the captions) and suggests a concrete action ('shrinking the captions'). While the reviewer doesn't provide external references or a definitive proof of the overlap, the suggestion itself is a logical and verifiable claim. The reviewer implies that the captions are redundant and that shrinking them would improve the paper's presentation. The suggestion is actionable and directly addresses the identified issue.", "helpfulness_rationale": "The review point clearly identifies a potential issue with the figure captions ('large overlaps') and offers a direct and actionable suggestion ('shrinking the captions') to improve the presentation of the paper by allocating more space to methods or related work. This is a helpful comment as it directly addresses a practical aspect of the paper's structure and presentation."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing citation 'Vidgen et al, 2021' from Table 2 and asks a direct question about why this dataset was not used as a potential benchmark. This provides clear guidance on what the authors should do to improve their draft by including this work in their evaluation. The reviewer identifies a specific area for improvement and suggests a concrete action.", "grounding_specificity_rationale": "The reviewer refers to 'Table 2' within the paper, providing a specific location for the missing citation. They also mention 'this work' in a general sense, which could be interpreted as referring to the current paper or a broader concept of context in hate detection. While the initial grounding is specific, the later part of the statement is less precise. The reviewer clearly identifies the missing element and the potential benefit of including it.", "verifiability_rationale": "The reviewer states that 'this dataset might be really similar to the dataset presented in this work' and 'should be used as a potential benchmark'. This is a claim that requires justification. While the reviewer provides a reason for similarity, they do not explicitly provide evidence or references within the review point itself to support this claim. The claim is somewhat supported by the reviewer's reasoning, but lacks concrete backing within the review itself.", "helpfulness_rationale": "The reviewer identifies a potential issue by pointing out the missing consideration of a potentially relevant dataset (Vidgen et al, 2021) and its potential use as a benchmark. They ask a question to justify why this dataset was not used, which is a direct request for clarification and justification. The reviewer also suggests including this work as a benchmark, which is a concrete and actionable suggestion for improvement. This review point directly addresses a potential gap in the evaluation and offers a clear direction for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem of presenting results from single runs and offers concrete, actionable solutions such as calculating the mean over many runs and including error bars. This directly addresses the identified issue and provides clear guidance for improvement.", "grounding_specificity_rationale": "The reviewer refers to a specific experiment ('the results comparing standard vs. evolutional dropout on shallow models') and explains why this experiment needs improvement ('the results are from single runs, potentially subject to significant fluctuations') and how it should be improved ('mean over many runs (at least 10), ideally with error bars)'). This demonstrates a clear understanding of the specific area and the proposed solution.", "verifiability_rationale": "The reviewer makes a claim about the statistical rigor of the results but does not provide any logical reasoning, common knowledge, or external references to support this claim within the scope of this review point. They simply state the desired statistical practice without explaining why it's a valid or necessary improvement for the results.", "helpfulness_rationale": "The reviewer identifies a weakness in the presented results (lack of statistical rigor due to single runs) and offers specific and actionable suggestions for improvement (mean over many runs and error bars). These suggestions are directly aimed at addressing the identified weakness and empowering the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer describes the proposed approach as 'merely learning a surrogate model for solving the linear/linearized system of equations arising in FEM'. While this provides some actionable information, it doesn't explicitly state what the authors should do next or how to implement this surrogate model. The reviewer explains *why* it's still relying on FEM components, but not *how* to improve the draft based on this observation. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'basis functions,' 'meshes,' 'stiffness matrix assembly,' and 'FEniCS' in the context of the proposed approach. These are specific technical terms directly related to the method being criticized. The reviewer also mentions 'surrogate model for solving the linear/linearized system of equations,' which implicitly refers to a specific aspect of the method. This strong identification of specific parts of the method clearly demonstrates high grounding specificity.", "verifiability_rationale": "The reviewer states that 'operator learning methods could potentially replace the need for carefully choosing basis functions and meshes and assembling stiffness matrices.' While this is a plausible suggestion, the reviewer's *review point itself doesn't provide evidence to *verify* this claim. The statement is a potential future direction, not a current limitation that's been proven. The claim is presented as a possibility, not a verifiable fact within the review point.", "helpfulness_rationale": "The reviewer clearly criticizes the reliance on FEM and suggests operator learning as an alternative. This conveys a negative assessment. However, the reviewer doesn't explicitly recommend operator learning or provide strong evidence *for* its superiority within the review point itself. The criticism is present, but the recommendation isn't strongly backed by evidence *within the review point*. The reviewer points out a limitation, but doesn't offer a concrete, wellsupported improvement."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the action the authors need to take, which is to describe the experimental environment in more detail, including the CUDA and PyTorch versions. It also provides concrete information about the specific versions required. This makes the action clear and directly actionable for the authors.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper that is missing information. While it implies that the lack of detail in the experimental environment is a problem, it does not point to a particular section, table, or figure. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a suggestion for improvement rather than a statement that needs to be supported by evidence or logical reasoning. Therefore, it does not fit into the categories of 'claim extraction' or 'verifiability verification'.", "helpfulness_rationale": "The comment is 5 because it provides specific and actionable feedback to the authors. It tells them exactly what information is missing (CUDA and PyTorch versions) and what they need to do to address it. This is a direct and useful suggestion for improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states a fact and expresses an opinion. While they identify a limitation of realistic datasets, they do not provide explicit or concrete actions for the authors to take to address this. The opinion about societal impact is also not actionable.", "grounding_specificity_rationale": "The reviewer makes a general statement about the limitations of realistic datasets and the societal impact. They do not specify which aspects of variation are difficult to control or which specific societal impact they are referring to. The references are broad and lack specificity.", "verifiability_rationale": "The reviewer makes claims about the limitations of realistic datasets and the societal impact. However, they do not provide any evidence or reasoning to support these claims. The statements are presented as facts without justification.", "helpfulness_rationale": "The reviewer points out a limitation and expresses agreement with the authors' judgment about societal impact. While this is a valid observation, it does not offer any actionable feedback or suggestions for improving the draft. The review is more of a constructive criticism than a helpful suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the paragraph is unclear and suggests a missing element ('there are bandit algorithms that plan to explore') and provides a concrete example ('Gittins strategy, which treats the evolution of the posterior for each arm as a Markov chain'). This indicates a clear action the author should take: seek clarification on the paragraph's content and the role of bandit algorithms, particularly focusing on the Gittins strategy.", "grounding_specificity_rationale": "The reviewer refers to 'this paragraph' and then specifically mentions 'the figure' and the 'dashed lines in the figure'. This indicates that the reviewer has identified specific parts of the paper being addressed, making the grounding explicit and precise.", "verifiability_rationale": "The reviewer provides a claim ('the dashed lines indicate that the agent can plan ahead...') and supports it by mentioning 'Gittins strategy, which treats the evolution of the posterior for each arm as a Markov chain'. While the explanation of the dashed lines is vague ('dashed lines indicate that the agent can plan ahead...'), the reference to Gittins provides a basis for understanding, making the claim 3.", "helpfulness_rationale": "The reviewer identifies a lack of clarity in a paragraph, points out a relevant prior work (Gittins strategy) that could be helpful, and criticizes a figure's presentation. These points provide actionable feedback and highlight areas for improvement, making the review 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the suggestion to 'mention the evaluation metric' and its benefit for clarity. This directly points to a specific action the authors should take. The action is also quite concrete, directly stating what needs to be done.", "grounding_specificity_rationale": "The reviewer explicitly states 'For clarity, it would be better if the evaluation metric is mentioned here'. This directly refers to a specific part of the paper (the discussion of evaluation metrics) and its elements. The reviewer also mentions 'the Fmeasure scores (LF1) (including ROOT arcs)', which specifies the aspect of the evaluation metric being referred to.", "verifiability_rationale": "The reviewer makes a claim that 'mentioning the evaluation metric will improve clarity'. While this is generally true, the reviewer does not provide any specific evidence or reasoning to support this claim within the review itself. The benefit is implied rather than explicitly proven.", "helpfulness_rationale": "The reviewer provides a suggestion for improvement by suggesting the inclusion of an evaluation metric. This is a clear and actionable suggestion that directly points to a specific change the authors should make. While the suggestion is helpful, it is relatively minor and focuses on presentation rather than addressing a major technical issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests 'studying the behaviour of the model under higher noise.' This is a clear and explicit action that the authors can directly implement. The suggestion is also concrete, specifying 'higher noise' which implies a clear contrast to the currently stated noise level of 3.", "grounding_specificity_rationale": "The reviewer refers to 'the observations in the plot compared to the true trajectories.' This is a specific part of the paper that the authors can identify. The comment directly relates to this visual element, making the grounding explicit.", "verifiability_rationale": "The reviewer states that the standard deviation of the noise is '3, but judging from the observations in the plot compared to the true trajectories, this is actually not a very high noise value.' This statement is a claim that requires verification. While the *observation* is grounded, the claim about the noise level being 'not very high' lacks a clear definition of what constitutes 'high' noise or a reference to external standards. The reasoning is subjective based on visual interpretation.", "helpfulness_rationale": "The reviewer suggests 'studying the behaviour of the model under higher noise.' This is a relevant and actionable suggestion that directly addresses a potential limitation highlighted by the authors. While the review point itself doesn't definitively prove the noise is low, it provides a clear direction for further investigation that could be beneficial for the authors. The suggestion is concrete and directly related to the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states a fact about the limitations of the approach but does not explicitly tell the author what to change or how to improve. While it identifies a problem, it lacks specific actionable steps. For example, it mentions 'arbitrarily long inputs' but doesn't specify how large these inputs need to be or what concrete changes are needed to address this limitation.", "grounding_specificity_rationale": "The review point refers to 'the bounds' and 'arbitrarily long inputs' without explicitly pointing to a specific section or table. While it mentions a general concept like 'arbitrarily long inputs', it doesn't provide a precise reference to a specific part of the paper where this limitation is discussed. The grounding is weak because the connection to a specific part of the paper is not clear.", "verifiability_rationale": "The review point makes a claim about the limitations of the approach based on the information provided ('o(1) terms' and 'arbitrarily long inputs'). This claim is supported by logical reasoning within the review itself. While it doesn't provide external references, the logic connecting the mentioned terms to the limitation is clear and verifiable.", "helpfulness_rationale": "The review point identifies a limitation of the approach, which is a form of feedback. It encourages the authors to consider the scope and applicability of their work. However, it doesn't offer specific suggestions for improvement or concrete steps to address the identified limitation. The feedback is focused on highlighting a problem rather than providing a clear path towards resolution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point is a question prompting further investigation rather than a direct instruction on how to modify the draft. While the reviewer is interested in seeing how DVP performs on video with different lengths, the point itself doesn't specify what needs to be changed or done in the current draft.", "grounding_specificity_rationale": "The review point is a general question about the performance of DVP on video with different lengths. It does not explicitly or implicitly refer to a specific part of the paper, such as a table, figure, or unique element. The reviewer is asking about a broad concept rather than a specific issue within the paper.", "verifiability_rationale": "The review point is a question, not a claim that requires verification. It does not make any assertions or judgments about the paper. Therefore, it does not present a verifiable statement that can be supported by evidence or references.", "helpfulness_rationale": "The review point raises a relevant question about the performance of DVP on video with different lengths. While it prompts further investigation, it does not directly provide actionable feedback or suggestions on how to improve the current draft. It is more of a prompt for further analysis than a direct improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer's point is an implicit request for clarification. While they desire an action (clarification), the specific section or detail causing confusion is not explicitly mentioned, making it vague.", "grounding_specificity_rationale": "The reviewer expresses confusion about the paper's focus on cloze queries but does not specify which part of the paper or what aspect is unclear. This makes the grounding weak as the authors cannot confidently determine the referenced part. The specificity is also low as the nature of the confusion is not detailed.", "verifiability_rationale": "The review point does not contain a claim. It is a statement of confusion rather than a statement requiring justification or evidence.", "helpfulness_rationale": "The reviewer explicitly states they were confused about the paper's focus on cloze queries. While the clarification came later in the paper, the initial confusion made the review point helpful in guiding the authors to seek more information."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the KLdivergence term is ignored in equation (3) in Section 3.3. They also provide a concrete action for the authors to take: 'Can you evaluate such approximation error, ie. calculate the actual KLdivergence and check whether it indeed approaches zero? Experiments:'. This clearly indicates an actionable suggestion with a defined methodology.", "grounding_specificity_rationale": "The reviewer directly references 'Section 3.3' and 'equation (3)' in their review. This is a clear and specific identification of the part of the paper being discussed. The reviewer also specifies the issue: 'The proposed training objective has ignored the KLdivergence term in equation (3)'. This shows a clear understanding of what needs to be addressed within the referenced section and equation. Therefore, the grounding is fully specific.", "verifiability_rationale": "The reviewer makes a claim: 'The proposed training objective has ignored the KLdivergence term in equation (3)'. This claim is verifiable through a logical reasoning and a concrete method: 'Can you evaluate such approximation error, ie. calculate the actual KLdivergence and check whether it indeed approaches zero? Experiments:'. The reviewer provides a clear path for the authors to investigate and verify the claim, making it 5.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: to evaluate the approximation error of ignoring the KLdivergence term by calculating it. This is a direct and useful piece of feedback for the authors, as it provides a concrete step they can take to improve their understanding or implementation. The suggestion to conduct experiments is also helpful in validating the approximation. This review point is highly informative and directly addresses a potential area of concern."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of connection between Section 2 and the methodology. While this identifies a potential issue, the reviewer does not explicitly state how to address this gap or improve the connection. The suggestion is implied but not directly stated, making it somewhat vague. Therefore, the actionability is somewhat vague as the explicit action is missing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 2' and 'methodology section' when pointing out the issues. This indicates a clear identification of the specific part of the paper being addressed. However, the reviewer does not specify *what* is wrong with the connection or the theoretical analysis beyond stating it is 'limited' and 'somewhat simplistic'. Therefore, the grounding is fully grounded, but the specificity of the issues is underspecific.", "verifiability_rationale": "The reviewer states two potential issues: 'Section 2 shows limited connection with the methodology section' and 'the theoretical analysis is somewhat simplistic and closely related to 1'. These statements can be considered implicit claims. While the reviewer mentions the methodology section and cites 1, they do not provide a clear explanation of *why* there is a limited connection or *how* the analysis is simplistic. The evidence is asserted rather than verified. Therefore, the verifiability is 1.", "helpfulness_rationale": "The reviewer identifies two areas for improvement: the connection between Section 2 and the methodology, and the simplicity of the theoretical analysis. However, the reviewer does not provide specific suggestions on how to improve these aspects. The suggestions are implied but not explicitly stated. Therefore, the helpfulness is 3 as the issues are identified, but the guidance on improvement is lacking."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests further discussion about 'specular areas' and the behavior of 'losses' in those areas. While this implies a potential area for improvement or clarification, it doesn't explicitly state what needs to be changed or how the discussion should proceed. The action is inferred rather than directly stated.", "grounding_specificity_rationale": "The reviewer mentions 'specular areas' without explicitly identifying the specific section, table, figure, or unique aspect of the paper being addressed. While the concept of 'specular areas' is clear, the exact location or element within the paper is not specified. The grounding is weak because the specific part is not named.", "verifiability_rationale": "The review point contains a suggestion for further discussion, which can be interpreted as a recommendation or a request for more information. However, it does not contain a claim that can be verified through logical reasoning, common knowledge, or external references. The suggestion is a request for clarification rather than a statement that can be proven or disproven.", "helpfulness_rationale": "The review point is a question and a suggestion for further analysis. While it points to a potential area for improvement in understanding loss behavior, it doesn't directly identify a flaw or provide a concrete solution. The feedback is more of a prompt for further investigation than a direct improvement suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states the *what* (the paper isn't strong enough for ICLR) but doesn't tell the authors *how* to improve it. There's no specific actionable item.", "grounding_specificity_rationale": "The comment is general about the paper's overall strength. It doesn't pinpoint a specific section, table, figure, or aspect that needs improvement. There's no indication of where the weakness lies.", "verifiability_rationale": "The comment makes a claim: \"the paper in its present state is strong enough for ICLR.\" However, it doesn't *support* this claim with evidence, reasoning, or references. It's a statement of opinion without backing.", "helpfulness_rationale": "The comment is critical and provides a reason for rejection (or a low bar for acceptance). While it's a valid concern, it lacks specific guidance on how to address it. The authors don't get concrete steps to improve the paper based on this comment."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies the issue of 'unclear major contributions' but does not explicitly state what needs to be done to address this. While the suggestion to 'figure out what the contributions are' is implicit, the specific steps or actions are not clearly defined. This makes the point somewhat implicit in its actionable nature.", "grounding_specificity_rationale": "The review point discusses the 'major contributions' of the paper in general terms. It does not specify a particular section, table, figure, or unique element of the paper where the issue lies. Therefore, it is 1 in a specific part of the paper. While it clearly identifies the issue within this general area, the lack of specificity in pinpointing the exact location makes it not specific.", "verifiability_rationale": "The review point makes a claim that 'Analyzing previous work does not constitute as a contribution.' This is a statement of opinion or judgment. While it might be supported by common knowledge or implicit reasoning, it does not explicitly state any external references or logical reasoning to back it up. Therefore, it is not 5 but has some justification, making it 3.", "helpfulness_rationale": "The review point raises a valid concern about the clarity of the paper's major contributions. It challenges the reviewer's assumption about what constitutes a contribution. While it doesn't provide a direct solution or specific steps for the author to take, it does highlight a potential issue that could be helpful for the author to consider. Therefore, it is 3 in prompting reflection and consideration of their own work's significance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states what is missing ('how to determine n_t') and what is unclear ('what does 'appropriate number' mean'). It directly points to Algorithm 2 and line 225, making the missing information readily identifiable. The reviewer provides a clear action for the authors: go back to Algorithm 2 and line 225 and provide the missing information.", "grounding_specificity_rationale": "The reviewer directly points to Algorithm 2 and line 225, making the specific part of the paper being addressed obvious. The comment also explains *what* is missing ('how to determine n_t') and *why* it's unclear ('appropriate number'), adding to the specificity.", "verifiability_rationale": "While the comment doesn't contain a direct claim, it identifies a gap in the information provided in Algorithm 2 and line 225. The reviewer implicitly suggests that the authors should provide more detail on how to determine n_t and what constitutes an 'appropriate number'. This could be argued as '3' as the suggestion is clear and points to a specific area for improvement, but it doesn't provide a concrete justification or reference.", "helpfulness_rationale": "The comment is 5. It directly points to specific locations in the text (Algorithm 2 and line 225) and clearly states the type of information needed ('how to determine n_t' and 'what does 'appropriate number' mean'). This directly helps the authors improve their draft by providing concrete directions for further investigation or clarification."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment asks a question but doesn't provide a specific action or suggestion on how to address the reproducibility issue.", "grounding_specificity_rationale": "The comment is about a general problem (reproducibility) and asks a question related to code availability, which is a relevant aspect but not a specific part of the paper being criticized. Therefore, it's 1.", "verifiability_rationale": "The comment is a question, not a statement making a claim that requires verification.", "helpfulness_rationale": "The comment raises a valid concern about reproducibility (a helpful aspect), but it's a question and doesn't offer specific actions or solutions, making it 3 in identifying the problem but lacking in providing constructive improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a *lack of support* for a claim made in the paper. It states the claim ('\"in practice the mixing time is even better\"') and then criticizes the *experiments* as insufficient support. It *doesn't* directly tell the authors what to do. It highlights a problem.", "grounding_specificity_rationale": "The review criticizes the *experiments* as insufficient support. However, it *doesn't* specify *which* experiments are problematic. It's a general criticism of the experimental section. It also doesn't detail *what* is wrong with the experiments (e.g., lack of specific metrics, limited parameter range, etc.).", "verifiability_rationale": "The review contains the claim: 'the claims that \"in practice the mixing time is even better\" are not nearly sufficiently supported by the experiments'. This is a clear statement of opinion requiring justification. The review *doesn't* provide any specific examples, references, or logical reasoning to support its claim about the experiments' limitations. It's a general criticism.", "helpfulness_rationale": "The review points out a potential issue with the paper's claims and suggests the experimental section needs improvement. While it identifies a problem, it doesn't offer concrete solutions or specific steps for the authors to take. It's a critique, not a solution."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests extending the protected feature A to a vector form. While this points to a potential improvement, the review lacks explicit instructions on how to achieve this extension or what the implications might be. The reviewer implicitly suggests a change but doesn't provide concrete steps, making it difficult for the author to directly implement the suggestion. The reviewer could have stated, for example, 'You could consider representing the attributes of A as elements in a vector space and explore the impact on your analysis.' This would have made the action more explicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'protected feature A' and suggests extending it to a 'vector form'. This clearly identifies the specific part of the paper and the specific idea being proposed. The reviewer's comment is grounded in the specific element of the paper and provides a specific suggestion. The reviewer is not leaving it open to interpretation which part of the paper they are referring to.", "verifiability_rationale": "The reviewer's comment is a suggestion to extend the protected feature A to a vector form. This is a claim or suggestion for improvement. However, the reviewer does not provide any justification or reasoning for why this extension would be beneficial or how it could be implemented. There is no logical reasoning, common knowledge, or external references provided to support this suggestion. The reviewer simply proposes a change without explaining its implications or feasibility.", "helpfulness_rationale": "The reviewer's comment identifies a potential area for improvement by suggesting extending the protected feature A to a vector form. This is a relevant point that points towards a specific direction for further work. While the reviewer does not provide concrete implementation details, the suggestion itself is a valuable piece of feedback that could guide the author in exploring new ways to represent their data. The reviewer's comment is focused on a concrete aspect of the work and proposes a specific type of change."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point directly addresses specific implementation details by asking about the variables 'x' and 't' in the equation, the L2normalization process, and the similarity metric used for nearest neighbors. These are concrete questions that the authors should be able to answer based on their existing work, providing clear guidance on implementation choices. The reviewer is asking for specific information that can be directly found or inferred from the authors' paper.", "grounding_specificity_rationale": "The review point explicitly mentions 'x and t' in the equation and asks about L2normalization and the similarity metric (cosine or dotproduct). These are specific elements of the paper being referenced, allowing the authors to directly identify the relevant section, table, figure, or unique aspect being addressed. The reviewer is pointing to specific implementation details.", "verifiability_rationale": "The review point is a question seeking information that the authors should be able to provide based on their existing work. While it doesn't present a definitive statement, it's a request for clarification that can be verified through their documentation or experiments. The reviewer is asking for specific implementation details that are likely known to the authors.", "helpfulness_rationale": "The review point directly addresses implementation details that are crucial for understanding and potentially reproducing the results. It helps the authors understand the method better by clarifying the notation and the specific steps involved in calculating nearest neighbors. The reviewer is asking for specific implementation choices that are likely known to the authors and would help them improve their understanding or reproduce the results."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review identifies the need for reproducibility and multiple runs in deep RL experiments. However, it doesn't explicitly state the steps the authors should take to achieve this, making it only partially actionable.", "grounding_specificity_rationale": "The review mentions the importance of experiments but doesn't specify which part of the paper or experiment is lacking. It also doesn't pinpoint a specific issue within the methodology.", "verifiability_rationale": "The review makes a claim about the importance of reproducibility in deep RL and provides a citation to support this claim, making it verifiable.", "helpfulness_rationale": "The review raises a valid concern about the reproducibility of deep RL experiments and provides a relevant reference. While it doesn't offer specific suggestions for improvement, it encourages the authors to consider the robustness of their experimental setup, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what the author should do. While it points to specific locations (Figure 2, Line 433, Line 468), it does not provide concrete instructions on how to check these locations or address any potential issues. The action is implicit, requiring the author to infer the next steps.", "grounding_specificity_rationale": "The review point explicitly mentions specific parts of the paper (Figure 2, Line 433, Line 468), which can be considered full grounding as it directly references specific elements. However, it does not specify what is wrong with these parts, making it not specific.", "verifiability_rationale": "The review point does not contain a claim. It is a request to check specific locations for a potential issue (inconsistent punctuation). It does not make a judgment or assertion about what is correct or incorrect. Therefore, it fits the 'X' category.", "helpfulness_rationale": "The review point identifies potential issues by pointing to specific locations and highlighting a lack of consistency in punctuation. While it doesn't provide a solution, it directs the author's attention to areas that might need further investigation. This makes it 3 in guiding the author's next steps, even if those steps are just to investigate further."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the similarity between $kNNECD$ and $kNNMT$ and directly links this to the limited technical contribution of the paper. The action is to point out this similarity and its implication.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper (e.g., a section, table, figure) where the similarity between $kNNECD$ and $kNNMT$ is discussed or its impact is analyzed. The mention of the methods is general.", "verifiability_rationale": "The review point contains a claim: 'The technical contribution of the paper is limited.' The support for this claim is the statement about the similarity between $kNNECD$ and $kNNMT$. While this provides a basis for inference, there are no explicit references to external works or logical reasoning to directly verify the claim about limited contribution.", "helpfulness_rationale": "The review point is helpful in that it identifies a potential issue with the paper's technical contribution by highlighting the similarity between two existing methods. This provides a direction for the authors to investigate further and potentially clarify their work's novelty. However, the feedback is somewhat general and lacks specific suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question, which implies they want clarification or further information. While it's a helpful question, it's not explicitly * commanding* an action. Therefore, it's 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"Figure 1\" in their comment, providing a clear reference point. This demonstrates strong grounding.", "verifiability_rationale": "The reviewer suggests that the figures are artificially generated and proposes realworld experiments to support the phenomenon. This implies a claim that requires justification (or at least further clarification). However, the justification is not provided within the review point itself.", "helpfulness_rationale": "The reviewer is asking a question and suggesting an experiment. While these are potentially helpful, they are openended and lack concrete instructions. The reviewer isn't *directly* telling the authors what to do, but they are prompting them to consider important aspects of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that they were unable to understand the numbers of parameters. This indicates an explicit action that is not yet taken (i.e., the authors haven't clarified the information). Therefore, the review point is not yet actionable in its current form. The reviewer's suggestion to clarify the numbers is a concrete action they believe would make the review actionable.", "grounding_specificity_rationale": "The reviewer refers to 'numbers of parameters used in each approach' and specifically mentions 'Section B.3'. This directly identifies a specific part of the paper and asks for numerical details. Therefore, the grounding is strong, and the specificity is high as they are asking for concrete numerical information.", "verifiability_rationale": "The reviewer is pointing out a lack of clarity, which is a statement of a problem, not a claim that requires verification. Therefore, this review point does not contain a claim that can be verified. The reviewer is reporting an issue rather than proposing a solution or making a judgment that needs evidence.", "helpfulness_rationale": "While the reviewer identifies a valid issue (lack of clarity), the review itself does not directly improve the paper. It suggests a potential improvement (clarifying the numbers), but it doesn't provide the clarification itself. Therefore, the review point is not 5 as it doesn't directly address the need in the paper. It's more of a pointer to a potential area for improvement rather than a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests *what* would be helpful (an example and perhaps a figure) but doesn't explicitly state *how* to create or use it. While it identifies a potential area for improvement, the lack of a clear action or method makes it implicit rather than explicit. The reviewer implies a need for clarification on uniform shattering, but doesn't provide concrete steps on how the example/figure would be helpful.", "grounding_specificity_rationale": "The review point doesn't explicitly mention a specific part of the paper (e.g., 'Section 3.2') or the method of explanation (e.g., 'improving the definition of uniform shattering'). It's a general suggestion for improvement without pinpointing a specific location or technique. Therefore, the reviewer doesn't identify a specific element that needs addressing, making the grounding weak.", "verifiability_rationale": "The review point itself is not a declarative statement of a claim that requires verification. It's a suggestion for improvement, not a statement that needs to be supported by evidence. Therefore, there is X being made that needs to be verified.", "helpfulness_rationale": "The review point suggests providing an 'example and perhaps a figure' to explain uniform shattering. While this is a relevant suggestion and points to a potential weakness in the paper's clarity, it lacks specific actionable steps. The reviewer doesn't specify *how* the example/figure would be constructed or how it would be used to improve understanding. It's a general suggestion for improvement rather than a concrete, actionable remedy. Therefore, it's helpful in identifying a need for clarification, but lacks the specifics to be fully beneficial."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their belief that the proposed transductive method is not very novel and connects it to selftraining methods in semisupervised learning. The statement 'I don't believe the proposed transductive method is very novel' is a direct and clear indication of an actionable point for the authors. The reviewer also provides a specific reference point (selftraining methods in semisupervised learning), making the action explicit and concrete.", "grounding_specificity_rationale": "The reviewer attempts to ground their claim about the lack of novelty by mentioning 'selftraining methods in semisupervised learning'. This provides a specific area of related work. However, the reviewer does not explicitly state which specific aspect of the proposed method is similar to selftraining or how the proposed method is exactly related to it. The connection is implied rather than explicitly stated and pointed to within the paper. Therefore, the grounding is present but not fully specific.", "verifiability_rationale": "The reviewer makes a claim: 'I don't believe the proposed transductive method is very novel'. This is a clear claim. The reviewer attempts to support this claim by stating their belief that it is related to 'selftraining methods in semisupervised learning'. However, the review point itself does not provide direct evidence or references to verify this claim. The reviewer's statement is based on their own understanding and experience, not on information directly presented within the review point. Therefore, the claim is stated, but there is no direct verification within the review point itself.", "helpfulness_rationale": "The reviewer provides a clear and actionable criticism of the proposed method's novelty, specifically linking it to selftraining in semisupervised learning. This is a valuable piece of feedback for the authors. The reviewer's statement directly informs the authors about a potential area of overlap and suggests a relevant area of research to consider. This is a direct and helpful piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out that the formulation or definition in the manuscript is 'somewhat trivial'. While this is an observation, the reviewer does not explicitly state what the author should do about this perceived triviality. They identify the issue but don't provide concrete actions or modifications. Therefore, it is not fully actionable as it lacks explicit and direct instructions for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'classes' in the context of the manuscript but does not specify which particular class or section they are referring to. The comment is general and does not pinpoint a specific part of the paper where the issue lies. Therefore, the grounding is weak as the reader cannot confidently determine the exact area being addressed.", "verifiability_rationale": "The reviewer states that the formulation or definition is 'NOT practice'. This is a statement of opinion or judgment. While it identifies a potential issue, it does not provide any logical reasoning, common knowledge, or external references to support this claim. Therefore, it is not verifiable as it lacks supporting evidence.", "helpfulness_rationale": "The reviewer criticizes the formulation or definition as 'NOT practice' but does not offer any suggestions or actions for improvement. The comment is a critique without constructive feedback, failing to provide the authors with any actionable insights or guidance. Therefore, it is not helpful as it does not empower the authors to improve their work."}
{"actionability_label": "1", "grounding_specificity_label": "3: 2", "verifiability_label": "3", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The review point criticizes the statistical significance of the evaluation results and the methodology used to obtain them. It does not provide any specific action or suggestion on how to improve the evaluation or the statistical analysis itself. The focus is on criticizing the outcome and the process rather than proposing concrete changes.", "grounding_specificity_rationale": "The review point mentions 'evaluation results reported in table 1' and the number of trials. While it identifies a potential issue (the small number of trials affecting statistical significance), it doesn't specify *which* part of table 1 is problematic or *exactly* what the issue is with the three trials. The grounding is weak because it points to a general area (table 1) rather than a specific section, table, figure, or unique element within the paper. The number of trials is mentioned, but the grounding is on the *methodology* of the evaluation rather than a specific part of the paper being evaluated.", "verifiability_rationale": "The reviewer *claims* that the evaluation results are not statistically significant due to the small sample size. This is a claim that *could* be supported by examining the sample size and standard deviation. However, the *reviewer* is making this claim, not the authors. The verifiability lies in the *reviewer's* assertion that the results are not statistically significant, which *could* be supported by external references (like statistical principles or common knowledge about sample size limitations). The claim is made by the reviewer, not the paper being evaluated.", "helpfulness_rationale": "The review point is a critique of the authors' methodology and the interpretation of their results. It does not offer any actionable feedback or suggestions on how the authors can improve their draft based on this critique. The focus is on identifying a limitation in the evaluation process rather than providing concrete advice for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review points out a lack of comparison with relevant prior work, implying the need for the authors to identify and compare with two specific papers. While the action of comparing is suggested, the review does not explicitly state how the authors should go about finding these papers or what specific aspects of the papers to compare. The action is implied but not fully concrete.", "grounding_specificity_rationale": "The review mentions 'two relevant papers,' which provides a basis for grounding. However, it does not explicitly state which specific section or table of the paper contains these relevant papers. The reviewer implies the comparison is relevant, but the exact location and the specific aspects of the comparison are not clearly defined. The grounding is present but not fully specific.", "verifiability_rationale": "The review states that a 'feature comparison with prior work is shallow, missing two relevant papers.' This is a clear claim that requires justification. The claim is supported by the statement that the comparison is 'shallow' and the identification of 'two relevant papers' as missing elements. The evidence provided directly supports the suggestion for a more thorough comparison.", "helpfulness_rationale": "The review provides a clear and actionable suggestion for the authors: to perform a 'feature comparison with prior work, especially these two.' While it doesn't specify the exact steps to take or the specific aspects of the comparison, it directly points to a relevant area for improvement and provides a starting point for the authors to find and compare with the mentioned papers. The suggestion is directly related to improving the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the use of the word 'equivalent' at specific line numbers (8, 56, 70, 93). This directly points to a potential action the authors should take, making it explicit. While it doesn't provide specific instructions on what to replace 'equivalent' with, it clearly identifies the location, which is a concrete piece of information. Therefore, it is considered 5 as it directly points to a specific area for improvement.", "grounding_specificity_rationale": "The comment explicitly mentions the lines (8, 56, 70, 93) where the word 'equivalent' is used. This allows the authors to precisely locate the issue, making the grounding fully grounded. While the comment doesn't specify *what* is wrong with the usage, it clearly identifies the *part* of the paper being addressed, which is a key aspect of grounding specificity.", "verifiability_rationale": "The comment suggests that the usage of 'equivalent' might be imprecise or unclear. While it doesn't provide specific examples of why it's imprecise, it implies a potential issue that could be verified. The reviewer is suggesting that the authors should be more cautious, which implies a potential area for improvement in their writing. Therefore, it is considered 3 as it points to a potential issue that could be investigated.", "helpfulness_rationale": "The comment identifies a potential area for improvement in the writing by suggesting being more cautious with the word 'equivalent.' This provides a clear direction for the authors to refine their language. While it doesn't offer a specific alternative or solution, it points to a concrete action they can take to improve their draft. Therefore, it is considered 4 as it provides a clear suggestion for improvement, though it could be expanded."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a problem (lack of understanding of the multiview clustering approach's effectiveness) and suggests a solution (further analysis of the different views). While the reviewer doesn't explicitly state the action to take, the suggestion implies an actionable step. However, the suggestion itself is somewhat vague, as it doesn't specify *how* to analyze the differences between the views or the clustering techniques.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'other views' and the 'combination' of views, indicating a clear identification of the specific aspect of the paper being addressed. They also provide a concrete example by stating there is an 'empirical example of how the different views help in clustering paraphrases of the word 'slip''. This demonstrates a strong grounding in the specific part of the paper and a clear specification of the issue.", "verifiability_rationale": "The reviewer states a fact: 'almost all across the board, the paraphrase similarity view does significantly better than other views and their combination.' This is a claim that requires verification. However, the reviewer does not provide any reasoning, examples, or external references to support this claim. The lack of justification makes it difficult to verify the statement.", "helpfulness_rationale": "The reviewer clearly states a problem ('I don't understand effectiveness of the multiview clustering approach') and offers a direct suggestion for improvement ('further analysis of the different views and clustering techniques'). This is a helpful comment as it directly addresses the identified issue and provides a concrete direction for the authors to take. The suggestion is specific to the problem identified."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the architecture is not clearly explained and refers to Jiang et al. (2019) for details. This indicates an implicit action, as the reviewer desires a clearer explanation, but it is not explicitly provided. The action is also vague because the reviewer doesn't specify what aspects of the architecture are unclear. Therefore, the action is not explicit and lacks concrete details.", "grounding_specificity_rationale": "The reviewer points out that the architecture is not clearly explained and refers to Jiang et al. (2019) for details. While the paper might implicitly refer to the architecture (e.g., through citations or descriptions), the reviewer doesn't explicitly state which section, table, figure, or unique element is lacking. The grounding is weak because the authors cannot confidently determine which part the comment addresses. The issue is not specifically defined, making it difficult to pinpoint the exact area of concern.", "verifiability_rationale": "The reviewer claims that the lack of a clear explanation makes the paper not selfcontained. This is a claim that the paper lacks specific information about the architecture. However, the reviewer does not provide any specific examples or references to support this claim. The claim is made generally, without pointing to a specific instance of missing information. Therefore, the claim is not fully supported by evidence.", "helpfulness_rationale": "The reviewer identifies a clear weakness in the paper: the lack of a clear explanation of the architecture. This directly points to a potential area for improvement for the authors. While the reviewer doesn't offer specific suggestions for improvement, the identification of this weakness is valuable information for the authors and contributes to their understanding of the paper's shortcomings. The reviewer's comment highlights a concrete issue that could hinder the authors' ability to build upon the work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the metrics (BertScore and BLEURT) and suggests a solution (standardization). This provides a clear action for the authors to take.", "grounding_specificity_rationale": "The comment explicitly mentions the metrics (BertScore and BLEURT), which can be considered full grounding. However, it doesn't specify *where* in the paper this inconsistency occurs, making it somewhat specific in identifying the *what* but not the *where*. The suggestion to standardize is clear, making it somewhat specific in terms of the action.", "verifiability_rationale": "The comment identifies a potential inconsistency and suggests a solution. While it doesn't provide a definitive justification for why this inconsistency is problematic within the review itself, the suggestion to standardize is a constructive action. It implies a potential improvement but lacks immediate, explicit verification within the review.", "helpfulness_rationale": "The comment directly points out a minor formatting issue and offers a clear, actionable suggestion to improve consistency. This provides valuable guidance for the authors to make a straightforward change."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem ('it sounds unreasonable...') and suggests a solution ('providing more detail'). This is an actionable suggestion.", "grounding_specificity_rationale": "The reviewer clearly identifies the *type* of issue: a contradiction between their results and a cited paper. They also specify the *area* of their own paper: 'model size increase hurting performance' and 'Wikipedia experiments.' They are asking for details about their specific experiments where model size increased but performance decreased. This is fully grounded as they are pointing to a specific area in their own paper. The comment also clearly specifies what needs to be addressed in this part ('providing more detail').", "verifiability_rationale": "The reviewer makes a claim: 'It sounds unreasonable that increasing the model size can hurt the performance, as recent paper Ni et al. shows that the scaling law is also apply to dense retrieval model, so the preliminary experimental results on Wikipedia about model size should be provided in detail.' This claim is supported by a potential source (Ni et al.) and a suggestion for a specific action (providing more detail). The reviewer is attempting to ground the issue by referencing a relevant paper and providing a concrete suggestion for improvement. The claim is also 3 as the reviewer provides a potential source, although the connection between Ni et al.'s findings and their specific Wikipedia experiments could be more explicit.", "helpfulness_rationale": "The reviewer's point is highly relevant for anyone working on model scaling and performance. It directly addresses a potential problem in their experimental setup or understanding. The suggestions for providing more detail are actionable and directly address the identified issue. This is a 5 comment as it directly points to a potential problem and offers a clear, actionable solution."}
{"actionability_label": "2", "grounding_specificity_label": "3: Somewhat Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out weaknesses in the presentation quality, such as figures and tables, but doesn't explicitly state what needs to be improved or how to do it. While the general idea of improvement is implied, the specific actions are missing.", "grounding_specificity_rationale": "The reviewer identifies specific parts of the paper, like 'Figs 1&2' and 'tables with a \"\"', indicating some grounding. However, they don't specify *why* these are weaknesses or *how* they should be addressed, making the grounding somewhat underspecific.", "verifiability_rationale": "The reviewer claims that certain aspects of the presentation quality are weaknesses. However, they don't provide any evidence, reasoning, or external references to support these claims. The assessment is presented as a statement of opinion rather than a verifiable fact.", "helpfulness_rationale": "The reviewer clearly identifies problems in the presentation of the paper, which is directly beneficial to the authors in improving their draft. While the reviewer doesn't provide specific actions or detailed explanations of the issues, they *do* point out concrete areas for improvement, making the feedback helpful, albeit potentially requiring further clarification from the authors."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly states a desire for *related experiments* that the *information axis tool* can help with. This is an explicit and concrete action the reviewer is suggesting for the authors.", "grounding_specificity_rationale": "The review point is about the *information axis tool* and *related experiments*, without specifying a particular section, table, figure, or unique element within the *paper* that needs clarification.", "verifiability_rationale": "The review point is a question, not a statement of a claim that needs verification.", "helpfulness_rationale": "The review point is a suggestion for future research and doesn't directly identify weaknesses or provide concrete improvements for the *current draft*."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggestion for the authors. While it implies a desire for more information, it doesn't directly tell them what to do. The reviewer asks 'I\u2019d be interested to know if other multilingual pretraining setups also struggle with Greek.' This is a question, not a directive.", "grounding_specificity_rationale": "The reviewer mentions 'multilingual pretraining setups' and 'Greek' but does not specify which part of the paper or the authors' work this refers to. The grounding is weak as the authors cannot confidently determine which aspect the comment addresses.", "verifiability_rationale": "The review point does not contain a claim that needs verification. It is a question about a specific detail (struggle with Greek in multilingual setups). There is no assertion that something is incorrect or needs improvement, so verifiability is not applicable.", "helpfulness_rationale": "The review point is 3 as it points to a specific area of potential confusion or lack of knowledge for the authors (struggle with Greek in multilingual setups). It encourages the authors to seek more information, which could be beneficial. However, it is not a direct instruction or a clear recommendation for improvement, making it less helpful than a direct suggestion."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The comment 'It would be difficult for readers to understand and evaluate the results.' implies an action (improving clarity), but it doesn't specify *how* to do this. The vagueness makes it less actionable.", "grounding_specificity_rationale": "The comment explicitly refers to 'the text in line 293295,' providing strong grounding. However, it doesn't specify *what* is unclear or *how* the manual observation helps. The issue is identified, but not the solution or the problem itself.", "verifiability_rationale": "The comment contains a claim ('It would be difficult...') but doesn't provide any evidence or reasoning to support this claim. It lacks logical reasoning, common knowledge, or external references to back up the assertion.", "helpfulness_rationale": "The comment points out a potential issue with the writing, which could be helpful for the authors. However, it lacks specificity about *what* is unclear and *how* the manual observation helps. The suggestion is vague."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problems with the proofs (poor organization, difficulty in following logic, hard to verify correctness) and asks a specific question about Lemma 3. This makes the action somewhat explicit by pointing to the specific issue with Lemma 3. While it doesn't directly tell the authors what to do, it clearly identifies a problem and a direction for improvement, making it 3.", "grounding_specificity_rationale": "The review point explicitly mentions \"proofs\" and then specifically asks about \"Lemma 3.\" This clearly identifies the specific part of the paper being addressed, indicating full grounding. The comment also specifies what needs to be addressed in this part (the generality of Lemma 3's result), indicating high specificity.", "verifiability_rationale": "The review point makes a claim about the quality of the proofs and asks a question. However, it does not provide explicit reasoning, examples, or external references to support its claim that the proofs are not wellorganized and difficult to follow. The justification is implicit, relying on the reader's interpretation of the provided information. Therefore, it is not 5 as it lacks strong supporting evidence within the review itself.", "helpfulness_rationale": "The review point clearly identifies a problem with the organization of the proofs and specifically asks a question about a key lemma (Lemma 3). This directly points to an area where the authors can improve their draft. The question is also directly actionable, as the authors can consider the generality of the lemma's result and potentially reorganize the proof. The reviewer is providing a clear direction for improvement, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that conducting experiments on realworld datasets would be better for validating the paper's claim of aiming for a realistic scenario. While the suggestion is clear, it doesn't explicitly state what needs to be done, such as identifying specific realworld datasets or detailing the experimental setup. The action is implied rather than explicitly stated and concretely outlined.", "grounding_specificity_rationale": "The review point mentions 'this paper' and the 'outofdistribution setting' as areas where realworld datasets would be beneficial. While it identifies the general area of concern, it doesn't pinpoint a specific section, table, figure, or unique element within the paper that needs improvement. The reference to 'realworld datasets' is a general suggestion rather than a specific call to action for a particular part of the paper.", "verifiability_rationale": "The review point makes a claim that conducting experiments on realworld datasets would be better for validating the paper's claim of aiming for a realistic scenario. This claim is supported by the paper's stated goal of addressing realistic scenarios and the common practice of using synthetic data in representation learning. However, the justification is somewhat implicit, relying on the critique of synthetic data in the context of the paper's claims.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the authors to improve their draft. By recommending the inclusion of experiments on realworld datasets, it directly addresses the paper's claim of aiming for a realistic scenario. This is a valuable direction for improvement, as it aligns with the stated goals and provides a concrete next step for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a potential area for improvement (vague explanation) but does not explicitly state how the author should go about making it less vague. It points to a specific location but lacks concrete action steps.", "grounding_specificity_rationale": "The comment explicitly mentions \"the last paragraph of Section 3 (lines 207210) on the single image case,\" providing a clear and specific reference point within the paper.", "verifiability_rationale": "The comment is a suggestion or question about the clarity of an explanation, not a claim that requires verification. It does not present a statement that needs to be supported by evidence.", "helpfulness_rationale": "The comment points to a potential area for improvement and suggests investigating related literature. While it doesn't guarantee improvement, it provides a direction for the author to consider and is a constructive suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitation of considering only one truck and one drone ('It only consider ONE truck and ONE drone') and poses a clear question ('Would it be easy to extend to multiple trucks and drones?'). This indicates an explicit action and a concrete suggestion for improvement.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'ONE truck' and 'ONE drone' in the paper, which are specific parts of the work. The suggestion to 'extend to multiple trucks and drones' also refers to specific parts of the potential extension. This strong grounding allows the authors to understand the specific aspect being addressed and the direction of the suggested improvement.", "verifiability_rationale": "The reviewer states that extending to multiple trucks and drones is 'easy' and that it's a 'more interesting and practical setting.' While the suggestion is clear, the reviewer does not provide any specific evidence or reasoning to support the claim that it is 'easy'. The 'more interesting and practical setting' is a statement of opinion rather than a verifiable claim based on the paper's content.", "helpfulness_rationale": "The reviewer identifies a limitation in the scope of the work (focusing on a single truck and drone) and suggests a relevant direction for future work (extending to multiple trucks and drones). This provides a clear and actionable feedback for the authors, making it helpful for improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the proposed approach has 'limited novelty' and that it 'follows the strategies used in ELECTRA'. While this points to a potential issue, it doesn't explicitly tell the authors what to do or how to improve their work. The reviewer implies that their method is similar to ELECTRA's, but doesn't provide concrete steps for the authors to make it more novel. Therefore, it is not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions 'strategies used in ELECTRA' as a basis for their criticism. While this provides some grounding, it doesn't specify a particular section, table, figure, or unique aspect of the authors' paper that needs improvement. The reference to ELECTRA is general and doesn't directly pinpoint the problem in the authors' work. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim that the proposed approach has 'limited novelty' and provides a reason ('it more or less just follows the strategies used in ELECTRA'). This claim is somewhat supported by the reasoning, as the reviewer is drawing a comparison. However, the reasoning is a general interpretation and not a direct citation or a detailed explanation of the authors' method. Therefore, the verifiability is 3.", "helpfulness_rationale": "The reviewer points out a potential lack of novelty in the proposed approach. While this is a valid concern, the criticism is somewhat general and doesn't offer specific suggestions for the authors to make their work more novel. The reviewer suggests they should do something different, but doesn't provide concrete steps. Therefore, the review point is 3 in identifying a potential issue, but lacks specific guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "Not Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the 'motivation/need for the Newton algorithm in section 4 was somewhat lacking'. While they don't pinpoint the exact missing element, they clearly identify a gap in justification. The reviewer doesn't provide a direct action or a clear path to implementation.", "grounding_specificity_rationale": "The reviewer mentions 'section 4' when describing the lacking motivation. This indicates a level of grounding as they are pointing to a specific part of the paper. However, they do not specify what is lacking in that section. The statement is a general assessment of the section's content.", "verifiability_rationale": "The reviewer's statement is a judgment about the motivation's lack. They are expressing their opinion that the motivation is insufficient. There is X being made that something is or isn't the case, just an opinion. Therefore, it's not verifiable.", "helpfulness_rationale": "The reviewer provides a clear reason for their criticism: the lack of justification for using Newton's method for a simple 1D convex problem. They even offer a potential improvement by suggesting experiments to demonstrate the impact on runtime. This provides a concrete direction for the authors to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the observation that the impact of the proposed upweighing and KNN methods is similar on both idiomatic and random data. This is a clear action: analyzing the results and drawing conclusions about the methods' idiomspecificity. The reasoning is directly stated, making it a concrete action based on the observed data.", "grounding_specificity_rationale": "The review point refers to 'the proposed upweighing and KNN methods' and 'idiomatic vs random data' and 'MT modelling methods' and their 'idiomspecificity'. While it mentions these terms, it doesn't explicitly point to a specific section or subsection of the paper where these methods are discussed. The grounding is implied rather than explicitly stated. The specificity is present in the interpretation of the results, but the grounding of *what* is being interpreted is weak.", "verifiability_rationale": "The review point presents a claim: 'the proposed MT modelling methods seem far from idiomspecific.' While it doesn't explicitly state *why* they seem far from idiomspecific, it offers an interpretation based on the similar impact on idiomatic and random data. This is a deduction based on the presented data. However, it lacks direct evidence or citations to support the claim that the methods aren't inherently idiomspecific. The connection to KNN and upweighing isn't explicitly verified.", "helpfulness_rationale": "The review point criticizes a specific method (upweighing and KNN) and suggests an alternative interpretation of the results. While it provides some insight into the limitations of the methods, it doesn't directly suggest concrete, actionable improvements to the specific implementation of the MT models or the upweighing/KNN methods. It encourages the authors to consider alternative interpretations, which can be helpful for understanding, but it doesn't offer direct guidance on how to modify their work. The value is in prompting a different perspective rather than providing a direct solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the issue: 'we believe the resulting volume should be WxHx1 and the bias is a scalar' and suggests a solution: 'we only found this hyperparameter for the feed forward models...C biases is confusing'. The explicit statement of the problem and the suggestion to investigate section 3.4 indicate a clear action for the authors to take. The reviewer is directly pointing out a discrepancy and suggesting a potential area of confusion.", "grounding_specificity_rationale": "The review point explicitly mentions 'section 3.4' and the specific issue is about the number of biases (C) not being a hyperparameter for feedforward models. This direct mention of a specific section and the nature of the problem indicates high grounding specificity. The authors can easily identify the relevant part of the paper and understand the exact issue.", "verifiability_rationale": "The review point contains a claim: 'we believe the resulting volume should be WxHx1 and the bias is a scalar' and 'we only found this hyperparameter for the feed forward models...C biases is confusing'. While the reviewer doesn't provide explicit evidence *within this review point* to verify the claim, the suggestion to 'check section 3.4' implies a lack of clarity or potential error in that section, which can be considered implicit evidence supporting the claim. The reviewer is pointing out a discrepancy that needs to be verified.", "helpfulness_rationale": "The review point is 5 because it directly identifies a likely error in the paper's description of biases. The reviewer clearly states what the authors *should* have found (WxHx1 volume and a scalar bias) and points out that the paper incorrectly states there are C biases for feedforward models. This highlights a specific area of confusion and provides a clear direction for the authors to seek clarification or correction in section 3.4. The reviewer's suggestion to 'check section 3.4' is a concrete action the authors can take."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly suggests a change to be made to the code (remove the subtraction of s from the dynamic information). This is a clear and direct action for the authors to take. The action is also concrete, specifying exactly what needs to be done.", "grounding_specificity_rationale": "The comment refers to 'Equation 8' and 's', which are parts of the mathematical formulation. However, it does not explicitly identify the specific section, table, or figure within the paper that contains Equation 8. While it mentions 's', it doesn't specify which variable or term within the equation is causing the issue. The reviewer implies a problem with the operation involving 's' in Equation 8, but lacks the precise referencing needed for full grounding.", "verifiability_rationale": "The comment presents a potential consequence of subtracting 's' from dynamic information, suggesting a loss of dynamic information. This is a logical deduction based on the nature of mathematical operations. While it doesn't provide a definitive proof or external reference, the reasoning is sound and plausible, making it 3.", "helpfulness_rationale": "The comment is highly specific and directly addresses a potential issue in the code implementation. It suggests a concrete change (removing the subtraction) that is likely to be beneficial for the authors. The reviewer's point is actionable and directly addresses a potential flaw in the dynamic information processing."}
{"actionability_label": "1", "grounding_specificity_label": "4: 5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question rather than providing a direct action or suggestion. While it implies a desire for clarification and empirical investigation, it doesn't explicitly state what the reviewer wants to do next. The action would be the reviewer themselves going out and finding the empirical evidence or exploring the network structure.", "grounding_specificity_rationale": "The review point explicitly mentions 'how does the number of MC samples affect performance', 'network structure', and 'empirically'. This clearly identifies the specific parts of the paper or the nature of the work the reviewer is referring to. The grounding is explicit and points to very specific areas.", "verifiability_rationale": "The review point contains a claim (a question that implies a lack of knowledge or a desire for empirical evidence). However, it doesn't provide any justification or reasoning for why this claim should be believed. There's no logical reasoning, common knowledge, or external references provided to support the request for empirical evidence. Therefore, it is 1 as it stands.", "helpfulness_rationale": "The review point highlights a gap in the authors' understanding. While it points to areas for improvement (further investigation), it doesn't offer any concrete suggestions or actions the authors *themselves* could take to address this gap. It's a request for information, not a suggestion for improvement within the review itself."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the desired action: 'show the smoothed GT shapes' and clearly identifies the location: 'Figure 3 and Figure 5'. This provides a direct instruction for the authors to improve their understanding of the reconstruction quality.", "grounding_specificity_rationale": "The comment explicitly mentions the specific sections of the paper where the smoothed GT shapes should be shown: 'Figure 3' and 'Figure 5'. This is a clear and precise identification of the relevant part of the paper.", "verifiability_rationale": "The comment implies that showing these smoothed GT shapes will improve the reader's understanding of the reconstruction quality. While it doesn't explicitly state a claim about the superiority of smoothed shapes, the suggestion itself is a logical deduction based on the stated goal. The grounding is strong as the section numbers are provided.", "helpfulness_rationale": "The comment directly points to a specific area for improvement in the figures and explains why it will be helpful for the reader's understanding of the reconstruction quality. This is a clear and actionable suggestion."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a potential issue ('there are no direct comparisons with it') but does not explicitly state an action the authors should take to address this. While it points to a gap, it doesn't tell them how to make the comparisons or what metrics to use.", "grounding_specificity_rationale": "The review point explicitly mentions \"PRANC is directly modified by the authors\" and then lists specific aspects of the work where comparisons are lacking: \"there are no direct comparisons with it in either the language or vision tasks used to evaluate the proposed approach.\" It also mentions specific evaluation metrics used in the paper: \"There is a comparison of training loss in Section 3.4 and a comparison of the rank of possible solutions of the two approaches in Section 3.5\". The reviewer then concludes with \"without a direct comparison of test accuracy it is unclear if this approach is indeed an improvement over the baseline that it directly modifies.\" This clearly specifies the parts of the work and the metric where the comparison is missing.", "verifiability_rationale": "The review point makes a claim: \"there is a comparison of training loss... but without a direct comparison of test accuracy it is unclear if this approach is indeed an improvement over the baseline that it directly modifies.\" This is a claim that needs verification. The reviewer identifies a gap in the evaluation by pointing out the absence of a crucial comparison (test accuracy). While they don't provide external references to verify this claim, the reason for the lack of comparison is stated.", "helpfulness_rationale": "The review point is 5 because it identifies a clear weakness in the evaluation (lack of direct test accuracy comparison) and provides a concrete suggestion for improvement: \"there is a comparison of training loss in Section 3.4 and a comparison of the rank of possible solutions of the two approaches in Section 3.5 but without a direct comparison of test accuracy it is unclear if this approach is indeed an improvement over the baseline that it directly modifies.\" This directly addresses the identified issue and suggests a specific area for the authors to focus their evaluation efforts."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises a valid point about the generalizability of the method to other domains. While the paper doesn't explicitly state the limitations of the method, the concern is a reasonable question for authors wanting to apply it in different contexts. The lack of explicit grounding in the method description might make it less actionable in domains beyond the specific event types used in the paper. The reviewer's question about the selection of event types from Freebase also falls under this category, as it's a lack of explicit actionability in understanding the method's scope.", "grounding_specificity_rationale": "The reviewer's questions about the selection of event types and their coverage in the ACE dataset directly address the grounding specificity of the method. The paper mentions selecting 21 event types from Freebase but doesn't detail the criteria for selection. This lack of explicit grounding makes it difficult for the reviewer (and potentially other readers) to understand how the method would perform with different types of events or in different domains. The coverage of these event types in the ACE dataset further impacts the understanding of the method's applicability and potential biases. The reviewer's questions highlight a lack of explicit grounding in the method description.", "verifiability_rationale": "The reviewer's concern about the generalizability of the method to other domains is also related to verifiability. While the paper doesn't explicitly claim to be universally applicable, the lack of specific details about the method's components and their underlying assumptions makes it difficult to verify its effectiveness in different settings. The reviewer's questions about the event type selection and their coverage in the ACE dataset are also crucial for verifying the method's reliability and potential biases. Without explicit references or justifications, the claims about the method's performance are less verifiable.", "helpfulness_rationale": "The reviewer's questions about the generalizability of the method and the selection of event types are highly relevant and helpful for authors who might want to use the method. These questions directly address the practical applicability and limitations of the approach. Understanding how the method would perform in different domains and with different event types is crucial for its effective adoption. The reviewer's questions are not just about the method itself but also about its practical utility for other researchers. The lack of clarity on these aspects makes the review point somewhat unhelpful in terms of providing concrete guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the gap between the claimed importance of language modeling and the actual experiments conducted. They identify 'word similarity and SquAD' as tasks that do not directly reflect language modeling capabilities. The reviewer then suggests 'language modeling, machine translation or text sumarization' as more appropriate tasks. This is an explicit action identifying a missing element and a concrete suggestion for improvement.", "grounding_specificity_rationale": "The reviewer explicitly identifies the issue as a lack of direct testing of language modeling capabilities. They mention 'word similarity and SquAD' as the existing experiments. They then concretely suggest 'language modeling, machine translation or text sumarization' as the missing components. This strong identification of the specific area and the specific missing elements demonstrates high grounding specificity.", "verifiability_rationale": "The reviewer makes a clear claim: 'Experiments on word similarity and SquAD in section 5.3 cannot really reflect the capability of language modeling.' They then provide reasoning for this claim, stating that these tasks do not directly measure language modeling *capability*. This claim is supported by logical reasoning and examples, making it 5.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improving the experiments. They identify a specific weakness in the current experimental design (lack of direct language modeling tasks) and propose concrete improvements (including language modeling, machine translation, or text summarization tasks). This actionable feedback is 5 for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment identifies a potential issue ('inconsistent notation') but does not specify the exact location within Section 2 or suggest a concrete action to address it. While it points out a problem, it lacks the detail needed for the author to act immediately.", "grounding_specificity_rationale": "The comment refers to 'Section 2' generally, indicating a lack of precise identification of the problematic area within the paper. It does not specify a particular subsection, table, figure, or unique element. The grounding is weak because the authors would need to search Section 2 to find the issue. The specificity is also low as it only mentions 'inconsistent notation' without detailing what is inconsistent.", "verifiability_rationale": "The comment states that there is an 'inconsistent notation' in Section 2 but does not provide any evidence, justification, or references to support this claim. It does not explain why the notation is inconsistent or suggest any specific changes. The verifiability is low because the reviewer has not provided any basis for the authors to believe the comment is valid or actionable.", "helpfulness_rationale": "The comment identifies a potential issue ('inconsistent notation') but does not provide any context, explanation, or suggestions for improvement. It lacks the necessary information for the authors to understand the problem and how to address it. The helpfulness is low because the comment is a statement of a problem without any accompanying solution or guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'The authors should cite and discuss'. This action is clear and directly addresses the identified issue of missing references. While the action itself is somewhat vague regarding the *specific* references, the reviewer provides a direct instruction on what needs to be done.", "grounding_specificity_rationale": "The review point mentions 'important references for domain adaptation'. While it identifies a category of references, it does not specify a particular section, table, figure, or unique element within the paper. The reviewer's comment is not precise enough to pinpoint the exact location or detail that is lacking.", "verifiability_rationale": "The review point makes a claim: 'This paper lacks some very important references for domain adaptation.' It also provides a suggestion for improvement: 'The authors should cite and discuss'. This claim is supported by the suggested action, making it verifiable. The reviewer provides a clear direction for the authors to take, indicating an understanding of the deficiency and a proposed solution.", "helpfulness_rationale": "The review point is 5 as it identifies a significant weakness in the paper (lack of important references) and provides a concrete suggestion for improvement ('cite and discuss'). This actionable feedback is directly relevant to the authors and will help them strengthen their manuscript by incorporating relevant literature."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer states the suspicion and provides a potential explanation ('Are the chosen hyperparameters ever at the end of the searched range? The distance to the next best model is suspiciously large there.') which is an explicit action. However, the exact nature of the issue isn't fully defined, making it 3.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'domain pricing' as the specific part of the paper being addressed, making the grounding very clear. The reviewer also specifies the concern is about the 'SCNN getting 'lucky' on domain pricing', making it specific.", "verifiability_rationale": "The reviewer makes a claim ('the SCNN getting \"lucky\" on domain pricing is suspicious') and provides potential explanations and suggestions for investigation ('Are the chosen hyperparameters ever at the end of the searched range? The distance to the next best model is suspiciously large there'). This makes the claim verifiable, though not definitively proven.", "helpfulness_rationale": "The reviewer raises a concern that could help the authors identify issues with their model or hyperparameter tuning. While the exact nature of the issue isn't fully resolved, the point prompts further investigation and clarification, making it helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a problem with the experimental setup, but it's implicit and vague, making it difficult for the authors to take concrete action. While the reviewer states 'some aspects' were unclear, they don't specify which ones. The phrase 'see details below' indicates the information is not immediately available, requiring the authors to seek further clarification from the reviewer.", "grounding_specificity_rationale": "The review point mentions 'the experimental setup', 'corpora', and 'datasets', but doesn't specify *which* parts of the experimental setup are unclear. It also doesn't detail *why* these aspects are poorly motivated. The grounding is weak because the authors can't confidently determine the referenced part. The specificity is low because the comment doesn't clearly detail what needs to be addressed in these parts.", "verifiability_rationale": "The review point makes a claim about the unclear experimental setup, but it lacks specific examples or references to support this claim at this stage. The comment is a statement of a problem, not a claim that can be verified with evidence. The 'see details below' makes it difficult to assess verifiability.", "helpfulness_rationale": "The review point identifies a relevant issue in the experimental setup, which is likely to be helpful for the authors. However, the generality of the point means it requires further clarification from the reviewer. While the authors know there's a problem, they don't know *what* is wrong without more information from the reviewer."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement explicitly mentions the 'improvement of the proposed method over existing RL method' and 'not impressive'. This indicates an explicit action or statement about the comparison. However, it doesn't specify how to improve the proposed method, making it vague.", "grounding_specificity_rationale": "The comment refers to the 'improvement of the proposed method over existing RL method' and 'impression'. While it identifies the comparison, it doesn't point to a specific section, table, or figure in the paper. The use of 'impression' also suggests a lack of specific grounding.", "verifiability_rationale": "The comment contains the claim 'the improvement of the proposed method over existing RL method is not impressive'. This is a subjective statement and does not have supporting evidence or logical reasoning within the review point itself. Therefore, it is not verifiable.", "helpfulness_rationale": "The comment identifies a weakness ('not impressive') in the proposed method compared to existing RL methods. However, it does not provide any specific suggestions or actionable steps to address this weakness. It is a negative comment without constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the size of the hourglass modules, which implies a need for this information. While not explicitly stating an action, the question encourages the authors to seek this information. The reviewer also points out that the authors don't specify how big each module is, making the question somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions '4 hourglass modules', which grounds the discussion to a specific part of the model. However, they do not specify how big each hourglass module is, making the grounding specific but not fully precise.", "verifiability_rationale": "The reviewer is making a statement about a missing detail in the paper ('the authors mention that the model consists of 4 hourglass modules, but do not say how big each hourglass module is'). This statement is verifiable by checking the paper for details about the module size. However, it doesn't require external references or logical reasoning to understand.", "helpfulness_rationale": "The reviewer points out a potential weakness in the paper by highlighting the lack of detail about the model's size. This could hinder reproducibility or allow for better comparisons. While the reviewer doesn't directly tell the authors what to do, they identify a potential area for improvement in the paper. This is 3 as it points out a missing piece of information that could be valuable."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their belief about the correct dimensions of the projection matrices and provides a reason why the current dimensions might be problematic. This makes the action clear: check the dimensions of $A_i$ and the tensor $T$.", "grounding_specificity_rationale": "The reviewer refers to the dimensions of the projection matrices ($A_i$) and the tensor ($T$) in their comment. While they don't explicitly name a section or table, the context is clear within the mathematical notation. This can be considered weak grounding as the authors would need to infer the connection between the dimensions and the issue.", "verifiability_rationale": "The reviewer makes a claim about the correctness of the matrix dimensions. They provide a reasoning based on the requirement for matrix multiplication to be defined. While the reasoning is logical, it might be considered somewhat underspecified as it doesn't provide concrete examples or references to external work.", "helpfulness_rationale": "The reviewer provides a specific technical point and a potential correction regarding the dimensions of the projection matrices. This is generally helpful for someone working with tensor decompositions. However, the helpfulness depends on the authors' familiarity with tensor decompositions and the specific projection method being used. If the reviewer is mistaken, the feedback might be less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "Actionability is borderline because the review point identifies a characteristic of PACE (diagnostictype prediction) but does not explicitly instruct the authors on what to do with this information. While it implies that prior work might have made a similar claim, it doesn't provide a clear path for the authors to address or clarify this in their draft.", "grounding_specificity_rationale": "Grounding specificity is high because the review point explicitly mentions 'PACE' and 'diagnostictype prediction,' clearly identifying the specific aspect of the work being discussed.", "verifiability_rationale": "Verifiability is low because the review point makes a claim about prior work ('prior work (e.g. ClimateBench or ClimateSet) does exactly this') without providing any supporting evidence or justification within the review point itself.", "helpfulness_rationale": "Helpfulness is moderate because the review point identifies a potential mischaracterization of prior work. While it doesn't directly ask the authors to change their method, it highlights a lack of clarity or accuracy, which could be helpful for the authors to consider and potentially reevaluate their description of PACE."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the metric learning theory in the paper is based on generalization theory and that it doesn't offer better results. While this is an explicit statement, it lacks specific details on *how* the metric learning theory is implemented or where the lack of better results is evident in the paper. The action is implicit (identifying a potential weakness), but the details are missing, making it partially actionable.", "grounding_specificity_rationale": "The reviewer criticizes the metric learning theory but does not specify which part of the paper is being referred to. The comment lacks a clear reference to a specific section, theorem, or definition. Therefore, the grounding is weak, making it 1 at all.", "verifiability_rationale": "The reviewer makes claims about the metric learning theory not giving better results and not working within the paper's context. However, they do not provide any evidence or reasoning to support these claims. The claims are presented without logical reasoning, common knowledge, or external references, making them 1.", "helpfulness_rationale": "The reviewer provides a critique of the paper's theoretical contribution, stating that the metric learning theory doesn't offer better results and doesn't seem to work. While this is a helpful critique, it lacks specific actionable feedback. The reviewer doesn't tell the authors what part of the paper needs improvement or how to address the identified issues. The feedback is broad and lacks concrete suggestions, making it 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests improving presentation by moving visual results, which is a general suggestion without explicitly stating what needs to be moved.", "grounding_specificity_rationale": "The reviewer implies visual results are in the supplementary material but doesn't specify the exact section or table. However, they do specify the type of visual results (visual results from supplementary) and the area (crowd density estimation).", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement, not a claim requiring verification.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion to improve the paper's presentation by moving visual results from the supplementary material to the main paper. This directly addresses a practical issue for the authors and is a helpful suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential area of confusion regarding the notation 'r' but does not explicitly state what action should be taken to resolve this confusion. While it implicitly suggests that clarification is needed, it lacks specific guidance on how to achieve this clarification.", "grounding_specificity_rationale": "The comment explicitly mentions specific terms related to the notation 'r', such as 'risk for minimization problems' and 'primal risk for minimax problem', indicating a high level of grounding. It accurately pinpoints the specific aspect of the notation being potentially confusing.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a statement of perceived confusion, which does not fall under the definition of verifiability.", "helpfulness_rationale": "The comment points out a potential source of misunderstanding in the paper. If the authors are able to clarify the notation based on this feedback, it could significantly improve the clarity and understanding of the paper. While it doesn't provide a specific solution, it highlights a potential area for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer poses a question about a potential issue with a specific patient in Figure 8, implying a need for verification. While not explicitly stating an action, the question suggests a desire to understand the discrepancy. The suggestion to use corpus residual value provides a degree of concreteness to the potential action. However, the lack of a direct instruction leaves the action somewhat implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the patient in Figure 8' and asks about its characteristics. This directly identifies the specific part of the paper being addressed, fulfilling the criteria for 'Full Grounding'. The question also specifies the 'British' nature of the patient, adding detail and clarity within the referenced section. The suggestion to use corpus residual value further clarifies what needs to be addressed within this part.", "verifiability_rationale": "The reviewer poses a claim: 'What if we don\u2019t know that a test example is crucially different...'. This is a statement of uncertainty or a question about a potential issue. The reviewer then attempts to verify this claim by asking about 'corpus residual value', providing a method for investigation. While the initial statement is a question, the subsequent suggestion offers a concrete way to verify the claim, making it 3.", "helpfulness_rationale": "The reviewer directly addresses a potential ambiguity in the use of a specific patient in Figure 8. By asking about the 'British' nature of the patient and suggesting the use of 'corpus residual value', they provide a concrete method for the author to investigate and potentially resolve the issue. This directly addresses a potential source of error or misinterpretation and offers a clear path forward, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly states the reviewer's suggestion to use WebQuestions (Berant et al., 2013) instead of WebQuestionsSP. The action is clear: 'switch the dataset'. This is a direct and explicit action that the authors can readily identify and implement.", "grounding_specificity_rationale": "The comment explicitly names the two datasets being considered: 'WebQuestions (Berant et al., 2013)' and 'WebQuestionsSP'. This provides a precise and specific grounding of the comment to the relevant parts of the paper (or the concept of datasets in general).", "verifiability_rationale": "The comment does not provide any justification or reasoning for why WebQuestionsSP was chosen or why WebQuestions would be a better alternative. It simply states the suggestion. There are no references to external works or logical reasoning provided to support the claim that WebQuestionsSP is inherently better.", "helpfulness_rationale": "The review point does not directly address any specific weaknesses or issues in the authors' current draft. It proposes a change in the dataset without providing any rationale or explanation of how this change would benefit the authors or their work. While the suggestion might be valid, it does not directly help the authors improve their current submission."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their confusion about the desirability of sparsity and the need for more justification. They are pointing out a lack of clarity in the paper's explanation of why sparsity is beneficial. The reviewer also implies that the benefits need to be demonstrated, which is a concrete action the authors should take. The criticism is clear and identifies a specific area needing improvement.", "grounding_specificity_rationale": "The reviewer mentions 'sparsity' and 'training' but doesn't specify a particular section, table, or figure. They are broadly questioning the concept. However, they clearly specify *what* is unclear: 'the need to make such claims' and the lack of demonstration of benefits (generalization, training speed). This adds a layer of specificity, even though the initial grounding is weak.", "verifiability_rationale": "The reviewer is not making a claim that needs to be supported. They are questioning an assumption and suggesting that the benefits of sparsity need to be demonstrated. The phrase 'I don't really see the need to make such claims' indicates a lack of conviction or a request for justification, rather than a definitive statement requiring evidence. The focus is on identifying a potential issue with the presentation, not making a claim that needs verification.", "helpfulness_rationale": "The reviewer is pointing out a potential issue with the presentation of sparsity. They are suggesting that the paper might be unclear or lack sufficient evidence. This could be helpful for the authors if addressed. However, the criticism itself isn't a direct, actionable suggestion. It highlights a need for better communication rather than a direct fix."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "2 (2)", "verifiability_label": "1 (1)", "helpfulness_label": "2 (2)", "actionability_rationale": "The review point does not explicitly state an action or suggestion for the authors. It only points out a limitation in novelty.", "grounding_specificity_rationale": "The review point does not specify which aspect of the paper is limited in novelty. It makes a general statement about the overall novelty.", "verifiability_rationale": "The review point makes a claim about the limited novelty but does not provide any evidence or justification for this claim.", "helpfulness_rationale": "The review point identifies a valid concern about the limited novelty of the work. However, it does not offer any specific suggestions or actionable steps for the authors to address this limitation. It is a negative comment without constructive recommendations."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment implicitly suggests an action: 'Analyze the framework on other datasets like ImageNet derivatives.' However, it doesn't explicitly state the steps to take or how to implement this action.", "grounding_specificity_rationale": "The comment explicitly mentions 'ImageNet1k or even ImageNet100' as examples of 'other datasets,' providing a clear grounding. It also specifies the purpose: 'to verify the effectiveness of the framework.' The specificity is good as it names the datasets and the goal of the analysis.", "verifiability_rationale": "The comment suggests an action: 'Present these results in the main paper.' It also implies a prediction: 'These results ideally can be presented in the main paper.' While it doesn't provide the details of how to analyze or present the results, it clearly states what the authors should do and where the relevant information should be located. The reasoning is logical \u2013 expanding evaluation is generally beneficial.", "helpfulness_rationale": "The review point identifies a potential area for improvement (lack of broader evaluation) and suggests a concrete next step ('These results ideally can be presented in the main paper'). This provides clear guidance for the authors on how to enhance their work. The suggestion to present results in the main paper is a reasonable and actionable goal. While it doesn't provide specific methods for analysis, it points towards a standard practice in academic papers."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem 'Unclear model design' and provides concrete suggestions for improvement: 'provide a plot of model illustration, pseudocode table, or code repository'. These suggestions are direct actions the authors should take to address the identified issue.", "grounding_specificity_rationale": "The review point mentions 'model architecture and learning details' and specifically names 'Neurochaos Learning'. While it doesn't pinpoint the exact section or table within the paper that is unclear, the mention of 'learning details' and the specific method 'Neurochaos Learning' strongly suggests the issue is related to a particular part of the model description. The reviewer implies the problem is within the implementation or application of this method.", "verifiability_rationale": "The review point contains a claim that the model design is unclear and suggests specific ways to verify this claim (providing a plot, pseudocode, or code repository). These suggestions are logically sound and directly address the stated problem. Providing these elements would indeed make the model design clearer, thus verifying the reviewer's concern.", "helpfulness_rationale": "The review point is 5 because it directly identifies a significant weakness ('Unclear model design') and offers concrete, actionable suggestions for improvement ('provide a plot, pseudocode, or code repository'). These suggestions empower the authors to focus their efforts on making the model description clearer and more accessible."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a discrepancy between the Abstract/Introduction and the Experiments section regarding the treatment of BigFive and MBTI. In the Abstract and Introduction, they are presented as models to be extended, suggesting a future development. However, in the Experiments section, they are treated as datasets, implying they are being used as input for analysis. This discrepancy creates an implicit action: the authors should clarify the relationship between these models/datasets and ensure consistency throughout the paper. While the reviewer doesn't explicitly state the action, the implication is clear, making it 3 but lacking detail on how to apply it.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly tied to a specific part of the paper. They are pointing out a potential inconsistency in the paper's structure and justification regarding the use of BigFive and MBTI. The comment is a general observation about the flow of the paper rather than a precise instruction about a particular section or table. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer states a potential inconsistency: BigFive and MBTI are described as models to be extended but used as datasets. This is a claim that could be verified by examining the paper's content. The reviewer doesn't provide external references to support this claim, but the statement itself is verifiable. Therefore, the claim is verifiable but lacks external support.", "helpfulness_rationale": "The reviewer points out a potential issue in the paper's structure and justification. They highlight a discrepancy that could confuse readers and hinder understanding. While the reviewer doesn't provide a direct solution, they identify a problem that authors should address. This comment is helpful in pointing out a potential area for improvement, even though it doesn't offer a concrete fix."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that 'Rejection rate is not shown in any experiments.' This indicates an actionable request, but the specific steps or details on how to find this information are not provided, making it only 3.", "grounding_specificity_rationale": "The reviewer refers to 'rejection rate' generally without specifying which aspect or experiment it pertains to. This lack of specificity means the comment does not clearly identify the relevant part of the paper, making it 1.", "verifiability_rationale": "The reviewer makes a claim that 'One could view a misclassification as a rejection.' This claim is supported by logical reasoning (misclassification implies a failure to correctly classify, which could be interpreted as a rejection). The reviewer also provides a recommendation ('Please include rejection rates or view them as misclassifications in the results') based on this claim, providing some justification.", "helpfulness_rationale": "The reviewer identifies a potential issue in the review process ('Rejection rate is not shown') and suggests a solution ('include rejection rates'). This is a constructive comment aimed at improving the clarity and completeness of the review process, even though it doesn't directly provide a solution."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their intention to improve the paper by clarifying the generalization gaps between DIMES's training and its application to specific TSP instances. They also suggest further experiments to investigate this. This indicates a clear and actionable suggestion for the authors to address a perceived limitation in the paper. The reviewer identifies a specific area for improvement and proposes concrete actions, such as clarifying the generalization gaps and conducting additional experiments.", "grounding_specificity_rationale": "The reviewer mentions 'DIMES' and its components like 'direct RL training for largescale problems' and 'meta finetuning' when discussing the generalization gaps. While they identify a relevant aspect of the paper (DIMES), they do not explicitly pinpoint a specific section, table, figure, or unique element of the paper being addressed. The reviewer refers to 'generalization to the specific TSP instances' and 'TSP100' indistribution testing, which suggests they understand the context, but they don't provide a literal mention of a specific part of the paper. Therefore, the grounding is present but not as precise as it could be.", "verifiability_rationale": "The reviewer suggests a comparison of DIMES with other methods on TSP100 indistribution testing performance with and without metalearning. This constitutes a claim that the paper could benefit from such a comparison. The reviewer suggests this is an 'interesting' followup experiment, which implies a belief that this would be a valuable addition. However, the reviewer does not explicitly provide logical reasoning, common knowledge, or external references to support this claim. The suggestion is presented as a potential improvement rather than a statement that is definitively true or proven.", "helpfulness_rationale": "The reviewer's overall tone is constructive and suggests improvements to the paper. They identify a specific area for improvement (generalization to TSP instances) and propose concrete actions, such as clarifying the gaps and conducting additional experiments. While the reviewer suggests experiments, the justification for why these experiments are crucial isn't explicitly detailed in the review point itself. The suggestions are relevant and could significantly enhance the paper's clarity and impact, making them helpful for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point points out a need for information (thresholds) but doesn't explicitly instruct the authors on how to obtain or use it. Therefore, it is implicitly suggesting an action but not directly stating it.", "grounding_specificity_rationale": "The review point is a general question about the results and reproducibility, lacking any specific reference to a part of the paper. Therefore, it is 1 at all.", "verifiability_rationale": "The review point is a question, not a statement making a claim. It doesn't offer an opinion, judgment, or suggestion. Therefore, it contains X and is classified as 'X'.", "helpfulness_rationale": "While the review point is a question, asking for essential information like final thresholds is crucial for the authors to understand and reproduce their work. It empowers them to seek further clarification or information. Therefore, it is 3 as it points to a critical aspect of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a potential flaw in the paper's interpretation of the dataset analysis. They point out that the paper's conclusion about the relationship between readability and question difficulty is too general and doesn't account for the specific features used in the analysis. The reviewer suggests considering the impact of POS/dependency parse features, which is a direct and actionable suggestion for the authors to investigate. The reviewer clearly identifies an area where the authors' work could be improved by considering different analysis methods.", "grounding_specificity_rationale": "The reviewer directly addresses the paper's interpretation of its own findings. They specifically mention 'dataset analysis' as the area where the authors' conclusion might be too broad. Furthermore, the reviewer provides a concrete example of a feature (POS/dependency parse) that could influence the interpretation. This demonstrates a strong grounding in the specific part of the paper being discussed and a clear specification of the potential issue.", "verifiability_rationale": "The reviewer presents a claim about a potential nuance in the paper's interpretation of the dataset analysis. They state that the paper's conclusion about the relationship between readability and question difficulty might be too general and that the specific features used in the analysis are crucial. While the reviewer identifies a valid point that could refine the paper's findings, they do not provide any specific evidence or citations to support their claim at the time of the review. The claim is based on an understanding of how different analysis methods might work, but without further investigation or data, it remains a hypothesis rather than a 5 statement.", "helpfulness_rationale": "The reviewer's comment is 5 because it points out a potential limitation in the paper's interpretation of the dataset analysis. They encourage the authors to consider the impact of different analysis methods, specifically mentioning POS/dependency parse features. This is a valuable suggestion that could lead to a more nuanced and accurate understanding of the relationship between dataset readability and question difficulty. The reviewer provides a specific example to guide the authors' investigation, making the comment both informative and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that Figure 1 could be optimized to use less whitespace. This is an explicit action. However, it does not provide concrete steps on how to achieve this optimization. Therefore, it is 3 but lacks specific guidance on the 'how'.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1' as the part of the paper being addressed. This is a literal mention, indicating full grounding. It also clearly identifies the issue as 'use less whitespace', specifying what needs to be improved in the figure.", "verifiability_rationale": "The comment does not contain a claim. It is a suggestion for improvement, not a statement that requires verification. Therefore, it falls under the 'X' category.", "helpfulness_rationale": "The comment identifies a specific area (Figure 1) and suggests an improvement (optimization). This provides some guidance for the author. However, it lacks specific details on *how* to optimize the whitespace. It's not completely useless, but it could be more helpful with more concrete suggestions."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question ('Do you have any evidence...') and suggests a specific analysis ('It would be nice to have some analysis...'). This indicates an intention to identify a potential issue or area for improvement. However, the reviewer does not specify *how* to perform this analysis or what specific metrics to use, making the action implicit.", "grounding_specificity_rationale": "The reviewer's question is general and does not point to a specific part of the paper or a particular issue within a defined section. They are asking about the *general* meaningfulness of the geometry. While the suggestion ('It would be nice to have some analysis...') touches on a specific aspect (morphfitting results), the question itself is 1 in a specific element of the paper.", "verifiability_rationale": "The reviewer presents a question ('Do you have any evidence...') and a suggestion ('It would be nice to have some analysis...'). This constitutes a claim that the geometry of the space might not be meaningful. However, the reviewer does not provide any evidence or references to support this claim within the review point itself. The suggestion is a potential improvement, not a verified claim.", "helpfulness_rationale": "The review point raises a pertinent question about the interpretability of the embedding space and suggests a concrete next step ('It would be nice to have some analysis...'). This encourages the authors to consider and potentially improve their embedding model. While the review point itself doesn't provide a solution, it identifies a potential area for improvement and guides further investigation, making it helpful in that context."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific issue \u2013 the imbalance in space allocation between memory networks and the forward model, suggesting an action to adjust the length of these sections. The reviewer also mentions a lack of detail in the related work, implying a need for specific information. While the general comment about writing quality is vague, the specific examples provided (same space, missing pieces) make the action more explicit and concrete.", "grounding_specificity_rationale": "The reviewer refers to 'basic memory networks' and 'forward model' without explicitly stating which section, table, or unique element of the paper they are addressing. Similarly, the 'related work' is mentioned without a specific subsection or table number. The reviewer does not point to a specific part of the paper that needs improvement.", "verifiability_rationale": "The reviewer states a claim that the writing quality needs improvement and that the related work is lacking. They provide examples to support these claims, such as 'the authors spend the same space on explaining basic memory networks and then the forward model' and 'The related work has missing pieces on more reinforcement learning tasks in the literature'. These examples serve as justification for the claims.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion regarding the space allocation between memory networks and the forward model. They also suggest improving the related work section by including more reinforcement learning tasks. These suggestions are specific and likely to be helpful for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue with the theoretical construction by stating, 'I assume that either Ass.1 (finite length of an option) or Ass.2 (some other assumption) is responsible.' While the reviewer identifies a potential problem, they do not explicitly state what action the author should take to address it. The reviewer highlights a potential flaw but doesn't provide a direct path for the author to resolve it. The reviewer's statement is an observation and a potential cause, but lacks explicit instructions for action.", "grounding_specificity_rationale": "The reviewer refers to 'the first column of Qo' and 'the first state' in their review point. While they don't have a specific section number, the reference is very precise. They are referring to a specific element of the mathematical notation. This precise reference indicates that the reviewer has identified a specific part of the paper being discussed. Furthermore, the reviewer clearly states what changed ('vo is used to form P'o') and what happened as a result ('the first state is not reachable anymore but from a terminating state'). This specificity makes it clear what the reviewer is observing and suggesting.", "verifiability_rationale": "The reviewer makes a claim by stating, 'I assume that either Ass.1 (finite length of an option) or Ass.2 (some other assumption) is responsible.' This claim is based on the observation that 'the first state is not reachable anymore but from a terminating state' and the potential for 'an infinite loop'. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this assumption. The claim is presented as an assumption without further justification or evidence.", "helpfulness_rationale": "The reviewer's review point highlights a potential issue with the theoretical construction by pointing out the change in the state reachability and suggesting that this could lead to an infinite loop. While the reviewer identifies a potential problem, they do not provide specific, actionable advice on how the author should modify their construction to prevent this infinite loop. The reviewer's comment is more of a diagnostic observation than a direct solution, making it 3 in identifying a problem but not in providing concrete guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the suggestion to 'look at if there is any improvement on the accuracy or specific properties' which is a direct and actionable instruction. The reviewer is proposing a clear next step for the authors to take.", "grounding_specificity_rationale": "The reviewer suggests 'accuracy or specific properties' which is a general area. While the suggestion is specific in terms of the *type* of property, it doesn't pinpoint a specific section or table within the paper. The example 'recurrent model and sequential relationships' adds a degree of specificity by mentioning a model and a concept, making it 'Weakly Grounded'.", "verifiability_rationale": "The suggestion to 'look at if there is any improvement on the accuracy or specific properties' is verifiable. The authors can attempt to measure accuracy or analyze specific properties to see if improvements exist. While it doesn't provide a definitive answer, it offers a clear direction for investigation.", "helpfulness_rationale": "The review point is 5 as it directly addresses a potential limitation the authors might be facing (lack of improvement in FLOPs/inference time). It provides a clear and actionable suggestion to investigate accuracy and specific properties. This offers the authors a concrete next step to take if their initial focus doesn't yield positive results. The suggestion is practical and directly relevant to improving the model's performance."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly points out a potential issue with a core assumption of the paper. They explicitly state, 'An important assumption being made is that d_e are good replacements for entity embeddings. Was this assumption tested?' This is a clear and explicit action that the authors should take to investigate the validity of this assumption. The reviewer provides a clear direction for the authors' next steps.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'entity embeddings' as the subject of their question. This clearly grounds the comment to a specific part of the paper. The reference is specific and not left to interpretation.", "verifiability_rationale": "The reviewer raises a question that could be addressed with further investigation. While the question itself isn't a claim requiring external references, it points to a potential area for improvement in the paper. The reviewer is asking for evidence or justification, which could be considered verifiable if the authors provide it. However, the current state of the comment is more about raising a question than providing a verifiable claim.", "helpfulness_rationale": "The reviewer's question directly challenges a core assumption of the paper. This is a 5 point for the authors as it prompts them to critically evaluate a fundamental aspect of their work. The question is clear, specific, and directly relevant to their methodology. It has the potential to significantly improve the quality of the paper by ensuring the validity of the assumptions."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the components of the 'scoring function' and the threshold values/ranges are unclear. This implies that the criteria for actionability are not explicitly defined, making it difficult to understand what constitutes an actionable comment based on the scoring function. The lack of clarity in the thresholds suggests that the actionability is somewhat vague, as it's not immediately clear how the scores translate to specific actions for the authors.", "grounding_specificity_rationale": "The reviewer's statement doesn't directly address the grounding of the 'scoring function'. However, the lack of clarity in the thresholds and components of the scoring function could be interpreted as a lack of grounding. The grounding of the scoring function itself is not explicitly identified, making it difficult to pinpoint which aspects of the review are being considered and how they are weighted. The thresholds, if they exist, are also not clearly defined, further contributing to the lack of specificity.", "verifiability_rationale": "The review point itself does not contain a claim or assertion that requires verification. It is a statement about the scoring function's lack of clarity. Therefore, the verifiability verification would be 'X'. However, the reviewer's point about the lack of clarity in the scoring function could be seen as a metacomment about the verifiability of the scoring process itself. If the scoring process is not welldefined, it's difficult to verify the outcome of the scoring.", "helpfulness_rationale": "The core of the review point is the lack of clarity regarding the 'scoring function'. If the reviewer cannot understand how the score is determined, the review is not very helpful in explaining the criteria for helpfulness. The lack of clarity makes it difficult to understand the value and direction of the feedback provided by the scoring function."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that making the factors in a table does not help convey more messages than pure text. This is an implicit suggestion that the table is not effectively communicating information. While the reviewer does not explicitly state what needs to be done, the implication is that the table is lacking in some way. Therefore, it is 3 as the authors could try improving the table's design or implementation. However, the lack of a clear direction makes it not fully actionable.", "grounding_specificity_rationale": "The reviewer makes a general statement about tables not being effective in conveying information. They do not specify which particular table or section they are referring to. The comment lacks precision in identifying the specific part of the paper being addressed. Therefore, it is 1.", "verifiability_rationale": "The reviewer makes a claim that making the factors in a table does not help convey more messages than pure text. This claim is presented without any supporting evidence or logical reasoning within the review point itself. The reviewer is stating an opinion or judgment about the table's effectiveness. Therefore, it is verifiable as it contains a claim that can be supported or not supported by evidence (though no evidence is provided in this point).", "helpfulness_rationale": "The reviewer's comment is a critique of the table's effectiveness. They do not offer any suggestions or actions for improvement. The comment is negative and does not provide any value to the authors in terms of actionable feedback. Therefore, it is not helpful."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks 'How many different kinds of physical interaction can be in one simulation?'. This directly requests a specific piece of information and doesn't leave room for interpretation. The reviewer is clearly asking for a *number* of *kinds* of *physical interaction*. This is a clear and direct request for information.", "grounding_specificity_rationale": "The review point is a general question about the potential for different kinds of physical interactions in a simulation. It doesn't refer to a specific section, table, figure, or unique element of a hypothetical paper. The reviewer is asking about a broader concept rather than a specific instance within a document.", "verifiability_rationale": "The review point is a question, not a statement containing a claim or opinion. There is no assertion being made, and therefore no need for verification. The purpose of this review point is to prompt clarification or expansion, not to evaluate something.", "helpfulness_rationale": "While the question is about possibilities, it doesn't directly address a weakness or suggest an improvement in a draft. It asks *what* could be in a simulation, not *what *should* be in a simulation or *how* it could be improved. It prompts the author to think about the complexity of their simulation, but it doesn't provide specific feedback on their current work."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out two specific weaknesses: the lack of categorical features in most datasets and the omission of onehot encoding for one dataset. While these are valid points, the reviewer does not explicitly state what the authors should do to address these issues. The action is implied but not directly stated, making it less actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'datasets' and the 'encoding method' as the areas of concern. They clearly identify the specific parts of the paper where the issues lie, demonstrating strong grounding. The comment is not vague and clearly pinpoints the relevant sections and features.", "verifiability_rationale": "The reviewer makes claims about the datasets and the encoding method. The claim about the lack of categorical features is supported by the fact that most datasets are numerical. The claim about the omission of onehot encoding is supported by the standard practice in machine learning for handling categorical features. The reasoning is based on common knowledge and standard practices, making the claim verifiable.", "helpfulness_rationale": "The reviewer identifies specific limitations in the model comparison and suggests potential improvements, such as considering categorical features and using onehot encoding. While the reviewer doesn't provide explicit instructions on how to implement these changes, they offer clear directions and logical reasoning for why these changes might be beneficial. This provides the authors with actionable insights and guidance, making the review helpful in improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what the authors should do to address the identified issue with the datasets. While it points out the popularity of the datasets, it doesn't provide a clear action or a concrete step to improve their benchmarking results. The reviewer mentions 'better options' but doesn't specify what those options are or how the current datasets should be modified.", "grounding_specificity_rationale": "The reviewer explicitly names the two IoT datasets (FlatCam Face 26 and Headpose detection 11), which clearly grounds the comment in a specific part of the paper. The mention of 'weird choices' and the reasons for their unpopularity are specific to these datasets.", "verifiability_rationale": "The reviewer provides reasons for considering the datasets 'unpopular' and 'weird choices,' which can be seen as a form of justification or deduction. While they don't cite specific external references, the reasons provided are logical and based on the reviewer's understanding of the datasets' popularity. The reviewer also suggests 'better IoT benchmarking options,' which implies a desire for improvement based on their understanding of the field.", "helpfulness_rationale": "The review point identifies a potential weakness in the authors' dataset selection and provides some context for why the chosen datasets might be problematic. However, it doesn't offer direct, actionable feedback on how the authors should improve their benchmarking or what alternative datasets they should consider. The suggestions are more of a general observation than a specific prescription for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the authors do not mention anything about the potential necessity to find global top Q values of the metric over the average of gradients. This is a clear and actionable point, as the reviewer identifies a missing detail that the authors should consider. The reviewer also specifies the missing element: 'global top Q values of the metric over the average of gradients.' This makes the suggestion very concrete.", "grounding_specificity_rationale": "The reviewer identifies the specific area in the paper where the issue might lie, namely 'distributed settings' and 'pruning majorly works with large networks'. This demonstrates strong grounding as the reviewer can identify the specific part of the paper being addressed. Furthermore, the reviewer specifies the missing element: 'potential necessity to find global top Q values of the metric over the average of gradients.' This makes the grounding very specific.", "verifiability_rationale": "The reviewer presents a claim about a potential issue with major pruning methods in the context of distributed training and acceleration techniques. This claim is supported by the reviewer's statement that 'authors do not mention anything about potential necessity to find global top Q values of the metric over the average of gradients.' This lack of information makes the claim verifiable. The reviewer also suggests that this omission could potentially break acceleration techniques like quantization and sparsification, providing a basis for further investigation.", "helpfulness_rationale": "The review provides a specific and actionable suggestion for the authors: investigate a distributed approach for their pruning method. This is a helpful suggestion as it directly addresses the potential issue raised by the reviewer. The reviewer's point highlights a missing detail that is crucial for understanding the authors' work and potentially improving their method. This actionable feedback is likely to be beneficial for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'have some of the subfigures in Figs 1 and 2 been swapped by mistake?' This is a direct and actionable suggestion. The authors can immediately investigate the content of subfigures in figures 1 and 2 to check for the possibility of a swap. The reviewer is asking for a specific check, making the action very clear.", "grounding_specificity_rationale": "The reviewer specifically mentions 'figures 1 and 2' and 'swapped subfigures'. This strong specificity indicates that the reviewer has identified a particular part of the paper and has a specific issue in mind. The authors know exactly where to look and what to check. The grounding is explicit, as the reviewer is pointing to specific sections and their contents.", "verifiability_rationale": "The reviewer makes a claim: 'some of the subfigures in Figs 1 and 2 have been swapped by mistake.' This claim is 3 because the reviewer is pointing to a specific location (figures 1 and 2) and a specific potential issue (swapped subfigures). While the authors might need to visually inspect the figures themselves to confirm, the basis for verification is present. The reasoning is implicit but the elements are there.", "helpfulness_rationale": "The reviewer is directly asking the authors to check the content of specific figures for a potential error. This is a 5 comment because it directly points to a concrete action the authors can take. The authors can immediately go back to figures 1 and 2 and verify the content. This addresses a specific concern and guides the authors in improving their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the dropout probe 'improves sensitivity' and 'finds a causal role' where previous approaches missed it. This directly identifies an action the authors should consider taking (applying the dropout probe) and highlights a specific area of improvement. The reviewer also suggests a potential drawback ('increases the risk of false positives') and proposes a solution ('detailed discussion'). All these elements are concrete and directly address specific aspects of the draft.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'dropout probe' and its 'causal role'. This is a clear and specific identification of the part of the draft being discussed. The reviewer also mentions 'false positives', further grounding the discussion in a specific issue. The language used is precise and directly points to these specific elements.", "verifiability_rationale": "The reviewer states that the dropout probe 'improves sensitivity' and 'finds a causal role'. While these are observations, the reviewer does not provide any evidence, references, or logical reasoning to support these claims within the review point itself. The suggestion about the 'increased risk of false positives' is also presented as a potential issue without specific justification or citation. The justification is based on the reviewer's interpretation and intuition.", "helpfulness_rationale": "The reviewer provides information about a potential improvement (sensitivity) and a potential risk (false positives). They also suggest a valuable action for the authors (detailed discussion). While the reviewer's interpretation of the dropout probe's impact is not explicitly supported by evidence, the information provided is relevant and actionable. The call for a detailed discussion is a concrete suggestion that would likely be helpful for the authors. The information, while based on the reviewer's understanding, is still valuable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the regret bound for the proposed minibatch method is cast to the appendix. This provides a clear and direct action for the authors to take: they should search the appendix for this information. The action is explicit and directly addresses the location where the information should be found.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'appendix' as the location where the regret bound should be. This indicates a high level of grounding specificity, as the authors can directly identify the section to search. The comment is not vague or ambiguous in this regard.", "verifiability_rationale": "The reviewer makes a claim: 'I didn\u2019t find the regret bound for the minibatch estimator in the supplementary.' This is a claim that needs to be supported. While the reviewer *claims* the bound is in the appendix, they are *claiming* they couldn't find it. The verifiability of this claim depends on the actual content of the appendix, which is not provided. However, the *claim to check the appendix* is verifiable. The reviewer is making a logical reasoning to identify where the information should be. The claim itself, about *what* is in the appendix, is not directly verifiable without seeing the appendix content. The reviewer is pointing out a discrepancy between their expectation and their experience.", "helpfulness_rationale": "The reviewer is pointing out a crucial piece of information (the regret bound) that is central to understanding the performance and theoretical guarantees of the proposed minibatch method. By claiming it's in the appendix, they are directing the authors' attention to a specific area where they should look for key information. This is likely to be helpful for the authors in validating the claims made in the paper and understanding the method's behavior. The reviewer is essentially acting as a pointer to a potential issue or area requiring attention."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the formatting issues (NeurIPS style, abstract font size, bottom margins) and suggests a concrete action: 'fixing the paper style.' This indicates a clear next step for the authors to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'NeurIPS formatting style,' which allows the authors to identify the specific aspect being addressed. Furthermore, they specify *what* is wrong with this style (abstract font size, bottom margins) and *what* needs to be done (fixing the style). This provides a clear and specific indication of the issue.", "verifiability_rationale": "The reviewer makes a claim about the current formatting (it 'does not follow the NeurIPS formatting style,' 'the abstract font is too large,' 'the bottom page margins seem to be altered'). While the reviewer doesn't provide explicit logical reasoning or external references *within this specific review point* to support these claims, the implication is that these formatting issues are problematic and need to be addressed to create space for more NLP experiments. The suggestion to 'fix the paper style' implies the reviewer understands the practical consequences of these formatting choices.", "helpfulness_rationale": "The reviewer provides clear and actionable feedback on the formatting issues and suggests a concrete solution (fixing the style) that is likely to benefit the authors (creating space for more NLP experiments). The suggestions are directly tied to the identified issues and offer a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly names 'countbased methods' and 'intrinsic motivations (RND, ICM)' as missing elements in the RL literature. This indicates an awareness of alternative approaches. However, the reviewer does not specify *how* these methods should be discussed or compared. The action is identified, but the implementation details are missing.", "grounding_specificity_rationale": "The reviewer mentions 'countbased methods' and 'intrinsic motivations (RND, ICM)'. While they name specific methods within the latter category, they do not explicitly identify a *specific part* of the paper being addressed. The grounding is in the *field* of RL literature, not a specific element of the submitted work. The criticism is also quite general, not pointing to a specific flaw within the paper.", "verifiability_rationale": "The reviewer states that the paper is 'not sound' and lacks 'discussion and comparison' of relevant RL methods. This constitutes a claim. However, the reviewer does not provide any *evidence*, *reasoning*, or *references* to support this claim. There is no logical reasoning, common knowledge, or external references provided to justify why the paper is unsound or why the mentioned methods are relevant.", "helpfulness_rationale": "The reviewer identifies a potential area for improvement ('lacks discussion and comparison') and suggests a direction ('compare to other RL methods'). However, the reviewer does not provide any *specific details* on how to perform this comparison. The suggestion is very general and lacks concrete guidance on what aspects to consider or how to structure the comparison. Without specific guidance, the suggestion is not particularly helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment states that the annotations in Figure 4 can be 'further enlarged'. This is an implicit action, as the author is told what needs to be done (enlarged) but not explicitly how. The 'further' aspect makes it vague, as it doesn't specify the extent or method of enlargement. Therefore, while it points to an area for improvement, the specific action and its implementation are not clearly defined.", "grounding_specificity_rationale": "The comment explicitly mentions 'annotations in Figure 4'. This directly identifies the specific part of the paper being referred to. The reviewer can easily pinpoint the section where the issue lies. This level of specificity is clear and unambiguous.", "verifiability_rationale": "The comment does not contain a claim or assertion about the paper. It is a suggestion for improvement rather than a critique or judgment. Therefore, it does not require verification in the sense of providing evidence or logical reasoning. It's a suggestion, not a statement that needs to be proven.", "helpfulness_rationale": "The comment identifies a potential issue with the visibility of annotations in Figure 4. While it points out a valid concern that could lead to improvements, it does not provide a concrete solution or action on how to enlarge the annotations. It's a suggestion, but lacks the actionable steps to address the identified problem. Therefore, it is 3 in highlighting a potential area for improvement, but it doesn't fully empower the author to implement the change."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a problem (entities in NER are not limited to sentences) and provides a clear action (considering the entire document). This action is directly linked to the identified issue and provides a concrete direction for improvement. The suggestion to 'consider the entire document' is a specific and actionable step.", "grounding_specificity_rationale": "The review point explicitly mentions 'relation classification' within the context of 'relation extraction (RE) or joint entity and relation extraction'. This clearly identifies the specific aspect of the paper being addressed. Furthermore, the suggestion to 'consider the entire document' is specific to the identified problem of entities spanning multiple sentences. The authors can easily pinpoint the relevant section and understand the issue.", "verifiability_rationale": "The review point makes a claim about the limitations of current approaches in relation classification. This claim is supported by the definition of relation classification, which inherently involves considering entities across multiple sentences or documents. The statement is logically sound and doesn't require external references to be verified.", "helpfulness_rationale": "The review point is clear, identifies a specific problem (entities in NER not limited to sentences), and offers a concrete solution (considering the entire document). It directly tells the authors what needs to be done and where to look, making it 5 and helpful for improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a potential issue with the color bar in Fig. 4 and suggests a label change. This directly points to a specific area of the paper (Fig. 4) and proposes a concrete action (changing the label). The 'worse' label implies a specific type of mislabeling, indicating a clear direction for improvement. The reviewer is not just pointing out a problem but also suggesting a specific correction, making the action very explicit and concrete.", "grounding_specificity_rationale": "The review point explicitly refers to 'Fig. 4' and then specifically mentions 'the color bar' within that figure. This is a clear and accurate identification of the specific part of the paper being addressed. The use of 'presumably' indicates the reviewer is making an inference, but the identification of the section and element is explicit. The reviewer is not just mentioning a general area but pinpointing a specific visual element.", "verifiability_rationale": "The review point contains a claim: 'presumably one of the labels should say \u201cworse\u201d.' This is a statement of opinion or judgment about the figure's presentation. However, the review point does not provide any evidence, reasoning, or references to support why the label should be 'worse'. It's a suggestion based on a *presumption* rather than a wellsupported claim. The reviewer identifies a potential issue but doesn't explain what is wrong or why 'worse' is the correct label.", "helpfulness_rationale": "The review point identifies a potential issue with the presentation of Fig. 4 and suggests a specific change ('worse' label). This provides a clear direction for the authors to improve their draft. While the suggestion lacks justification, it points to a concrete area of improvement and offers a specific target. The reviewer is not just pointing out a problem but also suggesting a specific action to take, making the feedback actionable, even if the reasoning behind the suggestion is missing."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the issue ('training/validation/test') and clearly indicates where the missing information should be added ('sets'). While it doesn't specify *how* to implement the addition, the action is directly identified. The reviewer provides a clear and concise explanation of the grammatical error and the necessary correction.", "grounding_specificity_rationale": "The comment explicitly mentions 'Row 757 in Supp. Page 29'. This is a literal mention of a specific section in the supplementary material, providing clear grounding. It also specifies the *type* of information that is missing ('training/validation/test') and what it should be added ('sets'). This is 5 about the nature of the missing element and the correction.", "verifiability_rationale": "The comment does not contain a claim. It is a suggestion to improve the text. Therefore, it is classified as 'X'.", "helpfulness_rationale": "The comment is a clear and direct suggestion to improve the text by adding 'sets' to 'training/validation/test'. It points to a specific location in the supplementary material. This is a 5 comment as it directly addresses a grammatical error and provides a clear correction. The reviewer's intent is very clear and actionable for the authors."}
{"actionability_label": "Low", "grounding_specificity_label": "Low", "verifiability_label": "Low", "helpfulness_label": "Low", "actionability_rationale": "The reviewer's point is 3 in that it identifies a potential issue with the model's inference capabilities. However, the reviewer does not explicitly state how this issue can be addressed or what specific changes would be made. The lack of explicit actionability makes it difficult to pinpoint the exact next steps for the authors.", "grounding_specificity_rationale": "The reviewer's point is 1 as it does not specify which part of the paper or method is being discussed. The comment is general and does not point to a specific section, table, or figure. Therefore, the authors cannot confidently determine where the issue lies.", "verifiability_rationale": "The reviewer's point is not verifiable as it does not contain a claim that can be supported by evidence. The comment is a subjective assessment of the writing quality and does not provide any specific examples or references to back it up. Without a claim, there is no basis for verification.", "helpfulness_rationale": "The reviewer's point is not helpful as it does not provide specific feedback or actionable suggestions. The comment is a general critique of the writing quality and does not offer concrete improvements or guidance for the authors. Without specific information, the authors cannot take any meaningful steps based on this review point."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the action to be taken: 'an extra pair of brackets' and 'defining the bracketed term separately'. This directly indicates a clear and actionable step for the authors to improve their draft. The suggestion is not just a comment but a concrete proposal for modification.", "grounding_specificity_rationale": "The reviewer identifies the area of confusion as the 'definition of the quantile'. While they don't pinpoint the exact section or part of the paper, they clearly refer to the concept itself. The suggestion to 'improve the clarity' of this definition is specific to the identified concept, indicating a degree of grounding. However, it doesn't explicitly state which part of the paper contains this definition or provide specific examples within that definition.", "verifiability_rationale": "The reviewer's comment contains a claim: 'I found the definition of the quantile a little confusing'. This is an opinion or judgment about a specific part of the paper. This claim is supported by the suggestion to 'improve the clarity', which acts as a justification for the identified issue. While not a direct citation, the suggestion provides a logical reasoning for addressing the confusion.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion aimed at improving the clarity of a specific concept (quantile). This directly addresses a potential point of confusion for the authors and offers a concrete solution. The suggestion is likely to be helpful in improving the reader's understanding of this concept."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the section (line 152) and suggests a replacement for the model. This constitutes an explicit action. However, the suggestion itself is vague, using the phrase 'very high performing model' without specifying what makes the original model unsuitable or what characteristics the replacement should have. Therefore, while an action is taken, it is not concrete enough to guide direct implementation.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'line 152' in the paper, which is a clear indication of grounding. However, the suggestion itself, 'replace it with a very high performing model', is not specific about what aspects of the model need improvement or what kind of 'very high performing model' would be suitable. The grounding is present, but the specificity of the suggestion is lacking.", "verifiability_rationale": "The review point is a suggestion for improvement rather than a claim requiring verification. Therefore, it does not fit the criteria for verifiability.", "helpfulness_rationale": "The reviewer identifies a specific section (line 152) and suggests a positive change (using a 'very high performing model'). This provides a clear direction for improvement and is therefore helpful, even if the suggestion itself lacks specific details. The feedback is actionable in terms of pointing to a specific area for change."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that 'the proposed compression performs worse than PQ'. This is a direct and clear indication of a weakness. The action is to acknowledge this performance difference. While the exact nature of the 'worse' isn't specified, the comparison between 'the proposed compression' and 'PQ' is clear. Therefore, the action is explicit. However, the reviewer doesn't specify *how* it performs worse, making it only partially actionable.", "grounding_specificity_rationale": "The review point refers to 'the proposed compression' and 'PQ' without explicitly naming them. The authors can infer the methods being compared, but they don't have a precise reference. This is weak grounding. The specificity is in mentioning the comparison between 'performance' and 'code length', which is a specific aspect of the method. Therefore, it is somewhat specific.", "verifiability_rationale": "The review point makes a claim: 'the proposed compression performs worse than PQ'. However, it does not provide any justification or evidence for this claim. There are no logical reasoning, common knowledge, or external references provided to support this statement. Therefore, the claim is 1.", "helpfulness_rationale": "The review point identifies a weakness ('the proposed compression performs worse than PQ') and suggests further evaluation ('which is the main weakness of this method, in view of a practical side'). While it points out a problem, it doesn't offer concrete steps or suggestions on how to improve the method. It's a diagnostic statement rather than a prescriptive one. Therefore, it is 3 as it identifies a problem, but it lacks actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that some subjective statements are inappropriate, but it doesn't identify which ones. It also suggests that proofs and references are needed, which is a concrete action. However, the comment doesn't specify *how* to identify the inappropriate statements or *how* to create the proofs and references, making the action somewhat vague. The comment also identifies the unknown aspect of multiscale fusion and suggests skip connections as an alternative, both of which are concrete actions. The comment doesn't explicitly state a need for action or provide a concrete action, making it implicitly stated and vague. The comment identifies the need for proofs and references, making it explicit. The comment identifies the unknown aspect of multiscale fusion, making it explicit. The comment identifies the implicit use of multiscale information in skip connections, making it explicit.", "grounding_specificity_rationale": "The comment mentions 'subjective statements' but doesn't specify which ones, making it weakly grounded. The comment suggests 'proofs and references' which are specific, making it somewhat specific. The comment identifies 'unknown is that when to fuse the multiscale feature' which is a specific part of the design, making it 5. The comment mentions 'skip connections' and links them to 'multiscale information' which is a specific connection, making it 5.", "verifiability_rationale": "The comment contains claims about the appropriateness of subjective statements and the need for proofs and references. The claim about the need for proofs and references is 3 as it points to a gap in the current presentation. The comment also identifies the unknown aspect of multiscale fusion and suggests skip connections, both of which are implicitly stated and require further investigation or verification. The comment also identifies the implicit use of multiscale information in skip connections, which is a connection that needs to be verified with further analysis or examples.", "helpfulness_rationale": "The comment criticizes the work generally without providing specific actionable feedback, making it 1. The comment suggests proofs and references as improvements, which is a 3 suggestion. The comment identifies the unknown aspect of multiscale fusion, which is a helpful suggestion. The comment suggests skip connections as an alternative, which is a helpful suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a question, not an explicit instruction. While it implies a comparison, it doesn't specify what needs to be compared or how. Therefore, it's 2.", "grounding_specificity_rationale": "The review point is a general question about prior art and doesn't specify which prior work is being referenced or how the comparison should be made. Therefore, it's 1 in a specific aspect of the paper or a particular piece of information.", "verifiability_rationale": "The review point is a question, not a claim that needs verification. Therefore, it has X and is not verifiable.", "helpfulness_rationale": "The review point is a question that prompts the author to compare their method with prior art. It doesn't provide specific feedback on what might be wrong with the proposed method or suggest concrete improvements. Therefore, it is not 5 as it doesn't directly address potential weaknesses or offer actionable suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action they would like to take: 'I was wondering whether there would be some interesting observations comparing them.' This indicates a clear and direct action. The reviewer also implies a desire to expand the analysis, which is a concrete action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'language/nationality' and provides a list of examples (Japanese, Chinese, English, Arabic, German...). This clearly identifies the specific part of the paper being addressed. The reviewer also mentions 'detailed analysis' and 'comparing them', which specifies the type of analysis desired.", "verifiability_rationale": "The reviewer makes a claim by stating 'Some analyses can be more detailed' and 'I was wondering whether there would be some interesting observations comparing them.' This claim is supported by the desire for more analysis and the suggestion of comparing different languages/nationalities. While the subjective aspect of 'interesting' is debatable, the claim itself is verifiable based on the desire for deeper insights.", "helpfulness_rationale": "The reviewer directly points out a potential limitation ('Some analyses can be more detailed') and offers a concrete solution ('I was wondering whether there would be some interesting observations comparing them'). This clearly identifies a weakness and provides actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question ('Besides norm, is there any other property of features can be used?') which implicitly suggests an action: exploring alternative feature properties. However, the question is vague and doesn't provide specific guidance on how to identify or utilize these alternative properties. Therefore, while it points towards an actionable direction, the lack of concrete details makes it only 3.", "grounding_specificity_rationale": "The reviewer asks about 'other property of features'. While the topic is clearly related to 'features', the question is general and doesn't specify a particular section, table, figure, or unique element within the paper. The reviewer is implicitly asking about a general property, making the grounding somewhat weak. The specificity is also low as it doesn't detail what kind of alternative property is being sought.", "verifiability_rationale": "The review point is a question, not a statement of what is or isn't the case. Therefore, it doesn't contain a claim that can be verified. The nature of the review point is to seek information rather than critique or recommend changes based on evidence.", "helpfulness_rationale": "The review point is a question prompting the authors to consider alternative feature properties. While it encourages further exploration and potentially leads to improvements, it doesn't directly identify a weakness in the current draft or provide a clear path for improvement. It's more of a suggestion for design enhancement rather than a direct critique or actionable feedback on the existing work."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The comment raises a valid concern about the conservation properties of learningbased methods, which could be actionable for researchers in this field. However, it lacks specific details on how to apply this to the authors' specific method or problem. The comment is vague on the *how* of identifying and addressing conservation properties in the context of learning F^\u2020.", "grounding_specificity_rationale": "The comment mentions specific examples like symplectic integrators and Hamiltonian systems, indicating good grounding. However, it doesn't explicitly state which part of the authors' work is being addressed. The grounding is implicit rather than explicit.", "verifiability_rationale": "The comment poses questions and suggests a way to investigate (numerical illustrations) but doesn't provide explicit evidence or reasoning to support the claim that learning F^\u2020 might not conserve properties. The verifiability is in the potential *content* of the answers to these questions, not the questions themselves.", "helpfulness_rationale": "The review point raises a valid concern about the conservation of mathematical properties in learningbased methods, which is relevant to researchers working on physicsrelated problems. However, it doesn't provide specific, actionable advice or information on how to address this issue for the authors. The helpfulness is in highlighting a potential problem and suggesting an investigation, but it lacks concrete solutions or guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly questions the design choice of using two SIRENs, suggesting that a simpler network for 'd' might suffice. This implies a potential action: investigating the necessity of the two SIRENs and exploring the possibility of a simpler architecture for 'd'. While the reviewer doesn't provide specific details on how to implement this, the question itself points towards a concrete action.", "grounding_specificity_rationale": "The reviewer's comment is general and doesn't explicitly point to a specific part of the paper or method. While the concept of implicit displacement fields is mentioned, the criticism about using two SIRENs is a broader architectural concern rather than a specific issue within a defined section or table. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer suggests a potential improvement (using a simpler network for 'd') but doesn't provide any evidence or reasoning to support this claim. They are essentially proposing an alternative design without justifying why the current approach is necessary or optimal. There's no logical reasoning, common knowledge, or external references provided to support this suggestion.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the potential inefficiency of using two SIRENs. This could be helpful for the authors in terms of model optimization. However, since the reviewer doesn't provide any evidence or reasoning to support their suggestion, it remains a potential improvement rather than a concrete issue that needs immediate attention. Therefore, it's 3 as it points out a potential area for optimization."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests that RQ1 adds no extra information and proposes an alternative analysis. While this offers a suggestion for improvement, it is presented as a critique of the existing RQ1 rather than a direct, actionable improvement for the current draft. The reviewer doesn't specify *how* to implement this suggestion or provide concrete steps. Therefore, while the suggestion is potentially useful, the reviewer's point is more about the *value* of the RQ1 rather than a direct, actionable improvement for the current draft.", "grounding_specificity_rationale": "The reviewer criticizes RQ1 without specifying which part of the paper or analysis this refers to. They also suggest an alternative analysis, which is a broad statement. The reviewer does not identify a specific section, table, figure, or unique aspect of the paper being addressed. The comment is not literal, nor does it mention unique elements. The grounding is weak because the reviewer cannot confidently determine which part the comment addresses. The specificity is also low as the reviewer does not detail what needs to be addressed in this part. The comment is more of a general critique rather than a specific suggestion.", "verifiability_rationale": "The reviewer makes a claim: 'This adds no extra information for the audience.' However, they do not provide any logical reasoning, common knowledge, or external references to support this claim within the context of the current draft. The claim is presented without any backing. The reviewer also suggests an alternative analysis, which is a statement requiring justification to be accepted. Therefore, the claim is not wellsupported by evidence or justification.", "helpfulness_rationale": "The reviewer provides a critique of RQ1's redundancy and suggests an alternative analysis. While the alternative analysis is a concrete suggestion for improvement, the initial critique of RQ1's redundancy is more of a negative comment without clear evidence or justification within the current draft. The helpfulness is moderate because while the suggestion is good, the initial critique is not directly actionable for improving the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states an expectation for a paper on Personalized Embeddings (PE) to include a 'variety of tasks beyond link predict'. This is an explicit statement of what constitutes a good paper in this domain. While it doesn't directly tell the authors *how* to achieve this variety, it sets a clear direction and expectation, making it 3 in guiding improvement towards a broader scope.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or the user's draft where this expectation is being addressed. It's a general statement about the expected scope of a PE paper. Therefore, it lacks grounding specificity as it doesn't pinpoint a particular section or element.", "verifiability_rationale": "The review point contains a claim: 'It is expected to see a variety of tasks beyond link predict where PE is important.' However, it does not provide any justification or evidence for this expectation. It simply states what is considered important without explaining *why* or providing *examples*. Therefore, it is 1 as it lacks supporting reasoning or references.", "helpfulness_rationale": "The review point is clear in its intent to broaden the task variety in PE papers. It provides a direction for improvement by suggesting the inclusion of tasks beyond link prediction. While it doesn't offer specific *howto* guidance, it is a constructive suggestion that encourages a more comprehensive approach. Therefore, it is 3 in guiding authors towards a positive direction of improvement."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "3 (3)", "verifiability_label": "4 (4)", "helpfulness_label": "2 (2)", "actionability_rationale": "The review point is a question prompting further explanation, but it doesn't explicitly state what the limitations are or how the proposed work differs. It's more of a request for more information than a direct critique with actionable suggestions.", "grounding_specificity_rationale": "The reviewer mentions 'other works focusing on the semantic face editing' and specifically asks about 'continuous control over different attributes,' indicating an attempt to ground the criticism. However, they do not explicitly identify a specific paper or section, making the grounding weak. The reviewer does specify the type of work and the aspect being questioned, making the specificity high.", "verifiability_rationale": "The reviewer states a fact: 'There are also some other works focusing on the semantic face editing and they show the ability to achieve continuous control over different attributes, like 1.' This constitutes a claim that needs to be addressed. The reviewer does provide a potential reference, making the grounding 3. However, the reviewer does not explicitly state how their work differs from this specific paper, making the verifiability somewhat lacking in explicit comparison.", "helpfulness_rationale": "The review point is a question prompting further explanation, but it doesn't directly identify a weakness in the author's work or suggest a specific improvement. It's more of a request for more information than a direct critique with actionable suggestions."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states actions: 'Move important content to the main body' and 'Move details to the appendix'. These actions are concrete and directly suggest changes to the paper structure. The reviewer is indicating a preference for better organization.", "grounding_specificity_rationale": "The review point explicitly mentions 'footnotes' and 'parameter settings'. This provides a clear reference point for the reviewer, grounding the feedback in specific aspects of the paper. The reviewer is directly addressing the use of footnotes and the details of parameter settings.", "verifiability_rationale": "The review point expresses a preference for better organization and suggests specific locations (main body and appendix) for certain content. While it doesn't provide external references or logical reasoning to *prove* that footnotes are distracting or that parameter settings are necessary, it offers a clear rationale based on common practices and the need for clarity. The reviewer is making a judgment about what is important and where it should reside.", "helpfulness_rationale": "The review point is clear, actionable, and directly addresses potential issues authors might face with their drafts. The reviewer is suggesting concrete improvements: moving important content to the main body and details to the appendix. These suggestions are welltargeted and likely to be helpful for improving the paper's flow and readability. The reviewer is expressing a practical concern about space and suggesting a solution based on common sense."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the *absence* of fewshot demonstrations and criticizes the *lack of discussion* about them. While the reviewer suggests including zeroshot generation results, they don't explicitly state what the authors should do with the fewshot demonstrations or how they should be discussed. The suggestion is vague.", "grounding_specificity_rationale": "The reviewer mentions 'fewshot demonstrations' generally, without specifying a particular section or table in the paper. They criticize the *lack of discussion* about them but don't specify *where* in the paper this discussion should occur or what specific points it should address. The reviewer's comment is about a *specific aspect* of the experiments but doesn't clearly link it to a specific part of the paper or provide detailed suggestions.", "verifiability_rationale": "The reviewer *claims* that the paper 'finds the inclusion of zeroshot generation results a bit strange here.' This is a statement of opinion or judgment. However, the reviewer doesn't provide specific examples or references to support their opinion about zeroshot results being 'strange.' The justification is subjective and lacks logical reasoning or external references.", "helpfulness_rationale": "The reviewer provides a specific area for improvement (discussion of fewshot demos) and suggests a concrete change (including zeroshot results). While the reviewer doesn't explicitly state what the authors should do with the zeroshot results, their suggestion is clear and actionable. The feedback is focused on a specific aspect of the experiments and offers a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about Figure 3, which implies they are referring to it. They also mention 'OAA', a specific element within the figure, indicating an action to be taken regarding this element. While the action is implied, the reviewer does not explicitly state the action to be taken, making it 3.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 3' and then specifically mentions 'OAA' within that figure. While the figure itself is not explicitly named, the context strongly suggests it. The reviewer also identifies a specific element within the figure, 'OAA', which indicates a degree of specificity. Therefore, the grounding is fully grounded, and the specificity is underspecific as the exact nature of the issue with 'OAA' is not detailed.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are pointing out a missing element ('OAA') in a figure, but do not state anything that needs to be proven or justified. Therefore, there is X to be evaluated for verifiability.", "helpfulness_rationale": "The reviewer identifies a specific issue related to Figure 3 and points out the absence of 'OAA'. This highlights a clear weakness in the draft. However, the reviewer does not provide any suggestions or actions for the author to take to address this issue. While the feedback points to a need for improvement, it lacks concrete guidance, making it 3 but not 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states \"The authors must be more clear in the introduction...\" which implies a specific action the authors should take. This action is to clarify their contribution in the introduction. Therefore, the comment is 3 as it points the authors towards a specific improvement.", "grounding_specificity_rationale": "The reviewer states \"This framework has been already proposed by 12...\" and then refers to the introduction (lines 2930) as the context for this claim. The introduction is a specific section of the paper, and the reviewer is pointing to the claim about the framework within that section. Therefore, the comment is grounded and specific.", "verifiability_rationale": "The reviewer states \"This framework has been already proposed by 12...\" but does not provide any immediate justification or evidence for this claim within the review point itself. The burden of proof lies on the authors to verify this claim or provide their own justification later. Therefore, the claim is not yet verifiable as it lacks supporting evidence within this review point.", "helpfulness_rationale": "The reviewer points out a lack of clarity in the introduction regarding the authors' contribution and suggests that the authors should clarify this. This directly addresses a potential area of confusion for the authors and guides them towards a specific improvement. Therefore, the comment is 3 as it identifies a concrete area for authors to focus their revision efforts."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the effective receptive field after applying the GS module. While the question is relevant to understanding the impact of the GS module, it does not explicitly state an action or provide guidance on how to improve the receptive field. The reviewer is prompting for information rather than directing them to a solution.", "grounding_specificity_rationale": "The reviewer mentions '2' and asks about the 'effective receptive field'. This provides some grounding by referencing a specific external work. However, the reviewer does not explicitly state which part of the paper or aspect of the GS module is being investigated regarding the receptive field. The connection to the specific implementation of the GS module is not clearly established.", "verifiability_rationale": "The review point is a question, not a statement that requires verification. The reviewer is asking for information about the effective receptive field and how it changed after applying the GS module. There is X being made, and no logical reasoning, common knowledge, or external references are being presented as a claim.", "helpfulness_rationale": "The reviewer is asking a question that could be relevant to understanding and potentially improving their GS module implementation. While the question is relevant and could provide valuable information, it does not actively guide the authors on how to improve their draft. The reviewer is prompting for information rather than providing a direct solution or a clear next step."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The suggestion to add another head to the LSTM network is somewhat explicit in identifying the action (adding a head). However, it lacks concrete details on how this head would be implemented or what specific changes to the network architecture would be required. The reviewer proposes adding a head to compute value functions for states, but doesn't specify how this would be integrated into the existing network or how the probabilities of actions would be adjusted. Therefore, while the general action is clear, the specific steps are missing, making it 3 but lacking detailed guidance.", "grounding_specificity_rationale": "The review point suggests adding another head to the LSTM network for computing value functions. However, it does not specify which layer or part of the network this addition would target. The suggestion is general and does not pinpoint a specific section, table, figure, or unique aspect of the paper. The reviewer mentions the probabilities of actions and value functions but doesn't provide any grounding in a specific part of the paper or a concrete implementation detail. Therefore, the suggestion is 1 at all.", "verifiability_rationale": "The review point presents a suggestion to add another head to the LSTM network. This can be considered a claim that this simplification is a valid approach. However, the review point does not provide any evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to justify why adding a head to compute value functions would be a beneficial simplification. The suggestion is plausible but speculative without further justification. Therefore, the claim is not verifiable within the provided review point.", "helpfulness_rationale": "The review point suggests a practical simplification by proposing the addition of another head to the LSTM network for computing value functions. This directly addresses the potential need to retrain the LSTM from scratch, which could be a significant development effort. The suggestion is clear, actionable, and directly proposes a concrete alternative. It does not require extensive reimplementation from the reviewers' side and offers a straightforward way for the authors to potentially improve their model without discarding the pretrained weights. Therefore, the suggestion is 5 as it provides a clear and actionable improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC's regularization in the latent space. While the reviewer is asking for information, it is not a direct instruction to perform an action. The reviewer is seeking clarification on a methodological choice made by the authors. Therefore, while the information is relevant, it is not inherently actionable in the sense of prompting a specific change to the draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'G4RL' and 'HRAC' when asking about their combination. This clearly grounds the question in specific components of the paper. Furthermore, the reviewer asks about the relationship between them (specifically, regularization in the latent space), which adds further specificity to the request. The reviewer is asking for details about a specific part of the paper and how it functions.", "verifiability_rationale": "The reviewer is asking a question about the relationship between G4RL and HRAC. This is a statement of inquiry, not a claim that needs verification. The question itself does not present a logical reasoning, common knowledge, or external references. It is a request for clarification.", "helpfulness_rationale": "The reviewer is seeking information about a methodological choice (the combination of G4RL and HRAC and the potential regularization). While this information could be helpful for the authors to understand the rationale behind their approach, it is not directly prompting them to make a change to their draft. The reviewer is asking for clarification on a decision that was already made."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests 'it would be good to acknowledge some of the older works too.' While this implies an action (acknowledging older works), it lacks specific guidance on *how* to achieve this. The reviewer doesn't provide concrete steps or examples of how to incorporate older works, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'related works' generally, without specifying a particular section, table, figure, or unique aspect of the paper. The suggestion is broad and doesn't pinpoint the exact location or nature of the improvement needed in the related work section.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement rather than a claim that something is missing or incorrect. There is no assertion that the current related work section is flawed or needs justification. The statement is a desire for a change, not a claim requiring verification.", "helpfulness_rationale": "The reviewer's suggestion to 'acknowledge some of the older works too' points towards a valuable improvement in the related work section. It encourages the author to organize their related work better and potentially include a more comprehensive overview of the field's history. While the suggestion is vague, it provides a direction for improvement, making it 3."}
{"actionability_label": "High", "grounding_specificity_label": "Medium", "verifiability_label": "Medium", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states their confusion about why uniform sampling performs better than expected given the authors' claims about the effectiveness of decay methods. This is a clear indication that the reviewer identifies a potential issue or area for further investigation, which can be directly acted upon by the authors.", "grounding_specificity_rationale": "The reviewer states their confusion about the results in Table 2, specifically regarding the performance of linear/exponentialdecay sampling compared to uniform sampling. While they identify a specific area of the paper (Table 2 and the associated discussion), they do not explicitly pinpoint the exact section or table number where the issue lies. The grounding is present but could be more precise.", "verifiability_rationale": "The reviewer's confusion is based on the presented results in Table 2 and the authors' interpretation of these results. While the claim that uniform sampling underperforms is directly supported by the data, the reviewer's *expectation* based on the authors' argument about predictor accuracy is a logical deduction, not a lack of verifiability in the presented data itself. The verifiability issue lies in the *implication* of the results, not the data's lack of support for the claim.", "helpfulness_rationale": "The reviewer's confusion and request for clarification regarding the experimental results are a valuable piece of feedback for the authors. It directly points to a potential area for improvement in their methodology or explanation, making it 5 for them to address."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies three potential weaknesses related to time complexity: the itemoriented autoencoder, the elementwise function, and the number of hidden units. While the reviewer doesn't explicitly state how to fix these issues, they clearly point out *what* might be contributing to the high complexity. The action is to investigate these components further.", "grounding_specificity_rationale": "The reviewer mentions 'itemoriented autoencoder,' 'elementwise function,' and 'number of hidden units' as potential sources of high time complexity. While they don't pinpoint a specific section or unique element, they clearly identify the components being discussed. The grounding is present but not as precise as it could be.", "verifiability_rationale": "The reviewer makes claims about the potential high time complexity due to the mentioned components. They provide reasoning (e.g., 'may be lots of users associated with a typical item,' 'elementwise function is expensive,' 'number of hidden units is much larger than a typical matrix factorizationbased method'). However, they don't provide concrete evidence or references to support these claims. The claim is present, but the verification is lacking.", "helpfulness_rationale": "The reviewer points out potential areas for improvement and suggests specific components that might be contributing to the problem. While the comment is more of a diagnosis (identifying potential issues) than a direct solution (offering concrete steps to take), it still provides valuable information for the authors to consider. The feedback is relevant and suggests directions for further investigation."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a change to the figure labels, indicating an action to be taken: changing the labels to 'pretrained solution encoders & solution decoders'. This is an explicit action. Once the action is identified, the authors know exactly what needs to be done: change the labels. The action is also concrete, as the reviewer provides specific labels to use.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'pretrained solution encoders & solution decoders' and suggests a change related to their description. The reviewer can accurately pinpoint the specific part of the paper being addressed (the figures and the description of autoencoders). The comment specifies what needs to be addressed in this part (improving the clarity of the description of these specific autoencoders). This is 5.", "verifiability_rationale": "The reviewer's preference is based on a reasonable expectation of clarity and a suggestion for improvement rather than a definitive statement requiring justification. While not a claim, the reviewer's preference is based on a reasonable expectation of clarity and a suggestion for improvement rather than a definitive statement requiring justification. It's a suggestion for improvement rather than a definitive statement requiring justification.", "helpfulness_rationale": "The review point directly suggests a concrete action (changing figure labels) and explains *why* it would be helpful (improves clarity). The reviewer clearly states the benefit of the suggested change, making it 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out a *lack* of comparison with specific methods (NeRFbased methods like Zero1to3 and pointe). While they identify the missing element, they don't explicitly state what needs to be done to address this, such as adding a comparison in the experimental section. The action is implicit \u2013 the reviewer identifies a gap but doesn't directly instruct the authors on how to fill it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'NeRFbased methods, like the recent Zero1to3' and 'comparison with pointe'. This clearly identifies the specific methods being referred to, making the grounding explicit. They also clearly state that these comparisons are *missing*, specifying the issue within the mentioned category.", "verifiability_rationale": "The reviewer states that the comparisons are 'missing' and doesn't provide any justification or reasoning for why these comparisons are important or how they would benefit the paper. There is no logical reasoning, common knowledge, or external references provided to support the claim about the missing comparisons.", "helpfulness_rationale": "The reviewer points out that the method is 'missing comparison with a NeRFbased methods, like the recent Zero1to3  I also recommend comparison with pointe'. This identifies a weakness in the paper but doesn't offer any suggestions or actions for the authors to take. The comment is about what is missing, not what to do about it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer is pointing out a missing definition, which can be interpreted as an implicit instruction to identify a weakness. While not a direct instruction to perform an action, it highlights a lack of information, which can be considered a form of actionable feedback by revealing a missing piece of information. However, the action of *looking up* the definition is not explicitly stated by the reviewer.", "grounding_specificity_rationale": "The reviewer explicitly asks for the definition of 'multiaspect' in the context of the paper. This demonstrates a clear identification of a specific part of the paper (the definition section) and a specific issue (the meaning of 'multiaspect'). This fulfills the criteria for 'fully grounded' and 'specific'.", "verifiability_rationale": "The reviewer is not making a claim or suggesting a change. They are pointing out a lack of information or clarity in the paper. This does not involve logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer's suggestion to add a definition for 'multiaspect' is a clear and actionable suggestion for improving the paper. It directly addresses the identified weakness and provides a concrete improvement. While it's not a claim, it's a helpful suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's question about the extraction of proportions is not explicitly stated in the paper. The paper describes the *what* (measuring the proportion of documents and parts of sentences) but not the *how* (the specific method or rules used for extraction). This makes the action implicit rather than explicit. Furthermore, the method of extraction is not detailed, making the action vague and not concrete. Without knowing the specific rules, it's impossible to determine the exact process, which limits the actionable insights for the authors.", "grounding_specificity_rationale": "The reviewer's question about the extraction of proportions is 1 in the paper. The paper describes the *purpose* of the extraction (to measure proportions) but does not specify which sections, tables, or unique elements are being targeted. The request for 'how the parts of sentences and documents are extracted' is a general question about the methodology, not a specific reference to a particular part of the paper. Therefore, the grounding is weak as the authors cannot confidently identify the referenced part based on the provided information.", "verifiability_rationale": "The reviewer's request for a 'more detailed analysis' regarding the extraction of proportions lacks sufficient justification or supporting evidence within the paper. The paper describes the *what* but not the *how* or *why*. There are no logical reasoning, common knowledge, or external references provided to support the method of extraction. The claim that 'p indicates the proportion of documents, I would like to know how the parts of sentences and documents are extracted' is presented without any backing or explanation of the extraction process. Therefore, the verifiability is low as the claim is not wellsupported.", "helpfulness_rationale": "The reviewer's request for a 'more detailed analysis' regarding the extraction of proportions suggests that the initial information provided was insufficient or unclear. The paper describes the *what* but not the *how* or *why*. The lack of clarity and the absence of a detailed explanation make the information less helpful for the authors to understand and potentially reproduce the extraction process. Therefore, the helpfulness is low as the information provided is not comprehensive or welljustified."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for information (computation time, hardware, experimental setup) but not explicitly stating an action or improvement based on that information. While the information is relevant to the experiments, the request itself is not an actionable statement within the context of improving the draft.", "grounding_specificity_rationale": "The reviewer is asking for information related to the experiments described in the draft (computation time, hardware, setup). However, they are not explicitly identifying a specific part of the paper where this information is needed or lacking. The request is general to the experimental section as a whole.", "verifiability_rationale": "The reviewer is making a request for information rather than stating a claim or opinion about the paper. There is no assertion that something is wrong or needs improvement based on the information being requested.", "helpfulness_rationale": "The review point is asking for information that, while potentially useful for reproducibility, does not directly critique or enhance the content of the draft. It does not provide specific feedback on weaknesses or suggest concrete improvements to the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the implementation details of the meta sampler. While the question targets a specific aspect of the method, it doesn't explicitly state an action or provide concrete steps for the authors to take. The reviewer is prompting for clarification rather than directly pointing out a missing action or suggesting a specific course of action.", "grounding_specificity_rationale": "The review point explicitly mentions 'meta sampler' and 'decoupled way', which are specific terms related to the method. However, it doesn't pinpoint the exact section or table where this information might be found. The reviewer is asking about a specific implementation detail but isn't providing a direct reference within the paper.", "verifiability_rationale": "The review point asks a question about the implementation details of the meta sampler. While the question implies a lack of clarity, it doesn't explicitly state a claim that requires verification. The reviewer is seeking information rather than pointing out a gap in justification or evidence.", "helpfulness_rationale": "The review point is primarily a question seeking clarification on implementation details. While this can be helpful for the authors to understand their method better, it doesn't directly identify a weakness in the paper or offer a concrete suggestion for improvement. It's a request for more information rather than a critique or actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests improvements (using standard metrics, including Equality Odds, expanding experiments) and even provides a citation. This immediately suggests high actionability, as the reviewer clearly identifies what needs to be done.", "grounding_specificity_rationale": "The reviewer mentions specific fairness metrics (equality odds) and datasets (COMPAS, Drug Consumption). This demonstrates strong grounding as the reviewer can accurately pinpoint the relevant aspects of the work.", "verifiability_rationale": "The reviewer provides specific suggestions and even a citation, which supports the idea that the claims are verifiable. While the rationale for *why* these are important or how they connect to the existing work isn't explicitly detailed, the suggestions are concrete and point to actionable improvements.", "helpfulness_rationale": "The reviewer provides clear suggestions and even a specific paper to follow. This strongly suggests high helpfulness, as the reviewer directly points out concrete improvements the authors should make."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential issue ('seems speculative or overly opinionated') and suggests an action ('should be stated as a remark, or an aside in a Discussion section, or removed'). This makes the action somewhat explicit as the potential issue is identified. However, the action is vague as it doesn't specify how to determine if it's speculative or opinionated or what specific changes should be made. Therefore, it is 3 but lacks concrete details on how to implement the action.", "grounding_specificity_rationale": "The comment explicitly mentions the section of the paper being referred to ('L107114'). This clearly grounds the comment to that specific part of the paper. However, the comment does not specify what is speculative or opinionated within that section. It refers to the section as a whole without pinpointing a specific element (e.g., a figure, a table, a specific sentence). Therefore, while the section is identified, the issue within it is not clearly defined, making it underspecific.", "verifiability_rationale": "The comment contains a claim ('L107114 seems speculative or overly opinionated') that expresses an opinion or judgment about a specific part of the paper. However, the comment does not provide any evidence, reasoning, or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the content is speculative or opinionated. Therefore, the claim is not supported by any justification.", "helpfulness_rationale": "The comment identifies a potential issue with a specific section of the paper ('L107114 seems speculative or overly opinionated'). However, it does not offer any concrete suggestions or actionable steps to address this issue. The suggested actions ('should be stated as a remark, or an aside in a Discussion section, or removed') are possibilities but not concrete improvements. The comment is a pointer to a problem without providing a clear solution. Therefore, it is not particularly helpful in guiding the authors towards improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The reviewer uses 'It would have been nice' and 'consider' which implies a suggestion rather than a direct instruction. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The review point is a general suggestion about exploring alternative methods without specifying which part of the paper or results this relates to.", "verifiability_rationale": "The review point is a suggestion, not a declarative statement that requires verification. It doesn't make a claim about the current work or propose a solution that needs justification.", "helpfulness_rationale": "The review point suggests exploring alternative positional embeddings as a potential improvement. While it doesn't force a change, it points towards a valuable area for future research and could be considered helpful if the authors are looking for ways to potentially enhance their model's performance or understanding of positional encoding effects."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the importance of the neighborhood size 'h' and its influence on the model's performance. It also points out the inconsistency in using different hyperparameter sets per dataset, which is a clear indication of an actionable item for the authors. The reviewer suggests providing insights into how performance varies with a constant set of parameters, which is a direct request for actionable feedback. The reviewer also asks for insights into the robustness of the method with respect to varying 'h', which is another actionable item. However, the reviewer does not explicitly state the value of 'h' or how to implement the analysis of its influence, making it partially actionable.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. The reviewer is pointing out a general missing element (value of 'h') and a general area for improvement (analysis of its influence). While the reviewer mentions 'h' and 'model's performance', these are not tied to a specific section, table, or figure. The reviewer also mentions 'key parameter' and 'value of h to use', which are general statements. The reviewer also asks for 'intuitive knowledge of the value of h to use', which is a general request. The reviewer also asks for 'robustness of the method with respect to larger or smaller neighborhoods', which is a general question. The reviewer also asks for 'how performance varies with a constant set of parameters', which is a general request. The reviewer also asks for 'insights into the robustness of the method with respect to varying h', which is a general question. While the reviewer identifies a gap in the paper, they do not pinpoint the exact location of this gap.", "verifiability_rationale": "The review point contains a claim: 'Another important missing element from the paper is the value of neighborhood size h, as well as an analysis of its influence over the model's performance.' This claim is supported by logical reasoning, as the reviewer points out a clear gap in the paper. The reviewer also provides external references (different hyperparameter sets per dataset) which support the claim. The reviewer also provides a suggestion: 'providing readers with intuitive knowledge of the value of h to use, and the robustness of the method with respect to larger or smaller neighborhoods is essential.' This suggests a concrete action the authors can take. The reviewer also provides a request: 'Similarly, different hyperparameter sets are used per dataset, which is not ideal. Can authors provide insights into how performance varies with a constant set of parameters?' This suggests a concrete action the authors can take. The reviewer also provides a request: 'and the robustness of the method with respect to varying h.' This suggests a concrete action the authors can take. The reviewer provides verifiable information by pointing out the inconsistency in hyperparameter settings and suggesting improvements. The reviewer provides a clear claim and supports it with logical reasoning and external references (different hyperparameter sets per dataset). The reviewer also provides concrete suggestions and requests for the authors.", "helpfulness_rationale": "The review point is 5 as it directly addresses a key missing element in the paper: the value and influence of the neighborhood size 'h'. The reviewer's suggestion to provide 'intuitive knowledge of the value of h to use' and insights into the 'robustness of the method with respect to larger or smaller neighborhoods' are actionable and would significantly improve the paper's completeness and practical value for the community. The reviewer also highlights the inconsistency in using different hyperparameter sets per dataset, which is a clear indication of a need for clarification and guidance for the authors. The reviewer's request for insights into how performance varies with a constant set of parameters and the robustness of the method with respect to varying 'h' are concrete and actionable suggestions for the authors. The reviewer is not just pointing out a missing element but also suggesting concrete actions the authors can take to improve their work. The reviewer is providing a comprehensive understanding of a key parameter and its impact, which is highly valuable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point asks a question about the model's behavior with imperfect multimodal data. While it highlights a potential issue, it doesn't explicitly state what needs to be done or provide a concrete action. The reviewer is prompting the authors to consider the impact of missing data and the model's reliance on different modalities. While the underlying issue is actionable, the specific action isn't clearly stated, making it 2.", "grounding_specificity_rationale": "The review point refers to 'multimodal data' and its 'imperfection,' specifically mentioning 'missing modalities.' It then discusses the potential impact on 'higherorder interactions' and 'polynomial tensors.' While the general area of the paper is addressed, the specific section, table, or figure being discussed is not explicitly identified. The reviewer uses technical terms, suggesting some level of grounding, but it's not as precise as 'fully grounded'. The specificity is present in the concepts discussed but lacks pinpointing of a specific part of the paper.", "verifiability_rationale": "The review point presents a question about the model's behavior with imperfect multimodal data. It does not contain a declarative statement that requires verification. The question itself is the content being asked about. There is X being made within this review point that needs to be supported by evidence or logical reasoning.", "helpfulness_rationale": "The review point raises a crucial question about a potential limitation of the model when dealing with imperfect multimodal data. It prompts the authors to consider the impact of missing data and whether the model can compensate for this by leveraging other modalities. This question directly addresses a potential area for improvement and encourages the authors to think critically about their model's behavior under specific conditions. The potential insights gained from this question could significantly benefit the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3: 4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is suggesting a *specific analysis* of the SST dataset related to negation and intensity words. They are *not* recommending a change to the paper itself, but rather pointing out a missing analysis. There is no explicit action being proposed, only a suggestion for investigation.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"the SST dataset\" and \"negation or intensity words\", providing a clear and specific reference point. The comment identifies the exact area of the paper and the specific linguistic phenomena being considered.", "verifiability_rationale": "The reviewer is making a *suggestion* rather than stating a fact or claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support the suggestion itself. It's a proposal for further investigation.", "helpfulness_rationale": "The reviewer is not directly asking the authors to make any changes to their draft. Instead, they are suggesting an *analysis* that could potentially improve their understanding of the SST dataset. While relevant, it doesn't directly guide the authors on how to improve their current work. The helpfulness is indirect and could be considered low."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'Authors don\u2019t verify the stability of the OGEAug on OOD benchmarks such as DrugOOD'. This clearly identifies an action the authors should take (verify stability) and provides a method to do so (DrugOOD). The suggestion to use DrugOOD is a concrete action. While the exact implementation details might be missing, the reviewer points to a specific area for improvement, making it actionable.", "grounding_specificity_rationale": "The review point mentions 'stability of the OGEAug' and suggests 'DrugOOD'. While it doesn't explicitly state 'Section 4.2' or any other specific section, the mention of a dataset implies an attempt to ground the feedback. The suggestion to use DrugOOD is also quite specific, indicating a clear area for improvement. However, the authors still need to figure out how to connect the suggested dataset to the specific aspect of 'stability'.", "verifiability_rationale": "The review point makes a claim: 'SPE 2 is validated on this dataset'. This is a claim that needs to be verified. While the reviewer doesn't provide specific examples or references to support this claim within the review point itself, the suggestion to 'validate this with SPE' implies a logical reasoning process for verification. The claim is present, but the verification method is only partially suggested (using SPE), lacking explicit references or detailed steps within the review point.", "helpfulness_rationale": "The review point directly points out a potential gap in the authors' work (lack of OOD validation) and offers a concrete suggestion (using DrugOOD and validating with SPE). This is helpful because it guides the authors towards a specific area of investigation and provides a potential solution. It highlights a practical improvement that can be made to the authors' research."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment suggests alternative methods to SVD, which can be considered an implicit action. However, it doesn't explicitly state what to do next with these suggestions, making it somewhat vague on how to apply them. The reviewer implies that these methods could be explored experimentally, but the exact steps are not laid out.", "grounding_specificity_rationale": "The comment explicitly mentions 'freezing some layers of the model' and 'LoRA', which directly identifies specific parts of the model and a specific technique. This provides strong grounding as the reviewer pinpoints the relevant aspects of the model.", "verifiability_rationale": "The comment does not contain a claim in the sense of making a judgment about the current approach. It's more of a suggestion for future work. Therefore, it doesn't have verifiable content in the typical sense of supporting a point with evidence.", "helpfulness_rationale": "The comment provides valuable suggestions for improvement by suggesting alternative dimensionality reduction techniques and guiding the authors towards exploring parameterefficient methods. The reviewer explicitly states that these methods are 'natural to think about' and could provide a 'valuable basis for experimental comparison', making it 5 for guiding further research and analysis."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "6: X", "helpfulness_label": "4: 3", "actionability_rationale": "The review point suggests expanding the related work section and comparing to strong baselines using coordinates. While it implies an action, the specifics of how to expand the related work or how to compare the baselines are not provided. The action is implied but not explicitly stated, and the details are lacking, making it less actionable.", "grounding_specificity_rationale": "The review point suggests expanding the related work section and comparing to strong baselines using coordinates. It does not specify which part of the paper the related work section should be expanded or how the comparison should be made. The action is implied but not explicitly stated, and the grounding is not specific to a particular part of the paper.", "verifiability_rationale": "The review point suggests expanding the related work section and comparing to strong baselines using coordinates. These are suggestions and recommendations, not explicit claims that require verification. There is no statement that something is wrong or needs to be justified.", "helpfulness_rationale": "The review point suggests expanding the related work section and comparing to strong baselines using coordinates. While these suggestions are relevant to improving the paper's context and positioning, they are very general and lack specific details. The reviewer is pointing out areas for improvement but doesn't provide concrete steps, making it less immediately helpful."}
{"actionability_label": "5", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests an action: 'train on multiple seeds' and identifies a problem with the current approach: 'making it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence.' This clearly indicates an actionable suggestion.", "grounding_specificity_rationale": "The review point refers to 'Single Seed Experiments' generally and suggests 'multiple seed experiments' as an improvement. While it identifies a general area of concern (the limitations of single seed experiments for assessing significance), it doesn't explicitly pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. The suggestion is at a high level rather than targeting a specific element.", "verifiability_rationale": "The review point contains a claim: 'Multiple seed experiments would provide a more robust evaluation.' It also provides a justification for this claim by stating: 'Single Seed Experiments: The experiments in the paper are limited to training on a single seed, making it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence.' This justification provides a logical reasoning for why multiple seeds are beneficial.", "helpfulness_rationale": "The review point is 5 as it directly suggests a concrete and actionable improvement to the authors' work. It identifies a specific limitation (the lack of multiple seed experiments) and proposes a clear and direct solution (training on multiple seeds). This empowers the authors to address the identified weakness and enhance the robustness of their evaluation."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a gap in the explanation by asking 'Why use the VMF distribution and the truncated normal distribution...'. While they don't explicitly state what is missing, they imply a lack of justification for these choices. The action is implied (explaining the motivation), but the specifics of how to implement this explanation are vague. The reviewer is asking for a concrete action, but the action itself is not fully detailed.", "grounding_specificity_rationale": "The reviewer asks a question about the motivation behind specific distribution choices. They do not explicitly state which part of the paper discusses these distributions or how the motivation is explained. The grounding is weak because the reviewer cannot confidently determine where the relevant information is. The comment does not specify what needs to be addressed in this part (the motivation), making it only weakly grounded.", "verifiability_rationale": "The reviewer does not present a claim that needs verification. They are asking a question about the motivation behind a methodological choice. There is no assertion of something that is true or false that requires logical reasoning, common knowledge, or external references. The comment is a question, not a statement requiring evidence.", "helpfulness_rationale": "The reviewer's comment is helpful because they are pointing out a potential lack of clarity or justification for a methodological choice in the paper. By asking 'Why use...', they are highlighting a point that could hinder understanding for the authors. While they don't offer a solution, they are identifying a potential area for improvement in the paper's clarity and completeness."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out a *what* (a multiGPU setup is needed) but doesn't *how* to achieve this. It's a valid observation, but lacks actionable steps for the authors.", "grounding_specificity_rationale": "The reviewer mentions \"optimizations in the proposed method\" generally. This could refer to any part of the method. The reviewer doesn't specify *which* optimizations are being referred to. They could be talking about any of the steps in the method. The authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer states a fact: \"An entire multiGPU setup is required for the optimizations in the proposed method\". This is a claim that *something* is required. However, the reviewer doesn't provide any evidence, reasoning, or references to support why a multiGPU setup is *necessary* for these optimizations. They don't explain the computational demands or the limitations of singleGPU setups for this specific method. The claim is stated without sufficient justification or evidence.", "helpfulness_rationale": "The review points out a valid practical limitation of the proposed method. It highlights a potential barrier to adoption. However, it doesn't offer any constructive suggestions or solutions to make the method more accessible. The authors cannot *do anything* based on this review to improve their draft. It identifies a problem but doesn't offer a solution."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states 'Missing citation' and implies a need for the authors to add a citation at the specified location L425. This is a direct and concrete action, indicating that the authors should go to section L425 and add a citation for the public skipgram data set.", "grounding_specificity_rationale": "The comment explicitly mentions 'skipgram data set' and its location 'L425'. This is a literal mention of a specific part of the paper, providing full grounding. It also clearly identifies the issue as the 'missing citation', specifying what needs to be addressed.", "verifiability_rationale": "The comment points out a factual omission \u2013 the missing citation for the public skipgram data set at L425. While it doesn't explicitly state why this is a problem, the absence of a citation is a verifiable factual error. The reviewer has identified a specific issue and provided a location for it.", "helpfulness_rationale": "The comment is 5 as it directly points out a specific issue (missing citation) at a concrete location (L425). The authors will immediately understand the problem and the necessary action (adding the citation). The action is explicit and does not require further interpretation or reasoning from the authors."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'Compare this system, which also captures semantics.' This is a clear action. Furthermore, they mention 'Ref2 can be a strong baseline to compare the performance of the current system.' This is a concrete suggestion for comparison. The reviewer also offers 'suggestions to improve:'. This is a clear action to take. The combination of explicitly stating the comparison and providing concrete examples and suggestions makes this review point 5.", "grounding_specificity_rationale": "The reviewer refers to 'this system' and 'Ref2'. While 'this system' is not explicitly named at first, the subsequent mention of 'Ref2' grounds the reference to a specific work. The reviewer also provides 'suggestions to improve', which are grounded in the current system being reviewed. The reviewer explicitly mentions 'Ref2' which is a specific reference. The suggestions to improve are also grounded in the current system.", "verifiability_rationale": "The reviewer makes a claim: 'As the current system captures the semantics through RNN based models. So, it would be better to compare this system, which also captures semantics.' This is a claim that needs to be supported. However, the reviewer does not provide specific reasoning or references to support this claim. While they mention RNNs and semantics, they do not explain *why* this comparison is beneficial or cite *specific* examples of systems that capture semantics or *why* Ref2 is a strong baseline. The reviewer also offers 'suggestions to improve:' which are claims that require justification. The reviewer states the *what* (comparison, Ref2) but lacks the *why* and *how*.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement ('suggestions to improve:') and offers a specific reference ('Ref2'). This indicates a desire to provide value to the authors. While the reviewer *claims* it would be better to compare systems, the *justification* for this claim is weak (as identified in verifiability). However, the *action* of suggesting improvements and providing a reference is helpful. The reviewer offers concrete suggestions for improvement, which are directly related to the current system."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a missing piece of information regarding the methodology used to obtain the quantitative results. This is an implicit action, as the reviewer is prompting for details that are not currently present. The information is also concrete, as it specifically asks for details on the data used for training, validating, and testing. Therefore, the reviewer is essentially asking for a more explicit and detailed explanation of the experimental setup and data handling process.", "grounding_specificity_rationale": "The review point does not explicitly state the source of the quantitative results or the specific sections of the paper detailing the data splitting. The reviewer is making a request for information, which is a general comment. While the point implies a need for clarity on data handling, it doesn't pinpoint the exact location or type of data. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part. However, the point does specify the *purpose* (obtaining quantitative results and data splitting), making it somewhat specific about the goal.", "verifiability_rationale": "The review point does not contain a claim or assertion. It is a request for information or clarification. Therefore, it does not have verifiable elements as it doesn't present a statement that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The review point is relevant and would be helpful for the authors. By providing details on how quantitative results are obtained and the data splitting process, the reviewer is directly addressing a common need for clarity in experimental methodology. This information is crucial for understanding the reproducibility and validity of the results. Therefore, the point is helpful in guiding the authors towards a more transparent and understandable experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states potential reasons for the failure (assumptions, learning difficulties) but doesn't explicitly and concretely suggest a specific action the authors should take. They are asking for clarification rather than providing a direct solution.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'triangle dataset' and asks about 'true sources', thus accurately identifying the specific part of the paper being discussed. They also provide a descriptive term for the dataset.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are posing a question for clarification rather than making a statement that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer is asking for clarification and potential explanations for the model's failure. While they are not providing a direct solution, they are prompting the authors to investigate further, which can be a helpful starting point."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a limitation ('it feels like the system should be able to generalize to more views') and suggests an improvement ('it should feel like the system should be able to generalize to more views without too much difficulty'). This is an explicit statement of what the reviewer wants to see. However, the reviewer does not specify *how* this generalization would be achieved or what those additional views would represent, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'two views' and 'more views,' indicating an awareness of the existing and desired number of views. However, the reviewer does not explicitly identify the specific part of the paper or system component these views relate to. The suggestion is about the *number* of views, not a specific aspect of the system or paper. Therefore, the grounding is weakly implied but not explicitly stated.", "verifiability_rationale": "The reviewer states a limitation ('it feels like the system should be able to generalize to more views') and suggests an improvement ('it should feel like the system should be able to generalize to more views without too much difficulty'). This statement, while understandable, is a subjective feeling or expectation rather than a claim that can be logically verified or supported by evidence. There is no explicit claim being made, so it is not verifiable.", "helpfulness_rationale": "The reviewer's comment directly relates to the usability and flexibility of the system for authors. They express a desire for more views to generalize, which could be a valuable feature for authors. However, the comment is somewhat vague and does not provide specific examples or details about what these additional views might entail, making it 3 but lacking concrete suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: the chosen metrics are not suitable for datasets without clear task boundaries. They provide a clear and direct suggestion for improvement: consider alternative metrics or datasets with clearer boundaries. This is a specific and actionable point.", "grounding_specificity_rationale": "The reviewer identifies the problem with the metrics but doesn't explicitly name the specific metrics or datasets they have in mind. They mention 'continual learning, loss after switch and recovery time after switch' generally, which could refer to various metrics. This makes the grounding somewhat weak, as the authors can only infer the specific parts being criticized. However, the reviewer clearly states the *general* issue of unclear task boundaries, which helps the authors understand the context of the problem.", "verifiability_rationale": "The reviewer makes a claim about the unsuitability of the metrics for the datasets. They provide a justification by stating that the task boundaries are not known or there are no hard task boundaries. This justification, while not backed by specific citations or examples, provides a logical reasoning for their claim, making it 3.", "helpfulness_rationale": "The reviewer provides a clear and relevant critique of the chosen metrics in the context of the datasets used. They suggest specific improvements, such as considering alternative metrics or datasets with clearer boundaries. This makes the comment constructive and actionable, providing the authors with a clear direction for their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer's question directly points to a core mechanism of sequence models, specifically the use of a causal mask (unidirectional attention) in autoregressive decoders. The decoder at time step t only uses information up to t because it only has access to the previously generated tokens (which represent the input up to that point) and not the future tokens. This is a fundamental aspect of how autoregressive models generate text sequentially. The reviewer's suggestion to use all time steps is not the standard practice for autoregressive decoders due to the causal mask. The action is 'explain why the decoder uses only past information', and this action is explicit and concrete.", "grounding_specificity_rationale": "The reviewer's question is very specific and directly addresses a particular aspect of the decoder's operation. They are asking why the decoder at time step t uses only the information up to t. The authors can easily identify the relevant part of the model \u2013 the decoder and its attention mechanism \u2013 and understand that this is due to the causal mask (unidirectional attention). The grounding is explicit and clear. The action is 'identify the specific part of the model responsible for using only past information', and this action is directly identifiable. The grounding is 'weak' because while the mechanism is clear, the *why* is implied (causal mask).", "verifiability_rationale": "The claim in the review point is generally verifiable. The reviewer is making an observation about the standard behavior of autoregressive decoders, which is the use of a causal mask (unidirectional attention). This is a wellestablished technique. The claim 'The decoder at time step t uses only the information up to time step t' is supported by the concept of the causal mask. The grounding is 'weak' because while the mechanism is wellknown, the reviewer might be implicitly assuming a different decoding strategy (e.g., beam search with lookahead). However, for standard autoregressive decoding, the claim is verifiable. The evidence is 'logical reasoning' based on the principles of autoregressive generation and the causal mask.", "helpfulness_rationale": "This review point is 5 for the authors. Understanding why the decoder operates this way is crucial for debugging and potentially improving their model. It directly addresses a common assumption about how sequence models generate text. The action is 'understand the mechanism of the decoder', and this action is directly achievable. The feedback is actionable and directly addresses a core aspect of the model."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a specific weakness: the lack of guidance on setting the hyperparameter \u03b3. While the reviewer doesn't explicitly state 'Here's how to set it,' the implication is clear. They are pointing out a missing piece of information that authors would need to implement or understand the method. The reviewer is suggesting that the original draft should have included this information. The reviewer is also implicitly suggesting that this missing information is a weakness, as they ask for it. This points to an implicit call for action on a specific aspect of the method. The reviewer is not stating the action directly, but they are indicating that the original draft lacked this crucial information.", "grounding_specificity_rationale": "The reviewer names the hyperparameter 'gamma' and refers to 'a graph analysis method.' While not perfectly specific, they are pointing to a particular section or aspect of the paper where more detail is needed. The reviewer is not providing a literal mention of a section, table, or figure, but they are indicating a specific area of the paper that requires clarification. The reviewer is also asking for a *specific* improvement, which aligns with the idea of grounding specificity. The reviewer is not stating that the authors can *immediately* find the information, but they are implying that the information is present elsewhere in the paper, just not in the right place for the authors to understand it.", "verifiability_rationale": "The reviewer makes a claim: 'The discussion on arbitrary hyperparameter \u03b3 is missing.' They then provide reasons for why this is a problem: 'including how to set it in practice for a given graph and analyzing on the sensitivity of this hyperparameter, otherwise it will be hard for the researchers to follow.' The reviewer is providing logical reasoning to support their claim. They are also suggesting external references (literature on hyperparameter tuning and sensitivity analysis) to justify their point. The reviewer is not just stating a problem, but they are also providing a path towards a solution, which strengthens the verifiability of their claim.", "helpfulness_rationale": "The reviewer directly addresses a potential weakness in the original draft by pointing out the missing discussion of the hyperparameter \u03b3 and its importance. They are providing a clear suggestion for improvement: 'how to set it in practice for a given graph and analyzing on the sensitivity of this hyperparameter.' This is a valuable piece of feedback that will help authors understand and implement the method correctly. The reviewer is not just pointing out a problem, but they are also providing a concrete direction for improvement, making their feedback 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a potential confounding factor (head location) and suggests a concrete solution (controlled baseline ablation). This directly identifies an issue and proposes a specific action to address it.", "grounding_specificity_rationale": "The comment explicitly mentions 'head location' and suggests 'ablation of heads at different locations'. This directly identifies the specific part of the model being referenced and proposes a specific action to address the identified issue.", "verifiability_rationale": "The comment provides a suggestion for an improvement in the ablation study methodology. While it doesn't present a definitive result, it offers a logical next step based on the identified potential confounding factor. It is a constructive suggestion.", "helpfulness_rationale": "The review point directly addresses a potential flaw in the ablation study methodology by highlighting the confounding factor of head location. It offers a clear and actionable suggestion for improving the controlled baseline, which is directly relevant to the goal of understanding the impact of induction heads versus FV heads. This makes it 5 for the authors to refine their experimental design."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that a section on synonym identification is missing. This makes it an explicit action the authors should take. However, the comment doesn't specify *how* this section should be implemented, making it only 3.", "grounding_specificity_rationale": "The comment explicitly mentions 'a section on synonym identification' and its relation to 'a larger context of similarity measurement'. This clearly grounds the authors in the specific part of the paper being addressed. However, the comment doesn't specify *what* is in that section or *how* it's approached, making it less specific.", "verifiability_rationale": "The comment itself doesn't contain a claim that needs verification. It's more of a request for information about a missing section. Therefore, it doesn't have supporting evidence or justification, making it 1.", "helpfulness_rationale": "The comment identifies a missing section within a larger framework. While this could be considered helpful in pointing out a potential gap in the paper's organization and the authors' understanding, it doesn't actively guide the authors on how to improve the draft. Therefore, it's 3 but lacks active direction."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that an overview is needed, which is an action. However, it does not specify what aspects of the workflow or model require this overview, making the action vague and not fully concrete.", "grounding_specificity_rationale": "The reviewer does not identify a specific part of the paper (e.g., a section, table, or figure) where the workflow or model is discussed. They refer to them generally, making the grounding weak. The comment also does not specify what is wrong with the workflow or model, so it is not specific.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It is a request for information rather than a statement that needs supporting evidence.", "helpfulness_rationale": "The review point requests an overview of the workflow and model. While this can be helpful for understanding, it does not directly identify a weakness or provide a concrete suggestion for improvement, making it less helpful than a critique or specific recommendation."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential issue (knowing the statistical dimension d_lambda) and implies a consequence (potential bias). While the reviewer doesn't explicitly state how to compute it, they point to a specific missing piece of information, making it 3.", "grounding_specificity_rationale": "The reviewer mentions the statistical dimension d_lambda but doesn't explicitly identify where in the paper it should be found or how it's computed. The comment is not precise about the referenced part, making it weakly grounded. The comment specifies what needs to be addressed (knowing d_lambda), making it somewhat specific.", "verifiability_rationale": "The reviewer claims the paper doesn't discuss the computational cost of obtaining d_lambda. This claim can be verified by examining the paper. The comment also implies a potential bias, which could be considered verifiable if the paper explicitly states this. The comment doesn't contain a claim that requires external references to be understood, so it's not 5. The comment doesn't contain a claim that requires external references to be understood, so it's not 5. The comment doesn't contain a claim that requires external references to be understood, so it's not 5. The comment doesn't contain a claim that requires external references to be understood, so it's not 5.", "helpfulness_rationale": "The reviewer raises a valid technical point about the practical limitations of the proposed approach. The paper likely doesn't explicitly address the computational cost of obtaining d_lambda or the potential bias. While the reviewer might understand the technical details, their point is still relevant to the practical applicability of the method."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a change to how Figure3 should be presented, indicating a clear action the authors should take. The suggestion is to redefine the figure as expected quantities are scalars but shown as a vector. This is a concrete action that the authors can directly implement.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'figure3' and provides a specific suggestion for how it should be represented. The suggestion details what needs to be addressed in this part (scalar quantities shown as vectors). This demonstrates a clear and precise identification of the relevant part of the paper and the specific issue within it.", "verifiability_rationale": "While the reviewer does not make a definitive claim that Figure3 is incorrect, the suggestion to redefine it based on the expected representation of scalar quantities is a clear indication of a potential area of confusion or misinterpretation. The reviewer is essentially pointing out a specific way the figure *should* be presented, which implies a difference from the current representation. This provides a basis for the authors to consider and potentially improve their figure.", "helpfulness_rationale": "The review point directly addresses a potential point of confusion regarding the representation of scalar quantities in Figure3. By suggesting a specific alternative representation, the reviewer provides a clear and actionable improvement that the authors can directly implement. This directly helps them understand and present their data more accurately."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states 'The ablations seem to deserve better experiment setup', which is an explicit action pointing to the need for improvement. However, the specific action, 'better experiment setup', is vague and doesn't detail what needs to be changed.", "grounding_specificity_rationale": "The reviewer refers to 'ablations' and 'experiment setup' generally, without pinpointing a specific section, table, or unique aspect of the paper. While 'ablations' is somewhat specific, the 'experiment setup' is a broader concept, making the grounding weak. The reviewer doesn't provide specific examples of what is missing or needs improvement in the setup, making the specificity underspecific.", "verifiability_rationale": "The reviewer makes a claim: 'The ablations seem to deserve better experiment setup'. However, they do not provide any evidence or reasoning to support this claim. They do not explain why the current experiment setup is lacking or what makes it need improvement. Therefore, the verifiability is 1.", "helpfulness_rationale": "The reviewer's comment points to a potential weakness in the paper (the ablations) and suggests improvement in the experimental setup. However, they don't provide any specific suggestions on how to improve the setup. The comment is about a problem without offering a solution, making it not helpful."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out that 'no empirical evidence is provided' and suggests 'looking deeper'. While it identifies a missing element (the evidence), it doesn't specify *how* to obtain or demonstrate this evidence. The action is implied but lacks concrete steps, making it difficult to act upon directly.", "grounding_specificity_rationale": "The review mentions 'lowfrequency words' and 'word similarity data sets' as examples, suggesting a focus on these areas. However, it doesn't explicitly state which section, table, or unique aspect of the paper this refers to. The grounding is present but not precise. Once grounded, the specificity is low as it broadly mentions related concepts without pinpointing the exact issue or how to test the hypothesis.", "verifiability_rationale": "The review states 'a reasonable argument is made' and 'it would have been interesting to look deeper'. These statements express an opinion or judgment about the hypothesis and suggest a potential improvement. However, it doesn't provide specific evidence or reasoning to *justify* this argument or improvement. The claim is present, but the supporting evidence is missing or vague.", "helpfulness_rationale": "The review identifies a potential weakness in the paper (lack of empirical support for a specific hypothesis) and suggests a potential improvement (further investigation). This is a constructive suggestion pointing out a gap in the analysis. However, the suggestion is general and doesn't provide specific steps or areas for improvement, making it 3 but not fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks about the voxel resolution and its impact, which is a direct and actionable question for the authors. They also suggest an experiment comparing different resolutions, which is a concrete action. While the reviewer doesn't directly state how to implement the experiment, the suggestion itself is a clear action to take.", "grounding_specificity_rationale": "The reviewer refers to the 'Study of global feature' and 'Sec4.2', indicating a clear understanding of the paper's structure and the specific area being addressed. They also specify the concern is about the computational cost of 3D voxels, which is a concrete detail within that section.", "verifiability_rationale": "The reviewer states that the computational cost of 3D voxels is a concern and proposes an experiment to study the importance of global features by varying voxel resolutions. This is a claim that can be verified through further investigation and experimentation. While the reviewer doesn't provide specific examples or references for this claim, the suggestion itself is a verifiable hypothesis.", "helpfulness_rationale": "The reviewer provides a clear question about the voxel resolution and its impact on computational cost. They also suggest a relevant experiment to study the importance of global features. This is a valuable and actionable suggestion that directly addresses a potential implementation detail and connects it to a specific section of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'the error analysis on the movie dataset is missing' and 'In order for other researchers to continue on this task, they need to know what are the cases that such model fails.' These are direct statements about what is lacking and what needs improvement, making the action clear and actionable. The reviewer directly points out the need for information and how it will benefit the authors.", "grounding_specificity_rationale": "The review point explicitly mentions 'the movie dataset' and specifies the need for 'error analysis' and 'cases that such model fails.' This clearly identifies the specific part of the paper and the type of information needed, making it 5.", "verifiability_rationale": "The review point contains a claim that error analysis is missing and that this is important for other researchers. While it doesn't provide specific examples of failure cases, it clearly identifies the area where information is lacking and the consequence of this lack. Therefore, it is 3 as it points to a specific need and its potential impact.", "helpfulness_rationale": "The review point is 5 as it directly identifies a concrete weakness (missing error analysis) and provides a clear suggestion for improvement (providing the error analysis and failure cases). This actionable feedback is directly relevant to the authors and addresses a practical need for other researchers to build upon their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment identifies the issue (PM+CL behaving differently) and suggests an action (developing set trends). While the action is implied, the comment points to a specific area for improvement, making it partially actionable.", "grounding_specificity_rationale": "The comment explicitly refers to 'Table 3' and mentions specific elements like 'PM+CL', 'PM', and 'CL'. This allows the authors to accurately pinpoint the section and identify the specific behavior being described, making it 5.", "verifiability_rationale": "The comment states a claim ('it\u2019s hard to see trends here') and suggests an action ('it would be interesting to see development set trends'). However, it does not provide any evidence or reasoning to support why this claim is valid or how to verify the suggested action. Therefore, it is verifiable but lacks sufficient justification, making it '3'.", "helpfulness_rationale": "The review points out a specific issue in Table 3 (PM+CL behaving differently) and suggests a relevant improvement (developing set trends). This directly addresses a potential problem in the results section and encourages further investigation into a specific observation. The suggestion is directly related to the identified issue, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out two issues: 'it is difficult to understand e.g. figure 5' and 'the main metrics reported are performance compared to remaining weights'. The first issue is explicit  the reviewer is stating a problem with a specific element (Figure 5). However, the action is vague  the reviewer doesn't specify *how* the figure is difficult to understand or *what* needs to be done to improve it. The second issue is also explicit  the reviewer is pointing out a gap in the reported metrics. This action is also vague  the reviewer doesn't specify *which* metric is problematic or *why* it's missing. Therefore, while the actions are explicit, they lack concrete details on how to apply them, making it 2.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 5' explicitly, grounding the comment to a specific part of the paper. However, the specificity of the issue is underspecified. The reviewer states 'it is difficult to understand' but doesn't pinpoint the exact problem within the figure (e.g., overlapping lines, unclear labels). Similarly, when referring to 'the main metrics reported', the reviewer doesn't specify *which* metric is missing or *why* it's important to include flops or model size. Therefore, while the actions are grounded to a specific section, the details of the issue and the desired changes are not specific.", "verifiability_rationale": "The reviewer makes two claims: 'it is difficult to understand e.g. figure 5' and 'the main metrics reported are performance compared to remaining weights'. The first claim is not supported by any evidence or justification. The reviewer states the difficulty without providing any examples or reasoning. Similarly, the second claim is also not verifiable as the reviewer doesn't provide any logical reasoning or references to support why the metrics are lacking or why flops or model size should be included. Therefore, neither claim is supported by evidence, making them 1.", "helpfulness_rationale": "The reviewer identifies two areas for improvement: the clarity of Figure 5 and the metrics reported. While the reviewer doesn't provide specific suggestions for improving the figure's clarity, they do point out a concrete problem ( difficulty understanding). Similarly, while the reviewer doesn't provide specific reasons for the missing metrics, they identify a concrete gap in the reported information. By highlighting these specific areas for improvement, the reviewer provides actionable feedback that can help the authors. Therefore, the review point is helpful, even if the suggestions are not fully detailed."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states that some details of the proposed method are missing. While it points out a lack of information, it doesn't explicitly state what is missing or how to address this lack of information. The action is implicit (identifying a problem), but the suggestion is not concrete.", "grounding_specificity_rationale": "The review point refers to 'the proposed method' generally and then mentions 'as noted in the questions section below.' While it implies the method, it doesn't precisely identify a specific section, table, figure, or unique aspect of the method. The grounding is weak because the authors can only make an educated guess about the referenced part.", "verifiability_rationale": "The review point states that 'some details of the proposed method are missing...'. This is a statement of a problem or a request for more information, not a claim that requires verification. There is no assertion of what is missing or why it is important, so there is X to be supported by evidence.", "helpfulness_rationale": "The review point informs the authors that details are missing, which is a helpful starting point. It highlights a gap in the information provided. However, it doesn't specify *what* is missing or *how* the authors should provide the missing details. The feedback is informative but lacks specific guidance, making it 3 rather than 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they would like simplification and better explanation. This suggests an actionable suggestion. The reviewer names specific sections (Figure 7, Section 8) and lines (3964), making the target very clear. They also suggest specific actions like 'simplifying' and 'clarifying the architecture and computations'. This indicates a concrete understanding of what needs to be improved.", "grounding_specificity_rationale": "The reviewer names specific sections (Figure 7, Section 8) and a range of lines (3964). They also provide specific suggestions for improvement within those sections and lines, such as 'simplifying' and 'clarifying the architecture and computations'. This indicates a strong grounding in the specific parts of the paper being referred to and a clear articulation of the issues within those parts.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are suggesting improvements based on their interpretation of the current content. While the reviewer identifies a problem ('paper is too dense'), they do not claim that this problem is definitively true or that their proposed solutions are definitively better. The focus is on suggesting actions rather than making assertions about the paper's state.", "helpfulness_rationale": "The reviewer explicitly states the impact they expect: 'Paper is too dense and is not very easy to follow; multiple reads were required to grasp the concepts and contribution.' They also suggest concrete actions like 'simplifying the description and explaining the architecture and computations better'. They even point to specific sections and lines for improvement. This indicates a clear understanding of the authors' pain point and a direct suggestion to address it. The reviewer's point is not just a comment but a constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer proposes a specific experiment to evaluate oversmoothing. The suggestion is explicit, naming the model (EIGNN), the problem (oversmoothing), the setting (standard), and the comparison (GCNII). This directly addresses the evaluation of oversmoothing techniques and provides a clear direction for the authors to investigate. The suggestion is actionable as it points to a concrete experiment that can be implemented.", "grounding_specificity_rationale": "The reviewer's suggestion is somewhat grounded as it focuses on the *evaluation of oversmoothing techniques* in general. While it doesn't pinpoint a specific section or table within a paper, the focus is clear. However, it is underspecific as it doesn't target a particular aspect of oversmoothing or a specific model implementation within EIGNN or GCNII. The suggestion is broad in scope, covering 'standard setting on realworld datasets.\"", "verifiability_rationale": "The reviewer makes a clear claim that the suggested experiment will be informative. This claim is 5 as the experiment is welldefined: evaluating the performance of EIGNN under a standard oversmoothing setting on realworld datasets and comparing it to GCNII. The reasoning is explicit, and there are no missing elements or unclear aspects. The claim is supported by the logical structure of evaluating model performance under a specific condition and comparing it to a relevant baseline.", "helpfulness_rationale": "The reviewer's suggestion is 5. It directly addresses the evaluation of oversmoothing techniques and proposes a concrete experiment that the authors can readily implement and analyze. This will provide valuable insights into the performance of EIGNN under oversmoothing and its comparison to GCNII, which are relevant to the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'there lacks a separate part or subsection' regarding the inference strategy. This is an explicit statement identifying a missing element. While the reviewer doesn't provide the exact implementation details, the presence of the 'i.e., how to use the multiple prompts in the test stage' provides a clear direction for the authors to find or create this information. The action is to identify the missing subsection and understand its purpose.", "grounding_specificity_rationale": "The review point explicitly mentions 'the approach method,' 'inference strategy,' 'multiple prompts,' and 'test stage.' This clearly identifies the specific part of the paper being addressed. The reviewer also specifies 'how to use the multiple prompts in the test stage,' indicating a clear understanding of what is missing within that specific part.", "verifiability_rationale": "The review point is a statement of a deficiency: 'there lacks a separate part or subsection to introduce the inference strategy.' There is X being made or any suggestion for improvement. It's a factual observation about the current structure of the paper.", "helpfulness_rationale": "The review point identifies a missing element (a subsection) that would improve the paper's clarity and usability. While it doesn't directly tell the authors *how* to use the prompts, it points out a significant gap in the explanation. This is helpful because it highlights a potential area of confusion or lack of clarity for other readers or users of the method."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'Figure 4 is confusing' and 'it's not clear what the columns mean.' This is a direct and specific action the authors should take. The reviewer also identifies the exact issue: 'the columns,' which is a concrete action to be taken.", "grounding_specificity_rationale": "The reviewer directly refers to 'Figure 4' and then specifically points to the 'columns' within that figure. This demonstrates a clear identification of the specific part of the paper being addressed, and the issue within that part. The reviewer provides a precise reference point.", "verifiability_rationale": "The reviewer makes a claim: 'Figure 4 is confusing' and 'it's not clear what the columns mean.' However, based on the *review point itself*, there is no evidence or justification provided to support this claim. The reviewer is stating an observation, but not providing a logical reasoning, common knowledge, or external references to back it up. Therefore, it is 1 based on the information provided in the review point.", "helpfulness_rationale": "The reviewer clearly identifies a specific area for improvement (clarity of Figure 4) and the exact issue (unclear column meaning). This provides the authors with a clear direction for revision. The reviewer's comment directly points to a actionable step the authors can take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests discussing the results of the Streetview experiment. While this is a suggestion, it is not explicitly stated as an action to be taken on a specific part of the paper. The reviewer does not provide a concrete stepbystep action to be performed on the results. The suggestion is to discuss the results, which is an implicit action.", "grounding_specificity_rationale": "The reviewer suggests discussing the results of the Streetview experiment. The paper does not have explicit sections, tables, or figures labeled 'Streetview experiment' or 'experiment results' that the reviewer is referring to specifically. While the reviewer mentions 'experiment results' generally, they do not point to a specific location in the paper. However, the reviewer then mentions 'realworld applications' and 'Algorithm 4', which points to a specific algorithm. This suggests a lack of clear grounding for the initial suggestion but a potential grounding for the later suggestion.", "verifiability_rationale": "The reviewer does not make a claim or assertion about the paper. They are stating suggestions or recommendations for improvement. There is X being made that requires verification or justification.", "helpfulness_rationale": "The reviewer suggests discussing the results of the Streetview experiment and clarifying the realworld applications and computational complexity of the proposed algorithms. These are suggestions for improvement and provide guidance for the authors. While the suggestions are not explicitly stated as actions, they are valuable feedback that can help the authors improve their work. The suggestions point towards specific areas where the authors might need to make changes or additions. The reviewer is providing constructive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to explain why the ablation experiments resulted in low performance and how these results compare to earlier methods. This is a clear indication of an actionable request. The reviewer is directly addressing a potential issue and seeking clarification on a specific aspect of the experimental results. The action is to understand the reasons behind the low performance and the comparison to other methods.", "grounding_specificity_rationale": "The reviewer refers to 'ablation experiments' and specifically mentions 'fCLSWGAN 4' and 'fVAEGAND2 5'. This demonstrates an attempt to identify the specific part of the paper or methodology being discussed. The reviewer is not just saying 'the results are low', but rather pointing to specific experiments and baseline models. This shows a degree of grounding as the reviewer is referencing specific elements. However, the reviewer does not explicitly state *what* is wrong with the ablation experiments or how the baseline models address the issue, making it less fully grounded.", "verifiability_rationale": "The reviewer makes a claim about the ablation experiments being 'so low' and 'even lower than some simple early methods'. This claim requires verification. The reviewer then suggests 'giving explanations', which is the method of verification. The reviewer is stating a belief and then proposing a way to validate it. This makes the claim partially verifiable as it can be supported or refuted by further analysis or information. The suggestion to provide explanations is the attempt to verify the claim.", "helpfulness_rationale": "The reviewer's request to explain the low performance of the ablation experiments and the comparison to other methods is directly aimed at improving understanding and potentially addressing a perceived issue. This is a helpful request for the authors as it seeks to clarify a specific aspect of the experimental results and provide context. The reviewer is actively trying to contribute to a better understanding of the work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the problem ('lack of ablation analysis') and proposes a solution ('it makes it easier to pinpoint the source of performance gain'). The action is clearly defined and the consequence is directly linked to the proposed solution.", "grounding_specificity_rationale": "The reviewer mentions 'lack of ablation analysis' but does not specify which part of the paper this refers to. They do not provide a unique identifier for the section, table, figure, or aspect where the ablation analysis is missing. While the concept of ablation analysis is implied, the specific location is not clearly identified.", "verifiability_rationale": "The review point contains a claim ('lack of ablation analysis makes it difficult to pinpoint the source of performance gain') but does not provide any supporting evidence or justification for this claim. It is stated as a statement of observation rather than a logically derived conclusion.", "helpfulness_rationale": "The review point identifies a potential issue in the paper's analysis (lack of ablation analysis) and suggests a concrete improvement (including an ablation analysis). This directly addresses a potential weakness and offers a constructive solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review points to experiment 2 and its findings regarding the noise rate of similarity labels when the number of classes is large. While the information is present, the review does not explicitly state how this information should be used or applied to the authors' work. The action is implied but not directly stated.", "grounding_specificity_rationale": "The review refers to 'experiment 2' and specifies the condition 'number of classes > 8' and the comparison 'noise rate of similarity labels is less than class labels'. This clearly identifies the specific part of the paper and details its content, indicating strong grounding and specificity.", "verifiability_rationale": "The review contains a claim that 'experiment 2 shows that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels'. The reviewer also infers that 'And the authors use Th.', suggesting they believe the authors have established this relationship. While the reasoning isn't fully elaborated, the claim is stated and supported by the reviewer's interpretation of the authors' work, making it 3.", "helpfulness_rationale": "The review provides information about an experiment and its findings. However, it does not offer specific, actionable advice or guidance on how this information should be used to improve the authors' work. The review is more of an observation than a direct recommendation for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a specific action: comparing the model trained on the original dataset with that trained on the mixture of original and adversarial examples. This action is clearly stated and directly addresses the identified issue with the experimental setup. The reviewer proposes a concrete modification to the training process to better highlight the impact of the augmented adversarial examples.", "grounding_specificity_rationale": "The review point explicitly mentions 'the adversarial set only' and 'the original dataset' as the two training sets to be compared. This directly identifies specific parts of the paper being addressed, making the grounding fully specific. The comparison is between clearly defined datasets, providing a precise focus for the reviewer's suggestion.", "verifiability_rationale": "The review point makes a claim that the experiment in Section 3.1 is 'not well verified' and that the suggested comparison is 'critical to make it more convincing'. This constitutes a claim that requires justification. The reviewer provides a logical reasoning for why this comparison is important, linking it to the motivation of the work and the need to highlight the impact of augmented adversarial examples. While the reviewer doesn't explicitly cite external references, the reasoning is clear and based on the established goals of the paper.", "helpfulness_rationale": "The review point is generally positive and constructive. It directly addresses a perceived weakness in the experimental design and offers a clear, actionable suggestion for improvement. The reviewer's language ('it is critical to make it more convincing,' 'It is better to...') indicates a helpful and focused critique, aimed at guiding the authors towards a better experimental setup. The suggestion is specific and directly related to the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment expresses a concern about the CNN experiments but does not explicitly state what needs to be improved. While it implies a lack of convincingness, it doesn't provide a direct action or specific details on how to make the experiments more convincing.", "grounding_specificity_rationale": "The comment refers to 'the CNN experiments' generally, without specifying which part of the paper or what specific aspect of the experiments is unconvincing. This lack of specificity means the reviewer cannot confidently identify the area needing improvement.", "verifiability_rationale": "The comment states that the CNN experiments are 'not fully convincing' but does not provide any evidence or justification for this claim. There is no logical reasoning, common knowledge, or external references to support this assertion.", "helpfulness_rationale": "The review point is a subjective opinion about the CNN experiments without any concrete suggestions or evidence. It does not empower the authors to improve their draft by providing actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point encourages the authors to doublecheck the results in Table 1 for model (3) (Chung et al. 2016) for CsEn. While it implies a potential issue, it doesn't explicitly state what needs to be changed or how the results should be adjusted. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The review point explicitly mentions 'model (3) (Chung et al. 2016) for CsEn' and 'Table 1' as the location of the potentially incorrect results. This provides a clear reference point for the authors. The point also suggests investigating whether the results were computed by the authors themselves, which adds a specific context.", "verifiability_rationale": "The review point makes a claim: 'In Table 1, the results for model (3) (Chung et al. 2016) for CsEn were not taken from the papers, since they are not reported. If the authors computed these results by themselves (as it seems) they should mention it.' This claim is supported by the statement that the results are not reported in the papers. However, it doesn't provide specific examples or references to back up the claim about the authors' computation.", "helpfulness_rationale": "The review point is helpful in that it points out a potential discrepancy in the reported results and asks for clarification. This can help the authors identify and correct errors in their work. While it doesn't provide a definitive solution, it prompts a closer examination of their results and methodology."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests a general area for improvement (prompt design) rather than a specific action. It doesn't point to a specific part of the paper or how to do something. While the topic is concrete, the 'how' is vague. The reviewer doesn't offer specific steps or examples. Therefore, while it points to a need for improvement, it lacks specific guidance, making it 2.", "grounding_specificity_rationale": "The review refers to \"this paper\" without specifying a particular section, table, figure, or unique element. The reviewer doesn't identify where in the paper the prompt design issue lies. The grounding is weak because the authors can only make an educated guess about which part is being addressed.", "verifiability_rationale": "The review point contains a claim: \"discuss how to design prompts effectively.\" However, it does not provide any specific examples, methods, or references to support this claim. The reviewer simply states the need for discussion without backing it up. There is no logical reasoning, common knowledge, or external references provided to justify the claim.", "helpfulness_rationale": "The review point identifies a valid area for improvement (prompt design) and suggests a direction for it. However, it lacks concrete guidance or specific examples. The reviewer doesn't offer any actionable steps or resources for the authors to improve their prompt design. The suggestion is general and lacks specific value, making it only marginally helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing with SoTA approaches, which is a valuable piece of advice. However, it doesn't explicitly state the steps to take or the specific comparisons to make. It's a general suggestion, making it 3 but not fully actionable.", "grounding_specificity_rationale": "The review point is a general suggestion and doesn't specify which part of the paper or model it refers to. It lacks any grounding to a specific aspect of the work.", "verifiability_rationale": "The review point is a suggestion for improvement, not a claim that needs verification. Therefore, it doesn't fit into the 'claim extraction' category.", "helpfulness_rationale": "Comparing with SoTA approaches is a common and generally helpful practice in machine learning. It provides a direction for improvement and can highlight potential weaknesses in the current model. While it lacks specifics, it's a valuable piece of feedback."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a lack of clarity regarding the use of freezing in MLS and asks a question about why not use the adaptive method. While it identifies a potential issue (lack of clarity), it doesn't *imply* a specific action the authors should take to fix it. The question is more about clarification than a directive.", "grounding_specificity_rationale": "The review refers to \"MLS selection,\" \"the use of freezing,\" and \"the adaptive method,\" explicitly identifying the specific parts of the paper being discussed. It also asks a question about why the adaptive method isn't used, which directly relates to the specific aspect of MLS selection. Therefore, the grounding is both explicit and specific.", "verifiability_rationale": "The review point contains a claim: \"It's not clear why the freezing is used in MLS selection\" and implicitly suggests considering the adaptive method. However, it does not provide any specific examples, citations, or logical reasoning to *support* why freezing is used or why the adaptive method *shouldn't* be used. The statement is a statement of observation and a suggestion, but lacks the backing of verifiable information.", "helpfulness_rationale": "The review point identifies a genuine lack of clarity regarding the use of freezing in MLS and suggests considering the adaptive method. While it doesn't provide a solution or explanation, it *does* direct the authors to a potential area for further investigation and improvement. By highlighting a specific point of confusion, it encourages the authors to seek more information or clarification, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a future work direction, but it doesn't explicitly state the action or provide concrete details on how the limitations should be addressed. The action is implicit, requiring the authors to infer the necessary changes.", "grounding_specificity_rationale": "The review point refers to 'limitations in the paper' generally and doesn't specify which part of the paper is being addressed.", "verifiability_rationale": "The review point itself doesn't contain a claim that can be verified. It's a suggestion for improvement, not a statement about the paper's content that requires evidence.", "helpfulness_rationale": "The review point offers a helpful suggestion about adding a future work section, but it's too general and doesn't provide specific actionable feedback for improving the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about the model's capabilities but does not explicitly state what action the authors should take to verify this. While the question implies an investigation, it lacks concrete steps or criteria for evaluation. Therefore, it is 2 as it points out a potential area for improvement but doesn't directly instruct how to implement it.", "grounding_specificity_rationale": "The reviewer mentions 'the proposed knowledgeCLIP model' and 'a KGaugmented method' which provides some grounding. However, the specific issue being addressed and the details of the analysis are not clearly defined. The reviewer doesn't specify *which* aspect of the model or analysis is being questioned, making the grounding weak. Therefore, it is 2.", "verifiability_rationale": "The review point suggests an analysis involving text modifications and a KGaugmented method but does not provide any justification or reasoning for why the proposed knowledgeCLIP model would or would not solve the issue. There are no references to external works or logical arguments to support the claim. The statement is presented as a question and a suggestion for analysis without any backing. Therefore, it is 1 as it lacks supporting evidence or justification.", "helpfulness_rationale": "The review point raises a relevant question about the model's capabilities and suggests a potentially useful analysis. However, it lacks specific details about the 'issue' and the 'analysis' being proposed. Without knowing what exactly is being questioned or how the analysis will be conducted, the feedback is vague and lacks actionable value for the authors. Therefore, it is 2 as it points out a potential area for improvement and a relevant technique, but it lacks concrete information to guide the authors. The suggestion is interesting, but without specifics, it's difficult to assess its practical value."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue with notation in Eq. 3 and suggests adding variance in Alg. 2. While the notation issue is a symptom, the suggestion to add variance is a concrete action. The reviewer also suggests consistency, which is a suggestion but not a direct action. Therefore, it's borderline.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Eq. 3' and 'Alg. 2,' grounding the comments in specific parts of the paper. They explain *why* the notation in Eq. 3 is confusing and *why* adding variance in Alg. 2 could be beneficial. They also point out a specific inconsistency in notation. This provides clear information about the location and nature of the issue.", "verifiability_rationale": "The reviewer claims that the notation in Eq. 3 is confusing and suggests adding variance in Alg. 2. They also claims that using \u03bc_g would improve consistency. These are claims that could be supported by logical reasoning and by checking the algorithm and equations. The *reasons* for these claims are present, making them 3.", "helpfulness_rationale": "The reviewer's comments are relevant and point towards potential improvements. The suggestion to add variance is directly actionable. The suggestion for consistency is also helpful. While the confusion about notation is valid, it's presented as a symptom rather than a direct solution, which reduces the overall helpfulness slightly."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a desire for a more comprehensive discussion on computational cost and complexity. They also raise a question about the scalability of the approach. While the reviewer doesn't state that the paper *lacks* an explicit statement, the reviewer's point is that the paper *doesn't* provide a detailed explanation of the computational cost. The reviewer is suggesting an *implicit* action: the authors should look for a more detailed explanation of the computational cost and complexity in the paper. The reviewer is not stating that the paper is missing the information, but rather that it's not being discussed sufficiently.", "grounding_specificity_rationale": "The reviewer provides a clear *topic* for the discussion (computational cost and complexity) and even a specific point (the paper not addressing 'significant delays in computation'). The reviewer is not just guessing where the information might be; they are pointing to a specific area within the broader topic. The reviewer is also asking a question that directly follows from the lack of explicit discussion of delays.", "verifiability_rationale": "The reviewer makes a claim: 'While the paper mentions the additional cost didn't lead to 'significant delays in computation'.' This is a factual statement about the paper's content. The reviewer also raises a question ('I wonder if the proposed approach becomes prohibitive in some settings?') which suggests a logical deduction or inference based on the lack of explicit discussion of delays. The reviewer is providing evidence (the lack of discussion) and then making a logical inference.", "helpfulness_rationale": "The reviewer provides a clear *request* for more information about the computational cost and complexity of the proposal. They are directly addressing a potential weakness in the paper's presentation of its computational aspects. This is a very helpful suggestion because it guides the authors to look for specific information that is currently missing. The reviewer is not just pointing out a missing link; they are guiding the authors to a specific area of improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the issue: 'how novel values in the test set are handled.' This clearly identifies a specific action the authors need to take. While it doesn't provide the *how*, it directly points to a missing explanation. Therefore, it can be considered explicit. However, it lacks detail on *how* this is handled, making it somewhat vague on the action itself.", "grounding_specificity_rationale": "The comment explicitly refers to 'novel values in the test set.' This directly points to a specific part of the paper (the test set) and a specific issue within it (how novel values are handled). The reviewer provides a clear reference point, indicating full grounding. Furthermore, the comment specifies what is missing: an explanation of how these novel values are handled. This adds to the specificity.", "verifiability_rationale": "The review point does not contain a claim. It is a request for clarification regarding a specific implementation detail. Therefore, it falls under the 'X' category. There is no evidence of logical reasoning, common knowledge, or external references provided within the review point itself.", "helpfulness_rationale": "The review point identifies a potential area of confusion for the authors by pointing out the lack of explanation for how novel values in the test set are handled. While it doesn't directly tell them what to do, it highlights a missing piece of information that could be crucial for reproducibility or understanding the experimental setup. Therefore, it is 3 in identifying a gap in the authors' knowledge."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that 'Similar methods have already been proposed...'. This indicates an explicit action or suggestion. However, it doesn't specify the exact nature of the similarity or the specific aspects of multitask learning that are missing, making it somewhat vague.", "grounding_specificity_rationale": "The comment does not explicitly identify any specific part of the paper being addressed. It is a general statement about the paper's content and its relation to existing methods. Therefore, it is 1.", "verifiability_rationale": "The comment criticizes the lack of discussion of similar methods in multitask learning. While it identifies a weakness, it doesn't provide any specific examples or references to support this claim. It lacks logical reasoning and external references, making it 1.", "helpfulness_rationale": "The comment points out a significant omission in the paper \u2013 the lack of discussion of similar methods in multitask learning. This highlights a weakness in the paper and provides a direction for improvement. While it doesn't directly tell the authors how to improve, it identifies a concrete area for revision, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "X: 1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the computational cost of FedMITR, which can be interpreted as an implicit suggestion to compare it with other methods. While not a direct instruction, it points to a relevant area for the authors to consider and potentially take action on.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper or method. It is a general question about the computational cost of FedMITR.", "verifiability_rationale": "The comment is a question and does not contain a claim that requires verification. It is a suggestion for further investigation rather than a statement that needs to be proven.", "helpfulness_rationale": "The question directly addresses a potential implementation detail (computational cost) that could impact the practical application of FedMITR. It encourages the authors to consider and potentially take action on this aspect of their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer is asking for clarification on specific implementation details, such as the choice of 0.6 for glove embedding similarity and whether kcrossvalidation was used. While these are specific questions, they are valid and could lead to actionable feedback for the authors if they provide the requested information. The reviewer is prompting for more information to understand the methodology better.", "grounding_specificity_rationale": "The reviewer is asking about the choice of 0.6 for glove embedding similarity and whether kcrossvalidation was used. While they could potentially infer these details from the paper, they are explicitly asking for clarification, indicating a lack of precise identification of the relevant parts. The questions are about specific parameters and procedures.", "verifiability_rationale": "The reviewer is asking questions about methodological choices and implementation details. These questions are about what the authors *did* and *how* they did it, not necessarily about making new claims or providing verifiable evidence. The answers would likely involve referencing the paper's methodology section.", "helpfulness_rationale": "The reviewer is asking for clarification on specific implementation details. While this can be helpful for understanding the methodology, it might not directly address the core weaknesses or novel contributions of the paper. It's a request for more information rather than a critique of the work itself."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a weakness ('lacking indepth analysis') and provides a clear direction for improvement ('investigate and explain the performance differences'). This is a direct instruction for the authors.", "grounding_specificity_rationale": "The reviewer identifies a general area for improvement ('lacking indepth analysis') but does not specify a particular section, table, or figure in the paper where the analysis is missing.", "verifiability_rationale": "The reviewer makes a claim about a missing analysis and provides a logical suggestion for improvement. While specific examples are missing, the reasoning is clear.", "helpfulness_rationale": "The reviewer points out a clear weakness in the experimental analysis and provides a specific direction for the authors to take. This is valuable feedback, even if it lacks specific implementation details."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'Use modern backbone baselines (say, Resnet50 or DenseNet121)' which is an explicit action. It also states '3 conv layers is definitely too small for anything nonsynthetic' which is a concrete action with a specific reason.", "grounding_specificity_rationale": "The review point explicitly mentions 'Resnet50' and 'DenseNet121' as examples, which are specific parts of the paper. However, it does not explicitly state the purpose of using these models (e.g., for feature extraction).", "verifiability_rationale": "The review point contains the claim 'I have to say that even given this version of the idea, I am skeptical this would work'. This claim is supported by the reasoning 'lots of such robustness/domain invariance interventions have been proposed and have failed'.", "helpfulness_rationale": "The review point provides clear and actionable feedback by recommending the use of modern backbone baselines. It also critiques a specific architectural choice ('3 conv layers') and expresses a concern based on past experience ('lots of such robustness/domain invariance interventions have been proposed and have failed'). While the skepticism is a critique of the idea, the suggestions are helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'Making sure that the baseline is fully tuned with the similar resource given to the proposed method could be important for a fair comparison.' However, it does not specify *how* to carry out this action, such as what specific tuning parameters or methods should be used for the baseline. The lack of concrete details makes it less actionable.", "grounding_specificity_rationale": "The comment mentions 'multiple hyperparameters' and specifically names 'temperature, penalty, and threshold'. This indicates some level of grounding as the specific hyperparameters are mentioned. However, it doesn't pinpoint a *specific* part of the paper or table where the issue lies. The grounding is weak because the authors can't confidently determine the referenced part beyond the general area of hyperparameter tuning.", "verifiability_rationale": "The comment contains a claim: 'Making sure that the baseline is fully tuned with the similar resource given to the proposed method could be important for a fair comparison.' However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion is presented as a potential issue without evidence or justification.", "helpfulness_rationale": "The comment raises a valid concern about the fairness of the comparison by suggesting that the baseline might not have been adequately tuned. This points to a potential weakness in the experimental setup and offers a constructive suggestion for improvement. While it doesn't pinpoint a specific error, it provides a clear direction for the authors to consider. The reviewer is asking the authors to reflect on their experimental design and potentially adjust their baseline tuning strategy."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the definition of perplexity on L259 is incorrect and that Eq1 is likely crossentropy, not perplexity. This directly identifies a potential error in the paper's description, providing a clear action for the authors to take: reevaluate the definition of perplexity and the interpretation of Eq1.", "grounding_specificity_rationale": "The reviewer directly references L259 and Eq1, providing specific line numbers and the equation label. This demonstrates a clear understanding of the relevant section and the specific point of contention, making the grounding explicit and precise.", "verifiability_rationale": "The reviewer makes a claim about the incorrectness of the perplexity definition and the likely incorrect attribution of Eq1. This is a verifiable claim, as the authors can independently check the definitions of perplexity and crossentropy and compare them to the paper's content. The lack of external references in the reviewer's claim doesn't negate its verifiability, as the verification can be done through standard knowledge or by checking the cited works.", "helpfulness_rationale": "The reviewer points out potential inaccuracies in the paper's description of perplexity and its relation to crossentropy. This is a valuable piece of feedback for the authors, as it highlights a potential misunderstanding or error in the paper's methodology or explanation. While it might not be a comprehensive review, it directly addresses a specific technical aspect, making it helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the concern about the condition in Proposition 6.1 and provides a clear action: to clarify the condition and compare it with Section 4. The action is directly tied to the identified issue.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Proposition 6.1' and the condition involving '\u03b7 \u2265 C\u2080'. This constitutes strong grounding as the specific part of the paper is identified. However, the reviewer does not explicitly state *why* this condition is strong or what the implications are for the model. The grounding is present, but the specificity regarding the issue is lacking.", "verifiability_rationale": "The reviewer makes a claim about the typicality of \u03b7 being a small value. While this might be a generally accepted fact within the field, the reviewer does not provide any specific references or logical reasoning to support this claim within the review itself. The claim is presented as an observation rather than a definitive statement requiring external evidence. The reasoning provided by the reviewer is based on their understanding of the context, not a direct claim that can be verified logically within the review.", "helpfulness_rationale": "The reviewer's comment is valuable as it points out a potential issue with a specific condition in a proposition and suggests a comparison with another section. This feedback is actionable and can help the authors understand the limitations of their model. While it doesn't provide a definitive solution, it highlights an area that needs further investigation. The feedback is relevant and constructive."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly names specific missing baselines (MVGRL, gptgnn) and suggests adding more. This is an explicit statement of what needs to be done and is very concrete.", "grounding_specificity_rationale": "The reviewer mentions 'the compared baseline is not sufficient' and names specific examples (MVGRL, gptgnn). While it doesn't explicitly state 'section X,' the context implies it's related to the experimental setup and comparisons. The reviewer also mentions 'graph classification task,' which points to a specific area. The reviewer specifies *which* baselines are missing and *why* (insufficient). The suggestion to 'add more baselines' is also general. Therefore, it is grounded but not fully specific about the missing elements within that area. The grounding is present but could be more precise about the missing elements within the graph classification task.", "verifiability_rationale": "The reviewer makes a claim that the baselines are insufficient and suggests adding more. This is a clear claim. However, the reviewer does not provide specific evidence or reasoning to support why the existing baselines are insufficient beyond the general statement. The suggestion to 'add more baselines' and 'test on common datasets' is a suggestion, not a claim that something is wrong. The lack of specific evidence for the claim makes it underverifiable.", "helpfulness_rationale": "The review point explicitly names specific missing baselines (MVGRL, gptgnn) and suggests adding more. This is an explicit statement of what needs to be done and is very concrete. The reviewer provides clear next steps for the authors, making it 5. The suggestion to add specific baselines and test on common datasets is also helpful for the authors to improve their draft. The reviewer's point is clear and directly addresses a potential weakness in the authors' experimental setup. The lack of verifiability does not diminish the helpfulness of the suggestion."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point primarily criticizes the authors' defense strategy and suggests an alternative evaluation scenario. While it identifies a potential weakness in the evaluation (structural damage vs. minimal structural alteration), it does not explicitly state an action or provide concrete steps for the authors to take. The reviewer proposes an 'adaptive attack' but doesn't detail how this should be implemented or what changes the authors should make to their defense.", "grounding_specificity_rationale": "The reviewer refers to 'proposed strategies' and 'edge map based defense strategies,' but doesn't pinpoint a specific section, table, or unique element within the paper that they are criticizing. While the topic is relevant, the exact location and details of the issue are not clearly specified.", "verifiability_rationale": "The reviewer makes a claim about the potential limitations of the authors' evaluation strategy (that it might not capture subtle adversarial attacks). However, they do not provide specific examples, references, or logical reasoning to support this claim within the provided text. The argument is presented as a concern rather than a wellsupported assertion.", "helpfulness_rationale": "The review point raises a valid concern about the authors' evaluation strategy and suggests an alternative approach. While it doesn't offer a direct solution or specific changes to implement, it encourages the authors to critically evaluate their methodology and consider the potential impact of different attack scenarios. It points out a potential gap in their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the desired change: 'the legends should be longer...'. It also implies the consequence: 'clarify whether the numbers are % errors, or % correct (MNIST and CIFAR respectively presumably)'. This makes the action clear and the expected outcome explicit.", "grounding_specificity_rationale": "The comment directly references the 'tables 1, 2, 3' and specifies the desired change in the 'legends'. This indicates a clear understanding of the location and a specific action to be taken. The comment also mentions the datasets (MNIST and CIFAR) which further grounds the specificity.", "verifiability_rationale": "The comment does not contain a claim in the sense of a statement of opinion or judgment. It is a suggestion for improvement. Therefore, it does not have verifiable support in the same way a critique would.", "helpfulness_rationale": "The comment is clear and directly points to a specific area for improvement (table legends). It suggests a concrete action (making legends longer and clearer) and provides context (MNIST and CIFAR datasets). This is a valuable and specific piece of feedback that directly benefits the authors by improving the clarity and understanding of their results."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review points out the absence of standard deviations in the experimental results. This is an explicit statement about a specific aspect of the paper (the experimental results section) and a clear indication of what is missing. The authors can directly infer that they should include standard deviations to properly assess the significance of their findings. The action is also concrete as the authors know exactly what they are missing.", "grounding_specificity_rationale": "The review mentions 'experimental results' generally, without specifying a particular section, table, or figure. While it identifies the area where the issue lies, it doesn't pinpoint the exact element within that area. The authors would need to make an educated guess to find the specific part where standard deviations are missing. Therefore, the grounding is weak. While the specificity of the *issue* (lack of standard deviations) is clear, the grounding of the *area* is not.", "verifiability_rationale": "The review states that the experimental results 'do not contain standard deviations'. This is a factual statement and can be considered a claim. However, the review does not provide any logical reasoning, examples, or external references to support why the absence of standard deviations makes it hard to judge the significance of the results. The claim is presented without sufficient justification.", "helpfulness_rationale": "The review identifies a clear omission in the experimental reporting: the absence of standard deviations. This is a specific piece of information that the authors can directly use to improve their draft. The suggestion to include standard deviations is a concrete and actionable step they can take to address the identified issue. The feedback is directly relevant and helpful for improving the rigor of their experimental analysis."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the specific areas of the analysis that lack theoretical backing: 'the existence and smoothness of the solution of SDE (2a)(2d)' and 'any guarantees of the discretization (in time and space)'. This provides clear and actionable feedback for the authors to improve their analysis. The reviewer also implies that these are standard aspects that should be considered for a rigorous analysis.", "grounding_specificity_rationale": "The reviewer mentions 'theoretical work on sampling and particlebased optimization methods,' which, while not a direct section number or table reference, points to the general theoretical framework of the paper. However, the reviewer then specifically names the 'existence and smoothness of the solution of SDE (2a)(2d)' and 'any guarantees of the discretization (in time and space)' as the specific issues. This demonstrates a good level of specificity within the grounding of the theoretical context.", "verifiability_rationale": "The reviewer makes a claim that 'the provided analysis seems somewhat weak' and then provides specific examples of what is missing, namely 'the existence and smoothness of the solution of SDE (2a)(2d), and any guarantees of the discretization (in time and space)'. While the reviewer doesn't provide explicit external references in this review point, the implication is that these are standard theoretical considerations for this type of analysis. The reasoning is logical and points to established areas of theoretical work.", "helpfulness_rationale": "The reviewer's comment is highly specific, pointing out exact areas in the analysis that lack theoretical justification. By naming 'the existence and smoothness of the solution of SDE (2a)(2d)' and 'any guarantees of the discretization (in time and space),' the reviewer provides clear and actionable feedback for the authors to strengthen their analysis. This directly addresses potential weaknesses in the methodology and results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer states 'Quality of generated images by proposed method is limited' and 'the realism of generated results is limited.' This is an explicit statement of a problem. However, the reviewer does not specify how the quality is limited (e.g., blurry, low resolution, lack of fine details). While the reviewer suggests 'improving the realism of generated results,' this is a general suggestion without specific details on how to achieve it. Therefore, the actionability is somewhat lacking as the reviewer identifies a weakness but doesn't provide concrete steps on how to address it.", "grounding_specificity_rationale": "The reviewer refers to 'generated images by proposed method' and 'realism of generated results.' This indicates some level of grounding as the reviewer is referring to the output of the proposed method. However, the reviewer does not explicitly identify a specific part of the generated images that is lacking realism (e.g., faces, backgrounds, specific object details). While the reviewer mentions 'realism,' they do not provide specific examples of what makes the results look less real. Therefore, the grounding is weak as the reviewer identifies the area of concern but lacks precise identification of the problematic aspect.", "verifiability_rationale": "The reviewer makes a claim that 'Quality of generated images by proposed method is limited' and 'the realism of generated results is limited.' This is a claim that requires verification. The reviewer provides a reason for this claim: 'While good continuous control is achieved, the realism of generated results showed in paper and supplemental material is limited.' This provides some logical reasoning and references external works (the paper and supplemental material). However, the reviewer does not explicitly cite specific examples or sections within the paper or supplemental material that demonstrate the limited realism. Therefore, the verifiability is somewhat lacking as the reviewer makes a claim and provides some justification, but the evidence is not fully explicit or detailed.", "helpfulness_rationale": "The reviewer points out a weakness in the generated images and suggests 'improving the realism of generated results.' This is a relevant critique that could help the authors. However, the reviewer does not specify *how* to improve the realism or target a specific aspect of the generated images in the paper. The suggestion is general and lacks concrete details. Therefore, the helpfulness is somewhat limited as the reviewer identifies a problem and offers a suggestion, but the suggestion is vague and lacks specific guidance on how to address the issue."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly points out a lack of clarity in how the graph G is constructed and requests specific details about its elements and dimensions. While they don't directly state 'I know the action but not how to implement it,' the request for size, elements, dimensions, and their relationships implies a need for precise action. The reviewer also asks for clarification on the DGCN model, which further necessitates concrete action from the authors.", "grounding_specificity_rationale": "The reviewer directly references 'Section 3.3' and asks for details about the graph G within that section. This clearly identifies the specific part of the paper they are referring to, making the grounding explicit. They also specify what information they need ('size and elements of G', 'dimensions of G,X, and W'), making the specificity high.", "verifiability_rationale": "The reviewer makes a claim by stating that the description of G is lacking and that adding the requested information will help the authors understand the DGCN model. This claim is supported by the reasoning that providing this information will clarify the methodology. While the request for clarification isn't a direct citation, it implies a need for justification, making the verifiability somewhat supported.", "helpfulness_rationale": "The reviewer directly points out a missing detail in the methodology, which is crucial for understanding and potentially improving the DGCN model. This is a clear and actionable feedback for the authors. While the request is specific, it's framed as a question for the authors, making it helpful in encouraging them to provide more information rather than simply criticizing the review's clarity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the statement 'This is not entirely true' is incorrect and provides a specific technical detail about the Cycle Consistency loss. The reviewer explains that the loss can iterate between two phases of reconstructions (ABA and BAB) with two separate standard backpropagation processes. This provides a clear action for the authors to take: they should revisit their understanding of the Cycle Consistency loss and how backpropagation is applied in this context. The reviewer's explanation is concrete, detailing the specific phases and the separate backpropagation processes.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Cycle Consistency loss' and further specifies the 'two phases of reconstructions (ABA and BAB)' and 'two separate standard backpropagation processes'. This demonstrates strong grounding as the reviewer accurately identifies the specific part of the paper being addressed and provides precise details about the issue. The use of specific terminology like 'ABA' and 'BAB' suggests a clear understanding of the relevant concepts within the Cycle Consistency loss framework.", "verifiability_rationale": "The reviewer makes a claim by stating that the statement 'This is not entirely true' is incorrect. The reviewer then provides a specific explanation and a concrete detail about the Cycle Consistency loss, including the two phases of reconstructions (ABA and BAB) and the use of two separate standard backpropagation processes. This evidence directly supports the claim and allows the authors to verify the accuracy of their understanding. The logical reasoning provided by the reviewer is clear and directly addresses the claim.", "helpfulness_rationale": "The reviewer's comment is 5 because it directly identifies a factual error in the authors' description of the Cycle Consistency loss. By pointing out the specific mechanism involving the two phases of reconstructions and the separate backpropagation processes, the reviewer provides the authors with concrete information to correct their understanding. This is a valuable piece of feedback that directly addresses a potential misunderstanding and guides the authors in improving their work."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states 'calling 'hyperspectral' is confusing.' This is an explicit action, as the reviewer identifies a potential issue. However, the review does not provide any concrete suggestions or actions for the authors to take to address this confusion. The action is simply 'to understand the confusion,' which is not a concrete action. Therefore, while the action is explicit, it is not concrete enough to be considered fully actionable.", "grounding_specificity_rationale": "The review point mentions 'hyperspectral' without specifying which part of the paper or figure this refers to. The grounding is weak because the authors cannot confidently determine which specific aspect is causing confusion. The comment also does not specify what needs to be addressed in this 'hyperspectral' context. The reviewer is making a general observation about the terminology without providing specific details about its usage or potential issues.", "verifiability_rationale": "The review point is a statement of observation: 'calling 'hyperspectral' is confusing.' This is a claim that needs to be supported. However, the review does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no evidence presented to justify why 'hyperspectral' is confusing. The claim is presented without sufficient backing.", "helpfulness_rationale": "The review point identifies a potential area of confusion for the reader ('hyperspectral'). However, it does not offer any specific suggestions or actions for the authors to take to address this confusion. The review is a diagnosis without a cure. It points out a problem but doesn't provide a solution or guidance on how to improve the clarity of the terminology."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides specific suggestions for improving the explanation of the 'energy' concept. They suggest a specific interpretation of 'energy' in Section 5.2 and ask for clarification on the 'peak' in Figure 5. These suggestions are concrete and directly address potential areas of confusion, making them actionable for the authors.", "grounding_specificity_rationale": "The reviewer explicitly mentions Section 5.2 when suggesting how 'energy' should be interpreted. They also directly refer to the 'peak' in Figure 5, indicating a clear understanding of the specific parts of the paper being discussed. This strong reference to specific sections and elements demonstrates high grounding specificity.", "verifiability_rationale": "The reviewer points out a potential area of confusion regarding the 'energy' concept and suggests a specific interpretation. While not a definitive claim requiring external evidence, it's a suggestion that could be further clarified or explained, making it 3 as a point that needs better justification or examples. The request to define the 'peak' in Figure 5 is a clear indication that the reviewer's understanding is not fully clear or that the explanation needs improvement.", "helpfulness_rationale": "The reviewer's suggestions directly address a potential point of confusion for the authors regarding the 'energy' concept and its application in Section 5.2. They also identify a missing element (the definition of 'peak' in Figure 5) that would improve the clarity of the paper. These suggestions are relevant and actionable, making them 5 for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The request is quite explicit: \"how each of them contributes to the final performance improvements\". It points to specific components (Linformer, window attention in BigBird) and the outcome (performance improvements). This clearly indicates an explicit action (identifying component contributions) and concrete details (specific components and their impact).", "grounding_specificity_rationale": "The reviewer doesn't explicitly name the components (Linformer, window attention in BigBird) but refers to \"the components\" generally. While the *outcome* is specific (\"performance improvements\"), the grounding of the components themselves is weak. The reviewer implies the existence of components but doesn't pinpoint them with certainty. The specificity of the request is also limited to the general outcome of performance improvements.", "verifiability_rationale": "The reviewer *states* they want to know how components contribute to performance. This constitutes a claim. However, the review point itself does not provide any evidence, reasoning, or external references to support this claim. The claim is presented as a request or expectation rather than a verifiable statement.", "helpfulness_rationale": "The reviewer clearly states their desire for information on how components contribute to performance. This directly addresses a common need for understanding the impact of different architectural choices or techniques in research. The information itself is valuable for authors, but the *helpfulness* depends on the clarity and depth of the provided information. The reviewer's request is a clear indication of a need for assistance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states what is missing ('grammar over kernels is not explained in any detail') and what should be done ('understand how this approach is applied in practice'). This directly points to an actionable item for the authors.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'grammar over kernels' as the specific part of the paper where details are missing. They also specify what is missing ('probabilities associated with the grammar that define a hypothesis space of kernels? How is inference performed?'). This strong identification of the specific part and the nature of the missing information indicates high grounding specificity.", "verifiability_rationale": "The reviewer implies a problem ('some of the details of the models are missing') and suggests improvements ('presumably there are also probabilities associated with the grammar that define a hypothesis space of kernels? How is inference performed?'). While the reviewer identifies the missing information and the desired information, they do not provide specific examples or external references to support their claims. The justification is present but could be stronger.", "helpfulness_rationale": "The reviewer provides specific examples of what is missing ('grammar over kernels is not explained in any detail') and directly suggests concrete improvements ('understand how this approach is applied in practice'). This actionable feedback is directly helpful for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the concern about the ablation study and provides specific evidence (Table 10) to support the claim that the perception module's effectiveness is unclear. The reviewer also points out the similar performance with and without the perception module, which is a concrete observation. While the reviewer doesn't directly propose an action, the information provided is sufficient for an author to investigate the missing details and the statistical significance of the results. The reviewer also asks about the implementation details of w/o perception, which is a concrete request for information.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"ablation study\", \"Table 10\", \"w/o perception module\", and discusses the *specific* results and their implications (similar performance, missing details, statistical significance). This indicates a clear understanding of the section and table being addressed. The reviewer also asks about the *specific* implementation details and the *specific* statistical significance, making the grounding very precise.", "verifiability_rationale": "The reviewer makes a clear claim about the similar performance in Table 10 and the unknown implementation details of the w/o perception module. This constitutes a claim. The reviewer provides evidence (similar performance) but lacks specific references to external works to support their claim about the implications of the sample size (1000 users) for statistical significance (p < 0.05). The reasoning is present but could be strengthened with statistical analysis.", "helpfulness_rationale": "The review point provides specific information about the missing details in the ablation study (Table 10) and raises a statistically relevant concern about the sample size. By pointing to the specific table and the specific comparison within that table, the reviewer helps the authors locate the relevant information. The reviewer's concern about the statistical significance is also a valuable piece of feedback that directly relates to the experimental results. While the reviewer doesn't explicitly ask for a solution, they highlight a concrete issue in the experimental setup that needs addressing."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that 'previous works on Lasso screening are not cited or compared' in the paper. This is a direct criticism of a specific claim made in the paper ('Transfer Lasso showed the best accuracy in feature screening'). The reviewer is also pointing out what needs to be done \u2013 adding citations and comparisons. This is an explicit and concrete criticism of the paper's presentation and analysis.", "grounding_specificity_rationale": "The review point explicitly mentions 'Transfer Lasso showed the best accuracy in feature screening' as the specific claim being criticized. It also names 'citations to relevant prior work on Lasso screening' as the area that needs improvement. The reviewer is not just saying ' somewhere in the paper', but is pinpointing the exact section and the specific issue. This is 5.", "verifiability_rationale": "The review point contains a claim that 'previous works on Lasso screening are not cited or compared'. This is a statement that could be verified by examining the paper's bibliography and related discussions. While the review point doesn't provide explicit verification (like specific examples or references), it identifies a potential gap that could be addressed. Therefore, it is verifiable but lacks explicit examples or references, making it somewhat incomplete in its verification. It is underspecific in that it doesn't point to a specific missing citation, but it does identify a general area for improvement.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper's presentation \u2013 the lack of context and comparison for the claim about Transfer Lasso's accuracy. The reviewer suggests a concrete improvement \u2013 adding citations to relevant prior work. This is a helpful comment because it points out a specific area where the paper could be improved, guiding the authors on what to do. The reviewer doesn't criticize the *accuracy* of Transfer Lasso, but rather the *presentation* of its accuracy in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that 'the model has many components whose hyper parameters are not fully provided.' This is an explicit statement about a missing piece of information. However, the action the reviewer implies is for the authors to go through the code and try to find and document the missing hyperparameters, which is not a direct, actionable instruction like 'change the learning rate'. Therefore, while the issue is clear, the specific action to take is somewhat vague.", "grounding_specificity_rationale": "The review point identifies a problem ('the model has many components whose hyper parameters are not fully provided'), but it does not specify which components or which hyper parameters are missing. The authors are left to infer the specific parts of the paper and the issues within them. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point makes a claim ('the model has many components whose hyper parameters are not fully provided') without providing any evidence or reasoning. There is no logical deduction, external reference, or common knowledge cited to support this statement. Therefore, the verifiability of this claim is low as it lacks justification.", "helpfulness_rationale": "The review point correctly identifies a weakness in the paper (lack of information about hyperparameters). However, it does not provide any specific guidance on how the authors should go about addressing this weakness. The authors would still need to search the codebase, create documentation, and potentially rerun experiments, which is not a fully comprehensive and impactful suggestion. Therefore, the helpfulness is limited as it does not fully empower the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states '3%p' as the improvement for CIFAR10. While the numerical value is given, the 'p' is not defined, making the exact nature of the improvement unclear. The reviewer identifies the improvement but doesn't specify the metric. This can be seen as an implicit action pointing to a numerical improvement, but the lack of clarity makes it less concrete. Therefore, it is 3 as the authors know the *what* (a 3% improvement), but not the *how* (what exactly changed to cause this).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'CIFAR10' as the dataset where the improvement is claimed. This clearly identifies the specific part of the paper being addressed. The reviewer also states the improvement as '3%p', which further specifies the metric and the amount of improvement. While the reviewer doesn't specify *what* is being improved (e.g., accuracy, loss), they do identify the *dataset* and the *numerical value*. Therefore, it is 3 as the authors can infer the dataset and the nature of the improvement (a numerical value).", "verifiability_rationale": "The reviewer states 'The notation for results is not clear. The paper claims the improvement for CIFAR10 is 3%p but it is not clear what %p stands for.' This is a claim about a lack of clarity in the paper's presentation. However, the reviewer does not provide any evidence or reasoning to support this claim. They are stating a problem but not providing any data or references to back it up. Therefore, it is 1 as there is X to verify.", "helpfulness_rationale": "The reviewer points out a lack of clarity in the notation for the results. While this identifies a potential issue, it does not directly suggest a concrete improvement or fix. The reviewer is highlighting a problem that needs to be addressed, but they are not providing a solution or actionable feedback on how to improve the clarity. Therefore, it is not helpful in terms of providing direct guidance to the authors on how to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests showing qualitative results and analyzing them, which implies an action (analyzing visualizations or detailed data). However, it doesn't explicitly state the *method* of analysis or how to implement this action. The reviewer is pointing towards a direction of improvement, but the specific steps are missing.", "grounding_specificity_rationale": "The review point is general and doesn't specify *where* the issue lies. It mentions 'qualitative results' and 'failure cases' without pinpointing a specific section, table, figure, or unique aspect of the paper. The reviewer is making a suggestion about a general improvement rather than addressing a specific problem.", "verifiability_rationale": "The review point contains a claim: 'It would be nice and inspiring to show some qualitative results, possibly with zoomedin view, for cases where previous methods failed but okay with the proposed method.' This claim is supported by the general understanding that qualitative analysis can reveal nuances and limitations that quantitative methods might miss. The suggestion is based on common practices and logical reasoning in research evaluation.", "helpfulness_rationale": "The review point is 5 as it directly addresses a potential limitation of relying solely on quantitative metrics. By suggesting the inclusion of qualitative results and analysis, it provides a concrete direction for improvement and encourages a more comprehensive evaluation process. This is a valuable suggestion for researchers looking to gain deeper insights."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential weakness in the title's clarity and suggests a direction for improvement. While the suggestion is relevant, it doesn't explicitly state an action the authors should take. The reviewer implies the action of clarifying the title, but this isn't a concrete instruction.", "grounding_specificity_rationale": "The reviewer identifies the potential ambiguity of the title and suggests focusing on 'machine comprehension' as a way to clarify it. This demonstrates an attempt to ground the feedback in a specific aspect of the paper. However, the suggestion itself is a general direction rather than a precise section or element of the paper.", "verifiability_rationale": "The reviewer offers a suggestion for improving the title but doesn't provide any evidence or justification for why this suggestion is beneficial or how it would be implemented. The comment is a recommendation without supporting reasoning or examples.", "helpfulness_rationale": "The reviewer identifies a potential area for improvement in the title (ambiguity) and offers a suggestion to clarify it. This directly addresses a potential weakness and provides a direction for improvement. While the suggestion isn't a definitive solution or a highly detailed recommendation, it's a relevant comment that could help the authors refine their work. The reviewer doesn't explicitly state a claim about what the title *should* be, but the suggestion itself is a relevant piece of feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the authors' claim and directly points out the errors in it. They identify the specific limitations of the CLT that make the authors' statement incorrect. This is an explicit and concrete criticism.", "grounding_specificity_rationale": "The reviewer provides a clear and specific reference to \"line 238\" in the authors' paper, indicating a precise location of the problematic statement. They also explicitly state the incorrectness of the claim, detailing the limitations of the CLT in the context of the authors' statement.", "verifiability_rationale": "The reviewer presents counterarguments and explanations as evidence for why the authors' claim is incorrect. They explain that the standard CLT applies to the *limit* of a sum of random variables, not a finite combination, and that asymptotic behavior is crucial for Gaussianity. This provides logical reasoning and a clear explanation.", "helpfulness_rationale": "The review clearly identifies a specific error in the authors' understanding of a key statistical concept (the CLT). The reviewer explains *why* the authors' statement is incorrect, providing valuable context for the authors to understand the limitations of the theorem. While the review doesn't offer a direct fix, it empowers the authors to reevaluate their claim and potentially correct it. The specificity of the critique makes it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the requirement to 'analyze the time complexity of the proposed policies mentioned in Section 4'. This is an explicit action that the authors can readily identify. However, the point lacks specific details on *which* policies are being referred to within Section 4, and it doesn't provide guidance on *how* to perform this analysis. Therefore, while the action is clearly stated, the lack of specificity makes it only partially actionable.", "grounding_specificity_rationale": "The review point states 'analyze the time complexity of the proposed policies mentioned in Section 4'. While it identifies the *area* of analysis (time complexity of policies), it fails to specify *which* policies are being referred to within Section 4. The reviewer does not provide a unique element or a clear reference point within the paper to ground the discussion. Therefore, the reviewer cannot confidently determine which part of the paper they are addressing, making the grounding weak.", "verifiability_rationale": "The review point is a request for analysis ('analyze the time complexity...') and does not contain a claim or judgment about the paper. Therefore, it doesn't require verification in the sense of supporting a statement with evidence. The presence of a request doesn't inherently lack verifiability in the sense of providing justification for a claim. However, since there's X being made, it's appropriate to mark this as 'X'.", "helpfulness_rationale": "The review point is relevant to the authors as it points to a practical concern regarding the efficiency of their proposed policies. The request to analyze time complexity is a valuable feedback point that can guide the authors in refining their algorithms. However, the lack of specificity in the request means the authors will not receive concrete guidance on how to perform this analysis. Therefore, the feedback is relevant but lacks actionable detail, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a desire for a rationale to understand why TSS was used. This implies an implicit action: to seek clarification or justification. However, the review point itself does not explicitly state the need for this clarification or provide any concrete steps to achieve it. The request is vague and lacks a clear direction.", "grounding_specificity_rationale": "The reviewer states they 'don\u2019t understand why...'. This implies they have identified a specific area of confusion related to the use of TSS. However, the statement is general and doesn't pinpoint the exact section, table, figure, or unique aspect of the paper that is causing the confusion. The grounding is present (they *identify* a problem), but it's not as precise as 'full grounding'. The specificity of the issue is also lacking, making it 'underspecific'.", "verifiability_rationale": "The reviewer makes a claim: 'I don\u2019t understand why...'. The verifiability of this claim depends on whether the reasoning, common knowledge, or external references supporting the use of TSS are provided. The review point itself does not contain any justification for the choice of TSS. Therefore, the claim is not supported by any evidence within the review point itself. The lack of justification makes it difficult to verify the reviewer's statement about the lack of a clear rationale.", "helpfulness_rationale": "The reviewer explicitly states a desire for a rationale to understand why TSS was used. This directly addresses a key aspect of improving the evaluation process and provides a clear direction for the authors to seek clarification. The request is specific about the missing element (rationale for TSS). Therefore, the reviewer's statement is a helpful prompt for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point states that 'the experiments succinctly prove the point that the authors try to make'. While this identifies a weakness in the experimental validation, it does not provide explicit or concrete instructions on how to improve the experiments. The suggestion to include experiments across 'more diverse domains' is vague and lacks specific details on how to achieve this. Therefore, the review point does not offer actionable feedback.", "grounding_specificity_rationale": "The review point mentions 'experiments' in general and suggests including experiments across 'more diverse domains'. It does not explicitly identify a specific part of the paper, such as a section, table, or figure, where the issue lies. While it implies the need to look at the experimental section, it doesn't specify which table or figure within that section. Therefore, the review point is 1 at all.", "verifiability_rationale": "The review point contains a clear claim: 'it would strengthen the paper to include experiments across more diverse domains (those in TDMPC 2)'. This claim is directly verifiable by the authors. They can identify the relevant section of the paper (the experiments) and consider the domains mentioned in TDMPC 2 to understand how to diversify their experiments. The suggestion is specific in terms of the *domain* and even provides a potential source of diversity. Therefore, the claim is fully supported by explicit, sufficient, and robust evidence.", "helpfulness_rationale": "The review point is 5 because it directly addresses a potential weakness in the experimental validation by suggesting a concrete improvement: including experiments across more diverse domains. The suggestion is specific enough to guide the authors in modifying their experimental setup and data sources. It is not vague or unhelpful, and it directly relates to the experimental section of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests improvements but does not specify how to implement them. While the reviewer implies including confidence intervals and more datasets, the exact steps or methodologies for doing so are not detailed. The suggestions are general and lack concrete action steps.", "grounding_specificity_rationale": "The reviewer does not explicitly identify a specific part of the paper being addressed. The criticism is about the evaluation methodology in general, without pinpointing a particular section, table, or figure. The mention of 'standard datasets' is a general observation, not a specific reference to a part of the paper.", "verifiability_rationale": "The review point makes claims about the limitations of the evaluation methodology (lack of statistical significance and limited dataset diversity) but does not provide explicit justification or references to support these claims. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that these are significant weaknesses.", "helpfulness_rationale": "The review point provides general feedback about the evaluation methodology but lacks specific suggestions or details on how to improve the draft based on these criticisms. While the reviewer's intention is helpful, the feedback is vague and does not offer concrete guidance on what changes are needed or how to approach them."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the missing evaluation. It directly points out what is not present in the paper. The action is to evaluate the interpretability tax, which is clear and actionable.", "grounding_specificity_rationale": "The comment refers to 'the interpretability tax associated with the method.' While it doesn't explicitly name a section, table, or figure, it clearly identifies the concept being evaluated as being related to the method. This can be considered weak grounding as the authors can infer the location is within the method description. The specificity is about the 'magnitude,' which is a general concept and less specific than pointing to a particular detail.", "verifiability_rationale": "The comment contains a claim: 'The paper does not evaluate the magnitude of interpretability tax associated with the method.' This claim requires verification. The verifiability lies in the fact that this is a factual statement about the paper's content. While it doesn't provide specific examples or references, the claim itself is verifiable by checking the paper's sections related to the method and its evaluation.", "helpfulness_rationale": "The comment identifies a missing evaluation, which is a valid point for improvement. It provides a clear direction for the authors to look within their paper. While it doesn't specify *where* the evaluation is lacking, it highlights a potential area for clarification or improvement in the authors' understanding or presentation of their method's interpretability. It's helpful because it points to a concrete area for further investigation or discussion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out a *specific* issue: the lack of clarity in the LUQ design process. It suggests a *potential* improvement: focusing on a clear goal and then applying standard techniques. While it identifies a problem, it doesn't tell the author *how* to address it. The suggestion is vague.", "grounding_specificity_rationale": "The review explicitly mentions \"Sec. 5\" when discussing the LUQ design, which indicates a clear identification of the specific part of the paper being addressed. However, the explanation of why the LUQ design is straightforward and why the approaches are standard lacks specific details. The comment specifies what needs to be addressed (the design process) but doesn't provide concrete examples or references within that section.", "verifiability_rationale": "The review makes claims about the LUQ design being 'straightforward' and the approaches being 'standard'. While it identifies a section (Sec. 5), it doesn't provide any logical reasoning, common knowledge, or external references to support these claims. The comment states an opinion about the nature of the techniques without providing evidence.", "helpfulness_rationale": "The review identifies a potential area for improvement ( streamlining the LUQ design process). However, it doesn't provide concrete steps or specific suggestions on *how* to achieve this. The reviewer's opinion about the straightforwardness and standard nature of the techniques might be seen as less helpful than a clear path forward. While it points to a problem, the lack of actionable advice reduces its helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their wish to see training losses, indicating an action. However, the request lacks specifics on *which* losses or *how* they should be calculated, making it less concrete.", "grounding_specificity_rationale": "The reviewer mentions specific terms like 'deep localization network' and 'differentiable Sinkhorn,' suggesting they are referring to a specific part of the paper. However, the request for losses is vague, making it only partially grounded.", "verifiability_rationale": "The review point is a request for information, not a claim that needs verification.", "helpfulness_rationale": "The reviewer explicitly states their desire for training losses, which is a clear and actionable need for someone implementing or understanding a method. This directly contributes to the authors' ability to improve their draft by providing empirical evidence."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue (overclaiming) and provides some context, but lacks specific details on *which* part of the theoretical analysis is overclaimed. Authors can infer that the authors' theoretical analysis might benefit from a clearer articulation of the connections between the different aspects, but the review point itself doesn't directly instruct them on *what* to do with a specific section or figure.", "grounding_specificity_rationale": "The reviewer doesn't explicitly state which part of the paper they are referring to. They are making a general critique of the theoretical analysis.", "verifiability_rationale": "The reviewer states a claim: \"the paper overclaims the strength of the proposed BC loss in theoretical analysis.\" However, the reviewer argues that the different aspects (geometric interpretability, Theorem 1, high/low entropy representations, hardnegative mining) are essentially the same underlying concept. While the reviewer presents an argument, they do not provide specific evidence or references to support this claim of redundancy. They are making an assertion about the potential overclaiming without concrete examples or citations.", "helpfulness_rationale": "The reviewer's assessment of the score is that the comment is \"potentially valuable\" but \"not entirely convincing.\" While the reviewer identifies a potential issue in the presentation, they do not offer specific, actionable steps for the authors to take. They suggest *what* might be overclaimed, but not *how* to address it. The feedback is relevant but lacks the specific guidance needed for immediate action by the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer suggests that automatic scores may be less relevant to the authors' motivations in the abstract section and proposes alternative evaluation methods. While the reviewer offers a suggestion, the review point itself doesn't explicitly state an action or concrete improvement the authors should take based on this suggestion. The reviewer's point is more of a critique and a potential alternative rather than a direct instruction on how to improve the draft.", "grounding_specificity_rationale": "The reviewer mentions the 'abstract section' and 'automatic scores' in the review point. While these are specific parts of the paper and evaluation methods, the reviewer's core criticism is about the *effectiveness* and *affordability* of these scores, rather than pinpointing a specific issue within a specific part of the paper that needs addressing. The criticism is more general about the type of scores being considered.", "verifiability_rationale": "The review point primarily expresses an opinion about the limitations of automatic scores and the applicability of arenabased evaluation systems. It does not contain a claim that requires verification or justification. The reviewer states their belief about the ineffectiveness and cost but doesn't provide specific examples or references to support this claim within the review point itself.", "helpfulness_rationale": "The reviewer's comment is a critique of the proposed method (automatic scores) and the applicability of arenabased evaluation systems to single dialogue system evaluation. This directly impacts the authors' ability to understand and improve their work based on these methods. The reviewer's point is not a constructive suggestion or a critique that provides actionable feedback on the authors' work, but rather a negative assessment of the proposed evaluation approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the technical detail about RegMixup seeing 2x samples per iteration and its impact on running speed. It also points out the potential unfairness in comparison with other methods. This provides a clear action for the authors to consider or investigate further.", "grounding_specificity_rationale": "The review point explicitly mentions 'RegMixup' and its behavior of seeing '2x samples per iteration'. This is a literal mention and a precise identification of the method and its specific characteristic. It also specifies the consequence of this behavior, which is the 'slow running speed'.", "verifiability_rationale": "The review point makes a claim about RegMixup's behavior and its impact on speed. It provides a logical reasoning by linking the increased sample size to the slower running speed. It also refers to the authors' claim of 1.5x slower, suggesting the reviewer has observed this themselves, providing external verification through direct observation of the authors' results.", "helpfulness_rationale": "The review point is highly specific about a potential issue with RegMixup's implementation and its impact on performance. It highlights a potential unfairness in comparison with other methods. This is a valuable piece of feedback that directly addresses a technical aspect of the method and encourages the authors to consider alternative approaches or provide more context about their specific implementation of RegMixup."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly points out a potential ambiguity in the notation t_R^m and suggests a concrete action: defining t_R^m. This is a clear and direct instruction for the author, making the action explicit. The reviewer also implies that this definition is necessary by stating 'It is used subsequently and it's meaning is unclear', which guides the author on how to apply the action. The action is also concrete, as the reviewer suggests a specific task (defining t_R^m) rather than leaving it openended.", "grounding_specificity_rationale": "The reviewer explicitly refers to t_R^m and its usage in the subsequent equation. While they don't provide a specific section number, the context strongly implies they are referring to the equation mentioned in the previous sentence. The reviewer also clearly specifies the ambiguity of the superscript (m vs. m1), making the grounding quite precise. The specificity is high as the reviewer directly addresses the ambiguity and requests a definition for t_R^m.", "verifiability_rationale": "The reviewer does not make a claim in the traditional sense of stating an opinion or judgment. However, they suggest a course of action: 'please define t_R^m'. While this is a helpful suggestion, the reviewer does not provide any justification or reasoning for why this definition is necessary or how it should be done. There are no external references or logical reasoning provided to support this suggestion. Therefore, while the reviewer's point is helpful, it is not 5 as it lacks supporting evidence or justification.", "helpfulness_rationale": "The reviewer identifies a potential point of confusion for the author regarding the notation t_R^m and its usage. They suggest a concrete improvement: defining t_R^m. This directly addresses a weakness in the paper and provides a clear direction for the author to take. The suggestion is actionable and directly related to improving the clarity and understanding of the paper. Therefore, the review point is helpful in guiding the author towards a specific improvement."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem: 'This paper gives me a feeling that the authors only want to have a unified form, but didn't consider the difference between the classification and regression tasks.' This is a direct criticism of the authors' approach. The reviewer also points out the potential issue: 'lower gradients for easy samples may cause inaccurate problem' in the context of regression. While the reviewer doesn't explicitly state the action, the criticism implies a desire for the authors to address the difference between classification and regression. The reviewer's point is clear and directly related to the use of focal loss in regression.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'focal loss is used in regression tasks' and then focuses on the IoU regression. This clearly identifies the specific part of the paper being addressed. The reviewer also mentions 'class imbalance problem' (classification) and 'accurate problem' (regression), which further clarifies the distinction. The reviewer's comment is grounded in the specific task and also draws a parallel to a different task (classification), indicating a clear understanding of the relevant parts. The grounding is strong as the reviewer doesn't just mention 'regression' but specifies 'focal loss in regression tasks' and then narrows it down to IoU regression.", "verifiability_rationale": "The reviewer makes a claim: 'lower gradients for easy samples may cause inaccurate problem' in the context of IoU regression. The reviewer provides a justification based on their understanding of focal loss and its behavior in regression. While they don't provide specific citations, the reasoning is logical and based on common knowledge of focal loss and its properties. The claim is supported by a clear explanation of why it might be a problem in regression. The reasoning is logical and based on common knowledge of focal loss and its properties.", "helpfulness_rationale": "The reviewer's point is relevant to the use of focal loss, a common technique. They highlight a potential issue (inaccurate gradients) that could affect the results. By pointing out the difference between classification and regression, they offer a valuable perspective on potential limitations. While it might not be a *complete* solution, it's a *valid* observation that could guide the authors. The reviewer's comment is helpful in identifying a potential area for improvement and highlights a difference between classification and regression tasks, which is a valuable insight for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "Not Verifiable", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point is a question, implying a desire for information about the method's scaling behavior. While it suggests an action (answering the question), it doesn't explicitly state what needs to be done. The action is implied but not clearly defined. The action, if inferred, is also vague, as it doesn't specify how the scaling is measured or what conclusions can be drawn. Therefore, it is 2 as it implies an action but is vague on how to apply it.", "grounding_specificity_rationale": "The review point is a general question about the method's scaling as corpus size or hidden dimension size increases. It does not specify which part of the paper or method it is referring to. There is no mention of a specific section, table, figure, or unique aspect of the paper. Therefore, the grounding is weak, as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point is a question, not a statement of a claim that needs verification. It does not present an opinion, judgment, or suggestion about the paper or the method. Therefore, it does not contain a claim that can be supported or verified. The comment is not verifiable because it doesn't present a claim that can be justified.", "helpfulness_rationale": "The review point is a question about the method's scaling behavior. While this information might be useful for the authors to understand the method's limitations, it does not directly provide actionable feedback on how to improve the paper's content. It's about the method's characteristics, not the paper's weaknesses. Therefore, it is not inherently helpful in the sense of directly improving the paper's content."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states they want the authors to 'verify' the statistical significance of the improvement. This is a clear and direct action. However, the reviewer does not specify *how* to perform this verification, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'the improvements of the proposed model over the RL without feedback model' and specifically points to 'row3 vs. row4 in table 6'. This indicates an attempt to identify the specific part of the paper being addressed. However, without knowing the content of Table 6, the grounding is somewhat weak as the authors might not be able to pinpoint the exact section or table. The reviewer also doesn't explicitly name a section or table, making the grounding weak. While the reviewer specifies the *type* of improvement (statistical significance of BLEU1) and the *models* being compared, this adds some specificity to the grounding.", "verifiability_rationale": "The reviewer makes a claim that the improvement is 'not so high' and 'a bit worse for BLEU1'. This is a claim that requires justification. The reviewer then asks for 'verification', which implies a need for logical reasoning, common knowledge, or external references to support this claim. However, the reviewer does not provide any specific examples, references, or logical reasoning within the review point itself to justify the claim about the statistical significance. The request to 'verify' is a form of justification, but it's not a complete one.", "helpfulness_rationale": "The reviewer clearly states their desire for statistical verification. This is a direct and understandable request that addresses a potential weakness in the model's performance. The request is actionable and points towards a specific next step for the authors. The reviewer's desire for verification is a valuable piece of feedback that directly addresses a specific observation in the results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their intention to ask clarifying questions and analyze assumptions related to reducing the need to visit all ballaction pairs. While the reviewer doesn't provide a specific action or solution, the intent to address a specific aspect of the paper is clear. The reviewer is prompting the authors to consider a potential optimization, which is a direct request for action.", "grounding_specificity_rationale": "The reviewer refers to 'ballaction pairs' and asks about 'minimal assumptions' and the 'consequences of partial coverage'. While the core concept of ballaction pairs might be specific to the paper, the reviewer does attempt to ground the question by referencing a previous remark and asking about specific aspects of the algorithm's behavior. However, the reviewer does not explicitly identify a specific section, table, or figure being addressed. The questions are about the *what* and *how* of a potential optimization, rather than a specific detail within a known part of the paper.", "verifiability_rationale": "The reviewer is *asking a question* rather than making a claim. They are seeking information and analysis, not asserting something as true or false. Therefore, verifiability, which involves supporting a claim with evidence, is not directly applicable to the review point itself. However, the reviewer's lack of clarity on the algorithm's specifics might imply that the original paper lacked sufficient detail to understand the 'ballaction pairs' concept clearly.", "helpfulness_rationale": "The reviewer's questions directly address a potential optimization of the algorithm, which is likely relevant to the authors. The questions are about the *minimal assumptions* needed and the *consequences of partial coverage*, prompting the authors to consider the implications of their approach. While the questions are general and don't offer specific solutions, they are focused and directly relevant to the potential improvement. The reviewer is seeking to understand the tradeoffs involved in the optimization strategy."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about a potential improvement using a better encoder. This constitutes an explicit action, as they are directly suggesting a change to the model. The suggestion is also concrete, as they propose a specific alternative model (RoBERTabase) and its potential impact on performance.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'BERT' and suggests considering a 'better encoder' like 'RoBERTabase'. This demonstrates strong grounding as they are directly identifying the specific aspect of the model being discussed. While they don't specify *how* the improvement would be observed, they clearly identify the area of interest (encoder choice).", "verifiability_rationale": "This review point is a question, not a statement containing a claim. Therefore, it does not have verifiability.", "helpfulness_rationale": "The reviewer directly asks a question that, if answered, could be very beneficial for the authors. They are specifically asking about the potential impact of a different model on their current results, which is a direct and actionable question."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests comparing the method to specific existing baselines (RefNeRF, MipNerf) for appearance decomposition and larger outdoor scenes. While the suggestion is clear about the *what* (comparing to specific methods), it lacks explicit instructions on the *how* of the comparison. The reviewer doesn't specify how the authors should analyze the results or what metrics to use. This makes the action somewhat implicit.", "grounding_specificity_rationale": "The reviewer explicitly names specific existing methods (RefNeRF, MipNerf) as potential baselines. This clearly identifies the specific part of the paper being addressed (the appearance decomposition and larger outdoor scene evaluations). The grounding is strong because the specific methods are named. The specificity of the suggestion is also good as it points to concrete areas for comparison.", "verifiability_rationale": "The reviewer makes a claim: 'Especially to evaluate the appearance decomposition part, it would be good to compare to other existing methods, as an example RefNeRF would be a good baseline that contains appearance decomposition. For the larger outdoor scene, MipNerf would be a good baseline.' This claim is verifiable as the reviewer provides specific examples of existing methods (RefNeRF and MipNerf) that are relevant to the areas mentioned (appearance decomposition and larger outdoor scenes). The evidence is direct and points to established techniques.", "helpfulness_rationale": "The reviewer suggests comparing the method to specific existing baselines (RefNeRF, MipNerf) for appearance decomposition and larger outdoor scenes. This is a relevant suggestion as it points to areas where the method could be evaluated against established techniques. By suggesting these comparisons, the reviewer is implicitly asking the authors to consider alternative approaches and potentially strengthen their work by including a wider range of evaluations. This provides a valuable direction for the authors to improve their work by identifying potential limitations or areas for improvement in existing methods. The reviewer is directly addressing potential weaknesses in the evaluation of appearance decomposition and larger outdoor scenes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a concern about the impact on predictive model performance but does not explicitly propose a solution or action to address it. The concern is presented as a point for discussion rather than a direct action.", "grounding_specificity_rationale": "The reviewer mentions 'severely damaging the performance of predictive model' but does not specify which part of the paper this refers to. The reference is general and lacks precision, indicating weak grounding. The specificity of the concern is also unclear as it's a statement about a potential negative impact rather than a specific issue with a defined section or element.", "verifiability_rationale": "The reviewer makes a claim about the paper's approach ('severely damaging the performance of predictive model') but does not provide any specific evidence or references to support this claim within the review point itself. The claim is presented without sufficient justification or backing.", "helpfulness_rationale": "The reviewer offers a suggestion to show how to achieve fair policy learning without severely damaging the predictive model's performance. This is a constructive comment that highlights a potential area for improvement in the paper's presentation and justification. It encourages the authors to be more precise about the tradeoffs involved."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a problem ('lack of implementation details') and suggests a solution ('They should have been described in the implementation details in Section 4.1'). While the suggestion is concrete, the reviewer doesn't specify *what* aspects of the implementation are lacking, making the action implicit rather than explicit. The action is also vague as it doesn't detail how the implementation details should be added.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 4.1' as the location for the missing implementation details. This clearly identifies the specific part of the paper being addressed, making the grounding fully grounded. However, the reviewer does not specify which specific elements within Section 4.1 are lacking, making the specificity underspecific.", "verifiability_rationale": "The review point states a problem ('lack of implementation details') and offers a solution ('They should have been described in the implementation details in Section 4.1'). The claim that there is a lack of implementation details is verifiable, as it points to a specific location in the paper. However, the claim lacks specific examples or references to justify the need for these details, making it underspecific.", "helpfulness_rationale": "The review point directly addresses a significant issue (lack of implementation details) and offers a concrete solution (adding these details in Section 4.1). This directly helps the authors by providing a clear direction for where to add the missing information. While the exact nature of the missing details isn't specified, the suggestion is actionable and directly addresses a potential bottleneck for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the absence of empirical evaluation and the lack of comparison with other methods. This directly points to a missing action for the authors: to provide empirical evidence and comparisons. The action is stated clearly, making it explicit. The reviewer also identifies the *type* of action, which is to perform empirical evaluation, making it concrete. Therefore, the reviewer provides a clear and actionable feedback.", "grounding_specificity_rationale": "The reviewer points out the *lack* of empirical evaluation. While the authors can identify the missing aspect (empirical evaluation), they cannot confidently pinpoint *where* within the evaluation process this is lacking (e.g., specific datasets, metrics, or baseline comparisons). The reviewer also mentions 'comparison (except for on an abstract level) with other methods,' which the authors can identify, but they don't know *how* to perform this comparison. Therefore, the grounding is weak as the authors can't fully identify the missing element or the specific type of comparison needed.", "verifiability_rationale": "The reviewer makes a claim that the authors should provide empirical evaluation and a comparison with other methods. This is a clear claim. However, the reviewer does not provide a strong justification for why this is necessary or how it would improve the work. The justification is at a high level, stating the lack of practical value and the need for the authors to 'argue for why it matters.' While the reasoning is logical, it lacks specific references or examples to support the claim. Therefore, the claim is somewhat justified, making it partially verifiable.", "helpfulness_rationale": "The reviewer's comment directly addresses the lack of empirical evaluation and practical value for the theoretical contribution. They clearly state that the authors should provide this information. While the reviewer doesn't explain *why* this is important or provide *examples* of how it would help, the action itself (providing empirical evaluation and comparisons) is clear and actionable. Therefore, the reviewer provides 3 feedback, as the authors can understand the direction they should take, even if the reasoning is lacking."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential ambiguity in notation, which, while not explicitly stating *how* to fix it, points to a clear area for improvement. The lack of clarity makes it 3, but not as strongly as if they had said 'You should change all Ps to Fs in the appendix'.", "grounding_specificity_rationale": "The reviewer directly points to the *notation* used in the *Appendix* (L44, and equations 3 & 4). This is quite specific. They mention \"Appendix\" and specific line numbers and equations, showing a clear understanding of where the issue lies. The reviewer clearly states the *problem* is the dual use of 'P'. This is very specific to the identified issue.", "verifiability_rationale": "The reviewer makes a claim about a problem in the manuscript. They provide specific locations to support this claim (Appendix, L44, and equations 3 & 4). While they don't explicitly *cite* a source for the standard notation, the common understanding of 'P' for probability is generally accepted, making it 3. The reviewer also identifies the *problem* as the dual use of 'P', which is very specific.", "helpfulness_rationale": "The reviewer clearly states the *problem* and suggests a *specific solution*. This is very helpful for the authors as it directly addresses a potential source of confusion and provides a clear direction for improvement. The reviewer suggests \"Use 'F' for CDF and 'P' for probability.\" This is a concrete and actionable suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a lack of understanding within the community about the use of artificial patterns versus natural spurious correlations. While they don't explicitly state what the authors *should* do, they highlight a crucial distinction and a potential gap in knowledge. The reviewer provides an example of how artificial patterns are often duplicated, further clarifying the difference. This sets up a concrete scenario for the authors to consider and potentially address in their future work.", "grounding_specificity_rationale": "The reviewer identifies a lack of clarity regarding the type of spurious correlations being used in the community's research. They differentiate between 'natural spurious correlations' and 'artificial patterns,' which helps the authors understand the specific issue being discussed. However, they do not explicitly name a specific section, table, or figure in the paper where this distinction is made, nor do they provide a unique element to pinpoint the issue.", "verifiability_rationale": "The reviewer makes a claim about the community's understanding of how neural networks learn natural rare spurious correlations and criticizes the use of artificial patterns. They provide an example to support their claim, stating that 'duplicating the same artificial pattern for multiple times is different from natural spurious features, which are complex and different in every example.' This example, while not a direct citation, offers a basis for the authors to verify the distinction and potentially explore research using natural spurious correlations.", "helpfulness_rationale": "The reviewer's point is highly relevant and potentially helpful for the authors. By highlighting the difference between artificial and natural spurious correlations, they draw attention to a potential limitation in the community's understanding and research practices. This could guide authors towards more realistic and insightful research directions. While the reviewer doesn't provide a complete solution or specific steps, they offer a valuable insight that can inform their work and potentially lead to more meaningful contributions."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a *limitation* of the paper's method and suggests a *related concept* (PRMRL). This suggests a potential action. The reviewer explicitly states a *limitation* ('the paper is limited in navigation problems') and suggests a *related area* ('PRMRL'). This is explicit.", "grounding_specificity_rationale": "The reviewer refers to \"navigation problems\" and \"PRMRL\". While they mention a specific area, the connection isn't explicitly stated as *precisely* as the paper's title or main idea. The authors cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part (combining RL and planning).", "verifiability_rationale": "The reviewer makes a claim that combining RL and planning has been discussed in PRMRL and provides a citation as evidence. The comment explicitly mentions which part of the paper it addresses (PRMRL) and it is obvious to the authors. The comment specifies what needs to be addressed in this part (combining RL and planning). The claim is supported by a reference.", "helpfulness_rationale": "The reviewer identifies a limitation in the paper's scope and suggests a relevant area for future work (combining RL and planning). This is helpful for the authors as it highlights a potential extension and encourages them to consider a broader applicability of their work. The reviewer's comment provides clear and actionable feedback on weaknesses and areas for improvement, though it could be expanded or refined to be fully comprehensive and impactful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a potential issue ('are all feature spaces wellsuited for 1NN?') and suggests a solution ('If a feature space is not close to a spherical Gaussian, it may perform poorly. If feature dimensions are individually standardized, it would avoid this issue.'). This indicates a clear action to be taken.", "grounding_specificity_rationale": "The comment directly references a specific line in the paper ('line 213') and then elaborates on the issue ('are all feature spaces wellsuited for 1NN?') and the suggested solution ('If feature dimensions are individually standardized, it would avoid this issue.') within the context of that line, indicating strong grounding and specificity.", "verifiability_rationale": "The comment poses a question ('are all feature spaces wellsuited for 1NN?') which is a claim. While it offers a potential solution ('If feature dimensions are individually standardized, it would avoid this issue.'), this solution is more of a suggestion than a direct verification of the claim itself. The reviewer doesn't provide specific examples or references to back up the claim that 'all feature spaces' are unsuitable for 1NN.", "helpfulness_rationale": "The review points out a relevant limitation of 1NN and provides a practical suggestion to improve its performance by standardizing feature dimensions. This actionable feedback is directly relevant to authors using 1NN and dealing with feature spaces, making it helpful for their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the 'contrastive gap' has never been defined clearly and even suggests a 'clear, formal definition' as the desired outcome. This directly identifies an actionable issue with the lack of a definition.", "grounding_specificity_rationale": "The reviewer identifies the specific issue as 'the contrastive gap' and explicitly states that this concept lacks a 'clear, formal definition.' This demonstrates strong grounding specificity as the reviewer not only identifies the area being discussed but also precisely states the deficiency within that area.", "verifiability_rationale": "The reviewer makes a claim that the 'contrastive gap' lacks a 'clear, formal definition.' This claim can be verified by examining the work for the presence or absence of such a definition. While specific references might not be provided, the claim itself is logically sound and points to a potential area for improvement in the work.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'a clear, formal definition.' This is a 5 suggestion for the authors. The reviewer doesn't just point out a problem; they offer a concrete next step. The suggestion is specific enough to guide the authors in improving their work. The reviewer's statement directly translates into a concrete action for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides two explicit suggestions: 'Correct the inaccurate statement on line 143' and 'Clarify the action space definition on line 154'. These are direct actions that the authors can take to improve their draft.", "grounding_specificity_rationale": "The reviewer points out an inaccurate statement on line 143 ('Then the state changes and environment gives a reward'). This is a clear grounding as the authors can identify the specific line and the factual error. However, on line 154, the reviewer states 'it's not clear if each action is a single feature or the power set'. While the topic is clear, the authors need to infer the specific details of the action space definition, making the grounding weaker. The reviewer's comment is 1 at the specific level of the action space definition, but it is grounded at the level of the factual error.", "verifiability_rationale": "The reviewer makes a claim on line 143: 'This is not true of standard MDP formulations.' This claim can be verified by checking standard MDP definitions. However, the reviewer does not provide specific references to support this claim, making it somewhat borderline. Similarly, on line 154, the reviewer states 'it's not clear if each action is a single feature or the power set'. This is a claim that can be verified by examining the surrounding text, but the reviewer does not provide specific references, making it somewhat borderline.", "helpfulness_rationale": "The reviewer's comment on line 143 directly points out a factual error in the description of MDPs, which could lead to confusion for readers. This is a helpful suggestion. The reviewer's comment on line 154, suggesting clarification of the action space definition, is also helpful as it directly addresses a potential point of confusion for readers trying to understand the MDP formulation. Both points offer concrete feedback that the authors can directly implement to improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies the phrase 'a response candidate can meet each utterace' as unclear. While the reviewer points out a potential area for improvement, the action taken is to identify the ambiguity rather than explicitly state an action or suggest a concrete change. The reviewer infers the need for clarification but doesn't provide specific steps on how to address the ambiguity.", "grounding_specificity_rationale": "The reviewer points to the phrase 'a response candidate can meet each utterace' on line 280 as the area of concern. While the reviewer doesn't explicitly state the line number, they clearly reference a specific part of the paper. The comment specifies what needs to be addressed \u2013 the clarity of the phrase. However, the reviewer doesn't identify a *unique* element within that phrase as being unclear (e.g., a specific word or phrase).", "verifiability_rationale": "The reviewer makes a claim that the phrase 'a response candidate can meet each utterace' is difficult to understand. This is a clear claim. However, the reviewer does not provide any external references, logical reasoning, or examples to support this claim. The justification for why the phrase is unclear is missing.", "helpfulness_rationale": "The reviewer identifies a potential point of confusion for the authors by pointing out the unclear phrase. This provides the authors with a signal that something might be unclear. However, the feedback is somewhat vague as the reviewer doesn't specify *what* is unclear or suggest *how* to improve the phrase. The helpfulness is limited because the feedback lacks concrete guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the inconsistency in naming conventions between L_task and L_class. While it doesn't directly suggest an action, the reviewer points to a potential area for clarification or consistency checking, which can be considered an implicit action. The specificity of the action is high as it targets a specific aspect of the loss function.", "grounding_specificity_rationale": "The review point refers to L_task and L_class without explicitly stating which section, table, figure, or unique aspect of the paper they correspond to. While it implies they relate to the text description of the task loss and the figure depicting a class loss, respectively, the grounding is not fully explicit. The specificity of the grounding is moderate as it identifies a potential issue in the naming but doesn't pinpoint the exact location.", "verifiability_rationale": "The review point makes a claim about an inconsistency in naming conventions. It is 3 because it points out a factual discrepancy. However, it does not provide any justification or reasoning for why this inconsistency exists or what its implications might be. The evidence provided is limited to the observation of the different names used for the same concept. The lack of further explanation or references makes it 3.", "helpfulness_rationale": "The review point identifies a potential source of confusion for the authors regarding the naming conventions of loss functions. While it doesn't explicitly suggest an action, it highlights a potential area for clarification or consistency checking. The helpfulness is moderate as it points out a potential improvement that could enhance the authors' understanding of the paper. The actionable aspect is implicit rather than explicit."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly asks for other limitations of the method and specifically questions if the network was 'pretty shallow' in the graph case, implying a direct action: to consider and potentially address this limitation. The language is clear and points towards a concrete improvement.", "grounding_specificity_rationale": "The review point mentions 'graph case' and 'network was pretty shallow'. While it identifies the context (graph case) and the specific aspect of the network (depth), it doesn't explicitly state which part of the network is being referred to (e.g., the neural network layer, the network architecture). The connection between the general question and the specific aspect of the network requires some inference on the part of the authors.", "verifiability_rationale": "The review point is a question: 'What are other limitations of the method? in the graph case the network was pretty shallow, is this the case here?'. It does not contain a claim that needs to be verified using logical reasoning, common knowledge, or external references. It's a request for information rather than a statement that requires justification.", "helpfulness_rationale": "The review point is a question prompting the authors to consider limitations and the depth of the network in the graph case. While it encourages critical thinking, it doesn't directly identify specific weaknesses or provide actionable suggestions on how to address them. It's more of a suggestion for selfreflection than a direct critique that would be 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out that the evaluation methodology is vague and lacks specific guidance. While the reviewer doesn't offer a direct actionable suggestion, the need for clarification in the evaluation itself can be seen as an implicit action for the authors to take. They need to clarify what aspects of their method are being evaluated and how.", "grounding_specificity_rationale": "The reviewer's suggestion of evaluating the method in machine translation indicates a desire for more specific grounding in a welldefined task. The current evaluation seems to be broad and not focused on specific, wellestablished tasks. The reviewer's point about the evaluation being 'close to open domain' suggests a lack of specific grounding in established benchmarks or tasks.", "verifiability_rationale": "The reviewer criticizes the evaluation for being 'close to open domain' and lacking concrete examples. This suggests a lack of verifiability, as the claims made about the proposed method are not wellsupported by evidence or examples. The reviewer's suggestion of machine translation implies a need for more robust verification through established benchmarks.", "helpfulness_rationale": "The reviewer's main point is that the evaluation methodology is vague and lacks specific guidance. The criticism about the evaluation being 'close to open domain' and the suggestion of machine translation highlight the lack of concrete examples and actionable feedback for the authors. The reviewer doesn't offer a specific actionable suggestion, making the review unhelpful in terms of providing direct improvement guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks for specific values (dropping rate and number of masks) related to the dropout mechanism. While the questions are specific about the *values*, the *action* of asking for these values is implicit in the paper's description of the dropout mechanism. The reviewer is not explicitly stating an action they plan to take, but rather asking for information that should be present to understand the mechanism.", "grounding_specificity_rationale": "The reviewer asks specific questions about the dropping rate and number of masks. However, without access to the paper, the authors cannot determine the *grounding* of these parameters. They don't know if the paper mentions a specific dropping rate or a general concept of dropout with multiple masks. The questions themselves are grounded in the reviewer's understanding of the method, but the paper's content regarding these specific parameters is unknown to the authors.", "verifiability_rationale": "The reviewer is not making a declarative statement or claim. They are posing a question about the implementation details of the dropout mechanism. Therefore, there is X to verify, and the verifiability aspect is not applicable to this review point.", "helpfulness_rationale": "The reviewer's question is directly related to understanding a specific implementation detail (dropout mechanism) of their own paper. This can be helpful for the authors to clarify their own understanding, potentially leading to improvements in their method or future work based on it. However, without the paper, the authors cannot provide a helpful answer, limiting its overall usefulness."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitations of the current evaluation and the need for further justification of the twostage approach. They mention 'Only showing the performance drop on fusion models is not enough' and 'Comparisons with other singlestage attacks are also needed'. These are explicit statements about what is missing and how it should be addressed. The reviewer is not inferring these actions but directly pointing out the gaps.", "grounding_specificity_rationale": "The reviewer refers to the 'twostage optimization approach' and the 'performance drop on fusion models', which are specific parts of the paper. They also specify what is missing: 'comparisons with other singlestage attacks'. The reviewer is not just mentioning general areas but pinpointing the exact aspects of the paper that require improvement. They are also providing details about what needs to be addressed.", "verifiability_rationale": "The reviewer makes a claim: 'Only showing the performance drop on fusion models is not enough' and 'Comparisons with other singlestage attacks are also needed'. This is a claim that needs to be supported. However, the reviewer does not provide specific examples of where the singlestage attacks fail or external references to support the superiority of the twostage approach in this specific context. The reasoning is present, but the supporting evidence is lacking.", "helpfulness_rationale": "The reviewer raises specific and actionable concerns about the evaluation methodology. They clearly identify the limitations of the current approach and suggest concrete improvements (comparisons with other singlestage attacks). This critique directly addresses the justification and validation of the proposed method, which is a crucial aspect of any technical contribution. The reviewer's points are clear and directly target the core claims of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states the missing information (lack of GPU type and inference time), making it 3 in that the author would need to contact the authors to obtain this information. However, the action of *contacting* is implicit rather than explicit.", "grounding_specificity_rationale": "The comment refers to 'this paper' generally, without pinpointing a specific section, table, figure, or any other concrete element. The issue is about the testing process in general, not a specific result.", "verifiability_rationale": "The comment claims that the paper lacks information on GPU type and inference time during testing. However, it does not provide any evidence or justification for this claim within the review point itself.", "helpfulness_rationale": "The comment identifies a valid weakness in the paper (lack of specific testing details). It encourages the author to seek this information, which is generally useful. However, it doesn't explicitly guide the author on *where* to find this information (e.g., suggesting a specific section or contact)."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "3", "actionability_rationale": "Part 1 of the review point is not actionable as it's a question about the significance of certain parts. Parts 2 and 3 are explicit actions pointing out notational issues.", "grounding_specificity_rationale": "Part 1 of the review point is 1 as the reviewer is making a general observation. Part 2 is weakly grounded as the reviewer refers to a specific equation but doesn't explicitly point to a section or table. Part 3 is fully grounded as the reviewer explicitly points to a specific element in an equation.", "verifiability_rationale": "Part 1 of the review point is 1 as it's a statement about an observed trend without providing evidence. Part 2 is 3 as the notational issue can be verified by checking the paper's notation. Part 3 is also 3 for the same reason.", "helpfulness_rationale": "Part 1 of the review point is not 5 as it's a question about significance, not a direct suggestion for improvement. Parts 2 and 3 are 3 as they point out specific issues that could help the authors understand the method better."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image, implying that the current connections are incorrect or misleading. This indicates a direct action the authors should take: 'Correct the connections in Figure 2 to accurately represent the flow of information or the impact of the inpainting process.' The reviewer provides a clear and actionable suggestion.", "grounding_specificity_rationale": "The reviewer directly points to the 'Perceptual Metric' in Figure 2, which is a specific and identifiable part of the paper. This demonstrates strong grounding as the reviewer can accurately pinpoint the section being addressed. The reviewer also explains *why* the connections are likely incorrect, providing further context and specificity.", "verifiability_rationale": "The reviewer's claim about the connections in Figure 2 is based on their understanding of how such figures typically represent information flow or impact. While they don't provide external references, the logical reasoning is based on standard interpretation. Therefore, it can be considered '3' as the verifiability relies on common knowledge within the field rather than explicit citations.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improving the clarity of Figure 2. This directly addresses a potential point of confusion for the authors and helps them understand the impact of the inpainting process. The suggestion is specific and directly related to the identified issue. Therefore, it is 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer states the sentence is confusing and provides a specific line number. This suggests a potential lack of clarity or explicitness. However, the reviewer does not explicitly state what the author should do to fix it. They identify a problem but don't detail the solution within the review itself.", "grounding_specificity_rationale": "The reviewer explicitly mentions the sentence 9395, indicating they have identified the specific part of the paper being addressed. However, the reviewer does not provide specific details about *what* is wrong with the sentence within this review point.", "verifiability_rationale": "The reviewer makes a claim that the sentence is confusing. This is a claim that requires justification. The reviewer offers their interpretation of *why* the sentence is confusing ('I believe I understood it after rereading it and the subsequent sentences but it is not immediately obvious what is meant.') as a potential explanation.", "helpfulness_rationale": "The reviewer's primary goal is to help the author understand and potentially resolve the confusion with the specific sentence. By pointing out this specific sentence, the reviewer is directly addressing a potential bottleneck in the author's understanding or implementation. This targeted feedback is likely to be more helpful than a general comment."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that previous work has tried to tackle... but with limited success (implicit action). They also state that diffusion models are more compute efficient (implicit action). While the reviewer identifies areas for improvement, the actions are not explicitly stated as concrete steps to take. For example, the reviewer doesn't specify *how* to improve the efficiency or *why* previous work has had limited success.", "grounding_specificity_rationale": "The reviewer mentions \"diffusion models have been able to outperform generative adversarial networks on image generation benchmarks\" (weak grounding, implicit action). They also mentions \"Previous work has tried to tackle... but with limited success\" (weak grounding, implicit action). Similarly, \"This improves the reliability and efficiency, because diffusion models are more compute efficient a training smaller dimensional latent variables and input tokens inherently have different lengths\" (weak grounding, implicit action). The reviewer identifies areas for improvement but doesn't explicitly point to specific sections or tables in the paper.", "verifiability_rationale": "The reviewer states \"diffusion models have been able to outperform generative adversarial networks on image generation benchmarks\" (claim), and provides a reason \"because diffusion models are more compute efficient a training smaller dimensional latent variables and input tokens inherently have different lengths\" (verifiable). However, the reviewer does not provide specific citations to support these claims.", "helpfulness_rationale": "The reviewer identifies areas for improvement in the paper (lines 129130 and 156158) and suggests that citing previous work and highlighting the efficiency of diffusion models are ways to improve the paper (lines 7879, 217218). While the reviewer provides suggestions, these suggestions are not concrete and actionable. For example, the reviewer doesn't specify *which* previous work to cite or *how* to highlight the efficiency of diffusion models."}
{"actionability_label": "4", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the inconsistency between Fig 1 and Fig 2. It identifies the specific detail: 'Fig 1 shows a single shared encoderdecoder for multiple tasks' and 'Fig 2 shows a single encoderdecoder per auxiliary task'. This provides a clear action for the authors to take: investigate and clarify the architectural difference.", "grounding_specificity_rationale": "The comment explicitly refers to 'Fig 1' and 'Fig 2', accurately identifying the specific parts of the paper being addressed. The comment also clearly specifies the difference in the number of encoderdecoders between the two figures. This demonstrates strong grounding as the authors can easily locate and understand the issue being pointed out.", "verifiability_rationale": "The comment contains a claim (an observation about the inconsistency) and provides supporting information by explicitly stating the number of encoderdecoders in each figure. While it doesn't provide external references, the logical reasoning and specific details make it verifiable.", "helpfulness_rationale": "The review point is 5 as it directly points out a discrepancy in the figures that the authors are likely to have seen. The explicit reference to the figure numbers makes it easy to understand and act upon. The suggestion to clarify the architectural difference is a concrete and actionable piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a lack of clarity regarding the attention mechanism's scope. While they can identify the potential action of questioning the 'N_l^(s)' notation and its relation to neighboring nodes, the paper doesn't explicitly state that 'N_l^(s)' refers to neighboring nodes. The reviewer's suggestion to clarify this is a direct action the authors could take to improve their understanding of the method. However, the paper doesn't provide enough detail to pinpoint *how* to apply this understanding, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly grounded in the paper. They are making an inference about the meaning of 'N_l^(s)' based on their understanding of attention mechanisms and the context of the paper. However, the paper does not explicitly state that 'N_l^(s)' refers to neighboring nodes. The reviewer's comment is not specific about which part of the paper they are referring to, and they are making an assumption about the meaning of the notation. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer's comment is verifiable. The paper provides equation 2, which defines 'N_l^(s)', and the surrounding text explains the context of attention mechanisms. The reviewer's question directly relates to this information, and the paper provides the necessary evidence to answer their question. The reviewer is asking for clarification on a specific point in the paper, which is a valid request that can be addressed by the information provided.", "helpfulness_rationale": "The reviewer's comment is not inherently helpful. While the comment raises a valid point about the clarity of the attention mechanism description, it doesn't explicitly state what the authors should do to address this issue. The comment is a question or suggestion for clarification, but it doesn't provide a concrete action or insight that would directly improve the authors' understanding or the paper itself. Without a clear next step, the comment is not particularly helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing link between Lemma 7 and the inequality at line 433. The action is to explain this connection, which is a direct and actionable request.", "grounding_specificity_rationale": "The reviewer directly asks 'how Lemma 7 comes into play here'. This explicitly identifies the section of the paper (Lemma 7) that is relevant to the point being made at line 433, demonstrating strong grounding. The comment clearly specifies what needs to be addressed (the connection to Lemma 7).", "verifiability_rationale": "The reviewer is asking for clarification on a logical connection. The request is about how a previous result (Lemma 7) is used to derive a subsequent result. This is a logical and verifiable request. The information needed to verify this claim would be the statement of Lemma 7 and the surrounding context at line 433.", "helpfulness_rationale": "The reviewer is asking for a crucial clarification that would significantly improve the reader's understanding of the proof. By explicitly asking how Lemma 7 is used, the reviewer is pointing out a potential point of confusion for other readers. The information provided directly addresses a need for clarification."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issues: 'The main contribution of this paper is unclear,' 'they either somewhat overstated the ability or applicability of the proposed method or were not wellsupported,' 'the main idea of how the proposed method copes with dynamic largescale multitasking is not clear,' and 'How the automation is achieved is also unclear.' These are direct statements of what needs to be addressed, making the action explicit. Furthermore, the reviewer points to specific areas (novelty claims, automation, multitasking), making the action concrete.", "grounding_specificity_rationale": "The reviewer refers to the 'main contribution,' 'novel properties,' 'how the automation is achieved,' and 'how the method copes with dynamic largescale multitasking.' While they don't name specific sections or tables, they clearly identify the aspects of the paper that are problematic. This indicates a level of grounding as the reviewer can infer the specific parts being discussed. However, the grounding is not as precise as 'fully grounded' because the authors would need to infer which specific aspect is being criticized. The specificity is moderate as the reviewer describes the issues in general terms (lack of clarity, overstated claims, unclear mechanisms) rather than providing concrete examples within those areas.", "verifiability_rationale": "The reviewer makes claims such as 'the main contribution of this paper is unclear,' 'they either somewhat overstated the ability or applicability of the proposed method or were not wellsupported,' 'the main idea of how the proposed method copes with dynamic largescale multitasking is not clear,' and 'How the automation is achieved is also unclear.' However, the reviewer does not provide any specific evidence, examples, or references to support these claims. The statements are presented as opinions or observations without any logical reasoning or external references to back them up. Therefore, the claims are not welljustified.", "helpfulness_rationale": "The reviewer points out several areas where the paper needs improvement, including the clarity of the main contribution, the justification of novelty claims, and the explanation of the method's mechanisms. While the reviewer doesn't explicitly ask for specific changes or suggestions, they clearly identify significant shortcomings in the paper. This provides the authors with a clear direction for their revision and helps them understand what aspects of their work need to be clarified or better supported. The reviewer's comments highlight specific areas of confusion, making the feedback helpful in improving the paper's overall quality and clarity."}
{"actionability_label": "2", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests two actions: including results on the crowdpose dataset in Table 4 and evaluating performance on the MS COCO dataset with a focus on easy settings. While these are concrete actions, they are presented as suggestions rather than explicit instructions. The reviewer doesn't specify *how* to include the results or *how* to perform the MS COCO evaluation. The phrasing is more about the *desire* to include these elements rather than a clear instruction on how to do so.", "grounding_specificity_rationale": "The review point explicitly mentions \"crowdpose dataset\" and \"Table 4\" for the first suggestion. While it doesn't pinpoint the exact section of the paper containing Table 4, it strongly implies it. For the second suggestion, it clearly mentions \"MS coco dataset\" and 'standard MS coco dataset,\" which is a specific dataset. It also refers to \"easy (non occluded) settings,\" which is a specific aspect of the evaluation. The grounding is present for the datasets but less precise for the table reference.", "verifiability_rationale": "The review point makes a claim by stating \"It will be nice to include...\" and \"It will be nice to evaluate...\". These are suggestions for improvement and evaluation. However, the review point does not provide any logical reasoning, common knowledge, or external references to support these suggestions. It's a statement of preference rather than a claim that requires verification.", "helpfulness_rationale": "The suggestions in the review point are relevant to improving the paper's presentation and evaluation. Including results on additional datasets is generally beneficial for completeness and demonstrating broader applicability. Evaluating performance on standard datasets like MS COCO and focusing on specific settings like \"easy\" settings can provide valuable insights into the method's strengths and weaknesses. However, the lack of concrete steps or specific guidance on *how* to implement these suggestions limits their immediate helpfulness to the authors. The reviewers are left to figure out the implementation details themselves."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the weakness: \"the author only compare their method to the BERTbaseline.\" This is a clear and direct statement of the missing comparisons. It identifies the action of comparing to token pruning and token combination baselines, which are concrete and actionable suggestions for improvement.", "grounding_specificity_rationale": "The review point is 1 as it does not specify where the comparison was done or why these specific baselines were omitted. While it identifies the type of missing baselines (token pruning and token combination), it doesn't pinpoint the exact section, table, or figure where this weakness is most relevant. The specificity is underspecified.", "verifiability_rationale": "The claim is that the experiment comparison is weak. This is not explicitly verifiable from the text itself. The reviewer's statement is a direct observation of the comparison made in the paper. There is no logical reasoning, common knowledge, or external references provided to support this claim within the review point itself.", "helpfulness_rationale": "The review point identifies a clear weakness in the experimental evaluation and provides concrete suggestions for improvement by suggesting specific baseline comparisons. This provides the authors with a clear direction for strengthening their work, making it 5 in guiding their next steps."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a specific action: 'Compare to coordinateaware methods like TFN or SchNet.' This is a clear indication of an actionable suggestion, as the authors are directed to add a specific comparison to their work. The suggestion is not just a general comment but a concrete next step.", "grounding_specificity_rationale": "The review point explicitly refers to 'the experimental section' and names specific methods, 'coordinateaware methods,' and provides examples, 'TFN or SchNet.' This indicates a high level of grounding specificity. The authors can easily identify the section being addressed and the specific methods being referenced.", "verifiability_rationale": "The review point makes a claim by suggesting a comparison to 'coordinateaware methods, such as TFN or SchNet.' This claim is 3 because the reasoning is based on the understanding that TFN and SchNet are coordinateaware and relevant to the point being made in the experimental section (comparing methods with different awareness). While it doesn't provide a detailed justification *why* these methods are appropriate, it offers a clear and logical reason based on prior knowledge of the field.", "helpfulness_rationale": "The review point is 5 because it directly suggests a concrete and actionable improvement to the experimental section. By recommending a comparison to coordinateaware methods like TFN or SchNet, the reviewer is guiding the authors to add a specific and relevant analysis. This is a clear and direct piece of feedback that empowers the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a potential weakness in the model but does not provide any specific actions or suggestions for improvement. It lacks a clear prescription for addressing the issue. While it implicitly suggests the need for demonstrating weaknesses, it doesn't explicitly state what needs to be done to show them.", "grounding_specificity_rationale": "The comment is 1 because it does not specify which part of the paper it is addressing. It makes a general statement about the model lacking demonstrated weaknesses without pointing to a specific section, table, figure, or unique aspect of the model. The comment is too vague to identify the issue precisely.", "verifiability_rationale": "The comment does not make a claim that can be verified. It states a concern about the lack of demonstrated weaknesses but does not provide any evidence or reasoning to support this concern. It's a statement of a potential issue rather than a claim that can be validated.", "helpfulness_rationale": "The comment identifies a valid concern about the lack of demonstrated weaknesses in the model but does not provide any specific suggestions or guidance on how to address this issue. It identifies a problem but doesn't offer a solution. The feedback is a diagnosis, not a prescription for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question ('What does the system offer...') and suggests a comparison ('over the previous extractthengenerate methodologies'). While this points towards an actionable next step for the authors (to seek information and compare), the question itself is quite general and lacks specific details about what methodology or aspect of the system is being referred to. The suggestion to compare is also broad and doesn't specify how or what to compare.", "grounding_specificity_rationale": "The review point asks a question about the system's methodology and compares it to 'previous extractthengenerate methodologies'. It does not explicitly identify a specific part of the paper or methodology being discussed. The reference to 'others' is vague and doesn't point to a particular section, table, or unique element of the paper. The comparison is also general and lacks specific details about the extractthengenerate methodologies being referenced or compared against.", "verifiability_rationale": "The review point contains a claim: 'What the others have done...' This is a question seeking information about what other methodologies exist. While the suggestion to compare is also a claim, the paper does not provide any evidence or references to support the claim that the proposed system offers something over previous extractthengenerate methodologies. There are no citations or logical reasoning provided to back up this assertion.", "helpfulness_rationale": "The review point asks a question about the system's methodology and makes a comparative statement ('What the others have done... What does the system offer... This is troublesome considering that the paper does not have any Related Work section, nor experimenting other extractthengenerate with their proposed model.'). While this points to a potential area for improvement, it does not directly instruct the authors on what changes should be made or how to improve their system. The lack of a related work section and experimental comparison makes it difficult to provide concrete, actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an action: exploring alternative methods for dealing with churn. This is an explicit action that authors could directly implement.", "grounding_specificity_rationale": "The review point mentions practical considerations like '3040 models to burn in' and 'unlabeled target data' which can be seen as grounding the discussion in specific aspects of the problem. However, it also implicitly suggests that the current approach (training 3040 models) is not appealing, which is an action that needs to be inferred rather than explicitly stated. The grounding is present but could be more explicit about the drawbacks of the current approach.", "verifiability_rationale": "The review point raises a question about the verifiability of the current approach ('Also, the thought of having to train 3040 models to burn in in order to test this approach isn't particularly appealing'). It doesn't provide any evidence or reasoning to support or refute this claim. The claim is presented without sufficient justification or reference to external sources or common knowledge.", "helpfulness_rationale": "The review point offers a suggestion: 'Another interesting direction for dealing with churn could be unlabelled data, or applying via constraints: e.g. if we are willing to accep X% churn, and have access to unlabeled target data, what's the best way to use that to improve the stability of our model?'. While this is a potential helpful suggestion, the review point itself doesn't provide specific details about why the current approach is unappealing or how the suggested alternatives would work. The helpfulness is limited by the lack of concrete information."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the introduction of related work is 'not sufficient' but does not explicitly state what should be done to make it sufficient. The reviewer's suggestion to 'give more work on GLN' is vague and does not provide specific actionable steps for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'more work on GLN' and specifically suggests 'reflect the advantages or difference of the proposed method, such as the difference from BGLN.' This indicates that the reviewer is identifying a specific area within the related work (GLN) and even a specific comparison point (BGLN), suggesting they can identify the relevant part of the paper. However, the reviewer does not specify *how* the related work should be expanded or what specific differences should be highlighted, making it underspecific.", "verifiability_rationale": "The reviewer states a fact: 'the introduction of related work is not sufficient.' This is a factual observation and does not contain a claim that requires verification or justification. The statement is a direct observation about the content of the related work section.", "helpfulness_rationale": "The reviewer points out a valid issue with the related work section but does not provide specific, actionable feedback on how to improve it. While the feedback is relevant to the paper's context, it lacks concrete suggestions for the authors to follow."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a difference in the number of dropout rates used in two different approaches (Moon's and Variational dropout). However, it doesn't explicitly state what should be done about this difference or how it affects the model. The reviewer is implicitly suggesting that this difference might be a point of confusion or a design choice that needs further explanation. While the action is implicit, the lack of a clear next step makes it 2.", "grounding_specificity_rationale": "The comment refers to 'Moon's approach' and 'Variational dropout,' which are specific methods. While it doesn't explicitly name sections, tables, or figures, the names of the approaches are distinctive enough to allow the reader to identify the relevant parts. The comment also specifies what is being compared \u2013 the number of dropout rates. Therefore, while the grounding is not literal, it is reasonably strong as the methods are clearly implied. The specificity is high as it directly addresses the number of dropout parameters.", "verifiability_rationale": "The comment identifies a difference in the hyperparameter settings (dropout rates) between two approaches. This constitutes a claim that there is a difference. However, the comment does not provide any justification or reasoning for why this difference exists (why only one for Moon's and two for Variational dropout). It simply states the observation. Therefore, the verifiability is borderline as there is a claim without sufficient supporting evidence.", "helpfulness_rationale": "The comment points out a potential inconsistency or a design choice in the original paper regarding the number of dropout rates used in different approaches. This could be helpful for readers trying to understand the nuances of the different methods. However, it doesn't directly suggest a concrete improvement or fix. It's more of a clarifying question than a direct suggestion for action. Therefore, it is 3 in identifying areas where the original paper could be improved, but it doesn't directly help the reader improve their own work in this specific instance."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a missing element (largerscale experiments) but doesn't demand a specific action to be taken. They present a problem without directly instructing the authors on what to do. While the implications are that the authors should include these experiments, the criticism itself doesn't explicitly state the next step.", "grounding_specificity_rationale": "The reviewer explicitly states 'largerscale experiments' as a missing element and provides specific examples like 'gridworlds with walls' and suggests 'simulators for such experiments are publicly available'. This clearly identifies the specific part of the paper (the experimental setup) and details what is missing. The comment is not merely inferable.", "verifiability_rationale": "The reviewer identifies a problem ('it is hard to judge') and offers suggestions for improvement, such as 'at least gridworlds with walls, and other nontrivial tiles', 'simulators for such experiments are publicly available', and 'comparison against other approaches'. While not a formal logical argument, the suggestions point to verifiable steps the authors could take. The comment itself doesn't provide a definitive answer or justification, making it 3.", "helpfulness_rationale": "The reviewer clearly states a problem ('it is hard to judge') and offers concrete suggestions for improvement, such as 'at least gridworlds with walls, and other nontrivial tiles', 'simulators for such experiments are publicly available', and 'comparison against other approaches'. This directly benefits the authors by providing actionable steps they can take to address the identified limitations."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a deficiency in the authors' work by stating they 'did not propose any quantitative measurement to the extent of occupation bias relative to real distributions in society'. While this suggests a potential improvement the authors could make, it doesn't explicitly state what action the authors should take. The reviewer implicitly suggests adding such a measurement, but doesn't provide specific details on how to do so. Therefore, it's not fully actionable as it doesn't directly tell the authors what to implement.", "grounding_specificity_rationale": "The reviewer's comment is 1 in the authors' work. They are criticizing the authors' methodology without specifying which part of their paper they are referring to. The comment is a general critique about the lack of a quantitative measurement.", "verifiability_rationale": "The reviewer's comment is not verifiable as it doesn't contain a claim that requires justification or evidence. It's a critique of the authors' methodology.", "helpfulness_rationale": "The reviewer's comment is helpful in that it identifies a potential weakness in the authors' approach \u2013 the lack of a quantitative measurement for occupation bias. This suggests a concrete improvement the authors could make to their work. While it doesn't provide specific details on how to implement this improvement, it points to a clear area for enhancement."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically regarding updates to weights associated with 'hard features'. This directly addresses a methodological choice and its potential consequences for the results. The reviewer also provides a specific example ('hard features'), making the action more concrete.", "grounding_specificity_rationale": "The reviewer refers to 'adaptive gradient methods' and 'hard features', which are specific technical terms and characteristics of the model. This demonstrates a clear identification of the relevant parts of the paper and the specific issue being addressed. The mention of 'hard features' even adds a degree of specificity.", "verifiability_rationale": "The reviewer poses a question about the potential impact of a methodological choice on the findings. While this can be interpreted as a claim or area needing clarification, the review point itself does not provide explicit evidence or a definitive answer to this question. The information is presented as a question for consideration.", "helpfulness_rationale": "The reviewer raises a valid and relevant question about a potential methodological choice that could impact the results. By asking about the potential effect of adaptive gradient methods on updates to 'hard features', the reviewer encourages the authors to consider the implications of their optimizer choice and the behavior of their model on difficult examples. This is a valuable point of discussion that could lead to a deeper understanding of the results."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out specific shortcomings in the experiments, such as 'limited types of teacher architectures' and 'most compared methods are proposed before 2019'. While the reviewer doesn't explicitly state *how* to address these limitations, they clearly identify the *nature* of the problem. The suggestions, though not fully detailed, indicate a direction for improvement. The reviewer's statement '2) The experiments are not sufficient enough' is a clear indication of a lack of actionability. The reviewer identifies the *problem* but doesn't provide concrete steps on how to *fix* it.", "grounding_specificity_rationale": "The reviewer mentions '2) The experiments are not sufficient enough. 21) There are limited types of teacher architectures' and '22) Most compared methods are proposed before 2019 (see Tab.)'. While the reviewer identifies the *types* of limitations, they don't explicitly name the *section*, *table*, or *unique aspect* of the paper being addressed. The reviewer refers to 'teacher architectures' generally and 'compared methods' as a category. The mention of 'see Tab.' suggests they are aware of a specific table but don't explicitly link it to the point. Therefore, the grounding is weak as the reviewer doesn't pinpoint the exact location or specific detail being discussed.", "verifiability_rationale": "The reviewer states '2) The experiments are not sufficient enough. 21) There are limited types of teacher architectures. 22) Most compared methods are proposed before 2019 (see Tab.)'. The reviewer provides reasons for the insufficiency, such as 'limited types of teacher architectures' and 'proposed before 2019'. These reasons, while not fully detailed, offer some justification for the criticism. The reviewer also refers to 'see Tab.', implying they have evidence from a table. The claim 'the experiments are not sufficient enough' is supported by the reasons provided, even if the level of detail could be improved. The reviewer is making a claim that requires some level of justification.", "helpfulness_rationale": "The reviewer criticizes the sufficiency of the experiments, specifically mentioning 'limited types of teacher architectures' and 'most compared methods are proposed before 2019'. While the reviewer identifies a valid concern about the experimental design, the criticism lacks specific, actionable suggestions. The reviewer doesn't provide concrete steps on how to improve the experiments or how to address the identified limitations. The suggestions are vague and don't offer concrete improvements. The reviewer's statement is a valid point but lacks the detailed guidance needed for immediate action."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that no information from 2hop neighbors is included and suggests including this information. This is a clear indication of an actionable suggestion.", "grounding_specificity_rationale": "The comment refers to '2hop neighbors' without explicitly stating which part of the paper this refers to. While the concept is understandable, the specific location or section where this information should be included is not clearly identified.", "verifiability_rationale": "The comment states that the information about 2hop neighbors is 'unclear why it is effective'. This is a statement of uncertainty, not a claim that requires verification. The reviewer is expressing their perception of the information's clarity, not providing evidence to support or refute it.", "helpfulness_rationale": "The comment clearly identifies a missing element (information about 2hop neighbors) and suggests a specific action (including this information). This is a direct and actionable piece of feedback for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the preference for using DICOM images over PNG and recommends the FastMRI challenge dataset. They also suggest comparing inference speeds. These are all concrete actions the authors can take to improve their draft. The reviewer provides specific file formats and a dataset, making the actions clear.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the real dicom image' and 'FastMRI challenge dataset,' which are specific parts of the paper. They clearly identify the issue (image format) and the proposed solution (using DICOM and the dataset). While they don't specify *how* to compare inference speeds, they do point to a relevant dataset, making the grounding quite strong.", "verifiability_rationale": "The reviewer recommends using DICOM and the FastMRI dataset. While they provide a *what*, they don't explicitly state *why* DICOM is superior for this purpose or provide specific examples of issues with PNG in this context. They also don't offer a direct comparison or external reference for the inference speed recommendation. Therefore, the claim is somewhat supported but lacks key elements like specific examples or references.", "helpfulness_rationale": "The reviewer provides clear recommendations for the authors to use DICOM images and the FastMRI dataset. They also suggest comparing inference speeds, which is a practical and actionable step. The reviewer's suggestions directly address a common concern in image processing and provide a clear direction for experimentation. The recommendations are welldefined and immediately actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states 'ProtPainter just provides an empirical conformation estimation.' This is a statement of observation. While it suggests 'Further optimization and validation are required,' this is an implied action rather than an explicit and concrete instruction on how to achieve this. The reviewer does not specify the exact steps or methods for optimization and validation.", "grounding_specificity_rationale": "The comment refers to 'ProtPainter' and 'binder design' without specifying a particular section, table, figure, or unique element within the paper. It mentions 'empirical conformation estimation' but does not clearly identify where this estimation occurs in the ProtPainter method or results. The reviewer provides a general description but lacks precision in pinpointing the relevant part of the paper.", "verifiability_rationale": "The comment states 'ProtPainter just provides an empirical conformation estimation.' This is a claim about the current state of ProtPainter. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. There is no logical reasoning presented to justify why ProtPainter only provides empirical estimations, and no external references are cited to back this assertion.", "helpfulness_rationale": "The comment identifies a potential limitation of ProtPainter regarding optimization and validation. While it suggests 'Further optimization and validation are required,' this is a general recommendation and lacks specific guidance on how to proceed. The reviewer does not offer concrete steps or strategies for optimization and validation, making the suggestion quite broad and less actionable for the author. The comment is more of a suggestion for future work rather than a direct improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly asks for clarification on the training procedure of the model in Figure 7. This is an explicit instruction to look for information related to this specific aspect. However, the reviewer also suggests a specific experiment ('If the duration of the cycle changes (shortens...)', which is not explicitly mentioned in the original paper, making the action slightly vague.", "grounding_specificity_rationale": "The reviewer refers to 'the model in fig. 7', which is a specific reference. They also ask about a specific aspect of the model's training ('Was it on full field flicker stimulus changing contrast with a fixed cycle?'). However, they don't explicitly state the section where this information might be found, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer states a need for clarification on the training procedure. This is a claim that requires justification. However, the reviewer does not provide any logical reasoning, external references, or examples to support why this clarification is needed or important. The statement is presented as a request for information without any backing.", "helpfulness_rationale": "The reviewer's request is to clarify the training procedure of a specific model in a figure. While this information is likely relevant for understanding and reproducing the results, the request itself is very specific and lacks broader context or actionable steps. The reviewer is essentially asking for more detail on a single point, which is helpful but not groundbreaking or transformative in itself."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a constraint: 'what happens if the original CAD model is already associated with spatiallyvarying (SV) BRDF maps?'. This directly implies that the CAD model *cannot* be freely associated with SV BRDF maps without addressing potential issues. This is an explicit action that is also concrete, as the action is to consider the implications of this association. The reviewer is prompting the author to think about a specific scenario and its consequences.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper. It is a general question about a potential constraint on the CAD model when working with SV BRDF maps. Therefore, the grounding is weak. The comment is not pointing to a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The review point is a question, not a declarative statement that makes a claim. Therefore, it does not contain a claim and the verifiability criteria do not apply.", "helpfulness_rationale": "The review point raises a valid concern about a potential constraint on CAD models when working with SV BRDF maps. It points out a scenario that the author might not have considered, which could be helpful for them to understand potential limitations or requirements in their workflow. While it doesn't provide a solution, it offers a relevant observation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action: 'More evaluation would have been welcome.' However, it lacks detail on *how* this evaluation should be conducted or what specific aspects of the model or experiments require further evaluation. The action is stated, but the implementation details are missing, making it less actionable.", "grounding_specificity_rationale": "The comment explicitly mentions CIFAR10 and lower label scenarios, indicating a clear identification of the specific part of the paper being addressed. However, it does not specify *why* more evaluation is needed for these specific areas. The grounding to the specific dataset and scenarios is present, but the reasons for the need for more evaluation are not elaborated upon.", "verifiability_rationale": "The review point does not contain a claim. It is a suggestion for improvement rather than a statement of what is wrong or needs verification. Therefore, it does not fall into any of the verifiability categories.", "helpfulness_rationale": "The comment is helpful in guiding the authors towards a more thorough evaluation of their model on CIFAR10, especially in lower label scenarios. It encourages them to consider additional evaluation methods or experiments, which can be beneficial for improving their work. While it doesn't provide specific details on *how* to evaluate, it sets a direction for further work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a potential flaw in the experimental comparisons and identifies the specific pairs of experiments (H>N vs. H>N+B, H>N>H vs. H>N+B>H) that might be affected by varying amounts of data. This directly points to an actionable improvement in the experimental design.", "grounding_specificity_rationale": "The reviewer provides specific names for the experimental setups being compared (H>N, H>B, H>N+B, H>N>H). This allows the authors to precisely identify the relevant parts of the study and understand the specific issue being raised.", "verifiability_rationale": "The reviewer makes a claim about a potential flaw in the experimental comparisons and provides specific examples of experiments (H>N and H>N+B, H>N>H and H>N+B>H) that might be affected by varying amounts of data. This allows for verification of the concern and provides a clear explanation of why the comparison might be problematic.", "helpfulness_rationale": "The reviewer's point directly addresses a potential flaw in the experimental methodology and provides a clear suggestion for improvement (considering experiments with equal amounts of data). This is highly relevant and actionable for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point contains multiple suggestions that are directly actionable. The reviewer suggests improving organization by placing the comment at the end, clarifying the behavior of Algorithm 1 with more iterations, pointing out a missing citation, highlighting a lack of explanation in the introduction, and suggesting adding a label to a figure. These are all concrete actions the authors can take to improve their work. While the placement suggestion is less specific, the other points are clear and directly lead to actionable improvements.", "grounding_specificity_rationale": "The reviewer does not explicitly identify the specific part of the paper being addressed in any of the points. They are making general suggestions about the placement, behavior, and clarity of the algorithm, and pointing out a missing citation. None of these points specify *where* in the paper or *what* is missing. The reviewer's comments are about the content and presentation of the work, not about specific elements within a section or figure.", "verifiability_rationale": "The reviewer's claims are not explicitly stated as claims in the sense of requiring justification or proof. Instead, they are questions or suggestions for improvement. For example, 'What happens for larger T?' and 'usually iterative algorithms run until some criterion is fulfilled' are questions rather than claims that need verification. The missing citation and the lack of explanation in the introduction are implied gaps that the reviewer is pointing out, but they are not explicit claims that require evidence. The missing label for Figure 1 is a suggestion, not a claim that needs verification.", "helpfulness_rationale": "The review point provides several suggestions that are likely to be helpful for the authors. Pointing out a missing citation can help them find relevant background information. Highlighting a lack of explanation in the introduction can guide them to improve the clarity of their presentation. Suggesting improvements to the algorithm's behavior and adding a label to a figure can directly enhance the quality of their work. While the suggestion about placement is less directly helpful, the other points are valuable feedback. The overall impact on the authors' ability to improve their draft is likely positive."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer states a problem ('I don't understand why Section 2.1 is included') and suggests a potential improvement ('the time spent describing the ResNet architecture could be better used...'). While the suggestion is present, it is not an explicit action or concrete change. The reviewer implies an action but doesn't specify *what* to do or *how* to do it. The action is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer attempts to ground the comment by mentioning 'Section 2.1' and 'the description of the ResNet architecture' as the area of confusion. However, they do not explicitly identify the *specific* part within those sections that is unclear. The grounding is weak because the reviewer cannot confidently determine which part the comment addresses. The comment specifies the *area* but not the *specific element* within that area.", "verifiability_rationale": "The reviewer does not make a claim that requires verification. They are posing a question ('I don't understand why...') rather than making a statement that needs to be supported by evidence. Therefore, there is X to evaluate for verifiability.", "helpfulness_rationale": "The reviewer clearly states their problem ('I don't understand why...') and offers a suggestion ('the time spent describing the ResNet architecture could be better used...'). While the suggestion is present, it is vague and lacks specific guidance. The reviewer's criticism is clear, and their suggestion is actionable in a general sense (reorganize the description). However, the lack of specificity makes the helpfulness only '2' as the authors still need to figure out *how* to reorganize the description."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the missing element: a figure demonstrating accuracy decline. This is a clear and actionable suggestion for the authors. While the reviewer doesn't specify the exact type of predictor or setting, the suggestion is concrete enough to guide the authors in creating the necessary visualization. The reviewer identifies a clear next step for the authors to take.", "grounding_specificity_rationale": "The reviewer identifies a potential issue (accuracy decline) but doesn't explicitly pinpoint a specific part of the paper or method that needs improvement. They refer broadly to 'a predictor' without specifying which section, table, figure, or unique element is affected. While the issue is implied, the location remains vague.", "verifiability_rationale": "The reviewer's comment does not contain a claim that needs verification. They are pointing out a missing element and suggesting a way to address it, but not making a judgment about the paper's quality or the validity of the problem. The comment itself is a statement of a problem to be addressed, not a claim requiring evidence or justification.", "helpfulness_rationale": "The reviewer's comment is relevant to the problem of accuracy decline, as it directly addresses a potential cause. However, it doesn't provide concrete help with the *motivation* behind the problem. While suggesting a figure is a helpful step towards understanding the issue, it doesn't explain *why* the accuracy decline is a problem or what the consequences are for the authors. The comment is more about demonstrating the problem than directly aiding the authors' motivation."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the need to 'explain more about the definition of excessive risk in line 103 and how to calculate in practice, in terms of expectation' and addresses the potential for negative values, the observed positive values in figures, the comparability of values, and the justification of excessive risk as a fairness representation. While the reviewer doesn't provide a specific action or instruction, they clearly identify a gap in the explanation and highlight potential areas of confusion for the authors. The reviewer is implicitly suggesting that the authors should provide a more detailed explanation of the calculation and address the apparent inconsistency with the possibility of negative values. The reviewer is also implicitly suggesting that the authors should justify the use of excessive risk as a fairness metric.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. The reviewer is asking for clarification on a concept and its calculation, which is a general request about the method. The reviewer is also asking about the comparability of values across different groups, which could be interpreted as a lack of grounding in the specific context of the paper. However, the reviewer is asking for clarification on a general concept rather than pinpointing a specific section or element of the paper. The request for justification of excessive risk as a fairness representation is also general.", "verifiability_rationale": "The review point contains a claim: 'Can authors explain more about the definition of excessive risk in line 103 and how to calculate in practice, in terms of expectation, in terms of expectation?' and 'What's more, are values of excessive risk comparable among different groups? If not, can authors explain why excessive risk is a good representation for fairness?' The claim is supported by the reviewer's questions and observations about the potential for negative values and the positive values in the figures. The reasoning provided is that the reviewer is questioning the consistency of the explanation with the possibility of negative values and the apparent lack of negative values in the figures. The external references provided are the figures themselves. The verifiability is somewhat borderline as the claim is present, but the level of detail and justification could be improved.", "helpfulness_rationale": "The review point is 5 as it directly addresses several potential areas of confusion and lack of clarity for the authors. The reviewer is asking for clarification on a key concept ('excessive risk'), its calculation, and its interpretation in the context of the figures. The questions about the potential for negative values and the observed positive values highlight a gap in the explanation. The request for justification of excessive risk as a fairness representation is crucial for its adoption and understanding. The reviewer is essentially prompting the authors to provide a more detailed and comprehensive explanation of their method and its implications. By addressing these points, the authors can significantly improve the clarity and impact of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the relationship between NGD and NGF ('NGD is a discretization of NGF') and concludes that initialization should play a role in the context of initial value problems ('Thus, initialization should play a role such as pretraining.'). This constitutes an explicit action. However, the reviewer does not provide specific details on *how* initialization should be pretrained, making the action somewhat vague and not fully actionable.", "grounding_specificity_rationale": "The reviewer refers to concepts like 'NGD,' 'NGF,' 'initial value problem (IVP),' and 'initialization.' While these terms are relevant, the reviewer does not explicitly identify a specific section or element in the paper they are referring to. The connection is implied but not explicitly made. The reviewer also suggests 'pretraining' as a potential action, which is a general concept rather than a specific, detailed suggestion.", "verifiability_rationale": "The reviewer makes a claim about the relationship between NGD, NGF, discretization, IVP, and initialization. While the reviewer's suggestion about 'pretraining' is a suggestion, it is not necessarily a claim that requires external verification. The connection between NGD/NGF, discretization, and IVP is generally understood in the field. The reviewer's point is more about pointing out a potential area for clarification in the paper.", "helpfulness_rationale": "The reviewer points out a potential area for clarification in the paper regarding the role of initialization in the context of NGD, NGF, and IVPs. Suggesting 'pretraining' as a potential solution is a helpful suggestion. However, the suggestion is quite general and lacks specific details, making it 3 but not entirely actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point implicitly suggests an action related to named entity extraction by pointing out a lack of clarity. However, it does not explicitly state what needs to be done or how to achieve it. The suggestion regarding English proofreading is more explicit, recommending a specific action. Therefore, while the point contains actionable elements, the named entity extraction part is vague and implicit, making it 3 but not fully actionable. The English proofreading part is explicitly actionable and concrete.", "grounding_specificity_rationale": "The review point mentions named entity extraction and English proofreading but does not specify which part of the paper or dataset it refers to. For named entity extraction, it's a general comment about a process. For English proofreading, it's a suggestion without pinpointing the location or type of errors. Therefore, the grounding for both aspects is weak as the specific section, table, figure, or unique aspect being addressed is not clearly identified.", "verifiability_rationale": "The review point does not contain any claims that require verification. It is a statement of a potential issue and a suggestion for improvement. Therefore, there are no verifiable claims in the review point.", "helpfulness_rationale": "The review point, while not containing verifiable claims, offers helpful feedback. It points out a potential area for improvement (named entity extraction) and suggests a concrete action (English proofreading). Even though the specific details of the improvement are lacking, the suggestion to proofread is a valuable piece of advice for the authors. Therefore, the review point provides 3 feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point provides two distinct suggestions. The first part, 'for every arm a' implies there is a single optimistic parameter, but of course it depends on a **', is an implicit suggestion that needs to be clarified. While the reviewer doesn't explicitly state the implication, the ellipsis suggests a missing detail. The second part, 'Why not choose T_0 = m Sqrt(T)? Then the condition becomes B > Sqrt(m) T^(3/4), which improves slightly on what you give.', is an explicit suggestion to try a different initialization and provides the resulting condition. Therefore, while the first part is implicit, the second part is explicit. The overall actionability is high because the reviewer provides clear, actionable feedback on potential ambiguities and suggests concrete improvements.", "grounding_specificity_rationale": "The review point explicitly mentions 'for every arm a' and 'T_0', indicating a clear reference to specific parts of the paper. The reviewer also points out the condition involving B, m, and T. The use of the asterisk ** suggests a specific location within the paper. Therefore, the reviewer explicitly identifies the relevant parts of the paper, making the grounding fully specific.", "verifiability_rationale": "The review point provides clear justifications for its suggestions. The first part explains why 'for every arm a' is ambiguous. The second part provides the alternative initialization and demonstrates the improvement in the condition. The logical reasoning and the specific example of the improved condition provide strong verifiability. The reviewer's statements are wellsupported.", "helpfulness_rationale": "The review point is 5. The suggestions are clear, actionable, and directly address potential ambiguities and improvements. The reviewer provides a concrete alternative initialization and demonstrates its benefit, empowering the authors to understand the missing details and refine their approach. The feedback is specific and directly relevant to the points raised."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out the inconsistency in the formatting of variables 'L' and 'E' at specific line numbers (296302). They state that 'L' and 'E' should be defined and that the formatting is inconsistent (italicized vs. not italicized). This is an explicit action the authors should take: define 'L' and 'E' and ensure consistent formatting. The reviewer provides a clear and actionable suggestion.", "grounding_specificity_rationale": "The reviewer explicitly identifies the location of the issue by stating 'Line 296: L and E should be defined in the immediate vicinity.' This is strong grounding as the reviewer not only identifies the need for definition but also specifies the exact line where the issue occurs. Furthermore, they point out a formatting inconsistency ('Again, sometimes L, E are italicized (line 296) and sometimes not (line 302)'). This further grounds the comment by specifying the visual difference.", "verifiability_rationale": "The reviewer implies a claim that inconsistent formatting can cause confusion. They provide a justification for this by stating 'This inconsistency can cause confusion and hinder understanding.' While not a direct claim, the reviewer provides a logical reasoning for why the suggested action is beneficial. The grounding of the issue (line 296) also supports the verifiability. The reviewer is not just stating a problem, but also explaining why it's a problem and how to solve it.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'L and E should be defined in the immediate vicinity' and 'This inconsistency can cause confusion and hinder understanding.' This is a helpful comment because it directly addresses a potential issue and provides a reason for the suggestion. The authors can directly follow these instructions to improve their draft. The reviewer is not just pointing out a problem, but also offering a solution and explaining its benefits."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment 'More experiments are required' does not specify what action the authors should take. It suggests a general improvement but lacks concrete steps or details on how to achieve it.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper (e.g., a section, table, or figure) that is weak. It is a general statement about the experimental section being weak without pinpointing the exact issue.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a suggestion for more experiments, not a statement that needs supporting evidence.", "helpfulness_rationale": "The comment is a general suggestion for more experiments but lacks specific details on what experiments to add, why they are needed, or how to design them. This generality makes it less helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests *comparing* with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. This is a general direction, not a specific action. While it encourages exploration, it doesn't provide explicit steps or concrete examples of how to achieve this comparison. The authors are not told which models to consider, how to implement the comparison, or what specific aspects of the comparison are relevant. Therefore, while the suggestion is valuable, it lacks the explicit and concrete nature required for high actionability.", "grounding_specificity_rationale": "The review point suggests *more extensive comparisons* with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. This suggestion is not tied to a specific part of the paper. It's a general recommendation for improvement without specifying where these comparisons should occur or what aspects of the models/techniques are relevant. The reviewer implies the need for more comparisons but doesn't pinpoint the exact location or nature of these comparisons within the paper. Therefore, the reviewer does not identify a specific section, table, figure, or unique aspect of the paper being addressed.", "verifiability_rationale": "The review point itself does not contain a claim or a statement that requires verification. It is a suggestion for improvement, not an assertion that needs to be supported by evidence. There are no explicit opinions, judgments, or requests for changes. It doesn't fall into the categories of subjective opinions, suggestions, judgments about the paper, or deductions. Therefore, there is X that is being made and verified.", "helpfulness_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. This is a valuable suggestion that encourages the authors to explore more advanced techniques and potentially improve their work. While it doesn't provide specific details, it points towards a concrete direction for future research and development. Therefore, the review point identifies a meaningful weakness and suggests a valuable improvement, making it helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "Each point in the review directly identifies an error and suggests a specific correction. For example, 'line 2: \"Despite of being compact\" > \"Despite being compact\"' is an explicit action to change the phrasing. Similarly, 'grounding specificity_rationale': Each point explicitly states the line number where the error occurs, providing clear grounding. For example, 'line 56: \"We refer multiway arrays\" > \"We refer to multiway arrays\"' clearly points to the specific location of the issue. The other points follow the same pattern of explicit grounding and specific suggestions.", "grounding_specificity_rationale": "Each point in the review explicitly refers to a specific part of the paper (line number) and clearly explains what is wrong. For example, 'line 158: \"HPFN to a even deeper ConAC\" > \"HPFN to an even deeper ConAC\"' not only points to the line but also corrects the article from 'a' to 'an'. This level of detail ensures the authors understand exactly where the issue lies and what needs to be changed. The other points follow the same pattern of explicit grounding and specific suggestions.", "verifiability_rationale": "Each point in the review identifies a grammatical or stylistic error and provides a clear and direct suggestion for correction. For example, 'line 2: \"Despite of being compact\" > \"Despite being compact\"' is a clear claim about the grammatical error. The suggestion directly addresses the identified issue. Similarly, 'line 56: \"We refer multiway arrays\" > \"We refer to multiway arrays\"' is a clear claim about the need for proper terminology. The other points follow the same pattern of identifying the error and providing a straightforward solution. There is no ambiguity in the suggestions, making them 5.", "helpfulness_rationale": "The review point is 5 as it directly identifies specific errors in the text and provides clear, actionable suggestions for improvement. Each point is concise and directly addresses a distinct issue. For example, 'line 2: \"Despite of being compact\" > \"Despite being compact\"' highlights a grammatical error that could affect the reader's perception. The suggestions are specific and easy for the authors to implement. While there are four points, they all focus on different aspects of writing quality, making the feedback comprehensive and targeted."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'Mistakes in Eqs.' which directly points to a problem. However, it doesn't specify how to address or fix these mistakes, leaving the authors with a clear issue but no concrete action to take.", "grounding_specificity_rationale": "The reviewer refers to 'equations' generally and then specifically mentions 'W4'. This shows some grounding, as they are pointing to a specific equation. However, they do not explicitly state the section or equation number within the text itself, relying on the context of 'Mistakes in Eqs.' to imply it.", "verifiability_rationale": "The reviewer states 'Is it the inversion of matrix determination or number the division of the number of samples? W4 \u2013 Mistakes in Eqs.' This is a claim that there might be mistakes in the equations. While not providing a specific example or citation, it's a clear statement that requires further investigation or clarification.", "helpfulness_rationale": "The reviewer points out a potential issue ('Mistakes in Eqs.') but does not offer any specific suggestions or guidance on how to address it. They are asking for clarification, which is a form of help, but it lacks concrete actionability for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment states the paper is 'somewhat incremental' and the model is a 'fairly straightforward extension' of GANs for static images. This is a general statement about the overall approach, not a specific suggestion for improvement. While it implies a lack of significant novelty, it doesn't explicitly state what needs to be changed or how to achieve a more substantial contribution. The reviewer doesn't identify a specific aspect of the model or methodology that requires attention, nor does they provide concrete steps for improvement. The comment is a general observation rather than a direct instruction for action.", "grounding_specificity_rationale": "The comment is about the overall approach being 'somewhat incremental' and a 'fairly straightforward extension' of GANs for static images. It does not identify a specific part of the paper, such as a section, table, figure, or unique aspect, that is being addressed. The reviewer is making a general comment about the nature of the work rather than pinpointing a particular component for discussion. Therefore, the comment lacks grounding in the specific parts of the paper being discussed.", "verifiability_rationale": "The comment contains a claim: 'the developed model is a fairly straightforward extension of the GAN for static images.' This claim can be considered verifiable based on the reviewer's assessment of the model's simplicity. While the assessment is subjective, it is based on the description of the model as a 'fairly straightforward extension,' which provides a basis for verification. The reviewer provides a description of the model's nature, allowing for a judgment on its complexity relative to the base GAN model. Therefore, the claim is supported by a description of the model's characteristics.", "helpfulness_rationale": "The comment identifies a potential limitation of the work \u2013 its incremental nature and straightforward extension of GANs for static images. While this is a valid observation about the current approach, it does not offer concrete suggestions or directions for improvement. The reviewer points out a lack of significant novelty but does not provide specific steps or ideas on how to address this. The comment is a critique of the outcome (lack of significant advancement) rather than a constructive suggestion for the process or content of the paper. Therefore, the comment is not particularly helpful in guiding the authors towards improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks a question: 'Does the proposed method perform better in pure combinational logic (without register)?' and suggests a hypothesis: 'it seems it may be much easier to model without state related registers, it would be interesting to see a comparison between sequential design and combinational design.' This is an explicit action, stating what needs to be investigated. While the action itself is somewhat vague (the 'how' of the comparison isn't specified), the reviewer clearly identifies the area of interest (performance comparison between sequential and combinational designs).", "grounding_specificity_rationale": "The review point explicitly mentions 'the proposed method' and 'pure combinational logic (without register)'. This clearly identifies the specific part of the paper being addressed. The reviewer also implies the need to compare 'sequential design' with 'combinational design', further grounding the specific area of interest. The grounding is strong as the parts are clearly referenced.", "verifiability_rationale": "The review point contains a claim: 'it would be interesting to see a comparison between sequential design and combinational design.' This is a suggestion for an experiment or further analysis. While the claim is 3 in that it points towards a useful investigation, it lacks specific details on how this comparison should be conducted. The reviewer doesn't provide concrete examples or references to support the claim, making it less 5. The claim is present, but the supporting evidence is somewhat lacking in detail.", "helpfulness_rationale": "The review point raises a valid question about the impact of register usage on modeling difficulty and suggests a relevant comparison. It provides a clear direction for further investigation. While it doesn't provide a definitive answer or a specific methodology for the comparison, it highlights a potential area for improvement and encourages the authors to explore different design choices. This makes it 3 as it guides the authors towards a valuable experiment, but it doesn't directly tell them what to do."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This is a direct and explicit request for a specific metric, making it 5 as the authors can directly use this information to improve their draft by comparing their model's performance against this baseline.", "grounding_specificity_rationale": "The reviewer's request is highly specific. They are asking for the performance of a *specific* baseline (LDA+LSTM) and a *specific* metric (topic switch percent). This strong specificity ensures that the authors can easily identify the referenced part and understand the issue being addressed.", "verifiability_rationale": "The reviewer is making a claim that the LDA+LSTM baseline has a performance metric (topic switch percent). While the provided text doesn't explicitly state this value, the request itself implies a claim that such a metric exists and is relevant. Therefore, it is 3, as the reasoning and common knowledge suggest that such a metric would be relevant for evaluating topic modeling performance. The external references would be the actual value of this metric.", "helpfulness_rationale": "The reviewer's point is 5 in that it highlights a potential gap in the paper. While the request itself isn't directly improving the paper's content, it points out a missing piece of information (the performance of the LDA+LSTM baseline) that would be valuable for the authors to include. This makes it 5 in terms of identifying areas for improvement in the paper itself, even though the request isn't directly improving the authors' draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The reviewer states the motivation is 'unclear' and questions the 'quality' of annotations. While the reviewer asks a question ('How might uncertainty in amodal predictions be handled or utilized in subsequent tasks?'), this is an implicit suggestion rather than an explicit action. The reviewer does not provide concrete steps or guidance on how to address the unclear motivation or improve the annotation process. The lack of explicit action and concrete guidance makes the actionability borderline.", "grounding_specificity_rationale": "The reviewer mentions 'position, size and motion' and 'occluded objects' as aspects of the state being difficult to predict. However, the reviewer does not explicitly state which specific part of the paper (e.g., a section, table, figure, or a unique element) is being addressed. The reviewer's comments are general and do not pinpoint the exact location or type of information being discussed. Therefore, while the reviewer identifies some specifics, they are 1 in the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer provides specific details about the difficulty of predicting the state of occluded objects and mentions 'downstream tasks' as a potential application. The reviewer attempts to provide justification by stating that the annotation effort is 'questionable' and asking how uncertainty might be handled. However, the lack of clarity and specific examples in the review point makes it difficult to fully verify the claims. The reviewer's statements are somewhat vague and lack the logical reasoning, common knowledge, or external references needed for full verifiability.", "helpfulness_rationale": "The reviewer directly states the motivation is 'unclear' and questions the 'quality' of annotations. The reviewer also asks a question ('How might uncertainty in amodal predictions be handled or utilized in subsequent tasks?') as a way to seek clarification. However, the reviewer does not provide any concrete suggestions or actionable feedback on how to address these issues. The lack of clear and helpful feedback makes the review point unhelpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests including experiments with GPT3.5, which is a potential alternative to GPT4. However, they do not specify how to implement this suggestion or what the expected outcome should be. The reviewer offers a general idea but lacks concrete steps for the author to take.", "grounding_specificity_rationale": "The reviewer's comment is a general suggestion for improving the evaluation process. They do not identify a specific aspect of the paper or their work that needs addressing or improvement.", "verifiability_rationale": "The review point is a suggestion for a change in the evaluation process. It does not make a claim about the quality of the author's work or provide any evidence to support such a claim. It's simply a recommendation.", "helpfulness_rationale": "The reviewer's comment is a suggestion for a more costeffective evaluation method. While relevant to the broader context of research, it does not directly address any specific issues or weaknesses within the author's current draft. It's a general recommendation rather than a specific critique of their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'Please also include bold numbers for the baselines of previous work. Specifically for WMT17WIKT the best result in terms of BLEU is actually in the baselines.' This is an explicit action that the authors can directly address. The reviewer also infers the need to check the WMT17WIKT row and the BLEU column for the best result, making the action somewhat concrete.", "grounding_specificity_rationale": "The reviewer provides a very specific location for the issue: 'Table 4'. Within this table, they identify a very specific aspect: 'the baselines of previous work'. They also point to a specific metric: 'the best result in the baselines'. This is strong grounding as the authors can precisely identify the table and the specific information being referred to. The reviewer also identifies the *nature* of the error: 'the best result in the baselines'.", "verifiability_rationale": "The reviewer makes a claim: 'the best result in the baselines of previous work for WMT17WIKT is not in the baselines according to their paper'. This claim is verifiable as the reviewer is stating a specific observation that can be checked against the referenced work. The reviewer also identifies the *nature* of the missing information: 'bold numbers for the baselines of previous work'.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential issue with the presented results. By pointing out the missing bolding and the incorrect best result, they are providing a clear suggestion for improvement. This is likely to be helpful for the authors who are trying to understand the performance of different models. The reviewer is essentially correcting a factual error and suggesting a formatting improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment requests 'examples of 'unreliable neighbors'' but does not explicitly state what action the author should take with this information. It's a request for clarification rather than a direct instruction on how to improve the draft based on this specific point.", "grounding_specificity_rationale": "The comment refers to 'unreliable neighbors' generally without specifying which part of the paper or section this relates to. It does not identify a specific element within the paper (e.g., a citation, a section, a figure).", "verifiability_rationale": "The comment presents a potential issue ('unreliable neighbors') but does not provide any evidence or justification for this claim. It lacks references to external works or logical reasoning to support the assertion.", "helpfulness_rationale": "The comment is more of a suggestion for the author to investigate further rather than a direct instruction on how to improve their draft. It prompts for examples but doesn't explicitly guide the author on how to use or address the potential issues identified."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states what is missing ('insufficient backingup') and what should be included ('missing information about the TD3GA algorithm'). This indicates a clear and actionable point. The reviewer also specifies the *relevance* of the missing information by stating 'the main paper does not even mention the TD3GA algorithm' and 'the study of combining DQD with TD3 is crucial to understand these synergies'. This makes the action clear and the need for improvement explicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the TD3GA algorithm' as the specific part of the paper that is missing and relevant. This demonstrates strong grounding as the reviewer can accurately pinpoint the section, table, figure, or unique aspect being addressed. The reviewer also specifies *why* this is important by stating 'the study of combining DQD with TD3 is crucial to understand these synergies'. This adds to the specificity of the grounding.", "verifiability_rationale": "The reviewer makes a claim about the 'synergies between DQD and PPO looks insufficiently backedup'. This is a claim that needs verification. The reviewer then states 'In particular, the main paper does not even mention the TD3GA algorithm, while the study of combining DQD with TD33 is crucial to understand these synergies.' This statement provides some justification, making the claim 3. However, the reviewer does not provide *specific examples* or *external references* to support their claim about the lack of backing. While there is some justification, it lacks key elements like concrete examples or references, making it only 3.", "helpfulness_rationale": "The reviewer provides specific examples of what is missing from the paper ('insufficient backingup' and 'missing information about the TD3GA algorithm') and *why* it is missing ('the main paper does not even mention the TD3GA algorithm' and 'the study of combining DQD with TD3 is crucial to understand these synergies'). This makes the review not only identifying a problem but also providing a clear path for the authors to address it. The reviewer also highlights the *importance* of understanding the synergy between DQD and different RL algorithms, making the review 5 for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about why a surprising result occurred, which is not an explicit instruction on what to do or how to fix it. The request is for clarification rather than a direct action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Sections 6.1 and 6.2' where the surprising result is observed, providing a clear grounding of the issue. However, the reviewer does not specify *what* is surprising or what aspect of the result needs explanation, making it less specific than identifying a typo or a missing detail in a specific algorithmic step.", "verifiability_rationale": "The reviewer is not presenting a claim that requires verification. They are asking a question about the results, which is a valid inquiry but does not involve making a statement that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer's request for an explanation of a surprising result is a valid and helpful contribution to understanding the method's behavior. While it doesn't directly fix a bug or improve the method, it addresses a valid curiosity and can enhance the reader's comprehension."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: \"We have found it easier to be confident about applying ceterus paribus convexity;\". This clearly indicates a desire for clarification. However, the reviewer does not specify *how* to achieve this clarity or provide concrete steps for improvement. The action is identified, but the explicitness and concreteness of the action are not fully realized.", "grounding_specificity_rationale": "The reviewer mentions \"ceterus paribus convexity,\" which grounds the issue in a specific technical term. However, the reviewer does not specify *what* aspect of the explanation is unclear or provide concrete examples of where this ambiguity arises. The grounding is present, but the specificity of the problem is lacking.", "verifiability_rationale": "The reviewer does not make a claim in the sense of asserting something is wrong or needs improvement. They are pointing out a lack of clarity. Therefore, it does not fit the defined categories for verifiability. The suggestion is more of a request for clarification than a claim requiring justification.", "helpfulness_rationale": "The reviewer provides a clear description of the issue and a concrete suggestion for improvement: 'suggestion would be great.\" This indicates a helpful and actionable comment that guides the authors towards refining their explanation. The suggestion is specific to the identified issue and directly addresses the lack of clarity."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'The reviewer is concerned about the practicality of this work.' This action is clear and actionable for the authors. They can consider alternative approaches if prior knowledge is unreliable. The reviewer points to a specific aspect of the paper (using known causal relationships) as a potential limitation, which is a direct indication of a concern that needs addressing.", "grounding_specificity_rationale": "The review point mentions 'prior knowledge about causal relationships' as a potential issue. This allows the authors to identify the specific area of concern. While the phrasing is somewhat general, it clearly points to a limitation related to the proposed method. The authors can infer that the concern is about the reliability or availability of this prior knowledge. However, the exact nature of the problem (e.g., specific subpopulations, inaccuracies) is not explicitly stated, making the grounding somewhat weak.", "verifiability_rationale": "The review point is more of an opinion or concern about the practicality of the proposed method rather than a claim that needs verification. It doesn't present a statement that requires supporting evidence or logical reasoning. The reviewer is expressing a limitation or a point of consideration, not making a definitive statement that needs to be proven.", "helpfulness_rationale": "The review point raises a valid concern about the limitations of relying on potentially flawed prior knowledge. This directly impacts the practical application and usefulness of the proposed method. The reviewer's concern is actionable and directly relevant to the authors' work, making it 5 in identifying potential weaknesses and areas for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The review states \"novelty is limited\" and provides a reason (\"tighter CIs with finetuning are expected\"). While it identifies a potential issue, it doesn't explicitly *suggest* *how* the authors should address the limited novelty or the expected behavior of CIs. The explanation is a hypothesis, not a concrete action.", "grounding_specificity_rationale": "The reviewer makes general statements about the \"novelty\" of the work and the \"expected behavior\" of confidence intervals. It doesn't explicitly refer to a specific section, table, figure, or unique aspect of the paper. The implications are broad and not tied to a concrete element.", "verifiability_rationale": "The review states \"tighter CIs with finetuning are expected\" as a reason for limited novelty. This is a statement of what *should* happen, not necessarily a claim about what *is* happening in the authors' work. While it implies a potential issue, it doesn't present a definitive assertion that requires justification. The novelty is presented as a finding, not a claim to be verified.", "helpfulness_rationale": "The review points out a potential weakness (limited novelty) and offers a plausible explanation (expected behavior of CIs). It encourages the authors to consider alternative interpretations or further analysis. While it doesn't offer a direct solution, it raises a valid point that could prompt further discussion and investigation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the desired change: 'It would make for a stronger case if the paper reports the numbers observed when the label noise experiment is performed on imagenet with 1000 classes as well'. This action is clear and directly addresses the request. The concreteness comes from specifying the exact experiment (label noise on ImageNet with 1000 classes) and the desired outcome (reporting the numbers).", "grounding_specificity_rationale": "The comment explicitly mentions 'label noise experiment', 'ImageNet', and '1000 classes'. These are specific elements of the paper, allowing the reader to identify the relevant section or experiment. The comment is also specific about the desired results ('numbers observed'). While it doesn't explicitly mention 'nontail classes', the reviewer suggests it as a 'potential followup', indicating an awareness of further detail within the same experiment. Therefore, the grounding is strong.", "verifiability_rationale": "The comment contains a claim: 'It would make for a stronger case if the paper reports the numbers observed when the label noise experiment is performed on imagenet with 1000 classes as well'. This claim suggests that reporting these numbers would be beneficial. While the verifiability is somewhat subjective, the request itself is clear and actionable. It points to a logical next step that would directly improve the paper's claims. It doesn't require external references to be considered verifiable, but it does suggest a concrete and valuable addition to the paper's experimental evaluation.", "helpfulness_rationale": "The comment provides a clear suggestion for improvement by proposing an additional experiment (label noise on ImageNet with 1000 classes) and specifying the desired outcome (reporting the numbers). This is a constructive suggestion aimed at strengthening the paper's empirical validation. While it doesn't offer a detailed methodology for the experiment, it provides a clear direction for the authors to take. The suggestion is specific enough to guide the authors in their future work. However, it doesn't offer a solution to a critical flaw in the current work, making it less than 'fully helpful'."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a suggestion and asks for justification. The phrase 'why is the number of weight updates a better metric than the number of network updates?' clearly indicates an actionable item for the authors. The reviewer is directly pointing out a potential issue with the evaluation methodology and asking for clarification, which is a clear indication of an actionable point.", "grounding_specificity_rationale": "While the reviewer implies they have encountered the paper (as they are questioning a metric used within it), they do not explicitly state the paper's title, section, or even the authors. The reviewer asks a question about a metric, which is a general request and does not specify the exact location or context of the metric within the paper. Therefore, the grounding is weak.", "verifiability_rationale": "The review point contains a claim: 'Given that the brain does everything in parallel, why is the number of weight updates a better metric than the number of network updates?'. This is a declarative statement that requires justification. While the reviewer doesn't provide the justification in the review point itself, the request for justification makes it potentially verifiable. The reviewer is asking for a logical reasoning or external references to support their question.", "helpfulness_rationale": "The review point is 5 as it directly points out a potential issue with the evaluation methodology (the choice of metric) and asks for justification. This is a constructive critique that can lead to significant improvements in the paper. The reviewer is not just pointing out a problem but also suggesting a direction for improvement by asking for a better metric. The request for justification is a valuable contribution to the paper's development."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the need to understand the motivation behind adversarial prediction accuracy. This is an explicit action. However, it doesn't specify *how* or *why* this motivation is important in a particular context, making it less concrete. Therefore, it's explicitly stated but not concrete in its application.", "grounding_specificity_rationale": "The review point is about a general concept (adversarial vs. classical accuracy) and doesn't directly refer to a specific part of a paper or experiment. It's asking about the *purpose* of a metric, not how it's applied to a specific instance. Therefore, it's 1 in a specific section or table. It also doesn't specify what makes adversarial accuracy important, so it's not specific in its details.", "verifiability_rationale": "The review point itself doesn't make a claim or assertion. It's a question about the *motivation* behind a choice, not a statement that can be verified. Therefore, it doesn't contain a claim that can be supported by evidence.", "helpfulness_rationale": "The review point asks a question about the *motivation* behind a specific type of accuracy. While it identifies a potential area for clarification, it doesn't directly point to a weakness in a paper or offer actionable advice on how to improve it. It's more about understanding a methodological choice than providing direct feedback on a paper's content. Therefore, it's not 5 in the context of improving a specific draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly mentions specific areas for improvement, such as the lack of information about the number of different sets of incontent examples and the absence of exploration of varying the number of InContext Examples. These are clear actions the authors should take to understand the experimental setup and its impact. The reviewer also points out the reliance on a single dataset, which is an actionable step to assess the generalizability of the results. All these points are stated directly, making them explicit and concrete actions. However, the reviewer does not explicitly state what needs to be done, requiring the authors to infer the necessary steps.", "grounding_specificity_rationale": "The review point explicitly mentions the 'number of different sets of incontent examples used in the experiments,' the 'effects of varying the number of InContext Examples,' and the 'reliance solely on one dataset.' These statements directly identify specific parts of the paper and the issues related to them, making them fully grounded. The reviewer also implies the importance of understanding the experiment setup and its impact on the results, making the grounding clear.", "verifiability_rationale": "The review point identifies specific issues and areas for improvement, such as the 'lack of comprehensiveness,' 'lack of transparency,' 'no mention of the number of different sets of incontent examples,' 'no exploration of the effects of varying the number of InContext Examples,' and 'reliance solely on one dataset.' These are all claims that need to be supported. However, the review point does not provide any logical reasoning, common knowledge, or external references to support these claims. The claims are based on the reviewer's observation of the paper's content.", "helpfulness_rationale": "The review point identifies several areas where the evaluation is lacking, such as comprehensiveness, transparency, and the impact of varying parameters. While these are important points for the authors to consider, the review point itself does not provide specific, actionable suggestions or insights on how to address these limitations. The reviewer points out problems without offering concrete solutions or guidance, making it less directly helpful in improving the draft itself."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The statement explicitly claims that the 'contrastive learning framework' is the 'same as SimCLR'. This is a direct action pointing to verify the relationship between these two methods. The action is concrete as it directly compares the two terms.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or method. It makes a general statement about the relationship between two established frameworks. Therefore, it is 1. The specificity of the statement is also low as it doesn't detail any specific aspect of the contrastive learning framework or SimCLR.", "verifiability_rationale": "The review point contains a claim ('The contrastive learning framework is the same as SimCLR') that can be verified. However, it does not provide any supporting evidence or details to justify this claim. It lacks specific references or examples to back up the assertion.", "helpfulness_rationale": "The review point raises a valid question about the relationship between the contrastive learning framework and SimCLR. This can be helpful for the authors if they are unsure about this relationship. However, it lacks specific details or guidance, making it less directly actionable for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the 'lack of comparative experiments' in Section 4.3 and suggests 'comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2'. This is an explicit statement that directly suggests an action: the authors should have included these specific types of experiments. The concreteness of the suggested block types further enhances the actionability of the comment. Therefore, the review point is 5.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 4.3' and specifies 'nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2'. This allows the authors to directly identify the specific part of their paper being referred to and the type of experiments that are lacking. The explicit mention of the block types further enhances the grounding of the comment. Therefore, the grounding is 5.", "verifiability_rationale": "The review point makes a claim about the 'lack of comparative experiments' with specific block types in Section 4.3. While it doesn't provide direct evidence of this lack within the review itself, it clearly identifies a specific area where the authors could have improved their experimental evaluation. The claim is stated, and the reasoning is clear. Therefore, the claim is 3.", "helpfulness_rationale": "The review point identifies a potential weakness in the experimental section (lack of specific comparisons) and suggests a concrete improvement by including these comparisons. It guides the authors to consider a specific type of comparison. This is a valuable, though not exhaustive, suggestion that can help the authors improve their experimental evaluation. Therefore, the review point is 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding more related work but does not specify how to do this, making it 1.", "grounding_specificity_rationale": "The review explicitly mentions the references 1, 2, and 3, providing full grounding and specificity.", "verifiability_rationale": "The review point is a suggestion for improvement and does not make a claim that needs verification.", "helpfulness_rationale": "The review point suggests adding more related work, which could be helpful, but it lacks specific details, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the absence of comparison against existing text GANs. While they don't explicitly state what the authors should do, they identify a missing element. However, the suggestion lacks specific details on which GANs to compare against or how to perform the comparison, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'existing text GANs' and 'SeqGAN'. While they name a specific model (SeqGAN), they don't pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. The issue (lack of comparison) is clear, but the reference isn't fully grounded. The reviewer mentions opensource implementations, which adds some grounding but doesn't specify which ones or how they relate to the paper's content.", "verifiability_rationale": "The reviewer makes a claim: 'There is no comparison against existing text GANs'. This claim is supported by the absence of such a comparison in the paper. They also mention 'SeqGAN' and 'open source implementations', which can be considered as supporting evidence or references. The claim is based on the general understanding of research practices (comparing against baselines is common).", "helpfulness_rationale": "The reviewer identifies a gap in the paper by pointing out the lack of comparison against existing text GANs. This is a relevant point, as comparison against baselines is a common practice in the field. However, the reviewer doesn't provide specific suggestions on *what* comparison to add or *how* to perform it, making the feedback somewhat general and potentially less actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states the *problem* (lack of focus on algorithms) and *suggestion* (the Blackwell winner concept makes the novelty seem limited). The *how* of addressing this isn't explicitly suggested (e.g., \"Analyze the algorithmic complexity,\" \"Compare with existing algorithms\"). The reviewer points out a potential weakness but doesn't offer specific, actionable advice on how to address it. The connection between the Blackwell winner and the limited novelty could be more explicit.", "grounding_specificity_rationale": "The reviewer makes a general comment about the *algorithmic aspects* of the solution. While they mention the \"Blackwell winner,\" they don't specify *which* algorithm or part of the solution they're referring to. The connection to \"novelty\" is also general. The reviewer mentions algorithmic aspects and the Blackwell winner, but lacks precise identification of a specific section, table, figure, or unique element. The mention of \"novelty\" is also quite general.", "verifiability_rationale": "The reviewer states a *belief* about the paper's limitations due to the algorithmic focus. This is a claim. However, the reviewer doesn't provide any specific evidence, reasoning, or references to support this belief. The statement is presented as an opinion.", "helpfulness_rationale": "The reviewer raises a valid point about the potential limitations of focusing solely on the algorithmic aspects and the perceived lack of novelty due to the Blackwell winner. However, they don't offer specific, actionable steps for the authors to take to address this. The suggestion is more of a question or a statement of concern than a concrete piece of advice. The authors might gain a *concern* about the paper's scope and the perceived novelty of the Blackwell winner, but they won't get a clear roadmap on how to improve it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desired action: 'split the tables' and provides specific instructions: 'put the 8 SFII columns together' and 'put the 8 SPDI columns together'. This is a clear and concrete action to be taken.", "grounding_specificity_rationale": "The reviewer refers to 'Tables 4 and 5' and mentions the specific data types 'SFII' and 'SPDI'. This clearly identifies the specific parts of the paper being addressed. The reviewer also provides very specific instructions about which columns to move where, making it 5.", "verifiability_rationale": "The reviewer makes a claim about the readability of Tables 4 and 5 and suggests a solution. While the impact on readability isn't directly verifiable through the review point itself, the suggestion itself is a clear and actionable recommendation. The reviewer is stating a claim that this reorganization will improve readability, and this claim is supported by logical reasoning (improving readability) and specific instructions (how to reorganize).", "helpfulness_rationale": "The suggestion directly addresses a practical issue (readability of tables) and is very specific about how to improve it. It is a clear and actionable recommendation that is likely to be beneficial for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that clarifying the difference between 'valid' and 'orig' in Figure 5 is needed. This is a direct identification of a specific action the authors should take. Therefore, the action is explicit. Furthermore, the reviewer directly asks for clarification on a specific aspect of the figure, which is a concrete action with a clear goal.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Fig. 5' and then specifically asks about the difference between 'valid' and 'orig' within that figure. This directly identifies the specific part of the paper being addressed and the issue within it. Therefore, the grounding is fully grounded. The specificity is high as the reviewer clearly states what needs to be clarified.", "verifiability_rationale": "The reviewer states that clarifying the difference between 'valid' and 'orig' in Figure 5 would be helpful for the authors. While the reviewer states the benefit, they do not provide any logical reasoning, examples, or references to support why this clarification is valuable. The claim is present ('it would be helpful'), but the verification is missing.", "helpfulness_rationale": "The reviewer explicitly states that clarifying the difference between 'valid' and 'orig' in Figure 5 would be helpful for the authors. This directly indicates the value of the feedback provided."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the desired improvement: 'It could be improved by making these comparisons more systematic with respect to the tuning of each methodi.e. compare the best performance of each.' This clearly indicates an action the authors should take. Furthermore, the suggestion to 'compare the best performance of each' is concrete and provides a clear direction for improvement. The authors know exactly what needs to be done.", "grounding_specificity_rationale": "The comment refers to 'the best performance of each method,' which implies a specific aspect of the comparison. While it doesn't explicitly name a section or table, the focus on 'best performance' suggests the authors can identify the relevant part. This can be considered 'weak grounding' as the authors need to infer where to find this information. The comment specifies 'what needs to be addressed' (comparison of best performances) but is vague on how to *systematically* achieve this.", "verifiability_rationale": "The comment contains a claim: 'It could be improved by making these comparisons more systematic with respect to the tuning of each methodi.e. compare the best performance of each.' This claim is supported by the idea of finding the 'best performance' and comparing it. The reasoning is logical \u2013 improving systematicity and comparing best performances are reasonable suggestions for improvement. External references are not directly provided, but the suggestion is based on common practices in evaluating methods.", "helpfulness_rationale": "The comment is 5 because it directly addresses a potential weakness in the current comparison (lack of systematic comparison of best performances) and provides a clear and actionable suggestion for improvement. The authors can directly implement this by focusing on the best performance of each method and comparing them systematically. The suggestion is clear, measurable, and directly relevant to the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing to 'methods mentioned in the computer vision setting,' which can be considered an explicit action. However, the specifics of these methods are not detailed, making the action somewhat vague.", "grounding_specificity_rationale": "The review point mentions 'methods mentioned in the computer vision setting.' While it identifies a category of methods, it doesn't specify which particular method or provide details on how these methods relate to the current work. This makes the grounding weakly specific.", "verifiability_rationale": "The review point states an opinion that 'These are not always applicable and typically require a supervised setup' and suggests that 'some of them can probably be adapted to language tasks relatively easily.' The first part is a factual statement that can be verified. The second part is a suggestion and inference, which is not verifiable with concrete evidence.", "helpfulness_rationale": "The review point suggests a potential improvement by comparing to 'methods mentioned in the computer vision setting.' This points to a specific area for further investigation and could be considered helpful as it offers a direction for comparison. However, the lack of specificity makes the suggestion somewhat vague and potentially less impactful."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a missing element (time complexity estimation) but does not explicitly state what action the author should take to address this. While it implicitly points to an area for improvement, the lack of concrete guidance makes it 3.", "grounding_specificity_rationale": "The review point mentions 'time complexity of the learning algorithm,' which is a specific technical term within the paper. While it doesn't explicitly name a section or figure, it clearly identifies the area where the issue lies. However, it doesn't specify what is wrong or missing within this area.", "verifiability_rationale": "The review point states that 'the time complexity of the learning algorithm should be explicitly estimated.' This is a prescription for improvement, not a claim that requires verification. It doesn't provide any logical reasoning, common knowledge, or external references to support this suggestion.", "helpfulness_rationale": "The review point identifies a valid point for improvement (the lack of explicit time complexity estimation) but does not provide any concrete steps or guidance on how to address this. It essentially tells the author what they *should* do but not how to *do it*."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests investigating a potential connection to the properties of universal kernels, specifically mentioning Chapter 4 of Steinwart and Christmann. This is an explicit action, as the reviewer clearly states the action to be taken: 'investigate the connection'. The action is to explore this theoretical link.", "grounding_specificity_rationale": "The reviewer mentions 'properties of universal kernels' and specifically points to 'chapter 4 of Steinwart and Christmann'. This indicates a strong grounding as the reviewer identifies a specific area of external knowledge. However, the reviewer does not specify which property of universal kernels is relevant or which specific aspect of the paper they are connecting it to. The grounding is weak because the authors cannot confidently determine the exact part of the external resource that is relevant to their work.", "verifiability_rationale": "The reviewer suggests a potential connection and provides a reference to Steinwart and Christmann as justification. This constitutes a claim that the paper should investigate this connection. The claim is 3 because the reviewer provides a reference to external literature that supports the possibility of such a connection. However, the reviewer does not explicitly explain *why* this connection is important or how it would improve the paper.", "helpfulness_rationale": "The reviewer's suggestion to investigate the connection to universal kernels is a suggestion for improvement. While the suggestion is relevant to the theoretical underpinnings of the paper, it does not directly point to a specific flaw or improvement needed in the submitted work. The reviewer is offering a highlevel direction for further research rather than a concrete, actionable fix. Therefore, it is 3 as a direction for improvement, but not a direct solution."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "X (X)", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a problem ('terse and not very clearly explained') but does not explicitly state what the author should do to address it. The author would need to infer that they should expand the discussion and improve the clarity of their explanations. The action is implicit.", "grounding_specificity_rationale": "The review point explicitly mentions 'equation (10)', which is a specific part of the paper. The author can identify the section where the discussion takes place. The grounding is literal.", "verifiability_rationale": "The review point makes a statement about the clarity of the discussion around equation (10) without making a specific claim that can be verified. It's a critique of the writing style. There is X being made that requires logical reasoning, common knowledge, or external references to be supported.", "helpfulness_rationale": "The review point identifies a valid area for improvement (the discussion around equation 10). It alerts the author to a potential weakness in their writing. However, it doesn't provide specific, actionable guidance on *how* to improve the discussion. The author still needs to figure out the next steps. While it points to a problem, it doesn't fully empower the author to fix it."}
